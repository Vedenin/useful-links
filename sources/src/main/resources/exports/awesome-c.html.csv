"category"	"name"	"url"	"description"	"star"	"stackOverflow"	"stackOverflowUrl"	"license"	"licenseUrl"	"site"	"userGuide"	"newStars"	"newWatchs"	"newForks"	"pageText"	"newStackOverflow"	"github"	"allText"	"isExist"
"awesome-c"	"@kozross"	"https://github.com/kozross"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"kozross (Koz Ross) · GitHub Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub Koz Ross kozross koz.ross@runbox.com http://www.retro-freedom.nz Joined on Aug 16, 2014 29 Followers 58 Starred 0 Following Follow Overview Repositories Public activity Popular repositories awesome-c 890 A curated list of awesome C frameworks, libraries, resources and other shiny things. Inspired by all the other awesome-... projects out there. base-prelude 0 The most complete prelude formed only from the ""base"" package classy-prelude 0 A typeclass-based Prelude. flycheck 0 Modern on the fly syntax checking for GNU Emacs mono-traversable 0 Type classes for mapping, folding, and traversing monomorphic containers 176 contributions in the last year Jul Aug Sep Oct Nov Dec Jan Feb Mar Apr May Jun S M T W T F S Summary of pull requests, issues opened, and commits. Learn how we count contributions. Less More Period: 1 week Filter activity 1 day 3 days 1 week 1 month Contribution activity kozross has no activity during this period. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/kozross"	""	"true"
"Build Systems"	"aimake"	"http://nethack4.org/projects/aimake/"	"A build tool designed to avoid complex configurations. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"Aimake NetHack 4 homepage aimake Originally developed for NetHack 4, aimake is a build system designed to enable compilation of C programs without a need for time-consuming configuration. To this end, it attempts to determine things like dependencies and the exact paths of header files automatically. aimake is a single file (a Perl script) licensed under the GNU GPL, that therefore can be shipped with your project and allow users to compile your program with no further build system depenencies but Perl and a C toolchain. Typical usage is as follows:    mkdir build   cd build   ../aimake -i ~/install_dir     # or wherever you want  aimake is still a work in progress; in particular, some features might be unimplemented or not work yet. (In particular, it currently needs manual configuration to be able to install the files it compiles.) Resources you might be interested in: aimake's source repository is available via darcs:  darcs clone http://nethack4.org/media/aimake3   You can also download aimake's source code or test suite directly. aimake's documentation is available online (including a longer explanation of why you may find aimake useful); this documentation can also be viewed using aimake --documentation."	"null"	"null"	"A build tool designed to avoid complex configurations. or later."	"true"
"Build Systems"	"Autoconf"	"https://www.gnu.org/software/autoconf/"	"An extensible package of M4 macros that produce shell scripts to automatically configure software source code packages. Part of the Autotools. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	""	"null"	"null"	"An extensible package of M4 macros that produce shell scripts to automatically configure software source code packages. Part of the Autotools. or later."	"true"
"Build Systems"	"Automake"	"https://www.gnu.org/software/automake/automake.html"	"A tool for automatically generating files compliant with the GNU Coding Standards. Requires the use of Autoconf. Part of the Autotools. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"Automake - GNU Project - Free Software Foundation Skip to main text Set language English [en] The  9th HACKERS MEETING  will be held in Rennes (France) from August 18 to 20. JOIN THE FSF Free Software Supporter GNU Operating System Sponsored by the Free Software Foundation About GNU Philosophy Licenses Education = Software = Documentation Help GNU Automake Table of Contents Introduction to Automake Downloading Automake Documentation Mailing Lists Bug Reports Introduction to Automake Automake is a tool for automatically generating Makefile.in files compliant with the GNU Coding Standards. Automake requires the use of Autoconf. Downloading Automake Please note that Automake 1.12.2 and Automake 1.11.6 fix a security issue (CVE-2012-3386) present in the make distcheck rules of all packages using Automake. See here for details. GNU Automake can be found on http://ftp.gnu.org/gnu/automake/ [via http] and ftp://ftp.gnu.org/gnu/automake/ [via FTP]. It can also be found on one of our FTP mirrors. You can also order a CD-ROM from the FSF or use other methods to obtain a copy. Alpha/beta releases of Automake can be found in ftp://alpha.gnu.org/pub/gnu/automake/, and the latest in-development sources for Automake can always be fetched through git from Savannah. DO NOT use Automake sources from these locations for production use. Documentation The Automake manual can be read on-line or downloaded in PDF format; also, more formats are offered for download or on-line reading. If you have installed Automake on your system, you may also find more information about it by looking at your local documentation; for example you might use info automake at the shell prompt. In case you are interested or merely curious, a brief history of Automake (up to roughly 2007) is available on our site; again, more formats are offered for download or on-line reading. Mailing Lists Automake has several public mailing lists, each of which is archive. For general Automake discussions, use <automake@gnu.org> (archives and subscription). If you have a patch for Automake, please send the it to <automake-patches@gnu.org> (archives and subscription). The HACKING file present in the Automake git repository should explain how to properly prepare, format and post a patch. Bug reports can be emailed to <bug-automake@gnu.org> (archives and subscription). Before submitting a bug report, please read the Bug Reporting section of the manual. You can subscribe to any Automake mailing list via the associated web interfaces, linked above. Or you can send an empty mail with a Subject: header line of just ""subscribe"" to the relevant -request list. For example, to subscribe yourself to the bug-automake list, you would send mail to <bug-automake-request@gnu.org> with no body and a Subject: header line of just ""subscribe"". It has been necessary to moderate the GNU Automake mailing lists to prevent the flood of spam. Postings to the lists are held for release by the list moderator. Sometimes the moderators are unavailable for brief periods of time. Please be patient when posting. If you don't see the message in the list archive an hour or so after having sent it, then it did not get posted. Bug Reports For bugs in Automake, please see the Bug Reporting section of the manual. GNU home page FSF home page GNU Art GNU's Who? Free Software Directory Hardware Site map “Our mission is to preserve, protect and promote the freedom to use, study, copy, modify, and redistribute computer software, and to defend the rights of Free Software users.” The Free Software Foundation is the principal organizational sponsor of the GNU Operating System. Support GNU and the FSF by buying manuals and gear, joining the FSF as an associate member, or making a donation, either directly to the FSF or via Flattr. back to top Please send general FSF & GNU inquiries to <gnu@gnu.org>. There are also other ways to contact the FSF. Broken links and other corrections or suggestions can be sent to <bug-automake@gnu.org>. Please see the Translations README for information on coordinating and submitting translations of this article. Copyright © 1997, 1998, 2001-2007, 2010-2012 Free Software Foundation, Inc. This page is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License. Copyright Infringement Notification Updated: $Date: 2016/05/23 19:47:30 $"	"null"	"null"	"A tool for automatically generating files compliant with the GNU Coding Standards. Requires the use of Autoconf. Part of the Autotools. or later."	"true"
"Build Systems"	"Jam"	"https://www.perforce.com/resources/documentation/jam"	"A build system, designed to be easier than make. Understands C build rules implicitly.."	"null"	"null"	"null"	"Jam License"	"https://en.wikipedia.org/wiki/Perforce_Jam#License"	"null"	"null"	"null"	"null"	"null"	"Jam | Perforce <img height=""1"" width=""1"" style=""display:none"" src=""https://www.facebook.com/tr?id=1691462611112457&amp;ev=PageView&amp;noscript=1""> Skip to main content Search form Search English中文日本語한국어 Community Partners Careers Contact MENU   MENU   Products Helix Overview Helix Versioning Engine Helix GitSwarm Helix Swarm Helix Apps Watch a Demo Customers Game Development Automotive Banking & Finance Embedded Systems Case Studies Compare Perforce Migration Tools Watch a Testimonial Resources DevOps Best Practices Security Scalability Events Webinars Blog Subscribe Support Tutorial Videos Documentation Knowledge Base Open Support Case Consulting Training How to Reach Us Download Software Free Trial You are here Home › DevOps › › Jam Jam Product Information Jam is a software build tool that makes building simple things simple and building complicated things manageable. It has been freely available as C source for many years from the Perforce Workshop and is widely used to build commercial and academic software. Jam is a very good solution for conventional C/C++ compile-and-link builds. Because Jam understands C/C++ dependencies, there is no need to declare header or object files. The built-in Jam rule ""Main"" handles header file dependencies and object files both automatically and on-the-fly. Table 1 compares a Makefile and a Jamfile for building a simple program. Table 1 - Jamfile vs Makefile for compiling a simple C program Jamfile Makefile Main proga : data.c main.c io.c ; proga: data.o main.o io.o       cc data.o main.o io.o -o proga data.o: data.c data.h       cc -c data.c main.o: data.h io.h main.c       cc -c main.c io.o: io.h io.c       cc -c io.c Before any targets are updated, Jam gathers complete dependency information for C/C++ source files, allowing Jam to: Build as much as possible, instead of halting on the first build error. Avoid building targets if targets on which they depend fail to build. Build across parallel paths with multiple, concurrent processes. Additional Jam features Unintrusive and clean Jam is small, it has negligible CPU overhead, and it doesn't create or leave behind temporary files. Scalable Jam is able to build large projects spread across many directories in a single pass and can manage and distribute build steps to multiple processors on one or more networked machines. Highly portable Jam runs on UNIX, VMS, NT, OS/2, Mac OS X, and Mac MPW. Most Jamfiles (like the sample above) are also portable. Multiplatform Platform independent rules and platform specific actions can be defined separately from dependency rules. Customizable Developers can enhance/extend Jam by creating user defined rules to utilize other built-in directives. Language Jam includes flow-control statments, variables, and a few other features of general purpose languages. Free Jam is free and can be incorporated into commercial products without licensing restrictions. Getting the Source The source for Jam is freely available from the Perforce Workshop.   White Papers and Examples Jam has been around since 1993 and has a long history of use in many different settings. Here are some white papers and examples of Jam in use: Getting Started with Jam - A Tutorial (PDF) - from the 2001 Perforce User Conference. The UNIX Application Development Symposium paper on Jam - Jam product overview (1994). Constructing a Large Product with Jam - an experience report from SCM7, the 7th International Workshop on Software Configuration Management, Boston, May 1997. Getting and Building the Haiku Source Code with Jam Comparing the Jam language to other programming languages   Documentation Jam.html - Jam man page - a terse description of Jam and its language. Jambase.html - Reference for the rule boilerplate file. Jamfile.html - Easy reading on creating a Jamfile and using jam. RELNOTES - Current release notes. Porting - Notes on porting jam to wildcat platforms. README - Installation instructions. jam.c - Contains jam's main() as well as an introduction to the code, for serious hackers. Support While Jam comes with no warranties or guarantees and is not supported by Perforce, assistance on Jam is available from the Jamming mailing list which provides a forum to submit your own questions or to review posts from other Jam users. Helpful tips and past discussion can be found in the Jamming archive. Consulting services specific to Jam and build related issues are available from VIZIM Worldwide, a Perforce Consulting Partner.   Release History November, 1993 - release 1.0 March, 1995 - release 2.0 February, 1996 - release 2.1 November, 1997 - release 2.2 December, 2000 - release 2.3 March, 2002 - release 2.4 April, 2003 - release 2.5 August, 2014 - release 2.6   Other Resources FreeType.org's modified version of Jam, FT Jam, is 100% backwards compatible with classic Jam and can be used as a plug-in replacement for it. Products Helix Helix Swarm Helix GitSwarm Helix Apps Third-Party Integrations — Free Trial Demo Pricing Downloads Customers Case Studies Video Testimonials Compare Perforce — Game Development Automotive Industry Banking & Finance Embedded Systems — MERGE Conference Resources Events Webinars Resources Blog — Sign up for our Newsletter Support Downloads How to Reach Us Support Plans — Documentation Knowledge Base Tutorial Videos — Consulting Training ABOUT Our Company Our Team — Partners Press Releases Press Coverage Careers — Contact Us Communication Center Visit our Communication Center to sign up for News, Tips and Updates Copyright © 2016 Perforce. All rights reserved. Contact Site Map Terms of Use Privacy Policy Privacy Settings"	"null"	"null"	"A build system, designed to be easier than make. Understands C build rules implicitly.."	"true"
"Build Systems"	"Libtool"	"https://gnu.org/software/libtool/"	"A generic library support script. Part of the Autotools. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"GNU Libtool - GNU Project - Free Software Foundation Skip to main text Set language English [en] The  9th HACKERS MEETING  will be held in Rennes (France) from August 18 to 20. JOIN THE FSF Free Software Supporter GNU Operating System Sponsored by the Free Software Foundation About GNU Philosophy Licenses Education = Software = Documentation Help GNU GNU Libtool - The GNU Portable Library Tool Home | Documentation | Contributing | Administration Introduction to GNU Libtool GNU libtool is a generic library support script. Libtool hides the complexity of using shared libraries behind a consistent, portable interface. To use libtool, add the new generic library building commands to your Makefile, Makefile.in, or Makefile.am. See the documentation for details. Downloading GNU Libtool GNU Libtool can be found on http://ftpmirror.gnu.org/libtool/ [via http] and ftp://ftp.gnu.org/gnu/libtool/ [via FTP]. It can also be found on one of our FTP mirrors; please use a mirror if possible. The latest stable version is http://ftpmirror.gnu.org/libtool/libtool-2.4.6.tar.gz. The latest libtool development sources are available via git. Use the following command to check them out:  $ git clone git://git.savannah.gnu.org/libtool.git  Once you have the tree checked out, you can keep it up to date by using git pull. Please see http://savannah.gnu.org/git/?group=libtool for more information. Documentation GNU Libtool documentation can be found at http://www.gnu.org/s/libtool/manual/. You may also find more information about GNU Libtool by running info libtool on your system. Mailing Lists GNU Libtool has four mailing lists: <libtool@gnu.org> , <libtool-patches@gnu.org> , <bug-libtool@gnu.org> and <libtool-commit@gnu.org> . The main discussion list is <libtool@gnu.org>, and is used to discuss all aspects of GNU Libtool, including development and porting. There is a separate list used for reporting bugs, <bug-libtool@gnu.org>. For details on submitting a bug report, please see the section Report a Bug below. libtool-patches@gnu.org is where the patches to the libtool repository are posted for peer review before being commited. libtool-commit@gnu.org is where summaries of changes committed to the repository are automatically posted. Announcements about GNU Libtool, Autoconf, Automake, and M4 are made on <autotools-announce@gnu.org>. Important announcements about Libtool and most other GNU Software in general are also made on <info-gnu@gnu.org>. You can read also read release announcements by subscribing to the atom feed at http://savannah.gnu.org/news/?group=libtool for libtool specific news, or watch GNU Planet for libtool items among other GNU news. To subscribe to these or any GNU mailing lists, please send an empty mail with a Subject: header line of just ""subscribe"" to the relevant -request list. For example, to subscribe yourself to GNU announcement list, you would send mail to <info-gnu-request@gnu.org> with no body and a Subject: header line of just ""subscribe"". Or you can use the mailing list web interface. Request an Enhancement If you would like any new feature to be included in future versions of GNU Libtool, please send a request to <libtool@gnu.org>. Please remember that development of GNU Libtool is a volunteer effort, and you can also contribute to its development. For information about contributing to the GNU Project, please read How to help GNU. Report a Bug If you think you have found a bug in GNU Libtool, then please send as complete a report as possible to <bug-libtool@gnu.org>. Maintainer GNU Libtool is currently being maintained by Bob Friesenhahn. GNU home page FSF home page GNU Art GNU's Who? Free Software Directory Hardware Site map “Our mission is to preserve, protect and promote the freedom to use, study, copy, modify, and redistribute computer software, and to defend the rights of Free Software users.” The Free Software Foundation is the principal organizational sponsor of the GNU Operating System. Support GNU and the FSF by buying manuals and gear, joining the FSF as an associate member, or making a donation, either directly to the FSF or via Flattr. back to top Please send general FSF & GNU inquiries to <gnu@gnu.org>. There are also other ways to contact the FSF. Broken links and other corrections or suggestions can be sent to <libtool@gnu.org>. Please see the Translations README for information on coordinating and submitting translations of this article. Copyright © 2007, 2008, 2011 Free Software Foundation, Inc. This page is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License. Copyright Infringement Notification Updated: $Date: 2016/06/04 08:51:50 $"	"null"	"null"	"A generic library support script. Part of the Autotools. or later."	"true"
"Build Systems"	"Meson"	"http://mesonbuild.com/"	"An extremely fast, user-friendly build system. Based on Ninja.."	"null"	"null"	"null"	"Apache2.0"	"http://directory.fsf.org/wiki/License:Apache2.0"	"null"	"null"	"null"	"null"	"null"	"The Meson® Build System The Meson Build System Main page Sample code Download Documentation Dependencies Development Community Videos Legal Overview Meson is an open source build system meant to be both extremely fast, and, even more importantly, as user friendly as possible. The main design point of Meson is that every moment a developer spends writing or debugging build definitions is a second wasted. So is every second spent waiting for the build system to actually start compiling code. Features multiplatform support for Linux, OSX, Windows, Gcc, Clang, Visual Studio and others supported languages include C, C++, Fortran, Java, Rust build definitions in a very readable and user friendly non-turing complete DSL cross compilation for many operating systems as well as bare metal optimized for extremely fast full and incremental builds without sacrificing correctness built-in multiplatform dependency provider that works together with distro packages fun!"	"null"	"null"	"An extremely fast, user-friendly build system. Based on Ninja.."	"true"
"Compilers"	"Clang"	"http://clang.llvm.org/"	"A C compiler for LLVM. Supports C11.."	"null"	"null"	"null"	"NCSA"	"http://directory.fsf.org/wiki/License:IllinoisNCSA"	"null"	"null"	"null"	"null"	"null"	"""clang"" C Language Family Frontend for LLVM LLVM Home Clang Info Download About Features Comparisons Related Projects User's Manual Language Compatibility Language Extensions C++ Status Clang Development Get Started Get Involved Open Projects Clang Internals Hacking on Clang Clang Tools Automatic Bug-Finding Writing Clang Tools Communication cfe-users List cfe-dev List cfe-commits List Bug Reports Planet Clang IRC: irc.oftc.net#llvm The Code Check Out SVN Browse SVN Browse ViewVC doxygen Quick Links Testing Coverage Clang Events October 2009 November 2010 LLVM events clang: a C language family frontend for LLVM The goal of the Clang project is to create a new C, C++, Objective C and Objective C++ front-end for the LLVM compiler. You can get and build the source today. Features and Goals Some of the goals for the project include the following: End-User Features: Fast compiles and low memory use Expressive diagnostics (examples) GCC compatibility Utility and Applications: Modular library based architecture Support diverse clients (refactoring, static analysis, code generation, etc.) Allow tight integration with IDEs Use the LLVM 'BSD' License Internal Design and Implementation: A real-world, production quality compiler A simple and hackable code base A single unified parser for C, Objective C, C++, and Objective C++ Conformance with C/C++/ObjC and their variants Of course this is only a rough outline of the goals and features of Clang. To get a true sense of what it is all about, see the Features section, which breaks each of these down and explains them in more detail. Why? Development of the new front-end was started out of a need for a compiler that allows better diagnostics, better integration with IDEs, a license that is compatible with commercial products, and a nimble compiler that is easy to develop and maintain. All of these were motivations for starting work on a new front-end that could meet these needs. A good (but quite dated) introduction to Clang can be found in the following video lectures: Clang Introduction (May 2007) Features and Performance of Clang (July 2007) For a more detailed comparison between Clang and other compilers, please see the clang comparison page. Current Status Clang is considered to be a production quality C, Objective-C, C++ and Objective-C++ compiler when targeting X86-32, X86-64, and ARM (other targets may have caveats, but are usually easy to fix). If you are looking for source analysis or source-to-source transformation tools, Clang is probably a great solution for you. Clang supports C++11, please see the C++ status page for more information. Get it and get involved! Start by getting the code, building it, and playing with it. This will show you the sorts of things we can do today and will let you have the ""Clang experience"" first hand: hopefully it will ""resonate"" with you. :) Once you've done that, please consider getting involved in the clang community. The Clang developers include numerous volunteer contributors with a variety of backgrounds. If you're interested in following the development of Clang, signing up for a mailing list is a good way to learn about how the project works."	"null"	"null"	"A C compiler for LLVM. Supports C11.."	"true"
"Compilers"	"CompCert"	"https://github.com/AbsInt/CompCert"	"A fully-verified C compiler. Supports almost all of C89. or later."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"196"	"23"	"30"	"GitHub - AbsInt/CompCert: The CompCert C verified compiler Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 23 Star 196 Fork 30 AbsInt/CompCert Code Issues 5 Pull requests 2 Pulse Graphs The CompCert C verified compiler http://compcert.inria.fr/ 1,761 commits 3 branches 3 releases 7 contributors Coq 49.2% C 38.3% OCaml 10.4% Assembly 1.5% Makefile 0.3% Standard ML 0.1% Other 0.2% Coq C OCaml Assembly Makefile Standard ML Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags generic-selection master release2.7 Nothing to show v2.7 v2.6 v2.5 Nothing to show New pull request Latest commit c9cbfda Jul 11, 2016 xavierleroy committed on GitHub Merge pull request #105 from m-schmidt/master … Fix parsing and handling of CMinor files Permalink Failed to load latest commit information. arm Port to Coq 8.5pl2 Jul 8, 2016 backend Merge pull request #105 from m-schmidt/master Jul 11, 2016 cfrontend Port to Coq 8.5pl2 Jul 8, 2016 common Unwanted partial constant propagation in 64-bit integer arguments to … Jul 8, 2016 cparser Port to Coq 8.5pl2 Jul 8, 2016 debug Activate advanced debug information for arm, ia32. Jun 28, 2016 doc Update in preparation for release 2.7 Jun 22, 2016 driver add missing asmexpand step to cminor handler in driver Jul 1, 2016 exportclight Fixed warning 45 for ExportClight.ml. May 28, 2016 extraction Port to Coq 8.5pl2 Jul 8, 2016 flocq Port to Coq 8.5pl2 Jul 8, 2016 ia32 Port to Coq 8.5pl2 Jul 8, 2016 lib Port to Coq 8.5pl2 Jul 8, 2016 powerpc Port to Coq 8.5pl2 Jul 8, 2016 runtime Added iso646 header for alternate spellings. Apr 6, 2016 test Unwanted partial constant propagation in 64-bit integer arguments to … Jul 8, 2016 tools Updated PR by removing whitespaces. Bug 17450. Oct 20, 2015 .depend Port to Coq 8.5pl2 Jul 8, 2016 .gitignore Port to Coq 8.5pl2 Jul 8, 2016 Changelog Port to Coq 8.5pl2 Jul 8, 2016 LICENSE common/Determinism.v: dual-license with GPL Jun 30, 2016 Makefile Port to Coq 8.5pl2 Jul 8, 2016 Makefile.extr Remove code that will is deprecated in ocaml 4.03 Jun 21, 2016 Makefile.menhir Use ifndef correct. Bug 17481 Oct 27, 2015 README.md Further updates to README.md Apr 4, 2015 VERSION Port to Coq 8.5pl2 Jul 8, 2016 configure Port to Coq 8.5pl2 Jul 8, 2016 coq ia32/Select*: complete the modifications to shifts. Apr 11, 2014 pg ia32/Select*: complete the modifications to shifts. Apr 11, 2014 README.md CompCert The verified C compiler. Overview The CompCert C verified compiler is a compiler for a large subset of the C programming language that generates code for the PowerPC, ARM and x86 processors. The distinguishing feature of CompCert is that it has been formally verified using the Coq proof assistant: the generated assembly code is formally guaranteed to behave as prescribed by the semantics of the source C code. For more information on CompCert (supported platforms, supported C features, installation instructions, using the compiler, etc), please refer to the Web site and especially the user's manual. License CompCert is not free software. This non-commercial release can only be used for evaluation, research, educational and personal purposes. A commercial version of CompCert, without this restriction and with professional support, can be purchased from AbsInt. See the file LICENSE for more information. Copyright The CompCert verified compiler is Copyright 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015 Institut National de Recherche en Informatique et en Automatique (INRIA). Contact General discussions on CompCert take place on the compcert-users@inria.fr mailing list. For inquiries on the commercial version of CompCert, please contact info@absint.com Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/AbsInt/CompCert"	"A fully-verified C compiler. Supports almost all of C89. or later."	"true"
"Compilers"	"GCC"	"https://gcc.gnu.org/"	"Provides a C compiler as part of its compiler set. Supports C11 and OpenMP. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"GCC, the GNU Compiler Collection - GNU Project - Free Software Foundation (FSF) GCC, the GNU Compiler Collection The GNU Compiler Collection includes front ends for C, C++, Objective-C, Fortran, Java, Ada, and Go, as well as libraries for these languages (libstdc++, libgcj,...). GCC was originally written as the compiler for the GNU operating system. The GNU system was developed to be 100% free software, free in the sense that it respects the user's freedom. We strive to provide regular, high quality releases, which we want to work well on a variety of native and cross targets (including GNU/Linux), and encourage everyone to contribute changes or help testing GCC. Our sources are readily and freely available via SVN and weekly snapshots. Major decisions about GCC are made by the steering committee, guided by the mission statement. News GCC 5.4 released [2016-06-03] 2015 ACM Software System Award [2016-04-29] GCC 6.1 released [2016-04-27] Heterogeneous Systems Architecture support [2016-01-27] Heterogeneous Systems Architecture 1.0 support was added to GCC, contributed by Martin Jambor, Martin Liška and Michael Matz from SUSE. GCC 5.3 released [2015-12-04] GCC 5.2 released [2015-07-16] GCC 4.9.3 released [2015-06-26] GCC 4.8.5 released [2015-06-23] GCC 5.1 released [2015-04-22] MIPS Release 6 architecture support [2015-01-20] Support for MIPS Release 6 (r6) has been contributed by Imagination Technologies. OpenMP 4.0 offloading support in GCC [2015-01-14] OpenMP 4.0 offloading support was added to GCC. Contributed by Jakub Jelinek (Red Hat), Bernd Schmidt and Thomas Schwinge (CodeSourcery), Andrey Turetskiy, Ilya Verbin and Kirill Yukhin (Intel). Older news | Nick's Blog | More news? Let gerald@pfeifer.com know! Releases GCC 6.1 (changes) Status: 2016-04-27 (regression fixes & docs only). Serious regressions. All regressions. GCC 5.4 (changes) Status: 2016-06-03 (regression fixes & docs only). Serious regressions. All regressions. GCC 4.9.3 (changes) Status: 2015-06-26 (regression fixes & docs only). Serious regressions. All regressions. Development: GCC 7.0 (release criteria) Status: 2016-04-15 (general development, stage 1). Serious regressions. All regressions. Search our site Match: All words Any word Boolean expression Sort by: Newest Best Match There is also a detailed search form. Get our announcements About GCC Mission Statement Releases Snapshots Mailing lists Contributors Steering Committee @gnutools gnutools Documentation Installation · Platforms Manual FAQ Wiki Pointers Download Mirrors Binaries Sources SVN read access SVN write access Git read access Rsync Development Development Plan · Timeline Contributing Why contribute? Open projects Front ends Back ends Extensions Benchmarks Build Robot Translations Bugs Known bugs How to report Bug tracker · Management For questions related to the use of GCC, please consult these web pages and the GCC manuals. If that fails, the gcc-help@gcc.gnu.org mailing list might help. Comments on these web pages and the development of GCC are welcome on our developer list at gcc@gcc.gnu.org. All of our lists have public archives. Copyright (C) Free Software Foundation, Inc. Verbatim copying and distribution of this entire article is permitted in any medium, provided this notice is preserved. These pages are maintained by the GCC team. Last modified 2016-06-05."	"null"	"null"	"Provides a C compiler as part of its compiler set. Supports C11 and OpenMP. or later."	"true"
"Compilers"	"PCC"	"http://pcc.ludd.ltu.se/"	"A venerable C compiler. Supports C99. all free."	"null"	"null"	"null"	"Various licenses"	"http://pcc.ludd.ltu.se/licenses/"	"null"	"null"	"null"	"null"	"null"	"pcc - pcc portable c compiler pcc Welcome to pcc, the Portable C Compiler. This website is a wiki. Please join and help improve the website and pcc. The compiler is based on the original Portable C Compiler by S. C. Johnson, written in the late 70's. About 50% of the frontend code and 80% of the backend code has been modified. See the PCC History wiki page for details. PCC 1.1.0 is out as of 2014-12-10! News Downloads Mailing Lists Documentation PCC C Language Internals Books Bugs and issue tracking. TODO Standards and Regression Testing Useful links The project goal is to write a C99 compiler while still keeping it small, simple, fast and understandable. PCC is not affiliated with any other project, but the compiler has been imported into the OpenBSD and NetBSD base systems. The project is maintained by me (ragge). This product includes software developed or owned by Caldera International, Inc. (See Licenses.) Edit RecentChanges History Preferences Discussion Last edited Wed Dec 10 18:13:08 CET 2014"	"null"	"null"	"A venerable C compiler. Supports C99. all free."	"true"
"Compilers"	"TCC"	"http://bellard.org/tcc/"	"Tiny C Compiler; a small, fast C compiler. Supports C99 (except complex types). only."	"null"	"null"	"null"	"GNU LGPL2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"null"	"null"	"null"	"TCC : Tiny C Compiler Tiny C Compiler News [Note: I am no longer working on TCC. Check the mailing list to get up to date information.] (Feb 15, 2013) TCC version 0.9.26 is out thanks to Thomas Preud'homme (Changelog). Summary of the changes: Support for C99 VLA Generation of make dependencies (-MD/-MF) Support improved for various architectures (x86-64, arm, OSX, WinCE, kFreeBSD, Hurd) A bunch of bug fixes (May 20, 2009) TCC version 0.9.25 is out thanks to Grischka (Changelog). TCC version 0.9.25 is the first that supports the x86-64 target. Thanks to Shinichiro Hamaji for this. (Apr 1, 2008) TCC version 0.9.24 is out thanks to Grischka (Changelog). TCC now supports compilation from standard input and the arm eabi. (Jun 17, 2005) TCC version 0.9.23 is out (Changelog). This is the first version with support for the Windows target. (Nov 8, 2004) TCC version 0.9.22 is out (Changelog). Linux kernel compilation is 30% faster (10 seconds on a 2.4 GHz Pentium 4). (Oct 25, 2004) TCC version 0.9.21 is out (Changelog). This version is the first one able to build a bootable Linux kernel with only a few patches to the kernel sources. As a demonstration, you can try the TCCBOOT boot loader. It is able to compile and boot a Linux kernel directly from its source code. NOTE: if you want to compile the Linux kernel with TCC, you must use a custom build script as in TCCBOOT . I never tried to compile the Linux kernel with TinyCC and the standard Linux Makefiles. Features SMALL! You can compile and execute C code everywhere, for example on rescue disks (about 100KB for x86 TCC executable, including C preprocessor, C compiler, assembler and linker). FAST! tcc generates x86 code. No byte code overhead. Compile, assemble and link several times faster than GCC. UNLIMITED! Any C dynamic library can be used directly. TCC is heading torward full ISOC99 compliance. TCC can of course compile itself. SAFE! tcc includes an optional memory and bound checker. Bound checked code can be mixed freely with standard code. Compile and execute C source directly. No linking or assembly necessary. Full C preprocessor and GNU-like assembler included. C script supported : just add '#!/usr/local/bin/tcc -run' at the first line of your C source, and execute it directly from the command line. With libtcc, you can use TCC as a backend for dynamic code generation. Download Compilation Speed Links Browser project9 times Compilation speed for the . There are 76936 lines (including headers). 1950947 lines (67.2 MBytes) are compiled because the same headers are included in many files. TinyCC is about faster than GCC. Compiler Time(s) lines/second MBytes/second TinyCC 0.9.22 2.27 859000 29.6 GCC 3.2 -O0 20.0 98000 3.4 Measures were done on a 2.4 GHz Pentium 4. Real time is measured. Compilation time includes compilation, assembly and linking. More up to date tests are available: 1, 2, 3, 4. Online Documentation You want to help ? Here are some suggestions: Report bugs to the mailing list (and eventually fix them). Links TinyCC mailing list Savannah project page and git repository OTCC - The smallest self compiling pseudo C compiler FFASN1 - My small but powerful ASN.1 compiler. TinyCC fork by Rob Landley LLVM Compiler Infrastructure SmartEiffel - With TCC you can compile your Eiffel code faster The GNU C Compiler The LCC Compiler The Small Device C Compiler Cyclone, A Safe Dialect of C The D language Programming in C The Scriptometer evaluates various scripting languages (including TCC). License TCC is distributed under the GNU Lesser General Public License. Copyright (c) 2001-2009 Fabrice Bellard Fabrice Bellard - http://bellard.org/ - http://www.tinycc.org/"	"null"	"null"	"Tiny C Compiler; a small, fast C compiler. Supports C99 (except complex types). only."	"true"
"Networking and Internet"	"GnuTLS"	"http://www.gnutls.org/"	"A secure communication library, implementing SSL, TLS and DTLS. or later."	"null"	"null"	"null"	"GNU LGPL2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"null"	"null"	"null"	"GnuTLS The GnuTLS Transport Layer Security Library Overview News Download Support Development Documentation Security advisories Authors Welcome to GnuTLS project pages Overview GnuTLS is a secure communications library implementing the SSL, TLS and DTLS protocols and technologies around them. It provides a simple C language application programming interface (API) to access the secure communications protocols as well as APIs to parse and write X.509, PKCS #12, OpenPGP and other required structures. It is aimed to be portable and efficient with focus on security and interoperability. Features Support for TLS 1.2, TLS 1.1, TLS 1.0, and SSL 3.0 protocols Support for DTLS 1.2, and DTLS 1.0, protocols Support for certificate path validation, as well as DANE and trust on first use. Support for the Online Certificate Status Protocol (OCSP). Support for multiple certificate types including X.509 and OpenPGP certificates. Support for public key methods, including RSA and Elliptic curves, as well as password and key authentication methods such as SRP and PSK protocols. Support for all the strong encryption algorithms, including AES and Camellia. Support for CPU-assisted cryptography with VIA padlock and AES-NI instruction sets. Support for cryptographic accelerator drivers via /dev/crypto. Supports natively HSMs and cryptographic tokens, via PKCS #11 and the Trusted Platform Module (TPM). Runs on most Unix platforms and Windows. License The core library licensed under the GNU Lesser General Public License version 2.1 (LGPLv2.1+). The LGPL license is compatible with a wide range of free licenses, and even permit you to use GnuTLS in non-free proprietary programs. Documentation: You can obtain GnuTLS' manual at lulu.com or download any of the electronic formats. For more information on GnuTLS features, see the wikipedia article comparing different TLS implementations. News flashes   Follow @GnuTLS 2016-07-06 Released GnuTLS 3.3.24, GnuTLS 3.4.14, and GnuTLS 3.5.2 which are bug fix releases in the old, current and next stable branches. Added the GnuTLS-SA-2016-2 security advisory. 2016-06-14 Released GnuTLS 3.5.1 a feature update release in the next stable branche. 2016-06-06 Released GnuTLS 3.4.13 a bug fix release on the current stable branch. Added GnuTLS-SA-2016-1 security advisory. 2016-05-20 Released GnuTLS 3.3.23 and GnuTLS 3.4.12 which are bug fix releases in the previous and current stable branches. Please send broken links and other corrections or suggestions to bugs@gnutls.org."	"null"	"null"	"A secure communication library, implementing SSL, TLS and DTLS. or later."	"true"
"Crypto"	"libgcrypt"	"https://www.gnu.org/software/libgcrypt/"	"A general-purpose cryptography library, with a range of available ciphers. or later (code), or later (manual and tools)."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"null"	"null"	"null"	"Libgcrypt - GNU Project - Free Software Foundation (FSF) Libgcrypt Overview Libgcrypt is a general purpose cryptographic library based on the code from GnuPG. It provides functions for all cryptograhic building blocks: symmetric ciphers (AES, DES, Blowfish, CAST5, Twofish, SEED, Camellia, Arcfour), hash algorithms (MD4, MD5, RIPE-MD160, SHA-1, SHA-224, SHA-256, SHA-384, SHA-512, TIGER-192, Whirlpool), MACs (HMAC for all hash algorithms), public key algorithms (RSA, Elgamal, DSA, ECDSA), large integer functions, random numbers and a lot of supporting functions. Libgcrypt works on most POSIX systems and many pre-POSIX systems. It can also be built using a cross-compiler system for Microsoft Windows. Availibility Due to former U.S. export restrictions on cryptographic software, the program is not distributed via the standard GNU archives but from an European FTP site and its mirrors. The current stable version may also be retrieved through this download link. You find SHA-1 checksum also linked from this page. Development versions are available at ftp://ftp.gnupg.org/gcrypt/alpha/libgcrypt/. To access the GIT repository you may use this command: ""git clone git://git.gnupg.org/libgcrypt.git"" Manual The manual is included in the package and also available online: HTML version. PDF version. INFO version. HTML version of the development branch. PDF version of the development branch. INFO version of the development branch. Mailing Lists The gcrypt-devel mailing list is hosted at gnupg.org. To subscribe to the list, point your browser to http://lists.gnupg.org/mailman/listinfo/gcrypt-devel or send a mail with the subject ""subscribe"" to gcrypt-devel-request at gnupg dot org. Non-subscriber posting is allowed but it may take some time until a posting has been approved. Maintainer Libgcrypt is still maintained by its principal author Werner Koch. The file AUTHORS in the distribution includes contact information. Commercial support is available, see the GnuPG service directory. Return to the GNU Project home page. Please send FSF & GNU inquiries to gnu@gnu.org. There are also other ways to contact the FSF. Please send broken links and other corrections (or suggestions) to webmasters@gnu.org. Please see the Translations README for information on coordinating and submitting translations of this article. Copyright (C) 2007 Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA Verbatim copying and distribution of this entire article is permitted worldwide without royalty in any medium provided this notice is preserved. Updated: $Date: 2015/08/27 13:26:07 $ $Author: werner $"	"null"	"null"	"A general-purpose cryptography library, with a range of available ciphers. or later (code), or later (manual and tools)."	"true"
"Networking and Internet"	"OpenSSL"	"https://www.openssl.org/"	"Implementation of the SSL and TLS protocols, and also includes a cryptography library."	"null"	"null"	"null"	"Dual Licensed under the OpenSSL License and the SSLeay License"	"https://www.openssl.org/source/license.html"	"null"	"null"	"null"	"null"	"null"	"OpenSSL OpenSSL Cryptography and SSL/TLS Toolkit Home Downloads Docs News Policies Community Support Welcome to OpenSSL! OpenSSL is an open source project that provides a robust, commercial-grade, and full-featured toolkit for the Transport Layer Security (TLS) and Secure Sockets Layer (SSL) protocols. It is also a general-purpose cryptography library. For more information about the team and community around the project, or to start making your own contributions, start with the community page. To get the latest news, download the source, and so on, please see the sidebar or the buttons at the top of every page. The OpenSSL toolkit is licensed under an Apache-style license, which basically means that you are free to get and use it for commercial and non-commercial purposes subject to some simple license conditions. Latest News Date Item 03-May-2016 Security Advisory: several security fixes 03-May-2016 OpenSSL 1.0.2h is now available, including bug and security fixes 03-May-2016 OpenSSL 1.0.1t is now available, including bug and security fixes 28-Apr-2016 OpenSSL 1.0.2h and 1.0.1t security releases due 3rd May 2016 19-Apr-2016 Beta 2 (pre-release 5) of OpenSSL 1.1.0 is now available: please download and test it More...   Legalities Please remember that export/import and/or use of strong cryptography software, providing cryptography hooks, or even just communicating technical details about cryptography software is illegal in some parts of the world. So when you import this package to your country, re-distribute it from there or even just email technical suggestions or even source patches to the authors or other people you are strongly advised to pay close attention to any laws or regulations which apply to you. The authors of openssl are not liable for any violations you make here. So be careful, it is your responsibility. Acknowledgement This product includes cryptographic software written by Eric Young. This product includes software written by Tim Hudson (tjh@cryptsoft.com). You are here: Home Sitemap Home Downloads: Source code Docs: FAQ, FIPS, manpages, ... News: Latest information Policies: How we operate Community: Blog, bugs, email, ... Support: Commercial support and contracting Sponsor Acknowledgements Please report problems with this website to webmaster at openssl.org. Copyright © 1999-2016, OpenSSL Software Foundation."	"null"	"null"	"Implementation of the SSL and TLS protocols, and also includes a cryptography library."	"true"
"Crypto"	"libsodium"	"https://github.com/jedisct1/libsodium"	"A modern and easy-to-use crypto library.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"3007"	"247"	"400"	"GitHub - jedisct1/libsodium: A modern and easy-to-use crypto library. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 247 Star 3,007 Fork 400 jedisct1/libsodium Code Issues 9 Pull requests 0 Pulse Graphs A modern and easy-to-use crypto library. 2,320 commits 4 branches 24 releases 53 contributors C 94.5% Assembly 2.4% M4 1.6% Shell 0.7% Makefile 0.6% Batchfile 0.1% Other 0.1% C Assembly M4 Shell Makefile Batchfile Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags arm coverity_scan master stable Nothing to show 1.0.10 1.0.9 1.0.8 1.0.7 1.0.6 1.0.5 1.0.4 1.0.3 1.0.1 1.0.0 0.7.1 0.7.0 0.6.1 0.6.0 0.5.0 0.4.5 0.4.4 0.4.3 0.4.2 0.4.1 0.4 0.3 0.2 0.1 Nothing to show New pull request Latest commit 351ae49 Jul 6, 2016 jedisct1 cpuid is not available on i686-nacl Permalink Failed to load latest commit information. builds Version bump (not released yet) Jun 30, 2016 dist-build CRLF Jun 5, 2016 m4 Import ax_pthread.m4 Apr 19, 2016 msvc-scripts Version bump (not released yet) Jun 30, 2016 packaging/nuget https Apr 12, 2016 src crit_{enter,leave} can fail Jul 6, 2016 test Add dist-build/nativeclient-x86-64.sh Apr 29, 2016 .gitignore Forgot to ignore libsodium-uninstalled.pc Jun 4, 2016 .travis.yml Travis: Limit the double compilation to a single OS Dec 11, 2015 AUTHORS Add crypto_core/curve25519 Mar 16, 2016 ChangeLog Update ChangeLog Jun 29, 2016 LICENSE Add license title Jun 30, 2016 Makefile.am CRLF Mar 17, 2016 README.markdown Link text = ""installation"" only Mar 17, 2016 THANKS THANKS << Scott Arciszewski Nov 28, 2015 appveyor.yml Update appveyor version Apr 4, 2016 autogen.sh pkg-config is not required Dec 25, 2015 configure.ac cpuid is not available on i686-nacl Jul 6, 2016 libsodium-uninstalled.pc.in Update description Mar 17, 2016 libsodium.pc.in Update description Mar 17, 2016 libsodium.sln Retarget the top solution to Visual Studio 2015 Nov 1, 2015 libsodium.vcxproj Add blake2b-compress-avx2.c to the top-level Visual Studio solution Mar 17, 2016 libsodium.vcxproj.filters Add blake2b-compress-avx2.c to the top-level Visual Studio solution Mar 17, 2016 logo.png Larger logo, less prominent saltcellar Apr 19, 2016 README.markdown Sodium is a new, easy-to-use software library for encryption, decryption, signatures, password hashing and more. It is a portable, cross-compilable, installable, packageable fork of NaCl, with a compatible API, and an extended API to improve usability even further. Its goal is to provide all of the core operations needed to build higher-level cryptographic tools. Sodium supports a variety of compilers and operating systems, including Windows (with MingW or Visual Studio, x86 and x64), iOS and Android. Documentation The documentation is a work-in-progress, and is being written using Gitbook: libsodium documentation - online, requires Javascript. offline documentation in PDF, MOBI and ePUB formats. Integrity Checking The integrity checking instructions (including the signing key for libsodium) are available in the installation section of the documentation. Community A mailing-list is available to discuss libsodium. In order to join, just send a random mail to sodium-subscribe {at} pureftpd {dot} org. License ISC license. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/jedisct1/libsodium"	"A modern and easy-to-use crypto library.."	"true"
"Crypto"	"libtomcrypt"	"https://github.com/libtom/libtomcrypt"	"A fairly comprehensive, modular and portable cryptographic toolkit. Public domain."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"380"	"65"	"135"	"GitHub - libtom/libtomcrypt: LibTomCrypt is a fairly comprehensive, modular and portable cryptographic toolkit that provides developers with a vast array of well known published block ciphers, one-way hash functions, chaining modes, pseudo-random number generators, public key cryptography and a plethora of other routines. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 65 Star 380 Fork 135 libtom/libtomcrypt Code Issues 26 Pull requests 17 Wiki Pulse Graphs LibTomCrypt is a fairly comprehensive, modular and portable cryptographic toolkit that provides developers with a vast array of well known published block ciphers, one-way hash functions, chaining modes, pseudo-random number generators, public key cryptography and a plethora of other routines. http://www.libtom.net 493 commits 10 branches 45 releases 17 contributors C 91.5% TeX 7.3% Makefile 0.5% Python 0.3% Java 0.2% Shell 0.2% C TeX Makefile Python Java Shell Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: develop Switch branches/tags Branches Tags develop feature/doc feature/eccAddA feature/rsa_import_x509 fix/ccm_constant_time fix/90 fix/106 idea/ltc_rng master miko-ecc-enhancements Nothing to show 1.17 1.16 1.15 1.14 1.13 1.12 1.11 1.10 1.09 1.08 1.07 1.06 1.05 1.04 1.03 1.02 1.01 1.00 0.99 0.98 0.97 0.97b 0.97a 0.96 0.95 0.94 0.93 0.92 0.91 0.90 0.89 0.88 0.87 0.86 0.85 0.84 0.83 0.82 0.81 0.80 0.79 0.78 0.77 0.76 0.75 Nothing to show New pull request Latest commit 6ad5225 Jul 7, 2016 karel-m removing forgotten debug comment Permalink Failed to load latest commit information. demos fix some compiler warnings Jan 23, 2016 doc flush content of CVS/SVN tags Apr 29, 2014 notes regen rsa-testvectors Aug 28, 2014 src removing forgotten debug comment Jul 7, 2016 testprof make testprof/makefile silent Jan 23, 2016 .clang-format add .clang-format Aug 25, 2015 .gitignore fix gitignore Apr 3, 2016 .travis.yml travis: update local package index as first step Jan 5, 2016 Doxyfile added libtomcrypt-1.17 Jun 16, 2010 LICENSE after multiple objections of libtom users [1], we decided to change l… Jan 19, 2011 README.md add coverity badge May 25, 2014 TODO added libtomcrypt-1.17 Jun 16, 2010 build.sh automatically determine the number of parallel make jobs for the tests Apr 3, 2016 changes added libtomcrypt-1.17 Jun 16, 2010 coverage.sh bring coverage results near reality Apr 3, 2016 coverity.sh fix coverity script Oct 10, 2014 crypt.tex ccm: clarify pt and ct parameters in doc and API description Apr 30, 2014 filter.pl mark scripts as executable Nov 23, 2012 fixupind.pl mark scripts as executable Nov 22, 2012 genlist.sh sort HEADERS in makefiles, so it doesn't change spontaneously Sep 1, 2015 libtomcrypt.dsp add hkdf impl Mar 15, 2013 libtomcrypt.pc.in pkgconfig: set libdir= to $LIBPATH (for multi-arch) Feb 25, 2014 libtomcrypt_VS2005.sln Added project and solution files for Visual Studio 2005 and Visual St… Jun 16, 2010 libtomcrypt_VS2005.vcproj add hkdf impl Mar 15, 2013 libtomcrypt_VS2008.sln Added project and solution files for Visual Studio 2005 and Visual St… Jun 16, 2010 libtomcrypt_VS2008.vcproj add hkdf impl Mar 15, 2013 makefile bring coverage results near reality Apr 3, 2016 makefile.icc introduce new all_test make-target Jan 23, 2016 makefile.include make build process silent Jan 19, 2016 makefile.mingw introduce new all_test make-target Jan 23, 2016 makefile.msvc introduce new all_test make-target Jan 23, 2016 makefile.shared install without USER and GROUP Apr 1, 2016 makefile.unix introduce new all_test make-target Jan 23, 2016 mess.sh mark scripts as executable Nov 22, 2012 parsenames.pl flush content of CVS/SVN tags Apr 29, 2014 printinfo.sh printinfo: display version of correct compiler if CC does not point t… May 7, 2014 run.sh flush content of CVS/SVN tags Apr 29, 2014 testbuild.sh travis: print version information in build scripts Feb 25, 2014 testme.sh testme.sh: add test runs without ""timing resistance"" May 8, 2014 updatemakes.sh trim trailing spaces in mingw makefiles Aug 6, 2014 README.md libtomcrypt See doc/crypt.pdf for a detailed documentation Project Status develop: Submitting patches Please branch off from develop if you want to submit a patch. Branches Please be aware, that all branches besides master and develop can and will be force-pushed, rebased and/or removed! If you want to rely on such an unstable branch, create your own fork of this repository to make sure nothing breaks for you. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/libtom/libtomcrypt"	"A fairly comprehensive, modular and portable cryptographic toolkit. Public domain."	"true"
"Crypto"	"mbed TLS"	"https://tls.mbed.org/"	"Another crypto implementation for C.."	"null"	"null"	"null"	"Apache2.0"	"http://directory.fsf.org/wiki/License:Apache2.0"	"null"	"null"	"null"	"null"	"null"	"SSL Library mbed TLS / PolarSSL: Download for free or buy a commercial license You seem to have disabled Javascript. This page relies on Javascript for logging in, searching, etc. Without it, elements of this site might not work as expected. PolarSSL is now part of Official announcement and rebranded as mbed TLS. Register or Log in to mbed TLS Home About us Features News SSL Library OpenSSL Alternative Dev corner Download mbed TLS Source Code Core features Blog Tech updates API reference High-level design Security Security Center Bug Bounty Program Support Knowledge Base Support Forum Report a bug Get Account Contact mbed TLS (formerly known as PolarSSL) makes it trivially easy for developers to include cryptographic and SSL/TLS capabilities in their (embedded) products, facilitating this functionality with a minimal coding footprint.   Easy to use mbed TLS offers an SSL library with an intuitive API and readable source code, so you can actually understand what the code does. Also the mbed TLS modules are as loosely coupled as possible and written in the portable C language. This allows you to use the parts you need, without having to include the total library. Read more Easy to get mbed TLS is available as open source under the Apache 2.0 license, the GPL 2.0 license or under an mbed partnership. The Apache 2.0 license enables you to use mbed TLS in both open source and closed source projects. Read more Support Knowledge Base Support Forum Direct e-mail     Our users Latest updates mbed TLS 2.3.0, 2.1.5 and 1.3.17 released mbed TLS 2.2.1, 2.1.4, 1.3.16 and PolarSSL 1.2.19 released mbed TLS 2.2.0, 2.1.3, 1.3.15 and PolarSSL 1.2.18 released mbed TLS 2.1.2 and 1.3.14, and PolarSSL 1.2.17 released mbed TLS Security Advisory 2015-01   Let's be friends!       Copyright © 2008 - 2015 ARM Limited All Rights Reserved Privacy Policy"	"null"	"null"	"Another crypto implementation for C.."	"true"
"Database"	"BerkeleyDB"	"http://www.oracle.com/us/products/database/berkeley-db/overview/index.html"	"A library for a high-performance embedded database for key-value data. only."	"null"	"null"	"null"	"GNU AGPLv3"	"https://gnu.org/licenses/agpl.html"	"null"	"null"	"null"	"null"	"null"	"Berkeley DB Products | Database | Oracle Oracle Country Country Communities I am a... I want to... Welcome Account Sign Out Sign In/Register Help Products Solutions Downloads Store Support Training Partners About OTN Products and Services Database Oracle Berkeley DB Products Overview Oracle Berkeley DB Products A Selection of Embeddable Databases to Meet Your Needs Oracle Berkeley DB provides the best open source embeddable databases allowing developers the choice of SQL, Key/Value, XML/XQuery or Java Object storage for their data model. At its core is a fast, scalable, transactional database engine with proven reliability and availability. Berkeley DB comes three versions: Berkeley DB, Berkeley DB Java Edition, and Berkeley DB XML. Download Price and buy Data sheet (PDF) Overview Resources Eliminates overhead while providing the flexibility to tailor the database to your requirements All administration is performed via an API and hidden from the end user, no DBA required Great for mobile devices with static library size less than 1MB and runtime dynamic memory requirements of only a few KB An embedded database lowers total cost of ownership with lower implementation and administration costs, and can lower licensing and hardware costs TechCast Live: Embedded Data Storage with Oracle Berkeley DB Oracle Berkeley DB allows developers to link a fully functional, robust data storage library directly into their application. Product manager David Segleau explains how.   Oracle Berkeley DB Products Oracle Berkeley DB Oracle Berkeley DB Java Edition Oracle Berkeley DB XML Get Started Download Oracle Database 12c Get training Attend an event Try Database Cloud Service for 30 days Contact Social Sign Up We're here to help Engage a Sales Expert Sales 1-800-633-0738 (US) Have Oracle Call You Global Contacts Find a Partner Support Directory Follow   Facebook   Twitter   LinkedIn   Google Plus  Youtube   Blog   Newsletter Follow Oracle Corporate  Facebook  Twitter  LinkedIn  Google Plus  Youtube Oracle Social Media Directory Oracle RSS Directory Be the first to know Subscribe to Oracle Communications Sign up by topic Subscription Center   Oracle Cloud Learn About Oracle Cloud Computing Get a Free Trial Learn About DaaS Learn About SaaS Learn About PaaS Learn About IaaS Learn About Private Cloud Learn About Managed Cloud Java Learn About Java Download Java for Consumers Download Java for Developers Java Resources for Developers Java Cloud Service Java Magazine Customers and Events Explore and Read Customer Stories All Oracle Events Oracle OpenWorld JavaOne Email Subscriptions Subscribe to Oracle Communications Subscription Center Communities Blogs Discussion Forums Wikis Oracle ACEs User Groups Social Media Channels Services and Store Log In to My Oracle Support Training and Certification Become a Partner Find a Partner Solution Purchase from the Oracle Store Contact and Chat US Sales: +1.800.633.0738 Global Contacts Oracle Support Partner Support   Integrated Cloud Applications and Platform Services © Oracle Subscribe Careers Contact Us Site Maps Legal Notices Terms of Use Privacy Ad Choices Oracle Mobile Facebook LinkedIn Twitter Google+ YouTube Oracle RSS Feed"	"null"	"null"	"A library for a high-performance embedded database for key-value data. only."	"true"
"Database"	"Hiredis"	"https://github.com/redis/hiredis"	"A minimalistic client library for Redis.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"2039"	"198"	"711"	"GitHub - redis/hiredis: Minimalistic C client for Redis >= 1.2 Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 198 Star 2,039 Fork 711 redis/hiredis Code Issues 32 Pull requests 5 Wiki Pulse Graphs Minimalistic C client for Redis >= 1.2 550 commits 17 branches 13 releases 67 contributors C 94.9% Makefile 3.3% C++ 1.8% C Makefile C++ Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags asyncdoc auto backwards-compatibility-macros buffer catch-error-buf-overflow debug-flags develop fix-cygwin master new-readme ng pr-438 string-len-size_t try unstable updated-sds with-timeout Nothing to show v0.13.3 v0.13.2 v0.13.1 v0.13.0 v0.12.1 v0.12.0 v0.11.0 v0.10.1 v0.10.0 v0.9.2 v0.9.1 v0.9.0 v0.0.1 Nothing to show New pull request Latest commit 5f98e1d Jul 9, 2016 not-a-robot committed on GitHub Auto merge of #445 - xxvv:master, r=badboy … fix: should close socket fd when retry connect (tcp) Permalink Failed to load latest commit information. adapters Added MacOS X addapter and corresponding example. Jul 27, 2015 examples fix snprintf format string Oct 5, 2015 .gitignore Generate pkgconf during build Jan 5, 2015 .travis.yml chore(CI): Exclude valgrind jobs on OSX Jun 20, 2016 CHANGELOG.md docs: Add breaking change note about makefile variable Apr 20, 2016 COPYING Update license Apr 21, 2011 Makefile fix: Rename DEBUG to DEBUG_FLAGS Apr 20, 2016 README.md Auto merge of #417 - redis:thread-safety, r=badboy Apr 20, 2016 appveyor.yml chore: Cleanup appveyor configuration Apr 20, 2016 async.c fixing typos Oct 28, 2015 async.h Add support for SO_REUSEADDR Jan 5, 2015 dict.c fixing typos Oct 27, 2015 dict.h Make dictionary functions static and include the .c file Jan 14, 2011 fmacros.h Do not define _XOPEN_SOURCE for OS X Jun 19, 2016 hiredis.c Typo format in redisFormatSdsCommandArgv function May 14, 2016 hiredis.h fix: Change string length type to size_t Apr 20, 2016 net.c fix: should close socket fd when retry connet remote (tcp) Jul 7, 2016 net.h Change copyright date and add copyright holder Apr 16, 2015 read.c Update read.c Apr 11, 2016 read.h fix: Remove backwards compatibility macro's Apr 20, 2016 sds.c remove unnessory code Apr 20, 2016 sds.h Update sds.h May 14, 2016 sdsalloc.h fix: Add sdsalloc.h file Apr 20, 2016 test.c test: Add regression test for sds argv formatting May 14, 2016 win32.h Added support for compiling the parser code with Microsoft Visual C c… Mar 13, 2015 README.md This Readme reflects the latest changed in the master branch. See v0.13.3 for the Readme and documentation for the latest release. HIREDIS Hiredis is a minimalistic C client library for the Redis database. It is minimalistic because it just adds minimal support for the protocol, but at the same time it uses a high level printf-alike API in order to make it much higher level than otherwise suggested by its minimal code base and the lack of explicit bindings for every Redis command. Apart from supporting sending commands and receiving replies, it comes with a reply parser that is decoupled from the I/O layer. It is a stream parser designed for easy reusability, which can for instance be used in higher level language bindings for efficient reply parsing. Hiredis only supports the binary-safe Redis protocol, so you can use it with any Redis version >= 1.2.0. The library comes with multiple APIs. There is the synchronous API, the asynchronous API and the reply parsing API. Upgrading to 1.0.0 Version 1.0.0 marks a stable release of hiredis. It includes some minor breaking changes, mostly to make the exposed API more uniform and self-explanatory. It also bundles the updated sds library, to sync up with upstream and Redis. For most applications a recompile against the new hiredis should be enough. For code changes see the Changelog. Upgrading from <0.9.0 Version 0.9.0 is a major overhaul of hiredis in every aspect. However, upgrading existing code using hiredis should not be a big pain. The key thing to keep in mind when upgrading is that hiredis >= 0.9.0 uses a redisContext* to keep state, in contrast to the stateless 0.0.1 that only has a file descriptor to work with. Synchronous API To consume the synchronous API, there are only a few function calls that need to be introduced: redisContext *redisConnect(const char *ip, int port); void *redisCommand(redisContext *c, const char *format, ...); void freeReplyObject(void *reply); Connecting The function redisConnect is used to create a so-called redisContext. The context is where Hiredis holds state for a connection. The redisContext struct has an integer err field that is non-zero when the connection is in an error state. The field errstr will contain a string with a description of the error. More information on errors can be found in the Errors section. After trying to connect to Redis using redisConnect you should check the err field to see if establishing the connection was successful: redisContext *c = redisConnect(""127.0.0.1"", 6379); if (c == NULL || c->err) {     if (c) {         printf(""Error: %s\n"", c->errstr);         // handle error     } else {         printf(""Can't allocate redis context\n"");     } } Note: A redisContext is not thread-safe. Sending commands There are several ways to issue commands to Redis. The first that will be introduced is redisCommand. This function takes a format similar to printf. In the simplest form, it is used like this: reply = redisCommand(context, ""SET foo bar""); The specifier %s interpolates a string in the command, and uses strlen to determine the length of the string: reply = redisCommand(context, ""SET foo %s"", value); When you need to pass binary safe strings in a command, the %b specifier can be used. Together with a pointer to the string, it requires a size_t length argument of the string: reply = redisCommand(context, ""SET foo %b"", value, (size_t) valuelen); Internally, Hiredis splits the command in different arguments and will convert it to the protocol used to communicate with Redis. One or more spaces separates arguments, so you can use the specifiers anywhere in an argument: reply = redisCommand(context, ""SET key:%s %s"", myid, value); Using replies The return value of redisCommand holds a reply when the command was successfully executed. When an error occurs, the return value is NULL and the err field in the context will be set (see section on Errors). Once an error is returned the context cannot be reused and you should set up a new connection. The standard replies that redisCommand are of the type redisReply. The type field in the redisReply should be used to test what kind of reply was received: REDIS_REPLY_STATUS: The command replied with a status reply. The status string can be accessed using reply->str. The length of this string can be accessed using reply->len. REDIS_REPLY_ERROR: The command replied with an error. The error string can be accessed identical to REDIS_REPLY_STATUS. REDIS_REPLY_INTEGER: The command replied with an integer. The integer value can be accessed using the reply->integer field of type long long. REDIS_REPLY_NIL: The command replied with a nil object. There is no data to access. REDIS_REPLY_STRING: A bulk (string) reply. The value of the reply can be accessed using reply->str. The length of this string can be accessed using reply->len. REDIS_REPLY_ARRAY: A multi bulk reply. The number of elements in the multi bulk reply is stored in reply->elements. Every element in the multi bulk reply is a redisReply object as well and can be accessed via reply->element[..index..]. Redis may reply with nested arrays but this is fully supported. Replies should be freed using the freeReplyObject() function. Note that this function will take care of freeing sub-reply objects contained in arrays and nested arrays, so there is no need for the user to free the sub replies (it is actually harmful and will corrupt the memory). Important: the current version of hiredis (0.10.0) frees replies when the asynchronous API is used. This means you should not call freeReplyObject when you use this API. The reply is cleaned up by hiredis after the callback returns. This behavior will probably change in future releases, so make sure to keep an eye on the changelog when upgrading (see issue #39). Cleaning up To disconnect and free the context the following function can be used: void redisFree(redisContext *c); This function immediately closes the socket and then frees the allocations done in creating the context. Sending commands (cont'd) Together with redisCommand, the function redisCommandArgv can be used to issue commands. It has the following prototype: void *redisCommandArgv(redisContext *c, int argc, const char **argv, const size_t *argvlen); It takes the number of arguments argc, an array of strings argv and the lengths of the arguments argvlen. For convenience, argvlen may be set to NULL and the function will use strlen(3) on every argument to determine its length. Obviously, when any of the arguments need to be binary safe, the entire array of lengths argvlen should be provided. The return value has the same semantic as redisCommand. Pipelining To explain how Hiredis supports pipelining in a blocking connection, there needs to be understanding of the internal execution flow. When any of the functions in the redisCommand family is called, Hiredis first formats the command according to the Redis protocol. The formatted command is then put in the output buffer of the context. This output buffer is dynamic, so it can hold any number of commands. After the command is put in the output buffer, redisGetReply is called. This function has the following two execution paths: The input buffer is non-empty: Try to parse a single reply from the input buffer and return it If no reply could be parsed, continue at 2 The input buffer is empty: Write the entire output buffer to the socket Read from the socket until a single reply could be parsed The function redisGetReply is exported as part of the Hiredis API and can be used when a reply is expected on the socket. To pipeline commands, the only things that needs to be done is filling up the output buffer. For this cause, two commands can be used that are identical to the redisCommand family, apart from not returning a reply: void redisAppendCommand(redisContext *c, const char *format, ...); void redisAppendCommandArgv(redisContext *c, int argc, const char **argv, const size_t *argvlen); After calling either function one or more times, redisGetReply can be used to receive the subsequent replies. The return value for this function is either REDIS_OK or REDIS_ERR, where the latter means an error occurred while reading a reply. Just as with the other commands, the err field in the context can be used to find out what the cause of this error is. The following examples shows a simple pipeline (resulting in only a single call to write(2) and a single call to read(2)): redisReply *reply; redisAppendCommand(context,""SET foo bar""); redisAppendCommand(context,""GET foo""); redisGetReply(context,&reply); // reply for SET freeReplyObject(reply); redisGetReply(context,&reply); // reply for GET freeReplyObject(reply); This API can also be used to implement a blocking subscriber: reply = redisCommand(context,""SUBSCRIBE foo""); freeReplyObject(reply); while(redisGetReply(context,&reply) == REDIS_OK) {     // consume message     freeReplyObject(reply); } Errors When a function call is not successful, depending on the function either NULL or REDIS_ERR is returned. The err field inside the context will be non-zero and set to one of the following constants: REDIS_ERR_IO: There was an I/O error while creating the connection, trying to write to the socket or read from the socket. If you included errno.h in your application, you can use the global errno variable to find out what is wrong. REDIS_ERR_EOF: The server closed the connection which resulted in an empty read. REDIS_ERR_PROTOCOL: There was an error while parsing the protocol. REDIS_ERR_OTHER: Any other error. Currently, it is only used when a specified hostname to connect to cannot be resolved. In every case, the errstr field in the context will be set to hold a string representation of the error. Asynchronous API Hiredis comes with an asynchronous API that works easily with any event library. Examples are bundled that show using Hiredis with libev and libevent. Connecting The function redisAsyncConnect can be used to establish a non-blocking connection to Redis. It returns a pointer to the newly created redisAsyncContext struct. The err field should be checked after creation to see if there were errors creating the connection. Because the connection that will be created is non-blocking, the kernel is not able to instantly return if the specified host and port is able to accept a connection. Note: A redisAsyncContext is not thread-safe. redisAsyncContext *c = redisAsyncConnect(""127.0.0.1"", 6379); if (c->err) {     printf(""Error: %s\n"", c->errstr);     // handle error } The asynchronous context can hold a disconnect callback function that is called when the connection is disconnected (either because of an error or per user request). This function should have the following prototype: void(const redisAsyncContext *c, int status); On a disconnect, the status argument is set to REDIS_OK when disconnection was initiated by the user, or REDIS_ERR when the disconnection was caused by an error. When it is REDIS_ERR, the err field in the context can be accessed to find out the cause of the error. The context object is always freed after the disconnect callback fired. When a reconnect is needed, the disconnect callback is a good point to do so. Setting the disconnect callback can only be done once per context. For subsequent calls it will return REDIS_ERR. The function to set the disconnect callback has the following prototype: int redisAsyncSetDisconnectCallback(redisAsyncContext *ac, redisDisconnectCallback *fn); Sending commands and their callbacks In an asynchronous context, commands are automatically pipelined due to the nature of an event loop. Therefore, unlike the synchronous API, there is only a single way to send commands. Because commands are sent to Redis asynchronously, issuing a command requires a callback function that is called when the reply is received. Reply callbacks should have the following prototype: void(redisAsyncContext *c, void *reply, void *privdata); The privdata argument can be used to curry arbitrary data to the callback from the point where the command is initially queued for execution. The functions that can be used to issue commands in an asynchronous context are: int redisAsyncCommand(   redisAsyncContext *ac, redisCallbackFn *fn, void *privdata,   const char *format, ...); int redisAsyncCommandArgv(   redisAsyncContext *ac, redisCallbackFn *fn, void *privdata,   int argc, const char **argv, const size_t *argvlen); Both functions work like their blocking counterparts. The return value is REDIS_OK when the command was successfully added to the output buffer and REDIS_ERR otherwise. Example: when the connection is being disconnected per user-request, no new commands may be added to the output buffer and REDIS_ERR is returned on calls to the redisAsyncCommand family. If the reply for a command with a NULL callback is read, it is immediately freed. When the callback for a command is non-NULL, the memory is freed immediately following the callback: the reply is only valid for the duration of the callback. All pending callbacks are called with a NULL reply when the context encountered an error. Disconnecting An asynchronous connection can be terminated using: void redisAsyncDisconnect(redisAsyncContext *ac); When this function is called, the connection is not immediately terminated. Instead, new commands are no longer accepted and the connection is only terminated when all pending commands have been written to the socket, their respective replies have been read and their respective callbacks have been executed. After this, the disconnection callback is executed with the REDIS_OK status and the context object is freed. Hooking it up to event library X There are a few hooks that need to be set on the context object after it is created. See the adapters/ directory for bindings to libev and libevent. Reply parsing API Hiredis comes with a reply parsing API that makes it easy for writing higher level language bindings. The reply parsing API consists of the following functions: redisReader *redisReaderCreate(void); void redisReaderFree(redisReader *reader); int redisReaderFeed(redisReader *reader, const char *buf, size_t len); int redisReaderGetReply(redisReader *reader, void **reply); The same set of functions are used internally by hiredis when creating a normal Redis context, the above API just exposes it to the user for a direct usage. Usage The function redisReaderCreate creates a redisReader structure that holds a buffer with unparsed data and state for the protocol parser. Incoming data -- most likely from a socket -- can be placed in the internal buffer of the redisReader using redisReaderFeed. This function will make a copy of the buffer pointed to by buf for len bytes. This data is parsed when redisReaderGetReply is called. This function returns an integer status and a reply object (as described above) via void **reply. The returned status can be either REDIS_OK or REDIS_ERR, where the latter means something went wrong (either a protocol error, or an out of memory error). The parser limits the level of nesting for multi bulk payloads to 7. If the multi bulk nesting level is higher than this, the parser returns an error. Customizing replies The function redisReaderGetReply creates redisReply and makes the function argument reply point to the created redisReply variable. For instance, if the response of type REDIS_REPLY_STATUS then the str field of redisReply will hold the status as a vanilla C string. However, the functions that are responsible for creating instances of the redisReply can be customized by setting the fn field on the redisReader struct. This should be done immediately after creating the redisReader. For example, hiredis-rb uses customized reply object functions to create Ruby objects. Reader max buffer Both when using the Reader API directly or when using it indirectly via a normal Redis context, the redisReader structure uses a buffer in order to accumulate data from the server. Usually this buffer is destroyed when it is empty and is larger than 16 KiB in order to avoid wasting memory in unused buffers However when working with very big payloads destroying the buffer may slow down performances considerably, so it is possible to modify the max size of an idle buffer changing the value of the maxbuf field of the reader structure to the desired value. The special value of 0 means that there is no maximum value for an idle buffer, so the buffer will never get freed. For instance if you have a normal Redis context you can set the maximum idle buffer to zero (unlimited) just with: context->reader->maxbuf = 0; This should be done only in order to maximize performances when working with large payloads. The context should be set back to REDIS_READER_MAX_BUF again as soon as possible in order to prevent allocation of useless memory. AUTHORS Hiredis was written by Salvatore Sanfilippo (antirez at gmail) and Pieter Noordhuis (pcnoordhuis at gmail) and is released under the BSD license. Hiredis is currently maintained by Matt Stancliff (matt at genges dot com) and Jan-Erik Rediger (janerik at fnordig dot com) Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/redis/hiredis"	"A minimalistic client library for Redis.."	"true"
"Database"	"LMDB"	"http://symas.com/mdb/"	"An ultra-fast, ultra-compact key-value embedded data store.."	"null"	"null"	"null"	"newOpenLDAP"	"http://directory.fsf.org/wiki/License:OpenLDAPv2.7"	"null"	"null"	"null"	"null"	"null"	"Symas Lightning Memory-mapped Database | Enterprise Directory SoftwareEnterprise Directory Software Home Products Symas Enforcement Foundry Symas OpenLDAP Directory Symas Lightning Memory-mapped Database Symas Subscriptions Services Support Programs Professional Services Training Resources Downloads Knowledge Base Technical Support About Team News Blog Careers Contact Symas Lightning Memory-mapped Database Products Symas Enforcement Foundry Symas Lightning Memory-mapped Database Symas OpenLDAP Directory Symas Subscriptions Symas Lightning Memory-mapped Database An ultra-fast, ultra-compact, crash-proof key-value embedded data store. LMDB is an extraordinarily fast, memory-efficient database developed by Symas for the OpenLDAP Project. With memory-mapped files, it has the read performance of a pure in-memory database while retaining the persistence of standard disk-based databases. In other words, it runs like a bat out of hell, performing several times faster than other DB engines — several orders of magnitude faster in many cases. No buffers or caches needed, no memory copies generated. And it’s only limited to the size of the virtual address space, not to the size of physical RAM. Bottom line, with only 32KB of object code, LMDB may seem tiny. But it’s the right 32KB. Compact and efficient are two sides of a coin; that’s part of what makes LMDB so powerful. The features at a glance: Ordered-map interface (keys are always sorted; range lookups are supported) Fully-transactional, full ACID semantics with MVCC Reader/writer transactions (readers don’t block writers; writers don’t block readers) Fully serialized writers (writes are always deadlock-free) Extremely cheap read transactions, which can be performed using no mallocs or any other blocking calls Multi-thread and multi-process concurrency supported; environments may be opened by multiple processes on the same host Multiple sub-databases may be created with transactions covering all sub-databases Memory-mapped, allowing for zero-copy lookup and iteration Maintenance-free (no external process or background cleanup or compaction required) Crash-proof (no logs or crash recovery procedures required) No application-level caching (LMDB fully exploits the operating system’s buffer cache) 32KB of object code and 6KLOC of C Licensed under the OpenLDAP Public License Learn More How Does it Compare to Other Key Value Stores? Where Can I Find Support and Documentation? Where Can I Read the Published Reports? Where Can I See the Project Benchmarks? In What Other Projects is it Available? Are there LMDB Wrappers for Other Languages? Recent Blog Posts Introducing a Security Access Control Engine Inside OpenLDAP Understanding LMDB Database File Sizes and Memory Utilization ApacheDS & Fortress QUICKSTART Apache Fortress 1.0-RC42 Released Recent News Tollgrade Smart Grid EMS LightHouse Vulnerabilities | ICS-CERT https://ics-cert.us-cert.gov/advisories/ICSA-16-194-01 2 days ago GE Proficy HMI SCADA CIMPLICITY Privilege Management Vulnerability | ICS-CERT https://ics-cert.us-cert.gov/advisories/ICSA-16-194-02 2 days ago Find us on Facebook Follow Us on Twitter https://t.co/I4ZFchuPBh https://t.co/ejyvyhLiKr 2 days ago - symascorp https://t.co/Y74jPbsK6D https://t.co/8K4oSPIyPo 2 days ago - symascorp Search Our Site Copyright © 2001–2016, Symas Corporation. All rights reserved. Privacy Statement"	"null"	"null"	"An ultra-fast, ultra-compact key-value embedded data store.."	"true"
"Database"	"MariaDB"	"https://mariadb.com/"	"A robust, scalable and reliable SQL server, designed to be a drop-in replacement for MySQL.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"null"	"null"	"null"	"MariaDB | High availability, scalability and performance beyond MySQL Languages DOWNLOAD Search form Search Support Resources Downloads Community Tools Guides & White Papers Technical Presentations Webinars MariaDB.org MariaDB Books Report a Bug 24x7 Emergency Support MariaDB Portal Knowledge Base Blog My Portal Login / Sign Up Toggle navigation MariaDB Products MariaDB Enterprise MariaDB Enterprise Cluster MariaDB ColumnStore MariaDB MaxScale Cluster and Maxscale on Azure MariaDB on IBM POWER8 Connectors & Plugins Embedded for OEMs & ISVs Product Comparison Product FAQs Services Remote DBA Technical Account Manager Consulting Performance Tuning High Availability Database Migration MariaDB Security Audit Training Database Administration MariaDB Galera Cluster Administration Performance Tuning Developing Applications High Availability Custom Development Solutions High Availability Security Solutions Customers Partners Featured Partners Find a Partner Become a Partner Support Resources Knowledge Base Blog My Portal Login / Sign Up Database of the Year MariaDB Wins Members' Choice Award Request a demo Congrats to MariaDB MaxScale 2016 Application of the Year from #MySQL Community Awards Learn more MariaDB Enterprise Spring 2016 For Mission-Critical Data Request a demo MariaDB Innovation Days Join us in a City Near You Register now Transactions and Analytics United Introducing MariaDB ColumnStore Learn more Highly Available Databases Made Easy Contact Us Try MariaDB Enterprise Download MariaDB - The Database for the New Century Open Source MariaDB is the fastest growing open source relational database in the world. Join the community that delivers the innovation to address rapidly changing opportunities and threats without raising costs. Extensibility Build the applications that serve the needs of your business with MariaDB’s open architecture. Enterprise-Grade Grow your business confidently with MariaDB’s secure, high-performance database without adding complexity and cost. Develop, deploy and operate applications with the world’s top data management experts at your side. Availability Keep your business running 24/7 and meet service level agreements with High Availability solutions for MariaDB Security Secure your data at every layer of the database to protect your business against attacks, data theft, and compliance breaches Performance Ensure that your MariaDB deployments run faster and more efficiently than ever before under the most demanding conditions And we are back that took like 1 minute of work absolutely no excuses for not using @mariaDB brilliant @arulprakash Webinars Join us for free webinars and online events – both live and on-demand – featuring business leaders, industry experts, and MariaDB partners. Find a DBA Need a MariaDB expert? Help with an application build or big data deployment? We employ the best DBAs the industry offers. 24x7 Support We provide round-the-clock access to advanced support teams who can help with your pressing issues and mission-critical data initiatives. SUBSCRIBE TO GET MARIADB TIPS AND NEWS UPDATES IN YOUR INBOX Subscribe News & Events Press Releases In the News Events Newsletters Webinars About MariaDB Investors Leadership Careers Contact MariaDB.org Subscribe Sign Up Legal Copyright Privacy Policy Cookies © 2016 MariaDB Corporation Ab"	"null"	"null"	"A robust, scalable and reliable SQL server, designed to be a drop-in replacement for MySQL.."	"true"
"Database"	"mongo-c-driver"	"https://github.com/mongodb/mongo-c-driver"	"A high-performance client library for.."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"248"	"72"	"165"	"GitHub - mongodb/mongo-c-driver: A high-performance MongoDB driver for C Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 72 Star 248 Fork 165 mongodb/mongo-c-driver Code Pull requests 0 Pulse Graphs A high-performance MongoDB driver for C 3,421 commits 15 branches 51 releases 44 contributors C 93.7% M4 3.1% CMake 1.0% C++ 0.9% Makefile 0.7% Python 0.5% Other 0.1% C M4 CMake C++ Makefile Python Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags 1.2.0-dev 1.3.0-dev CDRIVER-520 CDRIVER-721-crash-unavail-rs debian glib legacy master mci r1.2 r1.3 refcount sdam socket-debug socket Nothing to show v0.8.1 v0.8 v0.7.1 v0.7 v0.6 v0.5.2 v0.5.1 v0.5 v0.4 v0.3.1 v0.3 v0.2 1.3.5 1.3.4 1.3.3 1.3.2 1.3.1 1.3.0 1.3.0-rc0 1.3.0-beta0 1.2.4 1.2.3 1.2.2 1.2.1 1.2.0 1.2.0-rc0 1.2.0-beta1 1.2.0-beta 1.1.11 1.1.10 1.1.9 1.1.8 1.1.7 1.1.6 1.1.5 1.1.4 1.1.2 1.1.0 1.1.0-rc0 1.0.2 1.0.0 0.98.2 0.98.0 0.96.4 0.96.2 0.96.0 0.94.2 0.94.0 0.92.2 0.92.0 0.90.0 Nothing to show New pull request Latest commit 4f8f007 Jul 15, 2016 ajdavis committed on GitHub Merge pull request #348 from derickr/generated-files-in-gitignore … Add generated file to .gitignore Permalink Failed to load latest commit information. build CDRIVER-1155: Use OpenSSL to verify the certificate hostname Jul 14, 2016 doc CDRIVER-1363 maxStalenessMS URI option Jul 8, 2016 examples Merge pull request #337 from puppyofkosh/CDRIVER-1201 Jun 17, 2016 orchestration_configs CDRIVER-1307: Enforce client certificate in evergreen May 26, 2016 src CDRIVER-1380: Don't verify certificate hostname for UDS Jul 14, 2016 tests CDRIVER-1155: Use OpenSSL to verify the certificate hostname Jul 14, 2016 .gitattributes CDRIVER-929 line-endings in test data files Oct 19, 2015 .gitignore Add generated files to .gitignore Jul 15, 2016 .gitmodules Ignore stray files/changes in submodules Oct 6, 2015 .mci.yml CDRIVER-1108: Windows + OpenSSL Build variant in Evergreen Jul 14, 2016 CMakeLists.txt CDRIVER-1182: Import CAs from the Windows Cert store to OpenSSL Jul 14, 2016 CONTRIBUTING.md CDRIVER-1337 disable experimental features by default Jul 13, 2016 COPYING doc: drop appendix from license. Mar 13, 2014 Makefile.am CDRIVER-1217 remove spec files May 2, 2016 NEWS CDRIVER-1104 remove MONGOC_I_AM_A_DRIVER and libmongoc-priv May 16, 2016 README.rst updated readme to include build from git instructions for windows and… Jul 6, 2016 VERSION_CURRENT post-release bump Mar 11, 2016 VERSION_RELEASED merge r1.3 branch May 7, 2016 autogen.sh CDRIVER-1080: Warn when downloading non-releases from Github Apr 14, 2016 configure.ac CDRIVER-1104 remove MONGOC_I_AM_A_DRIVER and libmongoc-priv May 16, 2016 valgrind.suppressions CDRIVER-884: Ignore ""still reachable"" messages from sasl Sep 28, 2015 README.rst mongo-c-driver About mongo-c-driver is a client library written in C for MongoDB. mongo-c-driver depends on Libbson. Libbson will automatically be built if you do not have it installed on your system. Documentation / Support / Feedback The documentation is available at http://api.mongodb.org/c/current/. For issues with, questions about, or feedback for libmongoc, please look into our support channels. Please do not email any of the libmongoc developers directly with issues or questions - you're more likely to get an answer on the mongodb-user list on Google Groups. Bugs / Feature Requests Think you’ve found a bug? Want to see a new feature in libmongoc? Please open a case in our issue management tool, JIRA: Create an account and login. Navigate to the CDRIVER project. Click Create Issue - Please provide as much information as possible about the issue type and how to reproduce it. Bug reports in JIRA for all driver projects (i.e. CDRIVER, CSHARP, JAVA) and the Core Server (i.e. SERVER) project are public. How To Ask For Help If you are having difficulty building the driver after reading the below instructions, please email the mongodb-user list to ask for help. Please include in your email all of the following information: The version of the driver you are trying to build (branch or tag). Examples: master branch, 1.2.1 tag Host OS, version, and architecture. Examples: Windows 8 64-bit x86, Ubuntu 12.04 32-bit x86, OS X Mavericks C Compiler and version. Examples: GCC 4.8.2, MSVC 2013 Express, clang 3.4, XCode 5 The output of ./autogen.sh or ./configure (depending on whether you are building from a repository checkout or from a tarball). The output starting from ""libbson was configured with the following options"" is sufficient. The text of the error you encountered. Failure to include the relevant information will result in additional round-trip communications to ascertain the necessary details, delaying a useful response. Here is a made-up example of a help request that provides the relevant information: Hello, I'm trying to build the C driver with SSL, from mongo-c-driver-1.2.1.tar.gz. I'm on Ubuntu 14.04, 64-bit Intel, with gcc 4.8.2. I run configure like: $ ./configure --enable-sasl=yes checking for gcc... gcc checking whether the C compiler works... yes  ... SNIPPED OUTPUT, but when you ask for help, include full output without any omissions ...  checking for pkg-config... no checking for SASL... no checking for sasl_client_init in -lsasl2... no checking for sasl_client_init in -lsasl... no configure: error: You must install the Cyrus SASL libraries and development headers to enable SASL support.  Can you tell me what I need to install? Thanks! Security Vulnerabilities If you’ve identified a security vulnerability in a driver or any other MongoDB project, please report it according to the instructions here. Building the Driver from Source Detailed installation instructions are in the manual: http://api.mongodb.org/c/current/installing.html From a tarball Download the latest release from the release page, then: $ tar xzf mongo-c-driver-$ver.tar.gz $ cd mongo-c-driver-$ver $ ./configure $ make $ sudo make install  To see all of the options available to you during configuration, run: $ ./configure --help  To build on Windows Vista or newer with Visual Studio 2015, do the following: cd mongo-c-driver-$ver cd src\libbson cmake -DCMAKE_INSTALL_PREFIX=C:\usr -G ""Visual Studio 14 Win64"" . msbuild.exe ALL_BUILD.vcxproj msbuild.exe INSTALL.vcxproj cd ..\.. cmake -DCMAKE_INSTALL_PREFIX=C:\usr -DBSON_ROOT_DIR=C:\usr -G ""Visual Studio 14 Win64"" . msbuild.exe ALL_BUILD.vcxproj msbuild.exe INSTALL.vcxproj  Building From Git You can use the following to checkout and build mongo-c-driver: $ git clone https://github.com/mongodb/mongo-c-driver.git $ cd mongo-c-driver $ git checkout x.y.z  # To build a particular release $ ./autogen.sh --with-libbson=bundled $ make $ sudo make install  Building from Git on using Visual Studio 2015: git clone https://github.com/mongodb/mongo-c-driver.git cd mongo-c-driver git checkout x.y.z # for your specific release git submodule init git submodule update # libbson is a submodule cd src\libbson cmake -DCMAKE_INSTALL_PREFIX=C:\libmongoc -G ""Visual Studio 14 Win64"" . msbuild.exe ALL_BUILD.vcxproj msbuild.exe INSTALL.vcxproj cd ..\.. cmake -DCMAKE_INSTALL_PREFIX=C:\libmongoc -DENABLE_SSL=WINDOWS -DBSON_ROOT_DIR=C:\libmongoc -G ""Visual Studio 14 Win64"" . msbuild.exe ALL_BUILD.vcxproj msbuild.exe INSTALL.vcxproj  Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/mongodb/mongo-c-driver"	"A high-performance client library for.."	"true"
"Database"	"MongoDB"	"https://www.mongodb.org/"	"A high-performance client library for.."	"null"	"null"	"null"	"Apache2.0"	"http://directory.fsf.org/wiki/License:Apache2.0"	"null"	"null"	"null"	"null"	"null"	"MongoDB for GIANT Ideas | MongoDB <iframe src=""//www.googletagmanager.com/ns.html?id=GTM-GDFN&amp;nojscript=true"" height=""0"" width=""0"" style=""display:none;""> Docs Open Source University Download For Giant Ideas Solutions Cloud Customers Resources About Us Try It Now MongoDB 3.2 MongoDB Atlas Download Center Products MongoDB Enterprise Advanced MongoDB Professional MongoDB Atlas Development Support Ops Manager Cloud Manager Compass Connector for BI Connector for Spark Services Consulting Training Log in to Cloud Log in Products MongoDB Atlas MongoDB Cloud Manager Resources MongoDB Atlas FAQ MongoDB Atlas Pricing MongoDB Atlas Training MongoDB Atlas Documentation MongoDB Cloud Manager Documentation Try It Now MongoDB 3.2 MongoDB Atlas Download Center Success Stories Government Retail High Tech Financial Services All industries Use Cases Single View Internet of Things Mobile Real-Time Analytics Personalization Content Management Catalog Try It Now MongoDB 3.2 MongoDB Atlas Download Center Resource Center Webinars Presentations White Papers Datasheets Events Documentation What is MongoDB Architecture Scalability NoSQL Database Explained Stay in the know Sign up for our newsletter Our Company Leadership Investors Office Locations Contact Us Blog Partners Press Room Careers Work at MongoDB Student Opportunities Something GIANT has arrived... MongoDB Atlas Learn More With Expedia Online Travel Gets PersonalLearn More Building on the Best of Relational with the Innovations of NoSQLTry MongoDB for Free Expressive Query Language & Secondary Indexes Access and manipulate your data in sophisticated ways, out of the box. Strong Consistency Provide your users with the most up-to-date copy of the data. Flexibility A data model that accommodates the various types of data dominating modern applications. One that allows faster iteration and improved productivity. Enterprise Management & Integration A database that can be secured, monitored, automated, and integrated with your existing IT infrastructure. Scalability & Performance Scale horizontally to deliver incredible performance at massive scale: millions of ops/sec, 100s of billions of documents, petabytes of data. Mission Critical Native replication synchronizes data across servers, racks and data centers to provide a consistent, high-quality experience for users all around the world. MongoDB 3.2 MongoDB 3.2 is a giant leap forward that helps organizations standardize on a single, modern database for their new, mission-critical applications.Learn More Explore Our Products MongoDB Enterprise Advanced MongoDB Enterprise Advanced features MongoDB Enterprise Server and a finely-tuned package of advanced software, support, certifications, and other services. More than one-third of the Fortune 100 rely on MongoDB Enterprise Advanced to help run their mission critical applications.Learn More MongoDB Enterprise Advanced MongoDB Professional MongoDB Atlas Cloud Manager Events Webinars User Groups University MongoDB Events Find out when the next MongoDB event is happening near you, or meet the MongoDB team at an industry conference or trade show.Learn More ANALYST REPORT MongoDB: A Gartner Magic Quadrant Leader A 2015 Magic Quadrant Leader for Operational Database Management SystemsRead the Report WHITE PAPER What’s New in 3.2 Download the white paper to learn about the latest features in MongoDB 3.2.Download EVENTS Join us in New York for MongoDB World MongoDB World provides your engineering teams with insight into database internals, where they’ll learn best practices from the team that builds the database.Register About About MongoDB, Inc. Careers Contact Us Legal Notices Security Information Office Locations Code of Conduct Learn More NoSQL Database Explained MongoDB Architecture Guide MongoDB Enterprise Advanced MongoDB Atlas MongoDB Engineering Blog FAQ MongoDB University View Course Catalog View Course Schedule Public Training Certification Docs MongoDB Manual Installation FAQ Popular Topics NoSQL Database Gartner Magic Quadrant Customer Data Analytics Cloud Server Open Source Data Management Database Performance Monitoring Gartner Operational Dbms Market AWS MongoDB Service Big Data Analytics Architecture Open Source Data Modeling Copyright © 2016 MongoDB, Inc. Mongo, MongoDB, and the MongoDB leaf logo are registered trademarks of MongoDB, Inc. Follow Us Github Twitter Facebook Youtube"	"null"	"null"	"A high-performance client library for.."	"true"
"Database"	"PostgreSQL"	"http://www.postgresql.org/"	"A powerful object-relational database system.."	"null"	"null"	"null"	"PostgreSQL licence"	"https://opensource.org/licenses/postgresql"	"null"	"null"	"null"	"null"	"null"	"PostgreSQL: The world's most advanced open source database Skip site navigation (1) Skip section navigation (2) Search Peripheral Links Donate Contact Home About Download Documentation Community Developers Support Your account 23rd June 2016 PostgreSQL 9.6 Beta 2 Released! The PostgreSQL Global Development Group is pleased to announce the availability of PostgreSQL 9.6 Beta 2, the second beta release of the upcoming 9.6 version of PostgreSQL. Please download and test the beta code with your applications, and report any issues you may find. 9.6 Beta 2 Release Announcement 9.6 Beta 2 Release Notes Download ""Our systems are deployed in high-availability environments and the combination of PostgreSQL on Linux has enabled us to deploy and support systems without any need for a large support team."" Tim Allen, Senior Software Developer, Proximity Group Case Studies|More Quotes|Featured Users 9.5.3 · May 12, 2016 · Notes 9.4.8 · May 12, 2016 · Notes 9.3.13 · May 12, 2016 · Notes 9.2.17 · May 12, 2016 · Notes 9.1.22 · May 12, 2016 · Notes Download | Why should I upgrade? Upcoming releases Security International Sites Mailing Lists Wiki Report a Bug FAQs PostgreSQL is free. Please support our work by making a donation. 2016-07-12 repmgr 3.1.4 released! 2016-07-06 New version of Postgres Migration Tookit has been released 2016-06-30 PostgreSQL Maestro 16.6 released 2016-06-29 Last week for PostgresOpen 2016 Early Bird Tickets! 2016-06-23 PostgreSQL 9.6 Beta 2 Released 2016-06-17 Announcement: Amazon RDS for PostgreSQL now supports cross-region read replicas 2016-06-09 RazorSQL 7.0 Database Query Tool Released More Submit News 2016-07-15 Shaun M. Thomas: PG Phriday: A Postgres Persepctive on MongoDB 2016-07-15 Ivan Lezhnjov IV: Upgrading Ubuntu LTS and PostgreSQL 2016-07-15 Stefan Petrea: Analyzing PostgreSQL logs using pgBadger 2016-07-15 Craig Ringer: How to check the lock level taken by operations in PostgreSQL 2016-07-14 Greg Sabino Mullane: Disabling Postgres constraints for pg_dump 2016-07-14 Craig Kerstiens: When to use unstructured datatypes in Postgres–Hstore vs. JSON vs. JSONB 2016-07-13 Joshua Drake: What is good for the community is good for the company (profit is the reward) More 2016-09-13 – 2016-09-16 PostgresOpen 2016 (Dallas, TX, United States) 2016-10-11 – 2016-10-13 Postgres Vision 2016 (San Francisco, California, United States) 2016-11-01 – 2016-11-04 PGConf.EU 2016 (Tallinn, Estonia) 2016-11-14 – 2016-11-16 PGConf Silicon Valley (South San Francisco, California, United States) 2016-12-02 – 2016-12-03 PGConf ASIA 2016 (Tokyo, Japan) More Submit Event There are 21 training events in 4 countries scheduled over the next six months from 2ndQuadrant Italia, SRA OSS, Inc. Japan and others. Take a look at our schedule to find the training that you want. Privacy Policy | About PostgreSQL Copyright © 1996-2016 The PostgreSQL Global Development Group"	"null"	"null"	"A powerful object-relational database system.."	"true"
"Database"	"recutils"	"https://www.gnu.org/software/recutils/"	"A set of tools and a C library for accessing human-editable, plaintext database files called recfiles. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"GNU Recutils - GNU Project - Free Software Foundation Skip to main text Set language English [en] The  9th HACKERS MEETING  will be held in Rennes (France) from August 18 to 20. JOIN THE FSF Free Software Supporter GNU Operating System Sponsored by the Free Software Foundation About GNU Philosophy Licenses Education = Software = Documentation Help GNU GNU Recutils GNU Recutils is a set of tools and libraries to access human-editable, plain text databases called recfiles. The data is stored as a sequence of records, each record containing an arbitrary number of named fields. The picture below shows a sample database containing information about GNU packages, along with the main features provided by recutils. A video with a talk introducing the program can be found here. An older video, which was recorded just before releasing the first version, can be downloaded from here If you want to discuss about recutils, some of the people involved in GNU recutils use to be in the #recutils channel in the irc.freenode.net IRC network. You are more than welcome to join. Features Data Integrity Mandatory and forbidden fields. Unique fields and primary keys. Auto-counters and time-stamps. Arbitrary constraints. Rich Type System for Fields Predefined: integer, real, date, etc. User-defined: based on regular expressions. Advanced database facilities Joins and foreign keys. Grouping and sorting. Aggregate functions. Encryption Support Selective: individual fields can be encrypted. Password-based AES. Converters from/to other formats mdb files to recfiles. csv files to/from recfiles. Advanced Emacs mode Navigation mode and editing mode. Field folding. Visual edition of fields driven by types. User manual. Integration with org-mode Read data from recfiles into a table in an org-mode buffer in Emacs. Publish the resulting data. Templates Generate reports. Build your own exporters. Complete user manual Full description of the format. Documentation for the utilities. Usage examples. Easy deployment C library: librec Rich set of utilities to be used in shell scripts and in the command line. Do you like this program? Please consider making a donation. The maintainer's PayPal id is jemarch@gnu.org. Thanks! :) Downloading Recutils Sources Distribution GNU recutils can be found on the main GNU ftp server: http://ftp.gnu.org/gnu/recutils/ (via HTTP) and ftp://ftp.gnu.org/gnu/recutils/ (via FTP). It can also be found on the GNU mirrors; please use a mirror if possible. Binary Packages Additionally there are binary packages for some GNU/Linux distributions. Trisquel GNU/Linux Debian packages. Fedora packages Arch packages. OpenSuse packages. Mandrake packages. Gentoo packages. Parabola x86_64 packages. Parabola i686 packages. OpenCSW Solaris packages. FreeBSD. If you know of some other binary distribution of GNU recutils please get in touch with the maintainer. Documentation Take a look to our Frequently Asked Questions section. Documentation for Recutils is available online, as is documentation for most GNU software. You can find more information about Recutils by running info recutils or by looking at /usr/doc/recutils/, /usr/local/doc/recutils/, or similar directories on your system. Mailing lists GNU recutils has two mailing lists: <bug-recutils@gnu.org> and <help-recutils@gnu.org>. The main discussion list is <bug-recutils@gnu.org>, and is used to discuss most aspects of recutils, including development and enhancement requests, as well as bug reports. There is a separate list for general user help and discussion, <help-recutils@gnu.org>. Announcements about Recutils and most other GNU software are made on <info-gnu@gnu.org>. To subscribe to these or any GNU mailing lists, please send an empty mail with a Subject: header of just subscribe to the relevant -request list. For example, to subscribe yourself to the GNU announcement list, you would send mail to <info-gnu-request@gnu.org>. Or you can use the mailing list web interface. Getting involved Development of Recutils, and GNU in general, is a volunteer effort, and you can contribute. For information, please read How to help GNU. If you'd like to get involved, it's a good idea to join the discussion mailing list (see above). Test releases Trying the latest test release (when available) is always appreciated. Test releases of Recutils can be found at http://alpha.gnu.org/gnu/recutils/ (via HTTP) and ftp://alpha.gnu.org/gnu/recutils/ (via FTP). Development For development sources, and other information, please see the Recutils project page at savannah.gnu.org. Please send bug reports and patches to <bug-recutils@gnu.org>. Translating Recutils To translate Recutils's messages into other languages, please see the Translation Project page for Recutils. If you have a new translation of the message strings, or updates to the existing strings, please have the changes made in this repository. Only translations from this site will be incorporated into Recutils. For more information, see the Translation Project. Maintainer Recutils is currently being maintained by Jose E. Marchesi. Please use the mailing lists for contact. Licensing Recutils is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 3 of the License, or (at your option) any later version. GNU home page FSF home page GNU Art GNU's Who? Free Software Directory Hardware Site map “Our mission is to preserve, protect and promote the freedom to use, study, copy, modify, and redistribute computer software, and to defend the rights of Free Software users.” The Free Software Foundation is the principal organizational sponsor of the GNU Operating System. Support GNU and the FSF by buying manuals and gear, joining the FSF as an associate member, or making a donation, either directly to the FSF or via Flattr. back to top Please send general FSF & GNU inquiries to <gnu@gnu.org>. There are also other ways to contact the FSF. Broken links and other corrections or suggestions can be sent to <bug-recutils@gnu.org>. Please see the Translations README for information on coordinating and submitting translations of this article. Copyright © 2010 Free Software Foundation, Inc. This page is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License. Copyright Infringement Notification Updated: $Date: 2016/05/06 11:34:30 $"	"null"	"null"	"A set of tools and a C library for accessing human-editable, plaintext database files called recfiles. or later."	"true"
"Database"	"Redis"	"http://redis.io/"	"An advanced key-value store.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"18819"	"1852"	"6875"	"GitHub - antirez/redis: Redis is an in-memory database that persists on disk. The data model is key-value, but many different kind of values are supported: Strings, Lists, Sets, Sorted Sets, Hashes, HyperLogLogs, Bitmaps. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 1,852 Star 18,819 Fork 6,875 antirez/redis Code Issues 737 Pull requests 409 Pulse Graphs Redis is an in-memory database that persists on disk. The data model is key-value, but many different kind of values are supported: Strings, Lists, Sets, Sorted Sets, Hashes, HyperLogLogs, Bitmaps. http://redis.io 5,867 commits 28 branches 176 releases Fetching contributors C 82.0% Tcl 14.7% Ruby 2.3% Shell 0.5% Makefile 0.3% C++ 0.2% C Tcl Ruby Shell Makefile C++ Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: unstable Switch branches/tags Branches Tags 2.2 2.4 2.6 2.8 3.0 3.2 current-client-fix dictc freelist issue_2175 latency lazyfree ldb less-mstime-28 less-mstime lfu memsync multi-if nosync onepass-bulk rdbchanges rssmaxmemory slave-diskless strcompr unstable waitpid-fix zaddnx zunion Nothing to show with-deprecated-diskstore vm-playpen v2.1.1-watch v2.0.0-rc4 v2.0.0-rc3 v2.0.0-rc2 v2.0.0-rc1 v2.0.0-rc1b v1.3.12 v1.3.11 v1.3.10 v1.3.9 v1.3.8 v1.3.7 twitter-20100825 twitter-20100804 3.2.1 3.2.0 3.2.0-rc3 3.2.0-rc2 3.2-rc1 3.0.7 3.0.6 3.0.5 3.0.4 3.0.3 3.0.2 3.0.1 3.0.0 3.0.0-rc6 3.0.0-rc5 3.0.0-rc4 3.0.0-rc3 3.0.0-rc2 3.0.0-rc1 3.0.0-beta8 3.0.0-beta7 3.0.0-beta6 3.0.0-beta5 3.0.0-beta4 3.0.0-beta3 3.0.0-beta2 3.0.0-beta1 3.0-alpha0 2.8.24 2.8.23 2.8.22 2.8.21 2.8.20 2.8.19 2.8.18 2.8.17 2.8.16 2.8.15 2.8.14 2.8.13 2.8.12 2.8.11 2.8.10 2.8.9 2.8.8 2.8.7 2.8.6 2.8.5 2.8.4 2.8.3 2.8.2 2.8.1 2.8.0 2.8.0-rc6 2.8.0-rc5 2.8.0-rc4 2.8.0-rc3 2.8.0-rc2 2.8.0-rc1 2.6.17 2.6.16 2.6.15 2.6.14 2.6.14-2 2.6.14-1 2.6.13 2.6.12 2.6.11 2.6.10 2.6.10-3 2.6.10-2 2.6.10-1 2.6.9 2.6.9-1 2.6.8 2.6.8-1 2.6.7 2.6.7-1 2.6.6 2.6.5 2.6.4 2.6.3 2.6.2 2.6.1 Nothing to show New pull request Latest commit e423f76 Jul 13, 2016 antirez LRU: Make cross-database choices for eviction. … The LRU eviction code used to make local choices: for each DB visited it selected the best key to evict. This was repeated for each DB. However this means that there could be DBs with very frequently accessed keys that are targeted by the LRU algorithm while there were other DBs with many better candidates to expire.  This commit attempts to fix this problem for the LRU policy. However the TTL policy is still not fixed by this commit. The TTL policy will be fixed in a successive commit.  This is an initial (partial because of TTL policy) fix for issue #2647. Permalink Failed to load latest commit information. deps geohash.c and geohash_helper.c are part of Redis. Jul 6, 2016 src LRU: Make cross-database choices for eviction. Jul 13, 2016 tests Regression test for issue #3333. Jul 6, 2016 utils LRU: Fix output fixes to new test-lru.rb. Jul 11, 2016 .gitignore Generate Makefile.dep at every build. Jul 6, 2016 00-RELEASENOTES Fix typo in 00-RELEASENOTES Sep 29, 2014 BUGS Fix typo Sep 29, 2014 CONTRIBUTING Fix typos in documentation Jun 7, 2016 COPYING update copyright year Apr 21, 2015 INSTALL INSTALL now redirects the user to README Feb 5, 2012 MANIFESTO Format to fit 80 columns Feb 8, 2013 Makefile Fix `install` target on OSX (see #495) May 15, 2012 README.md Fixup Jun 7, 2016 redis.conf Enable tcp-keepalive by default. Jun 13, 2016 runtest Check available tcl versions Jan 24, 2013 runtest-cluster Redis Cluster test framework skeleton. Apr 24, 2014 runtest-sentinel Sentinel test files / directories layout improved. Apr 24, 2014 sentinel.conf Fix sentinel.conf typo Sep 29, 2014 README.md This README is just a fast quick start document. You can find more detailed documentation at http://redis.io. What is Redis? Redis is often referred as a data structures server. What this means is that Redis provides access to mutable data structures via a set of commands, which are sent using a server-client model with TCP sockets and a simple protocol. So different processes can query and modify the same data structures in a shared way. Data structures implemented into Redis have a few special properties: Redis cares to store them on disk, even if they are always served and modified into the server memory. This means that Redis is fast, but that is also non-volatile. Implementation of data structures stress on memory efficiency, so data structures inside Redis will likely use less memory compared to the same data structure modeled using an high level programming language. Redis offers a number of features that are natural to find in a database, like replication, tunable levels of durability, cluster, high availability. Another good example is to think of Redis as a more complex version of memcached, where the operations are not just SETs and GETs, but operations to work with complex data types like Lists, Sets, ordered data structures, and so forth. If you want to know more, this is a list of selected starting points: Introduction to Redis data types. http://redis.io/topics/data-types-intro Try Redis directly inside your browser. http://try.redis.io The full list of Redis commands. http://redis.io/commands There is much more inside the Redis official documentation. http://redis.io/documentation Building Redis Redis can be compiled and used on Linux, OSX, OpenBSD, NetBSD, FreeBSD. We support big endian and little endian architectures, and both 32 bit and 64 bit systems. It may compile on Solaris derived systems (for instance SmartOS) but our support for this platform is best effort and Redis is not guaranteed to work as well as in Linux, OSX, and *BSD there. It is as simple as: % make  You can run a 32 bit Redis binary using: % make 32bit  After building Redis, it is a good idea to test it using: % make test  Fixing build problems with dependencies or cached build options Redis has some dependencies which are included into the deps directory. make does not automatically rebuild dependencies even if something in the source code of dependencies changes. When you update the source code with git pull or when code inside the dependencies tree is modified in any other way, make sure to use the following command in order to really clean everything and rebuild from scratch: make distclean  This will clean: jemalloc, lua, hiredis, linenoise. Also if you force certain build options like 32bit target, no C compiler optimizations (for debugging purposes), and other similar build time options, those options are cached indefinitely until you issue a make distclean command. Fixing problems building 32 bit binaries If after building Redis with a 32 bit target you need to rebuild it with a 64 bit target, or the other way around, you need to perform a make distclean in the root directory of the Redis distribution. In case of build errors when trying to build a 32 bit binary of Redis, try the following steps: Install the packages libc6-dev-i386 (also try g++-multilib). Try using the following command line instead of make 32bit: make CFLAGS=""-m32 -march=native"" LDFLAGS=""-m32"" Allocator Selecting a non-default memory allocator when building Redis is done by setting the MALLOC environment variable. Redis is compiled and linked against libc malloc by default, with the exception of jemalloc being the default on Linux systems. This default was picked because jemalloc has proven to have fewer fragmentation problems than libc malloc. To force compiling against libc malloc, use: % make MALLOC=libc  To compile against jemalloc on Mac OS X systems, use: % make MALLOC=jemalloc  Verbose build Redis will build with a user friendly colorized output by default. If you want to see a more verbose output use the following: % make V=1  Running Redis To run Redis with the default configuration just type: % cd src % ./redis-server  If you want to provide your redis.conf, you have to run it using an additional parameter (the path of the configuration file): % cd src % ./redis-server /path/to/redis.conf  It is possible to alter the Redis configuration by passing parameters directly as options using the command line. Examples: % ./redis-server --port 9999 --slaveof 127.0.0.1 6379 % ./redis-server /etc/redis/6379.conf --loglevel debug  All the options in redis.conf are also supported as options using the command line, with exactly the same name. Playing with Redis You can use redis-cli to play with Redis. Start a redis-server instance, then in another terminal try the following: % cd src % ./redis-cli redis> ping PONG redis> set foo bar OK redis> get foo ""bar"" redis> incr mycounter (integer) 1 redis> incr mycounter (integer) 2 redis>  You can find the list of all the available commands at http://redis.io/commands. Installing Redis In order to install Redis binaries into /usr/local/bin just use: % make install  You can use make PREFIX=/some/other/directory install if you wish to use a different destination. Make install will just install binaries in your system, but will not configure init scripts and configuration files in the appropriate place. This is not needed if you want just to play a bit with Redis, but if you are installing it the proper way for a production system, we have a script doing this for Ubuntu and Debian systems: % cd utils % ./install_server.sh  The script will ask you a few questions and will setup everything you need to run Redis properly as a background daemon that will start again on system reboots. You'll be able to stop and start Redis using the script named /etc/init.d/redis_<portnumber>, for instance /etc/init.d/redis_6379. Code contributions Note: by contributing code to the Redis project in any form, including sending a pull request via Github, a code fragment or patch via private email or public discussion groups, you agree to release your code under the terms of the BSD license that you can find in the COPYING file included in the Redis source distribution. Please see the CONTRIBUTING file in this source distribution for more information. Redis internals If you are reading this README you are likely in front of a Github page or you just untarred the Redis distribution tar ball. In both the cases you are basically one step away from the source code, so here we explain the Redis source code layout, what is in each file as a general idea, the most important functions and structures inside the Redis server and so forth. We keep all the discussion at a high level without digging into the details since this document would be huge otherwise and our code base changes continuously, but a general idea should be a good starting point to understand more. Moreover most of the code is heavily commented and easy to follow. Source code layout The Redis root directory just contains this README, the Makefile which calls the real Makefile inside the src directory and an example configuration for Redis and Sentinel. You can find a few shell scripts that are used in order to execute the Redis, Redis Cluster and Redis Sentinel unit tests, which are implemented inside the tests directory. Inside the root are the following important directories: src: contains the Redis implementation, written in C. tests: contains the unit tests, implemented in Tcl. deps: contains libraries Redis uses. Everything needed to compile Redis is inside this directory; your system just needs to provide libc, a POSIX compatible interface and a C compiler. Notably deps contains a copy of jemalloc, which is the default allocator of Redis under Linux. Note that under deps there are also things which started with the Redis project, but for which the main repository is not anitrez/redis. An exception to this rule is deps/geohash-int which is the low level geocoding library used by Redis: it originated from a different project, but at this point it diverged so much that it is developed as a separated entity directly inside the Redis repository. There are a few more directories but they are not very important for our goals here. We'll focus mostly on src, where the Redis implementation is contained, exploring what there is inside each file. The order in which files are exposed is the logical one to follow in order to disclose different layers of complexity incrementally. Note: lately Redis was refactored quite a bit. Function names and file names have been changed, so you may find that this documentation reflects the unstable branch more closely. For instance in Redis 3.0 the server.c and server.h files were named to redis.c and redis.h. However the overall structure is the same. Keep in mind that all the new developments and pull requests should be performed against the unstable branch. server.h The simplest way to understand how a program works is to understand the data structures it uses. So we'll start from the main header file of Redis, which is server.h. All the server configuration and in general all the shared state is defined in a global structure called server, of type struct redisServer. A few important fields in this structure are: server.db is an array of Redis databases, where data is stored. server.commands is the command table. server.clients is a linked list of clients connected to the server. server.master is a special client, the master, if the instance is a slave. There are tons of other fields. Most fields are commented directly inside the structure definition. Another important Redis data structure is the one defining a client. In the past it was called redisClient, now just client. The structure has many fields, here we'll just show the main ones: struct client {     int fd;     sds querybuf;     int argc;     robj **argv;     redisDb *db;     int flags;     list *reply;     char buf[PROTO_REPLY_CHUNK_BYTES];     ... many other fields ... }  The client structure defines a connected client: The fd field is the client socket file descriptor. argc and argv are populated with the command the client is executing, so that functions implementing a given Redis command can read the arguments. querybuf accumulates the requests from the client, which are parsed by the Redis server according to the Redis protocol and executed by calling the implementations of the commands the client is executing. reply and buf are dynamic and static buffers that accumulate the replies the server sends to the client. These buffers are incrementally written to the socket as soon as the file descriptor is writable. As you can see in the client structure above, arguments in a command are described as robj structures. The following is the full robj structure, which defines a Redis object: typedef struct redisObject {     unsigned type:4;     unsigned encoding:4;     unsigned lru:LRU_BITS; /* lru time (relative to server.lruclock) */     int refcount;     void *ptr; } robj;  Basically this structure can represent all the basic Redis data types like strings, lists, sets, sorted sets and so forth. The interesting thing is that it has a type field, so that it is possible to know what type a given object has, and a refcount, so that the same object can be referenced in multiple places without allocating it multiple times. Finally the ptr field points to the actual representation of the object, which might vary even for the same type, depending on the encoding used. Redis objects are used extensively in the Redis internals, however in order to avoid the overhead of indirect accesses, recently in many places we just use plain dynamic strings not wrapped inside a Redis object. server.c This is the entry point of the Redis server, where the main() function is defined. The following are the most important steps in order to startup the Redis server. initServerConfig() setups the default values of the server structure. initServer() allocates the data structures needed to operate, setup the listening socket, and so forth. aeMain() starts the event loop which listens for new connections. There are two special functions called periodically by the event loop: serverCron() is called periodically (according to server.hz frequency), and performs tasks that must be performed from time to time, like checking for timedout clients. beforeSleep() is called every time the event loop fired, Redis served a few requests, and is returning back into the event loop. Inside server.c you can find code that handles other vital things of the Redis server: call() is used in order to call a given command in the context of a given client. activeExpireCycle() handles eviciton of keys with a time to live set via the EXPIRE command. freeMemoryIfNeeded() is called when a new write command should be performed but Redis is out of memory according to the maxmemory directive. The global variable redisCommandTable defines all the Redis commands, specifying the name of the command, the function implementing the command, the number of arguments required, and other properties of each command. networking.c This file defines all the I/O functions with clients, masters and slaves (which in Redis are just special clients): createClient() allocates and initializes a new client. the addReply*() family of functions are used by commands implementations in order to append data to the client structure, that will be transmitted to the client as a reply for a given command executed. writeToClient() transmits the data pending in the output buffers to the client and is called by the writable event handler sendReplyToClient(). readQueryFromClient() is the readable event handler and accumulates data from read from the client into the query buffer. processInputBuffer() is the entry point in order to parse the client query buffer according to the Redis protocol. Once commands are ready to be processed, it calls processCommand() which is defined inside server.c in order to actually execute the command. freeClient() deallocates, disconnects and removes a client. aof.c and rdb.c As you can guess from the names these files implement the RDB and AOF persistence for Redis. Redis uses a persistence model based on the fork() system call in order to create a thread with the same (shared) memory content of the main Redis thread. This secondary thread dumps the content of the memory on disk. This is used by rdb.c to create the snapshots on disk and by aof.c in order to perform the AOF rewrite when the append only file gets too big. The implementation inside aof.c has additional functions in order to implement an API that allows commands to append new commands into the AOF file as clients execute them. The call() function defined inside server.c is responsible to call the functions that in turn will write the commands into the AOF. db.c Certain Redis commands operate on specific data types, others are general. Examples of generic commands are DEL and EXPIRE. They operate on keys and not on their values specifically. All those generic commands are defined inside db.c. Moreover db.c implements an API in order to perform certain operations on the Redis dataset without directly accessing the internal data structures. The most important functions inside db.c which are used in many commands implementations are the following: lookupKeyRead() and lookupKeyWrite() are used in order to get a pointer to the value associated to a given key, or NULL if the key does not exist. dbAdd() and its higher level counterpart setKey() create a new key in a Redis database. dbDelete() removes a key and its associated value. emptyDb() removes an entire single database or all the databases defined. The rest of the file implements the generic commands exposed to the client. object.c The robj structure defining Redis objects was already described. Inside object.c there are all the functions that operate with Redis objects at a basic level, like functions to allocate new objects, handle the reference counting and so forth. Notable functions inside this file: incrRefcount() and decrRefCount() are used in order to increment or decrement an object reference count. When it drops to 0 the object is finally freed. createObject() allocates a new object. There are also specialized functions to allocate string objects having a specific content, like createStringObjectFromLongLong() and similar functions. This file also implements the OBJECT command. replication.c This is one of the most complex files inside Redis, it is recommended to approach it only after getting a bit familiar with the rest of the code base. In this file there is the implementation of both the master and slave role of Redis. One of the most important functions inside this file is replicationFeedSlaves() that writes commands to the clients representing slave instances connected to our master, so that the slaves can get the writes performed by the clients: this way their data set will remain synchronized with the one in the master. This file also implements both the SYNC and PSYNC commands that are used in order to perform the first synchronization between masters and slaves, or to continue the replication after a disconnection. Other C files t_hash.c, t_list.c, t_set.c, t_string.c and t_zset.c contains the implementation of the Redis data types. They implement both an API to access a given data type, and the client commands implementations for these data types. ae.c implements the Redis event loop, it's a self contained library which is simple to read and understand. sds.c is the Redis string library, check http://github.com/antirez/sds for more information. anet.c is a library to use POSIX networking in a simpler way compared to the raw interface exposed by the kernel. dict.c is an implementation of a non-blocking hash table which rehashes incrementally. scripting.c implements Lua scripting. It is completely self contained from the rest of the Redis implementation and is simple enough to understand if you are familar with the Lua API. cluster.c implements the Redis Cluster. Probably a good read only after being very familiar with the rest of the Redis code base. If you want to read cluster.c make sure to read the Redis Cluster specification. Anatomy of a Redis command All the Redis commands are defined in the following way: void foobarCommand(client *c) {     printf(""%s"",c->argv[1]->ptr); /* Do something with the argument. */     addReply(c,shared.ok); /* Reply something to the client. */ }  The command is then referenced inside server.c in the command table: {""foobar"",foobarCommand,2,""rtF"",0,NULL,0,0,0,0,0},  In the above example 2 is the number of arguments the command takes, while ""rtF"" are the command flags, as documented in the command table top comment inside server.c. After the command operates in some way, it returns a reply to the client, usually using addReply() or a similar function defined inside networking.c. There are tons of commands implementations inside th Redis source code that can serve as examples of actual commands implementations. To write a few toy commands can be a good exercise to familiarize with the code base. There are also many other files not described here, but it is useless to cover everything. We want to just help you with the first steps. Eventually you'll find your way inside the Redis code base :-) Enjoy! Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/antirez/redis"	"An advanced key-value store.."	"true"
"Database"	"sophia"	"https://github.com/pmwkaa/sophia"	"A modern, embeddable key-value database.."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"1298"	"104"	"102"	"GitHub - pmwkaa/sophia: Modern key-value/row storage library. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 104 Star 1,298 Fork 102 pmwkaa/sophia Code Issues 29 Pull requests 1 Pulse Graphs Modern key-value/row storage library. http://sophia.systems 600 commits 5 branches 3 releases 6 contributors C 98.8% Other 1.2% C Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master v1.1 v1.2.2 v1.2.3 v2.1 Nothing to show version_2.1 version_1.2.3 version_1.2.2 Nothing to show New pull request Latest commit ff5b56a Jul 8, 2016 pmwkaa sophia: move read into db io layer Permalink Failed to load latest commit information. documentation sophia: align documentation/README.md logo for github Jan 24, 2016 example sophia: custom compare function Jun 6, 2016 sophia sophia: move read into db io layer Jul 8, 2016 test sophia: move read into db io layer Jul 8, 2016 .gitignore sophia: custom compare function Jun 6, 2016 .travis.yml sophia: implement views (point-in-time read-only views) Dec 22, 2015 LICENSE sophia: hide header copy Jan 21, 2015 README.md sophia: update README.md Jul 2, 2016 makefile sophia: set master version to 2.2 Jun 2, 2016 README.md Sophia is advanced transactional MVCC key-value/row storage library. Optimized for Updates and Range-Scans. It can efficiently work with large volumes of ordered data, such as a time-series, events, logs, counters, metrics, etc. Features Full ACID compliancy Multi-Version Concurrency Control (MVCC) engine Optimistic, non-blocking concurrency with N-writers and M-readers Pure Append-Only Unique data storage architecture Multi-threaded (linear compaction scalability) Multi-databases support (sharing a single write-ahead log) Secondary indexes Multi-Statement and Single-Statement Transactions (cross-database) Serialized Snapshot Isolation (SSI) AMQ Filter (approximate member query filter) based on Quotient Filter Upsert (fast write-only 'update or insert' operation) Consistent Cursors Prefix search Automatic garbage-collection Automatic key-expire Hot Backup Compression (no fixed-size blocks, no-holes, supported: lz4, zstd) Compression for hot and cold data (distinct compression types) Optimizations for faster recovery with large datasets (snapshot) Easy to use (minimalistic API) Easy to write bindings (FFI-friendly) Easy to built-in (amalgamated source) Implemented as small C-written library with zero dependencies Carefully tested Open Source Software, BSD Licensed Support Sophia Documentation and Bindings for the most common languages are available on the website. Please use Official Sophia Google Group or StackOverflow to ask any general questions. More information is available Here. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/pmwkaa/sophia"	"A modern, embeddable key-value database.."	"true"
"Database"	"SQLite"	"http://www.sqlite.org/"	"A self-contained, serverless, zero-configuration, transactional SQL database engine with a C interface. Public domain."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"SQLite Home Page Small. Fast. Reliable. Choose any three. About Documentation Download License Support Purchase SQLite is a software library that implements a self-contained, serverless, zero-configuration, transactional SQL database engine. SQLite is the most widely deployed database engine in the world. The source code for SQLite is in the public domain. More... Sponsors Continuing enhancement and maintenance of SQLite is made possible by SQLite Consortium members, including: Current Status Version 3.13.0 of SQLite is recommended for all new development. Common Links Features When to use SQLite Frequently Asked Questions Getting Started SQL Syntax Pragmas SQL functions Date & time functions Aggregate functions JSON functions C/C++ Interface Spec Introduction List of C-language APIs The TCL Interface Spec Development Timeline Report a Bug News"	"null"	"null"	"A self-contained, serverless, zero-configuration, transactional SQL database engine with a C interface. Public domain."	"true"
"Database"	"UnQLite"	"https://unqlite.org/"	"A self-contained, serverless, zero-configuration, transactional NoSQL engine with a C interface.."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"null"	"null"	"null"	"UnQLite - An Embeddable NoSQL Database Engine An Embeddable NoSQL Database Engine Tweet Follow @unqlite_db About Distinctive Features Getting Started Documentation Downloads License FAQ Online Support About unQLite. UnQLite is a in-process software library which implements a self-contained, serverless, zero-configuration, transactional NoSQL database engine. UnQLite is a document store database similar to MongoDB, Redis, CouchDB etc. as well a standard Key/Value store similar to BerkeleyDB, LevelDB, etc. UnQLite is an embedded NoSQL (Key/Value store and Document-store) database engine. Unlike most other NoSQL databases, UnQLite does not have a separate server process. UnQLite reads and writes directly to ordinary disk files. A complete database with multiple collections, is contained in a single disk file. The database file format is cross-platform, you can freely copy a database between 32-bit and 64-bit systems or between big-endian and little-endian architectures. UnQLite features includes: Serverless, NoSQL database engine. Transactional (ACID) database. Zero configuration. Single database file, does not use temporary files. Cross-platform file format. UnQLite is a Self-Contained C library without dependency. Standard Key/Value store. Document store (JSON) database via Jx9. Support cursors for linear records traversal. Pluggable run-time interchangeable storage engine. Support for on-disk as well in-memory databases. Built with a powerful disk storage engine which support O(1) lookup. Thread safe and full reentrant. Simple, Clean and easy to use API. Support Terabyte sized databases. BSD licensed product. Amalgamation: All C source code for UnQLite and Jx9 are combined into a single source file. Highly available online support.   Refer to the feature page for a detailed description. Current Stable Release: 1.1.6 UnQLite is a self-contained C library without dependency. It requires very minimal support from external libraries or from the operating system. This makes it well suited for use in embedded devices that lack the support infrastructure of a desktop computer. This also makes UnQLite appropriate for use within applications that need to run without modification on a wide variety of computers of varying configurations. UnQLite is written in ANSI C, Thread-safe, Full reentrant, compiles unmodified and should run in most platforms including restricted embedded devices with a C compiler. UnQLite is extensively tested on Windows and UNIX systems especially Linux, FreeBSD, Oracle Solaris and Mac OS X. UnQLite is a standard key/value store similar to BerkeleyDB, LevelDB, etc. but, with a rich feature set including support for transactions (ACID), concurrent reader, etc. Under the KV store, both keys and values are treated as simple arrays of bytes, so content can be anything from ASCII strings, binary blob and even disk files. The KV store layer is presented to host applications via a set of interfaces, these includes: unqlite_kv_store(), unqlite_kv_append(), unqlite_kv_fetch_callback(), unqlite_kv_append_fmt(), unqlite_kv_delete(), etc. The Document store interface to UnQLite which is used to store JSON docs (i.e. Objects, Arrays, Strings, etc.) in the database is powered by the Jx9 programming language. Jx9 is an embeddable scripting language also called extension language designed to support general procedural programming with data description facilities.  Jx9 is a Turing-Complete, dynamically typed programming language based on JSON and implemented as a library in the UnQLite core. Finally, UnQLite is an open-source product release under the 2-Clause BSD license. See the license page for additional information. unQLite Programming Interfaces. Documentation describing the APIs used to program UnQLite. Note that UnQLite is very easy to learn, even for new programmer. Here is some useful links to start with: UnQLite In 5 Minutes Or Less A very quick introduction to programming with UnQLite with working examples implemented in C. Introduction To The UnQLite C/C++ Interface Gives an overview and roadmap to the C/C++ interface to UnQLite. Introduction To Jx9 Jx9 is the embedded scripting language which power the document-store interface to UnQLite. Jx9 is a Turing complete programming language based on JSON and implemented as a library in the UnQLite core. C/C++ API Reference Guide This document describes each API function in details. The Architecture of the UnQLite Database Engine Gives a high-level overview of the UnQLite architecture and the related interfaces. Foreign Function Implementation Is a howto guide on how to create and install foreign functions (Typically implemented in C/C++) and how to invoke them from your Jx9 script. Constant Expansion Mechanism Is a howto guide on how to install foreign constants (Typically implemented in C/C++) and how to expand their values from your Jx9 script. Other Useful links. Download Get a copy of the last public release of UnQLite, start embedding and enjoy programming with. Distinctive Features This document enumerates and describes some of the features and powerfull extensions introduced by UnQLite and the Jx9 programming language to the database model. Frequently Asked Questions FAQ: The title of the document says all... Sponsorship Program The UnQLite sponsorship program is dedicated to insuring the continuing vitality of UnQLite. UnQLite is high-quality, Open-source software. The goal of the sponsorship program is to make sure it stays that way. Copyright/Licensing UnQLite is an Open-source product. Find more on the licensing situation there. Online Community Support Need some help, join the UnQLite online community. Copyright © Symisc Systems"	"null"	"null"	"A self-contained, serverless, zero-configuration, transactional NoSQL engine with a C interface.."	"true"
"Deep Learning"	"Darknet"	"http://pjreddie.com/darknet/"	"An open source neural network framework written in C and CUDA. It is fast, easy to install, and supports CPU and GPU computation."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"891"	"117"	"307"	"GitHub - pjreddie/darknet: Convolutional Neural Networks Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 117 Star 891 Fork 307 pjreddie/darknet Code Pull requests 11 Wiki Pulse Graphs Convolutional Neural Networks http://pjreddie.com/darknet/ 285 commits 1 branch 0 releases 1 contributor C 90.7% Cuda 8.6% Other 0.7% C Cuda Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Latest commit a6b2511 Jun 25, 2016 pjreddie idk Permalink Failed to load latest commit information. cfg idk Jun 25, 2016 data CVPR prep Jun 22, 2016 scripts damnit alex Jun 6, 2016 src idk Jun 25, 2016 .gitignore inet label script Jun 12, 2015 LICENSE add license Jul 10, 2015 Makefile idk Jun 25, 2016 README.md Update README.md Aug 5, 2015 README.md Darknet Darknet is an open source neural network framework written in C and CUDA. It is fast, easy to install, and supports CPU and GPU computation. For more information see the Darknet project website. For questions or issues please use the Google Group. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/pjreddie/darknet"	"An open source neural network framework written in C and CUDA. It is fast, easy to install, and supports CPU and GPU computation."	"true"
"Editors"	"Anjuta DevStudio"	"http://anjuta.org/"	"The GNOME IDE. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"null"	"null"	"null"	"Anjuta DevStudio Anjuta DevStudio GNOME Integrated Development Environment Menu Home Features Development Projects Team Home Latest Releases Download Anjuta 3.18 Download Anjuta Extras 3.10 Documentation Anjuta Manual Anjuta FAQ Anjuta Build Tutorial Anjuta core API docs Anjuta Architecture Creating project templates New plugins tutorial Anjuta DevStudio is a versatile software development studio featuring a number of advanced programming facilities including project management, application wizard, interactive debugger, source editor, version control, GUI designer, profiler and many more tools. It focuses on providing simple and usable user interface, yet powerful for efficient development.   Simple user interface Anjuta UI is designed to be simple to operate, yet provides powerful tools. Project wizards and templates Easy wizards and project templates for getting started with new projects. Many supported languages Anjuta supports programming languages C, C++, Java, Javascript, Python, Vala Integrated Glade Full Glade integration for WYSIWYG UI development for GTK+/GNOME applications Integrated GDB Fully integrated GDB for onboard debugging Integrated DevHelp DevHelp integration for context sensitive help   Learn More Anjuta News Developer Experience Hackfest Report I have been at the Developer Experience Hackfest representing Anjuta with Carl-Anton.... Anjuta 3.6.0 released Anjuta 3.6.0 (September 26, 2012) — James Liggett This is a new stable version of Anj... Anjuta 3.2.2 released There is a new stable release of anjuta in the 3.2 branch fixing some important bugs.... More News Development Resources Anjuta wiki Bugzilla product Git: git clone git://git.gnome.org/anjuta Browse source code Tarballs Future Roadmap Building Anjuta Old Roadmap Web site Admin Development Getting in Touch IRC channel Mailing list File a bug Copyright 2014 Anjuta Team"	"null"	"null"	"The GNOME IDE. only."	"true"
"Editors"	"Code::Blocks"	"http://www.codeblocks.org/"	"An extensible, configurable IDE supporting C. only."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"Code::Blocks Code::Blocks - The IDE with all the features you need, having a consistent look, feel and operation across platforms. Home Features Downloads Forums Wiki Main Home Features Screenshots Downloads Plugins User manual Licensing Donations Quick links FAQ Wiki Forums Forums (mobile) Nightlies Ticket System Browse SVN Browse SVN log The open source, cross platform, free C, C++ and Fortran IDE. Code::Blocks is a free C, C++ and Fortran IDE built to meet the most demanding needs of its users. It is designed to be very extensible and fully configurable. Finally, an IDE with all the features you need, having a consistent look, feel and operation across platforms. Built around a plugin framework, Code::Blocks can be extended with plugins. Any kind of functionality can be added by installing/coding a plugin. For instance, compiling and debugging functionality is already provided by plugins! Special credits go to darmar for his great work on the FortranProject plugin, bundled since release 13.12. We hope you enjoy using Code::Blocks! The Code::Blocks Team   Code::Blocks 16.01 is here! Written by MortenMacFly    Thursday, 28 January 2016 10:21 Many, many improvements, new plugins and features, more stable and major code completion enhancement, the new Code::Blocks release has finally arrived. Get it from the downloads section! A changelog summarises new features and fixes. We provide binaries for the major platforms supported by Code::Blocks, with more to come in the next time. Last Updated on Thursday, 28 January 2016 21:13   15.12 release is close to be released - try RC1! Written by MortenMacFly    Monday, 07 December 2015 19:07 We are close to release the next version of Code::Blocks. Please try version 15.12 RC1 now an report back!   Moved to new server Written by Yiannis Mandravellos    Friday, 18 September 2015 12:43 After struggling with the hardware issues we had with the old server, we finally took the plunge and moved to a new (and hopefully better) server! Services are still being enabled and configured on the new server but most user-critical services should be up and running. These include the main web site and the forums. In the coming hours, all services should be accessible again, just like they were before the move. Thank you all for your patience. For those interested, the old server has been serving us since Feb 1st of 2008 and did that well over all these years. We can only hope the new server will last as long as the old one, if not longer! Last Updated on Saturday, 23 January 2016 16:05   Don't miss the nightlies! Written by MortenMacFly    Wednesday, 26 August 2015 15:20 We are well alive and kicking! Please remember, that while waiting for the next release, you can try new features by using the ""nightlies"" that we provide here (downloads are on SourceForge, as usual). We also provide nightly ""setups"" for windows for those, who like and/or need installer. Last Updated on Sunday, 30 August 2015 08:16   Server problems Written by Yiannis Mandravellos    Friday, 18 September 2015 08:23 We 've been facing some hardware problems with our main server and they 've only gotten worse during the last few days. We apologize about that. We 're actively handling the issue. Hopefully it will be resolved soon, even if it means moving to a new server. Please bear with us and stay tuned :) Last Updated on Saturday, 23 January 2016 16:05   Bug&Patch Tracker now at SourceForge Written by MortenMacFly    Friday, 16 May 2014 04:58 Due to the fact that BerliOS will close its services we have created a ticket system at SourceForge and closed the bug and patch tracker at BerliOS. Last Updated on Wednesday, 26 August 2015 15:28   Build system Code::Blocks implements a custom build system with very important features: ultra-fast dependencies generation, build queues and parallel builds are the most important ones to mention. Debugging The debugging subsystem has been greatly enhanced in the latest version. Automatic/manual watches, code/data breakpoints, call stack, disassembly listing and memory dumps are only few of its features."	"null"	"null"	"An extensible, configurable IDE supporting C. only."	"true"
"Editors"	"CodeLite"	"http://www.codelite.org/"	"A cross-platform IDE. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"638"	"83"	"187"	"GitHub - eranif/codelite: CodeLite, a cross platform C/C++/PHP and Node.js IDE written in C++ Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 83 Star 638 Fork 187 eranif/codelite Code Issues 124 Pull requests 2 Pulse Graphs CodeLite, a cross platform C/C++/PHP and Node.js IDE written in C++ http://codelite.org 9,146 commits 1 branch 19 releases 30 contributors C++ 65.7% C 27.3% PHP 5.3% CMake 0.4% Lex 0.3% HTML 0.3% Other 0.7% C++ C PHP CMake Lex HTML Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show v5.0.6213 v4.1.5770 v4.0.5589 v3.5.0.5375 9.2 9.1 9.0 8.1 8.0 8.0-1 7.0 6.1.1 6.1 6.0.1 6.0 5.4 5.3 5.2 5.1 Nothing to show New pull request Latest commit 3a74a35 Jul 13, 2016 eranif Updated Windows resource file to 9.2.0 … Updated OSX Info.plist to 9.2.0 Permalink Failed to load latest commit information. CMakePlugin Fixed: The default Setting of Cmake plugin has a mistake in windows Jul 6, 2016 CallGraph Added new logging API in addition to the old C-Style printf like macr… May 4, 2016 ClangOutputParser - clang cc: added a yacc based parser to parse clang cc output (bette… Jun 22, 2011 CodeCompletionsTests Make boost::shared_ptr and boost::scoped_ptr code completion work wit… Mar 18, 2016 CodeDesigner Merge pull request #774 from jcowgill/duplicate-rpath May 15, 2015 CodeFormatter Fixed: the generated package (from the CMakeLists.txt) is now using l… Jun 9, 2016 CodeLite Really fix: ""completion of *.php5 contents"" Jul 5, 2016 CodeLiteDiff Preparing the code base to support codelite-lldb on Windows Apr 3, 2016 CommentParser added support for project level environment variables + project level… Sep 18, 2010 ContinuousBuild Changed the ""Builder"" interface to support custom user arguments to p… Apr 16, 2016 Copyright Fixed: replace in files panel: disable the replace-all button while a… Dec 4, 2015 CxxParser Fixed: assertion in Open Resource dialgot due to wx3.1 changes Apr 23, 2015 DatabaseExplorer No (intentional) real changes; just fixes to multiple files for wx3.1… May 18, 2016 Debugger Fixed build error on Windows 32 bit Jul 12, 2016 ExternalTools Windows: use native wxAuiToolBar theme Mar 14, 2016 File2Hex Changing branch scintilla 2.0 into trunk Sep 3, 2009 FileCrawler/trunk Fixed: when ""crawling"" to header files from an #include statement, ke… Jun 19, 2014 FileGrep git-svn-id: https://codelite.svn.sourceforge.net/svnroot/codelite/tru… Jun 18, 2011 Gizmos Fixed: Remember ""#pragma once"" setting in ""New Class""-Dialog Jan 21, 2016 HelpPlugin Preparing the code base to support codelite-lldb on Windows Apr 3, 2016 InnoSetup Don't package LLDB on Windows 32 bit Jul 13, 2016 Interfaces Changed gdb defaults: Apr 18, 2016 LLDBDebugger Fixed: the generated package (from the CMakeLists.txt) is now using l… Jun 9, 2016 LiteEditor Updated Windows resource file to 9.2.0 Jul 13, 2016 MacBundler Fixed: replace in files panel: disable the replace-all button while a… Dec 4, 2015 MemCheck Fixed: replace in files panel: disable the replace-all button while a… Dec 4, 2015 Outline Truly fix: Window postition not restored correctly (#1099) Feb 23, 2016 PCH Fixed: replace in files panel: disable the replace-all button while a… Dec 4, 2015 Plugin Fixed: handle ""php5"" file extension as a PHP file Jun 28, 2016 PreProcessor - regenerated PP files using the correct yacc Jul 2, 2011 QmakePlugin No (intentional) real changes; just fixes to multiple files for wx3.1… May 18, 2016 Runtime Updated Windows resource file to 9.2.0 Jul 13, 2016 SFTP Fixed: XML: highlight tags that contain ""-"" Apr 18, 2016 ScopeOptimizer C++ Code Completion: suggest code completion for C++11 lambda functio… Apr 8, 2015 SnipWiz Preparing the code base to support codelite-lldb on Windows Apr 3, 2016 SpellChecker Windows: use native wxAuiToolBar theme Mar 14, 2016 Subversion2 Added tooltip to the source control field in the status bar Jun 6, 2016 TestDir Fixed: build error on Windows due to cppcheck source files update Apr 3, 2015 Tweaks Fixed: replace in files panel: disable the replace-all button while a… Dec 4, 2015 UnitTest++ Added more CMake files Feb 7, 2013 UnitTestCPP Fixed: replace in files panel: disable the replace-all button while a… Dec 4, 2015 WebTools Fixed: HTML close tag auto completion issue - adds extra characters Jul 4, 2016 WordCompletion Fixed: Word Completion Plugin: no word completion for words surrounde… Jul 6, 2016 ZoomNavigator Truly fix: Window postition not restored correctly (#1099) Feb 23, 2016 abbreviation Mass spelling fixes Feb 7, 2016 art Updated CodeLite splash screen to 2016 + new Logo Dec 31, 2015 bitmaps Updated the status bar warning/error images Jun 6, 2016 cmake/Modules updated icon.icns Dec 4, 2015 codelite-icons-dark Removed obsolete icons Nov 4, 2015 codelite-icons-fresh-farm Removed obsolete icons Nov 4, 2015 codelite-icons Removed obsolete icons Nov 4, 2015 codelite_echo Fixed: build error on Windows due to cppcheck source files update Apr 3, 2015 codelite_launcher Mass spelling fixes Feb 7, 2016 codelite_make fixed codelite-make to support the new builder changes Apr 16, 2016 codelite_terminal Mass spelling fixes Feb 7, 2016 codelite_utils make-weekly script now also builds the Windows weekly (64 bit) Feb 3, 2016 codelitegcc Remove RPATH settings from plugin CMakeLists May 14, 2015 codelitephp Added ""*.php5"" to the default php5 view Jul 3, 2016 cppchecker No (intentional) real changes; just fixes to multiple files for wx3.1… May 18, 2016 cscope Fixed crash on MSW debug build Jun 8, 2016 formbuilder Fixed: don't use tree-book control for the code completion dialog May 7, 2016 gdbparser GDB: Fixed: Problem with breakpoints in C++ function templates Sep 2, 2015 git cscope: display the matches in a layout similar to the ""find-in-files"" Jun 8, 2016 icons Removed obsolte file Jun 9, 2016 le_exec Fixed: build error on Windows due to cppcheck source files update Apr 3, 2015 lib/gcc_lib added dummy .gitignore file to so the folder lib/gcc_lib is kept in git Feb 24, 2015 patches When creating new project of type 'wxCrafter' prompt the user if the … Dec 6, 2012 sdk Clang code completion: updated libclang64 to the latest clang (64 bit… Apr 4, 2016 sqlite3 Removed obsolete files Apr 3, 2015 svgs Updated the status bar warning/error images Jun 6, 2016 translations updated following files for translate2chinese: Feb 26, 2016 wxformbuilder Fixed: replace in files panel: disable the replace-all button while a… Dec 4, 2015 .drone.yml Continuous Integration: Configure Tea CI. May 27, 2016 AUTHORS updated todo list Sep 7, 2013 BuildInfo.txt Renamed project 'LiteEditor' to 'CodeLiteIDE' Nov 26, 2014 CMakeLists.txt Updated version to 9.2.0 Jul 3, 2016 COPYING Updated COPYING license file Apr 15, 2014 DESC Linux: generate a more standard deb packages using cmake (Part III) Sep 14, 2015 LICENSE cmake: added support for 'install' target Feb 9, 2013 LiteEditor.workspace CMake plugin: support windows resource files Jun 20, 2016 README.md README.md: apt-get install libwxbase3.0-dev libsqlite3-dev libwxsqlit… Apr 10, 2016 TODO.TXT Fixed: #1135 Feb 8, 2016 about.html Changing branch scintilla 2.0 into trunk Sep 3, 2009 codelite.spec - Changed version number from 2.3 to 2.5 as preparation for the new c… Mar 29, 2010 codelite.xml - Applied patch to register .project / .workspace mime types as codel… Jan 9, 2011 codelite_prefix.h Updated CodeLite copyrights header file Dec 2, 2015 compilers.json Startup wizard: fetch the compilers suggestion list to install from t… Jul 27, 2015 mac-build.sh added exec permissions Aug 11, 2013 make-weekly 7-zip the Windows binaries before uploading it May 19, 2016 make_repo.txt added post install step to .deb file Mar 24, 2008 make_src_targz.sh Produce a Linux .xz tarball as well as the current .tar.gz Jul 20, 2013 pack-icons-all.bat Added new icons packaging script Mar 31, 2013 README.md What is CodeLite? CodeLite is an open source, free, cross platform IDE for the C/C++ programming languages which runs on all major Platforms ( OSX, Windows and Linux ) You can download pre-built binaries for Windows / OSX and Linux from our main Download Page More information can be found here: Official Website Wiki Download Page Building CodeLite on Linux To build CodeLite on your computer you will need these packages: wxWidgets 3.0 or later The gtk development package: often called libgtk2.0-dev or wxGTK-devel or similar pkg-config (which usually comes with the gtk dev package) The build-essential package (or the relevant bit of it: g++, make etc) git cmake You should have wxWidgets 3.0 or later built on your machine. If you don't know how to build (or you're just lazy ...) you can download it install wxWidgets from CodeLite's repository On Ubuntu / Debian you can install all of the above (except for wxWidgets 3.0) by typing: sudo apt-get install libgtk2.0-dev pkg-config build-essential git cmake libssh-dev libwxbase3.0-dev libsqlite3-dev libwxsqlite3-3.0-dev  Git clone the sources: git clone https://github.com/eranif/codelite.git  Run cmake and build codelite: cd codelite mkdir build-release cd build-release cmake -G ""Unix Makefiles"" -DCMAKE_BUILD_TYPE=Release .. make -j4 sudo make install  Building CodeLite on OS X Prerequisites: wxWidgets 3.x CMake HomeBrew git XCode XCode command-line tools Preparation: (Optional) Make a separate folder for building if you want to get rid of all except the .app file after building Install XCode from Mac App Store Install XCode command-line tools xcode-select --install Install HomeBrew :  ruby -e ""$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)""  Update HomeBrew : brew update (Optional) Upgrade HomeBrew packages : brew upgrade Install git : brew install git Install CMake : brew install cmake Install wxWidgets : brew install wxmac --dev --use-llvm Clone the repo (lets assume that you have a folder /Users/YOU/src)   cd /Users/YOU/src   git clone https://github.com/eranif/codelite.git the above will create the folder /Users/YOU/codelite To build CodeLite:   cd /Users/YOU/codelite   mkdir build-release   cd build-release   cmake .. -DCMAKE_BUILD_TYPE=Release   make -j4   make install You should now have an app bundle /Users/YOU/codelite/build-release/codelite.app To launch CodeLite: open /Users/YOU/codelite/build-release/codelite.app Building CodeLite on Windows Git clone the sources git clone https://github.com/eranif/codelite.git  Download codelite installer for Windows from our Download Page Download wxWidgets 3.0 installer. Also from our Download Page Open the workspace LiteEditor.workspace (located in the codelite folder) Make sure that the project CodeLiteIDE is selected (the active project uses bold font) Select the Win_x64_Release or Win_x86_Release (depending if you want to build a 32 or 64 bit version of CodeLite) and hit F7 When the compilation is over, close the workspace Next, locate the workspace codelite_utils/codelite_utils.workspce and open it Select the Win_x64_Release or Win_x86_Release (depending if you want to build a 32 or 64 bit version of CodeLite) hit F7 and wait for the compilation to end Close CodeLite To update your installation with the new codelite, close codelite and from a CMD.EXE window navigate to codelite-sources/Runtime/ and run the file update.bat OR update64.bat (again, depending on your selected arch) Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/eranif/codelite"	"A cross-platform IDE. only."	"true"
"Editors"	"Eclipse"	"http://www.eclipse.org/ide/"	"An IDE written in Java.."	"null"	"null"	"null"	"EPL"	"http://directory.fsf.org/wiki/License:EPLv1.0"	"null"	"null"	"null"	"null"	"null"	"Eclipse desktop & web IDEs Skip to main content Create account Log in Download Download Getting Started Members Projects Community Marketplace Events Planet Eclipse Newsletter Videos Participate Report a Bug Forums Mailing Lists Wiki IRC How to Contribute Working Groups Automotive Internet of Things LocationTech Long-Term Support PolarSys Science OpenMDM More Community Marketplace Events Planet Eclipse Newsletter Videos Participate Report a Bug Forums Mailing Lists Wiki IRC How to Contribute Working Groups Automotive Internet of Things LocationTech Long-Term Support PolarSys Science OpenMDM Toggle navigation Breadcrumbs Home IDE Desktop IDEs Eclipse is famous for our Java Integrated Development Environment (IDE), but our C/C++ IDE and PHP IDE are pretty cool too. You can easily combine language support and other features into any of our default packages, and the Eclipse Marketplace allows for virtually unlimited customization and extension. Java IDE Java EE C/C++ PHP Cloud IDEs Develop your software wherever you go. It'll be there, in the cloud, right where you left it. Use your browser to develop with hosted workspaces or install desktop packaging to experience a modern development environment for Java, JavaScript, CSS, and HTML. IDE Platforms Create the next generation of developer tooling with our extensible platforms. Use your imagination to build services and tools that can be assembled into new IDEs or packages tailored to your identity. We provide multiple platforms to build plug-ins for desktop tools, distributed services used by cloud IDEs, and browser interfaces. You can then publish plug-ins to our Eclipse Marketplace of 1000s. Eclipse Platform Tools Extend the extensible platform. An impressive collection of tools can be easily installed into your Eclipse desktop IDE, including GUI builders and tools for modeling, charting and reporting, testing, and more. Marketplace Customize and extend Eclipse and make it your own. Use the Eclipse Marketplace Client to find, install, and vote for new plug-ins from our vast ecosystem of providers. Extend Join the Community. Extend the desktop and web-based IDEs by writing your own plug-ins using the Plug-in Development Environment (PDE), or mash up features to build the web IDE of your dreams. Discover Find an Eclipse open source project. List of projects Back to the top Eclipse Foundation About us Contact Us Donate Governance Logo and Artwork Board of Directors Legal Privacy Policy Updated Terms of Use Updated Copyright Agent Eclipse Public License Legal Resources Useful Links Report a Bug Documentation How to Contribute Mailing Lists Forums Marketplace Other IDE and Tools Community of Projects Working Groups Copyright © 2016 The Eclipse Foundation. All Rights Reserved. Back to the top"	"null"	"null"	"An IDE written in Java.."	"true"
"Editors"	"Geany"	"http://www.geany.org/"	"A very small and fast IDE. or later."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"null"	"null"	"null"	"Geany : Home Page  Geany Search: View | History | Print Geany HomePage About Screenshots Authors / Thanks Reviews Download Releases Third Party Packages Git / Nightly Extras Documentation Manual / Wiki FAQ Release Notes ChangeLog ToDo Hacking Geany Support Plugins / Wishlist Mailing lists / IRC Bugs and Features Building from Source Running on Windows Contribute Developers Translators Documentation Support Login  Main»Home Page Home Page Welcome! Geany is a text editor using the GTK+ toolkit with basic features of an integrated development environment. It was developed to provide a small and fast IDE, which has only a few dependencies from other packages. It supports many filetypes and has some nice features. For more details see About. Latest version is: 1.28 News: Geany-Plugins 1.28 released! Posted on Jul. 10, 2016 at 01:55 PM Permanent link We are happy to announce a new version of the combined Geany-Plugins release -- right after Geany 1.28, Geany-Plugins 1.28 has been released. Here are some of the most prominent news. Improve GTK3 for several plugins (Quentin Glidic). Rename plugin GeanySendMail to SendMail (Frank Lanitz). Update translations: de, fr, pt, tr. Improve listing tasks containing comments (Quentin Glidic). Fix a crash in the PairTagHighlighter plugin when the tag name is missing (Colomban Wendling). Fix several memory leaks in the PrettyPrinter plugin (Colomban Wendling). Include Scope plugin in the Windows installer (Colomban Wendling). A more complete list of changes can be found in the NEWS file As usual, you can find source tarballs and Windows installer for the new release on plugins.geany.org. A huge thanks to everybody contributing to this great release. Geany 1.28 is out! Posted on Jul. 10, 2016 at 01:49 PM Permanent link We are happy to announce a new release of Geany! For a comprehensive list of changes please see Release Notes. A very detailed and complete list of changes can be found in the ChangeLog. Some highlights: Improve support for GTK 3.20. Fix type name coloring when types change (Jiří Techet). Fix undo of line end type change (Jiří Techet). Update Scintilla to version 3.6.6. Improve Goto Symbol popup contents (Jiří Techet). Treat .h headers as C++ by default (Jiří Techet). Improve symbols for Ruby. Update translations: ca, de, el, es, fr, it, ja, lt, pt, ru, sk, tr, zh_CN. We want to thank all developers, translators and everyone who contributed to this release with patches, feedback, bug reports and so on. Thank you! As usual, all downloads can be found on Releases. Geany-Plugins 1.27 released! Posted on Mar. 13, 2016 at 02:32 PM Permanent link We are happy to announce a new version of the combined Geany-Plugins release -- right after Geany 1.27, Geany-Plugins 1.27 has been released. There have been a lot of changes, but here are some of the most prominent or noteworthy ones. Dropped build support via Waf -- please use Autotools instead Improve building on Windows a lot and so ship more plugins with installer for Windows New plugin LineOperations Debugger: Fix many memory leaks and potential crashes Debugger: Fix handling of non-ASCII characters in file names Debugger: Speed up stack trace display on large traces Debugger: Report the signal name when the process received one GeanyPy: Add keybinding support for Python plugins GeniusPaste: Make pastebins configurable via configuration files, adding support for user-defined pastebins GeniusPaste: Add configurations for fpaste.org and paste.debian.net ProjectOrganizer: Use the term ""symbol"" instead of ""tag"" Spellcheck: Improve detection of English contractions and other use of single quotes i18n/l10n: Update of translations for de, fr, pt, ru A more complete list of changes can be found in the NEWS file. As usual, you can find source tarballs and Windows installer for the new release on plugins.geany.org. (news archive) Page History Page last modified on January 31, 2016, at 04:16 PM Recent Changes (All) | Admin Contents Copyright 2006-2012 Enrico Tröger, Matthew Brush, Colomban Wendling, Frank Lanitz, Nick Treleaven and Dominic Hopf Powered by PmWiki running the ""Light"" skin."	"null"	"null"	"A very small and fast IDE. or later."	"true"
"Editors"	"KDevelop"	"https://www.kdevelop.org/"	"The KDE IDE. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"null"	"null"	"null"	"Welcome to KDevelop.org | KDevelop Welcome to KDevelop.org   KDevelop is a free, open source IDE (Integrated Development Environment) for Linux, Solaris, FreeBSD, Mac OS X and other Unix flavors. It is a feature-full, plugin extensible IDE for C/C++ and other programming languages. It is based on KDevPlatform, and the KDE and Qt libraries and is under development since 1998. KDevPlatform is a free, open source set of libraries that can be used as a foundation for IDE-like programs. It is programing-language independent, and is planned to be used by programs like: KDevelop, Quanta, Kile, KTechLab ... etc. News KDevelop 4.7.3 Release Hello! I have the pleasure to announce the new stable release of KDevelop 4.7.3. This is a bug fix release increasing the stability of our KDE 4 based branch. Please update to this version if you are currently using 4.7.2 or older. You can download the sources from the KDE mirrors at: http://download.kde.org/stable/kdevelop/4.7.3/src/ Many thanks to everyone involved in this new release! Comments: 9 Add new comment KDevelop 5.0 Beta 2 Release Three months after the first KDevelop 5.0 Beta release, I have the pleasure to announce our second beta release! We have worked hard on improving the stability and performance of our new KDevelop 5.0 based on Qt 5 and KDE Frameworks 5. We also continued to port many features from our old C++ language support to the new Clang-based C/C++ plugin, which is still an ongoing effort. Comments: 28 Add new comment kdev-python 1.7.3-py3 released Due to a regression in kdev-python 1.7.2-py3 related to module search paths, I have prepared a new release which fixes this issue. All users of the 1.7-py3 series, especially the 1.7.2-py3 version are urged to upgrade as soon as possible. The issue only affects the Python 3 series, for Python 2 kdev-python 1.7.2 is still the recommended and up-to-date release. Download You can download the tarball from http://download.kde.org/stable/kdevelop/kdev-python/1.7.3/src/kdev-python-v1.7.3-py3.tar.xz.mirrorlist. Comments: 6 Add new comment First Beta release of KDevelop 5.0.0 available After more than a year of continuous work by our community, I'm very pleased to finally announce the first beta release of KDevelop 5.0.0. This release is made up of hundreds of commits, and marks a huge step forward: We have ported our huge code base to Qt 5 and KDE frameworks 5 (KF5). We replaced our legacy C++ parser and semantic analysis plugin with a much more powerful one that is based on Clang from the LLVM project. We removed the hand-written CMake interpreter and now leverage meta data provided by upstream CMake itself. We finally integrated semantic language support for QML and JavaScript, as well as a project manager for QMake. Finally, we cleaned up many areas of our code base and improved the performance of some work flows significantly. Comments: 20 Add new comment KDevelop 4.7.2 Released Hey all, I'm happy to announce the availability of KDevelop 4.7.2. This is a bug fix release increasing the stability of our KDE 4 based branch. Please update to this version if you are currently using 4.7.1 or older. Download from: http://download.kde.org/stable/kdevelop/4.7.2/src/ SHA sums: SHA256Sum: 5801a38a9abfebead18b74c0a0f5a6d68118b297c96ef1e2f75c8bfae3463b19 kdevelop-4.7.2.tar.xz SHA256Sum: 2dff2f54f631296c87007be84a0dc439d328d473717577c0d1450a9fc7e6e828 kdevelop-php-docs-1.7.2.tar.xz Comments: 6 Add new comment KDevelop 4.7.1 Released Hello all! it's my pleasure to announce the immediate availability of KDevelop 4.7.1. This release contains many improvements and bug fixes - everyone is urged to upgrade. Distributions should already provide updated packages, otherwise you can download via: kdevplatform 1.7.1 kdevelop 4.7.1 kdev-python 1.7.1-py3 kdev-python 1.7.1-py2 kdev-php 1.7.1 kdev-php-docs 1.7.1 Thanks to all contributors, users and bug reporters for making this release possible! Add new comment KDevelop 4.7.0 Released Today, the KDevelop team is proud to announce the final release of KDevelop 4.7.0. It is, again, a huge step forwards compared to the last release in terms of stability, performance and polishedness. This release is special, as it marks the end of the KDE4 era for us. As such, KDevelop 4.7.0 comes with a long-term stability guarantee. We will continue to improve it over the coming years, but will refrain from adding new features. For that, we have the upcoming KDevelop 5, based on KDE frameworks 5 and Qt 5, which our team is currently busy working on. See below for more on that topic. Important KDevelop 4.7.0 Changes This new release of KDevelop comes with many important changes that should ensure it will stay usable for the foreseeable future. The CMake support was improved and extended to ensure that all idioms needed for KF5 development are available. The unit test support UI was polished and several bugs fixed. In the same direction, some noteworthy issues with the QtHelp integration were addressed. KDevelop's PHP language support now handles namespaces better and can understand traits aliases. Furthermore, some first fruits of the Google summer of code projects are included in this release. These changes pave the path toward better support for cross compile toolchains. Feature-wise, KDevelop now officially supports the Bazaar (bzr) version control system. On the performance front, it was possible to greatly reduce the memory footprint when loading large projects with several thousand files in KDevelop. Additionally, the startup should now be much faster. Comments: 14 Add new comment KDevelop master now depends on KDE Frameworks 5! Good news everyone! Our master branches are now officially depending on KDE Frameworks 5 and thus also Qt 5. People who build KDevelop regularly from the git master branches are suggested to switch to the stable 4.7/1.7 branches for the short term. The release of the final KDevelop 4.7.0 will be announced in the next days. This will be the last KDE4 based feature release of KDevelop. All future development will be targeted at the new Qt5 version. Add new comment KDevelop 4.7.0 Beta 1 Released Finally, after months of work, the KDevelop team is happy to release a first beta of the 4.7 version. It comes packed with new features, lots of bug fixes as well as many performance improvements. Comments: 1 Add new comment KDevelop 4.6.0 Final Released We are happy to announce the immediate availability of KDevelop 4.6.0! It adds more than a thousand commits worth of bug fixes, performance improvements and new features. KDevelop aims to create an IDE which doesn't get into your way and nevertheless provides a powerful and versatile set of tools for software development. Support for C++ and CMake are KDevelop's most prominent and widely used features, but the 4.6.0 release -- among other things -- also continues to improve the language support for PHP and Python. Comments: 16 Add new comment Developer Blogs Randa sprint wrap-up and considerations on packaging complex applications with AppImage by Sven Brauch on 06/20/2016 - 23:22 On Sunday, this year’s KDE sprint in Randa, Switzerland came to an end and I am now back home. It was a productive and fun week, as always when meeting the other KDE folks. Navigation widget in KDevelop with proper spacing and margins I spent a lot of time on polishing things and fixing small issues mostly in KDevelop, such as: reduce flickering of the completion widget in kdevelop fix various cases where KDevelop’s navigation widget (see above) would have weirdly large spacing in between or at the end fix kdev-... KDevelop 5.0 standalone executable for Linux by Sven Brauch on 06/16/2016 - 16:58 I am currently at the KDE sprint in Randa, Switzerland. There are about 40 nice people here, working on making KDE software awesome. This year’s focus is on deploying our software more nicely — on Windows and OS X, but on Linux as well. The landscape around our sprint location Especially for user-faced applications like KDevelop, it really makes a big difference whether you use today’s version, or the one from two years ago. Many people run quite old Linux distributions, which do not provide up-to-date packages for KDevelop. Another situation where it can be... Working on KDevelop and KDE on Windows in Randa by Kevin Funk on 06/13/2016 - 19:30 Right now, around 40 developers are working together on bringing KDE to other platforms in Randa (Switzerland) for an entire week. I just arrived Sunday evening, and we immediately started with discussions around KDE on different platforms. Not much coding has happened yesterday evening yet, but I at least managed to work-around a compiler bug of GCC 4.8 showing up in the KDevelop code base. My plans for this week are as follows: Preparing the KDevelop 5.0 release (fixing... Sitemap   If there are any problems with the website, please contact the webmaster. Donate Support us with a donation: € Donate The money is used to fund our annual development sprints and travel costs to conferences. More information and other ways to donate Download Latest release: KDevelop 4.7.3 Jan 31, 2016 (KDE 4.7 or higher) Experimental release: KDevelop 5.0 Beta 2 Jan 31, 2016 (Qt 5.4 and KF 5.3 or higher) Legacy releases: KDevelop 4.4.1 Aug 11, 2012 (KDE 4.5)KDevelop 4.1.2 Jan 14, 2011 (KDE 4.4) More: Latest sources from Git Support Learn to use KDevelop: User Manual F.A.Q., Tips & Tricks Ask Questions: Forum, Mailing Lists Report Bugs: Bugs & Wishes Contribute Programming Join Us! Translating translate KDevelop & plugins Documentation write documentation Recent Commits KDevelop 15 Jul 17:32 - Improve gdb plugin unit tests by 7437103@gmail.com (Peifeng Yu) 14 Jul 22:18 - Cleanup MIDebugger output signals by 7437103@gmail.com (Peifeng Yu) 14 Jul 20:16 - Make compile by kfunk@kde.org (Kevin Funk) 14 Jul 18:34 - support -iframework and -F header search path options by rjvbertin@gmail.com (René J.V. Bertin) 13 Jul 19:06 - Merge remote-tracking branch 'origin/5.0' by kfunk@kde.org (Kevin Funk) 13 Jul 18:49 - test_files: Fix dynamicObjectProperties.2.qml test by kfunk@kde.org (Kevin Funk) KDevPlatform 14 Jul 17:50 - KDevPlatform changes for supporting the -iframework and -F header search path by rjvbertin@gmail.com (René J.V. Bertin) 14 Jul 11:22 - removes a link command from the toplevel CMakeLists.txt that was by rjvbertin@gmail.com (René J.V. Bertin) 14 Jul 11:07 - [OS X] Show job progress in the Dock tile. by rjvbertin@gmail.com (René J.V. Bertin) 13 Jul 19:06 - Merge remote-tracking branch 'origin/5.0' by kfunk@kde.org (Kevin Funk) Documentation User Manual FAQ Tips and Tricks Wiki Development Development Portal KDevelop Source Code How to Compile Contribute Community Credits Mailing Lists KDevelop KDE Development Environment Search this site: News Screenshots"	"null"	"null"	"The KDE IDE. only."	"true"
"Editors"	"Qt Creator"	"https://www.qt.io/ide/"	"A cross-platform IDE written with C++ and Qt, part of the Qt SDK. Supports Clang Code Model. only."	"null"	"null"	"null"	"GNU GPL3 with Qt exception"	"https://github.com/qtproject/qt-creator/blob/master/LICENSE.GPL3-EXCEPT"	"null"	"null"	"null"	"null"	"null"	"Qt - Product | The IDE We bake cookies in your browser for a better experience. Using this site means that you consent. Read More Menu Blog Partners Company Investors Sign in Search Download Create Applications Build Devices Developers Sign in The IDE Qt Creator   Start for Free Fully-stocked cross-platform integrated development environment for easy creation of connected devices, UIs and applications. Beyond the Code Design and Create We believe that delivering connected devices, UIs and applications that meet and exceed end user demands takes more than just clean code. You can’t live on intuitive and comprehensive APIs alone. We want you to be able to not only code, but to also design and create. You’ve surely heard us say “code less, create more”? Well, this is where “create” comes into play. Cross-platform Qt Creator IDE Whether you are creating a mobile app, desktop application or a connected embedded device, Qt Creator is the cross-platform IDE that makes application and UI development a breeze. Since time-to-market is key, the IDE includes productivity tools that speed up your development time. The Tools Create visual appeal that speaks to your end users. Our integrated UI design tools help you design UIs using Qt Widgets with Qt Designer, and smooth animated UIs with Qt Quick Designer. Qt also comes with stand-alone tools: Expand your global market with Qt Linguist, which speeds the translation and internationalization of your applications. Give your end users the help and documentation they need with Qt Assistant, which is a configurable and redistributable documentation reader In case you are more comfortable with Visual Studio we have an add-in for you. However, we still think you should give Qt Creator a try…of course Not Forgetting The Code Sophisticated Code Editor Support for editing C++ and QML context-sensitive help, code completion, navigation and more. Version Control Integration with most popular version control systems Project & Build Management All the necessary files are generated including support for importing existing projects or creating one from scratch. Desktop to Embedded Multiscreen and multi-platform support for quickly switching between build targets. Get Started for Free Download Now Download Qt for Device Creation Qt for Application Development Buy Qt Terms & Conditions Licensing Build with Qt Device Creation Application Development Automotive UIs Resource Center Built with Qt Services Qt Training Partner Directory Consultancy Services Qt for Educational Use Developers Documentation Development Tools Wiki Forums Contribute to Qt Company About Us Events News Careers Contact Us Qt Merchandise Sign In Feedback © 2016 The Qt Company Follow @qtproject"	"null"	"null"	"A cross-platform IDE written with C++ and Qt, part of the Qt SDK. Supports Clang Code Model. only."	"true"
"Environments"	"Cygwin"	"https://cygwin.com/"	"Designed to emulate a POSIX-compatible environment extensively under Windows.."	"null"	"null"	"null"	"Various licenses, all free"	"https://cygwin.com/licensing.html"	"null"	"null"	"null"	"null"	"null"	"Cygwin Cygwin    Install Cygwin    Update Cygwin    Search Packages    Licensing Terms Cygwin/X Community    Reporting Problems    Mailing Lists    Newsgroups    IRC channels    Gold Stars    Mirror Sites    Donations Documentation    FAQ    User's Guide    API Reference    Acronyms Contributing    Snapshots    Source in Git    Cygwin Packages Related Sites Cygwin Get that Linux feeling - on Windows This is the home of the Cygwin project What... ...is it? Cygwin is: a large collection of GNU and Open Source tools which provide functionality similar to a Linux distribution on Windows. a DLL (cygwin1.dll) which provides substantial POSIX API functionality. ...isn't it? Cygwin is not: a way to run native Linux apps on Windows. You must rebuild your application from source if you want it to run on Windows. a way to magically make native Windows apps aware of UNIX® functionality like signals, ptys, etc. Again, you need to build your apps from source if you want to take advantage of Cygwin functionality. The Cygwin DLL currently works with all recent, commercially released x86 32 bit and 64 bit versions of Windows, starting with Windows XP SP3. NOTE: The most recent Cygwin version 2.5.2 will be the last version supporting Windows XP and Server 2003. For more information see the FAQ. Current Cygwin DLL version The most recent version of the Cygwin DLL is 2.5.2. Install it by running setup-x86.exe (32-bit installation) or setup-x86_64.exe (64-bit installation). Use the setup program to perform a fresh install or to update an existing installation. Note that individual packages in the distribution are updated separately from the DLL so the Cygwin DLL version is not useful as a general Cygwin distribution release number. Support for Cygwin For all Cygwin-related questions and observations, please check the resources available at this site, such as the FAQ, the User's Guide and the mailing list archives. If you've exhausted these resources then please send email to an appropriate mailing list. This includes observations about web pages, setup questions, questions about where to find things, questions about why things are done a certain way, questions about the color preferences of Cygwin developers, questions about the meaning of the number 42, etc. Please send notification of technical problems (bad html, broken links) concerning these web pages to the Cygwin mailing list. Please do not send personal email with ""quick questions"" to individual Cygwin contributors. The Cygwin mailing lists are the places for all questions. Really. I mean it. The Cygwin DLL and utilities are Copyright © Cygwin authors. Other packages have other copyrights. NOT SEND EMAIL TO THIS ADDRESS: aaaspam@sourceware.org IT IS HERE ONLY TO COLLECT SPAM. IF YOU SEND EMAIL TO THIS ADDRESS YOU WILL BE AUTOMATICALLY BLOCKED."	"null"	"null"	"Designed to emulate a POSIX-compatible environment extensively under Windows.."	"true"
"Environments"	"MinGW-w64"	"http://mingw-w64.yaxm.org/doku.php/start"	"A minimalist environment for C development on Windows with 64 bit support.."	"null"	"null"	"null"	"Various licenses, all free"	"http://mingw.org/license"	"null"	"null"	"null"	"null"	"null"	"Mingw-w64 - GCC for Windows 64 & 32 bits [mingw-w64] mingw-w64 GCC for Windows 64 & 32 bits Sources • Documentation • Support • Contribute • Donate Table of Contents Mingw-w64 Version 4.0 has been released Headers, Libraries and Runtime Tools Friend projects Some Projects using Mingw-w64 Most Recent Activity Mingw-w64 Mingw-w64 is an advancement of the original mingw.org project, created to support the GCC compiler on Windows systems. It has forked it in 2007 in order to provide support for 64 bits and new APIs. It has since then gained widespread use and distribution. The development and community are very active and welcoming with new contributors every month and simple installers. Version 4.0 has been released 32bit ARM thumb software math (Thanks to André Hentschel!). New ftw() support for gcc-5.x support. Experimental printf changes - Ability to print 128bit integers (%I128*) and Decimal Floats (%H, %D), disabled by default. Build the CRT with —-enable-experimental to use. Updated OpenGL 4.5 headers. Better DirectX 11 support. Better Windows 7, 8/8.1 API support. You can also look at the full list of versions. Headers, Libraries and Runtime More than a million lines of headers are provided, not counting generated ones, and regularly expanded to track new Windows APIs. Everything needed for linking and running your code on Windows. Winpthreads, a pthreads library for C++11 threading support and simple integration with existing project. Winstorecompat, a work-in-progress convenience library that eases conformance with the Windows Store. Better-conforming and faster math support compared to Visual Studio's. Tools gendef: generate Visual Studio .def files from .dll files. genidl: generate .idl files from .dll files. widl: compile .idl files. Friend projects Mingw-w64 interacts a lot with other projects in order to help everyone move forward. Contributions have been going to and coming from these projects: Cygwin ReactOS Wine Some Projects using Mingw-w64 Fedora cross-compiler Npackd OpenSUSE Win-builds Code::Blocks Ecere SDK GCC: The GNU Compiler Collection GDB: The GNU Project Debugger GNU Binutils ManKai Common Lisp OCaml OpenLisp Perl (5.12.0 and later) PToolsWin Strawberry Perl (bundles C toolchains) The R Project for Statistical Computing Barchart-UDT Blender Boost Botan Ceemple DAE Tools devkitPro Disk Based HashTables Ekiga Emerge Desktop Enlightenment Factor FFmpeg FLTK Freecell Solver Freeverb3 GIMP GNU SASL GnuTLS GraphicsMagick GTK+ Hexen II: Hammer of Thyrion iAuxSoft ImageMagick JPen KDE Software Collection libav LibreOffice libsndfile libvirt libvpx Libxml2 MAME (Yes, the arcade emulator!) mCtrl mpg123 MPIR MS MPI (repackaged) MS MPI OpenFOAM OpenSC OpenSSL OpenTURNS PostgreSQL pthreads Qt QuakeSpasm ReMooD SBC Archiver Smart Image Denoiser smartmontools strongSwan Tomahawk Player VideoLAN VLC VSXu Woo wxPerl PPMs wxWidgets YafaRay zlib QEMU Most Recent Activity Page Tools Show pagesource Old revisions Backlinks Back to top [ Back to top | Sitemap ] [ Login ] Except where otherwise noted, content on this wiki is licensed under the following license: CC Attribution-Share Alike 3.0 Unported"	"null"	"null"	"A minimalist environment for C development on Windows with 64 bit support.."	"true"
"Frameworks"	"APR"	"http://apr.apache.org/"	"Apache Portable Runtime; another library of cross-platform utility functions.."	"null"	"null"	"null"	"Apache2.0"	"http://directory.fsf.org/wiki/License:Apache2.0"	"null"	"null"	"null"	"null"	"null"	"Welcome! - The Apache Portable Runtime Project Get Involved Subversion Mailing Lists Build on Win32 Build on Unix Download! from a mirror APR Docs Version 1.5 Version 1.6 (dev preview) Trunk APR 2.0 (dev preview) APR-util Docs Version 1.5 Trunk APR 2.0 (dev preview) APR-iconv Docs Version 1.2 Trunk (dev preview) Guidelines Project Guidelines Contributing Version Numbers Miscellaneous License Security Reports Projects using APR Sponsors Sponsorship Welcome The mission of the Apache Portable Runtime (APR) project is to create and maintain software libraries that provide a predictable and consistent interface to underlying platform-specific implementations. The primary goal is to provide an API to which software developers may code and be assured of predictable if not identical behaviour regardless of the platform on which their software is built, relieving them of the need to code special-case conditions to work around or take advantage of platform-specific deficiencies or features. Recommended releases The recommended releases of the several Apache Portable Runtime libraries are APR 1.5.2, released April 29, 2015 APR-util 1.5.4, released September 22, 2014 APR-iconv 1.2.1, released November 26, 2007 Apache Portable Runtime 1.5.2 Released The Apache Software Foundation and the Apache Portable Runtime Project are proud to announce the General Availability of version 1.5.2 of the Apache Portable Runtime library. APR 1.5.2 resolves an important issue on the Windows platform that can result in vulnerabilities in APR applications which use APR pipes; this issue is tracked by CVE-2015-1829. APR 1.5.2 fixes a number of additional run-time and build-time bugs affecting multiple platforms. Users of previous versions are encouraged to update to this release. For further details of this release, see the official announcement as well as the CHANGES-APR-1.5 file. Download Programmer's Manual: APR Apache Portable Runtime Utility 1.5.4 Released The Apache Software Foundation and the Apache Portable Runtime Project are proud to announce the General Availability of version 1.5.4 of the APR Apache Portable Runtime Utility library. APR-util 1.5.4 is a bug fix release. For further details of this release, see the official announcement as well as the CHANGES-APR-UTIL-1.5 file. Download Programmer's Manual: APR-util Projects Using APR After several years of development, APR is beginning to see use outside of the Apache HTTP Server. To encourage more people to investigate APR for their projects, here are a list of both Open Source and Commercial projects that are currently using APR. If you are using APR, and would like your project recognized, please send e-mail to the developer's mailing list. APR subprojects The following is a list of supported development projects under the APR Project. All of the development happens on the indicated mailing lists. See mailing lists to learn how to take part in these discussions. Or, check the archives. apr - a portable runtime library Source: apr Mailing list: dev@apr.apache.org Releases: apr releases API Documentation: apr docs (current stable branch), Using APR Pools Tutorial: An Introduction to APR covers the structure and basic concepts. See sample code. Test Coverage: apr test coverage apr-util - a companion library to APR Source: apr-util Mailing list: dev@apr.apache.org Releases: apr-util releases API Documentation: apr-util docs (current stable branch) apr-iconv - a portable implementation of the iconv() library Source: apr-iconv Releases: apr-iconv releases Mailing list: dev@apr.apache.org API Documentation: apr-iconv docs (current stable branch) How to start developing with APR We hope this website starts you in the right direction. Please read the docs and tutorials for the project you are interested in. If you have suggestions of any sort, please feel free to send us an email at dev@apr.apache.org! Copyright © 2008-2016, The Apache Software Foundation"	"null"	"null"	"Apache Portable Runtime; another library of cross-platform utility functions.."	"true"
"Frameworks"	"C Algorithms"	"https://github.com/fragglet/c-algorithms"	"A collection of common algorithms and data structures for C.."	"null"	"null"	"null"	"ISC"	"http://directory.fsf.org/wiki/License:ISC"	"null"	"null"	"574"	"73"	"174"	"GitHub - fragglet/c-algorithms: A library of common data structures and algorithms written in C. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 73 Star 574 Fork 174 fragglet/c-algorithms Code Issues 3 Pull requests 0 Pulse Graphs A library of common data structures and algorithms written in C. https://fragglet.github.io/c-algorithms/ 260 commits 2 branches 3 releases 5 contributors C 97.4% C++ 1.1% Other 1.5% C C++ Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags gh-pages master Nothing to show c-algorithms-1.2.0 c-algorithms-1.1.0 c-algorithms-1.0.0 Nothing to show New pull request Latest commit 5b0555f Jul 14, 2016 fragglet committed on GitHub Merge pull request #10 from waldyrious/patch-1 … Add license title Permalink Failed to load latest commit information. doc Remove trailing whitespace from files. Apr 26, 2015 src Fixed comments. Jul 14, 2016 test Moved SortedArray struct to .c file so it is hidden. Jun 6, 2016 tools Wipe out ChangeLog file. Apr 26, 2015 .gitignore Add a .gitignore file. Apr 26, 2015 .lvimrc Add local vim project settings file. Oct 1, 2008 .travis.yml Remove clang from Travis config. Apr 26, 2015 AUTHORS Update email address. Apr 25, 2015 COPYING Add license title Jun 30, 2016 ChangeLog Wipe out ChangeLog file. Apr 26, 2015 Makefile.am Install header files, pkgconfig .pc file Dec 13, 2005 NEWS Remove trailing whitespace from files. Apr 26, 2015 README Reword some of the text about the license. Sep 4, 2008 autogen.sh Generate a configuration file so that the compiler command line is not Nov 26, 2005 configure.ac Tweak configure.ac to work with older automake versions. Apr 26, 2015 libcalg-1.0.pc.in Install header files, pkgconfig .pc file Dec 13, 2005 README  C Algorithms  The C programming language includes a very limited standard library in comparison to other modern programming languages.  This is a collection of common Computer Science algorithms which may be used in C projects.  The code is licensed under the ISC license (a simplified version of the BSD license that is functionally identical).  As such, it may legitimately be reused in any project, whether Proprietary or Open Source.   Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/fragglet/c-algorithms"	"A collection of common algorithms and data structures for C.."	"true"
"Frameworks"	"CPL"	"http://www.eso.org/sci/software/cpl/"	"The Common Pipeline Library; a set of libraries designed to be a comprehensive, efficient and robust software toolkit. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"null"	"null"	"null"	"ESO - Common Pipeline Library     European Southern Observatory ESO — Reaching New Heights in Astronomy   Public Science User Portal Subscribe Contact Site Map   Go!  15 Jul 2016 Science Users Information > Science Software > Common Pipeline Library jump to navigation jump to content Science Users Information Observing Facilities La Silla Paranal Observatory Paranal Facilities La Silla Facilities APEX ALMA Observatory Future Facilities and Development E-ELT Science with E-ELT The Telescope Instrumentation Site Publications and Documents Gallery and Links Internal Access Instrumentation Development Instrumentation News Instruments Projects Detectors and Controllers Adaptive Optics Laser Guide Stars Integration and Cryo-vacuum Observing with ESO Telescopes Policies and Procedures Science Operations Policy Director's Discretionary Time Target of Opportunity Guaranteed Time Observations Public Surveys Publications with ESO Data Telescope Time Allocation Telescope Schedule Large Programmes ToO Programmes DDT Programmes GTO Programmes ESO/GTC Programmes Phase 1 Proposals Applying for Observing Time Proposal Package Proposal Categories Phase 2 Preparation The P2PP Tool Service Mode Guidelines Visitor Mode Guidelines Phase 3 Public Surveys Public Survey Projects Public Surveys Phase 2 Public Surveys Policies Protected Targets Useful Links Observing Tools and Services ESO ETC's Instrumental Characteristics Archives and Catalogues Ephemerides and Calculators Mag/Flux Converter Weather Images Astroclimatology Meteo Information Visiting Astronomers General Instructions Guidelines Paranal Guidelines La Silla End-of-Run Report Paranal End-of-Run Report La Silla Science Software Instrument Pipelines Common Pipeline Library Scisoft Collection ESO-MIDAS Eclipse Gasgano Reflex Data Handling and Products Quality Control and Data Processing Data Pipelines and Calibrations Trend Analysis Data Packages Science Data Products Forum Science Archive Facility Data Portal ESO Data Hubble Space Telescope Data Virtual Observatory Tools Catalogues, Plates and DSS Tools and Documentation Related External Services ESO and HST Image Galleries News and Updates ESO Data Access Policy Science Activities Science Staff Science in Garching Science Projects Staff Garching Scientific Visitors Science in Santiago Science Projects Staff Santiago/Chile Scientific Visitors Fellowships and Studentships VLT Commissioning FLAMES NACO PRIMA UVES XSHOOTER VLT/VLTI Science Verification AMBER CRIRES FLAMES FORS1 and ISAAC FORS2 and UVES HAWK-I MIDI NACO SINFONI VIMOS VISIR XSHOOTER MAD UT1 - Test Camera VISTA Science Verification APEX Science Verification APEX 2A LABOCA SHFI SABOCA Science and Technical Meetings Seminars in Garching Seminars in Santiago Conferences and Workshops IT Services Libraries Libraries Catalog Library Self Checkout Electronic Journals Electronic Books ESO Telescope Bibliography Information Resources Publications Science Announcements ESO Science Newsletter About the Newsletter Archive of the ESO Enews The Messenger ESO Annual Reports Job Opportunities CPL - The Common Pipeline Library Home Documentation Downloads Links Contact Latest News CPL version 7.0 has been released - (26-Feb-2016) CPL version 6.6.1 has been released - (22-Jul-2015) CPL version 6.6 has been released - (06-Mar-2015) CPL version 6.5.1 has been released - (01-Dec-2014) Overview The Common Pipeline Library (CPL) comprises a set of ISO-C libraries that provide a comprehensive, efficient and robust software toolkit to develop astronomical data-reduction tasks (known as ""recipes""). These data-reduction tasks can then be executed manually by a user, or can be triggered in an automated data-reduction framework (known as ""pipelines"") which are used at ESO to monitor the health status of VLT instruments, for quick-look data processing at the observatory, and the creation of data products available from the ESO archive facility. The Common Pipeline Library was developed to standardise the way VLT instrument pipelines are built, to shorten their development cycle and to ease their maintenance. However, it may be more generally applied to any similar application, and the details of the CPL code have been engineered in away to make the library portable and flexible, as well as minimising external dependencies. The CPL provides a host of functionality, presented in a clear, generic and uniform manner. Among its many features, the CPL offers: many useful low-level data types (images, tables, matrices, strings, property lists, ...), many fundamental statistic, arithmetic and conversion operations for these data types. medium-level data access methods (e.g. a data abstraction layer for FITS files), data table organisation and manipulation, keyword/value handling and management, a standardised application interface for pipeline recipes, and, support for dynamic loading of recipe modules. Despite the current bias towards instrument pipeline development, the library also provides a variety of general-purpose image- and signal-processing functions, making it an excellent framework for the creation of more generic data-handling packages. For more information about the CPL project, please see the web pages whose links appear at the top of this page.   Last Update: 25.02.16 © ESO Send us your comments! | Subscribe to Newsletter | Privacy Statement"	"null"	"null"	"The Common Pipeline Library; a set of libraries designed to be a comprehensive, efficient and robust software toolkit. only."	"true"
"Frameworks"	"EFL"	"https://www.enlightenment.org/?p=about%252Fefl"	"A large collection of useful data structures and functions. Various licenses, all free."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Enlightenment Main Main About Download Contact Docs News Devel Options Show pagesource Backlinks Media Manager Sitemap Login / Register EFL 1.17.2 and Enlightenment 0.21.0 are out - go to our Download page. Window Manager Enlightenment started as a project to build a Window Manager for X11. That was way back in 1996. It has grown much since. It still produces this Window Manager, but it has evolved to also cover Mobile, Wearable and TV UI needs for projects such as Tizen as well as traditional the “desktop” UI. We still push out releases, so see our download page for more details on the latest releases, or see our contribute page for source code repositories in their latest development state. It also is in the transition from X11 to Wayland. We are fully committed to moving to Wayland eventually as this is definitely the future of the graphical display layer on Linux. We still primarily support Linux for Enlightenment, but there is some effort (based on help and support from users and some developers) to support the BSDs. Libraries In the process of developing a Window Manager, A set of libraries were developed in order to achieve that goal. These libraries are known collectively as EFL. They cover a range of functionality from main-loop, to graphics, scene graphs, networking, widgets, data storage, IPC and much more. We now are starting to pull in bindings support directly into EFL. We are working on having bindings auto-generated for C++, Lua and Javascript (v8/node.js). We also would like to pull in our Python bindings in the future so we can support as many languages as possible and keep them up to date. For our libraries, our primary development environment is Linux, but we make an effort to support the BSDs as fully as possible, as well as OSX and Windows. Applications We eat our own dog food. We use our libraries not just to make Enlightenment but to also make other applications for regular every-day use. We make these applications available for free. We have some of the usual suspects like a terminal emulator, a video player, and even the start of an IDE. Even native Tizen applications use EFL for their development because we have focused on remaining lean and still featureful. Unlike many traditional toolkits, we have based ourselves around a scene graph from the ground up, making EFL very different in nature, yet allowing us to seamlessly switch from software rendering to OpenGL or any other mechanism that can be put in a render engine for the canvas scene graph engine we call Evas, as well as layer widgets and objects with alpha channels from the ground up and no special tricks. This is by no means a complete list of applications, and we are not done making more. We may not have started the traditional way, but are building our library over time, and Tizen has another library brewing over there as well."	"null"	"null"	"A large collection of useful data structures and functions. Various licenses, all free."	"true"
"Frameworks"	"GLib"	"https://wiki.gnome.org/Projects/GLib"	"A library of utility functions and structures, designed to be portable, efficient and powerful. only."	"null"	"null"	"null"	"GNU LGPL2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"null"	"null"	"null"	"Projects/GLib - GNOME Wiki! Projects/GLib Home RecentChanges Schedule Login GNOME.org GLib GLib provides the core application building blocks for libraries and applications written in C. It provides the core object system used in GNOME, the main loop implementation, and a large set of utility functions for strings and common data structures. Getting in Touch IRC channel Mailing list File a bug Development Resources Bugzilla product Git: git clone git://git.gnome.org/glib Browse source code Tarballs Reference Manual Roadmap Thorns! Supported platforms Toolchain requirements Components GApplication GVariant GNotification GLib testing framework Unicode support Notes D-Bus version 2 Projects/GLib (last edited 2016-01-29 08:30:26 by SébastienWilmet)     Search: Copyright © 2005 - 2015 The GNOME Project. Hosted by Red Hat."	"null"	"null"	"A library of utility functions and structures, designed to be portable, efficient and powerful. only."	"true"
"Frameworks"	"GIO"	"https://developer.gnome.org/gio/"	"A modern and easy-to-use VFS API. only."	"null"	"null"	"null"	"GNU LGPL2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"null"	"null"	"null"	"GIO Reference Manual -  	  GNOME Developer Center Go to page content Go to main menu Go to the search field GNOME.org About Users Administrators Developers Search: GIO Reference Manual GIO provides a modern and easy-to-use VFS API. It provides a file system abstraction which allows applications to access local and remote files with a single consistent API. Available Versions: 2.26.1 2.28.7 2.30.3 2.32.4 2.34.3 2.36.4 2.38.2 2.40.2 2.42.2 2.44.1 2.46.2 2.48.1 2.49.2 (development version) Downloads gio-html-2.49.2.tar.gz gio-html-2.48.1.tar.gz gio-html-2.46.2.tar.gz gio-html-2.44.1.tar.gz gio-html-2.42.2.tar.gz gio-html-2.40.2.tar.gz gio-html-2.38.2.tar.gz gio-html-2.36.4.tar.gz gio-html-2.34.3.tar.gz gio-html-2.32.4.tar.gz gio-html-2.30.3.tar.gz gio-html-2.28.7.tar.gz gio-html-2.26.1.tar.gz Note the API references are usually available as packages in the distributions and visible via the Devhelp tool. This documentation is generated from the following tarball: glib     The GNOME Project About Us Get Involved Teams The GNOME Foundation Support GNOME Contact Resources Documentation Wiki Mailing Lists IRC Channels Bug Tracker Development Code Build Tool News Latest Release Planet GNOME Development News Identi.ca Twitter This website is available in many languages Switch Language Copyright © 2005‒2014 The GNOME Project Optimised for standards. Hosted by Red Hat."	"null"	"null"	"A modern and easy-to-use VFS API. only."	"true"
"Frameworks"	"GObject"	"https://developer.gnome.org/gobject/stable/"	"An object-oriented system and object model for C. only."	"null"	"null"	"null"	"GNU LGPL2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"null"	"null"	"null"	"GObject Reference Manual: GObject Reference Manual Go to page content Go to main menu Go to the search field GNOME.org About Users Administrators Developers Search: GObject Reference Manual for GObject 2.48.1 The latest version of this documentation can be found on-line at https://developer.gnome.org/gobject/unstable/. Introduction I. Concepts Background Data types and programming Exporting a C API The GLib Dynamic Type System Copy functions Conventions Non-instantiable non-classed fundamental types Instantiable classed types: objects Initialization and Destruction Non-instantiable classed types: interfaces Interface Initialization Interface Destruction The GObject base class Object instantiation Object memory management Reference count Weak References Reference counts and cycles Object properties Accessing multiple properties at once The GObject messaging system Closures C Closures Non-C closures (for the fearless) Signals Signal registration Signal connection Signal emission The detail argument II. API Reference Type Information — The GLib Runtime type identification and management system GTypePlugin — An interface for dynamically loadable types GTypeModule — Type loading modules GObject — The base object type Enumeration and Flag Types — Enumeration and flags types Boxed Types — A mechanism to wrap opaque C structures registered by the type system Generic values — A polymorphic type that can hold values of any other type Parameters and Values — Standard Parameter and Value Types GParamSpec — Metadata for parameter specifications Varargs Value Collection — Converting varargs to generic values Signals — A means for customization of object behaviour and a general purpose notification mechanism Closures — Functions as first-class objects Value arrays — A container structure to maintain an array of generic values GBinding — Bind two object properties III. Tools Reference glib-mkenums — C language enum description generation utility glib-genmarshal — C code marshaller generation utility for GLib closures gobject-query — display a tree of types IV. Tutorial How to define and implement a new GObject Boilerplate header code Boilerplate code Object construction Object destruction Object methods Non-virtual public methods Virtual public methods Virtual private Methods Chaining up How to define and implement interfaces Defining interfaces Implementing interfaces Interface definition prerequisites Interface properties Overriding interface methods How to create and use signals Simple use of signals V. Related Tools Vala GObject builder Graphical inspection of GObjects Debugging reference count problems Writing API docs Index Index of deprecated symbols Index of new symbols in 2.2 Index of new symbols in 2.4 Index of new symbols in 2.6 Index of new symbols in 2.8 Index of new symbols in 2.10 Index of new symbols in 2.12 Index of new symbols in 2.14 Index of new symbols in 2.18 Index of new symbols in 2.22 Index of new symbols in 2.24 Index of new symbols in 2.26 Index of new symbols in 2.28 Index of new symbols in 2.30 Index of new symbols in 2.32 Index of new symbols in 2.34 Index of new symbols in 2.36 Index of new symbols in 2.38 Index of new symbols in 2.40 Index of new symbols in 2.42 Index of new symbols in 2.44 Index of new symbols in 2.46 Annotation Glossary Generated by GTK-Doc V1.25.1     The GNOME Project About Us Get Involved Teams The GNOME Foundation Support GNOME Contact Resources Documentation Wiki Mailing Lists IRC Channels Bug Tracker Development Code Build Tool News Latest Release Planet GNOME Development News Identi.ca Twitter This website is available in many languages Switch Language Copyright © 2005‒2014 The GNOME Project Optimised for standards. Hosted by Red Hat."	"null"	"null"	"An object-oriented system and object model for C. only."	"true"
"Frameworks"	"libnih"	"https://github.com/keybuk/libnih"	"A lightweight library of C functions and structures. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"28"	"11"	"18"	"GitHub - keybuk/libnih: NIH Utility Library Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 11 Star 28 Fork 18 keybuk/libnih Code Issues 2 Pull requests 6 Pulse Graphs NIH Utility Library 1,092 commits 1 branch 29 releases Fetching contributors C 99.8% Other 0.2% C Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show upstart-0.6.3 upstart-0.6.2 upstart-0.6.1 upstart-0.6.0 upstart-0.5.2 upstart-0.5.1 upstart-0.5.0 upstart-0.3.9 upstart-0.3.8 upstart-0.3.7 upstart-0.3.5 upstart-0.3.2 upstart-0.3.0 upstart-0.2.7 upstart-0.2.6 upstart-0.2.5 upstart-0.2.1 upstart-0.2.0 upstart-0.1.1 upstart-0.1.0 1.0.3 1.0.2 1.0.1 1.0.0 0.3.2 0.3.1 0.3.0 0.2.0 0.1.0 Nothing to show New pull request Latest commit ecf8f37 Dec 9, 2013 keybuk Merge pull request #12 from xnox/subdir-objects … Enable automake's subdif-objects option. Permalink Failed to load latest commit information. m4 * m4/libnih.m4 (NIH_WITH_LOCAL_LIBNIH): Add macro cribbed from the Apr 24, 2010 nih-dbus-tool nih-dbus libnih-dbus requires dbus-1 Nov 20, 2013 nih Fix formatting as per review. Oct 31, 2013 po * NEWS: Release 1.0.3 Dec 23, 2010 .gitignore AUTHORS * AUTHORS: Mention the ChangeLog file. Sep 7, 2006 COPYING * COPYING: Change licence to version 2 of the GNU GPL. Jun 23, 2009 ChangeLog Fallback to lstat, if the non-portable dirent.d_type is not available. Oct 31, 2013 HACKING * configure.ac (AC_PRERQ): Update to 2.62 Nov 21, 2009 Makefile.am * Makefile.am: Always build libnih-dbus and nih-dbus-tool Nov 21, 2009 NEWS * configure.ac: Bump version to 1.0.4 Dec 23, 2010 README * README: Remove the usage instructions, since this is going to Nov 21, 2009 TODO * TODO: Update. Nov 28, 2009 configure.ac README libnih is a light-weight ""standard library"" of C functions to ease the development of other libraries and applications.  Its goals are:   * despite its name, to _not_ reimplement anything found in the    standard C library or any library normally found in /lib;   * use standard C types and conventions where appropriate;   * have a simple and consistent programming interface;   * be useful to library developers without needing to be exposed in    the library's API;   * not hide implementation details or structure contents, we're all    adults after all.   Dependencies ------------  The D-Bus messaging system is required to build the libnih-dbus library and nih-dbus-tool utility.  In order to query the availability of the external library, the pkg-config tool is used; and in order to parse D-Bus introspection data, the expat XML parsing library will be used.  The recommended versions are:  	* pkg-config 0.22 	* D-Bus 1.2.16 	* expat 2.0.0  These should all be available from the current release of any modern Linux distribution.  For detailed compilation and installation instructions see the INSTALL file.  If you've checked libnih out from revision control, or want to hack on libnih, see the HACKING file.   Cross-compiling ---------------  libnih uses the nih-dbus-tool utility it builds during its own build process to generate further sources to be built.  When cross-compiling this will fail because the built nih-dbus-tool will most likely not be able to run on the build architecture.  This can be solved by building and installing nih-dbus-tool for the build architecture first, then when performing the cross-compile, the installed copy will be used instead.  If installed into a common system directory, this is automatic; if not, you can pass the path of the nih-dbus-tool binary to the configure script, e.g.:  	./configure --build=i486-linux-gnu --host=gnueabi-linux-arm \ 		NIH_DBUS_TOOL=/cross/bin/nih-dbus-tool  Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/keybuk/libnih"	"A lightweight library of C functions and structures. only."	"true"
"Frameworks"	"libU"	"http://www.koanlogic.com/libu/"	"A small library of basic utilities, including memory allocation, string manipulation and logging.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"124"	"16"	"31"	"GitHub - koanlogic/libu: LibU is a multiplatform utility library written in C, with APIs for handling memory allocation, networking and URI parsing, string manipulation, debugging, and logging in a very compact way, plus many other miscellaneous tasks Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 16 Star 124 Fork 31 koanlogic/libu Code Issues 0 Pull requests 0 Wiki Pulse Graphs LibU is a multiplatform utility library written in C, with APIs for handling memory allocation, networking and URI parsing, string manipulation, debugging, and logging in a very compact way, plus many other miscellaneous tasks http://koanlogic.com/libu 822 commits 2 branches 26 releases Fetching contributors C 98.6% Shell 1.4% C Shell Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags LIBU_1_5_MAINT_BRANCH master Nothing to show WI_AUTH_REL_1_2_0 REL_0_0 REL_BCA_1_0 LIBU_1_0_0 LIBU_REL_2_2_0 LIBU_REL_2_1_0 LIBU_REL_2_0_0 LIBU_REL_1_4_2 LIBU_REL_1_4_1 LIBU_REL_1_4_0 LIBU_REL_1_3_1 LIBU_REL_1_3_0 LIBU_REL_1_2_1 LIBU_REL_1_2_0 LIBU_REL_1_1_0 LIBU_REL_0_5_0 LIBU_REL_0_2_0 LIB_REL_0_2_0 KLONE_REL_2_2_0 KLONE_REL_2_1_0 KLONE_REL_2_0_2 KLONE_REL_1_1_1 KLONE_REL_1_1_0 KLONE_REL_1_0_4 KLONE_REL_1_0_3 KLONE_REL_1_0_2 Nothing to show New pull request Latest commit d6d6c3a Apr 16, 2012 babongo [libu] fix inconsistency in u_string_detach_cstr Permalink Failed to load latest commit information. build [libu] boh! Mar 19, 2012 contrib [libu] xsl generated reports pass through the w3c validator Feb 26, 2010 doc automatically substitute version in libu.doxy Jan 23, 2012 example s/2011/2012 Jan 13, 2012 include [queue] avoid complaints about redefined macros Apr 10, 2012 pkg [libu] fix the fix! Jan 31, 2007 pkgs rel-git.sh: 2.2.0 Jan 22, 2012 srcs [libu] fix inconsistency in u_string_detach_cstr Apr 16, 2012 test [libu] fix inconsistency in u_string_detach_cstr Apr 16, 2012 ChangeLog [libu] fix inconsistency in u_string_detach_cstr Apr 16, 2012 INTERFACE_CHANGES [libu] --compat_1x and related stuff Jan 15, 2010 LICENSE s/2011/2012 Jan 13, 2012 Makefile [libu/klone] kl2 build fix (1st attempt) Jul 4, 2008 Makefile.dist [libu] missing doxy files in dist Mar 23, 2010 README make README version-independent Jan 23, 2012 TODO fix conditional include logics that enables unit test sandboxing Nov 23, 2010 VERSION [libu] boh! Mar 19, 2012 configure [libu] add #-escaping to doxy docs + fix possible makl regression in … Jan 31, 2012 configure.help [libu] json module integration (wip) May 27, 2010 README == MaKL is a Prerequisite ==  LibU needs http://koanlogic.com/makl to configure and build.   The following commands should be sufficient to get MaKL installed on any Linux  flavour or Darwin/MacOSX:  $ wget http://koanlogic.com/download/makl/makl-${VERSION}.tar.gz $ tar zxf makl-${VERSION}.tar.gz && cd makl-${VERSION} $ sh configure.sh $ su  Password: **** # make install  Should your platform be one of Solaris, OpenSolaris, FreeBSD, PC-BSD, OpenBSD, NetBSD, DragonflyBSD, Minix or Windows (MinGW or Gygwin) take a look at the  INSTALL file in the top-level MaKL sources directory to track down specific  variations on the theme.  == Download ==   Once MaKL is there, you can start downloading the package (always check the  official http://koanlogic.com/libu page for the latest version and related  ChangeLog) and tailor it to your specific needs:  $ wget http://koanlogic.com/download/libu/libu-${VERSION}.tar.gz $ tar zxf libu-${VERSION}.tar.gz && cd libu-${VERSION}   == Configure ==  E.g. should you need to change the default installation path (i.e. /usr/local), use:  $ makl-conf --prefix=""/my/install/base/dir""   Debug symbols and warnings from the compiler can be switched on via --enable_debug and --enable_warns (use --enable_icc_warns instead when  working with the Intel C compiler):  $ makl-conf --enable_debug --enable_warns   Code profiling using gprof(1) can be activated via --enable_profile, and, more generally, any compiler flag can be passed to the build stage in the  following way:  $ makl-conf --extra-cflags=""-Wformat -Wno-format-extra-args -Wformat-security -Wformat-nonliteral -Wformat=2""  The --extra-xxx=""val"" is indeed a powerful mechanism by which any Makefile  variable 'XXX' (uppercase!) can be given an additional value 'val': (ab)use  it to tweak LDFLAGS, SHLIB_LDFLAGS, etc. as needed.  Anyway if in doubt,  or in search for exotic features, type makl-conf -h to display the complete  list of options: it's likely that what you are trying to achieve is already  there.  By default LibU is compiled as static library, to also enable shared library  build, supply the --enable_shared flag.  == Pick Up What Needs to be Included ==  The default is to build all the modules, but you can disable the  inclusion of specific bits selectively using the following switches:     - --no_hmap: to disable the hmap module     - --no_config: to disable the config module     - --no_net: to disable the net module     - --no_env: to disable the env module     - --no_fs: to disable the fs module     - --no_pwd: to disable the pwd module     - --no_list: to disable the list module     - --no_array: to disable the array module     - --no_ringbuffer: to disable the rb module     - --no_pqueue: to disable the pq module     - --no_json: to disable the json module     - --no_bst: to disable the bst module  Also, some specific features regarding the networking code can be disabled at configuration:     - --no_ipv6: to disable IPv6 protocol support     - --no_sctp: to disable SCTP protocol support     - --no_unixsock: to disable UNIX IPC support  If you need to enable compatibility with (some, not all) 1.X interfaces,  specify the --compat_1x command line switch.  == Build, Test and Install ==  When you are done with the configure step, you can build LibU bits and  optionally test them:  $ makl $ makl -C test   And finally install it:  $ su Password: **** # makl install   == Hello LibU ! ==  You now are ready to play with your first LibU program:  $ cat main.c #include <u/libu.h>  int facility = LOG_LOCAL0;  int main (void) {     u_con(""Hello LibU world !"");     return 0; }  Write a Makefile like the following:  $ cat Makefile include common.mk  PROG = hellolibu SRCS = main.c  LDADD += /path/to/install/prefix/lib/libu.a CFLAGS += -I/path/to/install/prefix/include  include prog.mk  Then type:  $ makl && ./hellolibu  and enjoy !  Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/koanlogic/libu"	"A small library of basic utilities, including memory allocation, string manipulation and logging.."	"true"
"Frameworks"	"PBL"	"http://www.mission-base.com/peter/source/"	"A large library of utilities, featuring data structures, among other things. or later (library), or later (test code)."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"null"	"null"	"null"	"Peter Graf's Free GPL Open Source Software Peter Graf's Free GPL Open Source Software PBL is now hosted on GitHub. The library PBL is published under The GNU Lesser General Public License as published by the Free Software Foundation; either version 2.1 of the License, or (at your option) any later version. The test cases, which are not directly part of the library, are published under the The GNU General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version. PBL - The Program Base Library PBL is an LGPL open source C library of functions that can be used in a C or C++ project. PBL is highly portable and compiles warning free on Linux gcc, MAC OS X and Windows Microsoft Visual C++ 2010 Express Edition. The code of the PBL library includes the following modules: PBL BASE - Some base functions, see pbl_* functions, PBL COLLECTION - An open source C implementation of a collection used by the list and set implementations. PBL LIST - An open source C implementation of array lists and linked lists similar to the Java List interface, see pblList* functions, pblArrayList: -- C array list, C-ArrayList, array list in C, ArrayList in C, List in C Open source C resizable-array implementation equivalent to the Java ArrayList class. Implements most optional list operations, and permits all elements, including NULL. In addition to implementing the List operations, this module provides methods to manipulate the size of the array that is used internally to store the list. The size, isEmpty, get, set, iterator, and listIterator operations run in constant time. The add operation runs in amortized constant time, that is, adding n elements requires O(n) time. All of the other operations run in linear time (roughly speaking). The constant factor is low compared to that for the LinkedList implementation. Each pblArrayList instance has a capacity. The capacity is the size of the array used to store the elements in the list. It is always at least as large as the list size. As elements are added to an ArrayList, its capacity grows automatically. The details of the growth policy are not specified beyond the fact that adding an element has constant amortized time cost. An application can increase the capacity of an ArrayList instance before adding a large number of elements using the ensureCapacity operation. This may reduce the amount of incremental reallocation. pblLinkedList: -- C linked list, C-LinkedList, linked list in C, LinkedList in C, List in C Open source C linked list implementation equivalent to the Java LinkedList class. Implements most optional list operations, and permits all elements (including null). In addition to implementing the List operations, this module provides uniformly named methods to get, remove and insert an element at the beginning and end of the list. These operations allow linked lists to be used as a stack, queue, or double-ended queue (deque). The module implements the Queue operations, providing first-in-first-out queue operations for add, poll, etc. Other stack and deque operations could be easily recast in terms of the standard list operations. All of the operations perform as could be expected for a doubly-linked list. Operations that index into the list will traverse the list from the beginning or the end, whichever is closer to the specified index. pblIterator: -- C list iterator, C-ListIterator, list iterator in C, ListIterator in C Open source C Iterator implementation equivalent to the Java ListIterator interface. An iterator for lists that allows the programmer to traverse the list in either direction, modify the list during iteration, and obtain the iterator's current position in the list. A ListIterator has no current element; its cursor position always lies between the element that would be returned by a call to previous() and the element that would be returned by a call to next(). In a list of length n, there are n+1 valid index values, from 0 to n, inclusive. Note that the remove() and set(Object) methods are not defined in terms of the cursor position; they are defined to operate on the last element returned by a call to next() or previous(). PBL Set - An open source C implementation of hash sets and tree sets similar to the Java Set interface, see pblSet* functions, pblHashSet: -- C hash set, C-HashSet, hash set in C, HashSet in C, Set in C Open source C resizable hash set implementation equivalent to the Java HashSet class. Hash sets make no guarantees as to the iteration order of the set; in particular, it does not guarantee that the order will remain constant over time. This module does not permit the NULL element. Hash sets offer constant time performance for the basic operations (add, remove, contains and size), assuming the hash function disperses the elements properly among the buckets. Iterating over this set requires time proportional to the sum of the HashSet instance's size (the number of elements) plus the ""capacity"" of the instance (the number of buckets). Thus, it's very important not to set the initial capacity too high (or the load factor too low) if iteration performance is important. pblTreeSet: -- C tree set, C-TreeSet, tree set in C, TreeSet in C, Set in C Open source C avl-tree-based balanced tree set implementation equivalent to the Java TreeSet class. Tree sets guarantees that the sorted set will be in ascending element order, sorted according to the natural order of the elements, or by the comparator provided. This implementation provides guaranteed log(n) time cost for the basic operations (add, remove and contains). PBL Map - An open source C implementation of hash maps and tree maps similar to the Java Map interface, see pblMap* functions, pblHashMap: -- C hash map, C-HashMap, hash map in C, HashMap in C, Map in C Open source C resizable hash map implementation equivalent to the Java HashMap class. Hash maps make no guarantees as to the iteration order of the set; in particular, it does not guarantee that the order will remain constant over time. Hash maps offer constant time performance for the basic operations (add, remove, contains and size), assuming the hash function disperses the elements properly among the buckets. Iterating over this map requires time proportional to the sum of the HashMap instance's size (the number of elements) plus the ""capacity"" of the instance (the number of buckets). Thus, it's very important not to set the initial capacity too high (or the load factor too low) if iteration performance is important. pblTreeMap: -- C tree map, C-TreeMap, tree map in C, TreeMap in C, Map in C Open source C avl-tree-based balanced tree map implementation equivalent to the Java TreeMap class. Tree maps guarantee that the sorted map will be in ascending element order, sorted according to the natural order of the elements, or by the comparator provided. This implementation provides guaranteed log(n) time cost for the basic operations (add, remove and contains). PBL HEAP -- Heap in C, C heap, heap in C, C-Heap, binary heap in C, binary min-max heap in C Open source C implementation of a binary heap. This heap orders elements according to a compare function specified. A heap does not permit null elements. PBL PRIORITY QUEUE -- PriorityQueue in C, C priority queue, priority queue in C, Heap in C, C-Heap, binary heap in C, binary max heap in C Open source C implementation of a priority queue based on a binary max-heap. This C implementation is similar to the Java PriorityQueue interface. This implementation provides O(log(n)) time for the insertion methods; O(log(n)) time for the removal methods; and constant time for the retrieval methods. PBL HASH: -- C hash table, C-HashTable An open source C memory hash table implementation, see pblHt* functions, Features random access lookups sequential access regression test frame PBL KEYFILE: -- C key file, C-KeyFile An open source C key file implementation, see pblKf* functions, Features ultra fast B* tree implementation for random lookups transaction handling sequential access methods embedable small footprint, < 35 Kb arbitrary size files, up to 4 terrabytes arbitrary number of records per file, up to 2 ^^ 48 records duplicate keys advanced key compression for minimal size B trees keylength up to 255 bytes regression test frame PBL ISAM: -- C isam file, C-IsamFile An open source C ISAM file implementation, see pblIsam* functions Features ultra fast B* tree implementation for random lookups transaction handling sequential access methods embedable small footprint, < 75 Kb arbitrary size files, up to 4 terrabytes arbitrary number of records per file, up to 2 ^^ 48 records duplicate keys and unique keys advanced key compression for minimal size index files keylength up to 255 bytes per index keylength up to 1024 per record regression test frame AvlDictionary<TKey,TValue>: -- C# .NET Avl-Tree based generic IDictionary<TKey,TValue> AvlDictionary<TKey,TValue> is an open source C# Avl-Tree based generic IDictionary<TKey,TValue> implementation. See the AvlDictionary documentation. Features implements generic IDictionary<TKey, TValue> interface implements generic ICollection<KeyValuePair<TKey, TValue>> interface implements generic IEnumerable<KeyValuePair<TKey, TValue>> interface [Serializable] In order to use AvlDictionary<TKey,TValue> copy AvlDictionary.cs to your solution and use the AVL-Tree based generic AvlDictionary<TKey,TValue> like you use the hash based generic Dictionary<TKey,TValue>. PriorityQueue<T>: -- C# .NET List<T> based generic min-heap PriorityQueue<T>. See the priority queue documentation. In order to use PriorityQueue<T> copy PriorityQueue.cs to your solution and use the List<T> based generic min-heap PriorityQueue<T>. VERSIONS: Version 1.00, Thu Sep 5 2002 - initial version Version 1.01, Fri Nov 1 2002 - improved memory management, see pblkf.c Revision 1.2, 1.3 Version 1.02, Wed Feb 19 2003 - fixed a bug reported by Csaba Palos, see pblisam.c Revision 1.2 Version 1.03, Sun Apr 4 2004 - fixed a bug reported by Jari Aalto, see pbl.h Revision 1.3 Version 1.04, Sun Mar 1 2009 - Optimizations during MAC OS X port. Exposed the array list, linked list, tree set and hash set functions. Version 1.04.02, Sun May 30 2010 - Exposed the map interface functions. Version 1.04.03, Sun Aug 8 2010 - Exposed the priority queue functions. Version 1.04.04, Sun Sep 5 2010 - Exposed the heap functions. GET PBL: See the PBL documentation. PBL is hosted on GitHub. Download the PBL master from GitHub. Take a look at the PBL sources. Take a look at Spam Probe, a project that uses PBL. PBL is listed as awesome-c framework. Copyright(C) 2003 - 2015 Peter Graf, this software is distributed under the GNU Lesser General Public License."	"null"	"null"	"A large library of utilities, featuring data structures, among other things. or later (library), or later (test code)."	"true"
"Frameworks"	"qlibc"	"https://github.com/wolkykim/qlibc"	"A simple and powerful C library, designed as a replacement for GLib while focusing on being small and light. (similar to )."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"196"	"33"	"37"	"GitHub - wolkykim/qlibc: qLibc is a simple and powerful C library Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 33 Star 196 Fork 37 wolkykim/qlibc Code Issues 3 Pull requests 0 Wiki Pulse Graphs qLibc is a simple and powerful C library http://wolkykim.github.io/qlibc 242 commits 2 branches 9 releases Fetching contributors C 93.7% Shell 2.4% Makefile 2.0% M4 1.1% Other 0.8% C Shell Makefile M4 Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags gh-pages master Nothing to show v2.4.1 v2.1.6 v2.1.1 v1.2.1 r2.1.2 r1.2.2 2.4.0 2.3.0 2.2.0 Nothing to show New pull request Latest commit dbea914 Jul 4, 2016 wolkykim committed on GitHub Merge pull request #55 from levidurfee/master … Fixed some spelling and grammar mistakes. Permalink Failed to load latest commit information. doc/html Update doc. Dec 16, 2015 examples Merging/Adjusting new vector into the build. #44, #41 Apr 22, 2015 include/qlibc Fix #48, include missing headers. Sep 16, 2015 lib Restructure include directory. Mar 25, 2014 src Fixed some spelling and grammar mistakes. Jul 4, 2016 tests update copyright Apr 23, 2015 .gitignore This resolves #36 Apr 3, 2015 CMakeLists.txt Make explicit the public dependency between qlibcext and qlibc. Sep 17, 2015 INSTALL.md This resolves #36 Apr 3, 2015 LICENSE Update copyright year. Mar 18, 2015 Makefile.in Simplify master makefile and add test target Dec 16, 2015 README.md Add new great contributor Carpentier Pierre-Francois Dec 16, 2015 config.guess Porting the latest revision r133 qLibc code to GitHub. Mar 20, 2014 config.h.in Porting the latest revision r133 qLibc code to GitHub. Mar 20, 2014 config.sub Porting the latest revision r133 qLibc code to GitHub. Mar 20, 2014 configure fix CFLAGS env not working Apr 14, 2015 configure.ac Fix #42, Apply the patch to configure.ac Apr 14, 2015 install-sh Porting the latest revision r133 qLibc code to GitHub. Mar 20, 2014 README.md What's qLibc? qLibc is currently one of the most functionally-complete, publicly-licensed C/C++ libraries. The goal of the qLibc project is to provide a simple and powerful general purpose C/C++ library that includes all kinds of containers and general library routines. It provides a ready-made set of common container APIs with a consistent API look. qLibc Copyright qLibc is published under 2-clause BSD license known as Simplified BSD License. Please refer the LICENSE document included in the package for more details. API Reference qlibc Core API Reference Containers for Key/Value pairs Tree Table --- in binary tree(left-leaning red-black tree) data structure. Hash Table --- in hash-based data structure. Static Hash Table --- in fixed size memory(array/mmapped/shared). List Table --- in (doubly) linked-list data structure. Containers for Objects List --- Doubly Linked List. Vector --- implements a growable array of elements. Queue --- FIFO(First In First Out) implementation. Stack --- LIFO(Last In First Out) implementation. General utilities. String --- string trimmer, modifier, replacer, case converter, pattern detectors, ... I/O --- non-blcking I/O, stream reader/writer, ... File --- file locking, file/directory hander, path correctors, ... IPC, Semaphore Shared-memory En/decoders --- Url en/decoder, Base64 en/decoder, Hex en/decoder, ... Hashes --- Murmur hases, FNV hases, MD5 hashes, ... Time --- time diff, time format converstion, ... qLibc Extension API Reference Apache-style Configuration File Parser. INI-style Configuration File Parser. HTTP client. Rotating File Logger. Database(MySQL) interface. Token-Bucket qLibc Tables at a Glance Characteristics Tree Table Hash Table Static Hash Table List Table Data structure Binary Tree Slot Index Block Array Linked-List Search complexity O(log n) O(1) / O(n) O(1) / O(n) O(n) Insert complexity O(log n) O(1) / O(n) O(1) / O(n) O(1) Delete complexity O(log n) O(1) / O(n) O(1) / O(n) O(n) Space complexity O(n) O(n) - O(n) Space allocation Dynamic Dynamic Pre-allocation Dynamic Data Stored Sorted Yes No No Yes (option) User comparator Supported - - Supported Allow multi-keys No No No Yes (option) Key stored digested No No Yes No Search Nearest Key Yes No No No Iterator support Yes Yes Yes Yes Iterator visit order min -> max random random insert order Thread-safe option Supported Suported No Supported Runs on shared mem No No Yes No Consistent API Look All container APIs have a consistent look and feel. It basically provides a creator function which usually returns a pointer to a container structure. Also, all functions related to the container can be accessed through function pointers inside of the container or traditional style direct access APIs. For an example, So, regardless of which container you use, you can simply put elements into a list with container->put(container, ...) or you can call them using direct API like qtreetbl_pub(container, ...). An examples below illustrates how it looks like.   // create a hash-table.   qhashtbl_t *tbl = qhashtbl(0, QHASHTBL_OPT_THREADSAFE);    // add an element which key name is ""score"".   int x = 12345;   tbl->put(tbl, ""score"", &x, sizeof(int));    // get the value of the element.   int *px = tbl->get(tbl, ""score"");   if(px != NULL) {     printf(""%d\n"", *px);     free(px);   }    // release table   tbl->free(tbl); Here is an identical implementation with a Linked-List-Table container. You may notice that there aren't any code changes at all, except for 1 line in the table creation. This is why qLibc encapsulates corresponding function pointers inside of the container object.   // create a linked-list-table. THE ONLY LINE YOU NEED TO CHANGE.   qlisttbl_t *tbl = qlisttbl(QLISTTBL_OPT_THREADSAFE);    // add an element which key name is ""score"".   int x = 12345;   tbl->put(tbl, ""score"", &x, sizeof(int));    // get the value of the element.   int *px = tbl->get(tbl, ""score"");   if(px != NULL) {     printf(""%d\n"", *px);                  free(px);   }    // release table   tbl->free(tbl); Looking for people to work with. We're looking for people who want to work together to develop and improve qLibc. Currently, we have high demands on following areas. Automated testing Documentation. New feature implementation. Contributors The following people have helped with suggestions, ideas, code or fixing bugs: (in alphabetical order by first name) Alexandre Lucchesi Anthony Tseng Carpentier Pierre-Francois Cesar Colin Charles Dmitry Vorobiev HyoSup Woo Keith Rosenberg Krishna Liu Zhongchao Luis Jimenez Maik Beckmann RQ Ryan Gonzalez Seungyoung Kim Umesh If we have forgotten or misspelled your name, please let us know. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/wolkykim/qlibc"	"A simple and powerful C library, designed as a replacement for GLib while focusing on being small and light. (similar to )."	"true"
"Frameworks"	"stb"	"https://github.com/nothings/stb"	"A range of single-file libraries for C. Public domain."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"3828"	"350"	"455"	"GitHub - nothings/stb: stb single-file public domain libraries for C/C++ Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 350 Star 3,828 Fork 455 nothings/stb Code Issues 40 Pull requests 21 Pulse Graphs stb single-file public domain libraries for C/C++ 1,103 commits 1 branch 0 releases 71 contributors C 98.4% C++ 1.6% C C++ Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Latest commit c9ead07 May 14, 2016 nothings Update other_libs.md Permalink Failed to load latest commit information. data change map image formats to workaround stb_image bug Apr 16, 2016 deprecated Merge branch 'headerify' Jun 3, 2014 docs Update other_libs.md May 14, 2016 tests stbcc 0.94 Apr 17, 2016 tools stb_connected_components added Apr 15, 2016 README.md stbcc 0.94 Apr 17, 2016 release_notes.md clarify Apr 2, 2016 stb.h update version numbers, documentation, and contributors Apr 2, 2016 stb_c_lexer.h Slightly modify the public domain license to keep it in the public do… Feb 25, 2016 stb_connected_components.h stbcc 0.94 Apr 17, 2016 stb_divide.h Slightly modify the public domain license to keep it in the public do… Feb 25, 2016 stb_dxt.h Slightly modify the public domain license to keep it in the public do… Feb 25, 2016 stb_easy_font.h Slightly modify the public domain license to keep it in the public do… Feb 25, 2016 stb_herringbone_wang_tile.h Slightly modify the public domain license to keep it in the public do… Feb 25, 2016 stb_image.h fix crash in 2.11 Apr 2, 2016 stb_image_resize.h update version numbers, documentation, and contributors Apr 2, 2016 stb_image_write.h update version numbers, documentation, and contributors Apr 2, 2016 stb_leakcheck.h Merge branch 'patch-1' of https://github.com/looki/stb Apr 2, 2016 stb_perlin.h Slightly modify the public domain license to keep it in the public do… Feb 25, 2016 stb_rect_pack.h Slightly modify the public domain license to keep it in the public do… Feb 25, 2016 stb_textedit.h update version numbers, documentation, and contributors Apr 2, 2016 stb_tilemap_editor.h Slightly modify the public domain license to keep it in the public do… Feb 25, 2016 stb_truetype.h fix unused variable warning Apr 2, 2016 stb_vorbis.c back out previous change to stb_vorbis (truncation of last frame in c… Apr 4, 2016 stb_voxel_render.h update version numbers, documentation, and contributors Apr 2, 2016 stretchy_buffer.h remove claims of supporting C++ in stretchy_buffer Apr 2, 2016 README.md stb single-file public domain libraries for C/C++ library lastest version category LoC description stb_vorbis.c 1.09 audio 5397 decode ogg vorbis files from file/memory to float/16-bit signed output stb_image.h 2.12 graphics 6755 image loading/decoding from file/memory: JPG, PNG, TGA, BMP, PSD, GIF, HDR, PIC stb_truetype.h 1.11 graphics 3267 parse, decode, and rasterize characters from truetype fonts stb_image_write.h 1.02 graphics 1048 image writing to disk: PNG, TGA, BMP stb_image_resize.h 0.91 graphics 2578 resize images larger/smaller with good quality stb_rect_pack.h 0.08 graphics 572 simple 2D rectangle packer with decent quality stretchy_buffer.h 1.02 utility 216 typesafe dynamic array for C (i.e. approximation to vector<>), doesn't compile as C++ stb_textedit.h 1.8 user interface 1304 guts of a text editor for games etc implementing them from scratch stb_voxel_render.h 0.84 3D graphics 3752 Minecraft-esque voxel rendering ""engine"" with many more features stb_dxt.h 1.04 3D graphics 630 Fabian ""ryg"" Giesen's real-time DXT compressor stb_perlin.h 0.2 3D graphics 182 revised Perlin noise (3D input, 1D output) stb_easy_font.h 0.7 3D graphics 258 quick-and-dirty easy-to-deploy bitmap font for printing frame rate, etc stb_tilemap_editor.h 0.37 game dev 4131 embeddable tilemap editor stb_herringbone_wa... 0.6 game dev 1220 herringbone Wang tile map generator stb_c_lexer.h 0.07 parsing 816 simplify writing parsers for C-like languages stb_divide.h 0.91 math 379 more useful 32-bit modulus e.g. ""euclidean divide"" stb_connected_comp... 0.94 misc 1000 incrementally compute reachability on grids stb.h 2.27 misc 14185 helper functions for C, mostly redundant in C++; basically author's personal stuff stb_leakcheck.h 0.2 misc 124 quick-and-dirty malloc/free leak-checking Total libraries: 19 Total lines of C code: 47814 FAQ What's the license? These libraries are in the public domain (or the equivalent where that is not possible). You can do anything you want with them. You have no legal obligation to do anything else, although I appreciate attribution. Are there other single-file public-domain/open source libraries with minimal dependencies out there? Yes. If I wrap an stb library in a new library, does the new library have to be public domain? No. Some of these libraries seem redundant to existing open source libraries. Are they better somehow? Generally they're only better in that they're easier to integrate, easier to use, and easier to release (single file; good API; no attribution requirement). They may be less featureful, slower, and/or use more memory. If you're already using an equivalent library, there's probably no good reason to switch. Can I link directly to the table of stb libraries? You can use this URL to link directly to that list. Why do you list ""lines of code""? It's a terrible metric. Just to give you some idea of the internal complexity of the library, to help you manage your expectations, or to let you know what you're getting into. While not all the libraries are written in the same style, they're certainly similar styles, and so comparisons between the libraries are probably still meaningful. Note though that the lines do include both the implementation, the part that corresponds to a header file, and the documentation. Why single-file headers? Windows doesn't have standard directories where libraries live. That makes deploying libraries in Windows a lot more painful than open source developers on Unix-derivates generally realize. (It also makes library dependencies a lot worse in Windows.) There's also a common problem in Windows where a library was built against a different version of the runtime library, which causes link conflicts and confusion. Shipping the libs as headers means you normally just compile them straight into your project without making libraries, thus sidestepping that problem. Making them a single file makes it very easy to just drop them into a project that needs them. (Of course you can still put them in a proper shared library tree if you want.) Why not two files, one a header and one an implementation? The difference between 10 files and 9 files is not a big deal, but the difference between 2 files and 1 file is a big deal. You don't need to zip or tar the files up, you don't have to remember to attach two files, etc. Why ""stb""? Is this something to do with Set-Top Boxes? No, they are just the initials for my name, Sean T. Barrett. This was not chosen out of egomania, but as a moderately sane way of namespacing the filenames and source function names. Will you add more image types to stb_image.h? If people submit them, I generally add them, but the goal of stb_image is less for applications like image viewer apps (which need to support every type of image under the sun) and more for things like games which can choose what images to use, so I may decline to add them if they're too rare or if the size of implementation vs. apparent benefit is too low. Do you have any advice on how to create my own single-file library? Yes. https://github.com/nothings/stb/blob/master/docs/stb_howto.txt Why public domain? I prefer it over GPL, LGPL, BSD, zlib, etc. for many reasons. Some of them are listed here: https://github.com/nothings/stb/blob/master/docs/why_public_domain.md Why C? Primarily, because I use C, not C++. But it does also make it easier for other people to use them from other languages. Why not C99? stdint.h, declare-anywhere, etc. I still use MSVC 6 (1998) as my IDE because it has better human factors for me than later versions of MSVC. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/nothings/stb"	"A range of single-file libraries for C. Public domain."	"true"
"Engines"	"Corange"	"https://github.com/orangeduck/Corange"	"A game engine in pure C.."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"470"	"59"	"62"	"GitHub - orangeduck/Corange: Pure C Game Engine Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 59 Star 470 Fork 62 orangeduck/Corange Code Issues 1 Pull requests 0 Pulse Graphs Pure C Game Engine http://www.youtube.com/watch?v=482GxqTWXtA 320 commits 1 branch 0 releases Fetching contributors C 91.1% GLSL 7.6% Other 1.3% C GLSL Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Latest commit f78964d May 14, 2016 orangeduck Merge pull request #17 from dave-kennedy/master … Line endings Permalink Failed to load latest commit information. assets_core renamed deferred renderer to just renderer Nov 25, 2014 demos Normalize all the line endings Apr 30, 2016 include Normalize all the line endings Apr 30, 2016 src Normalize all the line endings Apr 30, 2016 .gitattributes Enforce LF line endings Apr 30, 2016 .gitignore Fixed Cube Mapping Feb 16, 2013 LICENCE.md reorganized shaders Mar 31, 2012 Makefile fixed compilation errors and removed ^M Nov 25, 2014 README.md Update README.md Apr 17, 2016 corange.ico Added windows resource files and window icon. Mar 16, 2012 corange.rc Added windows resource files and window icon. Mar 16, 2012 README.md Corange game engine Version 0.8.0 Written in Pure C, SDL and OpenGL. Running Corange is a library, but to take a quick look at some of the things it does you can Look at some of the Demos. Warning: Some things shown are from a previous version and may not remain the same in this version. Compiling To compile on Windows you need MinGW and then you should be able to run ""make"" as usual. You will need to have installed SDL, SDL_Mixer and SDL_Net. make  To compile on Linux you need to install SDL2. Then you should run ""make"" sudo apt-get install libsdl2-dev sudo apt-get install libsdl2-mixer-dev sudo apt-get install libsdl2-net-dev make  Overview Small, Simple, Powerful, Cross platform Clean and easy Asset, UI, Entity management Modern Deferred renderer Demos I'm a graphics programmer by trade so apologies that most of the demos are graphical apps; they're just what I love! renderers Shows off the various renderers with shaders, shadows, animation etc. metaballs Uses OpenCL/OpenGL interop to do Metaball rendering. noise Feedback based noise pattern on screen using shader. Can generate tileable perlin noise in software. platformer Basic platforming game. Fairly well commented. sea Renders a sea-like surface, a ship, and some collision detection. scotland Demonstrates terrain system. tessellation Demo showing tessellation shaders in OpenGL 4. FAQ How is that pronounced? Rhymes with Purple. Why not C++? There are plenty of C++ engines which do what I've done here and better. Pure C game engines on the other hand are much rarer. Corange provided me an outlet to practice my C skills. Of course if you are just linking to it you can still program your game/executable using C++. What stuff does it do? I've used it as a platform for trying out all sorts of techniques and effects. These features are not out-of-the-box or plug-in-and-play, but if you are a developer who has knowledge of what they are, you should be able to utilize what I have written. Some are WIP or rough around the edges. Deferred Rendering / UI Rendering / Text Rendering. Multiple Lights. Post effects. SSAO. Shadow Mapping. Color Correction. Skeletal Animation. Inverse Kinematics. Collision Detection. OpenCL support. Asset / Entity / UI Management. Terrain. File loaders including .dds, .wav, .bmp, .obj, .smd. Maths and Geometry. And More... Can I use this for 2D stuff? Certainly. Though Corange doesn't provide a 2D renderer for you. That you can write yourself. Believe it or not, making a generalized 2D renderer can be exceedingly complicated when you have to optimise for different sprites, tile sets, dynamic objects and all sorts of other effects. You're better off writing the rendering code application specific. Can I contact you about something? Yes - contact@theorangeduck.com Using / Contributing This is still mainly a personal project and so there are going to be lots of bugs, unfinished features and messy bits of code. The engine is heavily WIP and subject to sweeping changes. It isn't really viable to use without also being part of the project development and in communication with me. Rather than a full game engine like Unity, Corange is more of a framework and gives you access to features at about the same level as XNA. I have a big backlog of Work in Progress changes I need to push up to the repository once they get to a reasonable point so if you are interested in those please contact me. Saying that, it is a great excuse to practise your C and I very much welcome help. If the project appeals to you here are a couple of quick things that might help get you started. First take a look at the demos. These give a brief overview of how Corange can be used. The platformer demo is probably the most commented. There is no real documentation so your first port of call is the header files and your second is the c files. The code has very minimal comments but should be pretty clear most of the time. Corange doesn't hide anything from you. OpenGL and SDL calls are in the namespace so you've got access to the basics. The corange_init and corange_finish functions are fairly short so it is even possible to not call them and only use the components you want. Structs are typedefed without their pointer. The reason for this is a personal choice but there are also quite a few data types which are passed by value on the stack (vectors, matrices, spheres, boxes). I didn't want the notion of these to get confused. Some important parts of the engine are the asset, UI and entity managers. These basically let you access and store assets (models, textures - objects in the file system) and entities (lights, cameras, engine objects) and UI elements. They clean up memory on destruction and let you get pointers from all parts of the code. Corange mangles the namespace pretty badly, taking names such as ""error"", ""warning"", ""vec2"" and ""image"". It isn't a general purpose library. But I've still tried to decouple stuff so it should be possible to extract certain code if you need it. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/orangeduck/Corange"	"A game engine in pure C.."	"true"
"Engines"	"Darkplaces"	"https://icculus.org/twilight/darkplaces/"	"A modified version of the Quake2 engine. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"null"	"null"	"null"	"LordHavoc's DarkPlaces Quake Modification About/News  ReadMe  Download  Screenshots  Tech Notes  Email  About DarkPlaces is a Quake modification I have built over the course of 6 years on and off experimenting, it got somewhat of an overhaul when the Quake engine source code was released, and I began developing a custom OpenGL-only engine for it and other mods, which supports Windows WGL and Linux GLX, and has greatly improved graphics and image quality. It can not easily be described, as it is simply an improved Quake, not a total conversion (yet, anyway). The realism of shell casings falling to the floor, much improved bullet impacts, 32bit color alpha blended explosions, blood flying everywhere and sticking to the walls... Behind the scenes the code has changed a great deal, I was not content with the original QuakeC code, and I have greatly changed the engine while maintaining compatibility with normal quake modifications. LordHavoc Please read the ReadMe for additional information. Quake art enhancement projects Games On Net file section (Rygel's 2.7GB ultra pack can be found here as a 3 part rar) Quake Retexture/Remodel Project (maintained by Up2nOgOoD[ROCK] as primarily a QuakeWorld content replacement project, difficult to install on DarkPlaces, formerly known as the QE1M1/QE1 project made famous by Tenebrae). Romi's rtlights file for Quake (rtlights pack for Quake - drop this file in your id1 directory to get improved performance in all id1 maps when using Realtime World Lighting in the options menu) Romi's rtlights file for Quake mission pack 1 (rtlights pack for Scourge of Armagon - by Ritual Entertainment, formerly known as Hipnotic Entertainment) News 2014-05-13: New darkplaces update: Revised collision code for q3bsp again, collision_enternudge/collision_leavenudge cvars have been set back to 0 and removed due to problems on terrain maps such as the Nexuiz map ons-reborn, the other collision improvements should still help significantly. 2014-05-07: New darkplaces update: Fixed a model lighting bug on certain q1bsp maps where some entities were being lit incorrectly (black green armor in dm4 being one example) - thanks to jitspoe for discussion leading to this fix. Fixed the cvar sv_jumpstep which was being inverted (this made it too easy to jump up ledges in id1). Changed collision code to prevent getting stuck in many q3bsp maps and some q1bsp maps (the new collision_extendmovelength cvar affects this, as well as collision_enternudge/leavenudge). Fixed occasional black screens caused by r_useportalculling (a portal closer than the nearclip plane was being culled in some cases, portal bounds are now expanded according to r_nearclip). Fixed a bug in vid_soft when using a custom compiled SDL2 client (the regular SDL client is SDL1 based) where the decals would show garbage due to alpha compositing, alpha compositing is no longer used (thanks to divVerent for fixing this). 2014-04-30: New darkplaces update: FXAA added : r_fxaa 1 in console to activate it (thanks graphitemaster) r_glsl_postprocess will no longer force a blur effect unless the corresponding uservecs are in use (thanks divVerent). Updated ip address for master server dpmaster.deathmask.net and added ip6 address for it as well (someday we'll use threaded dns lookup instead). Increased effectinfo.txt limits as requested by JKoestler who managed to have *that* many effects defined. Allow .rtlights files to use style -1 for compatibility with fteqw-produced rtlights files. New vid_desktopfullscreen cvar will use your desktop resolution instead of changing video mode, this is better behaved on all platforms but especially Linux. gl_vbo_dynamicvertex and gl_vbo_dynamicindex have been optimized (but seem to still be slower on desktop GL than using conventional vertex arrays). Fixed some issues with the unmaintained D3D9 renderer pertaining to vid_sRGB and vid_stereobuffer. Fixed a bug with EF_FLAME and EF_STARDUST effects still emitting particles when paused. Changed behavior when stuck in brush models such that you can will not be stuck in an entity such as a door or platform, only stuck if in solid world geometry (an intentional quake behavior). 2013-03-04: New darkplaces update: Fix a crash on OpenGL 2.0 (DX9-class) video cards where glGetUniformBlockIndex is NULL, this was not properly guarded with an extension check, OpenGL 3.1 or higher drivers (DX10-class) have this function. 2013-03-01: New darkplaces update: added support for RMQe maps like ""Something Wicked This Way Comes"" by Tronyn, this map format is slightly worse (smaller coordinate limit) than the BSP2 that darkplaces already supported. fixed bug with the two shalrath not spawning in hip2m3 - this took a far-reaching analysis and bugfix effort for droptofloor and MOVETYPE_STEP in general, this should improve compatibility with other maps too. sv_gameplayfix_ cvars default off now, this should make most mods compatible by default rather than requiring tweaked cfg files, these cvars do default on for non-quake games however (Nexuiz, Steel Storm: Burning Retribution, etc). skeletal model animation is now hardware accelerated where possible (OpenGL 3 / DX10 cards), this greatly improves fps in Nexuiz and other games with skeletal models. New dpmod release to reenable the sv_gameplayfix_ cvars that are disabled by default now. 2012-12-22: New darkplaces update for the survivors of the end of the world: support for X360 gamepad (joy_enable 1 required). -quoth support. fixed hip1m1 gold key door bug. fixed some bugs with effectinfo.txt parsing that could cause effects to not be properly initialized. sound() builtin now supports speed control (pitch shifting) and 128 channels with snd_channel*volume cvars controlling their volume level independently (make weapon sounds louder/quieter compared to other sound types, etc). reduced memory usage (sounds are now resampled during mixing rather than at load time). better support for static (non-animated) iqm models. added dpshaderkillifcvar keyword in q3 shader files which allows alternative shaders to be used based on cvars (games can use this to swap in different kinds of water shader among other things). removed r_hdr cvar (use r_viewfbo 2 instead). multiple bugs with vid_sRGB 1 have been fixed. made mdl rendering mode faithful to software Quake by removing an unwanted half-pixel texcoord offset. added cvars r_nearest_2d and r_nearest_conchars which let you decide whether to use nearest filtering on the entire 2D UI or just the console font. support for BSP2 format (modified Quake bsp with higher limits) to match the new hmap2 feature. fix missing runes on the hud (due to previously bugged detection of hipnotic/rogue qc code). fixed playback of intro demos in Malice game. fixed a bug where playing back demos and changing slowmo cvar would not immediately take effect. New hmap2 release bringing support for much more complex maps (beyond Quake limits), it is much less likely to crash on complex maps now and will write BSP2 format if necessary. New dpmod release with some minor fixes. 2011-07-23: New dpmaster master server release from Mathieu Olivier, version 2.2 brings the following features: Flood protection against abusive clients (contributed by Timothee Besset). Support for Return To Castle Wolfenstein servers. Support for Wolfenstein: Enemy Territory servers. 2011-06-28: New DarkPlaces engine release to fix the following issues with the previous release: OSX build now supports .ogg music and .ogv theora video recording as intended (and as the other platforms do). 2011-06-26: New DarkPlaces engine release to fix the following issues with the previous release: Really fixed the solid water bug on dedicated servers this time. 2011-06-25: New DarkPlaces engine release to fix the following issues with the previous release: Fixed a bug where dedicated servers would incorrectly load Quake1 BSP Files and treat water as solid. 2011-06-24: New DarkPlaces engine release with many improvements and bugfixes, including: Significantly optimized rendering, much higher framerates than previous release. Photon traced 3D texture radiosity in realtime world mode (r_shadow_bouncegrid 1). Experimental Software Renderer (vid_soft 1;vid_soft_threads 4;vid_restart), not recommended for serious play, framerate is poor (but it renders very accurately), not feature complete yet; no fog for instance... Experimental Direct3D9 renderer choice (vid_dx9 1;vid_restart), not recommended because the D3D9 shadowmapping method is very slow compared to the OpenGL method, with shadows off it performs almost identically to the OpenGL 2.0 renderer. In other news, the DarkPlaces-powered game Steel Storm: Burning Retribution has been released on Steam, for those who love overhead arcade shooters and multiplayer mission editing. Also important, the web-based Quake Expo 2011 is well underway and nearing the end of its week-long run, be sure to check out the booths. Updated download page with autobuild download links for those who want to follow the latest in-development version, also added separate downloads for Windows and Windows 64bit without the Linux and OSX builds to decrease download size for most people. 2010-04-08: New DarkPlaces engine release with many improvements and bugfixes, including: High quality shadowmapping - r_shadow_shadowmapping 1 to enable, or r_shadows 2 for shadowmapped model shadows only. New Bounding Interval Hierarchy collision culling system to improve server performance on Q3BSP maps (mod_collision_bih cvar is on by default). In other news I am actively working on the console Nexuiz game coming this summer on Playstation Network and Xbox Live Arcade, powered by DarkPlaces engine, I had lots of fun at GDC, thanks everyone for the support and this game is going to rock (on the topic of licensing please see the interview at timedoctor.org), this means I have even more reason to actively maintain DarkPlaces engine and will continue adding great features. There is now a DarkPlaces wiki for modders, see this inside3d thread for more information and to contribute. 2010-01-13: New hmap2 (q1bsp compiler) release with the following changes: Fixed rotating door compilation, it was generating corrupt hull data for player and shambler collisions, now works perfectly. (To see this in action in your own q1 maps, try making a ""func_wall"" entity and setting the ""origin"" key to the center of rotation you want, then set ""nextthink"" ""999999999"" and ""avelocity"" ""0 90 0"" to see it spin 90 degrees per second on yaw and push you around) 2009-08-28: New dpmaster master server release from Mathieu Olivier, version 2.1 brings the following features of interest to game developers: A game type value can now be any name, not just a number. (Needed by Warsow 0.5) 2009-07-09: New DarkPlaces engine build, this is purely a bugfix release - the ogg dlls were missing in the previous build, making sound/cdtracks/track002.ogg and other emulated cd tracks fail to play (if you were not aware of this feature, see the readme for instructions on encoding and installing the Quake CD music for play without the CD in the drive). 2009-07-07: New DarkPlaces engine build, bringing more of the usual optimizations and bugfixes, this release is mainly to fix a permissions problem that kept the Mac version from starting in the last stable build. 2009-06-04: New dpmaster master server release from Mathieu Olivier, version 2.0 brings the following features of interest to game developers: IPv6 support. Logging system. Game type filters in server list queries (and ability to restrict supported games in the master server, may be of interest to game teams hosting their own master server). Updated documentation and many fixes and improvements. (Note: dpmaster is only of interest to game development teams who have a game engine that supports the Quake3(r) master server protocol, or the extended dpmaster protocol, it is not of interest to users) 2009-01-28: New DarkPlaces engine build, this release is mainly to fix the crash caused by recent ATI windows drivers when changing resolution or quitting. 2008-10-04: New DarkPlaces engine build with the following major changes: Made savegames compatible with other Quake engines. Extended savegame format with new features (no longer glitches when you reload a savegame on a mod that randomly replaces monsters or items with other ones). Disabled use of GL_ARB_texture_non_power_of_two extension on Mac because it often crashes or runs slowly (some graphics chips fully support it but not all, and crashing is unacceptable). 2008-09-30: New DarkPlaces engine build adding missing files to the Mac build (SDL.framework was not included and thus it would not run). 2008-09-10: New DarkPlaces engine build with a fix for specular lighting issues. 2008-09-09: New DarkPlaces engine build including Mac binaries, mostly bugfixes since the previous release. 2008-08-16: QuakeExpo 2008 is open as of August 15th and ending on September 12th (4 weeks - longest qexpo ever), be sure to give it a visit and see what people are doing with Quake, Quake II, and Quake III. 2008-08-08: New DarkPlaces engine build, many minor improvements have occurred, as well as optimizations and bugfixes. Note: no Mac binaries included this time, I have not set up compiling on a Mac I have access to yet, if you need Mac binaries please email me to remind me. 2008-07-15: New dpmodel build with fixed md3 normals (they were being calculated incorrectly - apparently Quake3 uses a strange latitude/longitude angle format instead of pitch/yaw), this utility converts .smd model files (saved by HalfLife export plugins for various modeling programs) to .dpm and .md3 model formats. 2008-06-16: New hmap2 build with better time estimates for vis and light, still not multithreaded however. 2008-06-15: Posted Elric's new dpmaster version 1.7, featuring a perl-based test suite, several bugfixes and minor one-time memory leak fixes, increases in default server limits, corrections to techinfo.txt, and other improvements. (Note: this server-list database program is only interesting to independent game development teams and tournament administrators) 2007-11-20: New DarkPlaces build: Improved performance on lowend cards (probably only slightly) by skipping a screen clear. Improved performance of reflections on water. Improved performance of GL 2.0 shader - glow layer was accidentally always enabled. Improved performance of GL 2.0 shader - directional shading was being used in Quake1 levels despite the fact Quake1 maps do not have any directional model lighting information (Quake3 maps do), this was using a very slow software code path to generate directional shading information on models, which went unused. Fixed bug with loading a savegame while demos are playing. You can now load/save multiplayer games (just remember to have everyone rejoin in the same order before loading). Improved performance of decals (split particle system into particle and decal subsystems with more finely tuned code for each). More than doubled blood opacity, it was hard to see before at default settings. Probably a few other fixes and changes I should mention bug forgot about. Known bugs: water does not reflect sky for unknown reasons (not a new bug). New dpmod build: Updated episode 1 rtlights files from romi's site. 2007-11-03: Updated screenshots page due to popular demand. 2007-09-28: New DarkPlaces build, this is the same as the previous one but adds Mac OSX binaries which failed to build last time (due to my friend's Mac being offline). 2007-09-27: New DarkPlaces build: Fixed the guardian boss in mission pack 2 (Dissolution of Eternity) not waking up. Fixed some misplaced code causing the score display on the left side of the hud in multiplayer to show up even at viewsize 120. Added support for mouse button 4 (left side button on some mice) in -dinput mode (in case anyone actually uses that), button 5 (right side button) still not supported in -dinput though. Improved fps significantly in some maps such as masque.bsp (Masque of the Red Death) by using larger lightmap textures for maps with lots of lightmaps. Rewrote OpenGL 2.0 shader in a way that may make it work with broken GL drivers on Mac OS X (it already worked on ATI Radeon X1600 and above but not other cards, let's see if this fixes it on other cards). Implemented (very slow) experimental pixel shader water (Try the following commands if you wish to try it: r_glsl_water 1;r_shadow_bumpscale_basetexture 4;r_restart;r_waterscroll 8;r_novis 1;r_wateralpha 0.1) In other news I put up a tech notes page which may be helpful to other engine developers, or to anyone interested in the technologies used in darkplaces. Rygel's 2.7GB ultra texture pack is amazing, be sure to set gl_texturecompression 1 before installing it however, it may not even load otherwise, and it takes about 3 minutes to load the first level! 2007-07-11: New DarkPlaces build to fix timing issues in Nehahra movie playback at scene transitions. 2007-07-07: New DarkPlaces build and dpmod build (just for good measure), many bugfixes and improvements. 2007-04-12: New DarkPlaces build, this has the following significant changes: Renders faster using the GL_ARB_vertex_buffer_object extension if available to store the map, models, and shadow volumes on the video card for faster drawing. Fixed crashes and broken lighting (which mostly affected ATI cards which have a more strict shader compiler). Fixed a significant issue in timing code that had been causing subtle timing issues such as inconsistent ping times, erratic shot timing, jerky movement of players using prediction. Known bugs and workarounds: If your cl_maxfps is near your rendering framerate it can be very jerky, if this happens please enter this in the console: cl_nettimesyncmode 1 (a better fix is in the works) DarkPlaces source code has moved from the cvs versioning system to the svn versioning system, if you are an avid DarkPlaces tester obsessed with having the latest in-development version at all times, or are maintaining patches for darkplaces for your games/mods, please do a fresh svn checkout and migrate your changes (use cvs diff >patch.txt and then patch -i patch.txt to apply it in your new svn checkout, you may need to copy other files as necessary), all future changes will only be committed to the svn, the cvs will not be updated, and will eventually die whenever icculus convinces all other projects to switch to svn. All future build zips will lack the CVS directories and can not be updated (sorry, but the .svn directory doubles the size of every zip, which is unacceptable), if you need to update please do a checkout instead of downloading a build zip. This also means that I can now add more developers to the DarkPlaces project as I now have control over the logins for DarkPlaces (for cvs, icculus was having to add real unix users for every developer and told me he wouldn't add any more, so some people were only able to submit patches to me, now they can commit directly without my intervention). If you are just a player, don't worry about this versioning system nonsense. :) 2007-03-15: New darkplaces engine and dpmod release: Fixed a really bad bug in dpmod deathmatch 7 code that made all monsters spawn at only one of the spawn points, rather than a randomly chosen one as was intended. Fixed bug that made ambient sounds not play (except in demos). Doubled default hearable sound range to match ProQuake. Added support for the strange macros often found in FuhQuake/ezQuake .loc files. Cleaned up the options menu and added some selectable presets for effects and lighting. Changed default value of con_closeontoggleconsole cvar to 1, to put an end to the nearly 2 years of complaints about the tilde key not closing the console. Added code to setinfo pmodel/emodel when connected to a quakeworld server (incase anyone cares about what version of player.mdl/eyes.mdl are being used). Fixed bugs in server query code when using sv_protocolname QUAKE, the server now properly responds to quake1 query tools when running quake protocol. Disabled cl_bobmodel code when cl_bob is 0 for better compatibility with quake configs that expected the gun bobbing to be off when view bobbing is off. Fixed a crash in the ""maps"" command. Optimized ""maps"" command which was taking seconds to execute with large numbers of files. Disabled movement prediction code on Quake servers, as it never works right without proper synchronization of moves (which only DP6/DP7/QW protocols offer). 2007-03-14: New darkplaces engine release fixing some bugs with .loc files that proquake accepted but darkplaces did not parse properly, no other noteworthy changes. 2007-03-12: New darkplaces engine and mod release: Many bugs fixed, some new features, fixed some map compatibility bugs (items falling out of levels and such), fixed many network issues (MUCH better now), some new network features (such as automatic downloads of missing files from darkplaces servers), fully updated readme (which has been converted to HTML and posted here, and now includes cvar and command lists), some optimizations, supports more OpenGL extensions to accelerate stencil shadows and other features, changed the look of rtlights to be a bit more realistic (small performance penalty). Removed pentium3-optimized builds (darkplaces_p3.exe and such) because they weren't really any faster from the few reports I've gotten, this reduces download size. No longer posting nexuizengine builds because the Nexuiz team make their own anyway. Note: no Mac version included in this release either, sorry. 2006-07-25: New darkplaces engine release: Several bugs fixed, not much in the way of new features. Note: no Mac version included in this release either, sorry. Happy QuakeExpo 2006 everyone! 2006-06-06: New darkplaces engine release: Many changes, bugfixes, features, and optimizations... Note: no Mac version included because my friend's Mac is currently out of commission (drive failure, already replaced but the system is not fully functioning yet). Happy 6-6-6 everyone! 2005-08-24: New dpmaster release, version 1.6: Several getserversResponse may now be sent for a single getservers. A getserversResponse packet can no longer exceed 1400 bytes. The maximum number of servers recorded by default has doubled (now 256). The default hash size has been increased from 5 bits to 6 bits. Several updates and corrections in the documentation. Compilation on FreeBSD was fixed. A couple of minor changes in ""COMPILING DPMASTER"" (in techinfo.txt). 2005-08-18: New dpmod release, just more tweaks and scraps of code of interest to modders, nothing really new. (Note: I'd welcome a critique of the highly experimental Ragdoll stick physics code in gore.qc from an experienced physics programmer, I'd like to find out how to fix the many problems with the stick physics) New darkplaces engine release, monsterously huge summary of changes follows: (the changelog itself is much larger) Fixed a bug that was making models twice as bright as they should be in the merged renderer. Added a special check for entities with NAN origins in server networking code to prevent a crash (NAN origin means it has no location at all, it is everywhere at once, a very bad situation). Black and LordHavoc changed normal/tangent smoothing to use areaweighting rather than summing normalized vectors, this looks a little better and is a lot less cpu work on animated high poly models (r_smoothnormals_areaweighting enables/disables this). Black fixed some bugs preventing Tenebrae light entities in q3bsp maps from loading in the rtlights loader. Elric fixed a crash with the mod coopmod. Improved memory debugging capabilities of developer_memorydebug 1 setting, now detects double-free attempts and other errors quite reliably. Added v_deathtilt, cl_deathscoreboard, and cl_deathnoviewmodel cvars to make certain clientside death behaviors optional. Fixed a really bad mistake in the client login process, it was sending \n (newline) characters at the end of the signon commands (the server does not expect newlines in these commands). Added a small check to prevent the ""cmd"" command from forwarding an empty command to the server when given nothing to forward. Added support for GL_NV_half_float OpenGL extension for a noticable lighting speedup on GeForce6 and a minor speedup on GeForceFX. Black made changelevel start a map if there is no server running. (so changelevel is now similar to QW's map command. Black added DP_CON_EXPANDCVAR and DP_CON_ALIASPARAMETERS extensions. DarkPlaces should now support 64bit file sizes on non-windows platforms since windows makes it more difficult (that's 16 Exabytes, or 16,384 Petabytes, or 16,777,216 Terabytes, or 17,179,869,184 Gigabytes). Fix problems with missing cubemap textures in GLSL. Tomaz fixed a bug in the Windows client with vsync where it was not applied when the window first opened. Black merged the menu and server QuakeC virtual machines for the most part, in preparation for client QuakeC. Fixed a bug that was only allowing one active lightning beam owned by world. Fixed a rare bug where stencil shadow volumes were not projected far enough to reach the light box. Default Offset Mapping off (as it messes up model skins). Black added sv_playerphysicsqc to control whether the qc physics function is called (if it is available). Black added support for loading LNO files produced by fteqcc (for reporting line numbers of QuakeC errors). Black made the server try up to 100 ports above the default (26000) if the default one fails to open, automatically assigning ports when running multiple servers. Added a patch from Christian Holmberg to make XK_section key (I do not know what this is) type ~ character for binds. Removed r_editlights_rtlightssizescale and r_editlights_rtlightscolorscale cvars (now they behave as if they were both 1.0) added r_editlights_edit commands radiusscale sizescale and colorscale (use these to fix old-format .rtlights files). Cured the 'can't bunnyhop' bug. Black added support for [515]'s BX_COLORTEXT extension. (BX = Betwix engine. Fixed crashes after level changes involving lightning bolt models that got unloaded during the level change (was happening often in The Ascension of vigil). Changed server to set self to world before calling SetNewParms qc function (to intentionally crash any broken mods which assume self is valid in that function). Fix a bug with savegames containing line breaks in their titles. Tomaz added gl_picmip (Texture Quality) slider and r_restart button (Renderer Restart) to Graphics Options menu. Tomaz added -demo and -demolooponly options (-demo plays a demo and then quits, -demolooponly stays in the demo loops and only allows the escape key, which quits). Elric added basic support for Q3's ""getstatus"" messages from Q3 server query tools (based on a patch by divVerent). Fixed several issues in filesystem searching functions (now ""dir *.cfg"" should actually report the right files, as well as ""ls maps/*.bsp"" and so on). Fixed a compile problem on Mandriva Linux (patch by Zero_Dogg). Elric added DP_SOUND_API targets (NULL, OSS, ALSA, BSD, WIN, COREAUDIO) in the makefile to allow choosing different sound drivers. No longer averages ping times, just uses the latest ping time (now all the ping numbers are nice round multiples of the server sys_ticrate). Fixed several bugs with prydon cursor tracing (including it constantly reporting world origin as the impact point). Fixed a bug that was causing impulses to lost very often. Now only gives shareware Quake warning if running GAME_NORMAL (Quake). Black added the cvars net_slist_timeout and net_slist_maxtries to query servers multiple times. Server browser now queries servers over time to avoid flooding out requests and getting very bad pings (net_slist_queriespersecond and net_slist_queriesperframe cvars control the rate of queries). EvilTypeGuy added Solaris 10 x86 support. Tomaz revised the embedded font to support all the special Quake font characters. Fixed two severe geometry bugs in the zym loader (which were causing parts of models to not render). Fixed a bug in SDL client which was preventing typing after vid_restart. Fixed some crashes with server commands (kick, view* commands). Fixed an endian swapping issue in Q3BSP loading (so Q3BSP loading now works on Mac). Added somewhat hacky support for Mac OS X .app packaging to allow proper Mac OS X binaries to be made. Fixed bmodel trails (if anyone ever dares to try them) to come from the center of the bmodel, this also cleaned up the sound code (and fixed a weird bug with a sound played in the same frame as an entity is removed). Added DarkPlaces7 network protocol with QW-style local player movement capabilities, warning: this has speedcheat/lagaport potential (and currently no way to force off cl_movement from the server). Added DP_QUAKE3_MAP extension. zym models now support TraceBox calls (bullet tracing among other things). Fix bug with ClientDisconnect not being called if a client drops between ""spawn"" and ""begin"" commands, now it is reliably called. Dhanged default heartbeat_period to 120 seconds so that usually two packets come in before the 5 minute timeout, this should help with packet loss in server heartbeats to the master servers. Fixed bug that rotated all sounds 90 degrees to the right in Nexuiz (because it has seriously messed up player models). Fix portal clipping of lighting in a single cluster map (box map) which has no portals. Fixed snow fluttering so it works properly again. Fixed crashes with .lit files of the wrong size (a start.lit in id1 for instance when running a mod which has its own start.bsp which is not compatible with the start.lit from id1). Fixed envmap command to save the proper skybox layout (matching Quake2). Fixed 64bit compatibility issues in QuakeC VM, so DarkPlaces 64bit builds now work. Completely merged Q1 mdl, Q2 md2, Q3 md3, Nexuiz zym, Q1 BSP, and Q3 BSP rendering, this is a massive code reduction and (more importantly) easier to maintain (which means less bugs). Fixed problems with getting stuck in wedges in maps (by turning off sv_newflymove cvar). Added sv_gameplayfix_blowupfallenzombies and sv_gameplayfix_findradiusdistancetobox cvars (to allow these changes to be disabled). Fixed a bug with dead explosion shells not being removed (resulting in them ceasing to work after a while). Fixed a bug that made menu sounds come from world origin (they are now global). Revised notes in r_shadow.c on Creative Labs' patent on the Carmack's Reverse stencil shadow volume technique. Rewrote scissor calculation to use brush clipping of the light box to determine which part is on screen and restrict rendering more exactly than before. Improved readability of ""memlist all"" reports, they now include the filename/linenumber of each allocation. Cleaned up init process again, now parses configs only once (not twice for video settings and such) and opens video as soon as the first map/startdemos/connect/playvideo/cd play command is executed (connect actually waits until it connects and won't open the window if it fails). Made r_restart/vid_restart reload models as intended. Fixed a bug that made view-attached entities render in third person. SDL builds are now enabled by default in the makefile. Silenced some texture loading warnings in dedicated servers (thanks to Biomass for reporting this). Black changed the SDL window icon back to DP's icon. Black changed commands, cvars and aliases to be sorted by name (for better console listings). Fixed a stupid bug in the te_customflash server qc builtin, it was fading instantly. Fixed a very minor bug in TE_CUSTOMFLASH parsing (forgot to add 1 to radius). Fixed missing gfx/net.lmp warning (and a few others in gfx.wad), they are now accessed properly. Fix a bug that made rtlighting crash (thanks to Vic for reporting this). No longer shows extra time reports in r_speeds report when using r_showtris 1. Added developer_texturelogging cvar (logs all attempts to load images to textures.log, useful for texture replacement projects to know what textures matter to a map). Default DLight shadows on. Fixed a bug where the player would be stuck in place (for a very long time) when going from singleplayer to multiplayer. Added cl_capturevideo_sound cvar (defaulted to 0) to allow enabling/disabling sound saving, with sound disabled you can save videos at a framerate your machine can't maintain (no sound sync to worry about). Fixed bugs that made doors and other pushers ignore some entities. Fixed transparency issues in q3 shader parsing. Fix fogging in hlbsp by clearing view to fog color (since sky polygons are missing in hlbsp). Changed script init in Nexuiz to play the logo video if there's nothing else to do. Changed crosshair mode to static by default (center of screen rather than showing where your shots will hit in the world). Changed in_pitch_min/max defaults to 90 degrees so you can now aim straight up/down (unlike in Quake). Fixed an items parsing bug when playing hipnotic demos. gl_texture_anisotropy now only affects mipmapped textures (should fix issues with lightmaps). Fixed a bug where gl_texturemode was changing textures that aren't supposed to be affected by it. Default to insert mode instead of replace mode in console. Cursoring past the end of the current commandline no longer takes characters from an old commandline. Allow typing international characters in the console (non-ASCII) for mods that use Latin1 fonts rather than quake's white/brown set. Fixed a crash in network parsing when an entity is tagged to an entity that is outside the current range of entities. Fixed a severe server bug affecting frikbots (the engine was running physics code on disconnected clients). Improved compliance with Targa spec in treatment of alpha and colormaps (palettes) in truecolor images - NOTE: this means many Paintshop Pro and Photoshop TGA files are no longer transparent, GIMP knows how to write them properly. Renamed r_shadow_cursor cvars to actually have the word cursor in their name like they were supposed to. Added playerclip and monsterclip brush support for q3bsp levels. Elric added the DP_HALFLIFE_SPRITE extension. Fixed a server bug that was only allowing 256 model animation frames to be used. Reduced client memory usage by 29MB by making cl_max_entities dynamically grow as needed. Elric fixed a number of bugs in the server browser. Elric added Quake2 sprite support (DP_QUAKE2_SPRITE extension). Rewrote server timing code again to make the (evil) host_framerate cvar work again for the game The Ascension Of Vigil. Fix some bugs in HalfLife sprite loading. Black fixed a bug where a server was pinged multiple times for the server list. Added tag attachment support to zym models for Nexuiz (to allow player models to hold weapons, etc). Fixed a bug that messed up the server after a failed level load. Fixed a skybox texture leak on level changes. Disabled item bobbing by default. Changed intermission behavior a bit to allow Nexuiz to freeze the action at level end. Fixed a bug with decals that made them never really disappear. Minor memory reduction in particles (3.8MB down to 3MB for 32768 particles), difficult to trim any more. Added a game mode for The Hunted Chronicles. Early exits (error during startup) no longer save a broken config.cfg. Now searchs for servers on your LAN (using a broadcast message to port 26000 like Quake did). Video capture no longer has 25% sound volume. Added back particles in teleport splash effect. Improved r_texturestats command output (now gives a total for each pool). Default dedicated servers to public (listen servers remain non-public by default as they are usually not professionally hosted). Made the key below escape bindable and like other binds it only works while ingame (Note: you must now hit escape to close the console, I use shift-escape instead). Now pops up the menu at startup if there is nothing to do and no demo loop. Added splashes to rain effect. Added Venim's dpmaster server (now up to 3 masters). Black fixed net_slist command to only print servers once. Added DP_CON_STARTMAP extension which defines two configurable aliases to choose a start map. Now smoothly interpolates weapon recoil (punchangle) in multiplayer. Added key repeat in SDL client. Fixed gl_flashblend so it overrides dynamic lighting (as intended). Fixed issues with r_editlights_edit cubemap command. Fixed bugs with cl_particles_size cvar so it works again. Fixed a bug where vsync was not restored properly after a vid_restart. Black added Quake3 color codes to text printing (console and elsewhere). Reduced quality of Offset Mapping in GLSL light shader to work on ATI Radeon 9500-9800/X300 cards (I hate limits!). Changed q3bsp curve loading slightly to allow finer curves. Skill values outside 0-3 are now allowed (mainly for Transfusion which uses 0-4). Fixed bugs with zoom in Nexuiz (zoom was being applied twice to fov). Now detects and avoids software fallbacks in GLSL shaders (mainly limited ATI Radeon cards). All text file access now supports Mac and Windows line endings consistently, and all text files (config.cfg, savegames, and files written by QuakeC) are now saved in UNIX format. Added documentation on glsl cvars to r_shadow_help. Implemented a GLSL shader per pixel lighting path (enabled by default), it even supports Offset Mapping (aka Parallax Mapping, not as good as Relief Mapping or Virtual Displacement Mapping, but still rather cool in the right situations). Fixed a stupid typo with the cl_netlocalping cvar (it is now in milliseconds as intended). Disable vsync by default. Games now have their own config directories (instead of always being ~/.darkplaces) so that Nexuiz doesn't look in ~/.darkplaces/. Newly spawned projectiles (rockets, etc) no longer appear in midair at low framerates. Fixed some geometry issues with beam polygons (such as the nex beam in nexuiz). Fixed a crash with rtlights outside the level. Added Ludwig Nussel to Thanks to section in readme. Fixed unnecessary warnings about missing skins/frames on q1bsp/q3bsp models. Fixed a rare ""Got signon 1 when at 1"" error in client (still not sure why it gets this however). Elric fixed PK3 and Ogg Vorbis support on NetBSD. Fixed a compile error with snd_alsa.c (patch by Ludwig Nussel). Linux/BSD libz, libvorbis, and libvorbisfile .so names are now versioned so they work without development packages installed (patch by Ludwig Nussel). Added ~/.darkplaces support to the filesystem (patch by Ludwig Nussel). Tomaz fixed more memory leaks. Tomaz added CL_Shutdown to fix 14 memory leaks totalling over 30mb. Updated email address in readme. (thanks to zarquon for pointing out that it was outdated. Black improved server browser to support sorting and filtering. Now saves seta cvars with the seta command and normal ones without it. Elric fixed JPEG and Ogg Vorbis support on Mac OS X, and fixed a big-endian bug in MD3 loading. Black added ""sv_progs"" cvar (default is progs.dat) to allow loading other QuakeC server programs in Nexuiz. Added vsync support for GLX clients using GLX_SGI_swap_control. Black made video playback system able to play multiple videos at once (may be useful to QC menus). Tomaz fixed an issue with sys_ticrate bounds checking which was spamming cvar changed messages in developer mode. Disabled vsync during timedemo. Elric fixed PK3 archive support on Mac OS X. Made sensitivity cvar affect cl_prydoncursor. Added Bloom effect (r_bloom* cvars or use the menu). Renamed cl_stainmapsclearonload to cl_stainmaps_clearonload and made it default to 1 (this should stop the bug reports about stainmaps staying after a reload). Filesystem now checks for attempts to access files outside the Quake directory and rejects them. Fixed a Sys_Error in input message building when connected to a QUAKE protocol server. Elric made DarkPlaces work on Mac OS X. Black added ' quote support in script parsing and elsewhere. Black added NEXUIZ_PLAYERMODEL extension. Elric fixed a HalfLife WAD loading bug in the filesystem code. Fixed animation glitches when weaponmodel changes. Now clears screen at startup so you don't see leftover garbage from the last 3D application. Added PRYDON_CLIENTCURSOR extension to allow FrikaC's Prydon Gate mod to have a clientside mouse pointer (more responsive, even highlights things as you mouse over them). Added DP_BUTTONUSE extension (+use/-use button). Added DP_BUTTONCHAT extension (true while input is not focused on the game). Added back DP_ENT_COLORMOD extension due to popular request (changed to allow colors above '1 1 1' which can brighten models. Upgraded network protocol to DP6 which uses less bandwidth and allows precaching models/sounds during the game (used for player models in Nexuiz). Added sv_gameplayfix_setmodelrealbox cvar which can be set to 0 to improve compatibility with some broken mods (TargetQuake, QuakeRally, probably others). Changed loading plaque to simply be an overlay on the last fram rendered. Added cl_capturevideo_rawyv12 mode (supported by some mpeg tools). Added scr_screenshot_gamma cvar (defaults to 2.2 gamma to make quake's linear color space appear correctly on PC monitors) --- THIS FEATURE IS NOT A BUG. Elric fixed a bug that was making ambient sounds silent. Fixed a bug with invisible dlights in FrikaC's Vile mod. Fixed skybox layout (front and back were swapped, and all other sides were rotated/flipped), now matches Quake2 layout as intended. Fixed Nehahra movie support (again). Fixed a bug that made corpses quickly get up and fall down again in Nexuiz. Reduced cpu use when at cl_maxfps limit. Improved showfps 1 accuracy. Fixed a cpu hogging bug in dedicated servers. Files now override paks, this makes it easier to patch things and is what users expect (however it loads slower). Fixed a rendering crash if unused lightmaps exist in q1bsp. Fixed bug that called PlayerPreThink and PlayerPostThink on unspawned clients. Upgraded rtlights format to have separate ambient, diffuse, and specular intensity scales, and also coronasize, this also allows corona-only lights by setting all scales to 0, and added normalmode/realtimemode flags so that lights can appear in normal mode, not just realtime mode (primarily useful for adding corona effects to a normal level) added ambient light support to RenderLighting (non-bumpmapped diffuse), and some dlights now use ambientscale (this has not been exposed as a qc extension yet, qc lights remain the same). Fixed a nasty bug with bind "";"" in config saving. Removed ""lightmapindex -3"" warning in q3bsp maps compiled with q3map2. Now warns about missing textures in q3bsp maps. Added DP_SV_BOTCLIENT extension to allow bots to spawn as actual players on a server (no more scoreboard hacks!). Q3 alphafunc shaders now render as transparent. VorteX fixed bugs in gettaginfo and gettagindex builtins. Fixed a runaway loop problem in server code if machine is too slow for server. Centerprint can now use full screen size (no longer limited to 40 columns). Added DP_SV_CLIENTCOLORS and DP_SV_CLIENTNAME extensions. Added DP_SV_PING, DP_SV_PUNCHVECTOR, DP_SND_FAKETRACKS, and DP_FS_SEARCH extensions. Added DP_CON_SET and DP_CON_SETA extensions (set and seta commands in console, set creates a cvar, seta creates a saved cvar, or makes one be saved in the future). Black added backslash-"" quoting support in the console and elsewhere. Realtime video capture (see cl_capturevideo cvars, raw yv12 format recommended if you have suitable encoders). Warning: video capture aborts if your machine can't keep up. Rewrote timing code, renamed host_maxfps to cl_maxfps, removed host_minfps, now runs server faster than client if framerate is too low to honor sys_ticrate cvar. Fixed the ""Joe changed name to Joe"" bug. * Improved quake.rc config execution to start a map even if startdemos is not used. Sound loader now supports sounds with and without sound/ directory, to allow mods to support sound and music entities in Quake3 maps. r_editlights mode now shows light number and total lights. Elric fixed a brief sound bug when a new level started. Fixed a rare sound crash that apparently occurs in Fiend Run Lite demos. Don't spam the console with warnings about missing frames and skins in models that failed to load. Elric added FreeBSD support (NetBSD and OpenBSD already supported). Fixed a bug with traceon/traceoff QC builtins not taking effect immediately (for printing Quakec code as it executes). Added DP_SV_DROPCLIENT extension. Fixed a bug that messed up the first scoreboard entry when players left a server. CD track emulation uses 3 digit replacement tracks (id1/sound/cdtracks/track002.ogg and such. Fixed a crash if dlights try to cast shadows when there is no map loaded. Fixed a crash in console logging of a memory corruption (sentinel) error report. RTLights system now supports .ent override files. Fixed a mouse twitch in GLX client after raising/lowering console (mouse grab). Fixed a messagemode/messagemode2 issue in which you could type "";quit"" as a chat message and have your client quit. Fixed an r_restart crash in skybox code. 2005-06-21: New hmap2 release which now works properly when given .map filenames for vis and light stages (which really want .bsp), this should fix problems with the GTKRadiant build menu, hmap has not been fixed (it is obsolete). 2005-03-08: I have moved all download files to the files directory to make beta builds easily accessible (I do not make frequent official releases due to the work involved in making the ""What's new"" descriptions). This breaks any pages directly linking to old betas, please update links to point to the new directory instead. A couple videos of the hard skill hall in start have been added to the screenshots page to demonstrate the darkplaces experience (totally stock data except for a .rtlights file). 2005-01-31: Released new version of lmp2pcx with .tga output, and conversion of .mip files (it already converted .lmp), now also outputs .lmp from gfx.wad images (in summary: wad outputs .mip/.lmp/.bin (depending on lump type) plus .pcx and .tga of each image, lmp and mip output .pcx and .tga of each image). 2005-01-22: Released some old maps (lordhavocmaps.pk3) with source .map files included: ctfgold8 - my map for the CTF Gold pack, designed to be a very linear map from base to base with two paths through the middle area, and a quad to spice things up, the bases are well equipped for prolonged fights, but full of deadly corners which make combat freightening at best in the base itself, the rooftop is relatively safe, and the traps at the sniper outposts are quite an odd touch, it has 1 quad and 2 red armors, 1 yellow armor, 3 rocket launchers, and all the other weapons can also be found, one goal of this map was to be difficult to quickly flag run despite being a small map, but due to the grappling skillz of many this turned out to be one of the fastest flag run maps and spawned a small competition to see the fastest cap possible, the fastest ever recorded on my server was 13 seconds (9 seconds has been reported from singleplayer using slow motion cheats to perfect it exactly, but that doesn't count). lhca1 - a Clan Arena map with a dm3 theme comprised of 3 massive interconnected arenas connected to eachother in a ring fashion with a central hub that was the site of many heated battles as it was smaller than the arenas themselves, the arenas turned out too large scale (Quake rockets aren't that fast), inspired dpdm1 connectivity and design. (previously unreleased). lhdm4 - a DM map I made on request for a DM tourney, very inconsistent connectivity and layout, although varied in theme as well, never got used because it was too small so I expanded it a bit, and then was told it was too large, go figure (previously unreleased). metlhell - a DM map I made very early, far too experimental and I was thinking more in a singleplayer theme when I made it, which resulted in terrible connectivity and lava laden rooms rather than arenas conducive to combat. (previously unreleased). rampcity - a DM map based on a very simple concept, this turned out better than expected, almost infuriatingly difficult vertical combat map, and the first map I ever made in the BSP map editor - still my favorite editor. (previously unreleased). 2004-11-18: New hmap2 release, what's new: Vic sent a patch that checks for incomplete brushes, removes them and prints warnings instead of exiting with a CheckWinding error (Thanks to Tomaz for committing the patch). fixed origin key handling in brush loader, so rotating bmodels should work properly (I hope). added -harshshade option. 2004-10-19: New darkplaces release, what's new: Fixed a number of problems with scoreboard updates (names/colors/frags) in the server. Fixed duplicate name bug in client mini-scoreboard (the one to the right of the statusbar in multiplayer). Tomaz enlarged particle font from 256x256 to 512x512 and added some code to allow saving it to a .tga (and an example one has been posted on the download page). Quitting without using the ""quit"" command in the console now disconnects from the server, and properly kicks off everyone on a local server. Credited romi and |Rain| for their contributions in the readme. Added 32bit color support to SDL builds. 2004-10-17: New darkplaces release, what's new: Rewrote Quake3 curve loading which finally makes maps look correct in all cases. Added DP_QC_GETTAGINFO extension written by VorteX so modders can find out where md3 model tags and attached entities are, thanks VorteX! 2004-10-16: New darkplaces release with various bugfixes, what's new: Now detects a few quake3 shader types to make quake3 maps look mostly correct (additive shaders are detected, as well as autosprite/autosprite2, and twosided shaders, also loads first pass texture if it can't find a texture of the same name as the shader, and transparent textures in quake3 maps now require a shader to indicate they are transparent). Fixed a bug that was preventing dynamic lights from lighting up quake3 maps. Now prints 8 QuakeC opcodes instead of 5 when a crash or warning occurs. MoALTz fixed the r_stereo_separation code so the anaglyph stereo glasses support works properly now. Rewrote chat message handling code to be cleaner. Added DP_LITSPRITES extension string (the feature existed already but was not documented). Fixed connect status messages in join game menu (it was only showing them in server list menu). Simplified cl_net* cvars to just cl_netlocalping and cl_netpacketloss and removed sv_netpacketloss cvars. Made tenebrae light cubemaps work on model entities again (they were being disabled because the requested skin did not exist in the model, so the cubemap was being set to 0). Greatly optimized findradius builtin (it now uses the physics culling data to avoid searching all entities). Removed cl_nodelta cvar as it never worked properly, and is unnecessary with the current network protocol. Fixed a bug that made the game world seem to freeze after a level change in multiplayer (networking was falling apart). Fixed framegroup animation on normal entities (static entities like Quake's torches worked already). Changed movement interpolation a bit to better handle less frequent updates on far away entities. Fixed a ""blue dlight"" bug when a map uses tenebrae dlights but the progs.dat did not support them (it was a silly typo in the engine). Fixed a crash when dedicated servers tried to talk to the players. Fixed a ""blue glow_trail"" bug, it was not properly interpreting the palette color. 2004-10-06: New darkplaces release with various bugfixes, what's new: fixed lingering entities in quake protocol, demos for example added cl_beams_* cvars to effects options menu now can connect to another server while remaining connected to current server up until the connection is accepted now shows loading screen at appropriate times which also stops sound fixed nehahra movie support sprites now support EF_NODEPTHTEST watershader now disabled on lightmapped water now compiles on x86_64 successfully, server still crashes though (will be fixed at some point) added commandline options to readme fixed an entity colormapping bug which caused players to be white in dpmod skybox works in hlbsp again fixed weird player model angles when looking down negative frags display correctly again Mathieu fixed a logging problem which was not recording cvar creation notices to the log Mathieu fixed sound channel volume clipping to work the same on 16bit and 8bit sounds removed detection of GL_NV_vertex_array_range as it's not used added -novideosync disable for WGL swap control fixed qc builtin cvar_string to not crash engine if the cvar does not exist 2004-10-02: New darkplaces mod release: Just added my dpdm1.rtlights file, only of concern to people playing that map. 2004-10-01: New darkplaces release, what's new: It works a LOT better than the previous release, has many more menu options, has a readme, GOOD network performance (smoother than qw, although no prediction or clientside movement) It's just plain better :) Thanks again to Tomaz for his ongoing efforts to beat down the todo list. P.S. Hopefully I won't be so lazy about posting new releases in the future; then again I've said that a few times before. New darkplaces mod release: More of the usual little changes and balance tweaks, got rid of nailgun casings because they looked a bit silly (although cool for making a pile of casings) and dragged down network performance a lot, added back nails sticking in walls though (and you can blast them loose). 2004-09-07: New version dpmaster released: - version 1.5: Address mapping added (see ADDRESS MAPPING in readme) Servers on a loopback address are accepted again if they have a mapping A valid ""infoReponse"" is now rejected if its challenge has timed out The size of the challenge sent with ""getinfo"" has been made random A timed-out server is now removed as soon as a new server needs a slot Several little changes in the printings to make them more informative A technical documentation was added Compiling dpmaster with MSVC works again 2004-08-31: Fixed link to download hmap2, sorry about that. Thanks to Gleeb for reporting this. 2004-08-27: Updated sv_user.qc with bugfixes supplied by Sajt, it no longer moves slower when looking up/down, pitch no longer affects swim up/down when underwater, and FL_ONGROUND is cleared when noclipping or swimming, thanks Sajt! 2004-08-12: First release of hmap2, a combined hqbsp/hvis/hlight/bsp2prt/bspinfo utility written by Vic based on hmap, and with further additions by me, tyrlite compatible (hlight lighting no longer supported, sorry), compiles q1/hammer/q2/q3/doom3 .map files (bp texturing not supported in q3 map files, texturing not properly supported in doom3 map files which use bp texturing exclusively). 2004-05-21: Tomaz changed the website layout and cleaned it up to use css. Thanks Tomaz! Posted a new litsupport zip updated by Tomaz to fix a few minor things (no actual bugs, just passing one parameter too many to a function, and fixed some begin/end comments). 2004-05-20: Changed email address because my telefragged account stopped working (and I don't think I can get it back, I have no telefragged site), I was also getting 10 spams a day, and telefragged has ssslllooowww email (300 spams downloaded in 15 minutes)... So my email has changed, and is no longer a simple email link to confuse spammers. (Yes there's still a new build in the works, it is delayed until I rewrite the networking to fix an annoying bug) 2004-01-28: romi has completed his .rtlights file collection for Quake Mission Pack 1: Scourge of Armagon (also known as hipnotic), and for those not aware of his Quake .rtlights file collection as well, I recommend it :) romi also has some videos in the works to show his lighting creations better than the screenshots do. (If anyone doesn't remember, to experience an rtlights file it must be placed in the maps directory, make sure in the Video Options menu that you are in 32bit color mode (sorry this can't be done on a 3Dfx Voodoo1/2/3/Rush/Banshee), load up the map you want, and then simply type r_shadow_realtime_world 1 in the console, enjoy. Maps without rtlights files are often slower and less colorful.) 2004-01-17: U8Poo has sent a nice screenshot running of realtime lighting mode in a q3bsp map he made, to spice up the screenshots section, thanks! In other news another release is still in the works (as expected), already fixed some significant physics bugs (which date back to july) but for some reason still am not quite in the mood to release it. 2003-12-07: Another new engine release (20031207b): Added r_wateralpha cvar to the effects options menu. New engine release: No longer limits framerate to 20fps while in console because I got so many complaints about this (no REALLY that was not a bug like everyone assumes, that was a feature, just a very misunderstood one), so now it only drops to 20fps when not the active window (it already did this). Changed hardware gamma handling in glx to no longer turn on/off based on mouse being in the window or not, but simply whether it is the active window. Fixed 16bit video modes in Linux support. (oww this was broken, I only use 32bit :) Fixed a bug with console parsing that existed in almost all versions of quake except quakeworld by switching to the qwcl COM_Parse for console parsing (in english: fixed connect commands involving a port, like 127.0.0.1:26000), thanks very much to Fuh for mentioning this bug. Removed need for gfx/menuplyr.lmp, some old unused code required it, no idea why that was still there (in english: this has no importance to quake players, only modders making standalone stuff). 2003-11-30: Due to popular demand I put up some new screenshots of qe1 textures in e1m1 running realtime lighting mode. 2003-11-29: New engine release, now parses scripts/*.shader files (including inside pak/pk3 archives) when loading q3bsp maps to check for surfaceparms (nodraw and trans and such) this fixed up q3bsp rendering a bit (at least in the sense that transparent textures for tricky opaque shaders are now rendered opaque). Another new engine release, now uses the surfaceflags inside the q3bsp for all flags it can (transparency is still read from shader surfaceparms as there is no surfaceflag for it), this may or may not affect anyone but it's more correct. 2003-11-19: New engine release, this fixes the bullet holes in Scourge of Armagon (and any other mods using oriented sprites). New hmap release with some enhancements by Vic: hqbsp now properly calculates node bounding boxes making them much smaller for non-axial planes (this means maps run faster in engines other than darkplaces; darkplaces already did this on loading) detects and skips degenerate edges corrected CheckWindingArea for portals area checking precise .prt files output (may fix some vis errors on complex maps) New dpmaster release from Elric, this fixes two buffer overflow vulnerabilities so anyone hosting a dpmaster master server should update. Here's the readme's words on the matter: - version 1.3.1:   SECURITY WARNING: 2 exploitable buffer overflows were fixed   Verbose option parsing fixed   Paranoid buffer overflow checkings added, in case of future code changes 2003-11-18: New engine release, this one has a few known bugs (short summary: rtlights don't handle animated textures or water motion) but fixes enough very annoying bugs to warrant a new release anyway, and adds some features, such as: Quake3 BSP file loading with rtlight support. (rtlight editing note: q3map2 and probably q3map itself, remove light entities when compiling, so don't expect any lights until you add some) Now defaults to 32bit color (I think this will still work on 3Dfx because I know they support 32bit screen modes with 16bit rendering) and stencil is now automatically enabled on 32bit color modes. Added r_editlights_help and r_shadow_help commands to give some information so people don't have to ask me about these subsystems. Added a lot of QuakeC builtin error checking regarding bogus entities being passed in (like trying to copyentity to/from world for example, or a free entity). Input sticking through a level change has been fixed! (thanks very much to Black for his work on this and other bugfixes in the input system :) Now supports non-QWERTY keyboards in windows (it already supported them in Linux). (thanks to Black and Mercury for their combined work on this) Added Anisotropic Filter setting to menu. (thanks to zinx for coding this, note: use r_restart to reload textures to make it take effect) DirectSound should work in windows again (been a long time since this worked because of DirectSound strangely needing an open window) so the sound rate has been bumped to 44khz (44khz ran into issues with many drivers with no window open) and the sound system is restarted by snd_restart or vid_restart (due to the window). Note: q3bsp support has NO SHADERS, this was meant for mods to use, not to play existing maps (which often have very odd alpha textures for shader effects), and as yet has no global fog support or volumetric fog support because of lacking shaders, and there are no plans to add q3 shader support because they are quite incompatible with rtlights. I would also like to announce that a new member called Black has joined the darkplaces team, and has been contributing a great deal of effort on the QuakeC subsystems (as well as bugfixes particularly in the input subsystems), he has been working hard on a QuakeC menu system (still experimental), and then after that, clientside QuakeC can begin to expand the horizons for quake mods :) New mod release, this one doesn't really fix many bugs to my knowledge (probably introduces a few), but contains a new weapon management system that allows more weapons than quake ever had, so now for example you can shoot an enforcer and grab a laser rifle from the backpack (being unable to use certain monster weapons like this always irritated me), note: laser rifle is a second weapon on impulse 3, and there is an experimental 'plasma shotgun' on impulse 2 which needs cells as well as shells. 2003-07-27: New engine release, hopefully this finally fixes the 'doesn't work through NAT routers' problem (also known as DSL routers, cable modem routers, etc) by reducing the connection packet size (it is once again split up like netquake did). New mod release, intended to fix some bugs that popped up such as backpacks giving no ammo, and other inventory glitches. 2003-07-18: New engine and mod release, the engine should fix a few bugs, and the mod reverts the Fury to Quad and allows ""coop"" difficulty settings to be changed during the game (coop controls monster health scale), but is otherwise mostly the same as the version released on the DarkPlaces booth at QExpo, and I also posted the versions (including Revelation) that were released on the booth, for completeness. 2003-06-30: New hmap release adding support for HalfLife WorldCraft texture alignment (as requested by FrikaC). 2003-06-15: Updated sv_user.qc to fix the name of the cl_rollangle variable (apparently I typed cl_rollspeed for some reason originally), sorry about that. Thanks to Electro for reporting this. 2003-06-10: New lhfire release: Added spritetype command (to allow types other than vp_parallel, like oriented for example) Documented spritetype command Documented worldbox command (which was not previously documented) 2003-06-09: Fixed the download link for hmap build 20030607, note to self: do not release in a hurry with no time to test links. Fixed the download link for darkplaces mod build 20030607, sorry about that being broken before! 2003-06-07: Another new release of darkplaces, changes: Fixed savegame loading crash someone reported a few days ago (thanks for reporting it). Fixed a SOLID_BSP with non-BSP model error that often occurred after Host_Error (this one's been tormenting me for ages). New release of darkplaces, dpmod, dpmaster, hmap, lhfire, lmp2pcx. No information because I can't remember what changed since the last versions, however I do remember there were important bugfixes in hmap and dpmaster, and many changes in darkplaces and dpmod. I really should set up nightly builds or something as most of these changes are quite old but never made it into builds until now. I hope these new builds are useful (and as always feel free to email me with suggestions/bug reports). 2003-04-08: New darkplaces release, changes are: loading saved games should work again playing dpv video streams should work again added DP_QUAKE3_MODEL extension for mods to check for 2003-04-06: New darkplaces release, changes are: fixed savegame menu so it displays saved games again (thanks to the two people who reported this bug - yes your saves are fine, it just wasn't showing them). split r_shadow_realtime into cvars r_shadow_realtime_world (requires stencil) and r_shadow_realtime_dlight (which does not require stencil, and infact works on a voodoo (but it's ugly) or decently on voodoo 2) and r_shadow_visiblevolumes. PK3 archive support and jpeg texture and screenshot support (scr_screenshot_jpeg 1), HUGE thanks to Elric of the Transfusion project for these features! 2003-04-03: New darkplaces release. Some of the new features I can remember: Color Control Options, hardware gamma now works in Linux, .viewmodelforclient now works (useful for modders), should be able to connect through NAT (such as Linux ipmasq, ADSL routers, etc), FrikaC's file access and string handling extension FRIK_FILE has been added, more extensions added for some effects that have been around for quite a while. Thank/blame diGGer for pestering me to release this new version (his mod needs it), I wanted to upgrade the entity protocol (to implement ""rate"" limiting for modemers - or people trying to play helm18) and bugtest for a few days, but here it is without either rate or bugtesting :) 2003-03-29: New dpmaster release, major bugfix (no longer locks up after running for a very long time when someone asks for a server list, encountered this on my own dpmaster), thanks Elric! 2003-03-12: New dpmaster release, offering nice improvements (such as an extra-secure daemon mode on UNIX/Linux and improved commandline options), thanks Elric! 2003-03-01: New engine release to fix bugs with using OgrO's model skins (for example the models are no longer invisible) and changed gloss brightness from external textures to mimic tenebrae (this is sad because I would imagine doom3 will not have a 25% brightness hack). New engine release (yes it hasn't even been months since the last one!), MAJOR improvements to realtime lighting consistency and correctness (even added back 3D attenuation texture use on supporting hardware), also fixed a graphical bug with the Chthon lightning trap in e1m7 (it now looks like in quake, no polygon lightning falling short of the end nonsense). 2003-02-26: New engine release to fix realtime lighting mode on non-NVIDIA cards (* LordHavoc slaps self for using GL_CLAMP when he knew better), no other changes. New engine, mod, and dpmaster releases, sorry very little explanation on these, I'm in a bit of a hurry (as usual). The new engine release fixes a lot of very annoying bugs in 20021103, and should improve performance all-round (especially in realtime shadowing mode), and can cope with totally insane mods (at least as entity limits go). The mod includes some weapon changes and new rtlights files for various id maps. Some features in the works for next release: rate limiting (this is mainly for sake of making banshee's helm18 (and successive maps) not croak if you spawn in the middle of 10000 knights), more realtime shadowing optimizations (must... make... it... faster!), hopefully more goodies 2002-11-29: I really should have released these rtlights files much earlier (they are dated 2002-11-17) but here they are, rtlights for most of e1 (start, e1m1, e1m2, e1m3, e1m4, e1m5, e1m6, e1m7, and dm6 thrown in), also available on the download page. Note: dm6 actually runs fairly quick in realtime mode for me, amazing :) Next engine release still under development, it will have light reduction support so you can make the map a little darker for performance (better results can be had by manually relighting it with r_editlights mode though), md3 model support, qe1m1 texture support (qe1m1 uses some paletted and greyscale targas), and some optimizations (to both normal rendering mode and realtime). 2002-11-14: Decided to post some new pics of realtime shadowing mode in the screenshots section, and here's two pics 1 2 of dpdm2 soaked in blood from a game of deathmatch 7 in dpdm2 last night... Much fun was had. Still experimenting with the new charge-up plasma rifle utilized so effectively by SSJ4-Death and others in that game last night. Discovered a few bugs too, which I need to fix (teleporting fiends being the most annoying). 2002-11-03: New engine release 20021103, greatly improved and optimized r_shadow_realtime mode, ingame light editing (r_editlights 1, and r_editlights_* cvars/commands - I should write up a guide for doing this, it's not simple to explain, one tip though: r_editlights_edit and r_editlights_spawn use this list of parameters - radius red green blue style - and you do not need to type the whole set of them, for example 200 makes a normal white light, and 200 0.5 makes a dim white light), also note this fixes all Geforce2 compatibility problems (just make sure you're using vid_bitsperpixel 32 and vid_stencil 1), if you want to force gloss on type r_shadow_gloss 2 (looks cheesy in my opinion and is a slowdown, but useful for benchmarking in comparison to tenebrae), also note this release is CPU limited on my tbird 900mhz, I need to optimize the model lighting more (caching bumpmapping info). Oh and a note, this probably makes normal rendering mode even slower, sorry about that, I need to re-optimize the normal mode. Here's my .rtlights files for start and e1m1 respectively (these were made solely with r_editlights commands), drop them in your id1/maps directory to get a performance boost, a bit of extra realism, and colored lighting. note: these files only affect r_shadow_realtime mode. 2002-10-31: Since some people keep telling me I need to post pics to prove that darkplaces is doing the whole doom3 rendering thing, here are some pics taken in e1m2 with exagerated bumpmap settings (and gloss forced on): 1: gloss, nogloss 2: gloss 3: gloss 2002-10-28: A new pic of r_shadow_realtime 1 mode in start (relit by hand) with scissor clipping working (gives about a 20-60% speed gain), mostly just working on speeding it up and fixing any bugs I can find (only one persists and it's rare, I don't understand it yet, and it may be related to the map loading bug (which seems to only occur with gcc 2.95.3, not with VC++) I've been trying to hunt down for months), finally DP's realtime lighting mode is CPU limited by my athlon 900mhz instead of fillrate limited by my Geforce4 Ti4200 :) 2002-10-24: A new pic of r_shadows 3 mode in e1m1 (relit by hand) with gloss working, reminds me of a sunset on water, not sure how soon the next release will be. 2002-10-20: A new pic of r_shadows 3 mode in dpdm2 (yes the map with 116 enormous lights in one room with ridiculous poly count) taken toward the end of dpdemo2 posted here, I've more than tripled the performance of r_shadows 3 mode with some new code, not sure how soon the next release will be however, and it's still not very playable even in more sane maps than dpdm2. 2002-10-19: Thanks to John Truex for hosting a master server on his cable, anyone who wishs to use it (as a client or server) should use a command like this: sv_master1 68.102.242.12 I will be adding it to the next release as sv_masterextra1. (which will not be saved to config, sv_master1, 2, 3, and 4 settings are saved to config so I can't just change them as they would not take effect for most people) I will also be adding a cvar sv_public which defaults to 0, set it to 1 to have your server show up on master servers. In other news, anyone trying out r_shadows 3 who suffers from severe slowness on their Geforce2 (or crashing - that's a driver bug, not my fault) or similar, try r_light_quality 0. This is a temporary workaround for the fact it's detecting 3D texture support (albeit software emulated), I'll fix this in the next release. 2002-10-16: New engine release: fix for crash when starting r_shadows 3 mode, MSVC's stack space is truly pathetic... New engine release: many bugfixes and r_shadows 3 mode now works correctly (except for a few shadow bugs I have not figured out yet) and looks great, it also now works on Geforce 2 class hardware (it's still horribly slow though), now includes both mingw (darkplaces-mingw.exe) and msvc (darkplaces.exe) builds of the engine because the mingw builds (which all builds this year have been) have a lot of strange crashs I have not been able to find (this irritates me a great deal because the same errors occur in Linux gcc 2.95.3), also now uses a specially constructed infinite farclip matrix (got the code from tenebrae), I hope this works with all drivers, if it does not work for someone please email me about it. New dpmaster release: now has commandline options, and some bugfixes, thanks again Elric :) Took another picture of the in-development realtime lighting mode, this one is more recent and shows off the fact I have bumpmapping working, and much less obviously the fact I have Geforce2 support working (the lowest card this mode supports). 2002-10-14: Took some pictures of the in-development realtime lighting mode. Here, Here, and Here. (yes I will be making it faster, it's currently unplayable, also currently requires a Geforce3 or Radeon 8500 class card because it relies on quadtexture) 2002-10-12: Emailed John Carmack about merging attenuation and normalization (for per pixel lighting and bumpmapping) into one texture, his reply is here. 2002-10-06: New engine, very minor update to try to make 3D texture support work with drivers that don't report GL_EXT_texture3D (strangely GF2 drivers don't? I would think they would... very odd) by checking for the OpenGL 1.2 built in support for 3D textures. (This only matters to those uncontrollably curious people who want to try r_shadows 3) New engine 20021006, fixes the numerous map/changelevel/restart/load bugs in the previous release (that release was embarassing). Full dynamic shadowing in development. I advise no one try r_shadows 3 unless they are uncontrollably curious, it is very incomplete/useless/etc (and really only works in hlight maps like dpdm1 - which is pathetically slow), you have been warned. 2002-09-28: New engine, now has ingame video mode switching (vid_restart and various vid_ variables), and the 2D renderer now uses the 3D renderer (this may work around bugs in some drivers), explosions now have sparks. (Technical note to engine coders: cl_particles.c is intended to be reasonably easy to drop into glquake engines (rename it to r_part.c and add #define WORKINGLQUAKE to the top, some other pieces of glquake need to be altered to use the new functions, requires programming knowledge). New mod, rocket launcher's altfire now fires spiraling rockets, a few bugfixes and cleanups elsewhere (can't remember them). 2002-09-24: New engine, now has an internet master server browser (net_inetslist command or use the menu), rendering has been a lot faster, and the spark effects look better now. New mod, bots can play any simple map (they're idiots around liquids, doors, etc), weapons changed a bit (pistol now has an altfire for rapid fire, plasma gun changed a bit and now fires 8 shots at once when sniping (doubling the damage), grenade launcher now fires impact and proximity grenades (detonate is gone), rocket launcher can load multiple rockets with it's altfire (detonate is gone)), and various little bugfixes. Please someone host a master server and tell me the IP so I can add it to the default master server list. 2002-09-20: The website returns, on it's new home at . Unfortunately the most recent release I've made is an old version (20020831), I'll try to find the time to make a new release someday soon."	"null"	"null"	"A modified version of the Quake2 engine. only."	"true"
"Engines"	"ioquake3"	"https://github.com/ioquake/ioq3"	"The Quake3 engine, freed at last. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"544"	"96"	"701"	"GitHub - ioquake/ioq3: The ioquake3 community effort to continue supporting/developing id's Quake III Arena Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 96 Star 544 Fork 701 ioquake/ioq3 forked from id-Software/Quake-III-Arena Code Issues 23 Pull requests 19 Pulse Graphs The ioquake3 community effort to continue supporting/developing id's Quake III Arena http://www.ioquake3.org/ 2,831 commits 1 branch 0 releases Fetching contributors C 96.1% C++ 1.8% Makefile 0.4% HTML 0.4% GLSL 0.3% Assembly 0.3% Other 0.7% C C++ Makefile HTML GLSL Assembly Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request #192 Compare This branch is 2830 commits ahead of id-Software:master. Latest commit ebc7894 Jul 11, 2016 SmileTheory committed on GitHub Fix OpenGL2 readme missing text in md Permalink Failed to load latest commit information. code Fix bot team order to kill last player it killed Jul 11, 2016 misc Include SDL2 dll from repository in NSIS installer May 27, 2016 ui Properly fill in occurances of ""foobar"" in GPL file headers, patch by… Jun 6, 2011 .gitignore Erroneously removed that line in .gitignore Jun 15, 2016 .travis.yml Make travis do all the builds again Dec 28, 2014 BUGS Lets actually make sure the people that don't read anything but this … Jan 11, 2006 COPYING.txt remove svn:executable property Aug 28, 2005 ChangeLog REFACTOR [a vs an] Jun 18, 2012 Makefile Make using Yacc optional, disabled by default Jul 11, 2016 NOTTODO This is moved as well. Jun 30, 2008 README.md Make using Yacc optional, disabled by default Jul 11, 2016 TODO Remove TODO, point to the internet so I don't waste ci's. Jun 30, 2008 id-readme.txt * Removed advertising clause from BSD license as per mailing list dis… Jan 18, 2006 jenkins-ci-build.sh Only run scan-build on one of the clang builds Aug 28, 2014 make-macosx-app.sh Fix 'Invalid architecture' message in make-macosx-app.sh Jul 26, 2015 make-macosx-ub.sh Remove 5 unused variables from make-macosx scripts Aug 4, 2013 make-macosx.sh Remove 5 unused variables from make-macosx scripts Aug 4, 2013 md4-readme.txt Fix typo Jun 21, 2010 opengl2-readme.md Fix OpenGL2 readme missing text in md Jul 11, 2016 travis-ci-build.sh Try to fix Travis CI MinGW builds May 19, 2014 voip-readme.txt - Apply parts of Ben Millwood's target bitfield patch (#3787) Jul 27, 2011 README.md                ,---------------------------------------.                |   _                     _       ____  |                |  (_)___  __ _ _  _ __ _| |_____|__ /  |                |  | / _ \/ _` | || / _` | / / -_)|_ \  |                |  |_\___/\__, |\_,_\__,_|_\_\___|___/  |                |            |_|                        |                |                                       |                `---------- http://ioquake3.org --------'  The intent of this project is to provide a baseline Quake 3 which may be used for further development and baseq3 fun. Some of the major features currently implemented are: SDL backend OpenAL sound API support (multiple speaker support and better sound quality) Full x86_64 support on Linux VoIP support, both in-game and external support through Mumble. MinGW compilation support on Windows and cross compilation support on Linux AVI video capture of demos Much improved console autocompletion Persistent console history Colorized terminal output Optional Ogg Vorbis support Much improved QVM tools Support for various esoteric operating systems cl_guid support HTTP/FTP download redirection (using cURL) Multiuser support on Windows systems (user specific game data is stored in ""%APPDATA%\Quake3"") PNG support Many, many bug fixes The map editor and associated compiling tools are not included. We suggest you use a modern copy from http://icculus.org/gtkradiant/. The original id software readme that accompanied the Q3 source release has been renamed to id-readme.txt so as to prevent confusion. Please refer to the web-site for updated status. More documentation is on: http://wiki.ioquake3.org/ Compilation and installation For *nix Change to the directory containing this readme. Run 'make'. For Windows, Please refer to the excellent instructions here: http://wiki.ioquake3.org/Building_ioquake3 For Mac OS X, building a Universal Binary Install MacOSX SDK packages from XCode. For maximum compatibility, install MacOSX10.4u.sdk and MacOSX10.3.9.sdk, and MacOSX10.2.8.sdk. Change to the directory containing this README file. Run './make-macosx-ub.sh' Copy the resulting ioquake3.app in /build/release-darwin-ub to your /Applications/ioquake3 folder. Installation, for *nix Set the COPYDIR variable in the shell to be where you installed Quake 3 to. By default it will be /usr/local/games/quake3 if you haven't set it. This is the path as used by the original Linux Q3 installer and subsequent point releases. Run 'make copyfiles'. It is also possible to cross compile for Windows under *nix using MinGW. Your distribution may have mingw32 packages available. On debian/Ubuntu, you need to install 'mingw-w64'. Thereafter cross compiling is simply a case running 'PLATFORM=mingw32 ARCH=x86 make' in place of 'make'. ARCH may also be set to x86_64. The following variables may be set, either on the command line or in Makefile.local:   CFLAGS               - use this for custom CFLAGS   V                    - set to show cc command line when building   DEFAULT_BASEDIR      - extra path to search for baseq3 and such   BUILD_SERVER         - build the 'ioq3ded' server binary   BUILD_CLIENT         - build the 'ioquake3' client binary   BUILD_BASEGAME       - build the 'baseq3' binaries   BUILD_MISSIONPACK    - build the 'missionpack' binaries   BUILD_GAME_SO        - build the game shared libraries   BUILD_GAME_QVM       - build the game qvms   BUILD_STANDALONE     - build binaries suited for stand-alone games   SERVERBIN            - rename 'ioq3ded' server binary   CLIENTBIN            - rename 'ioquake3' client binary   USE_RENDERER_DLOPEN  - build and use the renderer in a library   USE_YACC             - use yacc to update code/tools/lcc/lburg/gram.c   BASEGAME             - rename 'baseq3'   BASEGAME_CFLAGS      - custom CFLAGS for basegame   MISSIONPACK          - rename 'missionpack'   MISSIONPACK_CFLAGS   - custom CFLAGS for missionpack (default '-DMISSIONPACK')   USE_OPENAL           - use OpenAL where available   USE_OPENAL_DLOPEN    - link with OpenAL at runtime   USE_CURL             - use libcurl for http/ftp download support   USE_CURL_DLOPEN      - link with libcurl at runtime   USE_CODEC_VORBIS     - enable Ogg Vorbis support   USE_CODEC_OPUS       - enable Ogg Opus support   USE_MUMBLE           - enable Mumble support   USE_VOIP             - enable built-in VoIP support   USE_INTERNAL_LIBS    - build internal libraries instead of dynamically                          linking against system libraries; this just sets                          the default for USE_INTERNAL_SPEEX etc.                          and USE_LOCAL_HEADERS   USE_INTERNAL_SPEEX   - build internal speex library instead of dynamically                          linking against system libspeex   USE_FREETYPE         - enable FreeType support for rendering fonts   USE_INTERNAL_ZLIB    - build and link against internal zlib   USE_INTERNAL_JPEG    - build and link against internal JPEG library   USE_INTERNAL_OGG     - build and link against internal ogg library   USE_INTERNAL_OPUS    - build and link against internal opus/opusfile libraries   USE_LOCAL_HEADERS    - use headers local to ioq3 instead of system ones   DEBUG_CFLAGS         - C compiler flags to use for building debug version   COPYDIR              - the target installation directory   TEMPDIR              - specify user defined directory for temp files  The defaults for these variables differ depending on the target platform. Console New cvars   cl_autoRecordDemo                 - record a new demo on each map change   cl_aviFrameRate                   - the framerate to use when capturing video   cl_aviMotionJpeg                  - use the mjpeg codec when capturing video   cl_guidServerUniq                 - makes cl_guid unique for each server   cl_cURLLib                        - filename of cURL library to load   cl_consoleKeys                    - space delimited list of key names or                                       characters that toggle the console   cl_mouseAccelStyle                - Set to 1 for QuakeLive mouse acceleration                                       behaviour, 0 for standard q3   cl_mouseAccelOffset               - Tuning the acceleration curve, see below    in_joystickUseAnalog              - Do not translate joystick axis events                                       to keyboard commands    j_forward                         - Joystick analogue to m_forward,                                       for forward movement speed/direction.   j_side                            - Joystick analogue to m_side,                                       for side movement speed/direction.   j_up                              - Joystick up movement speed/direction.   j_pitch                           - Joystick analogue to m_pitch,                                       for pitch rotation speed/direction.   j_yaw                             - Joystick analogue to m_yaw,                                       for yaw rotation speed/direction.   j_forward_axis                    - Selects which joystick axis                                       controls forward/back.   j_side_axis                       - Selects which joystick axis                                       controls left/right.   j_up_axis                         - Selects which joystick axis                                       controls up/down.   j_pitch_axis                      - Selects which joystick axis                                       controls pitch.   j_yaw_axis                        - Selects which joystick axis                                       controls yaw.    s_useOpenAL                       - use the OpenAL sound backend if available   s_alPrecache                      - cache OpenAL sounds before use   s_alGain                          - the value of AL_GAIN for each source   s_alSources                       - the total number of sources (memory) to                                       allocate   s_alDopplerFactor                 - the value passed to alDopplerFactor   s_alDopplerSpeed                  - the value passed to alDopplerVelocity   s_alMinDistance                   - the value of AL_REFERENCE_DISTANCE for                                       each source   s_alMaxDistance                   - the maximum distance before sounds start                                       to become inaudible.   s_alRolloff                       - the value of AL_ROLLOFF_FACTOR for each                                       source   s_alGraceDistance                 - after having passed MaxDistance, length                                       until sounds are completely inaudible   s_alDriver                        - which OpenAL library to use   s_alDevice                        - which OpenAL device to use   s_alAvailableDevices              - list of available OpenAL devices   s_alInputDevice                   - which OpenAL input device to use   s_alAvailableInputDevices         - list of available OpenAL input devices   s_sdlBits                         - SDL bit resolution   s_sdlSpeed                        - SDL sample rate   s_sdlChannels                     - SDL number of channels   s_sdlDevSamps                     - SDL DMA buffer size override   s_sdlMixSamps                     - SDL mix buffer size override   s_backend                         - read only, indicates the current sound                                       backend   s_muteWhenMinimized               - mute sound when minimized   s_muteWhenUnfocused               - mute sound when window is unfocused   sv_dlRate                         - bandwidth allotted to PK3 file downloads                                       via UDP, in kbyte/s    com_ansiColor                     - enable use of ANSI escape codes in the tty   com_altivec                       - enable use of altivec on PowerPC systems   com_standalone (read only)        - If set to 1, quake3 is running in                                       standalone mode   com_basegame                      - Use a different base than baseq3. If no                                       original Quake3 or TeamArena pak files                                       are found, this will enable running in                                       standalone mode   com_homepath                      - Specify name that is to be appended to the                                       home path   com_legacyprotocol                - Specify protocol version number for                                       legacy Quake3 1.32c protocol, see                                       ""Network protocols"" section below                                       (startup only)   com_maxfpsUnfocused               - Maximum frames per second when unfocused   com_maxfpsMinimized               - Maximum frames per second when minimized   com_busyWait                      - Will use a busy loop to wait for rendering                                       next frame when set to non-zero value   com_pipefile                      - Specify filename to create a named pipe                                       through which other processes can control                                       the server while it is running.                                       Nonfunctional on Windows.   com_gamename                      - Gamename sent to master server in                                       getservers[Ext] query and infoResponse                                       ""gamename"" infostring value. Also used                                       for filtering local network games.   com_protocol                      - Specify protocol version number for                                       current ioquake3 protocol, see                                       ""Network protocols"" section below                                       (startup only)    in_joystickNo                     - select which joystick to use   in_availableJoysticks             - list of available Joysticks   in_keyboardDebug                  - print keyboard debug info    sv_dlURL                          - the base of the HTTP or FTP site that                                       holds custom pk3 files for your server   sv_banFile                        - Name of the file that is used for storing                                       the server bans    net_ip6                           - IPv6 address to bind to   net_port6                         - port to bind to using the ipv6 address   net_enabled                       - enable networking, bitmask. Add up                                       number for option to enable it:                                       enable ipv4 networking:    1                                       enable ipv6 networking:    2                                       prioritise ipv6 over ipv4: 4                                       disable multicast support: 8   net_mcast6addr                    - multicast address to use for scanning for                                       ipv6 servers on the local network   net_mcastiface                    - outgoing interface to use for scan    r_allowResize                     - make window resizable   r_ext_texture_filter_anisotropic  - anisotropic texture filtering   r_zProj                           - distance of observer camera to projection                                       plane in quake3 standard units   r_greyscale                       - desaturate textures, useful for anaglyph,                                       supports values in the range of 0 to 1   r_stereoEnabled                   - enable stereo rendering for techniques                                       like shutter glasses (untested)   r_anaglyphMode                    - Enable rendering of anaglyph images                                       red-cyan glasses:    1                                       red-blue:            2                                       red-green:           3                                       green-magenta:       4                                       To swap the colors for left and right eye                                       just add 4 to the value for the wanted                                       color combination. For red-blue and                                       red-green you probably want to enable                                       r_greyscale   r_stereoSeparation                - Control eye separation. Resulting                                       separation is r_zProj divided by this                                       value in quake3 standard units.                                       See also                                       http://wiki.ioquake3.org/Stereo_Rendering                                       for more information   r_marksOnTriangleMeshes           - Support impact marks on md3 models, MOD                                       developers should increase the mark                                       triangle limits in cg_marks.c if they                                       intend to use this.   r_sdlDriver                       - read only, indicates the SDL driver                                       backend being used   r_noborder                        - Remove window decoration from window                                       managers, like borders and titlebar.   r_screenshotJpegQuality           - Controls quality of jpeg screenshots                                       captured using screenshotJPEG   r_aviMotionJpegQuality            - Controls quality of video capture when                                       cl_aviMotionJpeg is enabled   r_mode -2                         - This new video mode automatically uses the                                       desktop resolution.  New commands   video [filename]        - start video capture (use with demo command)   stopvideo               - stop video capture   stopmusic               - stop background music   minimize                - Minimize the game and show desktop   togglemenu              - causes escape key event for opening/closing menu, or                             going to a previous menu. works in binds, even in UI    print                   - print out the contents of a cvar   unset                   - unset a user created cvar    banaddr <range>         - ban an ip address range from joining a game on this                             server, valid <range> is either playernum or CIDR                             notation address range.   exceptaddr <range>      - exempt an ip address range from a ban.   bandel <range>          - delete ban (either range or ban number)   exceptdel <range>       - delete exception (either range or exception number)   listbans                - list all currently active bans and exceptions   rehashbans              - reload the banlist from serverbans.dat   flushbans               - delete all bans    net_restart             - restart network subsystem to change latched settings   game_restart <fs_game>  - Switch to another mod    which <filename/path>   - print out the path on disk to a loaded item    execq <filename>        - quiet exec command, doesn't print ""execing file.cfg""    kicknum <client number> - kick a client by number, same as clientkick command   kickall                 - kick all clients, similar to ""kick all"" (but kicks                             everyone even if someone is named ""all"")   kickbots                - kick all bots, similar to ""kick allbots"" (but kicks                             all bots even if someone is named ""allbots"")    tell <client num> <msg> - send message to a single client (new to server)    cvar_modified [filter]  - list modified cvars, can filter results (such as ""r*""                             for renderer cvars) like cvarlist which lists all cvars  README for Developers pk3dir ioquake3 has a useful new feature for mappers. Paths in a game directory with the extension "".pk3dir"" are treated like pk3 files. This means you can keep all files specific to your map in one directory tree and easily zip this folder for distribution. 64bit mods If you wish to compile external mods as shared libraries on a 64bit platform, and the mod source is derived from the id Q3 SDK, you will need to modify the interface code a little. Open the files ending in _syscalls.c and change every instance of int to intptr_t in the declaration of the syscall function pointer and the dllEntry function. Also find the vmMain function for each module (usually in cg_main.c g_main.c etc.) and similarly replace the return value in the prototype with intptr_t (arg0, arg1, ...stay int). Add the following code snippet to q_shared.h: #ifdef Q3_VM typedef int intptr_t; #else #include <stdint.h> #endif  Note if you simply wish to run mods on a 64bit platform you do not need to recompile anything since by default Q3 uses a virtual machine system. Creating mods compatible with Q3 1.32b If you're using this package to create mods for the last official release of Q3, it is necessary to pass the commandline option '-vq3' to your invocation of q3asm. This is because by default q3asm outputs an updated qvm format that is necessary to fix a bug involving the optimizing pass of the x86 vm JIT compiler. Creating standalone games Have you finished the daunting task of removing all dependencies on the Q3 game data? You probably now want to give your users the opportunity to play the game without owning a copy of Q3, which consequently means removing cd-key and authentication server checks. In addition to being a straightforward Q3 client, ioquake3 also purports to be a reliable and stable code base on which to base your game project. However, before you start compiling your own version of ioquake3, you have to ask yourself: Have we changed or will we need to change anything of importance in the engine? If your answer to this question is ""no"", it probably makes no sense to build your own binaries. Instead, you can just use the pre-built binaries on the website. Just make sure the game is called with: +set com_basegame <yournewbase>  in any links/scripts you install for your users to start the game. The binary must not detect any original quake3 game pak files. If this condition is met, the game will set com_standalone to 1 and is then running in stand alone mode. If you want the engine to use a different directory in your homepath than e.g. ""Quake3"" on Windows or "".q3a"" on Linux, then set a new name at startup by adding +set com_homepath <homedirname>  to the command line. You can also control which game name to use when talking to the master server: +set com_gamename <gamename>  So clients requesting a server list will only receive servers that have a matching game name. Example line: +set com_basegame basefoo +set com_homepath .foo +set com_gamename foo  If you really changed parts that would make vanilla ioquake3 incompatible with your mod, we have included another way to conveniently build a stand-alone binary. Just run make with the option BUILD_STANDALONE=1. Don't forget to edit the PRODUCT_NAME and subsequent #defines in qcommon/q_shared.h with information appropriate for your project. Standalone game licensing While a lot of work has been put into ioquake3 that you can benefit from free of charge, it does not mean that you have no obligations to fulfill. Please be aware that as soon as you start distributing your game with an engine based on our sources we expect you to fully comply with the requirements as stated in the GPL. That includes making sources and modifications you made to the ioquake3 engine as well as the game-code used to compile the .qvm files for the game logic freely available to everyone. Furthermore, note that the ""QIIIA Game Source License"" prohibits distribution of mods that are intended to operate on a version of Q3 not sanctioned by id software: ""with this Agreement, ID grants to you the non-exclusive and limited right to distribute copies of the Software ... for operation only with the full version of the software game QUAKE III ARENA""  This means that if you're creating a standalone game, you cannot use said license on any portion of the product. As the only other license this code has been released under is the GPL, this is the only option. This does NOT mean that you cannot market this game commercially. The GPL does not prohibit commercial exploitation and all assets (e.g. textures, sounds, maps) created by yourself are your property and can be sold like every other game you find in stores. PNG support ioquake3 supports the use of PNG (Portable Network Graphic) images as textures. It should be noted that the use of such images in a map will result in missing placeholder textures where the map is used with the id Quake 3 client or earlier versions of ioquake3. Recent versions of GtkRadiant and q3map2 support PNG images without modification. However GtkRadiant is not aware that PNG textures are supported by ioquake3. To change this behaviour open the file 'q3.game' in the 'games' directory of the GtkRadiant base directory with an editor and change the line: texturetypes=""tga jpg""  to texturetypes=""tga jpg png""  Restart GtkRadiant and PNG textures are now available. Building with MinGW for pre Windows XP IPv6 support requires a header named ""wspiapi.h"" to abstract away from differences in earlier versions of Windows' IPv6 stack. There is no MinGW equivalent of this header and the Microsoft version is obviously not redistributable, so in its absence we're forced to require Windows XP. However if this header is acquired separately and placed in the qcommon/ directory, this restriction is lifted. Contributing Please send all patches to bugzilla (https://bugzilla.icculus.org), or as a GitHub pull request and submit your patch there. The focus for ioq3 is to develop a stable base suitable for further development and provide players with the same Quake 3 experience they've had for years. We do have graphical improvements with the new renderer, but they are off by default. Building Official Installers We need help getting automated installers on all the platforms that ioquake3 supports. We don't necessarily care about all the installers being identical, but we have some general guidelines: Please include the id patch pk3s in your installer, which are available from http://ioquake3.org/patch-data/ subject to agreement to the id EULA. Your installer shall also ask the user to agree to this EULA (which is in the /web/include directory for your convenience) and subsequently refuse to continue the installation of the patch pk3s and pak0.pk3 if they do not. Please don't require pak0.pk3, since not everyone using the engine plans on playing Quake 3 Arena on it. It's fine to (optionally) assist the user in copying the file or tell them how. It is fine to just install the binaries without requiring id EULA agreement, providing pak0.pk3 and the patch pk3s are not referred to or included in the installer. Please include at least an SDL so/dylib/dll on every platform. Please include an OpenAL so/dylib/dll, since every platform should be using it by now. Please contact the mailing list when you've made your installer. Please be prepared to alter your installer on the whim of the maintainers. Your installer will be mirrored to an ""official"" directory, thus making it a done deal. Credits Maintainers James Canete use.less01@gmail.com Ludwig Nussel ludwig.nussel@suse.de Thilo Schulz arny@ats.s.bawue.de Tim Angus tim@ngus.net Tony J. White tjw@tjw.org Zachary J. Slater zachary@ioquake.org Zack Middleton zturtleman@gmail.com Significant contributions from Ryan C. Gordon icculus@icculus.org Andreas Kohn andreas@syndrom23.de Joerg Dietrich Dietrich_Joerg@t-online.de Stuart Dalton badcdev@gmail.com Vincent S. Cojot optical alex@rigbo.se Aaron Gyes floam@aaron.gy Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/ioquake/ioq3"	"The Quake3 engine, freed at last. only."	"true"
"Engines"	"Orx"	"https://bitbucket.org/orx/orx"	"A portable, lightweight, plugin-based, data-driven, 2D-oriented game engine.."	"null"	"null"	"null"	"zlib"	"http://directory.fsf.org/wiki/License:Zlib"	"null"	"null"	"null"	"null"	"null"	"orx / orx   — Bitbucket  Bitbucket Features Pricing owner/repository English English 日本語 Sign up Log in orx Actions Clone Compare Fork Navigation Overview Source Commits Branches Pull requests 23 Issues Downloads Settings HTTPS HTTPS SSH Need help cloning? Learn how to clone a repository. Clone in SourceTree Atlassian SourceTree is a free Git and Mercurial client for Windows. Atlassian SourceTree is a free Git and Mercurial client for Mac. Orx: Portable Game Engine Engine orx Overview Clone in SourceTree Clone in SourceTree Atlassian SourceTree is a free Git and Mercurial client for Windows. Atlassian SourceTree is a free Git and Mercurial client for Mac. HTTPS HTTPS SSH Last updated 2016-07-14 Website http://orx-project.org/ Language C Access level Read 5 Branches 20 Tags 4 Forks 6 Watchers Orx - Portable Game Engine (Version 1.7) Email iarwain [at] orx-project.org to contact the author; or, better, check orx's homepage for the most up-to-date contact information. This engine is licensed under the very permissive zlib license, see the LICENSE file for details. Summary Orx is a 2D-oriented, data-driven, portable game engine focused primarily on ease of use and powerful features. See below for a list of supported platforms. This is the stable release for orx v1.7. If you find any bugs, please report them on the forum, in the ""Bug report - Feature request"" board, or via orx's issue page/tracker. The current features of orx engine are: hardware-accelerated rendering that provides: translation, anisotropic scale, rotation, transparency (alpha blending), different blending modes, coloring, tiling and mirroring advanced rendering features such as MRT (Multiple Render Targets) support and easy compositing powerful config system that makes orx data-driven and provides an easy to use load/save system powerful resource management allowing for easy multi-platform data support and patching automatic hotloading of resources upon modification on disk shortens drastically iteration times timelines and commands modules allow for config-driven scripting-like features interactive console can execute commands at runtime (very useful for tweaking/debug purposes) animation engine (including a chaining graph & custom animation events for synchronization) fragment (pixel) shader support visual FXs based on curve combinations integrated runtime profiler (with graphical display) to easily spot which parts of your game need to be optimized collision handling and rigid body physics camera/viewport scheme allowing multiple views displayed with camera translation, zoom and rotation generic input system that abstracts keyboard, mouse, joystick, touch and accelerometer inputs powerful localization module spawners (provides an easy way to create particles or projectiles) 3D positioning using ""scene nodes"" custom bitmap font support automatic differential scrolling and depth scaling upon request music and spatialized sound support clock system that provides time consistency and allows time stretching + high precision timers event manager unicode support with UTF-8 encoding plugin system screenshot capture tool (supports bmp, png, jpg, tga and dds) See the doc/html directory for the doxygen documentation of orx's API. The documentation for the latest release version is available here at orx's homepage. You can find details about the tutorials (as well as community-made ones), the tools and the data-driven side of orx (ie. how to use the config system) on orx's wiki. The English version is the most complete one. Chinese and Spanish translations are entirely written and maintained by community members, and they might be less accurate/somewhat outdated. Supported Platforms The engine compiles and is tested for: Linux (x86/x86-64 with codelite, codeblocks and GNU makefile) Windows (x86 with vs2012, vs2013 (x86/x86-64) and mingw32 with codelite, codeblocks and GNU makefile) MacOS X (x86/x86-64/ppc/ppc64 with xcode or x86/x86-64 with codelite, codeblocks and GNU makefile), version 10.5+ for GLFW plugins (default version) and 10.4+ for SFML ones (no joystick support) iOS (iPhone/iPod Touch/iPad, simulator & device with xcode) Android (NDK build files, simulator & device) Versions Those are not revision versions but link/run versions. Orx library can be compiled as a static or a dynamic library. In addition to these modes, orx can be compiled as an embedded version or not. Orx's core is basically platform-independent. All the platform/OS-dependent features are implemented via plugins. These plugins can be loaded at runtime (hotplug) or they can be embedded at linktime. If you use the non-embedded versions, you'll have to specify which plugins to use. This is more flexible but also requires additional files (the plugins themselves). The embedded version will store everything in orx's library, meaning you won't be able to choose which plugin to use at runtime, but will also be more compact. This will also make orx run considerably faster. From the download page you'll find precompiled binaries for Windows (x86), Linux (x86/x86-64), MacOS X (ppc/x86/x86-64), iOS and Android, using the dynamic embedded versions only. If you want to use the non-embedded versions (to use with your own plugins), you'll need to compile orx yourself from the source. Everything compiles out-of-the-box for the hardware platforms cited above. The embedded versions currently use: GLFW-based (+SOIL) plugins for display, joystick, keyboard and mouse for all non-iOS/non-Android platforms OpenAL-based (+libsndfile/stb_vorbis/tremor) plugins for sound for all platforms Box2D-based plugin for physics homemade plugin for 2D rendering OpenGL ES plugins for display on iOS and Android Touch/MultiTouch-based plugin for mouse on iOS and Android Accelerometer-based plugin for joystick on iOS and Android All the 11 basic and advanced official tutorials are shipped with the dev packages, including precompiled release binaries. Some tools (precompiled binaries only) are also shipped with the dev packages: orxCrypt : command line tool to encrypt/decrypt/merge multiple config files orxFontGen: command line tool (based on FreeType2) to generate custom bitmap fonts (.tga texture & .ini config file) from TrueType fonts Packages You can download all the packages from sourceforge or bitbucket. Here is a list with a small description for each package. orx-doc-1.7.zip: orx's API doxygen documentation orx-src-1.7.zip: orx's source code including build projects for codelite (Windows and Linux, all versions, Mac OS X, non-static versions) codeblocks (Windows and Linux, all versions, Mac OS X, non-static versions) GNU makefiles (Windows and Linux, all versions, Mac OS X, non-static versions) vs2012 & vs2013 (Windows Visual Studio, all versions) xcode (3.2+, for MacOS X, non-static versions; SDK 8.1 for iOS, static embedded versions) ndk build files for Android (static embedded versions) NB: You'll need orx-extern-1.7.zip (orx plugins' external dependencies) if you intend to compile orx yourself. orx-extern-1.7.zip: orx's external dependencies. You will only NEED these if you use orx-src-1.7.zip and you plan on compiling orx yourself. They are not needed otherwise. The external libraries are usually modified versions of the original ones. VERY IMPORTANT: If you want to compile orx yourself, you'll need these versions and not the official ones. orx-dev-linux32-1.7.tar.bz2 : dynamic embedded binaries for Linux (x86), release/profile/debug + tools. orx-dev-linux64-1.7.tar.bz2 : dynamic embedded binaries for Linux (x86-64), release/profile/debug + tools. orx-dev-mac-1.7.zip : dynamic embedded binaries for MacOS X (x86/x86-64), release/profile/debug + tools. orx-dev-mingw-1.7.zip : dynamic embedded binaries for Windows (mingw), release/profile/debug + tools. orx-dev-vs2012-1.7.zip : dynamic embedded binaries for Windows (Visual Studio 2012), release/profile/debug + tools. orx-dev-vs2013-32-1.7.zip : dynamic embedded binaries for Windows (Visual Studio 2013, x86), release/profile/debug + tools. orx-dev-vs2013-64-1.7.zip : dynamic embedded binaries for Windows (Visual Studio 2013, x86-64), release/profile/debug + tools. orx-full-ios-1.7.zip : static embedded binaries for iOS, release/profile/debug, simulator/device + doc + source + XCode project file. orx-dev-android-1.7.zip : static embedded binaries for Android, release/profile/debug (device). orx-dev-android-native-1.7.zip : static embedded binaries for Android Native, release/profile/debug (device). orx-tutorial-linux32-1.7.tar.bz2 : tutorials for Linux (x86) orx-tutorial-linux64-1.7.tar.bz2 : tutorials for Linux (x86-64) orx-tutorial-mac-1.7.zip : tutorials for MacOS X (x86/x86-64) orx-tutorial-mingw-1.7.zip : tutorials for Windows (mingw) orx-tutorial-vs2012-1.7.zip : tutorials for Windows (Visual Studio 2012) orx-tutorial-vs2013-1.7.zip : tutorials for Windows (Visual Studio 2013) All the *-dev-* packages above include: orx release/profile/debug libraries used for linking runtime release/profile/debug orx libraries headers to include at compile time template files exposing wich properties can be accessed using the config system (for user reference only, not needed by orx) All the *-tutorial-* packages above include: heavily commented source code for 11 basic and advanced tutorials precompiled binaries (orx link library, orx runtime library) headers to include at compile time template files exposing wich properties can be accessed using the config system (for user reference only, not needed by orx) build/project files Compiling Important - first step: If you just cloned orx with mercurial or git, you will need to run the setup.bat/setup.sh script that's located at its root before being able to compile the engine. This script will download all the needed dependencies and generate all the project files for your platform. The script will then hook itself to mercurial/git and you shouldn't have to run it manually after subsequent pulls. The easiest way to learn how to compile your project using orx for a given platform is to look at the tutorial build project files. NB: The debug version is far slower than the release one, but will output all the warning and error messages useful during development. Here's a quick list of the available compile preprocessor flags: __orxDEBUG__ : used to compile and link against the debug versions of orx library (liborxd.a / orxd.lib / liborxd.dylib), if not specified it refers to the release versions (liborx.a / orx.lib / liborx.dylib). NB: If you want to link against the debug versions of orx library, you need to specify it to your compiler! __orxPROFILER__ : used to enable the profiling push/pop macros for release builds It's automatically enabled for debug builds and it has been enabled to build liborxp.a / orxp.lib / orxp.dll / liborxp.dylib / liborxp.so NB: You can define it in your projects even when using regular release builds, but you won't be able to see orx's internal profiling markers! __orxSTATIC__ : used to compile and link against the static versions of orx library. NB: If you want to link against the static versions of orx library, you need to specify it to your compiler! __orxEMBEDDED__ : used to compile the embedded versions of orx library. NB: this flag is ONLY needed when compiling orx library, not when linking against it. There are other preprocessor flags used when compiling the orx library, but those should be easy enough to decipher. However, you might want to specify them manually for cross-compiling or use them so that your code will behave differently depending on the architecture for which you're compiling. Here's a quick list of these flags: Flag Description __orxARM__ orx is being compiled for an ARM architecture __orxPPC__ orx is being compiled for a PowerPC architecture __orxPPC64__ orx is being compiled for a PowerPC 64 architecture __orxX86__ orx is being compiled for a x86 architecture __orxX86_64__ orx is being compiled for a x86-64 architecture __orxLITTLE_ENDIAN__ orx is being compiled for a little endian architecture __orxBIG_ENDIAN__ orx is being compiled for a big endian architecture __orxGCC__ orx is being compiled with gcc __orxMSVC__ orx is being compiled with visual studio C/C __orxLLVM__ orx is being compiled with llvm/clang __orxWINDOWS__ orx is being compiled for Windows (x86 __orxMAC__ orx is being compiled for MacOS X (ppc/x86/x86-64 __orxLINUX__ orx is being compiled for Linux (x86/x86-64 __orxIOS__ orx is being compiled for iOS __orxANDROID__ orx is being compiled for Android __orxANDROID_NATIVE__ orx is being compiled for Android Native __orxRASPBERRY_PI__ orx is being compiled for Raspberry Pi __orxCPP__ orx is being compiled with a C++ compiler __orxOBJC__ orx is being compiled with an Objective-C compiler __orxFREEBASIC__ orx is being compiled for FreeBasic, WIP __orxPLUGIN__ a plugin for orx is being compiled __orxEXTERN__ code using orx's library is being compiled Comments If you have any questions, comments, ideas or reviews, feel free to post them on orx's forum or send them directly by email to iarwain [at] orx-project.org Enjoy! Unlimited private and public hosted repositories. Free for small teams! Sign up for free Close Recent activity - Updated .extern Pull request #13 merged in orx/orx Philippe Simons · 1 commit Pushed to orx/orx 2482793 - Updated .extern Philippe Simons · - Updated .extern Pull request #13 created in orx/orx Philippe Simons · 1 commit Pushed to orx/orx a7f8a95 - Updated .extern (up-to-date Windows binaries of lidquidfun) Rom · 1 commit Pushed to orx/orx c1785e7 - Removed VS2012 from buildbot config Rom · 1 commit Pushed to orx/orx 4bac3bb - Automatic update of doxygen docs, triggered by buildbot Rom · 5 commits Pushed to orx/orx c615327 - Working first version of travis-ci script for linux & mac 64b 71565ef - More travis-ci stuff 7e5de7a - travis-ci fix attempt 800c0ff - Some travis-ci test f2051f9 - First draft for travis-ci integration Rom · 1 commit Pushed to orx/orx 0f7451a - Added vs2015 to tools premake scripts Rom · 1 commit Pushed to orx/orx e2d4a5d - Automatic update of doxygen docs, triggered by buildbot Rom · 1 commit Pushed to orx/orx 836347e - Added commands Object.SetClock, Object.GetClock & Object.SetAnimFrequency Rom · 1 commit Pushed to orx/orx d955b04 - Automatic update of doxygen docs, triggered by buildbot Rom · Blog Support Plans & pricing Documentation API Site status Version info Terms of service Privacy policy English Git 2.7.4.1.g5468f9e Mercurial 3.6.3 Django 1.7.11 Python 2.7.3 b7520e3d05e9 / b7520e3d05e9 @ app-104 JIRA Software Confluence Bamboo SourceTree HipChat Atlassian Help Online help Learn Git Keyboard shortcuts Latest features Bitbucket tutorials Site status Support"	"null"	"null"	"A portable, lightweight, plugin-based, data-driven, 2D-oriented game engine.."	"true"
"Engines"	"Quake"	"https://github.com/id-Software/Quake"	"The Quake engine. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"1236"	"122"	"314"	"GitHub - id-Software/Quake: Quake GPL Source Release Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 122 Star 1,236 Fork 314 id-Software/Quake Code Pull requests 0 Pulse Graphs Quake GPL Source Release 2 commits 1 branch 0 releases 1 contributor C 86.2% Assembly 13.3% Other 0.5% C Assembly Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Latest commit bf4ac42 Jan 31, 2012 tbradshaw Just kind of shoving the QuakeWorld QuakeC source in here. Permalink Failed to load latest commit information. QW The Quake sources as originally release under the GPL license on Dece… Jan 31, 2012 WinQuake The Quake sources as originally release under the GPL license on Dece… Jan 31, 2012 qw-qc Just kind of shoving the QuakeWorld QuakeC source in here. Jan 31, 2012 gnu.txt The Quake sources as originally release under the GPL license on Dece… Jan 31, 2012 readme.txt The Quake sources as originally release under the GPL license on Dece… Jan 31, 2012 readme.txt  This is the complete source code for winquake, glquake, quakeworld, and  glquakeworld.  The projects have been tested with visual C++ 6.0, but masm is also required  to build the assembly language files.  It is possible to change a #define and  build with only C code, but the software rendering versions lose almost half  its speed.  The OpenGL versions will not be effected very much.  The  gas2masm tool was created to allow us to use the same source for the dos,  linux, and windows versions, but I don't really recommend anyone mess  with the asm code.  The original dos version of Quake should also be buildable from these  sources, but we didn't bother trying.  The code is all licensed under the terms of the GPL (gnu public license).   You should read the entire license, but the gist of it is that you can do  anything you want with the code, including sell your new version.  The catch  is that if you distribute new binary versions, you are required to make the  entire source code available for free to everyone.  Our previous code releases have been under licenses that preclude  commercial exploitation, but have no clause forcing sharing of source code.   There have been some unfortunate losses to the community as a result of  mod teams keeping their sources closed (and sometimes losing them).  If  you are going to publicly release modified versions of this code, you must  also make source code available.  I would encourage teams to even go a step  farther and investigate using public CVS servers for development where  possible.  The primary intent of this release is for entertainment and educational  purposes, but the GPL does allow commercial exploitation if you obey the  full license.  If you want to do something commercial and you just can't bear  to have your source changes released, we could still negotiate a separate  license agreement (for $$$), but I would encourage you to just live with the  GPL.  All of the Quake data files remain copyrighted and licensed under the  original terms, so you cannot redistribute data from the original game, but if  you do a true total conversion, you can create a standalone game based on  this code.  I will see about having the license changed on the shareware episode of  quake to allow it to be duplicated more freely (for linux distributions, for  example), but I can't give a timeframe for it.  You can still download one of  the original quake demos and use that data with the code, but there are  restrictions on the redistribution of the demo data.  If you never actually bought a complete version of Quake, you might want  to rummage around in a local software bargain bin for one of the originals,  or perhaps find a copy of the ""Quake: the offering"" boxed set with both  mission packs.  Thanks to Dave ""Zoid"" Kirsh and Robert Duffy for doing the grunt work of  building this release.  John Carmack Id Software    Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/id-Software/Quake"	"The Quake engine. only."	"true"
"Engines"	"Quake2"	"https://github.com/id-Software/Quake-2"	"The Quake2 engine. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"635"	"71"	"234"	"GitHub - id-Software/Quake-2: Quake 2 GPL Source Release Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 71 Star 635 Fork 234 id-Software/Quake-2 Code Pull requests 1 Pulse Graphs Quake 2 GPL Source Release 1 commit 1 branch 0 releases 1 contributor C 90.7% Assembly 6.2% Objective-C 3.0% Other 0.1% C Assembly Objective-C Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Latest commit 372afde Jan 31, 2012 tbradshaw The original Quake 2 sources as originally released under the GPL lic… … …ense on December 21, 2001. Permalink Failed to load latest commit information. baseq2 The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 client The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 ctf The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 game The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 irix The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 linux The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 null The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 qcommon The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 ref_gl The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 ref_soft The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 rhapsody The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 server The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 solaris The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 unix The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 win32 The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 3.15_Changes.txt The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 3.16_Changes.txt The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 3.17_Changes.txt The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 3.18_changes.txt The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 changes.txt The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 gnu.txt The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 joystick.txt The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 makefile The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 makezip The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 makezip.bat The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 quake2.001 The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 quake2.bce The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 quake2.bcp The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 quake2.dsp The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 quake2.dsw The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 quake2.mak The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 quake2.opt The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 quake2.plg The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 readme.txt The original Quake 2 sources as originally released under the GPL lic… Jan 31, 2012 readme.txt  This is the complete source code for Quake 2, version 3.19, buildable with visual C++ 6.0.  The linux version should be buildable, but we haven't tested it for the release.  The code is all licensed under the terms of the GPL (gnu public license).   You should read the entire license, but the gist of it is that you can do  anything you want with the code, including sell your new version.  The catch  is that if you distribute new binary versions, you are required to make the  entire source code available for free to everyone.  The primary intent of this release is for entertainment and educational  purposes, but the GPL does allow commercial exploitation if you obey the  full license.  If you want to do something commercial and you just can't bear  to have your source changes released, we could still negotiate a separate  license agreement (for $$$), but I would encourage you to just live with the  GPL.  All of the Q2 data files remain copyrighted and licensed under the  original terms, so you cannot redistribute data from the original game, but if  you do a true total conversion, you can create a standalone game based on  this code.  Thanks to Robert Duffy for doing the grunt work of building this release.  John Carmack Id Software    Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/id-Software/Quake-2"	"The Quake2 engine. only."	"true"
"Engines"	"Spearmint"	"https://github.com/zturtleman/spearmint"	"An engine designed for FPS games. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"51"	"9"	"5"	"GitHub - zturtleman/spearmint: Spearmint, an updated id Tech 3 engine for continuing the classics and creating new games. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 9 Star 51 Fork 5 zturtleman/spearmint Code Issues 75 Pull requests 0 Wiki Pulse Graphs Spearmint, an updated id Tech 3 engine for continuing the classics and creating new games. http://spearmint.pw 4,129 commits 7 branches 6 releases Fetching contributors C 95.9% C++ 2.7% Makefile 0.3% GLSL 0.3% Objective-C 0.3% Assembly 0.2% Other 0.3% C C++ Makefile GLSL Objective-C Assembly Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags archive/android archive/sdl12 coverity_scan devil feature/osx_dropfile gh-pages master Nothing to show tag-master-sdl12 release-0.4 release-0.3 release-0.2 release-0.1.1 release-0.1 Nothing to show New pull request Latest commit 6316e7d Jul 13, 2016 zturtleman spearmint: Change version to 0.4, protocol to 10 … Protocol was changed so that network games with incompatible VMs are separate.  Protocol 6,7,8,9 were skipped so that Turtle Arena 0.7 won't reuse an old protocol number. Permalink Failed to load latest commit information. code misc spearmint: Rename NSIS files May 27, 2016 .gitignore Merge remote-tracking branch 'ioquake3/master' Sep 26, 2015 .travis.yml COPYING.txt ChangeLog Makefile spearmint: Change version to 0.4, protocol to 10 Jul 13, 2016 README-old.md README.md spearmint: Fix displayed IRC server address in README Jul 5, 2016 id-readme.txt jenkins-ci-build.sh Only run scan-build on one of the clang builds Aug 28, 2014 make-linux-portable.sh make-macosx-app.sh make-macosx-ub.sh make-macosx.sh Merge remote-tracking branch 'ioquake3/master' Aug 16, 2013 md4-readme.txt opengl2-readme.md Merge remote-tracking branch 'ioquake3/master' (final part) Apr 4, 2016 travis-ci-build.sh voip-readme.txt README.md Spearmint is a fork of ioquake3 with two main goals; 1) provide a flexible engine for creating new games and mods, 2) support features from (and running) various id Tech 3-based games. Spearmint can be used to play Quake III Arena, Quake III: Team Arena, and Turtle Arena. Progress has been made toward running Return to Castle Wolfenstein (MP) and Wolfenstein: Enemy Territory, there is still quite a bit left before it's possible though. Spearmint is not compatible with existing mods (the QVM/DLL files) or demos (game recordings) for any game. New Spearmint 0.X releases will likely break VM and demo compatibility with previous releases. The source code for the Spearmint Quake 3 game, cgame, and ui code and QVM compiler is at zturtleman/mint-arena. Map editor and map compiler are available at https://icculus.org/gtkradiant/. Download Pre-built packages for Windows, GNU/Linux, and Mac OS X are available at the Spearmint website. Discuss Magical Clover Forum (supports GitHub login) #spearmint on chat.freenode.net Documentation Spearmint wiki Git branches master branch is compatible with Spearmint 0.1. devil branch is for Spearmint 0.4 API development (devil-op-mint) — it may be out of date compared to master. License Spearmint is licensed under a modified version of the GNU GPLv3 (or at your option, any later version). The license is also used by Return to Castle Wolfenstein, Wolfenstein: Enemy Territory, and Doom 3. Credits Zack Middleton (main developer) Tobias Kuehnhammer (feedback / bug reports / Bot AI fixes) And other contributors Spearmint is based on ioquake3 and also contains code from; RTCW SP - Gray Matter Interactive RTCW MP - Nerve Software Wolfenstein: Enemy Territory - Splash Damage Tremulous - Dark Legion Development World of Padman - Padworld Entertainment ioquake3 Elite Force MP patch - Thilo Schulz NetRadiant's q3map2 - Rudolf Polzer OpenArena - OpenArena contributors OpenMoHAA - OpenMoHAA contributors Xreal (triangle mesh collision) - Robert Beckebans Contributing Please submit all patches at the Magical Clover Forum or as a GitHub pull request. The focus for Spearmint is to develop a stable base suitable for further development and provide players with the same Quake 3 game play experience they've had for years. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/zturtleman/spearmint"	"An engine designed for FPS games. or later."	"true"
"Generic Programming"	"klib"	"https://github.com/attractivechaos/klib"	"Small and lightweight implementations of common algorithms and data structures.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"1420"	"139"	"167"	"GitHub - attractivechaos/klib: A standalone and lightweight C library Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 139 Star 1,420 Fork 167 attractivechaos/klib Code Issues 14 Pull requests 17 Wiki Pulse Graphs A standalone and lightweight C library http://attractivechaos.github.io/klib/ 317 commits 3 branches 2 releases 15 contributors C 80.0% C++ 12.0% Lua 7.5% Makefile 0.5% C C++ Lua Makefile Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags gh-pages ksw-reduce8 master Nothing to show spawn-final ksprintf-final Nothing to show New pull request Latest commit 325683f Dec 30, 2015 lh3 Merge branch 'master' of github.com:attractivechaos/klib Permalink Failed to load latest commit information. lua change to 0 indexed array Jun 3, 2011 test added Sep 29, 2015 .gitignore Add kputw() and kputl() tests Jul 22, 2013 README.md erh... wrong link in the last commit Nov 30, 2014 bgzf.c minor changes Oct 28, 2011 bgzf.h improved backward compatibility Oct 28, 2011 kbit.h some basic bit operations Apr 8, 2012 kbtree.h added Sep 29, 2015 kexpr.c fixed a bug and a portability issue May 22, 2015 kexpr.h set user-defined functions May 22, 2015 kgraph.h Graph related routines. Unfinished. DON'T USE! Dec 28, 2011 khash.h fix spelling mistake Oct 23, 2015 khmm.c Added the khmm library Jan 13, 2011 khmm.h Added the khmm library Jan 13, 2011 klist.h Prevent unused function warnings in khash.h, klist.h Jul 23, 2015 kmath.c draw a random number from Gaussian N(0,1) Dec 30, 2015 kmath.h draw a random number from Gaussian N(0,1) Dec 30, 2015 knetfile.c Don't call freeaddrinfo() when getaddrinfo() fails Jul 23, 2015 knetfile.h Added the knetfile library Jan 13, 2011 knhx.c Fixed output bug where branch length is not printed on branches to le… Jun 26, 2015 knhx.h print tree in the Newick format Dec 18, 2012 kopen.c Don't call freeaddrinfo() when getaddrinfo() fails Jul 23, 2015 ksa.c Constructing suffix array for multi-sentinel str. Aug 19, 2011 kseq.h Fix ks_getuntil2() extra empty record at EOF bug Nov 13, 2014 kson.c kson_query() -> kson_by_path() for clarity Nov 30, 2014 kson.h kson_query() -> kson_by_path() for clarity Nov 30, 2014 ksort.h Update ksort.h Nov 29, 2013 kstring.c Add kgetline() to kstring.c/.h Jul 23, 2015 kstring.h Add kgetline() to kstring.c/.h Jul 23, 2015 ksw.c bugfix: point address changes Feb 20, 2013 ksw.h added NW and SW-extension; backported from bwa Feb 12, 2013 kthread.c removed kt_spawn(); added kt_pipeline() Nov 30, 2014 kurl.c default to following redirect & no SSL certificate Nov 28, 2014 kurl.h allow to feed change key/secret/id-file Nov 21, 2013 kvec.h Two bugs reported by istreeter and wanghc78 Jan 26, 2013 README.md Klib: a Generic Library in C Overview Klib is a standalone and lightweight C library distributed under MIT/X11 license. Most components are independent of external libraries, except the standard C library, and independent of each other. To use a component of this library, you only need to copy a couple of files to your source code tree without worrying about library dependencies. Klib strives for efficiency and a small memory footprint. Some components, such as khash.h, kbtree.h, ksort.h and kvec.h, are among the most efficient implementations of similar algorithms or data structures in all programming languages, in terms of both speed and memory use. A new documentation is available here which includes most information in this README file. Common components khash.h: generic hash table based on double hashing. kbtree.h: generic search tree based on B-tree. ksort.h: generic sort, including introsort, merge sort, heap sort, comb sort, Knuth shuffle and the k-small algorithm. kseq.h: generic stream buffer and a FASTA/FASTQ format parser. kvec.h: generic dynamic array. klist.h: generic single-linked list and memory pool. kstring.{h,c}: basic string library. kmath.{h,c}: numerical routines including MT19937-64 pseudorandom generator, basic nonlinear programming and a few special math functions. Components for more specific use cases ksa.c: constructing suffix arrays for strings with multiple sentinels, based on a revised SAIS algorithm. knetfile.{h,c}: random access to remote files on HTTP or FTP. kopen.c: smart stream opening. khmm.{h,c}: basic HMM library. ksw.(h,c}: Striped Smith-Waterman algorithm. knhx.{h,c}: Newick tree format parser. Methodology For the implementation of generic containers, klib extensively uses C macros. To use these data structures, we usually need to instantiate methods by expanding a long macro. This makes the source code look unusual or even ugly and adds difficulty to debugging. Unfortunately, for efficient generic programming in C that lacks template, using macros is the only solution. Only with macros, we can write a generic container which, once instantiated, compete with a type-specific container in efficiency. Some generic libraries in C, such as Glib, use the void* type to implement containers. These implementations are usually slower and use more memory than klib (see this benchmark). To effectively use klib, it is important to understand how it achieves generic programming. We will use the hash table library as an example: #include ""khash.h"" KHASH_MAP_INIT_INT(m32, char)        // instantiate structs and methods int main() {     int ret, is_missing;     khint_t k;     khash_t(m32) *h = kh_init(m32);  // allocate a hash table     k = kh_put(m32, h, 5, &ret);     // insert a key to the hash table     if (!ret) kh_del(m32, h, k);     kh_value(h, k) = 10;             // set the value     k = kh_get(m32, h, 10);          // query the hash table     is_missing = (k == kh_end(h));   // test if the key is present     k = kh_get(m32, h, 5);     kh_del(m32, h, k);               // remove a key-value pair     for (k = kh_begin(h); k != kh_end(h); ++k)  // traverse         if (kh_exist(h, k))          // test if a bucket contains data             kh_value(h, k) = 1;     kh_destroy(m32, h);              // deallocate the hash table     return 0; }  In this example, the second line instantiates a hash table with unsigned as the key type and char as the value type. m32 names such a type of hash table. All types and functions associated with this name are macros, which will be explained later. Macro kh_init() initiates a hash table and kh_destroy() frees it. kh_put() inserts a key and returns the iterator (or the position) in the hash table. kh_get() and kh_del() get a key and delete an element, respectively. Macro kh_exist() tests if an iterator (or a position) is filled with data. An immediate question is this piece of code does not look like a valid C program (e.g. lacking semicolon, assignment to an apparent function call and apparent undefined m32 'variable'). To understand why the code is correct, let's go a bit further into the source code of khash.h, whose skeleton looks like: #define KHASH_INIT(name, SCOPE, key_t, val_t, is_map, _hashf, _hasheq) \   typedef struct { \     int n_buckets, size, n_occupied, upper_bound; \     unsigned *flags; \     key_t *keys; \     val_t *vals; \   } kh_##name##_t; \   SCOPE inline kh_##name##_t *init_##name() { \     return (kh_##name##_t*)calloc(1, sizeof(kh_##name##_t)); \   } \   SCOPE inline int get_##name(kh_##name##_t *h, key_t k) \   ... \   SCOPE inline void destroy_##name(kh_##name##_t *h) { \     if (h) { \       free(h->keys); free(h->flags); free(h->vals); free(h); \     } \   }  #define _int_hf(key) (unsigned)(key) #define _int_heq(a, b) (a == b) #define khash_t(name) kh_##name##_t #define kh_value(h, k) ((h)->vals[k]) #define kh_begin(h, k) 0 #define kh_end(h) ((h)->n_buckets) #define kh_init(name) init_##name() #define kh_get(name, h, k) get_##name(h, k) #define kh_destroy(name, h) destroy_##name(h) ... #define KHASH_MAP_INIT_INT(name, val_t) \     KHASH_INIT(name, static, unsigned, val_t, is_map, _int_hf, _int_heq)  KHASH_INIT() is a huge macro defining all the structs and methods. When this macro is called, all the code inside it will be inserted by the C preprocess to the place where it is called. If the macro is called multiple times, multiple copies of the code will be inserted. To avoid naming conflict of hash tables with different key-value types, the library uses token concatenation, which is a preprocessor feature whereby we can substitute part of a symbol based on the parameter of the macro. In the end, the C preprocessor will generate the following code and feed it to the compiler (macro kh_exist(h,k) is a little complex and not expanded for simplicity): typedef struct {   int n_buckets, size, n_occupied, upper_bound;   unsigned *flags;   unsigned *keys;   char *vals; } kh_m32_t; static inline kh_m32_t *init_m32() {   return (kh_m32_t*)calloc(1, sizeof(kh_m32_t)); } static inline int get_m32(kh_m32_t *h, unsigned k) ... static inline void destroy_m32(kh_m32_t *h) {   if (h) {     free(h->keys); free(h->flags); free(h->vals); free(h);   } }  int main() {     int ret, is_missing;     khint_t k;     kh_m32_t *h = init_m32();     k = put_m32(h, 5, &ret);     if (!ret) del_m32(h, k);     h->vals[k] = 10;     k = get_m32(h, 10);     is_missing = (k == h->n_buckets);     k = get_m32(h, 5);     del_m32(h, k);     for (k = 0; k != h->n_buckets; ++k)         if (kh_exist(h, k)) h->vals[k] = 1;     destroy_m32(h);     return 0; }  This is the C program we know. From this example, we can see that macros and the C preprocessor plays a key role in klib. Klib is fast partly because the compiler knows the key-value type at the compile time and is able to optimize the code to the same level as type-specific code. A generic library written with void* will not get such performance boost. Massively inserting code upon instantiation may remind us of C++'s slow compiling speed and huge binary size when STL/boost is in use. Klib is much better in this respect due to its small code size and component independency. Inserting several hundreds lines of code won't make compiling obviously slower. Resources Library documentation, if present, is available in the header files. Examples can be found in the test/ directory. Obsolete documentation of the hash table library can be found at SourceForge. This README is partly adapted from the old documentation. Blog post describing the hash table library. Blog post on why using void* for generic programming may be inefficient. Blog post on the generic stream buffer. Blog post evaluating the performance of kvec.h. Blog post arguing B-tree may be a better data structure than a binary search tree. Blog post evaluating the performance of khash.h and kbtree.h among many other implementations. An older version of the benchmark is also available. Blog post benchmarking internal sorting algorithms and implementations. Blog post on the k-small algorithm. Blog post on the Hooke-Jeeve's algorithm for nonlinear programming. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/attractivechaos/klib"	"Small and lightweight implementations of common algorithms and data structures.."	"true"
"Graphics"	"Cairo"	"http://cairographics.org/"	"A 2D graphics library. only or."	"null"	"null"	"null"	"MPLv1.1"	"https://directory.fsf.org/wiki/License:MPLv1.1"	"null"	"null"	"null"	"null"	"null"	"cairographics.org News Download Documentation Contact Examples Latest news: 2015-12-10: cairo 1.15.2 release available 2015-12-09: cairo 1.14.6 release available Cairo is a 2D graphics library with support for multiple output devices. Currently supported output targets include the X Window System (via both Xlib and XCB), Quartz, Win32, image buffers, PostScript, PDF, and SVG file output. Experimental backends include OpenGL, BeOS, OS/2, and DirectFB. Cairo is designed to produce consistent output on all output media while taking advantage of display hardware acceleration when available (eg. through the X Render Extension). The cairo API provides operations similar to the drawing operators of PostScript and PDF. Operations in cairo including stroking and filling cubic Bézier splines, transforming and compositing translucent images, and antialiased text rendering. All drawing operations can be transformed by any affine transformation (scale, rotation, shear, etc.) Cairo is implemented as a library written in the C programming language, but bindings are available for several different programming languages. Cairo is free software and is available to be redistributed and/or modified under the terms of either the GNU Lesser General Public License (LGPL) version 2.1 or the Mozilla Public License (MPL) version 1.1 at your option. Last edited Thu Nov 20 20:05:09 2014"	"null"	"null"	"A 2D graphics library. only or."	"true"
"Graphics"	"Cogl"	"https://github.com/rib/cogl-web/wiki"	"A GPU graphics and utilities API. (dependent on and possibly only libs)."	"null"	"null"	"null"	"LGPLv2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"0"	"3"	"1"	"Home · rib/cogl-web Wiki · GitHub Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 3 Star 0 Fork 1 rib/cogl-web Code Issues 0 Pull requests 1 Wiki Pulse Graphs Home Robert Bragg edited this page Sep 2, 2013 · 3 revisions Pages 2 Home Easy Hacks Clone this wiki locally Clone in Desktop Getting the code git clone git://git.gnome.org/cogl.git You can also browse the code here. Cogl is an autotooled project so to build just do: ./configure make install Getting involved Please join the mailing list Follow cogl3d on twitter Please file bugs in Bugzilla Find us on irc in #cogl on Freenode Note: The Cogl maintainers are Robert Bragg (rib) and Neil Roberts (bpeel) and we're both in the UK timezone. If you're interested in helping out but don't know where to start, please see the Easy Hacks page Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/rib/cogl-web/wiki"	"A GPU graphics and utilities API. (dependent on and possibly only libs)."	"true"
"Graphics"	"Clutter"	"https://blogs.gnome.org/clutter/get-it/"	"A UI library based on OpenGL. only."	"null"	"null"	"null"	"GNU LGPL2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"null"	"null"	"null"	"Get it! – Clutter Project Skip to content Clutter Project Have fun! Menu and widgets Clutter is a toolkit for creating compelling, dynamic, and portable graphical user interfaces. Clutter is free software, developed by the GNOME community. Follow this blog to learn about Clutter and track its development. Search for: Blogroll Show me the Source Wiki Tags announcement clutter-gtk features what's new Recent Posts Delegation PyClutter Reborn What’s new in Clutter 1.22 Changes in the layout of the Git repository New Clutter-GTK releases Recent Comments clutter on What’s new in Clutter 1.22 Surya on What’s new in Clutter 1.22 clutter on Get it! clutter on About Timur on About Archives July 2015 May 2015 March 2015 January 2015 October 2012 Meta Register Log in Entries RSS Comments RSS WordPress.org Get it! Releases Clutter releases are made in two streams: stable releases have even version numbers and are production use with a stable API/ABI; unstable releases have odd version numbers and are intended for developers wanting to test the latest Clutter features, and/or contribute to Clutter development. Source code tarballs for Clutter core, add-on libraries and bindings for various languages can be downloaded from http://download.gnome.org/sources/clutter. The latest releases of Clutter core are available here. For pre-built Linux binary packages consult your distribution’s package management tools. Packages for Clutter are currently available for several Linux distributions, including Debian, Fedora, Mandriva, SUSE, and Ubuntu. Source code repository Bleeding-edge Clutter source code is accessible through our Git repository. To check out a local copy of the sources:  git clone git://git.gnome.org/clutter  The repository is also browsable through a web interface. 9 thoughts on “Get it!” DZvonko says: October 17, 2012 at 10:57 am How to install (use) clutter with python 3.30 and PyScripter 2.5.3 on windows xp and windows 7? I have some examples using clutter like this: import clutter import time …… I am pretty new in this (it’s obvious, right?) Thanks in advance! Regards Reply andre says: November 8, 2012 at 12:31 pm DZvonko: Please ask on a mailing list for support. Reply OK says: February 21, 2013 at 8:32 pm Can Clutter be ported to non-OpenGL system? Reply clutter says: April 4, 2013 at 10:24 am @OK: Clutter itself does not use GL: it uses Cogl, which is a library that abstracts most GL usage. Cogl can be ported to non-GL drawing, like DirectX, but it hasn’t been done yet. if you mean porting to systems without hardware acceleration capabilities, you really want to contribute to Mesa, and its software rasterizer instead. GL is just an API: the implementation can be backed by a driver that does most operations on the GPU, or fall back on the CPU. Reply tumagonx says: June 11, 2013 at 7:46 am Dear clutter devs, I’d like to know where to get dax-0.2 (I’ve looking everywhere) as required by pinpoint-0.1.4, and is it still developed? looks like cool powerpoint apps! thanks Reply clutter says: June 11, 2013 at 9:26 am Dax is not developed any more, and you should be able to build Pinpoint without it. Reply tumagonx says: June 11, 2013 at 11:45 am but I want svg loading with it. thanks Reply Collin says: October 26, 2013 at 2:54 pm Where is pyclutter? Reply clutter says: December 24, 2014 at 12:30 am there is no need for PyClutter any more: Clutter exports introspection data, so it’s possible to use it like any other GNOME library, through pygobject. Reply Leave a Reply Cancel reply Your email address will not be published. Required fields are marked * Comment Name * Email * Website Wordpress Hashcash needs javascript to work, but your browser has javascript disabled. Your comment will be placed in moderation! Proudly powered by WordPress"	"null"	"null"	"A UI library based on OpenGL. only."	"true"
"Graphics"	"heman"	"https://github.com/prideout/heman"	"A tiny library of image utilities dealing with height maps, normal maps, distance fields and the like.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"261"	"19"	"11"	"GitHub - prideout/heman: C99 heightmap utilities. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 19 Star 261 Fork 11 prideout/heman Code Issues 1 Pull requests 0 Pulse Graphs C99 heightmap utilities. 119 commits 4 branches 3 releases Fetching contributors C 99.1% Other 0.9% C Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags gh-pages halton layout master Nothing to show r2 r1 r0 Nothing to show New pull request Latest commit db5e864 Nov 23, 2015 Philip Rideout Add heman_ops_max. Permalink Failed to load latest commit information. docs Use ""CPCF"" instead of ""CF"" to make it somewhat less vague. Oct 3, 2015 include Add heman_ops_max. Nov 23, 2015 kazmath Change the double-precision flag to match kazmath. Sep 6, 2015 src Add heman_ops_max. Nov 24, 2015 test Add new argument to draw_contour to allow small filters for performance. Nov 11, 2015 .clang-format Fix up the ""format"" SCons target. Aug 10, 2015 .gitignore Flesh out documentation. Aug 15, 2015 .travis.yml Fix aspect ratio issue with ops_warp et al. Oct 24, 2015 Dockerfile Remove boost from Dockerfile and update the plans for Python support. Aug 21, 2015 LICENSE Birth of a C99 library of heightmap utilities. Aug 9, 2015 README.md Replace boot2docker (apparently it is deprecated) with docker-machine. Oct 3, 2015 SConscript Enable link-time emscripten optimizations. Sep 7, 2015 SConstruct Fix aspect ratio issue with ops_warp et al. Oct 24, 2015 env.sh Fix aspect ratio issue with ops_warp et al. Oct 24, 2015 uncrustify.cfg Add uncrustify, because clang-format does not squash newlines. Aug 15, 2015 README.md heman This is a tiny MIT-licensed C library of image utilities for dealing with height maps, normal maps, distance fields, and the like. It has a very low-level API, where an ""image"" is simply a flat array of floats. It's pretty fast too, since it's parallelized with OpenMP. Heman can do stuff like this: Create a random height field using simplex noise and FBM. Generate a normal map from a height map. Compute ambient occlusion from a height map. Generate a signed distance field (SDF). Export a 3D mesh in PLY format. Apply a color gradient to a heightmap. Generate a color gradient, given a list of control points. Compute diffuse lighting with an infinite light source. Generate a nicely-distributed list of points according to a density field. Heman implements some really nice 21st-century algorithms: Ambient occlusion is generated using Sean Barrett's efficient method that makes 16 sweeps over the height field. Distance field computation uses the beautiful algorithm from Distance Transforms of Sampled Functions (Felzenszwalb and Huttenlocher). Density field samples are generated using Robert Bridson's Fast Poisson Disk Sampling in Arbitrary Dimensions. Python and JavaScript too! Unit tests are performed using the Python bindings, which live in prideout/heman-python. Heman also provides emscripten bindings for its API. The JavaScript demo is here. Example The above images were generated from code that looks like this: // Generate an island shape using simplex noise and a distance field. heman_image* elevation = heman_generate_island_heightmap(1024, 1024, rand());  // Compute ambient occlusion from the height map. heman_image* occ = heman_lighting_compute_occlusion(elevation);  // Visualize the normal vectors. heman_image* normals = heman_lighting_compute_normals(elevation);  // Apply a color gradient. heman_image* gradient = heman_color_create_gradient(...); heman_image* albedo = heman_color_apply_gradient(elevation, -0.5, 0.5, grad);  // Apply diffuse lighting. heman_image* final = heman_lighting_apply(elevation, albedo, ...); For the unabridged version, see test_lighting in test/test_heman.c. Documentation The latest Sphinx-generated docs are hosted here. You can also take a look at heman's one and only header file. Building Heman has no dependencies, so it should be easy just to incorporate the code directly into your project. For building a shared library in OS X, you can do this: brew install scons scons lib  Note that this will not use OpenMP or build any tests. Linux is required for OpenMP and tests. If you are not using a Linux machine but you want OpenMP support, take a look at the provided Dockerfile. There's a script in the repo, env.sh, that makes using Docker easy. It calls docker-machine and builds a container. Here's how to use it: brew install docker-machine . env.sh # Lots of stuff spews out as it builds the container... heman-bash # You're now inside the VM -- press enter twice for the prompt. scons && build/test_heman # You can now look at the generated images: ls build/*.png Roadmap Here are some to-be-done items: Provide ""Exponentially Distributed Noise"", in addition to Simplex. Flesh out the Python Bindings and provide docstrings. Implement a contour extractor: heman_ops_extract_contour(image, threshold, thickness) this just does a Sobel operator, that's all More distance field stuff. Allow non-monochrome source images. Allow computation of unsigned, squared distance. Spherical distance. Smarter Mesh Output Create a hull from poisson samples Sobel + (Step => Sobel) => Density Field => Poisson Samples Do not use marching squares! Two meshes: overwater and underwater Provide gamma decode and encode functions. More noise routines! Bridson's Curl noise (and a routine that performs advection?) Worley noise (useful for billows as seen in Real-time Volumetric Cloudscapes of Horizon) Analytic noise normals Wavelet Noise heman_image_sample doesn't do any interpolation. Maybe it should at least do a 2x2 box filter. Provide functionality from Scalable Height-Field Self-Shadowing If we need more string handling, we can integrate SDS. Integrate aaOcean, or some other implementation of Tessendorf waves. If we need to read JSON, we might use this or this. There are cool data structures in http://concurrencykit.org/ Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/prideout/heman"	"A tiny library of image utilities dealing with height maps, normal maps, distance fields and the like.."	"true"
"Graphics"	"libcaca"	"https://github.com/cacalabs/libcaca"	"An ASCII renderer for terminal-based interfaces.."	"null"	"null"	"null"	"WTFPLv2"	"http://www.wtfpl.net/txt/copying/"	"null"	"null"	"61"	"14"	"22"	"GitHub - cacalabs/libcaca Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 14 Star 61 Fork 22 cacalabs/libcaca Code Issues 5 Pull requests 5 Pulse Graphs No description or website provided. 1,957 commits 1 branch 6 releases 8 contributors C 70.9% Python 8.1% PHP 6.9% C# 3.0% C++ 2.1% Java 2.1% Other 6.9% C Python PHP C# C++ Java Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show v0.99.beta19 v0.99.beta18 v0.99.beta17 v0.99.beta16 v0.99.beta15 v0.99.beta14 Nothing to show New pull request Latest commit 0e23624 Jun 2, 2016 alxf Merge pull request #16 from alxf/issue-#15 … Issue #15: Fix returned pointer with caca types. Permalink Failed to load latest commit information. .travis Refactor a few things in the makefiles. Jan 24, 2016 XCode/libcacaXCode.xcodeproj * Added command line parsing (--dateformat, --font, --help, --version) Mar 6, 2011 build Fixed VS2015 error; snprintf std is now included Feb 10, 2016 caca-php build: fix the WTFPL homepage and copyright information. Dec 28, 2012 caca-sharp Refactor a few things in the makefiles. Jan 24, 2016 caca Update copyright information. Feb 1, 2016 cxx Move many build files to the build subdirectory. Jan 24, 2016 doc Refactor a few things in the makefiles. Jan 24, 2016 examples Move many build files to the build subdirectory. Jan 24, 2016 java Refactor a few things in the makefiles. Jan 24, 2016 kernel Refactor a few things in the makefiles. Jan 24, 2016 perl Large source code cleanup, getting rid of spaces, tabs, and svn keywo… Feb 8, 2010 python Fix free for caca types. May 22, 2016 ruby Autodetect ruby-minitest. Travis-CI doesn’t have it yet. Jan 24, 2016 src Move many build files to the build subdirectory. Jan 24, 2016 tools Refactor a few things in the makefiles. Jan 24, 2016 .gitignore Revert setlocale() effect as soon as possible. Closes #12. Feb 1, 2016 .travis.yml Remove mention of Travis-CI not allowing libimlib2-dev and ruby-minit… Jan 26, 2016 AUTHORS New improved ctypes-based Python bindings, by Alex Foulon <alxf@lavab… May 20, 2010 COPYING build: fix the WTFPL homepage and copyright information. Dec 28, 2012 COPYING.GPL * Added glue code to compile libcaca without a libc and build applic… Mar 9, 2006 COPYING.ISC Add a simple snake program using the <conio.h> interface. Aug 1, 2009 COPYING.LGPL * Changed the licensing to WTFPL, as per all copyright holders' perm… Mar 4, 2006 ChangeLog release: libcaca 0.99.beta18 Apr 6, 2012 Makefile.am Move many build files to the build subdirectory. Jan 24, 2016 NEWS release: libcaca 0.99.beta18 Apr 6, 2012 NOTES Large source code cleanup, getting rid of spaces, tabs, and svn keywo… Feb 8, 2010 README Clarify the need to bootstrap in README. Apr 16, 2010 THANKS win32: improvements to the Win32 driver by Bastian Märkisch <bmaerkis… Nov 18, 2012 bootstrap build: update bootstrap script. May 30, 2015 caca-config.in Large source code cleanup, getting rid of spaces, tabs, and svn keywo… Feb 8, 2010 configure.ac Autodetect ruby-minitest. Travis-CI doesn’t have it yet. Jan 24, 2016 libcaca.sln build: fix the Visual Studio compilation, remove old solution Jun 11, 2012 libcaca.spec * Removed cacademo from examples, manpages and distributions. It's u… Mar 6, 2006 README  Building libcaca     o  If you are using a Git or SVN checkout, you need to run the       bootstrap script in order to generate configure. This is not       necessary for official tarballs.     o  Run configure then make. Useful configure flags are:       --enable-ncurses: support for the ncurses library      --enable-slang: support for the SLang library      --enable-conio: support for MS-DOS conio.h      --enable-x11: support for native X11 rendering      --enable-gl: support for OpenGL rendering      --enable-win32: support for the Windows console      --enable-network: support for the network server       --disable-imlib2: remove Imlib2 support in cacaview       --disable-doc: do not build documentation     o  Cross-compilation examples:       ./configure --disable-imlib2 --host=i386-pc-msdosdjgpp       ./configure --disable-imlib2 --host=i586-mingw32msvc   Using libcaca     o  Look into the src/ and test/ directories for source code examples.     o  Compiling a libcaca program is fairly simple:        gcc -c foobar.c -o foobar.o `pkg-config --cflags caca`       gcc foobar.o -o foobar `pkg-config --libs caca`   Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/cacalabs/libcaca"	"An ASCII renderer for terminal-based interfaces.."	"true"
"Graphics"	"libimagequant"	"https://pngquant.org/lib/"	"Small, portable library for high-quality conversion of RGBA images to 8-bit indexed colour images.."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"1411"	"94"	"199"	"GitHub - pornel/pngquant: Lossy PNG compressor — pngquant command and libimagequant library Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 94 Star 1,411 Fork 199 pornel/pngquant Code Issues 10 Pull requests 0 Pulse Graphs Lossy PNG compressor — pngquant command and libimagequant library https://pngquant.org 964 commits 9 branches 45 releases Fetching contributors C 93.9% Makefile 1.8% Groff 1.8% Shell 1.4% Objective-C 1.1% C Makefile Groff Shell Objective-C Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags cpp master msvc noie6 original palette qualitymap slowcolorlookup wucut Nothing to show 2.7.1 2.7.1-msvc 2.7.0 2.6.0 2.5.2 2.5.1 2.5.0 2.4.2 2.4.1 2.4.0.1 2.4.0 2.3.6 2.3.5 2.3.4 2.3.3 2.3.2 2.3.1 2.3.0 2.2.0 2.1.0 2.0.2 2.0.1 2.0.0 1.8.4 1.8.3 1.8.2 1.8.1 1.8.0 1.7.4 1.7.3 1.7.2 1.7.1 1.7.0 1.6.4 1.6.3 1.6.2 1.6.1 1.6 1.5.1 1.5.0 1.4b 1.3b 1.3a 1.2b 1.2a Nothing to show New pull request Latest commit 46d9db0 Jul 7, 2016 pornel Better error message Permalink Failed to load latest commit information. lib Reject images that could cause overflows on 32-bit Jun 23, 2016 test Progress callbacks Apr 3, 2016 .gitignore Ignore May 24, 2016 CHANGELOG Tune dither level algorithm May 6, 2016 CODE_OF_CONDUCT.md Added CoC Mar 6, 2016 COPYRIGHT Relicense under GPL Dec 5, 2015 INSTALL Update installation instructions Jul 8, 2014 Makefile Unused May 28, 2016 README.md Recommend zopflipng May 31, 2016 configure Fixed dynamic lib search May 29, 2016 pngquant.1 Tuned --skip-if-larger quality check Apr 18, 2016 pngquant.c Better error message Jul 7, 2016 pngquant.spec Bump Jun 8, 2016 rwpng.c Fix integer overflow in rwpng.h (CVE-2016-5735) Jun 23, 2016 rwpng.h Remove png.h from rwpng.h May 28, 2016 rwpng_cocoa.m Updated rwpng Dec 5, 2015 README.md pngquant 2 This is the official pngquant and libimagequant. pngquant converts 24/32-bit RGBA PNGs to 8-bit palette with alpha channel preserved. Such images are fully standards-compliant and are supported by all web browsers. Quantized files are often 60-80% smaller than their 24/32-bit versions. This utility works on Linux, Mac OS X and Windows. Usage batch conversion of multiple files: pngquant *.png Unix-style stdin/stdout chaining: … | pngquant - | … To further reduce file size, try optipng, ImageOptim, or zopflipng. Improvements since 1.0 Generated files are both smaller and look much better. Significantly better quality of quantisation more accurate remapping of semitransparent colors special dithering algorithm that does not add noise in well-quantized areas of the image uses variance instead of popularity for box selection (improvement suggested in the original median cut paper) feedback loop that repeats median cut for poorly quantized colors additional colormap improvement using Voronoi iteration supports much larger number of colors in input images without degradation of quality gamma correction and optional color profile support (output is always in gamma 2.2 for web compatibility) More flexible commandline usage number of colors defaults to 256, and can be set automatically with the --quality switch long options and standard switches like -- and - are allowed Refactored and modernised code C99 with no workarounds for legacy systems or compilers (apart from Visual Studio) floating-point math used throughout Intel SSE optimisations multicore support via OpenMP quantization moved to standalone libimagequant Options See pngquant -h for full list. --quality min-max min and max are numbers in range 0 (worst) to 100 (perfect), similar to JPEG. pngquant will use the least amount of colors required to meet or exceed the max quality. If conversion results in quality below the min quality the image won't be saved (if outputting to stdin, 24-bit original will be output) and pngquant will exit with status code 99. pngquant --quality=65-80 image.png  --ext new.png Set custom extension (suffix) for output filename. By default -or8.png or -fs8.png is used. If you use --ext=.png --force options pngquant will overwrite input files in place (use with caution). -o out.png or --output out.png Writes converted file to the given path. When this option is used only single input file is allowed. --skip-if-larger Don't write converted files if the conversion isn't worth it. --speed N Speed/quality trade-off from 1 (brute-force) to 11 (fastest). The default is 3. Speed 10 has 5% lower quality, but is 8 times faster than the default. Speed 11 disables dithering and lowers compression level. --nofs Disables Floyd-Steinberg dithering. --floyd=0.5 Controls level of dithering (0 = none, 1 = full). Note that the = character is required. --posterize bits Reduce precision of the palette by number of bits. Use when the image will be displayed on low-depth screens (e.g. 16-bit displays or compressed textures in ARGB444 format). --version Print version information to stdout. - Read image from stdin and send result to stdout. -- Stops processing of arguments. This allows use of file names that start with -. If you're using pngquant in a script, it's advisable to put this before file names: pngquant $OPTIONS -- ""$FILE""  License pngquant is dual-licensed: GPL v3 or later, and additional copyright notice must be kept for older parts of the code. See COPYRIGHT for details. For use in non-GPL software (e.g. closed-source or App Store distribution) please ask kornel@pngquant.org for a commercial license. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/pornel/pngquant"	"Small, portable library for high-quality conversion of RGBA images to 8-bit indexed colour images.."	"true"
"Graphics"	"libjpeg-turbo"	"http://libjpeg-turbo.virtualgl.org/"	"A faster library for reading and writing JPEG files.."	"null"	"null"	"null"	"Various licences"	"http://www.libjpeg-turbo.org/About/License"	"null"	"null"	"258"	"47"	"95"	"GitHub - libjpeg-turbo/libjpeg-turbo: Main libjpeg-turbo repository Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 47 Star 258 Fork 95 libjpeg-turbo/libjpeg-turbo Code Issues 6 Pull requests 3 Pulse Graphs Main libjpeg-turbo repository 1,629 commits 9 branches 39 releases 11 contributors C 47.3% Assembly 28.0% HTML 9.0% PHP 5.9% Java 4.4% C++ 1.2% Other 4.2% C Assembly HTML PHP Java C++ Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags 1.0.x 1.1.x 1.2.x 1.3.x 1.4.x avx2_failed_experiments dev ijg master Nothing to show jpeg-ari jpeg-8 jpeg-8d jpeg-8c jpeg-8b jpeg-8a jpeg-7 jpeg-6 jpeg-6bx jpeg-6b jpeg-6a jpeg-5 jpeg-5b jpeg-5a jpeg-4 jpeg-4a jpeg-3 jpeg-2 jpeg-1 1.5.0 1.4.90 1.4.2 1.4.1 1.4.0 1.3.90 1.3.1 1.3.0 1.2.90 1.2.1 1.2.0 1.1.90 1.1.1 1.1.0 1.0.90 1.0.1 1.0.0 0.0.93 0.0.91 0.0.90 Nothing to show New pull request Latest commit db04435 Jul 14, 2016 dcommander Silence pedantic GCC6 code formatting warnings … Apparently it's ""misleading"" to put two self-contained if statements on a single line.  Who knew? Permalink Failed to load latest commit information. cmakescripts Win: Enable testing cross-compiled builds Feb 6, 2016 doc/html Bump TurboJPEG C API revision to 1.5 Feb 29, 2016 java Java: Fix parallel make with autotools Mar 2, 2016 md5 Format copyright headers more consistently May 28, 2016 release Clean up pkgconfig dir when removing RPM & Mac pkg Feb 14, 2016 sharedlib 12-bit JPEG support Aug 9, 2014 simd Fix AArch64 ABI conformance issue in SIMD code Jul 13, 2016 testimages 12-bit JPEG support Aug 9, 2014 win Build: Add integer version macro to jconfig.h May 10, 2016 .gitignore Convert svn:ignore properties to .gitignore Jul 29, 2015 BUILDING.md BUILDING.md: More NASM/YASM clarifications May 31, 2016 CMakeLists.txt Bump version to 1.5.1 to prepare for new commits Jul 6, 2016 ChangeLog.md Use plain upsampling if merged isn't accelerated Jul 13, 2016 LICENSE.md Markdown versions of README, LICENSE, BUILDING Oct 10, 2015 Makefile.am Don't install libturbojpeg.pc if TJPEG disabled Jul 12, 2016 README.ijg Include some comments/doc tweaks from jpeg-9+ Feb 18, 2016 README.md README.md: Link to BUILDING.md Mar 11, 2016 acinclude.m4 Build: Make the NASM autoconf variable persistent Feb 19, 2016 bmp.c Silence pedantic GCC6 code formatting warnings Jul 14, 2016 bmp.h Remove stray closing bracket that prevented the use of this header in… Aug 12, 2013 cderror.h Rename README, LICENSE, BUILDING text files Oct 10, 2015 cdjpeg.c Use consistent/modern code formatting for pointers Feb 19, 2016 cdjpeg.h Use consistent/modern code formatting for pointers Feb 19, 2016 change.log change.log: Refer users to ChangeLog.md Mar 13, 2016 cjpeg.1 Wordsmith GIF limitations in cjpeg.1/djpeg.1 Feb 17, 2016 cjpeg.c More minor code formatting tweaks Feb 19, 2016 coderules.txt Rename README, LICENSE, BUILDING text files Oct 10, 2015 configure.ac Bump version to 1.5.1 to prepare for new commits Jul 6, 2016 djpeg.1 libjpeg API: Partial scanline decompression Feb 19, 2016 djpeg.c libjpeg API: Partial scanline decompression Feb 20, 2016 doxygen-extra.css Make the documentation more readable by displaying fixed-width text (… Aug 10, 2014 doxygen.config Bump TurboJPEG C API revision to 1.5 Feb 29, 2016 example.c Use consistent/modern code formatting for pointers Feb 19, 2016 jaricom.c Replace INT32 with a new internal datatype (JLONG) Oct 14, 2015 jcapimin.c Use consistent/modern code formatting for pointers Feb 19, 2016 jcapistd.c Rename README, LICENSE, BUILDING text files Oct 10, 2015 jcarith.c Use consistent/modern code formatting for pointers Feb 19, 2016 jccoefct.c Use consistent/modern code formatting for pointers Feb 19, 2016 jccolext.c Replace INT32 with a new internal datatype (JLONG) Oct 15, 2015 jccolor.c Format copyright headers more consistently May 29, 2016 jcdctmgr.c More minor code formatting tweaks Feb 19, 2016 jchuff.c Format copyright headers more consistently May 29, 2016 jchuff.h Use consistent/modern code formatting for pointers Feb 19, 2016 jcinit.c Rename README, LICENSE, BUILDING text files Oct 10, 2015 jcmainct.c Use consistent/modern code formatting for pointers Feb 19, 2016 jcmarker.c Use consistent/modern code formatting for pointers Feb 19, 2016 jcmaster.c Merge branch '1.4.x' Mar 16, 2016 jcomapi.c Clean up a couple of copyright messages Feb 19, 2016 jconfig.h.in Build: Add integer version macro to jconfig.h May 11, 2016 jconfig.txt Rename README, LICENSE, BUILDING text files Oct 10, 2015 jconfigint.h.in Regression: Allow co-install of 32-bit/64-bit RPMs Jan 6, 2016 jcparam.c Use consistent/modern code formatting for dbl ptrs Feb 19, 2016 jcphuff.c Use consistent/modern code formatting for pointers Feb 19, 2016 jcprepct.c Use consistent/modern code formatting for pointers Feb 19, 2016 jcsample.c Format copyright headers more consistently May 29, 2016 jcstest.c Use C-style comments Feb 28, 2014 jctrans.c Use consistent/modern code formatting for dbl ptrs Feb 19, 2016 jdapimin.c libjpeg API: Partial scanline decompression Feb 20, 2016 jdapistd.c Fix v7/v8-compatible build Feb 22, 2016 jdarith.c More minor code formatting tweaks Feb 19, 2016 jdatadst-tj.c Don't allow opaque source/dest mgrs to be swapped May 10, 2016 jdatadst.c Don't allow opaque source/dest mgrs to be swapped May 11, 2016 jdatasrc-tj.c Don't allow opaque source/dest mgrs to be swapped May 11, 2016 jdatasrc.c Don't allow opaque source/dest mgrs to be swapped May 11, 2016 jdcoefct.c libjpeg API: Partial scanline decompression Feb 20, 2016 jdcoefct.h Use consistent/modern code formatting for pointers Feb 19, 2016 jdcol565.c Fix compiler warnings under Visual C++ Oct 15, 2015 jdcolext.c Replace INT32 with a new internal datatype (JLONG) Oct 15, 2015 jdcolor.c Use consistent/modern code formatting for pointers Feb 19, 2016 jdct.h Use consistent/modern code formatting for pointers Feb 19, 2016 jddctmgr.c Format copyright headers more consistently May 29, 2016 jdhuff.c Use consistent/modern code formatting for dbl ptrs Feb 19, 2016 jdhuff.h Use consistent/modern code formatting for pointers Feb 19, 2016 jdinput.c libjpeg API: Partial scanline decompression Feb 20, 2016 jdmainct.c Fix MinGW build Feb 6, 2016 jdmainct.h Use consistent/modern code formatting for pointers Feb 19, 2016 jdmarker.c Use consistent/modern code formatting for pointers Feb 19, 2016 jdmaster.c Use plain upsampling if merged isn't accelerated Jul 14, 2016 jdmaster.h libjpeg API: Partial scanline decompression Feb 20, 2016 jdmerge.c Clean up a couple of copyright messages Feb 19, 2016 jdmrg565.c Fix compiler warnings under Visual C++ Oct 15, 2015 jdmrgext.c Replace INT32 with a new internal datatype (JLONG) Oct 15, 2015 jdphuff.c Use consistent/modern code formatting for pointers Feb 19, 2016 jdpostct.c Use consistent/modern code formatting for pointers Feb 19, 2016 jdsample.c Implement h1v2 fancy upsampling Jul 13, 2016 jdsample.h Use consistent/modern code formatting for pointers Feb 19, 2016 jdtrans.c Rename README, LICENSE, BUILDING text files Oct 10, 2015 jerror.c Use consistent/modern code formatting for pointers Feb 19, 2016 jerror.h Rename README, LICENSE, BUILDING text files Oct 10, 2015 jfdctflt.c Use consistent/modern code formatting for pointers Feb 19, 2016 jfdctfst.c Format copyright headers more consistently May 29, 2016 jfdctint.c Format copyright headers more consistently May 29, 2016 jidctflt.c Use consistent/modern code formatting for pointers Feb 19, 2016 jidctfst.c Use consistent/modern code formatting for pointers Feb 19, 2016 jidctint.c Format copyright headers more consistently May 29, 2016 jidctred.c Format copyright headers more consistently May 29, 2016 jinclude.h Rename README, LICENSE, BUILDING text files Oct 10, 2015 jmemmgr.c Use consistent/modern code formatting for pointers Feb 19, 2016 jmemnobs.c Use consistent/modern code formatting for pointers Feb 19, 2016 jmemsys.h Use consistent/modern code formatting for pointers Feb 19, 2016 jmorecfg.h Replace INT32 with a new internal datatype (JLONG) Oct 15, 2015 jpeg_nbits_table.h Integrate a slightly modified version of Mozilla's patch for precompu… Mar 28, 2014 jpegcomp.h Format copyright headers more consistently May 29, 2016 jpegint.h Format copyright headers more consistently May 29, 2016 jpeglib.h libjpeg API: Partial scanline decompression Feb 20, 2016 jpegtran.1 Include some comments/doc tweaks from jpeg-9+ Feb 18, 2016 jpegtran.c Use consistent/modern code formatting for pointers Feb 19, 2016 jquant1.c Use consistent/modern code formatting for pointers Feb 19, 2016 jquant2.c Use consistent/modern code formatting for pointers Feb 19, 2016 jsimd.h Format copyright headers more consistently May 29, 2016 jsimd_none.c Format copyright headers more consistently May 29, 2016 jsimddct.h Use consistent/modern code formatting for pointers Feb 19, 2016 jstdhuff.c Merge branch '1.4.x' Mar 6, 2016 jutils.c Use consistent/modern code formatting for pointers Feb 19, 2016 jversion.h libjpeg API: Partial scanline decompression Feb 20, 2016 libjpeg.map.in Implement in-memory source/destination managers even when not emulati… Jan 18, 2013 libjpeg.txt libjpeg API: Partial scanline decompression Feb 20, 2016 rdbmp.c Use consistent/modern code formatting for pointers Feb 19, 2016 rdcolmap.c Use consistent/modern code formatting for pointers Feb 19, 2016 rdgif.c Rename README, LICENSE, BUILDING text files Oct 10, 2015 rdjpgcom.1 The Independent JPEG Group's JPEG software v7 Jul 27, 2015 rdjpgcom.c Use consistent/modern code formatting for pointers Feb 19, 2016 rdppm.c Merge branch '1.4.x' Mar 31, 2016 rdrle.c Use consistent/modern code formatting for dbl ptrs Feb 19, 2016 rdswitch.c Use consistent/modern code formatting for pointers Feb 19, 2016 rdtarga.c Use consistent/modern code formatting for pointers Feb 19, 2016 structure.txt Rename README, LICENSE, BUILDING text files Oct 10, 2015 tjbench.c Silence pedantic GCC6 code formatting warnings Jul 14, 2016 tjbenchtest.in Extend tjbenchtest so that it tests the dynamic JPEG buffer allocatio… Aug 22, 2014 tjbenchtest.java.in Run the TurboJPEG conformance tests out of a directory in /tmp (for i… Aug 22, 2014 tjexampletest.in Add flags to the TurboJPEG API that allow the caller to force the use… Jun 29, 2012 tjunittest.c Fix memory leak when running tjunittest -yuv Feb 25, 2016 tjutil.c Fix build on Windows May 24, 2011 tjutil.h Add max, min functions May 24, 2011 transupp.c Use consistent/modern code formatting for pointers Feb 19, 2016 transupp.h Use consistent/modern code formatting for pointers Feb 19, 2016 turbojpeg-jni.c Fix compiler warning Feb 14, 2016 turbojpeg-mapfile Oops. Include the tjPlane*() functions in the mapfile so that they ar… Nov 22, 2014 turbojpeg-mapfile.jni Oops. Include the tjPlane*() functions in the mapfile so that they ar… Nov 22, 2014 turbojpeg.c Silence pedantic GCC6 code formatting warnings Jul 14, 2016 turbojpeg.h Declare source buffers in TurboJPEG C API as const Aug 13, 2015 usage.txt usage.txt: Restore accidentally deleted phrase Feb 19, 2016 wizard.txt Convert tabs to spaces in the libjpeg code and the SIMD code (TurboJP… May 11, 2014 wrbmp.c Use consistent/modern code formatting for pointers Feb 19, 2016 wrgif.c Use consistent/modern code formatting for pointers Feb 19, 2016 wrjpgcom.1 The Independent JPEG Group's JPEG software v6 Jul 29, 2015 wrjpgcom.c Format copyright headers more consistently May 29, 2016 wrppm.c libjpeg API: Partial scanline decompression Feb 20, 2016 wrppm.h libjpeg API: Partial scanline decompression Feb 20, 2016 wrrle.c Use consistent/modern code formatting for pointers Feb 19, 2016 wrtarga.c Use consistent/modern code formatting for pointers Feb 19, 2016 README.md Background libjpeg-turbo is a JPEG image codec that uses SIMD instructions (MMX, SSE2, NEON, AltiVec) to accelerate baseline JPEG compression and decompression on x86, x86-64, ARM, and PowerPC systems. On such systems, libjpeg-turbo is generally 2-6x as fast as libjpeg, all else being equal. On other types of systems, libjpeg-turbo can still outperform libjpeg by a significant amount, by virtue of its highly-optimized Huffman coding routines. In many cases, the performance of libjpeg-turbo rivals that of proprietary high-speed JPEG codecs. libjpeg-turbo implements both the traditional libjpeg API as well as the less powerful but more straightforward TurboJPEG API. libjpeg-turbo also features colorspace extensions that allow it to compress from/decompress to 32-bit and big-endian pixel buffers (RGBX, XBGR, etc.), as well as a full-featured Java interface. libjpeg-turbo was originally based on libjpeg/SIMD, an MMX-accelerated derivative of libjpeg v6b developed by Miyasaka Masaru. The TigerVNC and VirtualGL projects made numerous enhancements to the codec in 2009, and in early 2010, libjpeg-turbo spun off into an independent project, with the goal of making high-speed JPEG compression/decompression technology available to a broader range of users and developers. License libjpeg-turbo is covered by three compatible BSD-style open source licenses. Refer to LICENSE.md for a roll-up of license terms. Building libjpeg-turbo Refer to BUILDING.md for complete instructions. Using libjpeg-turbo libjpeg-turbo includes two APIs that can be used to compress and decompress JPEG images: TurboJPEG API This API provides an easy-to-use interface for compressing and decompressing JPEG images in memory. It also provides some functionality that would not be straightforward to achieve using the underlying libjpeg API, such as generating planar YUV images and performing multiple simultaneous lossless transforms on an image. The Java interface for libjpeg-turbo is written on top of the TurboJPEG API. libjpeg API This is the de facto industry-standard API for compressing and decompressing JPEG images. It is more difficult to use than the TurboJPEG API but also more powerful. The libjpeg API implementation in libjpeg-turbo is both API/ABI-compatible and mathematically compatible with libjpeg v6b. It can also optionally be configured to be API/ABI-compatible with libjpeg v7 and v8 (see below.) There is no significant performance advantage to either API when both are used to perform similar operations. Colorspace Extensions libjpeg-turbo includes extensions that allow JPEG images to be compressed directly from (and decompressed directly to) buffers that use BGR, BGRX, RGBX, XBGR, and XRGB pixel ordering. This is implemented with ten new colorspace constants: JCS_EXT_RGB   /* red/green/blue */ JCS_EXT_RGBX  /* red/green/blue/x */ JCS_EXT_BGR   /* blue/green/red */ JCS_EXT_BGRX  /* blue/green/red/x */ JCS_EXT_XBGR  /* x/blue/green/red */ JCS_EXT_XRGB  /* x/red/green/blue */ JCS_EXT_RGBA  /* red/green/blue/alpha */ JCS_EXT_BGRA  /* blue/green/red/alpha */ JCS_EXT_ABGR  /* alpha/blue/green/red */ JCS_EXT_ARGB  /* alpha/red/green/blue */  Setting cinfo.in_color_space (compression) or cinfo.out_color_space (decompression) to one of these values will cause libjpeg-turbo to read the red, green, and blue values from (or write them to) the appropriate position in the pixel when compressing from/decompressing to an RGB buffer. Your application can check for the existence of these extensions at compile time with: #ifdef JCS_EXTENSIONS  At run time, attempting to use these extensions with a libjpeg implementation that does not support them will result in a ""Bogus input colorspace"" error. Applications can trap this error in order to test whether run-time support is available for the colorspace extensions. When using the RGBX, BGRX, XBGR, and XRGB colorspaces during decompression, the X byte is undefined, and in order to ensure the best performance, libjpeg-turbo can set that byte to whatever value it wishes. If an application expects the X byte to be used as an alpha channel, then it should specify JCS_EXT_RGBA, JCS_EXT_BGRA, JCS_EXT_ABGR, or JCS_EXT_ARGB. When these colorspace constants are used, the X byte is guaranteed to be 0xFF, which is interpreted as opaque. Your application can check for the existence of the alpha channel colorspace extensions at compile time with: #ifdef JCS_ALPHA_EXTENSIONS  jcstest.c, located in the libjpeg-turbo source tree, demonstrates how to check for the existence of the colorspace extensions at compile time and run time. libjpeg v7 and v8 API/ABI Emulation With libjpeg v7 and v8, new features were added that necessitated extending the compression and decompression structures. Unfortunately, due to the exposed nature of those structures, extending them also necessitated breaking backward ABI compatibility with previous libjpeg releases. Thus, programs that were built to use libjpeg v7 or v8 did not work with libjpeg-turbo, since it is based on the libjpeg v6b code base. Although libjpeg v7 and v8 are not as widely used as v6b, enough programs (including a few Linux distros) made the switch that there was a demand to emulate the libjpeg v7 and v8 ABIs in libjpeg-turbo. It should be noted, however, that this feature was added primarily so that applications that had already been compiled to use libjpeg v7+ could take advantage of accelerated baseline JPEG encoding/decoding without recompiling. libjpeg-turbo does not claim to support all of the libjpeg v7+ features, nor to produce identical output to libjpeg v7+ in all cases (see below.) By passing an argument of --with-jpeg7 or --with-jpeg8 to configure, or an argument of -DWITH_JPEG7=1 or -DWITH_JPEG8=1 to cmake, you can build a version of libjpeg-turbo that emulates the libjpeg v7 or v8 ABI, so that programs that are built against libjpeg v7 or v8 can be run with libjpeg-turbo. The following section describes which libjpeg v7+ features are supported and which aren't. Support for libjpeg v7 and v8 Features Fully supported libjpeg: IDCT scaling extensions in decompressor libjpeg-turbo supports IDCT scaling with scaling factors of 1/8, 1/4, 3/8, 1/2, 5/8, 3/4, 7/8, 9/8, 5/4, 11/8, 3/2, 13/8, 7/4, 15/8, and 2/1 (only 1/4 and 1/2 are SIMD-accelerated.) libjpeg: Arithmetic coding libjpeg: In-memory source and destination managers See notes below. cjpeg: Separate quality settings for luminance and chrominance Note that the libpjeg v7+ API was extended to accommodate this feature only for convenience purposes. It has always been possible to implement this feature with libjpeg v6b (see rdswitch.c for an example.) cjpeg: 32-bit BMP support cjpeg: -rgb option jpegtran: Lossless cropping jpegtran: -perfect option jpegtran: Forcing width/height when performing lossless crop rdjpgcom: -raw option rdjpgcom: Locale awareness Not supported NOTE: As of this writing, extensive research has been conducted into the usefulness of DCT scaling as a means of data reduction and SmartScale as a means of quality improvement. The reader is invited to peruse the research at http://www.libjpeg-turbo.org/About/SmartScale and draw his/her own conclusions, but it is the general belief of our project that these features have not demonstrated sufficient usefulness to justify inclusion in libjpeg-turbo. libjpeg: DCT scaling in compressor cinfo.scale_num and cinfo.scale_denom are silently ignored. There is no technical reason why DCT scaling could not be supported when emulating the libjpeg v7+ API/ABI, but without the SmartScale extension (see below), only scaling factors of 1/2, 8/15, 4/7, 8/13, 2/3, 8/11, 4/5, and 8/9 would be available, which is of limited usefulness. libjpeg: SmartScale cinfo.block_size is silently ignored. SmartScale is an extension to the JPEG format that allows for DCT block sizes other than 8x8. Providing support for this new format would be feasible (particularly without full acceleration.) However, until/unless the format becomes either an official industry standard or, at minimum, an accepted solution in the community, we are hesitant to implement it, as there is no sense of whether or how it might change in the future. It is our belief that SmartScale has not demonstrated sufficient usefulness as a lossless format nor as a means of quality enhancement, and thus our primary interest in providing this feature would be as a means of supporting additional DCT scaling factors. libjpeg: Fancy downsampling in compressor cinfo.do_fancy_downsampling is silently ignored. This requires the DCT scaling feature, which is not supported. jpegtran: Scaling This requires both the DCT scaling and SmartScale features, which are not supported. Lossless RGB JPEG files This requires the SmartScale feature, which is not supported. What About libjpeg v9? libjpeg v9 introduced yet another field to the JPEG compression structure (color_transform), thus making the ABI backward incompatible with that of libjpeg v8. This new field was introduced solely for the purpose of supporting lossless SmartScale encoding. Furthermore, there was actually no reason to extend the API in this manner, as the color transform could have just as easily been activated by way of a new JPEG colorspace constant, thus preserving backward ABI compatibility. Our research (see link above) has shown that lossless SmartScale does not generally accomplish anything that can't already be accomplished better with existing, standard lossless formats. Therefore, at this time it is our belief that there is not sufficient technical justification for software projects to upgrade from libjpeg v8 to libjpeg v9, and thus there is not sufficient echnical justification for us to emulate the libjpeg v9 ABI. In-Memory Source/Destination Managers By default, libjpeg-turbo 1.3 and later includes the jpeg_mem_src() and jpeg_mem_dest() functions, even when not emulating the libjpeg v8 API/ABI. Previously, it was necessary to build libjpeg-turbo from source with libjpeg v8 API/ABI emulation in order to use the in-memory source/destination managers, but several projects requested that those functions be included when emulating the libjpeg v6b API/ABI as well. This allows the use of those functions by programs that need them, without breaking ABI compatibility for programs that don't, and it allows those functions to be provided in the ""official"" libjpeg-turbo binaries. Those who are concerned about maintaining strict conformance with the libjpeg v6b or v7 API can pass an argument of --without-mem-srcdst to configure or an argument of -DWITH_MEM_SRCDST=0 to cmake prior to building libjpeg-turbo. This will restore the pre-1.3 behavior, in which jpeg_mem_src() and jpeg_mem_dest() are only included when emulating the libjpeg v8 API/ABI. On Un*x systems, including the in-memory source/destination managers changes the dynamic library version from 62.0.0 to 62.1.0 if using libjpeg v6b API/ABI emulation and from 7.0.0 to 7.1.0 if using libjpeg v7 API/ABI emulation. Note that, on most Un*x systems, the dynamic linker will not look for a function in a library until that function is actually used. Thus, if a program is built against libjpeg-turbo 1.3+ and uses jpeg_mem_src() or jpeg_mem_dest(), that program will not fail if run against an older version of libjpeg-turbo or against libjpeg v7- until the program actually tries to call jpeg_mem_src() or jpeg_mem_dest(). Such is not the case on Windows. If a program is built against the libjpeg-turbo 1.3+ DLL and uses jpeg_mem_src() or jpeg_mem_dest(), then it must use the libjpeg-turbo 1.3+ DLL at run time. Both cjpeg and djpeg have been extended to allow testing the in-memory source/destination manager functions. See their respective man pages for more details. Mathematical Compatibility For the most part, libjpeg-turbo should produce identical output to libjpeg v6b. The one exception to this is when using the floating point DCT/IDCT, in which case the outputs of libjpeg v6b and libjpeg-turbo can differ for the following reasons: The SSE/SSE2 floating point DCT implementation in libjpeg-turbo is ever so slightly more accurate than the implementation in libjpeg v6b, but not by any amount perceptible to human vision (generally in the range of 0.01 to 0.08 dB gain in PNSR.) When not using the SIMD extensions, libjpeg-turbo uses the more accurate (and slightly faster) floating point IDCT algorithm introduced in libjpeg v8a as opposed to the algorithm used in libjpeg v6b. It should be noted, however, that this algorithm basically brings the accuracy of the floating point IDCT in line with the accuracy of the slow integer IDCT. The floating point DCT/IDCT algorithms are mainly a legacy feature, and they do not produce significantly more accuracy than the slow integer algorithms (to put numbers on this, the typical difference in PNSR between the two algorithms is less than 0.10 dB, whereas changing the quality level by 1 in the upper range of the quality scale is typically more like a 1.0 dB difference.) If the floating point algorithms in libjpeg-turbo are not implemented using SIMD instructions on a particular platform, then the accuracy of the floating point DCT/IDCT can depend on the compiler settings. While libjpeg-turbo does emulate the libjpeg v8 API/ABI, under the hood it is still using the same algorithms as libjpeg v6b, so there are several specific cases in which libjpeg-turbo cannot be expected to produce the same output as libjpeg v8: When decompressing using scaling factors of 1/2 and 1/4, because libjpeg v8 implements those scaling algorithms differently than libjpeg v6b does, and libjpeg-turbo's SIMD extensions are based on the libjpeg v6b behavior. When using chrominance subsampling, because libjpeg v8 implements this with its DCT/IDCT scaling algorithms rather than with a separate downsampling/upsampling algorithm. In our testing, the subsampled/upsampled output of libjpeg v8 is less accurate than that of libjpeg v6b for this reason. When decompressing using a scaling factor > 1 and merged (AKA ""non-fancy"" or ""non-smooth"") chrominance upsampling, because libjpeg v8 does not support merged upsampling with scaling factors > 1. Performance Pitfalls Restart Markers The optimized Huffman decoder in libjpeg-turbo does not handle restart markers in a way that makes the rest of the libjpeg infrastructure happy, so it is necessary to use the slow Huffman decoder when decompressing a JPEG image that has restart markers. This can cause the decompression performance to drop by as much as 20%, but the performance will still be much greater than that of libjpeg. Many consumer packages, such as PhotoShop, use restart markers when generating JPEG images, so images generated by those programs will experience this issue. Fast Integer Forward DCT at High Quality Levels The algorithm used by the SIMD-accelerated quantization function cannot produce correct results whenever the fast integer forward DCT is used along with a JPEG quality of 98-100. Thus, libjpeg-turbo must use the non-SIMD quantization function in those cases. This causes performance to drop by as much as 40%. It is therefore strongly advised that you use the slow integer forward DCT whenever encoding images with a JPEG quality of 98 or higher. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/libjpeg-turbo/libjpeg-turbo"	"A faster library for reading and writing JPEG files.."	"true"
"Graphics"	"libpng"	"http://www.libpng.org/"	"The official PNG reference library.."	"null"	"null"	"null"	"libpng license"	"http://www.libpng.org/pub/png/src/libpng-LICENSE.txt"	"null"	"null"	"null"	"null"	"null"	"libpng.org:  top level Welcome to libpng.org! Home of Portable Network Graphics (PNG image format) Multiple-image Network Graphics (MNG and JNG image formats) and, of course, libpng (the free reference library for reading and writing PNGs) libpng.org is maintained by Greg Roelofs on servers provided by SourceForge. Different parts of it are mirrored in various locations around the world; see the PNG and MNG home pages for details. There is also a completely separate site for the free MNG library, libmng.             Copyright © 2001-2006 Greg Roelofs."	"null"	"null"	"The official PNG reference library.."	"true"
"Graphics"	"libxmi"	"https://gnu.org/software/libxmi/"	"A function library for rasterizing 2D vector graphics. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"Libxmi - GNU Project - Free Software Foundation (FSF) Libxmi What is libxmi? GNU libxmi is a C/C++ function library for rasterizing 2-D vector graphics. It can draw 2-D graphical primitives, including wide polygonal lines and circular and elliptical arcs, into a user-supplied matrix of pixels. Sophisticated line styles, such as multicolored dashing patterns, can be specified. There is also support for filling and texturing polygons. The current version of the libxmi package is version 1.2, released in June 2000. It can be installed on GNU/Linux, FreeBSD, and Unix systems. Since libxmi is written in ANSI C, it should be easy to compile and install on almost any system with a C compiler. The libxmi package is free software. Here is information on obtaining the source code. What is libxmi good for? It can be used as a drop-in rendering module in any application that needs to scan-convert 2-D vector graphics. It is highly customizable. For example, the `pixel' datatype can be redefined at compile time. The algorithm used for compositing pixels can be redefined too. By default, libxmi uses the Painter's Algorithm (a new pixel value replaces an old one). But it would be trivial to install it so that it uses alpha compositing instead. The package, and its header file xmi.h, include full documentation. Who wrote libxmi? libxmi is based on the scan-conversion code in the X11 sample server, which was written in the late 1980s by programmers associated with the X Consortium. Even though it maintains pixel-level compatibility with X11 drawing functions, it has been decoupled from the X Window System: it no longer requires an X display. In 1999, Robert Maier extracted the scan-conversion code, converted it to ANSI C, and modified it to use a two-stage graphics pipeline (the second stage being the stage when pixel-merging takes place). The resulting code was incorporated as a rendering module in the GNU plotting utilities package, of which he is the maintainer. The rendering module is now being distributed separately, under the name libxmi. Return to GNU's home page. Please send FSF & GNU inquiries & questions to gnu@gnu.org. There are also other ways to contact the FSF. Please send comments on these web pages to webmasters@gnu.org, send other questions to gnu@gnu.org. Copyright (C) 2000 Free Software Foundation, Inc. Verbatim copying and distribution of this entire article is permitted in any medium, provided this notice is preserved. Updated: 09 Aug 2000 rsm"	"null"	"null"	"A function library for rasterizing 2D vector graphics. or later."	"true"
"Graphics"	"mozjpeg"	"https://github.com/mozilla/mozjpeg"	"An improved JPEG encoder.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"2099"	"150"	"191"	"GitHub - mozilla/mozjpeg: Improved JPEG encoder. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 150 Star 2,099 Fork 191 mozilla/mozjpeg Code Issues 40 Pull requests 3 Pulse Graphs Improved JPEG encoder. 3,504 commits 8 branches 7 releases 25 contributors C 48.5% Assembly 27.2% HTML 8.8% PHP 5.7% Java 4.3% C++ 1.2% Other 4.3% C Assembly HTML PHP Java C++ Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags crush dctrellis jpegin jpg-yuv-cleanup libjpeg-turbo master qtable trellis Nothing to show v3.1 v3.0 v2.1 v2.0.1 v2.0 v1.0.1 v1.0 Nothing to show New pull request Latest commit 6ee36ad Jul 15, 2016 pornel committed on GitHub Merge pull request #213 from tmatth/yuvjpeg_crash … yuvjpeg: fix NULL dereference on invalid format string Permalink Failed to load latest commit information. cmakescripts Win: Enable testing cross-compiled builds Feb 6, 2016 doc/html Bump TurboJPEG C API revision to 1.5 Feb 29, 2016 java Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 md5 Format copyright headers more consistently May 28, 2016 release Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 sharedlib Merge libjpeg-turbo r1390 Sep 7, 2014 simd Merge tag '1.5.0' Jun 8, 2016 testimages 12-bit JPEG support Aug 9, 2014 win Merge tag '1.5.0' Jun 7, 2016 .gitauthors Script for git-svn reinitialization Sep 7, 2014 .gitignore Merge remote-tracking branch 'libjpeg-turbo/1.4.x' into libjpeg-turbo Apr 28, 2016 BUILDING.md BUILDING.md: More NASM/YASM clarifications May 31, 2016 BUILDING.txt Merge remote-tracking branch 'libjpeg-turbo/1.4.x' into libjpeg-turbo Apr 27, 2016 CMakeLists.txt Merge tag '1.5.0' Jun 7, 2016 ChangeLog.md Don't allow opaque source/dest mgrs to be swapped May 10, 2016 LICENSE.md Markdown versions of README, LICENSE, BUILDING Oct 10, 2015 Makefile.am Use turbo settings in md5 tests May 5, 2016 README-mozilla.txt Consider vertical gradient in DC trellis Dec 17, 2014 README-turbo.txt Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 README.ijg Include some comments/doc tweaks from jpeg-9+ Feb 18, 2016 README.md Re-order links. Jan 12, 2015 acinclude.m4 Build: Make the NASM autoconf variable persistent Feb 19, 2016 bmp.c Add the ability to benchmark YCCK JPEG compression/decompression. Thi… Jan 16, 2015 bmp.h Initial commit of libjpeg-turbo plus readme edits. Jan 13, 2014 cderror.h Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 cdjpeg.c Use consistent/modern code formatting for pointers Feb 19, 2016 cdjpeg.h Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 change.log change.log: Refer users to ChangeLog.md Mar 13, 2016 cjpeg.1 Wordsmith GIF limitations in cjpeg.1/djpeg.1 Feb 17, 2016 cjpeg.c Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 coderules.txt Rename README, LICENSE, BUILDING text files Oct 10, 2015 configure.ac Merge tag '1.5.0' Jun 7, 2016 djpeg.1 libjpeg API: Partial scanline decompression Feb 19, 2016 djpeg.c libjpeg API: Partial scanline decompression Feb 20, 2016 doxygen-extra.css Make the documentation more readable by displaying fixed-width text (… Aug 10, 2014 doxygen.config Bump TurboJPEG C API revision to 1.5 Feb 29, 2016 example.c Use consistent/modern code formatting for pointers Feb 19, 2016 git-init-svn.sh Script for git-svn reinitialization Sep 7, 2014 jaricom.c Replace INT32 with a new internal datatype (JLONG) Oct 14, 2015 jcapimin.c Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 jcapistd.c Restore backward ABI compatibility with libjpeg/libjpeg-turbo by movi… Nov 4, 2014 jcarith.c Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 jccoefct.c Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 jccolext.c Replace INT32 with a new internal datatype (JLONG) Oct 15, 2015 jccolor.c Format copyright headers more consistently May 29, 2016 jcdctmgr.c Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 jcext.c Const on getters Jan 24, 2015 jchuff.c Format copyright headers more consistently May 29, 2016 jchuff.h Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 jcinit.c Fix trellis / no Huffman opt combination Dec 9, 2014 jcmainct.c Use consistent/modern code formatting for pointers Feb 19, 2016 jcmarker.c Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 jcmaster.c Allocate from temporary image pool to avoid leaking mem mgr Jun 8, 2016 jcmaster.h Merge remote-tracking branch 'libjpeg-turbo/1.4.x' into libjpeg-turbo Apr 27, 2016 jcomapi.c Clean up a couple of copyright messages Feb 19, 2016 jconfig.h.in Merge tag '1.5.0' Jun 7, 2016 jconfig.txt Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 jconfigint.h.in Regression: Allow co-install of 32-bit/64-bit RPMs Jan 6, 2016 jcparam.c Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 jcphuff.c Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 jcprepct.c Use consistent/modern code formatting for pointers Feb 19, 2016 jcsample.c Format copyright headers more consistently May 29, 2016 jcstest.c Use mozjpeg defaults by default Nov 19, 2014 jctrans.c Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 jdapimin.c Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 jdapistd.c Fix v7/v8-compatible build Feb 22, 2016 jdarith.c More minor code formatting tweaks Feb 19, 2016 jdatadst-tj.c Don't allow opaque source/dest mgrs to be swapped May 11, 2016 jdatadst.c Allocate from temporary image pool to avoid leaking mem mgr Jun 8, 2016 jdatasrc-tj.c Don't allow opaque source/dest mgrs to be swapped May 11, 2016 jdatasrc.c Don't allow opaque source/dest mgrs to be swapped May 11, 2016 jdcoefct.c libjpeg API: Partial scanline decompression Feb 20, 2016 jdcoefct.h Use consistent/modern code formatting for pointers Feb 19, 2016 jdcol565.c Fix compiler warnings under Visual C++ Oct 15, 2015 jdcolext.c Replace INT32 with a new internal datatype (JLONG) Oct 15, 2015 jdcolor.c Use consistent/modern code formatting for pointers Feb 19, 2016 jdct.h Use consistent/modern code formatting for pointers Feb 19, 2016 jddctmgr.c Format copyright headers more consistently May 29, 2016 jdhuff.c Use consistent/modern code formatting for dbl ptrs Feb 19, 2016 jdhuff.h Use consistent/modern code formatting for pointers Feb 19, 2016 jdinput.c libjpeg API: Partial scanline decompression Feb 20, 2016 jdmainct.c Fix MinGW build Feb 6, 2016 jdmainct.h Use consistent/modern code formatting for pointers Feb 19, 2016 jdmarker.c Use consistent/modern code formatting for pointers Feb 19, 2016 jdmaster.c libjpeg API: Partial scanline decompression Feb 20, 2016 jdmaster.h libjpeg API: Partial scanline decompression Feb 20, 2016 jdmerge.c Clean up a couple of copyright messages Feb 19, 2016 jdmrg565.c Fix compiler warnings under Visual C++ Oct 15, 2015 jdmrgext.c Replace INT32 with a new internal datatype (JLONG) Oct 15, 2015 jdphuff.c Use consistent/modern code formatting for pointers Feb 19, 2016 jdpostct.c Use consistent/modern code formatting for pointers Feb 19, 2016 jdsample.c Format copyright headers more consistently May 29, 2016 jdsample.h Use consistent/modern code formatting for pointers Feb 19, 2016 jdtrans.c Rename README, LICENSE, BUILDING text files Oct 10, 2015 jerror.c Use consistent/modern code formatting for pointers Feb 19, 2016 jerror.h Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 jfdctflt.c Use consistent/modern code formatting for pointers Feb 19, 2016 jfdctfst.c Format copyright headers more consistently May 29, 2016 jfdctint.c Format copyright headers more consistently May 29, 2016 jidctflt.c Use consistent/modern code formatting for pointers Feb 19, 2016 jidctfst.c Use consistent/modern code formatting for pointers Feb 19, 2016 jidctint.c Format copyright headers more consistently May 29, 2016 jidctred.c Format copyright headers more consistently May 29, 2016 jinclude.h Rename README, LICENSE, BUILDING text files Oct 10, 2015 jmemmgr.c Use consistent/modern code formatting for pointers Feb 19, 2016 jmemnobs.c Use consistent/modern code formatting for pointers Feb 19, 2016 jmemsys.h Use consistent/modern code formatting for pointers Feb 19, 2016 jmorecfg.h Replace INT32 with a new internal datatype (JLONG) Oct 15, 2015 jpeg_nbits_table.h Use precomputed table Jul 24, 2014 jpegcomp.h Format copyright headers more consistently May 29, 2016 jpegint.h Allocate from temporary image pool to avoid leaking mem mgr Jun 8, 2016 jpeglib.h Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 jpegtran.1 Include some comments/doc tweaks from jpeg-9+ Feb 18, 2016 jpegtran.c Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 jpegyuv.c Merge pull request #207 from mozilla/jpg-yuv-cleanup May 25, 2016 jquant1.c Use consistent/modern code formatting for pointers Feb 19, 2016 jquant2.c Use consistent/modern code formatting for pointers Feb 19, 2016 jsimd.h Format copyright headers more consistently May 29, 2016 jsimd_none.c Format copyright headers more consistently May 29, 2016 jsimddct.h Use consistent/modern code formatting for pointers Feb 19, 2016 jstdhuff.c Merge branch '1.4.x' Mar 6, 2016 jutils.c Use consistent/modern code formatting for pointers Feb 19, 2016 jversion.h Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 libjpeg.map.in Initial commit of libjpeg-turbo plus readme edits. Jan 14, 2014 libjpeg.txt libjpeg API: Partial scanline decompression Feb 20, 2016 rd_average.sh Adding scripts to generate rd-curves. Mar 17, 2014 rd_collect.sh Adding scripts to generate rd-curves. Mar 17, 2014 rd_collect_sub.sh Adding scripts to generate rd-curves. Mar 17, 2014 rd_plot.sh Adding scripts to generate rd-curves. Mar 17, 2014 rdbmp.c Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 rdcolmap.c Use consistent/modern code formatting for pointers Feb 19, 2016 rdgif.c Rename README, LICENSE, BUILDING text files Oct 10, 2015 rdjpeg.c Reconcile indentation, whitespace, and other code formatting with lib… Nov 6, 2014 rdjpgcom.1 The Independent JPEG Group's JPEG software v7 Jul 27, 2015 rdjpgcom.c Use consistent/modern code formatting for pointers Feb 19, 2016 rdpng.c rdpng: convert 16-bit input to 8-bit Mar 13, 2015 rdppm.c Merge branch '1.4.x' Mar 31, 2016 rdrle.c Use consistent/modern code formatting for dbl ptrs Feb 19, 2016 rdswitch.c Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 rdtarga.c Use consistent/modern code formatting for pointers Feb 19, 2016 structure.txt Rename README, LICENSE, BUILDING text files Oct 10, 2015 tjbench.c TJBench: Fix segfault on Android Feb 1, 2016 tjbenchtest.in Extend tjbenchtest so that it tests the dynamic JPEG buffer allocatio… Aug 22, 2014 tjbenchtest.java.in Run the TurboJPEG conformance tests out of a directory in /tmp (for i… Aug 22, 2014 tjexampletest.in Initial commit of libjpeg-turbo plus readme edits. Jan 14, 2014 tjunittest.c Fix memory leak when running tjunittest -yuv Feb 25, 2016 tjutil.c Initial commit of libjpeg-turbo plus readme edits. Jan 14, 2014 tjutil.h Initial commit of libjpeg-turbo plus readme edits. Jan 14, 2014 transupp.c Use consistent/modern code formatting for pointers Feb 19, 2016 transupp.h Use consistent/modern code formatting for pointers Feb 19, 2016 turbojpeg-jni.c Fix compiler warning Feb 14, 2016 turbojpeg-mapfile Oops. Include the tjPlane*() functions in the mapfile so that they ar… Nov 22, 2014 turbojpeg-mapfile.jni Oops. Include the tjPlane*() functions in the mapfile so that they ar… Nov 22, 2014 turbojpeg.c Merge remote-tracking branch 'libjpeg-turbo/master' into libjpeg-turbo Apr 28, 2016 turbojpeg.h Declare source buffers in TurboJPEG C API as const Aug 13, 2015 usage.txt usage.txt: Restore accidentally deleted phrase Feb 19, 2016 wizard.txt Convert tabs to spaces in the libjpeg code and the SIMD code (TurboJP… May 11, 2014 wrbmp.c Use consistent/modern code formatting for pointers Feb 19, 2016 wrgif.c Use consistent/modern code formatting for pointers Feb 19, 2016 wrjpgcom.1 The Independent JPEG Group's JPEG software v6 Jul 29, 2015 wrjpgcom.c Format copyright headers more consistently May 29, 2016 wrppm.c libjpeg API: Partial scanline decompression Feb 20, 2016 wrppm.h libjpeg API: Partial scanline decompression Feb 20, 2016 wrrle.c Use consistent/modern code formatting for pointers Feb 19, 2016 wrtarga.c Use consistent/modern code formatting for pointers Feb 19, 2016 yuvjpeg.c yuvjpeg: fix NULL dereference on invalid format string Jul 15, 2016 README.md Mozilla JPEG Encoder Project This project's goal is to reduce the size of JPEG files without reducing quality or compatibility with the vast majority of the world's deployed decoders. The idea is to reduce transfer times for JPEGs on the Web, thus reducing page load times. 'mozjpeg' is not intended to be a general JPEG library replacement. It makes tradeoffs that are intended to benefit Web use cases and focuses solely on improving encoding. It is best used as part of a Web encoding workflow. For a general JPEG library (e.g. your system libjpeg), especially if you care about decoding, we recommend libjpeg-turbo. More information: Mailing List Version 3.0 Announcement Version 2.0 Announcement Version 1.0 Announcement Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/mozilla/mozjpeg"	"An improved JPEG encoder.."	"true"
"Graphics"	"OpenGL"	"https://www.opengl.org/"	"The industry standard for high-performance graphics, with a native C binding.."	"null"	"null"	"null"	"widget toolkits"	"https://en.wikipedia.org/wiki/Widget_toolkit"	"null"	"null"	"null"	"null"	"null"	"OpenGL - The Industry Standard for High Performance Graphics The Industry's Foundation for High Performance Graphics from games to virtual reality, mobile phones to supercomputers Loading Home Documentation About OpenGL 4.5 OpenGL Shading Language About OpenGL Extensions OpenGL Registry Spec Feedback OpenGL 4 Reference Pages OpenGL 3.3 Reference Pages OpenGL 2.1 Reference Pages OS/Platform Implementations OpenGL Books Coding Resources OpenGL SDK Getting Started OpenGL Registry FAQ GLUT & Utility Libraries Programming Language Bindings Sample Code & Tutorials Benchmarks Mailing Lists & News Groups OpenGL StackOverflow Archived Resources Wiki Forums About OpenGL Contact Us OpenGL logo Advertise on OpenGL Jobs Submit News OpenGL Headline News Mesa 12.0 Released With OpenGL 4.3 Support, Intel Vulkan & Many Other Features Category: Developers • Comments Jul 08, 2016 While it’s coming late, the huge Mesa 12.0 release is now official! Mesa 12.0 is easily one of the biggest updates to this important open-source user-space OpenGL driver stack in quite some time and will offer much better support and features especially for Intel, Radeon, and NVIDIA open-source Linux desktop users/gamers. OpenGL presentations from GPU Technology Conference now available Category: Developers • Comments Jul 07, 2016 Recorded OpenGL presentations and accompanying slides from this year’s GPU Technology Conference are available now.  Among the modern OpenGL content is GPU-Driven Rendering in Vulkan and OpenGL (PDF slides), Enhanced Blueprint Rendering in OpenGL (PDF slides), High-Performance, Low-Overhead Rendering with OpenGL and Vulkan (PDF slides), VR Multi GPU Acceleration Featuring Autodesk VRED (PDF slides).  The complete session list is available; sign in to view all the recorded presentations and download slides. NeoAxis 3D Engine 3.5 Released Category: Developers • Comments Jul 07, 2016 NeoAxis Group announces a new release of its OpenGL-based versatile 3D project development environment NeoAxis Engine 3.5. The latest version features updated editor design, a new tool to quickly import 3D models, updated example maps, as well as multiple minor changes and bug fixes. glbinding 2.1.1 released Category: Developers • Comments Jul 01, 2016 CG Internals released a minor iteration of its cross-platform C++ binding for the OpenGL API. glbinding 2.1.1 simplifies type-safe use of GLboolean and provides additional OpenGL meta and context information queries. A list of all changes of the 2.1.1 release is available on GitHub. Book: OpenGL Game Development By Example Category: Developers • Comments Jun 20, 2016 The book “OpenGL Game Development By Example” starts off by showing you how to set up a development environment using Visual Studio, and create a code framework for your game. It then walks you through creation of two games–a 2D platform game called Roboracer 2D and a 3D first-person space shooter game–using OpenGL to render both 2D and 3D graphics using a 2D coordinate system. Read more OpenGL news Upcoming Events 2016 All about the API OpenCL training in Toronto, Canada Web3D 2016 2016 SIGGRAPH OpenCL training in Sunnyvale, CA 2016 GDC Europe 2016 CEDEC More upcoming events Khronos Recent News Khronos at SIGGRAPH 2016 Interested in Becoming a Khronos Member? The long-awaited Vulkan patch for Doom is now available Five steps to adding ray tracing to an OpenGL ES-based deferred lighting system FPGA with OpenCL Solution Released to Deep Learning View all Khronos News Getting Started with OpenGL Official OpenGL 4.5 feedback thread OpenGL Reference Cards OpenGL Reference Pages OpenGL Conformant Products Getting Started with Vulkan Vulkan Reference Cards Getting Started with OpenGL ES OpenGL ES Reference Cards Getting Started with WebGL WebGL 1.0 Specification (Final) WebGL Public Wiki WebGL Reference Cards Sponsorship Links Deluxe Checks reorder 9450 SW Gemini Drive #45043 Beaverton, OR 97008-6018 USA Office: +1 (415) 869-8627 Fax: +1 (707) 202-0030 Quick Links Contact Us About Us Privacy Policy Advertise on OpenGL Subscribe to our newsletter Follow us! Facebook Twitter YouTube News feeds Hosting provided by OpenGL is a registered trademark of SGI Website Copyright ©1997-2016 Khronos Group. All rights reserved. OpenGL.org organization managed by Gold Standard Group and website maintained by Out of Control"	"null"	"null"	"The industry standard for high-performance graphics, with a native C binding.."	"true"
"Graphical User Interface"	"GTK+"	"http://www.gtk.org/"	"A cross-platform widget toolkit. only."	"null"	"null"	"null"	"GNU LGPL2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"null"	"null"	"null"	"The GTK+ Project The GTK+ Project About Features Download Screenshots Documentation Development Support News Feed Follow the GTK+ project on: blog | Twitter | identi.ca | Google+ What is GTK+, and how can I use it? GTK+, or the GIMP Toolkit, is a multi-platform toolkit for creating graphical user interfaces. Offering a complete set of widgets, GTK+ is suitable for projects ranging from small one-off tools to complete application suites. Where can I use it? Everywhere! GTK+ is cross-platform and boasts an easy to use API, speeding up your development time. Take a look at the screenshots to see a number of platforms GTK+ will run. What languages are supported? GTK+ is written in C but has been designed from the ground up to support a wide range of languages, not only C/C++. Using GTK+ from languages such as Perl and Python (especially in combination with the Glade GUI builder) provides an effective method of rapid application development. Are there any licensing restrictions? GTK+ is free software and part of the GNU Project. However, the licensing terms for GTK+, the GNU LGPL, allow it to be used by all developers, including those developing proprietary software, without any license fees or royalties. Get an overview of GTK+. Understand who started it, the basic architecture and why we use the license we do. GTK+ has been involved in many projects and some big platforms. To get a glimpse of what people think of GTK+ and how it has been used in commercial projects, read the success stories... To find out how more about what GTK+ can do for you, visit our features page. If you want to contribute, you are more than welcome. Copyright © 2007-2016 The GTK+ Team | Valid XHTML and CSS"	"null"	"null"	"A cross-platform widget toolkit. only."	"true"
"Graphical User Interface"	"IUP"	"http://webserver2.tecgraf.puc-rio.br/iup/"	"Another cross-platform widget toolkit.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"null"	"null"	"null"	"IUP - Portable User Interface <body> <p>This page uses frames, but your browser doesn&#39;t support them.</p> </body>"	"null"	"null"	"Another cross-platform widget toolkit.."	"true"
"Graphical User Interface"	"Tk"	"http://www.tcl.tk/"	"A basic widget toolkit. Part of Tcl/Tk.."	"null"	"null"	"null"	"Tcl/Tk License"	"http://www.tcl.tk/software/tcltk/license.html"	"null"	"null"	"null"	"null"	"null"	"Tcl Developer Site hosted by HOME ABOUT TCL/TK SOFTWARE CORE DEVELOPMENT COMMUNITY DOCUMENTATION Tcl Conference News Mark your calendars for the 14th European Tcl/Tk User Meeting to be held June 25-26, 2016 in Eindhoven, Netherlands. Older conference info Latest Software Releases Tcl/Tk 8.6.5 Feb 29, 2016 Tcl/Tk 8.5.19 Feb 12, 2016        Download Tcl/Tk Tcl Dev Kit 5.4.0 Dec 08, 2014 ActiveTcl 8.6.4.1 Jul 10, 2015 ActiveTcl 8.5.18.0 Apr 27, 2015 Tklib 0.6 Mar 25, 2013 Tcllib 1.18 Feb 3, 2016 Thread 2.7.3 Welcome to the Tcl Developer Xchange! Join the many thousands of software developers who are already more productive with help from the Tcl programming language and the Tk graphical user interface toolkit. Tcl (Tool Command Language) is a very powerful but easy to learn dynamic programming language, suitable for a very wide range of uses, including web and desktop applications, networking, administration, testing and many more. Open source and business-friendly, Tcl is a mature yet evolving language that is truly cross platform, easily deployed and highly extensible. Tk is a graphical user interface toolkit that takes developing desktop applications to a higher level than conventional approaches. Tk is the standard GUI not only for Tcl, but for many other dynamic languages, and can produce rich, native applications that run unchanged across Windows, Mac OS X, Linux and more. Learn More about Tcl/Tk Get Tcl/Tk Now ( 8.6 ) ( 8.5 ) Tcl achieves Rung 2 (highest) Coverity security rank New Tcl/Tk books on network programming and a programming cookbook. See more books. Also check out the TkDocs site for Tk examples and design ideas. Core Development A wide variety of developers contribute to the open source Tcl and Tk core, which is hosted at core.tcl.tk. The Tcl Core Team (TCT) helps steer this development through mechanisms like Tcl Improvement Proposals (TIP's) and the core mailing list. Read More about how the Tcl/Tk core is developed, and how you can help. Tcl/Tk Community The vibrant Tcl user community provides a variety of support resources to help working with Tcl/Tk. Among others, the Tcler's Wiki provides a constantly updated set of tips and tricks, while comp.lang.tcl remains the best forum for Tcl/Tk discussions. Read More about these and other useful community resources. This is the main Tcl Developer Xchange site, www.tcl.tk .    About this Site | webmaster@-SPAM-.tcl.tk Home | About Tcl/Tk | Software | Core Development | Community | Documentation"	"null"	"null"	"A basic widget toolkit. Part of Tcl/Tk.."	"true"
"Graphical User Interface"	"XForms Toolkit"	"http://xforms-toolkit.org/"	"A widget toolkit designed for the XWindow system. only."	"null"	"null"	"null"	"GNU LGPL2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"null"	"null"	"null"	"XForms Toolkit XForms Toolkit  (""Forms Library for X"") +++ 2014/06/28: New stable version xforms-1.2.4 has been released +++ The newest stable release of XForms, version 1.2.4, is now available from the ""Download Area"" of the Savannah project page. What is the XForms toolkit? XForms is a graphical user interface toolkit for X based on the X11 Xlib library. I.e., it allows you to create windows, containing all kinds of widgets (buttons, sliders, browsers, menus etc.) with a few lines of code and then attach actions to the widgets, i.e., have some function called when a button is pressed. To make this even easier XForms comes with a program called fdesign that allows you to design a GUI for a program directly on the screen and which then writes out the necessary C code for it. XForms is written in C and has a C API, i.e., you can use it directly from a C program. It should work with X11 R4, R5, R6 & R7 and under all kinds of operating systems of the UNIX family (including MacOS X) as well as at least OpenVMS, OS/2 und Windows NT 4.0. In addition, the library is extensible and new objects can easily be created and added to the library. Please note: the XForms toolkit has nothing to do with the W3C standardized XML XForms format which unfortunately also is called ""XForms"". The XForms toolkit existed long before the XML XForms format stuff was invented and those newcomers just picked the same name;-) If you're looking for this XML format you better go to e.g. www.w3.org/MarkUp/Forms/. Where do I get it? The source package for the XForms library (as well as a git repository going back to 2002) can be found at the XForms project page at Savannah, see the ""Download Area"". The newest ""stable"" version is 1.0.93 (but, of course, you're invited to test pre-releases for 1.0.94 when they become available). Where do I find binaries or RPM/DEP packages? Sorry, but there are no binaries for XForms to be downloaded from here or the XForms project page. XForms is supposed to work on a lot of different operating systems and architectures, which would make creating and distributing binaries a very difficult task - actually, it used to be necessary to do just that while XForms wasn't open source and that was a real PITA... On the other hand, the XForms toolkit is included in a lot of Linux, BSD and other distributions, so checking if it's part of your distribution may allow you to find a RPM or DEB package (or whatever your distribution uses) which is just right for your system. But take care: many distributions still come with a rather old versions of the library, if you want a newer one it may be necessary to build and install it from the sources, which actually isn't very difficult. Here you will find a short description of the process. Documentation If you're looking for a few very simple examples of how the XForms library can be used go here. Or just go directly to the newest version of the documentation. You can also download it in PDF format or a packed archive of the HTML version. An older version of the documentation (for version 0.89) exists only in a PostScript version. This is the version that should be consulted for versions of the library up to version 1.0.90 of the library. A packed archive of the HTML version 0.88 also still can be downloaded. Screenshots Since XForms is a toolkit and not a program there can't be any screenshots from XForms itself. But here you can find screenshots from programs that have been written using XForms. They may also give you an impression of what kind of applications XForms is being used for. If you have some more nice ones please don't hesitate to send them in;-) License While XForms was a closed source project at first (but with a liberal license for use in non-commercial applications) since 2002 it is open software, distributed under the GNU Lesser General Public License. Where do I get help? The best place to look for help, point out bugs or even send patches to is the XForms mailing list. The mailing list has been relocated in August 2009, if you're looking for posts from before August 11, 2009 please go here. How can I help? You can try out development releases and report your experiences (or send patches;-) to the the XForms mailing list. Don't falsely assume that a problem you encounter is too trivial (or already known). Is the XForms toolkit something new? Not at all, it actually was one of the first GUI toolkits freely available, It was developed in the begining of the 1990s by Prof. Mark Overmars and Dr. T. C. Zhao. Later also Steve Lamont joined the developers. See here what the original XForms homepage said about them. Since April 2002 XForms is open source and development has continued by a number of volunteers. Why use XForms and not some other GUI toolkit? Good question;-) First of all, XForms is small, thus it's relatively easy to learn how to use it. Then, when you write in C you will rather likely also want to use a toolkit with a C API (but that, of course, shouldn't keep you from using XForms with e.g. C++). That cuts down your options considerably. The most likely alternative would probably be GTK+. GTK+ is definitely quite nice and may have some advantages over XForms. On the other hand GTK+ (as well as other toolkits) can be a bit daunting to get used to. Moreover, GTK+ can't be used for setuid-ed programs (i.e. programs that run with the permissions of a different user than the one that started the program). While this is touted as a security feature it can get in the way of programs that need special permissions e.g. to be able to access devices, which typically have some access restrictions. Last modified: June 28, 2014 by Jens Thoms Törring"	"null"	"null"	"A widget toolkit designed for the XWindow system. only."	"true"
"Image Processing"	"libccv"	"http://libccv.org/"	"A Modern Computer Vision Library.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"5313"	"366"	"1292"	"GitHub - liuliu/ccv: C-based/Cached/Core Computer Vision Library, A Modern Computer Vision Library Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 366 Star 5,313 Fork 1,292 liuliu/ccv Code Issues 49 Pull requests 16 Wiki Pulse Graphs C-based/Cached/Core Computer Vision Library, A Modern Computer Vision Library http://libccv.org 903 commits 11 branches 0 releases 5 contributors C 71.0% Cuda 12.6% HTML 10.6% Ruby 1.5% C++ 1.1% Ragel in Ruby Host 1.1% Other 2.1% C Cuda HTML Ruby C++ Ragel in Ruby Host Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: stable Switch branches/tags Branches Tags gh-pages r0.1-rc1 r0.2-rc1 r0.3-rc1 r0.4-rc1 r0.5-rc1 r0.6-rc1 r0.7-rc1 r0.7-rc2 stable unstable Nothing to show Nothing to show New pull request Latest commit 07fc691 Apr 12, 2016 liuliu A better fix. Permalink Failed to load latest commit information. bin Added new post Dec 24, 2014 doc updated documents, added vgg-d model, about ready for the big release Dec 23, 2014 js changed ccv_unserialize/ccv_serialize to a more sensible name Mar 14, 2012 lib A better fix. Apr 12, 2016 samples Correct download logic Mar 6, 2016 serve updated documents, added vgg-d model, about ready for the big release Dec 23, 2014 site Added new post Dec 24, 2014 test Fix unittest on Mac OSX due to different libpng versions Dec 24, 2014 .doxygen.conf added a script to generate markdown doc from xml of Doxygen, haven't … Dec 21, 2014 .gitignore add libccv.org site source file to the tree Mar 1, 2014 .travis.yml try libatlas-base-dev Dec 12, 2014 COPYING fix typo. change license for files included in ./doc ./samples, ./sit… Mar 6, 2014 README.md portability => portable Dec 17, 2014 THANKS added THANKS Jan 12, 2014 README.md Build Status Travis CI VM: Raspberry Pi: FreeBSD x64: Linux x64: Mac OSX: Backstory I set to build ccv with a minimalism inspiration. That was back in 2010, out of the frustration with the computer vision library then I was using, ccv was meant to be a much easier to deploy, simpler organized code with a bit caution with dependency hygiene. The simplicity and minimalistic nature at then, made it much easier to integrate into any server-side deployment environments. Portable and Embeddable Fast forward to now, the world is quite different from then, but ccv adapts pretty well in this new, mobile-first environment. It now runs on Mac OSX, Linux, FreeBSD, Windows*, iPhone, iPad, Android, Raspberry Pi. In fact, anything that has a proper C compiler probably can run ccv. The majority (with notable exception of convolutional networks, which requires a BLAS library) of ccv will just work with no compilation flags or dependencies. Modern Computer Vision Algorithms One core concept of ccv development is application driven. Thus, ccv ends up implementing a handful state-of-art algorithms. It includes a close to state-of-the-art image classifier, a state-of-the-art frontal face detector, reasonable collection of object detectors for pedestrians and cars, a useful text detection algorithm, a long-term general object tracking algorithm, and the long-standing feature point extraction algorithm. Clean Interface with Cached Image Preprocessing Many computer vision tasks nowadays consist of quite a few preprocessing layers: image pyramid generation, color space conversion etc. These potentially redundant operations cannot be easily eliminated within a mature API. ccv provides a built-in cache mechanism that, while maintains a clean function interface, effectively does transparent cache for you. For computer vision community, there is no shortage of good algorithms, good implementation is what it lacks of. After years, we stuck in between either the high-performance, battle-tested but old algorithm implementations, or the new, shining but Matlab algorithms. ccv is my take on this problem, hope you enjoy it. License ccv source code is distributed under BSD 3-clause License. ccv's data models and documentations are distributed under Creative Commons Attribution 4.0 International License. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/liuliu/ccv"	"A Modern Computer Vision Library.."	"true"
"JSON"	"Jansson"	"http://www.digip.org/jansson/"	"A C library for encoding, decoding and manipulating JSON.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"1121"	"86"	"311"	"GitHub - akheron/jansson: C library for encoding, decoding and manipulating JSON data Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 86 Star 1,121 Fork 311 akheron/jansson Code Issues 19 Pull requests 10 Wiki Pulse Graphs C library for encoding, decoding and manipulating JSON data http://www.digip.org/jansson/ 776 commits 19 branches 23 releases Fetching contributors C 74.3% CMake 19.9% Shell 3.3% Makefile 1.4% M4 1.1% C CMake Shell Makefile M4 Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags 1.0 1.1 1.2 1.3 2.0 2.1 2.2 2.3 2.4 2.5 2.6 2.7 bignum c++-api isnan-isinf-checks master object-insertion-order pull-126 simplify-snprintf-checks Nothing to show v2.7 v2.6 v2.5 v2.4 v2.3.1 v2.3 v2.2.1 v2.2 v2.1 v2.0.1 v2.0 v1.3 v1.2.1 v1.2 v1.1.3 v1.1.2 v1.1.1 v1.1 v1.0.4 v1.0.3 v1.0.2 v1.0.1 v1.0 Nothing to show New pull request Latest commit 8f06796 Jun 20, 2016 akheron committed on GitHub Merge pull request #290 from Thynix/documentation … Polish API documentation Permalink Failed to load latest commit information. android Fix for issue #282 May 3, 2016 cmake Simplify snprintf and vsnprintf checking for Visual Studio May 30, 2016 doc doc: fix code block formatting Jun 17, 2016 examples examples/README.rst: Fix formatting Dec 30, 2014 src Fix subnormal number parsing on mingw32 May 17, 2016 test Fix for issue #282 May 3, 2016 .gitignore SmartOS build fix Apr 6, 2014 .travis.yml Add support for coverage/coveralls.io in cmake project. Dec 12, 2014 Android.mk Android.mk: Add -DHAVE_STDINT_H to LOCAL_CFLAGS Jul 31, 2014 CHANGES Fix a typo Dec 23, 2015 CMakeLists.txt Simplify snprintf and vsnprintf checking for Visual Studio May 30, 2016 CleanSpec.mk Create Android.mk, preconfigured jansson_config.h and CleanSpec.mk fo… Mar 27, 2013 LICENSE Update copyrights for 2014 Jan 28, 2014 Makefile.am Don't use GNU-make specific export for global AM_CFLAGS Aug 26, 2014 README.rst Change readthedocs domain Apr 28, 2016 appveyor.yml appveyor.yml: Build on all Visual Studio versions Jun 3, 2016 configure.ac Add Makefile.am for examples Dec 30, 2014 jansson.pc.in Add pkg-config support Jan 7, 2010 release.sh Compress bz2 doc tarballs with bzip2 instead of gzip Jan 6, 2013 README.rst Jansson README Jansson is a C library for encoding, decoding and manipulating JSON data. Its main features and design principles are: Simple and intuitive API and data model Comprehensive documentation No dependencies on other libraries Full Unicode support (UTF-8) Extensive test suite Jansson is licensed under the MIT license; see LICENSE in the source distribution for details. Compilation and Installation If you obtained a source tarball, just use the standard autotools commands: $ ./configure $ make $ make install  To run the test suite, invoke: $ make check  If the source has been checked out from a Git repository, the ./configure script has to be generated first. The easiest way is to use autoreconf: $ autoreconf -i  Documentation Documentation is available at http://jansson.readthedocs.io/en/latest/. The documentation source is in the doc/ subdirectory. To generate HTML documentation, invoke: $ make html  Then, point your browser to doc/_build/html/index.html. Sphinx 1.0 or newer is required to generate the documentation. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/akheron/jansson"	"A C library for encoding, decoding and manipulating JSON.."	"true"
"JSON"	"jsmn"	"http://zserge.com/jsmn.html"	"A minimalistic JSON parser.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"346"	"54"	"90"	"GitHub - zserge/jsmn: Jsmn is a world fastest JSON parser/tokenizer. This is the official repo replacing the old one at Bitbucket Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 54 Star 346 Fork 90 zserge/jsmn Code Issues 18 Pull requests 3 Pulse Graphs Jsmn is a world fastest JSON parser/tokenizer. This is the official repo replacing the old one at Bitbucket http://zserge.com/jsmn.html 123 commits 1 branch 0 releases 11 contributors C 96.7% Makefile 3.3% C Makefile Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Latest commit d1c85c5 Jun 13, 2016 zserge committed on GitHub Merge pull request #79 from ferambot/master … Minor fixes Permalink Failed to load latest commit information. example Fix deheader warnings Dec 14, 2015 test Fix typos Jun 13, 2016 LICENSE README and LICENSE added. MIT license choosen. Nov 15, 2010 Makefile moved tests into a subfolder, added table-driven tests Oct 17, 2015 README.md Typo fix. Mar 28, 2016 jsmn.c Fix trivial comment typo. Jan 13, 2016 jsmn.h changed jsmnerr_t type to int Oct 17, 2015 library.json @PlatformIO Library Registry manifest file Jan 19, 2016 README.md JSMN jsmn (pronounced like 'jasmine') is a minimalistic JSON parser in C. It can be easily integrated into resource-limited or embedded projects. You can find more information about JSON format at json.org Library sources are available at https://github.com/zserge/jsmn The web page with some information about jsmn can be found at http://zserge.com/jsmn.html Philosophy Most JSON parsers offer you a bunch of functions to load JSON data, parse it and extract any value by its name. jsmn proves that checking the correctness of every JSON packet or allocating temporary objects to store parsed JSON fields often is an overkill. JSON format itself is extremely simple, so why should we complicate it? jsmn is designed to be robust (it should work fine even with erroneous data), fast (it should parse data on the fly), portable (no superfluous dependencies or non-standard C extensions). And of course, simplicity is a key feature - simple code style, simple algorithm, simple integration into other projects. Features compatible with C89 no dependencies (even libc!) highly portable (tested on x86/amd64, ARM, AVR) about 200 lines of code extremely small code footprint API contains only 2 functions no dynamic memory allocation incremental single-pass parsing library code is covered with unit-tests Design The rudimentary jsmn object is a token. Let's consider a JSON string: '{ ""name"" : ""Jack"", ""age"" : 27 }'  It holds the following tokens: Object: { ""name"" : ""Jack"", ""age"" : 27} (the whole object) Strings: ""name"", ""Jack"", ""age"" (keys and some values) Number: 27 In jsmn, tokens do not hold any data, but point to token boundaries in JSON string instead. In the example above jsmn will create tokens like: Object [0..31], String [3..7], String [12..16], String [20..23], Number [27..29]. Every jsmn token has a type, which indicates the type of corresponding JSON token. jsmn supports the following token types: Object - a container of key-value pairs, e.g.: { ""foo"":""bar"", ""x"":0.3 } Array - a sequence of values, e.g.: [ 1, 2, 3 ] String - a quoted sequence of chars, e.g.: ""foo"" Primitive - a number, a boolean (true, false) or null Besides start/end positions, jsmn tokens for complex types (like arrays or objects) also contain a number of child items, so you can easily follow object hierarchy. This approach provides enough information for parsing any JSON data and makes it possible to use zero-copy techniques. Install To clone the repository you should have Git installed. Just run: $ git clone https://github.com/zserge/jsmn  Repository layout is simple: jsmn.c and jsmn.h are library files, tests are in the jsmn_test.c, you will also find README, LICENSE and Makefile files inside. To build the library, run make. It is also recommended to run make test. Let me know, if some tests fail. If build was successful, you should get a libjsmn.a library. The header file you should include is called ""jsmn.h"". API Token types are described by jsmntype_t: typedef enum {     JSMN_UNDEFINED = 0,     JSMN_OBJECT = 1,     JSMN_ARRAY = 2,     JSMN_STRING = 3,     JSMN_PRIMITIVE = 4 } jsmntype_t;  Note: Unlike JSON data types, primitive tokens are not divided into numbers, booleans and null, because one can easily tell the type using the first character: 't', 'f' - boolean 'n' - null '-', '0'..'9' - number Token is an object of jsmntok_t type: typedef struct {     jsmntype_t type; // Token type     int start;       // Token start position     int end;         // Token end position     int size;        // Number of child (nested) tokens } jsmntok_t;  Note: string tokens point to the first character after the opening quote and the previous symbol before final quote. This was made to simplify string extraction from JSON data. All job is done by jsmn_parser object. You can initialize a new parser using: jsmn_parser parser; jsmntok_t tokens[10];  jsmn_init(&parser);  // js - pointer to JSON string // tokens - an array of tokens available // 10 - number of tokens available jsmn_parse(&parser, js, strlen(js), tokens, 10);  This will create a parser, and then it tries to parse up to 10 JSON tokens from the js string. A non-negative return value of jsmn_parse is the number of tokens actually used by the parser. Passing NULL instead of the tokens array would not store parsing results, but instead the function will return the value of tokens needed to parse the given string. This can be useful if you don't know yet how many tokens to allocate. If something goes wrong, you will get an error. Error will be one of these: JSMN_ERROR_INVAL - bad token, JSON string is corrupted JSMN_ERROR_NOMEM - not enough tokens, JSON string is too large JSMN_ERROR_PART - JSON string is too short, expecting more JSON data If you get JSON_ERROR_NOMEM, you can re-allocate more tokens and call jsmn_parse once more. If you read json data from the stream, you can periodically call jsmn_parse and check if return value is JSON_ERROR_PART. You will get this error until you reach the end of JSON data. Other info This software is distributed under MIT license, so feel free to integrate it in your commercial products. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/zserge/jsmn"	"A minimalistic JSON parser.."	"true"
"JSON"	"json-c"	"https://github.com/json-c/json-c/wiki"	"A library for working with JSON.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"824"	"132"	"434"	"Home · json-c/json-c Wiki · GitHub Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 132 Star 824 Fork 434 json-c/json-c Code Issues 12 Pull requests 2 Wiki Pulse Graphs Home Eric Haszlakiewicz edited this page Jun 7, 2016 · 13 revisions Pages 1 Home Clone this wiki locally Clone in Desktop JSON-C - A JSON implementation in C (Note: this is the current site for json-c. The content over at metaparadigm.com is obsolete.) Overview JSON-C implements a reference counting object model that allows you to easily construct JSON objects in C, output them as JSON formatted strings and parse JSON formatted strings back into the C representation of JSON objects. It aims to conform to RFC 7159. Fetch release tarballs from the downloads page (Amazon S3). SHA-256 checksums: These can be verified by running ""openssl sha -sha256 json-c-0.12.1.tar.gz"" SHA256(json-c-0.12.1-nodoc.tar.gz)= 5a617da9aade997938197ef0f8aabd7f97b670c216dc173977e1d56eef9e1291 SHA256(json-c-0.12.1.tar.gz)= 2a136451a7932d80b7d197b10441e26e39428d67b1443ec43bbba824705e1123 Older releases: SHA256(json-c-0.12-nodoc.tar.gz)= 6fd6d2311d610b279e1bcdd5c6d4f699700159d3e0786de8306af7b4bc94fb35 SHA256(json-c-0.12.tar.gz)= 000c01b2b3f82dcb4261751eb71f1b084404fb7d6a282f06074d3c17078b9f3f c1356c3b0956b0f13966c1a75f136b38c41eca2c93344adec77f8a7dd583ee57 json-c-0.11-nodoc.tar.gz 28dfc65145dc0d4df1dfe7701ac173c4e5f9347176c8983edbfac9149494448c json-c-0.11.tar.gz 536a2e8846653ee11695722c1d546c28a9034f59accc8c1f76cf5823b1ff409f json-c-0.10-nodoc.tar.gz 274fc9d47c1911fad9caab4db117e4be5d6b68c4547eab0c508d79c4768e170c json-c-0.10.tar.gz 702a486c9bf8e19137d484ab5c49b4ad314eb5e1fe37062a72c0a0fa39439475 json-c-0.9.tar.gz MD5 checksums: These can be verified by running ""openssl md5 json-c-0.12.1.tar.gz"" MD5(json-c-0.12.1-nodoc.tar.gz)= 5b91ab230d9b6b0ee20fc19cf25094f5 MD5(json-c-0.12.1.tar.gz)= 55f7853f7d8cf664554ce3fa71bf1c7d Older releases: MD5(json-c-0.12-nodoc.tar.gz)= c2d07750dfd3edbdb1be18430dce2d94 MD5(json-c-0.12.tar.gz)= 3ca4bbb881dfc4017e8021b5e0a8c491 MD5 (json-c-0.11-nodoc.tar.gz) = 4ac9dae7cc2975dba7bc04b4c0b98953 MD5 (json-c-0.11.tar.gz) = aa02367d2f7a830bf1e3376f77881e98 MD5 (json-c-0.10-nodoc.tar.gz) = a84a359f11295c85ebe01a392c54154e MD5 (json-c-0.10.tar.gz) = a4edc79410eb894f08d7d52ca9f88732 MD5 (json-c-0.9.tar.gz) = 3a13d264528dcbaf3931b0cede24abae Building To setup JSON-C to build on your system please run: ./configure --prefix=/some/install/path make make check make install  If you are on Win32 and are not using the VS project file, be sure to rename config.h.win32 to config.h before building. Documentation For detailed information on using json-c, refer to the Doxygen generated API docs. There are also specific notes for building on Win32. GIT Repository git clone https://github.com/json-c/json-c.git Mailing List Send email to json-c at googlegroups dot com License This program is free software; you can redistribute it and/or modify it under the terms of the MIT License. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/json-c/json-c/wiki"	"A library for working with JSON.."	"true"
"JSON"	"WJElement"	"https://github.com/netmail-open/wjelement/"	"Advanced JSON manipulation library, with support for JSON Schema. LGPL, any version."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"56"	"10"	"29"	"GitHub - netmail-open/wjelement: advanced, flexible JSON manipulation in C Skip to content Personal Open source Business Explore Get started Sign in Pricing Blog Support Search GitHub This repository Watch 10 Star 56 Fork 29 netmail-open/wjelement Code Issues 8 Pull requests 2 Wiki Pulse Graphs advanced, flexible JSON manipulation in C 192 commits 2 branches 3 releases Fetching contributors C 97.1% CMake 2.9% C CMake Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags lint-callback master Nothing to show v1.1 v1.0.1 v1.0 Nothing to show New pull request Latest commit bac2b64 Feb 25, 2016 penduin tidy/revert oneOf Permalink Failed to load latest commit information. documentation updated documentation Aug 28, 2015 example Offset commit May 31, 2015 include Added variants of many functions using a format string to make it eas… Jul 26, 2015 src tidy/revert oneOf Feb 25, 2016 .gitignore Add .gitignore Feb 17, 2016 CMakeLists.txt build: clarified side-effects of missing regex library Aug 28, 2015 COPYING Offset commit May 31, 2015 COPYING.LESSER Offset commit May 31, 2015 INSTALL Offset commit May 31, 2015 README Offset commit May 31, 2015 README.md Offset commit May 31, 2015 README_PlanetLabs.md Offset commit May 31, 2015 cmake_uninstall.cmake.in Offset commit May 31, 2015 pkg-config.pc.cmake Offset commit May 31, 2015 README.md WJElement - JSON manipulation in C WJElement is a very flexible JSON library developed by Messaging Architects. It was created for MA's ""WARP"" webserver (""Warp Json Elements""), and is built on top of the lower-level WJReader and WJWriter libraries (also included). See the wiki for more information, example code and full API reference. WJReader and WJWriter are optimized for speed and memory-efficiency. WJElement focuses on flexibility and handy features, allowing C code to manipulate JSON documents with as few statements (fewer, sometimes!) as JavaScript itself. WJElement is also capable of json-schema validation. WJElement has grown into a generally-useful library, and is used across Messaging Architects' netmail and related projects. It is loved enough by MA's developers that we desire to use it elsewhere too, and we think others will enjoy it as well. So, here it is, ready to be consumed in any project, open or closed, as outlined by the GNU LGPL (any version). Include it as-is and link to it from your code, massage it into your own statically-linked package, or use it in ways we haven't thought of. Read the docs/headers, have fun, and if you use it for something awesome, let us know about it! :^) Owen Swerkstrom <owens@netmail.com> - community/repo front-man, WJESchema Micah N Gorrell <micahg@netmail.com> - primary author of WJElement Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/netmail-open/wjelement/"	"Advanced JSON manipulation library, with support for JSON Schema. LGPL, any version."	"true"
"JSON"	"YAJL"	"https://lloyd.github.io/yajl/"	"A fast C JSON streaming parser library."	"null"	"null"	"null"	"ISC"	"http://directory.fsf.org/wiki/License:ISC"	"null"	"null"	"null"	"null"	"null"	"yajl yajl by lloyd Overview Yet Another JSON Library. YAJL is a small event-driven (SAX-style) JSON parser written in ANSI C, and a small validating JSON generator. YAJL is released under the ISC license. Documentation Documentation generated by doxygen from source is available for v2.1.0, and for the previous stable release: v1.0.12. Code Get it on github: http://github.com/lloyd/yajl Support You can find Yajl on IRC in the #yajl channel on the Freenode network or you can subscribe to the Yajl mailing list by sending an email to yajl@librelist.com (more info on Librelist here) Download yajl-2.1.0.zip yajl-2.1.0.tar.gz yajl-1.0.12.zip yajl-1.0.12.tar.gz yajl-master.zip yajl-master.tar.gz You can also clone the project with Git by running: $ git clone git://github.com/lloyd/yajl Features Simple Interface Largely because YAJL is event driven, the interface is very concise object oriented C. The interface is not cluttered with data representation, that bit is left up to higher level code. Indeed it should be possible to port most existing JSON libraries onto YAJL if so desired. portable It's all ANSI C. It's been successfully compiled on debian linux, OSX 10.4 i386 & ppc, OSX 10.5 i386, winXP, FreeBSD 4.10, FreeBSD 6.1 amd64, FreeBSD 7 i386, and windows vista. More platforms and binaries as time permits. Stream parsing YAJL remembers all state required to support restarting parsing. This allows parsing to occur incrementally as data is read off a disk or network. Fast A second motivation for writing YAJL, was that many available free JSON parsers fall over on large or complex inputs. YAJL is careful to minimize memory copying and input re-scanning when possible. The result is a parser that should be fast enough for most applications or tunable for any application. On my mac pro (2.66 ghz) it takes 1s to verify a 60meg json file. Minimizing that same file with json_reformat takes 4s. Low resource consumption Largely because YAJL deals with streams, it's possible to parse JSON in low memory environments. Oftentimes with other parsers an application must hold both the input text and the memory representation of the tree in memory at one time. With YAJL you can incrementally read the input stream and hold only the in memory representation. Or for filtering or validation tasks, it's not required to hold the entire input text in memory. sample programs included in the source are a couple sample programs to demonstrate and test yajl: json_reformat: a minimizer and beautifier in one. json_verify: a JSON verifier. comments in JSON If you're dead set on using JSON throughout your system, you'll probably end up using it for your configuration files too. A little crazy, perhaps. But so am I. At parser allocation time you may specify a configuration parameter to allow comments inside the JSON input text. This is supported in versions 0.2.0 and above. Example Programmatic Usage In C  #include <yajl/yajl_parse.h> #include <yajl/yajl_gen.h>  #include <stdio.h> #include <stdlib.h> #include <string.h>  static int reformat_null(void * ctx) {     yajl_gen g = (yajl_gen) ctx;     return yajl_gen_status_ok == yajl_gen_null(g); }  static int reformat_boolean(void * ctx, int boolean) {     yajl_gen g = (yajl_gen) ctx;     return yajl_gen_status_ok == yajl_gen_bool(g, boolean); }  static int reformat_number(void * ctx, const char * s, size_t l) {     yajl_gen g = (yajl_gen) ctx;     return yajl_gen_status_ok == yajl_gen_number(g, s, l); }  static int reformat_string(void * ctx, const unsigned char * stringVal,                            size_t stringLen) {     yajl_gen g = (yajl_gen) ctx;     return yajl_gen_status_ok == yajl_gen_string(g, stringVal, stringLen); }  static int reformat_map_key(void * ctx, const unsigned char * stringVal,                             size_t stringLen) {     yajl_gen g = (yajl_gen) ctx;     return yajl_gen_status_ok == yajl_gen_string(g, stringVal, stringLen); }  static int reformat_start_map(void * ctx) {     yajl_gen g = (yajl_gen) ctx;     return yajl_gen_status_ok == yajl_gen_map_open(g); }   static int reformat_end_map(void * ctx) {     yajl_gen g = (yajl_gen) ctx;     return yajl_gen_status_ok == yajl_gen_map_close(g); }  static int reformat_start_array(void * ctx) {     yajl_gen g = (yajl_gen) ctx;     return yajl_gen_status_ok == yajl_gen_array_open(g); }  static int reformat_end_array(void * ctx) {     yajl_gen g = (yajl_gen) ctx;     return yajl_gen_status_ok == yajl_gen_array_close(g); }  static yajl_callbacks callbacks = {     reformat_null,     reformat_boolean,     NULL,     NULL,     reformat_number,     reformat_string,     reformat_start_map,     reformat_map_key,     reformat_end_map,     reformat_start_array,     reformat_end_array };  static void usage(const char * progname) {     fprintf(stderr, ""%s: reformat json from stdin\n""             ""usage:  json_reformat [options]\n""             ""    -m minimize json rather than beautify (default)\n""             ""    -u allow invalid UTF8 inside strings during parsing\n"",             progname);     exit(1);  }  int  main(int argc, char ** argv) {     yajl_handle hand;     static unsigned char fileData[65536];     /* generator config */     yajl_gen g;     yajl_status stat;     size_t rd;     int retval = 0;     int a = 1;      g = yajl_gen_alloc(NULL);     yajl_gen_config(g, yajl_gen_beautify, 1);     yajl_gen_config(g, yajl_gen_validate_utf8, 1);      /* ok.  open file.  let's read and parse */     hand = yajl_alloc(&callbacks, NULL, (void *) g);     /* and let's allow comments by default */     yajl_config(hand, yajl_allow_comments, 1);      /* check arguments.*/     while ((a < argc) && (argv[a][0] == '-') && (strlen(argv[a]) > 1)) {         unsigned int i;         for ( i=1; i < strlen(argv[a]); i++) {             switch (argv[a][i]) {                 case 'm':                     yajl_gen_config(g, yajl_gen_beautify, 0);                     break;                 case 'u':                     yajl_config(hand, yajl_dont_validate_strings, 1);                     break;                 default:                     fprintf(stderr, ""unrecognized option: '%c'\n\n"",                             argv[a][i]);                     usage(argv[0]);             }         }         ++a;     }     if (a < argc) {         usage(argv[0]);     }       for (;;) {         rd = fread((void *) fileData, 1, sizeof(fileData) - 1, stdin);          if (rd == 0) {             if (!feof(stdin)) {                 fprintf(stderr, ""error on file read.\n"");                 retval = 1;             }             break;         }         fileData[rd] = 0;          stat = yajl_parse(hand, fileData, rd);          if (stat != yajl_status_ok) break;          {             const unsigned char * buf;             size_t len;             yajl_gen_get_buf(g, &buf, &len);             fwrite(buf, 1, len, stdout);             yajl_gen_clear(g);         }     }      stat = yajl_complete_parse(hand);      if (stat != yajl_status_ok) {         unsigned char * str = yajl_get_error(hand, 1, fileData, rd);         fprintf(stderr, ""%s"", (const char *) str);         yajl_free_error(hand, str);         retval = 1;     }      yajl_gen_free(g);     yajl_free(hand);      return retval; }     License  Copyright (c) 2007-2011, Lloyd Hilaiel   Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies.  THE SOFTWARE IS PROVIDED ""AS IS"" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.  Related projects yajl-ruby - ruby bindings for YAJL yajl-objc - Objective-C bindings for YAJL YAJL IO bindings (for the IO language) Python bindings come in two flavors, py-yajl OR yajl-py yajl-js - node.js bindings (mirrored to github). lua-yajl - lua bindings ooc-yajl - ooc bindings yajl-tcl - tcl bindings JSON-YAJL - perl bindings yajl-d - D bindings for YAJL Contributors Many people have helped hone yajl to a fine edge, they have my deep appreciation for taking the time to give back. Here they are in alphabetical order (if I missed anyone, please tell me. It's been a while and my memory is bad): Adam McLaurin Andrei Soroker Artem S Vybornov (@vibornoff) Bobby Powers (@bpowers) Mr. Baptiste (@bapt) Brian Lopez (@brianmario) Brian Maher (@brimworks) Conrad Irwin (@ConradIrwin) Daniel P. Berrange Eric Bergstrome Florian Forster (@octo) Greg Olszewski (@gno) Hatem Nassrat John Stamp (@jstamp) Karl Adam (@thekarladam) Karl Lehenbauer Mark de Does Michael Hanson (@michaelrhanson) Mirek Rusin (@mirek) Neville Franks R. Tyler Croy (@rtyler) Randall E. Barker (@bluemarvin) Rick (@technoweenie) Robert Geiger Robert Varga Timothy J. Wood Vitali Lovich Original Author Lloyd Hilaiel (lloyd 4t hilaiel d0t com) get the source code on GitHub : lloyd/yajl (page style ""borrowed"" from Kyle Cordes)"	"null"	"null"	"A fast C JSON streaming parser library."	"true"
"Beginner"	"A tutorial on pointers"	"http://home.netcom.com/~tjensen/ptr/pointers.htm"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"A Tutorial on Pointers and Arrays in C A TUTORIAL ON POINTERS AND ARRAYS IN C by Ted Jensen Version 1.2 (HTML version) Feb. 2000 This material is hereby placed in the public domain Available in various formats via http://pweb.netcom.com/~tjensen/ptr/cpoint.htm PDF Version now available! TABLE OF CONTENTS Preface Introduction Chapter 1: What is a Pointer? Chapter 2: Pointer Types and Arrays. Chapter 3: Pointers and Strings Chapter 4: More on Strings Chapter 5: Pointers and Structures Chapter 6: More on Strings and Arrays of Strings Chapter 7: More on Multi-Dimensional Arrays Chapter 8: Pointers to Arrays Chapter 9: Pointers and Dynamic Allocation of Memory Chapter 10: Pointers to Functions Epilog"	"null"	"null"	""	"true"
"Beginner"	"Building C Projects"	"http://nethack4.org/blog/building-c.html"	""	"null"	"null"	"null"	"C Programming Wikibook"	"https://en.wikibooks.org/wiki/C_Programming"	"null"	"null"	"null"	"null"	"null"	"Building C Projects NetHack 4 homepage | NetHack 4 blog | ATOM feed Building C Projects Tags: aimake internals c | Wed Nov 5 11:10:26 UTC 2014 | Written by Alex Smith C is a compiled language, and as such, C programs need to be converted to executables in order to use them. Typically, programmers do this with some sort of build system, rather than running the necessary commands manually, because the compilation process for a large project tends to be quite complex. NetHack's build system is one of the parts of the code that is more frequently replaced in variants. The problem is that the build system in NetHack 3.4.3 requires manual intervention from the end user in order to work correctly, which nowadays (in 2014) is almost unheard of. However, the normal methods of modifing the build system (e.g. using autoconf as in UnNetHack or AceHack, or cmake as in NitroHack) basically just add extra layers of abstraction; and in a world as poorly standardised as that of building C, what typically happens is that each of these layers is trying to work around incompatibilities and nonstandard behaviour in the layers below it, meaning that you have a complex stack built mostly out of workarounds. Another issue is that there are many more steps in building a C program than most people realise. Some of these are handled by the build system, but others are typically left to the programmer or end user to do manually. This wastes everyone's time, really; the vast majority of the build process can be automated, and thus should be, because the time of a computer is so much less valuable than the time of a human (and computers are faster at it, anyway). For NetHack 4, I aimed to flatten these levels of abstraction as much as possible; instead of writing yet another wrapper around yet another set of poorly standardised existing tools, I'm using aimake, a build system I wrote originally for NetHack 4 (but is not specific to it). It's still somewhat unfinished – there are known bugs, missing features, and interface issues – but it works quite effectively for building NetHack 4, and hopefully will become more widely used some day, when it's ready for release. There are two main differences between aimake and other existing build tools. One is that aimake aims to avoid relying on lower-level build tools; most build systems work by producing output that serves as input to other build systems, and this can go down multiple layers before reaching anything that actually builds the code (e.g. with GNU Autotools, Makefile.am is the source for Makefile.in which is the source for Makefile, which contains instructions for actually building the code). The other is that aimake automates many more of these steps than most build systems do, handling steps which are often left to humans to deal with. One problem with this method, though, is that it can lead to gaps in understanding; most people who work on build systems are merely trying to adapt to existing tools, rather than actually handling the build themselves. This can make aimake quite hard to understand, as it works at a relatively unfamiliar level of abstraction. Therefore, I'm writing this blog post to explain what actually goes on when you build a C program. A disclaimer: this post focuses on how things typically work on modern consumer operating systems (especially Linux and Windows), rather than trying to cover all possible obscure systems. C doesn't have to work like this. It just normally does in practice. Normally, I'd start with the first step of the build and move forwards from there. However, that order of presenting things is actually quite confusing when it comes to building C; many of the steps are only needed to prepare for future steps, and it's hard to explain something without first explaining why it's needed. Thus, I'll start in the middle and work backwards and forwards from there. However, I'll first list the steps in order, before explaining them out of order (this order is not set in stone, but is a sensible and logical one to use): Configuration Standard directory detection Source file dependency calculation Header file location Header precompilation Preprocessing Compilation and assembly Object file dependency calculation Linking Installation Resource linking Package generation Dynamic linking Most build systems handle steps 3, 5 to 7, 9 and 10 in this list (leaving the others to be done manually, before or after the build). aimake currently handles 1 to 11 and has made a start on 12. Step 13 is almost always handled by the operating system. And now, the main body of this post, a description of the build itself. 6: Preprocessing As an example throughout this blog post, I'm going to use the following Hello World program in C. #include <stdio.h>  int main(void) {     fputs(""Hello, world!\n"", stdout);     return 0; }  Right now, I want to focus on the #include <stdio.h> line. A common misconception among people new to C is that it has something to do with libraries, typically that it causes the definition of fputs to be ""linked in"" to the program somehow. Actually, its effect is quite different: it serves to tell the compiler what types fputs and stdout have. The above program is, on Linux, 100% equivalent to this one: struct foo; typedef struct foo FILE;  extern int fputs(const char *, FILE *); extern FILE *stdout;  int main(void) {     fputs(""Hello, world!\n"", stdout);     return 0; }  We no longer have any mention of stdio.h anywhere, and yet the program still works. So clearly, it's nothing to do with linking. What's actually going on here is that stdio.h is just a list of declarations of types, functions, and variables, together with some macro definitions. The C standard places no restrictions on how a compiler chooses to implement these definitions, but in practice, headers like stdio.h are nearly always implemented in a slightly extended dialect of C (that uses compiler-specific extensions to do things that could not be expressed in C directly, such as adding buffer overflow check code based on the lengths of arrays in the source program). In this case, we're defining FILE as an incomplete type (the compiler doesn't need to know the definition of FILE to run the program, just that it's some sort of struct, because all sane compilers treat pointers to all struct identically); fputs as a function from a const char * and FILE * to an int; and stdout as a variable of type FILE. The extern means that this is just a declaration, and this file does not necessarily contain a definition of the function and variable in question. (We'll see where the definition actually is later on, when the linker gets involved.) On Linux, stdout is actually a variable. On Windows using mingw, however, an accessor function is needed to find the value of the standard filehandles stdin, stdout and stderr, so the preprocessor expands the program to something like this (I've omitted some details, and thousands of irrelevant lines): struct foo; typedef struct foo FILE;  extern int fputs(const char *, FILE *); extern FILE *__iob_func();  int main(void) {     fputs(""Hello, world!\n"", &__iob_func()[1]);     return 0; }  We can now see what the purpose of standard header files like stdio.h is: it's to paper over system-specific differences in the implementation details of the standard library. What the preprocessor is doing, then, is evaluating ""preprocessor directives"" like #include (to use definitions in a header file) or #define (to do symbol substitution on a source file, such as replacing stdout with &__iob_func()[1]). The result is a C source file that you could just have written directly, but is a little more system-specific than would be appropriate for the source files of your project. In addition to standard header files like stdio.h, projects can also have their own header files (e.g. NetHack's hack.h). From the point of view of the preprocessor, these work exactly the same way as standard header files, and they contain similar content (although, obviously, tend to be less system-specific). These are distinguished by using double quotes rather than angle brackets, i.e. you would write #include ""hack.h"" but #include <stdio.h>. The preprocessor is also traditionally responsible for removing comments from the source. It still does by default, for backwards compatibility, but modern compilers have no issue with comments, and the build process will work just fine even if you tell the preprocessor to leave the comments in. Nowadays, the preprocessor is nearly always built into the compiler, because they work so closely together. However, the preprocessor can also be run individually. The standard name for a command that does preprocessing is cpp (standing for, I believe, ""C Preprocessor""); this is normally implemented as a wrapper for the C compiler, providing the -E command-line option to tell it to do preprocessing only (and in fact, aimake currently uses the -E method when it needs to access the preprocessor individually in order to prevent mismatches between which preprocessor and compiler it uses). The standard filename for preprocessed output is .i. 5: Header precompilation In the early of C programming, the preprocessor worked on a very low level, pretty much just textually manipulating the source. Although preprocessors can still do that – in case someone decides to use them for something other than C, which is not unheard of – this rapidly runs into scaling problems in practice. The problem is that the standard headers have to be designed to handle all possible programs that might want to include them; our Hello World program just used fputs and stdout, but stdio.h has many other features, any or all of which a program might use. The result is that our preprocessed Hello World program is 1192 lines long; most of them are blank, and most of the rest are unused, but the compiler has no way to know this until after preprocessing. A traditional build process would preprocess each source file individually, meaning that each header file would have to be read by the preprocessor once for each source file. This has two problems. One of these is that it takes a long time (especially when using C++, whose build process is pretty similar to that of C). Modern computers are fast enough that the time taken is of the order of tens of seconds, rather than days, but even having to wait an extra minute in your build can significantly slow down your development process (because it reduces the rate at which you can use your compiler to catch errors, and means you can't get useful feedback from an IDE). The other problem is that if there is, say, a mistake in a declaration in a header file, this will cause an error compiling every single file that includes that header, whether it cares about the declaration or not. Given that modern compilers work so closely with their preprocessor counterparts, there is a solution to these problems: the preprocessor and compiler can cooperate to compile as much of a header file as possible ahead of time, without needing to know which source files will eventually use it. Although not every part of a header file can be precompiled (e.g. the effect of the textual substitution that #define performs is impossible to precalculate because it might end up being stringified), much of a header file is declarations, which can be. This means that the header file only needs to be parsed once (rather than once per file that uses it), and that errors in it may be caught before it's used. (It also helps in the common case where the source files are changed without changing any headers; the same precompiled header can be used as last time.) Although relatively old (I remember using them back in the 1990s), precompiled headers are nonetheless a newer innovation than most other parts of the C toolchain, and thus are relatively nonstandardised. gcc and clang use the extension .h.gch extension for precompiled headers; Visual Studio seems to use .ipch. aimake currently always precompiles headers. I'm not 100% convinced this actually saves time – although it speeds up the compiler in most cases, it slows down aimake because it has to keep track of them – but the improved error messages are worth it. 4: Header file location In order to be able to include header files, you have to be able to find them on the filesystem. The algorithm used by the vast majority of preprocessors is very simple: the preprocessor has a hardcoded list of directories, which the user can add to, and the preprocessor will scan them in sequence until it finds the file it's looking for. In the case of include ""file.h"", it will also scan the directory containing the source file. Although sufficient for small projects, in large projects, this approach is highly inadequate. Unlike in a small project, large projects will typically be formed out of several, mostly unrelated, parts (e.g. NetHack 4's source ships with libuncursed, which was originally written for NetHack 4 but is conceptually separate, and with libjansson, which was written entirely independently of NetHack and chosen as a dependency by the NitroHack developer). And with disparate sources comes naming clashes. So far, NetHack 4 has managed to avoid naming clashes among header files we ship (although there are currently six names which are used for multiple source files: dump.c, log.c, messages.c, options.c, topten.c, windows.c), but this increasingly becomes unlikely as projects get larger. There is another problem, which has a simple solution, but is worth mentioning because it catches some people out: not all C compilers are configured correctly for the system they run on, and may miss a few system headers as a result. I've most commonly seen this happen with the directory /usr/local/include on Linux systems, which is intended for system-wide header files that were installed manually, rather than by the operating system's package manager. The fix is just to add the directory as an include directory for every compile using command-line options. Anyway, as a result of the potential for name clashes, the set of header files to include for each individual source file needs to be determined for that file individually. The normal solution in build systems is to do this manually; the user will specify a list of directories to scan for header files, typically a project-wide list with options to override it for particular source files. Although these specifications tend to be quite simple to specify with some sort of loop, and are not hard to write, the fact that they need to be written at all increases the chance of human error (and this sort of error has definitely caused problems in practice). Their existence also encourages the tendency to use multiple nested build systems with different configurations that is frequently seen in large projects, and which is nearly always a bad idea. (There is a relatively famous paper about this called Recursive Make Considered Harmful [PDF].) In aimake, I use the approach of scanning the entire source tree for header files with appropriate names, then working out which header is intended via comparing paths (we take the closest matching header file in terms of directory structure). Different parts of a project have to be placed in different directories anyway when using a hierarchical build, and doing so is sensible anyway, so this is not a particularly odious requirement. It's also necessary to scan the system include directories for header files, because they aren't always at a consistent location on every system. For instance, on my Ubuntu laptop, the Postgresql header that NetHack 4's server daemon needs is stored at /usr/include/postgresql/libpq-fe.h. On some other people's systems, it's just /usr/include/libpq-fe.h. The solution to this problem I've most commonly seen used in practice is to require the user to specify the location as a configuration variable, then use conditional compilation to select between #include <postgresql/libpq-fe.h> and #include <libpq-fe.h> respectively. Getting the build system to just search for the header file in question on the file system is simpler, and requires less human intervention, and thus is preferable. aimake does this, in addition to scanning the source tree. There is one other subtlety here: because the preprocessor works at the level of directories rather than files, it's impossible to exclude a file from the header file search if another file in the same directory is included. This might seem minor, as there's no reason to arrange header files like that during the actual build. What it does do, however, is make it much more difficult to reliably discover dependency loops; a build system wants to avoid using files that aren't meant to have been built yet (and are left over from a previous compile), but the directory-level granularity of a preprocessor's header file search makes this impossible to avoid without using a separate directory for each generated header file (in case some are meant to have been generated at that point in the build, but not others). As a workaround for this problem, and for numerous other reasons, aimake now copies each header file in the source tree to a directory of its own in the build tree before building (with a #line directive so that errors are still reported against the original source file); I haven't had to resort to this for system headers, because they can't be confused with user headers due to the different syntax and system toolchain maintainers work to avoid clashes, but it would be a possibility if necessary. It should be noted that the original reason I wrote aimake was that I'd accidentally introduced a dependency loop into a beta of my ""attempt to merge AceHack with NitroHack"" in late March 2012, a couple of days before it got the name NetHack 4, and couldn't figure out what was going wrong with the build (back then, I was using the cmake build system inherited from NitroHack, which didn't realise that anything was amiss and was hopeless at giving appropriate feedback for this kind of mistake). Because I was under time pressure (wanting to get the program ready for April 1), I quickly knocked a script together as a replacement build system to get the build working, and after a couple of rewrites and numerous smaller changes, that script eventually became aimake. 3: Source file dependency calculation When working on a large project, you want to avoid recompiling it every time there are changes made to any file; rather, you want to compile just the bits that actually changed. This is probably the motivating factor behind the earliest build process automation tools; this sort of optimization is hard to express in a shellscript or batch file, leading to the creation of tools like make, which compare timestamps to determine what needs to be done in any given build. I'd argue that nowadays, trying to generate input for make is probably the #1 biggest mistake you can make in a build system (even though it's very common practice; the problems being that dependency resolution is a relatively small part of a build, and working around differences in different make implementations (some of which are very primitive) is quite complex, and thus it's normally simpler to just resolve the dependencies yourself rather than trying to get make to do it. make is also quite limited in what it can do; for example, it has no obvious support for rebuilding a file when the build rules for that file in the Makefile change (as opposed to rebuilding nothing, or the entire project). Most build systems work as wrappers around make (or the equivalent for IDEs like Visual Studio); aimake just skips this level of abstraction and handles the dependencies itself. (I'm not the first person to come to this conclusion; for instance, the standard toolchain for Perl used to use ExtUtils::MakeMaker, which generated Makefiles, but is now moving in the direction of Module::Build, which does the dependencies itself.) Anyway, regardless of whether you use make, aimake, or some completely different tool to process dependency calculation, you need to know what those dependencies actually are. This was originally left to the person writing the code to specify, and often still is in simple projects. However, as a task that can reasonably be automated (and that is somewhat time-consuming to do by hand for large projects), automating it makes a lot of sense. Something many people don't realise about dependency calculation is that correct dependency information is actually needed for two different purposes: Ensuring that if a file's dependencies change, it will be rebuilt. Ensuring that a file won't be built until after its dependencies. The most common method of dependency automation nowadays is to get the preprocessor to report on every header file it includes, during the build (and preprocessors have pretty advanced support for this; most can generate Makefile fragments directly). However, this leads to a chicken-and-egg problem (you can't calculate dependencies until you compile, but can't compile without knowing the dependencies). The standard solution to this (e.g. as used by GNU autotools) is to start the first build with no dependencies. This satisfies goal 1 (because on the first build, everything has to be rebuilt anyway, thus it doesn't matter that you don't know its dependencies), but fails goal 2, which tends to be dealt with using ugly workarounds. (Just look at this mess.) An alternative tradeoff (and one that aimake uses, although other choices are reasonable depending on what your goals are) is to run the source files through the preprocessor in a separate stage, without compiling them, to get hold of the dependencies. Thus, in aimake, this is step 3 of the build (whereas with many other build systems, it would be step 6). Although this seems simpler than producing dependencies as a side-effect of a compile would be, modern preprocessors actually make it much harder than you would think. The first problem is that they include header files transitively; this is what you want for a build (because you're actually building), but not what you want for dependency calculations (it's much faster, in the sense of ""linear rather than quadratic"", to look at what headers are needed without actually compiling them). The next problem is that the headers in question might not exist yet (e.g. they're generated files), and (in the order aimake does things) won't have been located yet. At least gcc and clang can be told to report on but ignore nonexistent files, which would seem to solve this problem. My first attempt at implementing dependency automation was to ignore the first problem (as it only affected performance) and use the obvious solution to the second, but it lead to unexpected compile failures in NetHack, due to a reasonably subtle problem. What happened was that one of the files in NetHack is called magic.h; although it's part of the source tree, it hadn't been located yet (and in general, because a good build system would handle arbitrary files being generated during the compile without prior warning, there's no point in locating header files early because that won't help with generated files). This is fine if there's no file magic.h anywhere, because then gcc and clang will treat it as empty and just report on the dependency, which is exactly what we want. However, some operating systems have a system header magic.h (which I believe is related to detecting file formats), leading the preprocessor to report a dependency on the system magic.h (and all its transitive dependencies) rather than the one in the source tree! Clearly, the behaviour I actually needed was to treat all header files as empty, rather than actually including them. Sadly, though, typically preprocessors don't have an option to do this. I actually seriously considered writing my own preprocessor to deal with the problem, but it would have been a mess and probably too large (aimake is implemented as a single file that you can ship with your project, much like configure, so I want to keep the size down if possible; it's already a little over ten thousand lines long). I eventually found a simpler solution, even if it is a bit sad: aimake reads the header files itself, looking for #include statements, then creates an empty file named after each header it finds, and tells the preprocessor to look there for include files. Note that one limitation of this method of dependency handling is that a file can't determine which header files to include dynamically based on constants included in a different header file. There are plausible useful reasons to do this, and it's permitted by the C standard. However, looking at what actually happened in practice in NetHack 4, it turned out that almost every location where it happened was a mistake that caused header file inclusion order to be relevant when it shouldn't have been (and the other cases were reasonably fixable). So again, this seems like a reasonable tradeoff to make. 2: Standard directory detection In order to be able to do any sort of processing of the system headers and libraries, you first have to know where they are. With header files, you need to know the location of the system headers to be able to scan the subdirectories of that location for header files like libpq-fe.h, which I discussed earlier. Libraries intended for public use are rarely stored in subdirectories; however, aimake needs to be able to look inside them in order to determine which library holds a particular symbol, so it needs to find the set of standard libraries, too. It's actually a surprisingly hard problem to determine where the system headers and libraries are stored with no hardcoded knowledge of the system you're on, and this may be part of the reason why header file location and object file dependency calculation are normally left to humans by most build systems, rather than being automated. The headers and libraries could be just about anywhere on a system (e.g. on my Windows system, I installed the compiler to a subdirectory of my Documents directory, which could have had an entirely arbitrary name); assuming that all we know the location of is the executables of the C toolchain, can we find the rest? I tried several techniques, and eventually settled upon two that seem reasonably portable (by which I mean that they work on Linux with gcc/clang and GNU ld/gold, on Windows with mingw, and apparently on Mac OS X too, although that's mostly been tested by other people because I don't have a Mac handy): For header files, the preprocessor must know where the header files are in order to be able to include them; and although there's no standard option for asking where they are, there is a standard option (-M) for reporting dependencies. Thus, all we need is to produce a file with one dependency in each of the possible standard header file directories. Currently, aimake uses five header files as dependencies. There's a full explanation in its source, but here's a quick summary of the possible directories that header files can be sorted into on systems I've seen, and which header file aimake uses as a test: Header files that ship with the compiler (<iso646.h>, because there is literally no reason not to ship it with a compiler, especially as many C libraries don't ship it); Header files that were patched by the compiler (<limits.h>, the only file that gcc patches unconditionally); Architecture-dependent header files (<sys/types.h>; none of the standard C headers are stored here on most systems which have it, so I used the most architecture-dependent POSIX header); Header files that ship with the C library (<setjmp.h> is the only header I've found that's in this category on every system I tested, probably because it's too weird for the compiler to mess with it); Nonstandard (i.e. non-C/POSIX) header files that shipped with libraries (<zlib.h>, because zlib is one of the world's most widely-used libraries). For libraries, again there's no standard way to find out where the linker is looking, even though it must know; I attempted to use gcc --print-search-dirs even though it's gcc-specific, but it appears to only find library directories that gcc needs for its own internal use, rather than all the library directories on the system. The most portable method I've found is to ask the linker to link in each of the libraries we care about to a small test file (one at a time so that the failure to find a library won't affect the search for the others), and get it to produce a debug trace as it does so. There are several problems with this method (even though I use it anyway). The first is that although the option to ask linkers for a trace is standard (-t), the format of the output is not, and can vary wildly even on a single linker depending on the reason that the library is being linked in. Here's a current regex aimake might use for parsing the output (with the part aimake uses to avoid matching the source file removed, and with file extensions set appropriately for Linux; the file extensions need to change on other systems): /^(?:(?:-l|lib)[^ ]+ )?\(?(.*?\/.*?(?:\.a|\.o|\.so)(?:\.[0-9]+)?)(?:\)|\([^\/]*\)|\z)/  The next problem is that, looking at the files matched by this, sometimes some of them will be text files! This problem is due to the fact that library developers sometimes have to do weird things for backwards compatibility. Here's what libncurses.so looks like on my Ubuntu system, in full: INPUT(libncurses.so.5 -ltinfo)  I don't know for certain, but my guess as to what happened here is that libncurses got split into two libraries sometime in the past (libncurses and libtinfo), and thus libncurses.so became a wrapper linker script that pulls in both libraries. Obviously, this script is useless for things like determining which symbols exist in which libraries. However, the linker trace will also contain both of the libraries it pulls in, so all that's necessary with such wrappers is that we ignore them. aimake scans the first kilobyte or so of the library looking for non-ASCII characters; if it fails to find any, it assumes that the ""library"" is actually just a linker script. Another issue is that, if we don't use at least one symbol from a library, the linker may optimize it out; and in some circumstances (e.g. if it's a static library), it then won't show on the linker trace output. aimake currently only searches for libraries that the user mentions might be required in the configuration file (for performance reasons; searching every library on the entire system for symbols takes about an hour on my laptop), so I solved this by asking the user to mention the name of a symbol that they expect to be in that library, and aimake then forces the linker to link that symbol using the standard -u option. An added benefit of this approach is that it ensures that we find the library we expected, rather than a different library with the same name. A bad side-effect of this is with respect to the standard libraries of the system, the ones that are linked in by default. (In addition to needing to analyse these in order to do dependency calculations correctly, as any dependencies on them won't need to be explicitly satisfied, we also need to not pass them to the linker, because Mac OS X's linker complains and refuses to build if you try to explicitly link a standard library.) We can't know how those are divided up between files, so specifying a symbol is of no use. Thus, I ended up having to settle on the rather drastic method of asking the linker to link in every symbol in the standard libraries (--whole-archive, plus --allow-multiple-definition to reduce the amount of error spam you get as a result). This normally doesn't produce a usable output file (nor could it really be expected to), but aimake doesn't care about this, just about the trace output. Incidentally, it causes mingw's linker to crash, but only after it's already printed the trace output aimake needs. (This is why building NetHack 4 on Windows shows an error dialogue box about ld.exe crashing.) All this annoys me, as something this apparently basic really shouldn't be this difficult. I guess the problem is that nobody really expects someone to try to determine inherently system-specific information (where the headers and libraries are installed) in a system-agnostic way. 1: Configuration Traditionally, the first thing done in any build is to fix values for the parts of the build that vary from build to build. This includes everything that needs to be specified by a human before the build starts; thus, configuration is quite lengthy and time-consuming with NetHack 3.4.3, as you have to answer questions like ""what terminal codes library does your system use?"". aimake cuts down considerably on this sort of question, because it can determine so much by itself, but there are always going to be questions that only a human can answer, such as ""are you interested in building the tiles ports"", or ""do you want me to install this to your home directory or system-wide?"". (At least aimake mostly manages to condense all these choices down to a couple of command-line options. It does have one major problem in terms of user-friendliness right now, though, which is that there's no simple way to specify unusual options you want to pass to the compiler, or similar special build rules; you can do it but the syntax is horrendous. This is something I need to work on before aimake is really ready for production use.) However, there are also lots of questions whose answers can be determined experimentally, and which a computer can answer as easily (in fact, more easily) than a human. This is normally performed by a program named configure (typically, but not always, generated by a GNU autoconf), with a separate configure program written for each project and shipped with the distribution tarball. configure's job is to paper over nonportabilities between systems by determining what needs to be done on each one. Just as happened with curses, though (as I wrote in my blog post on portable terminal control codes), configure is increasingly solving the wrong problem. I have written systems based on GNU Autotools that aimed to do everthing by the book as much as possible, but it was mostly as a joke / thought exercise; modern programs don't need to worry about, say, stdlib.h not existing (and don't really have an obvious workaround for if it doesn't). At least autoconf's documentation mentions that that particular check is obsolete nowadays, and recommends leaving it out. There are several checks that are more useful, but so far, I've only actually needed two checks of this nature in NetHack 4 (and aimake has support for doing them), a very small portion of the build system as a whole (and not something that warrants being one third of the ""standard"" build sequence, which for autotools, is configure, make, make install). One is about how to set the compiler to C11 mode (--std=c11, -std=c11, or nothing and let the compiler fall back to non-standards-compliance mode, which contains all the C11 and C99 features we use in the case of gcc and clang). The other is how to indicate that a function never returns: is it _Noreturn (the version recently standardised in C11), __declspec(noreturn) (used by Microsoft compilers), or __attribute__((noreturn)) (used by gcc and clang before the standard syntax was invented)? I originally tried to detect this using compiler predefined macros, but this caused problems on some specific old versions of clang (which are still used nowadays on some Mac OS X systems). Neither of these checks exists in my current version of autoconf, so it wouldn't have helped much here. It should be noted that this is the most user-visible step (because it requires the most manual intervention), and also the one that varies the most between build systems. Thus, it needs the best interface, and it's a particular pity that aimake falls down here. 7: Compilation and assembly We've now seen pretty much everything that happens at the C level, from the source files up to the preprocessor. As a recap from earlier, the preprocessor's output is typically a slightly extended C, which contains declarations for all the relevant parts of the standard library (and typically for irrelevant parts, too, but those get optimized out). The next part of the build process is the compilation and assembly, which takes the preprocessor's output and transforms it into an ""object file"". Just as the preprocessor's output is slightly extended C, the object file (which is the linker's input) is slightly extended machine code. The difference from the machine code that a processor actually runs is that it's full of instructions to the linker, as well as instructions to the processor; typical linker instructions are along the lines of ""this string is read-only data, place it with the other strings for me and tell the MMU to mark it read-only"", or ""I know I said to call the all-zeroes address as a subroutine, but can you replace that with the address of strcmp when you figure out where it is?"". In short, an object file contains as much of the machine code as can be calculated by looking at one file in isolation; the rest is made out of linker instructions to patch up the file later on in the build. There are two basic approaches that can be used for this C to machine code transformation. One is to do it directly; the other is to go via assembly code (which is almost as low-level as machine code, but which is much more human-readable, and which can express various linker instructions that machine code can't. When assembly code exists as an intermediate step (or sometimes even when it doesn't – some compilers can produce it on demand), compilers typically support the -S option to let you take a look at it. Our Hello World program expands to just 30 lines of assembly. It's also possible to ""disassemble"" the object file, to determine what its machine code would look like as assembly, to make it more human readable. Here's the Hello World program as C (as a reminder): #include <stdio.h>  int main(void) {     fputs(""Hello, world!\n"", stdout);     return 0; }  And here's how it looks as assembly produced by the compiler, and how the object file looks after disassembly (rearranged so that common lines are next to each other; my disassembler also printed the machine code as hexadecimal, but I've removed that to save space, even though it leads to the newline and NUL at the end of ""Hello, world!"" displaying ambiguously as periods):     .file   ""t.c""     .section    .rodata             Contents of section .rodata: .LC0:     .string ""Hello, world!\n""       Hello, world!..      .text                           Disassembly of section .text:     .globl  main     .type   main, @function main: .LFB0:     .cfi_startproc     pushq   %rbp                    push   %rbp     .cfi_def_cfa_offset 16     .cfi_offset 6, -16     movq    %rsp, %rbp              mov    %rsp,%rbp     .cfi_def_cfa_register 6     movq    stdout(%rip), %rax      mov    0x0(%rip),%rax     movq    %rax, %rcx              mov    %rax,%rcx     movl    $14, %edx               mov    $0xe,%edx     movl    $1, %esi                mov    $0x1,%esi     movl    $.LC0, %edi             mov    $0x0,%edi     call    fwrite                  callq  22 <main+0x22>     movl    $0, %eax                mov    $0x0,%eax     popq    %rbp                    pop    %rbp     .cfi_def_cfa 7, 8     ret     .cfi_endproc .LFE0:     .size   main, .-main     .ident  ""GCC: (Ubuntu 4.8.2-19ubuntu1) 4.8.2"" .section    .note.GNU-stack,"""",@progbits  On the left is the assembly output for the Hello World program; we can see that it contains many notes for the linker (the lines starting with .), and various constructs that don't exist in machine code (e.g. it can say call fwrite, and mention stdout, even without knowing where fwrite and stdout are in memory). Comparing this to the machine code produced by disassembling the object file, we can see that many of the lines are basically the same, but some have bits replaced by zeroes; movq stdout(%rip), %rax cannot sensibly be interpreted as mov 0x0(%rip),%rax, for instance. Likewise, the call to fwrite has been replaced by a call to the current instruction pointer location (which also translates as zeroes in machine code). It's worth noting that, even though this program was compiled without optimization, the compiler has done a small optimization anyway; the original Hello World program called fputs, but the compiler has compiled it into a call to fwrite. Both these functions need to use a buffer to store their output, according to the C standard; fputs has to do a series of strncpy or equivalent to fill the buffer (strncpy instead of strcpy because it has to allow for the potential that the string might be very long and so overflow the buffer, causing it to be output in sections), whereas fwrite knows the length before it even starts, and (for short strings like this) can memcpy it into the buffer directly. memcpy is faster than strncpy because it can copy more than one character at a time (strncpy has to take care not to read past the end of the string, and doesn't know where that will be in advance), so fwrite should be faster than fputs. (We can see the ""14"" in the assembly code, that isn't in the original program, containing the length of the string ""Hello, world!\n"" that appears in our program, not counting the terminating NUL because that isn't output.) The object file places its output into various sections, which tells the linker (and eventually the OS kernel) about the purpose of the data stored there. Our main function goes into a section that is, rather confusingly, named .text; this contains the actual code that makes up our program. (This is on Linux; on other operating systems; the name of the section varies, but is nearly always some variation on ""text"" for historical reasons, even though executable code is about as binary on the binary/text distinction as you can get.) The string ""Hello, world!\n"" itself is in a separate section, .rodata, which stores read-only data. The .cfi_ lines tell the assembler to generate stack unwind information, which is mostly irrelevant here (it's used by exception handling in C++ to figure out which catch blocks might be relevant for the current code location, and by debuggers to produce stack backtraces); they also compile into a section (.eh_frame) in the object file. In addition to the sections, our object file also contains headers, which contain instructions to the linker; the information about names like main and stdout hasn't just disappeared, but as it can't be expressed in machine code, it needs to be expressed some other way. On Linux, we can see these headers using objdump -x. This is more than a screenful of text, but here are some interesting excerpts: SYMBOL TABLE: [...] 0000000000000000 g     F .text  0000000000000029 main 0000000000000000         *UND*  0000000000000000 stdout 0000000000000000         *UND*  0000000000000000 fwrite  RELOCATION RECORDS FOR [.text]: OFFSET           TYPE              VALUE  0000000000000007 R_X86_64_PC32     stdout-0x0000000000000004 0000000000000019 R_X86_64_32       .rodata 000000000000001e R_X86_64_PC32     fwrite-0x0000000000000004  The ""symbol table"" tells the linker about any identifiers in the source code that need to be given a consistent meaning between files. In this case, main is 0x29 bytes from the start of the .text section, and the compiler doesn't know where stdout and fwrite are. Meanwhile, the ""relocations"" tell the linker which parts of the machine code will need patching up; it's asking the linker to substitute in appropriate values for just before stdout, just before fwrite, and for the start of this file's part of the .rodata section (which is where the ""Hello, world!\n"" string is stored). The compiler cannot figure out where any of these will be; it can't know where the .rodata section is relative to the .text section because it doesn't know how large those sections will be, and stdout and fwrite are in the standard library, not in the Hello World program itself. The hexadecimal numbers in the left column tell the linker where in the .text section the new values will need to be substituted (and the central column explains what format the linker should use for the substitutions). The traditional name for a compiler is cc, and for an assembler is as. However, the compiler also traditionally runs the linker once it's done; although appropriate for very small programs, this is not what you normally want for a large project (where you're going to want to recompile just the source files that changed, but relink all the executables that depend on any file that changed). Thus, it's typical to tell the compiler to do just the compile (and assemble, if necessary) using the -c command line option, which is standard. Object files have the extension .o with most toolchains, although some Windows toolchains use .obj. 8: Object file dependency calculation Once we have our object files, the next step is to work out how to fit them together to form executables. There are two sources of object files; one is the C source files we just built, and the other is the system libraries. (System libraries can ship object files directly; more commonly, though, they're bundled together into libraries of object files, with extensions like .lib or .a, which are simply archives containing multiple object files, typically with some extra metadata to allow the linker to figure out which of the contained object files are relevant more quickly. On Linux or UNIX-based systems like Mac OS X you can use the command ar x to unpack a library and look at the object files inside it directly.) In order to produce an executable, we need a list of object files and libraries that together have no unmet dependencies; any undefined symbols in any of the object files (such as stdout in our Hello World object file) need to be defined by one of the other object files. We also need an ""entry point"" to the program, so that it has somewhere to start running. (The way this is typically implemented is for the entry point to be somewhere in a standard library, normally in an object file whose sole purpose is to provide an entry point; and that object file calls main, which it leaves undefined, performing initialization before the call and cleanup afterwards.) Thus, one thing we need to do as part of the build is to produce such a list. This is a job that's normally left to the programmer, and in my opinion, making the programmer do it is a terrible idea. As usual with jobs that are left to humans, it's error-prone; unlike some of the other things that are normally left to humans, it's also somewhat time-consuming, as whenever you add a new file to your project, you'll need to add it as a source for one or more of your executables (or libraries, if you build libraries as part of your build). This is thus an excellent candidate for automation, and the concept here is pretty simple: we have one executable for each main function, and we find the files required to produce it by recursively looking for object files or libraries that define symbols that are undefined in the object files that are already part of the build. In the case of our Hello World program, aimake would start by checking the symbol table for our main program, finding it needed definitions of stdout and fwrite, then finding those in the standard library, and it'd be done. One potential problem here is if symbols with the same name are defined in multiple files, but aimake uses heuristics to figure out which file to link that work excellently in practice for correct programs. However, there's another problem: when the input programs contain subtle errors (such as linking against implementation details of a library defined elsewhere in the project, rather than using the public API of that library), aimake can normally find a solution that works anyway (for this example, linking against the relevant object files in that library directly), even though we wouldn't want it to. At the moment, I check to ensure this hasn't happened by inspecting the symbol tables manually once every few months, but this is unsatsifactory. Ideally, there should be some way to tell aimake (or some way to have it automatically deduce) that certain files should be kept separate; a crude way to do this at the moment is to define symbols with the same name in each to force a link error, but this isn't really satisfactory. In order to actually discover which symbols are defined (or referenced but undefined) in the various object files, we need to look at their symbol table headers. We could use a program like objdump for this, but it's rather system-specific; there's a more generally usable program, nm, that deals with symbol tables specifically. Again, we have to deal with variations in the output format, and come across a particularly weird problem: POSIX defines a standard output format for nm, but the way you get at that format varies from nm implementation to nm implementation, making it not particularly useful as a standard. Meanwhile, the default output format of nm is consistent enough that just matching it directly seems to cause no problems. 9: Linking Once we know which object files we need to combine to make an executable, the next step is to use the linker to actually make our executable. The first job of the linker is to work out how to lay everything out in memory; it will generally combine sections with the same name into contiguous blocks. On modern systems, the sections keep their identity all the way into the executable, and so combining them means that the executable's headers will be simpler and shorter. There are multiple reasons that the executable needs to know about the sections. One is to correctly configure permissions on memory while the executable is running; the kernel will tell the computer's memory management unit (MMU) which parts of memory are supposed to be readable, writable, and/or executable, and violating these rules will cause a crash. For our the sections used by our Hello World program, .rodata is readable but not writable or executable (which is useful for diagnosing errors in which you try to write to a string literal, or to deallocate one); .text is executable and readable but not writable (for security reasons, toolchains try to avoid memory that's both writable and executable as far as possible). Another reason is that some of the sections can be optimized out of the output entirely; the .bss section is for read-write data that's initialized entirely with zeroes, which is a common enough special case that it makes sense to not have to pad the executable with that many bytes of zeroes. The kernel knows about this rule, but needs the .bss section identified so it can allocate memory for it at runtime. The linker has a lot of control over the memory addresses used by the program; object files typically have no opinion on where something should be placed in memory, but it's in the linker's power to fix all the addresses within the resulting file, and this is what it does in typical usage. (There's no need to worry about clashes between executables; the MMU will place each executable in its own separate address space, so each executable has perfect control over how it wants to lay out memory.) Once the linker's decided all the addresses that the program should use, it creates an output file that's basically a memory image of each section, and substitutes in addresses according to the relocations requested by the compiler. This list of sections, plus appropriate headers, is the executable file (i.e. .exe on Windows) that's actually produced on disk. In order to run such a file, the operating system basically just has to memory-map all the sections in the executable at the virtual addresses that the linker indicates, then starts the program running at the start address indicated. (Modern operating systems can thus optimize memory storage for executables the same way they would for memory-mapped files.) It's worth noting that some operating systems have rather simpler executable formats than this. A DOS .com file is a memory image of a single section (starting at a virtual address of 0x0100), with an entry point at the start of the section, that's readable, writable and executable. The advantage of this format is that it doesn't need a header at all, as all the information that it would specify is fixed; the disadvantage is that because the 8086's memory management was so primitive, it means that the entire program is limited to 65280 bytes of program, static data, and stack. Although the main job of the linker is to fix memory addresses and patch up the relocations accordingly, it also has a few other jobs. One is handling code that define a variable in multiple source files. There are three ways to specify variables that the linker might potentially have to process, in C: Declaration that is never a definition, e.g. extern int foo; Tentatively defining a variable as zero-initialized, e.g. int foo; Definitely a definition due to an initializer, e.g. int foo = 0; The first and third cases are well-defined and have the same meaning everywhere; the first uses extern to explicitly state it isn't a definition, and the third initializes the variable (and thus must be a definition). The second case is more ambiguous; the standard states that it's always a definition, but not all C programmers seem to have got the message, and sometimes it's incorrectly used as just a declaration instead. Worse, sometimes all your object files just say int foo;, and none of them initialize it; now (in pre-standard C) one of them is a definition, the others are declarations. Many linkers thus have special logic to handle this case, converting one all but one plain int foo;-style definition into a declaration if it's required for the program to link correctly (by allocating all the definitions at the same memory address). Some don't, perhaps for technical issues (e.g. building shared libraries on Mac OS X). Because well-written programs shouldn't be doing this sort of thing anyway, and because it would confuse aimake's heuristics, aimake tells the compiler to tell the linker that all definitions are definitely definitions (rather than possibly declarations), and thus can help catch this sort of error. (NetHack 4 was unintentionally doing this for a long time; two different variables windowprocs were getting merged together, when they shouldn't have been. It didn't affect the operation of the program, as it happens, so I'd never have caught it without aimake telling me something was wrong. It didn't manage to articulate the problem very clearly, though, and I had an incorrect fix in place for months, until I finally figured out what was wrong when working on the Mac OS X port of NetHack 4.) The linker can also catch certain problems with an executable that the compiler can't; for instance, it can notice that a function isn't defined anywhere (leading to an undefined symbol error). However, the linker can't check as much as you'd like; if you declare a variable as an int in one file and a float in another, then it's very unlikely that the linker will be able to discover the type mismatch (it might know about the expected size of the two resulting symbols, on some operating systems, but both types are usually 4 bytes long; in order to know about the type, the only source of information the linker could rely on is the debug information, which linkers typically don't parse and which the compiler doesn't always generate). 10: Installation Although you might think that the build is done once the executables are produced, there's still several steps left in a full build process. One problem at this point in the build is, although we have a working executable, it would be very hard to ship. One possible build layout is for the executables and object files and source files to all be mixed together in the source tree (something I personally hate because it makes it impossible to have multiple builds from the same source, and makes reversing a build hard, but which is nonetheless very common), which is too disorganized to ship easily. The alternative, having files generated during the build in a separate directory, means that the executables are separate from any data they might need (which is still sitting in the source tree). Either way, some files are going to need to be copied and/or reorganized before they're really usable. The simplest possible form of installation is simply taking the files we just built, together with relevant data files from the source, and copying them to the location the user asked us to install them in (back during configuration, at the start of the build). There's nothing conceptually too difficult about this; however, it's nearly always a separate step from the actual build due to the potential need for elevated permissions (it's common to want to install into system directories that aren't writable by ordinary users, like /usr/bin on Linux or a subdirectory of CSIDL_PROGRAM_FILES (which is typically C:\Program Files on the filesystem) on Windows). There are also some subtle details that build systems take care of during this step. For instance, the build system needs to create directories before installing in them. Another example is that it's common to ""strip"" executables while installing them; this discards all information in the executable (symbol tables, debug information, etc.) that isn't absolutely necessary for it to run, and so reduces disk usage at the expence of debuggability. (A more recent innovation is to split out the debug symbols into a separate file, typically stored on a network and downloaded when debugging information is needed.) Another job of the install process is to set the permissions on the files it installs. This is surprisingly easy to get wrong, especially when they need to be different from the defaults. For example, on Linux and UNIX-based systems, NetHack in general and NetHack 4 in particular set permissions so that players can't write the high score table, or write bones files, without going through the nethack executable or using administrator privileges. Some distributions (which modified this step of the install process, despite warnings in the documentation that their new configuration was a bad idea) managed to screw this up to the extent of introducing a security bug that could allow anyone with local access to take over the whole system. It's also worth noting the ""DESTDIR convention"", which will become relevant later. The idea is that you compile as if you were installing into one location (telling your program to look for its data files in /usr/share, for instance), then actually place the compiled files in a different location (typically somewhere in your home directory). It's easy to add this feature to an installer, and forgetting will make some of the later steps of the build process almost impossible to complete. (The way you specify this using GNU automake, and with most hand-written makefiles, is to set a make variable DESTDIR; aimake uses a command-line option --destdir.) In addition to its use in generating packages, this is also handy when installing into a chroot; I use this feature when updating the server on nethack4.org. Still, this is one of the simpler steps. The main problem from the point of view of a build system designer is that because it needs enhanced privileges, the UI will inevitably be more complex than for the other steps. aimake supports three different models for handling the install step: If you don't actually need permissions for your install, you can just use -i (i.e. ""install as well as building"") directly, and things work fine. You can tell aimake how to elevate permissions with the -S option, e.g. -S sudo, and it'll use that method (sudo on Linux is very similar to UAC on Windows; it can only be used on an administrative account, and prompts for your password, elevating one process if i's entered correctly). You can run aimake without -i to do the build; then elevate permissions, and run with -i --install-only. (This is how -S is implemented internally.) The second method is the most convenient, and minimizes the risk of permissions-related errors (a build directory full of files you don't own is always frustrating to deal with). The third method is the one that most other build systems use, so it's included to make it easier to write a wrapper that makes aimake look like, say, GNU autotools. 11: Resource linking We're now past the point where most build systems consider their work to be done. This is a pity, as resource linking is something that typically has to be done at the same time as the installation; the normal workaround (that's been repeated so many times across so many projects that many people don't realise it is a workaround) is to manually write build rules to perform the relevant steps. On Windows, the situation is less bad, because Visual Studio does a resource link just after linking (and thus it happens immediately before installation). The term ""resource link"" comes from Windows, but the general principle is the same across operating systems: a plain executable by itself is not particularly usable, because all it has is a filename, and (if you're lucky) documentation. Documentation might be useful to a human, but what can a computer do with a name like nethack4.exe but place it in a list of thousands of other executables that nobody will ever scroll through? (This is not just a hypothetical; it's Firefox's actual UI on Linux for selecting a program to open a file, when it doesn't know of an appropriate option already, because it just opens up an ""Open File"" dialog box that you even have to navigate to /usr/bin by hand. This really sucks when all you wanted was to open a text file in a text editor.) Clearly, what is needed is some sort of metadata: a longer description than the filename, an icon, perhaps a version number, things like that. On Windows, this is compiled into the executable. On Linux, it's typically done by means of .desktop files in a known directory (/usr/share/applications); many desktop environments maintain an index of these files so that they can grab the metadata for a given executable on demand. (I'm not sure how this works on Mac OS X, although would be interested for someone to tell me.) It's impossible for a build system to know what all the metadata should be without being told. However, aimake can certainly translate it to an appropriate format for the OS by itself, and the amount of information it needs to make a decent shot at it is actually very small. (The only pieces of information that it can't at least make a reasonable guess at or a plausible placeholder for are the version number and icon; and if not specified, it'll just tell the OS to use its default placeholder icon.) It would be reasonable to do this step before the install, rather than after; that's where Visual Studio does it, and I originally tried to put it there. However, doing it just after the install (while aimake still has elevated permissions, so that it can write to system directories like /usr/share/applications) turned out to be much simpler in terms of aimake code (which in turn made NetHack 4's aimake.rules simpler as it didn't have to try to deal with the pre-resource-link and post-resource-link versions of executables separately). Besides, on Windows, you want to make a Start menu shortcut as well, and because shell links on Windows have a curious mix of overengineering and underengineering (some of which is to compensate for bad design decisions made elsewhere), it's impossible to create a robustly behaving shortcut unless its target exists at the time. (aimake currently does not make these shortcuts during the install process for this reason, also because most of the existing wrappers use the wrong APIs and when I wrote a new wrapper, it was 153 lines of C++ before even writing the code to communicate with aimake itself.) As a fun fact, the two main NetHack 4 executables, nethack4 and nethack4-sdl, differ only in filename and metadata (nethack4-sdl is a symlink on Linux, because the metadata is in external files). The filename difference determines the default interface plugin to use (an ending of -sdl loads the graphical interface by default); as well as explaining the interface difference, the metadata is used to request a terminal window for nethack4, while not opening one for nethack4-sdl because it doesn't need one and so it would look ugly. 12: Package generation So far, we've been focusing on the build and install process as it looks to a developer. However, distributing a source tarball and telling users to build it is considered a very user-unfriendly method of distribution nowadays. On Linux, nontechnical users want a package that they can point their distribution's package manager to. On Windows, most users will want an installer that they can double-click on. (Additionally, nothing about the previous steps has any particular support for an uninstaller, something which any software package should have; the sort of end-user installation framework discussed in this section typically comes with an uninstaller as well.) This step is going to be inherently somewhat system-specific; Windows Installer has many differences from dpkg (the Debian equivalent), for instance. However, some things are the same. The most notable is that the input into these install tools is a folder hierarchy containing the files that would be installed; the DESTDIR convention is very useful here. (The package generation tools also need to be told about the permissions on the files, but ideally, administrator permissions wouldn't be needed for a DESTDIR install; on Linux, the workaround for this problem is a program called fakeroot which intercepts attempts to set permissions and remembers which permissions the files ""should"" have, and on Windows, aimake will make a list of all the files it's installing and the permissions they need and pass that to the package generation tool separately.) Currently, aimake's support for generating an installer on Windows is almost complete; it can get as far as generating an input file for WiX, which can then take the build process the rest of the way. The only thing it doesn't do is actually run WiX; that's currently left to the user, even though it should be easier to automate than do manually. (One problem is that Windows Installer has a few design issues that need working around, and some of the recommended workarounds are ridiculous; eventually, I stopped trying to use them, and instead came up with my own workarounds which both practically and theoretically seem to work better, but now the build process spams warnings and errors because I'm not using the recommended workarounds. (Interestingly, the errors and many of the warnings are false positives caused by the same design issues that lead to the workarounds being necessary in the first place. It's a good thing that ""errors"" from Windows Installer's consistency checkers are really just warnings, and thus can be turned off.) The situation on Linux is a little more complex. So far I've been focusing on Debian (who have the most widely used package format). Debian's policy is written assuming that either the package was developed for Debian in particular, or that it was developed without knowledge of Debian and was packaged separately by one of their developers. The case of ""a package that exists on its own but knows how to deploy itself on Debian"" makes it quite hard to work out an appropriate source package (a binary package is much easier). Currently, aimake itself has all the appropriate options to handle being run by dpkg-buildpackage, which requires a short wrapper script (31 lines in NetHack 4, probably about 20 for most packages) to tell dpkg-buildpackage how aimake wants to be run. Much of the Debian metadata should be the same for all aimake-using programs, though (just as happened with WiX), so I'm hopeful that eventually, aimake will have an option to just automate all the steps in generating a Debian package. This would lead to a weird situation in which aimake is running dpkg-buildpackage to run itself, but this method maximises the chance that the build is reproducible. 13: Dynamic linking As something that happens at runtime, this is a little irrelevant to the design of a build system, but I'm mentioning it for completeness. So far, we've been implicitly assuming that the build is a so-called static build, in which all the code that runs at runtime is part of the executable. In practice, though, this isn't normally the case; an executable will depend on shared libraries (.so files on Linux, .dll on Windows, .dylib on Mac OS X), which contain code that's shared between multiple executables. Conceptually, dynamic linking is pretty similar to regular, static linking; the dynamic linker picks an address for the shared library and maps it into the address space of the executable, which then makes calls into it. This means that the executable needs to contain some sort of relocations, just the same way that the object file did. Here are the five relocations that end up in our Hello World executable on my 64-bit Linux system (as printed by readelf -r): Relocation section '.rela.dyn' at offset 0x3a8 contains 2 entries:   Offset          Info           Type           Sym. Value    Sym. Name + Addend 000000600ff8  000200000006 R_X86_64_GLOB_DAT 0000000000000000 __gmon_start__ + 0 000000601040  000400000005 R_X86_64_COPY     0000000000601040 stdout + 0  Relocation section '.rela.plt' at offset 0x3d8 contains 3 entries:   Offset          Info           Type           Sym. Value    Sym. Name + Addend 000000601018  000100000007 R_X86_64_JUMP_SLO 0000000000000000 __libc_start_main + 0 000000601020  000200000007 R_X86_64_JUMP_SLO 0000000000000000 __gmon_start__ + 0 000000601028  000300000007 R_X86_64_JUMP_SLO 0000000000000000 fwrite + 0  We can see our old friends stdout and fwrite here, still waiting to be linked against libc. However, we can see that the offsets for the relocations are much higher than existed in the object file; that's because the linker has already determined addresses for everything in the executable itself, and so knows where the relocations need to be at runtime. Dynamic linking is harder than static linking because the OS really wants the shared library to be bitwise identical between all the processes that run it (so that it can maintain just one copy of it in physical memory); on 64-bit Linux, the solution to this is to place the relocations in various tables that the dynamic linker updates, rather than in the code directly, and making calls indirectly via the table. (This won't work for stdout, which is a variable rather than a function; the linker resolved the problem by putting it in a separate table.) This also means that the shared library needs to be written in such a way that it can be moved around in memory and still run correctly, but on x86_64, the processor makes this pretty easy by allowing memory references to be relative to the program counter. (Meanwhile, on 32-bit x86, it's a complete nightmare; the compiler can handle it, but it has to jump through such hoops that you can instead tell the compiler to not bother, in which case the dynamic linker has to make a copy of the shared library in memory and patch up all the relocations the same way that the regular linker does. Linux's dynamic linker is actually willing to do this; on x86_64, though, it refuses, explaining that it really should be the compiler's job to make the library position-independent on a system where it's so easy.) I won't go into all the details of dynamic linking here, partly because they aren't relevant to understanding build systems and partly because I don't know what they are. However, there is one issue that needs to be addressed: what does it mean to link against a shared library, given that its code doesn't actually end up in the executable? The answer lies in the concept of an import library, which is a file that looks like a static library to the linker, but actually just puts relocations into the output executable, rather than code. On Linux, each shared library can also act an import library for itself, which makes shared library deployment pretty easy, but writing build systems confusing (especially when you consider the case of two shared libraries that need symbols from each other at runtime; this is not technically a circular dependency, but you need to somehow come up with a working import library by other means, such as by first linking the libraries without the dependency on each other). On Windows, import libraries tend to be separate files that are generated by a program dlltool from a description of which symbols go into the shared library; aimake gives it the object files from which the shared libraries are built as a handy method of describing the shared library without actually needing a copy of it (and thus breaking up the circular dependency that way). There's also a point that's important for programmers, too. On Windows, imports from a shared library will need special code generated for them, so they have to be marked in the source file. Likewise, exports need to be marked as such inside the shared library on Windows. On Linux, exports don't need to be marked, but they should be; this makes it possible for a build system to hide all the non-exported symbols from the API of the shared library by means of command-line options, thus reducing namespace pollution. Handling appropriate marking is normally done by the preprocessor. You typically have a header file declaring the API of your shared library, which looks something like this: #ifdef IN_SHARED_LIBRARY_INTERNALS # define IMPORT_EXPORT(x) AIMAKE_EXPORT(x) #else # define IMPORT_EXPORT(x) AIMAKE_IMPORT(x) #endif  int IMPORT_EXPORT(function1) (void); int IMPORT_EXPORT(function2) (int, int);  Then, users of the shared library just include the header; the shared library itself does #define IN_SHARED_LIBRARY_INTERNALS and then includes the header, and thus gets the ""export"" definitions rather than the ""import"" definitions. The AIMAKE_EXPORT and AIMAKE_IMPORT macros are defined by aimake to expand into whatever system-specific annotation is needed to import or export from a shared library. (The exact syntax is subject to change, because gcc doesn't like the way the current syntax interacts with functions that return pointers; I'm currently working around that with typedef, but really need a better solution.) As far as I can tell, this sort of marking is necessary to create shared libraries, as the API of the shared library has to be specified somehow. However, aimake will spot these annotations and automatically generate shared libraries rather than executables when it sees them, so no extra work is needed beyond the bare minimum. (Some improvements to this are needed, though; it currently doesn't work on Mac OS X because I don't know enough about shared libraries on that system, and there really should be some way to override the whole mechanism and generate static libraries instead.) Conclusions Hopefully, this post should give C programmers something of a better understanding of the toolchain that goes into actually building their programs; perhaps it'll even inspire someone to go into toolchain development. I hope I've also made the point that a lot more of a build toolchain can and should be automated than typically is; there's a lot of programmer time being wasted right now dealing with things that should really be done by a computer. Most of the attempts I've seen to fix this are dealing with the wrong problem; people look at existing build systems, and think ""we need a better tool for writing Makefiles"" or ""we need a better tool for generating configuration"", when these are really relatively small parts of a build. I hope aimake acts as a proof of concept that almost the entire build process can and should be automated, and perhaps one day grows into a tool that can be widely used for this purpose (even if today, it suffers from UI problems, the occasional bug, missing features, and incomplete platform support). At the very least, maybe the world's build system designers will be inspired to deal with every part of the build, not just the small corners they previously worked on, and I'll be able to use something standard rather than being forced to work on aimake."	"null"	"null"	""	"true"
"Beginner"	"Introduction to 'fun' C"	"https://gist.github.com/eatonphil/21b3d6569f24ad164365"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Introduction to ""Fun"" C (using GCC) · GitHub Skip to content All gists GitHub Sign up for a GitHub account Sign in Create a gist now Instantly share code, notes, and snippets. Star 16 Fork 6 eatonphil/functions.c Last active Jun 7, 2016 Embed What would you like to do? Embed Embed this gist in your website. Embed Share Copy sharable URL for this gist. Share Clone via HTTPS Clone with Git or checkout with SVN using the repository's web address. HTTPS Learn more about clone URLs Download ZIP Code Revisions 2 Stars 16 Forks 6 Introduction to ""Fun"" C (using GCC) Raw functions.c /** * This are a collection of examples for C 201. * These combine concepts you may or may not be * familiar with and are especially useful for * students new to C. There is a lot of really * cool stuff you can do in C without any cool * languages. * * This is file in particular is an introduction * to fun function usage in C. */ #include <stdio.h> int sum(int a, int b) { return a + b; } int sub(int a, int b) { return a - b; } // This function ""get_operator"" takes a *char expression // and returns a function that takes two ints and returns // an int. int (*get_operator(char* expression)) (int, int) { int i; // char pointers are automatically given a final character '\0' // to allow us to know when the char* ends. for (i = 0; expression[i] != '\0'; i++) { switch (expression[i]) { case '+': return sum; case '-': return sub; } } } void print_operator(char* expression) { // get_operator will return a function that takes two ints // and returns an int. int (*operator)(int, int) = get_operator(expression); // sum is automatically converted to a pointer, // you could also say ""operator == &sum"", but that is longer. if (operator == sum) { // comparing functions! printf(""Expression %s is a sum.\n"", expression); } else if (operator == sub) { // comparing functions again!! printf(""Expression %s is a sub.\n"", expression); } else { printf(""Expression %s has an unknown operation.\n"", expression); } // Challenge: // Instead of just printing out which operation it is, // find the two operands and perform the operation on them. // Then print the result of the expression instead. } int main() { char* expression1 = ""2 + 2""; char* expression2 = ""5 - 3""; char* expression3 = ""9 * 7""; print_operator(expression1); print_operator(expression2); print_operator(expression3); } Raw functions2.c /** * This is an example of more complex function usage in C. * Read structs.c before continuing. */ #include <stdio.h> // Good reference: // http://www.dirac.org/linux/programming/tutorials/function_pointers/ typedef struct { int legs; void (*sayName)(void); } Animal; void catSayName() { printf(""I am a cat.\n""); } void dogSayName() { printf(""I am a dog.\n""); } int sub(int a, int b) { return a - b; } int sum(int a, int b) { return a + b; } double sum_d(double a, double b) { return a + b; } // would fail if passed to operate: operate(sum_d, 1, 2) int operate(int (*f)(int, int), int a, int b) { return f(a, b); } void do_nothing(void) { return; } int main() { Animal cat; cat.legs = 4; cat.sayName = catSayName; Animal cat1; cat1.legs = 4; cat1.sayName = catSayName; Animal dog; dog.legs = 3; dog.sayName = dogSayName; cat.sayName(); // I am a cat. dog.sayName(); // I am a dog. cat.sayLegs(cat.legs); int my_sum = operate(sum, 1, 2); printf(""%d\n"", my_sum); // Prints 3 int my_sub = operate(sub, 11, 2); printf(""%d\n"", my_sub); // Prints 9 do_nothing(); } Raw pointers.c /** * This is a collection of pointer examples. * It is a fun way to test yourself. I'm * sorry I couldn't think of a better way * to show the answers. */ #include <stdio.h> void print(int i) { printf(""%d\n"", i); } int main() { int* myInt; int myIntsValue = 3; myInt = &myIntsValue; // int* somePointer; *somePointer = myIntsValue; myInt = somePointer; print(*myInt); // prints 3 int mySecondInt = 2; *myInt = mySecondInt; print(*myInt); // prints 2 print(mySecondInt); // prints 2 print(myIntsValue); // prints 2 myInt = &mySecondInt; // int* somePointer; *somePointer = mySecondInt; myInt = somePointer; mySecondInt = 5; print(*myInt); // prints 5 myIntsValue = 7; print(*myInt); // prints 5 mySecondInt = myIntsValue; print(*myInt); // prints 7 } Raw pointers2.c /** * This is a continuation of (more complex) * pointer examples. */ #include <stdio.h> void print(int i) { printf(""%d\n"", i); } void swap1(int a, int b) { int temp = b; b = a; a = temp; } void swap2(int* p_a, int* p_b) { int temp = *p_b; *p_b = *p_a; *p_a = temp; } int main() { int a = 1; int b = 2; swap1(a, b); print(a); // prints 1 print(b); // prints 2 swap2(&a, &b); print(a); // prints 2 print(b); // prints 1 int* c; int* d; c = &a; // c = some address... but *c = 2 d = &b; // d = some address... but *d = 1 swap1(*c, *d); print(*c); // prints 2 print(*d); // prints 1 swap2(c, d); print(*c); // prints 1 print(*d); // prints 2 } Raw structs.c /** * This is a brief example of typedef-ing and structs in C. */ typedef int Int; // int or Int struct Person { char* name; Int age; }; typedef struct Person APerson; // struct Person or APerson typedef struct Animal { int legs; } Animal; // struct Animal or Animal typedef struct { int mpg; } Car; // cannot use struct Car, can only use Car... the struct is anonymous int main() { APerson person; // could use ""struct Person person"" person.name = ""Phil""; person.age = 10; Animal cat; // could use ""struct Animal cat;"" cat.legs = 4; Car car; // could not use ""struct Car car;"" because the struct was anonymous car.mpg = 30; } Sign up for free to join this conversation on GitHub. Already have an account? Sign in to comment Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://gist.github.com/eatonphil/21b3d6569f24ad164365"	""	"true"
"Beginner"	"Learning C with GDB"	"https://www.recurse.com/blog/5-learning-c-with-gdb"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Learning C with gdb - Blog - Recurse Center Recurse Center About Residents Diversity FAQ Manual Blog Code Words Hire from RC Apply Log in Enjoy programming? Check out Code Words, a quarterly publication from the Recurse Center community. Learning C with gdb Coming from a background in higher-level languages like Ruby, Scheme, or Haskell, learning C can be challenging. In addition to having to wrestle with C’s lower-level features like manual memory management and pointers, you have to make do without a REPL. Once you get used to exploratory programming in a REPL, having to deal with the write-compile-run loop is a bit of a bummer. It occurred to me recently that I could use gdb as a pseudo-REPL for C. I’ve been experimenting with using gdb as a tool for learning C, rather than merely debugging C, and it’s a lot of fun. My goal in this post is to show you that gdb is a great tool for learning C. I’ll introduce you to a few of my favorite gdb commands, and then I’ll demonstrate how you can use gdb to understand a notoriously tricky part of C: the difference between arrays and pointers. An introduction to gdb Start by creating the following little C program, minimal.c: int main() {   int i = 1337;   return 0; }  Note that the program does nothing and has not a single printf statement.1 Behold the brave new world of learning C with gdb! Compile it with the -g flag so that gdb has debug information to work with, and then feed it to gdb: $ gcc -g minimal.c -o minimal $ gdb minimal  You should now find yourself at a rather stark gdb prompt. I promised you a REPL, so here goes: (gdb) print 1 + 2 $1 = 3  Amazing! print is a built-in gdb command that prints the evaluation of a C expression. If you’re unsure of what a gdb command does, try running help name-of-the-command at the gdb prompt. Here’s a somewhat more interesting example: (gbd) print (int) 2147483648 $2 = -2147483648  I’m going to ignore why 2147483648 == -2147483648; the point is that even arithmetic can be tricky in C, and gdb understands C arithmetic. Let’s now set a breakpoint in the main function and start the program: (gdb) break main (gdb) run  The program is now paused on line 3, just before i gets initialized.Interestingly, even though i hasn’t been initialized yet, we can still lookat its value using the print commnd: (gdb) print i $3 = 32767  In C, the value of an uninitialized local variable is undefined, so gdb might print something different for you! We can execute the current line with the next command: (gdb) next (gdb) print i $4 = 1337  Examining memory with x Variables in C label contiguous chunks of memory. A variable’s chunk is characterized by two numbers: The numerical address of the first byte in the chunk. The size of the chunk, measured in bytes. The size of a variable’s chunk is determined by the variable’s type. One of the distinctive features of C is that you have direct access to a variable’s chunk of memory. The & operator computes a variable’s address, and the sizeof operator computes a variable’s size in memory. You can play around with both concepts in gdb: (gdb) print &i $5 = (int *) 0x7fff5fbff584 (gdb) print sizeof(i) $6 = 4  In words, this says that i’s chunk of memory starts at address 0x7fff5fbff5b4 and takes up four bytes of memory. I mentioned above that a variable’s size in memory is determined by its type, and indeed, the sizeof operator can operate directly on types: (gdb) print sizeof(int) $7 = 4 (gdb) print sizeof(double) $8 = 8  This means that, on my machine at least, int variables take up fourbytes of space and double variables take up eight. Gdb comes with a powerful tool for directly examing memory: the x command. The x command examines memory, starting at a particular address. It comes with a number of formatting commands that provide precise control over how many bytes you’d like to examine and how you’d like to print them; when in doubt, try running help x at the gdb prompt. The & operator computes a variable’s address, so that means we can feed &i to x and thereby take a look at the raw bytes underlying i’s value: (gdb) x/4xb &i 0x7fff5fbff584: 0x39    0x05    0x00    0x00  The flags indicate that I want to examine 4 values, formatted as hex numerals, one byte at a time. I’ve chosen to examine four bytes because i’s size in memory is four bytes; the printout shows i’s raw byte-by-byte representation in memory. One subtlety to bear in mind with raw byte-by-byte examinations is that on Intel machines, bytes are stored in “little-endian” order: unlike human notation, the least significant bytes of a number come first in memory. One way to clarify the issue would be to give i a more interesting value and then re-examine its chunk of memory: (gdb) set var i = 0x12345678 (gdb) x/4xb &i 0x7fff5fbff584: 0x78 0x56 0x34 0x12  Examining types with ptype The ptype command might be my favorite command. It tells you the type of a C expression: (gdb) ptype i type = int (gdb) ptype &i type = int * (gdb) ptype main type = int (void)  Types in C can get complex but ptype allows you to explore them interactively. Pointers and arrays Arrays are a surprisingly subtle concept in C. The plan for this section is to write a simple program and then poke it in gdb until arrays start to make sense. Code up the following arrays.c program: int main() {     int a[] = {1,2,3};     return 0; }  Compile it with the -g flag, run it in gdb, then next over the initialization line: $ gcc -g arrays.c -o arrays $ gdb arrays (gdb) break main (gdb) run (gdb) next  At this point you should be able to print the contents of a and examine its type: (gdb) print a $1 = {1, 2, 3} (gdb) ptype a type = int [3]  Now that our program is set up correctly in gdb, the first thing we should do is use x to see what a looks like under the hood: (gdb) x/12xb &a 0x7fff5fbff56c: 0x01  0x00  0x00  0x00  0x02  0x00  0x00  0x00 0x7fff5fbff574: 0x03  0x00  0x00  0x00  This means that a’s chunk of memory starts at address 0x7fff5fbff5dc. The first four bytes store a[0], the next four store a[1], and the final four store a[2]. Indeed, you can check that sizeof knows that a’s size in memory is twelve bytes: (gdb) print sizeof(a) $2 = 12  At this point, arrays seem to be quite array-like. They have their own array-like types and store their members in a contiguous chunk of memory. However, in certain situations, arrays act a lot like pointers! For instance, we can do pointer arithmetic on a: = preserve do   :escaped     (gdb) print a + 1     $3 = (int *) 0x7fff5fbff570  In words, this says that a + 1 is a pointer to an int and holds the address 0x7fff5fbff570. At this point you should be reflexively passing pointers to the x command, so let’s see what happens: = preserve do   :escaped     (gdb) x/4xb a + 1     0x7fff5fbff570: 0x02  0x00  0x00  0x00  Note that 0x7fff5fbff570 is four more than 0x7fff5fbff56c, the address of a’s first byte in memory. Given that int values take up four bytes, this means that a + 1 points to a[1]. In fact, array indexing in C is syntactic sugar for pointer arithmetic: a[i] is equivalent to *(a + i). You can try this in gdb: = preserve do   :escaped     (gdb) print a[0]     $4 = 1     (gdb) print *(a + 0)     $5 = 1     (gdb) print a[1]     $6 = 2     (gdb) print *(a + 1)     $7 = 2     (gdb) print a[2]     $8 = 3     (gdb) print *(a + 2)     $9 = 3  We’ve seen that in some situations a acts like an array and in others it acts like a pointer to its first element. What’s going on? The answer is that when an array name is used in a C expression, it “decays” to a pointer to the array’s first element. There are only two exceptions to this rule: when the array name is passed to sizeof and when the array name is passed to the & operator.2 The fact that a doesn’t decay to a pointer when passed to the & operator brings up an interesting question: is there a difference between the pointer that a decays to and &a? Numerically, they both represent the same address: = preserve do   :escaped     (gdb) x/4xb a     0x7fff5fbff56c: 0x01  0x00  0x00  0x00     (gdb) x/4xb &a     0x7fff5fbff56c: 0x01  0x00  0x00  0x00  However, their types are different. We’ve already seen that the decayed value of a is a pointer to a’s first element; this must have type int *. As for the type of &a, we can ask gdb directly: = preserve do   :escaped     (gdb) ptype &a     type = int (*)[3]  In words, &a is a pointer to an array of three integers. This makes sense: a doesn’t decay when passed to &, and a has type int [3]. You can observe the distinction between a’s decayed value and &a by checking how they behave with respect to pointer arithmetic: = preserve do   :escaped     (gdb) print a + 1     $10 = (int *) 0x7fff5fbff570     (gdb) print &a + 1     $11 = (int (*)[3]) 0x7fff5fbff578  Note that adding 1 to a adds four to a’s address, whereas adding 1 to &a adds twelve! The pointer that a actually decays to is &a[0]: = preserve do   :escaped     (gdb) print &a[0]     $11 = (int *) 0x7fff5fbff56c  Conclusion Hopefully I’ve convinced you that gdb a neat exploratory environment for learning C. You can print the evaluation of expressions, examine raw bytes in memory, and tinker with the type system using ptype. If you’d like to experiment further with using gdb to learn C, I have a few suggestions: Use gdb to work through the Ksplice pointer challenge. Investigate how structs are stored in memory. How do they compare to arrays? Use gdb’s disassemble command to learn assembly programming! A particularly fun exercise is to investigate how the function call stack works. Check out gdb’s “tui” mode, which provides a grahical ncurses layer on top of regular gdb. On OS X, you’ll likely need to install gdb from source. Alan is a facilitator at Hacker School. He’d like to thank David Albert, Tom Ballinger, Nicholas Bergson-Shilcock, and Amy Dyer for helpful feedback. Curious about Hacker School? Read about us, see what our alumni say, and apply to our fall batch. Depending on how aggressive your C compiler is about optimizing useless code, you may have to make it do something :) I tried running these examples on my Raspberry Pi and everything got compiled away.↩ Formally, an array name is a “non-modifiable lvalue”. When used in an expression where an rvalue is required, an array name decays to a pointer to its first element. As for the exceptions, the & operator requires an lvalue and sizeof is just weird. ↩ Recent posts Thanks to Perka for funding $10k of diversity grants Andreas Fuchs, Sarah Sharp, and Jamey Sharp are Recurse Center residents Steve Klabnik, Paul Fenwick, and Frank Wang are Recurse Center residents Alan O'Donnell Aug 27, 2012 Tweet Home About Residents FAQ Manual Blog Apply The Recurse Center NY"	"null"	"null"	""	"true"
"Beginner"	"POSIX Threads Programming tutorial"	"https://computing.llnl.gov/tutorials/pthreads/"	"(a little dated, but most of it is still valid and useful)"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"POSIX Threads Programming POSIX Threads Programming Author: Blaise Barney, Lawrence Livermore National Laboratory UCRL-MI-133316 Table of Contents Abstract Pthreads Overview What is a Thread? What are Pthreads? Why Pthreads? Designing Threaded Programs The Pthreads API Compiling Threaded Programs Thread Management Creating and Terminating Threads Passing Arguments to Threads Joining and Detaching Threads Stack Management Miscellaneous Routines Exercise 1 Mutex Variables Mutex Variables Overview Creating and Destroying Mutexes Locking and Unlocking Mutexes Condition Variables Condition Variables Overview Creating and Destroying Condition Variables Waiting and Signaling on Condition Variables Monitoring, Debugging and Performance Analysis Tools for Pthreads LLNL Specific Information and Recommendations Topics Not Covered Exercise 2 References and More Information Appendix A: Pthread Library Routines Reference Abstract In shared memory multiprocessor architectures, threads can be used to implement parallelism. Historically, hardware vendors have implemented their own proprietary versions of threads, making portability a concern for software developers. For UNIX systems, a standardized C language threads programming interface has been specified by the IEEE POSIX 1003.1c standard. Implementations that adhere to this standard are referred to as POSIX threads, or Pthreads. The tutorial begins with an introduction to concepts, motivations, and design considerations for using Pthreads. Each of the three major classes of routines in the Pthreads API are then covered: Thread Management, Mutex Variables, and Condition Variables. Example codes are used throughout to demonstrate how to use most of the Pthreads routines needed by a new Pthreads programmer. The tutorial concludes with a discussion of LLNL specifics and how to mix MPI with pthreads. A lab exercise, with numerous example codes (C Language) is also included. Level/Prerequisites: This tutorial is ideal for those who are new to parallel programming with pthreads. A basic understanding of parallel programming in C is required. For those who are unfamiliar with Parallel Programming in general, the material covered in EC3500: Introduction to Parallel Computing would be helpful. Pthreads Overview What is a Thread? Technically, a thread is defined as an independent stream of instructions that can be scheduled to run as such by the operating system. But what does this mean? To the software developer, the concept of a ""procedure"" that runs independently from its main program may best describe a thread. To go one step further, imagine a main program (a.out) that contains a number of procedures. Then imagine all of these procedures being able to be scheduled to run simultaneously and/or independently by the operating system. That would describe a ""multi-threaded"" program. How is this accomplished? Before understanding a thread, one first needs to understand a UNIX process. A process is created by the operating system, and requires a fair amount of ""overhead"". Processes contain information about program resources and program execution state, including: Process ID, process group ID, user ID, and group ID Environment Working directory. Program instructions Registers Stack Heap File descriptors Signal actions Shared libraries Inter-process communication tools (such as message queues, pipes, semaphores, or shared memory). UNIX PROCESS THREADS WITHIN A UNIX PROCESS Threads use and exist within these process resources, yet are able to be scheduled by the operating system and run as independent entities largely because they duplicate only the bare essential resources that enable them to exist as executable code. This independent flow of control is accomplished because a thread maintains its own: Stack pointer Registers Scheduling properties (such as policy or priority) Set of pending and blocked signals Thread specific data. So, in summary, in the UNIX environment a thread: Exists within a process and uses the process resources Has its own independent flow of control as long as its parent process exists and the OS supports it Duplicates only the essential resources it needs to be independently schedulable May share the process resources with other threads that act equally independently (and dependently) Dies if the parent process dies - or something similar Is ""lightweight"" because most of the overhead has already been accomplished through the creation of its process. Because threads within the same process share resources: Changes made by one thread to shared system resources (such as closing a file) will be seen by all other threads. Two pointers having the same value point to the same data. Reading and writing to the same memory locations is possible, and therefore requires explicit synchronization by the programmer. Pthreads Overview What are Pthreads? Historically, hardware vendors have implemented their own proprietary versions of threads. These implementations differed substantially from each other making it difficult for programmers to develop portable threaded applications. In order to take full advantage of the capabilities provided by threads, a standardized programming interface was required. For UNIX systems, this interface has been specified by the IEEE POSIX 1003.1c standard (1995). Implementations adhering to this standard are referred to as POSIX threads, or Pthreads. Most hardware vendors now offer Pthreads in addition to their proprietary API's. The POSIX standard has continued to evolve and undergo revisions, including the Pthreads specification. Some useful links: standards.ieee.org/findstds/standard/1003.1-2008.html www.opengroup.org/austin/papers/posix_faq.html www.unix.org/version3/ieee_std.html Pthreads are defined as a set of C language programming types and procedure calls, implemented with a pthread.h header/include file and a thread library - though this library may be part of another library, such as libc, in some implementations. Pthreads Overview Why Pthreads? Light Weight: When compared to the cost of creating and managing a process, a thread can be created with much less operating system overhead. Managing threads requires fewer system resources than managing processes. For example, the following table compares timing results for the fork() subroutine and the pthread_create() subroutine. Timings reflect 50,000 process/thread creations, were performed with the time utility, and units are in seconds, no optimization flags. Note: don't expect the sytem and user times to add up to real time, because these are SMP systems with multiple CPUs/cores working on the problem at the same time. At best, these are approximations run on local machines, past and present. Platform fork() pthread_create() real user sys real user sys Intel 2.6 GHz Xeon E5-2670 (16 cores/node) 8.1 0.1 2.9 0.9 0.2 0.3 Intel 2.8 GHz Xeon 5660 (12 cores/node) 4.4 0.4 4.3 0.7 0.2 0.5 AMD 2.3 GHz Opteron (16 cores/node) 12.5 1.0 12.5 1.2 0.2 1.3 AMD 2.4 GHz Opteron (8 cores/node) 17.6 2.2 15.7 1.4 0.3 1.3 IBM 4.0 GHz POWER6 (8 cpus/node) 9.5 0.6 8.8 1.6 0.1 0.4 IBM 1.9 GHz POWER5 p5-575 (8 cpus/node) 64.2 30.7 27.6 1.7 0.6 1.1 IBM 1.5 GHz POWER4 (8 cpus/node) 104.5 48.6 47.2 2.1 1.0 1.5 INTEL 2.4 GHz Xeon (2 cpus/node) 54.9 1.5 20.8 1.6 0.7 0.9 INTEL 1.4 GHz Itanium2 (4 cpus/node) 54.5 1.1 22.2 2.0 1.2 0.6   fork_vs_thread.txt Efficient Communications/Data Exchange: The primary motivation for considering the use of Pthreads in a high performance computing environment is to achieve optimum performance. In particular, if an application is using MPI for on-node communications, there is a potential that performance could be improved by using Pthreads instead. MPI libraries usually implement on-node task communication via shared memory, which involves at least one memory copy operation (process to process). For Pthreads there is no intermediate memory copy required because threads share the same address space within a single process. There is no data transfer, per se. It can be as efficient as simply passing a pointer. In the worst case scenario, Pthread communications become more of a cache-to-CPU or memory-to-CPU bandwidth issue. These speeds are much higher than MPI shared memory communications. For example: some local comparisons, past and present, are shown below: Platform MPI Shared Memory Bandwidth (GB/sec) Pthreads Worst Case Memory-to-CPU Bandwidth (GB/sec) Intel 2.6 GHz Xeon E5-2670 4.5 51.2 Intel 2.8 GHz Xeon 5660 5.6 32 AMD 2.3 GHz Opteron 1.8 5.3 AMD 2.4 GHz Opteron 1.2 5.3 IBM 1.9 GHz POWER5 p5-575 4.1 16 IBM 1.5 GHz POWER4 2.1 4 Intel 2.4 GHz Xeon 0.3 4.3 Intel 1.4 GHz Itanium 2 1.8 6.4 Other Common Reasons: Threaded applications offer potential performance gains and practical advantages over non-threaded applications in several other ways: Overlapping CPU work with I/O: For example, a program may have sections where it is performing a long I/O operation. While one thread is waiting for an I/O system call to complete, CPU intensive work can be performed by other threads. Priority/real-time scheduling: tasks which are more important can be scheduled to supersede or interrupt lower priority tasks. Asynchronous event handling: tasks which service events of indeterminate frequency and duration can be interleaved. For example, a web server can both transfer data from previous requests and manage the arrival of new requests. A perfect example is the typical web browser, where many interleaved tasks can be happening at the same time, and where tasks can vary in priority. Another good example is a modern operating system, which makes extensive use of threads. A screenshot of the MS Windows OS and applications using threads is shown below. Click for larger image Pthreads Overview Designing Threaded Programs Parallel Programming: On modern, multi-core machines, pthreads are ideally suited for parallel programming, and whatever applies to parallel programming in general, applies to parallel pthreads programs. There are many considerations for designing parallel programs, such as: What type of parallel programming model to use? Problem partitioning Load balancing Communications Data dependencies Synchronization and race conditions Memory issues I/O issues Program complexity Programmer effort/costs/time ... Covering these topics is beyond the scope of this tutorial, however interested readers can obtain a quick overview in the Introduction to Parallel Computing tutorial. In general though, in order for a program to take advantage of Pthreads, it must be able to be organized into discrete, independent tasks which can execute concurrently. For example, if routine1 and routine2 can be interchanged, interleaved and/or overlapped in real time, they are candidates for threading. Programs having the following characteristics may be well suited for pthreads: Work that can be executed, or data that can be operated on, by multiple tasks simultaneously: Block for potentially long I/O waits Use many CPU cycles in some places but not others Must respond to asynchronous events Some work is more important than other work (priority interrupts) Several common models for threaded programs exist: Manager/worker: a single thread, the manager assigns work to other threads, the workers. Typically, the manager handles all input and parcels out work to the other tasks. At least two forms of the manager/worker model are common: static worker pool and dynamic worker pool. Pipeline: a task is broken into a series of suboperations, each of which is handled in series, but concurrently, by a different thread. An automobile assembly line best describes this model. Peer: similar to the manager/worker model, but after the main thread creates other threads, it participates in the work. Shared Memory Model: All threads have access to the same global, shared memory Threads also have their own private data Programmers are responsible for synchronizing access (protecting) globally shared data. Thread-safeness: Thread-safeness: in a nutshell, refers an application's ability to execute multiple threads simultaneously without ""clobbering"" shared data or creating ""race"" conditions. For example, suppose that your application creates several threads, each of which makes a call to the same library routine: This library routine accesses/modifies a global structure or location in memory. As each thread calls this routine it is possible that they may try to modify this global structure/memory location at the same time. If the routine does not employ some sort of synchronization constructs to prevent data corruption, then it is not thread-safe. The implication to users of external library routines is that if you aren't 100% certain the routine is thread-safe, then you take your chances with problems that could arise. Recommendation: Be careful if your application uses libraries or other objects that don't explicitly guarantee thread-safeness. When in doubt, assume that they are not thread-safe until proven otherwise. This can be done by ""serializing"" the calls to the uncertain routine, etc. Thread Limits: Although the Pthreads API is an ANSI/IEEE standard, implementations can, and usually do, vary in ways not specified by the standard. Because of this, a program that runs fine on one platform, may fail or produce wrong results on another platform. For example, the maximum number of threads permitted, and the default thread stack size are two important limits to consider when designing your program. Several thread limits are discussed in more detail later in this tutorial. The Pthreads API The original Pthreads API was defined in the ANSI/IEEE POSIX 1003.1 - 1995 standard. The POSIX standard has continued to evolve and undergo revisions, including the Pthreads specification. Copies of the standard can be purchased from IEEE or downloaded for free from other sites online. The subroutines which comprise the Pthreads API can be informally grouped into four major groups: Thread management: Routines that work directly on threads - creating, detaching, joining, etc. They also include functions to set/query thread attributes (joinable, scheduling etc.) Mutexes: Routines that deal with synchronization, called a ""mutex"", which is an abbreviation for ""mutual exclusion"". Mutex functions provide for creating, destroying, locking and unlocking mutexes. These are supplemented by mutex attribute functions that set or modify attributes associated with mutexes. Condition variables: Routines that address communications between threads that share a mutex. Based upon programmer specified conditions. This group includes functions to create, destroy, wait and signal based upon specified variable values. Functions to set/query condition variable attributes are also included. Synchronization: Routines that manage read/write locks and barriers. Naming conventions: All identifiers in the threads library begin with pthread_. Some examples are shown below. Routine Prefix Functional Group pthread_ Threads themselves and miscellaneous subroutines pthread_attr_ Thread attributes objects pthread_mutex_ Mutexes pthread_mutexattr_ Mutex attributes objects. pthread_cond_ Condition variables pthread_condattr_ Condition attributes objects pthread_key_ Thread-specific data keys pthread_rwlock_ Read/write locks pthread_barrier_ Synchronization barriers The concept of opaque objects pervades the design of the API. The basic calls work to create or modify opaque objects - the opaque objects can be modified by calls to attribute functions, which deal with opaque attributes. The Pthreads API contains around 100 subroutines. This tutorial will focus on a subset of these - specifically, those which are most likely to be immediately useful to the beginning Pthreads programmer. For portability, the pthread.h header file should be included in each source file using the Pthreads library. The current POSIX standard is defined only for the C language. Fortran programmers can use wrappers around C function calls. Some Fortran compilers may provide a Fortran pthreads API. A number of excellent books about Pthreads are available. Several of these are listed in the References section of this tutorial. Compiling Threaded Programs Several examples of compile commands used for pthreads codes are listed in the table below. Compiler / Platform Compiler Command Description INTEL Linux icc -pthread C icpc -pthread C++ PGI Linux pgcc -lpthread C pgCC -lpthread C++ GNU Linux, Blue Gene gcc -pthread GNU C g++ -pthread GNU C++ IBM Blue Gene bgxlc_r  /  bgcc_r C (ANSI  /  non-ANSI) bgxlC_r, bgxlc++_r C++ Thread Management Creating and Terminating Threads Routines: pthread_create (thread,attr,start_routine,arg) pthread_exit (status) pthread_cancel (thread) pthread_attr_init (attr) pthread_attr_destroy (attr) Creating Threads: Initially, your main() program comprises a single, default thread. All other threads must be explicitly created by the programmer. pthread_create creates a new thread and makes it executable. This routine can be called any number of times from anywhere within your code. pthread_create arguments: thread: An opaque, unique identifier for the new thread returned by the subroutine. attr: An opaque attribute object that may be used to set thread attributes. You can specify a thread attributes object, or NULL for the default values. start_routine: the C routine that the thread will execute once it is created. arg: A single argument that may be passed to start_routine. It must be passed by reference as a pointer cast of type void. NULL may be used if no argument is to be passed. The maximum number of threads that may be created by a process is implementation dependent. Programs that attempt to exceed the limit can fail or produce wrong results. Querying and setting your implementation's thread limit - Linux example shown. Demonstrates querying the default (soft) limits and then setting the maximum number of processes (including threads) to the hard limit. Then verifying that the limit has been overridden. bash / ksh / sh tcsh / csh  $ ulimit -a core file size          (blocks, -c) 16 data seg size           (kbytes, -d) unlimited scheduling priority             (-e) 0 file size               (blocks, -f) unlimited pending signals                 (-i) 255956 max locked memory       (kbytes, -l) 64 max memory size         (kbytes, -m) unlimited open files                      (-n) 1024 pipe size            (512 bytes, -p) 8 POSIX message queues     (bytes, -q) 819200 real-time priority              (-r) 0 stack size              (kbytes, -s) unlimited cpu time               (seconds, -t) unlimited max user processes              (-u) 1024 virtual memory          (kbytes, -v) unlimited file locks                      (-x) unlimited  $ ulimit -Hu 7168  $ ulimit -u 7168  $ ulimit -a core file size          (blocks, -c) 16 data seg size           (kbytes, -d) unlimited scheduling priority             (-e) 0 file size               (blocks, -f) unlimited pending signals                 (-i) 255956 max locked memory       (kbytes, -l) 64 max memory size         (kbytes, -m) unlimited open files                      (-n) 1024 pipe size            (512 bytes, -p) 8 POSIX message queues     (bytes, -q) 819200 real-time priority              (-r) 0 stack size              (kbytes, -s) unlimited cpu time               (seconds, -t) unlimited max user processes              (-u) 7168 virtual memory          (kbytes, -v) unlimited file locks                      (-x) unlimited  % limit  cputime      unlimited filesize     unlimited datasize     unlimited stacksize    unlimited coredumpsize 16 kbytes memoryuse    unlimited vmemoryuse   unlimited descriptors  1024  memorylocked 64 kbytes maxproc      1024  % limit maxproc unlimited  % limit cputime      unlimited filesize     unlimited datasize     unlimited stacksize    unlimited coredumpsize 16 kbytes memoryuse    unlimited vmemoryuse   unlimited descriptors  1024  memorylocked 64 kbytes maxproc      7168  Once created, threads are peers, and may create other threads. There is no implied hierarchy or dependency between threads. Thread Attributes: By default, a thread is created with certain attributes. Some of these attributes can be changed by the programmer via the thread attribute object. pthread_attr_init and pthread_attr_destroy are used to initialize/destroy the thread attribute object. Other routines are then used to query/set specific attributes in the thread attribute object. Attributes include: Detached or joinable state Scheduling inheritance Scheduling policy Scheduling parameters Scheduling contention scope Stack size Stack address Stack guard (overflow) size Some of these attributes will be discussed later. Thread Binding and Scheduling: Question: After a thread has been created, how do you know a)when it will be scheduled to run by the operating system, and b)which processor/core it will run on? The Pthreads API provides several routines that may be used to specify how threads are scheduled for execution. For example, threads can be scheduled to run FIFO (first-in first-out), RR (round-robin) or OTHER (operating system determines). It also provides the ability to set a thread's scheduling priority value. These topics are not covered here, however a good overview of ""how things work"" under Linux can be found in the sched_setscheduler man page. The Pthreads API does not provide routines for binding threads to specific cpus/cores. However, local implementations may include this functionality - such as providing the non-standard pthread_setaffinity_np routine. Note that ""_np"" in the name stands for ""non-portable"". Also, the local operating system may provide a way to do this. For example, Linux provides the sched_setaffinity routine. Terminating Threads & pthread_exit(): There are several ways in which a thread may be terminated: The thread returns normally from its starting routine. Its work is done. The thread makes a call to the pthread_exit subroutine - whether its work is done or not. The thread is canceled by another thread via the pthread_cancel routine. The entire process is terminated due to making a call to either the exec() or exit() If main() finishes first, without calling pthread_exit explicitly itself The pthread_exit() routine allows the programmer to specify an optional termination status parameter. This optional parameter is typically returned to threads ""joining"" the terminated thread (covered later). In subroutines that execute to completion normally, you can often dispense with calling pthread_exit() - unless, of course, you want to pass the optional status code back. Cleanup: the pthread_exit() routine does not close files; any files opened inside the thread will remain open after the thread is terminated. Discussion on calling pthread_exit() from main(): There is a definite problem if main() finishes before the threads it spawned if you don't call pthread_exit() explicitly. All of the threads it created will terminate because main() is done and no longer exists to support the threads. By having main() explicitly call pthread_exit() as the last thing it does, main() will block and be kept alive to support the threads it created until they are done. Example: Pthread Creation and Termination This simple example code creates 5 threads with the pthread_create() routine. Each thread prints a ""Hello World!"" message, and then terminates with a call to pthread_exit().      Pthread Creation and Termination Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29   #include <pthread.h>  #include <stdio.h>  #define NUM_THREADS     5   void *PrintHello(void *threadid)  {     long tid;     tid = (long)threadid;     printf(""Hello World! It's me, thread #%ld!\n"", tid);     pthread_exit(NULL);  }   int main (int argc, char *argv[])  {     pthread_t threads[NUM_THREADS];     int rc;     long t;     for(t=0; t<NUM_THREADS; t++){        printf(""In main: creating thread %ld\n"", t);        rc = pthread_create(&threads[t], NULL, PrintHello, (void *)t);        if (rc){           printf(""ERROR; return code from pthread_create() is %d\n"", rc);           exit(-1);        }     }      /* Last thing that main() should do */     pthread_exit(NULL);  }   Thread Management Passing Arguments to Threads The pthread_create() routine permits the programmer to pass one argument to the thread start routine. For cases where multiple arguments must be passed, this limitation is easily overcome by creating a structure which contains all of the arguments, and then passing a pointer to that structure in the pthread_create() routine. All arguments must be passed by reference and cast to (void *). Question: How can you safely pass data to newly created threads, given their non-deterministic start-up and scheduling? Example 1 - Thread Argument Passing This code fragment demonstrates how to pass a simple integer to each thread. The calling thread uses a unique data structure for each thread, insuring that each thread's argument remains intact throughout the program.  long taskids[NUM_THREADS];  for(t=0; t<NUM_THREADS; t++) {    taskids[t] = t;    printf(""Creating thread %ld\n"", t);    rc = pthread_create(&threads[t], NULL, PrintHello, (void *) taskids[t]);    ... }  Example 2 - Thread Argument Passing This example shows how to setup/pass multiple arguments via a structure. Each thread receives a unique instance of the structure.  struct thread_data{    int  thread_id;    int  sum;    char *message; };  struct thread_data thread_data_array[NUM_THREADS];  void *PrintHello(void *threadarg) {    struct thread_data *my_data;    ...    my_data = (struct thread_data *) threadarg;    taskid = my_data->thread_id;    sum = my_data->sum;    hello_msg = my_data->message;    ... }  int main (int argc, char *argv[]) {    ...    thread_data_array[t].thread_id = t;    thread_data_array[t].sum = sum;    thread_data_array[t].message = messages[t];    rc = pthread_create(&threads[t], NULL, PrintHello,          (void *) &thread_data_array[t]);    ... }  Example 3 - Thread Argument Passing (Incorrect) This example performs argument passing incorrectly. It passes the address of variable t, which is shared memory space and visible to all threads. As the loop iterates, the value of this memory location changes, possibly before the created threads can access it.  int rc; long t;  for(t=0; t<NUM_THREADS; t++)  {    printf(""Creating thread %ld\n"", t);    rc = pthread_create(&threads[t], NULL, PrintHello, (void *) &t);    ... }  Thread Management Joining and Detaching Threads Routines: pthread_join (threadid,status) pthread_detach (threadid) pthread_attr_setdetachstate (attr,detachstate) pthread_attr_getdetachstate (attr,detachstate) Joining: ""Joining"" is one way to accomplish synchronization between threads. For example: The pthread_join() subroutine blocks the calling thread until the specified threadid thread terminates. The programmer is able to obtain the target thread's termination return status if it was specified in the target thread's call to pthread_exit(). A joining thread can match one pthread_join() call. It is a logical error to attempt multiple joins on the same thread. Two other synchronization methods, mutexes and condition variables, will be discussed later. Joinable or Not? When a thread is created, one of its attributes defines whether it is joinable or detached. Only threads that are created as joinable can be joined. If a thread is created as detached, it can never be joined. The final draft of the POSIX standard specifies that threads should be created as joinable. To explicitly create a thread as joinable or detached, the attr argument in the pthread_create() routine is used. The typical 4 step process is: Declare a pthread attribute variable of the pthread_attr_t data type Initialize the attribute variable with pthread_attr_init() Set the attribute detached status with pthread_attr_setdetachstate() When done, free library resources used by the attribute with pthread_attr_destroy() Detaching: The pthread_detach() routine can be used to explicitly detach a thread even though it was created as joinable. There is no converse routine. Recommendations: If a thread requires joining, consider explicitly creating it as joinable. This provides portability as not all implementations may create threads as joinable by default. If you know in advance that a thread will never need to join with another thread, consider creating it in a detached state. Some system resources may be able to be freed. Example: Pthread Joining This example demonstrates how to ""wait"" for thread completions by using the Pthread join routine. Since some implementations of Pthreads may not create threads in a joinable state, the threads in this example are explicitly created in a joinable state so that they can be joined later.      Pthread Joining Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57   #include <pthread.h>  #include <stdio.h>  #include <stdlib.h>  #include <math.h>  #define NUM_THREADS	4   void *BusyWork(void *t)  {     int i;     long tid;     double result=0.0;     tid = (long)t;     printf(""Thread %ld starting...\n"",tid);     for (i=0; i<1000000; i++)     {        result = result + sin(i) * tan(i);     }     printf(""Thread %ld done. Result = %e\n"",tid, result);     pthread_exit((void*) t);  }   int main (int argc, char *argv[])  {     pthread_t thread[NUM_THREADS];     pthread_attr_t attr;     int rc;     long t;     void *status;      /* Initialize and set thread detached attribute */     pthread_attr_init(&attr);     pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);      for(t=0; t<NUM_THREADS; t++) {        printf(""Main: creating thread %ld\n"", t);        rc = pthread_create(&thread[t], &attr, BusyWork, (void *)t);          if (rc) {           printf(""ERROR; return code from pthread_create() is %d\n"", rc);           exit(-1);           }        }      /* Free attribute and wait for the other threads */     pthread_attr_destroy(&attr);     for(t=0; t<NUM_THREADS; t++) {        rc = pthread_join(thread[t], &status);        if (rc) {           printf(""ERROR; return code from pthread_join() is %d\n"", rc);           exit(-1);           }        printf(""Main: completed join with thread %ld having a status                 of %ld\n"",t,(long)status);        }    printf(""Main: program completed. Exiting.\n"");  pthread_exit(NULL);  }   Thread Management Stack Management Routines: pthread_attr_getstacksize (attr, stacksize) pthread_attr_setstacksize (attr, stacksize) pthread_attr_getstackaddr (attr, stackaddr) pthread_attr_setstackaddr (attr, stackaddr) Preventing Stack Problems: The POSIX standard does not dictate the size of a thread's stack. This is implementation dependent and varies. Exceeding the default stack limit is often very easy to do, with the usual results: program termination and/or corrupted data. Safe and portable programs do not depend upon the default stack limit, but instead, explicitly allocate enough stack for each thread by using the pthread_attr_setstacksize routine. The pthread_attr_getstackaddr and pthread_attr_setstackaddr routines can be used by applications in an environment where the stack for a thread must be placed in some particular region of memory. Some Practical Examples at LC: Default thread stack size varies greatly. The maximum size that can be obtained also varies greatly, and may depend upon the number of threads per node. Both past and present architectures are shown to demonstrate the wide variation in default thread stack size. Node Architecture #CPUs Memory (GB) Default Size (bytes) Intel Xeon E5-2670 16 32 2,097,152 Intel Xeon 5660 12 24 2,097,152 AMD Opteron 8 16 2,097,152 Intel IA64 4 8 33,554,432 Intel IA32 2 4 2,097,152 IBM Power5 8 32 196,608 IBM Power4 8 16 196,608 IBM Power3 16 16 98,304 Example: Stack Management This example demonstrates how to query and set a thread's stack size.      Stack Management Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48   #include <pthread.h>  #include <stdio.h>  #define NTHREADS 4  #define N 1000  #define MEGEXTRA 1000000    pthread_attr_t attr;    void *dowork(void *threadid)  {     double A[N][N];     int i,j;     long tid;     size_t mystacksize;      tid = (long)threadid;     pthread_attr_getstacksize (&attr, &mystacksize);     printf(""Thread %ld: stack size = %li bytes \n"", tid, mystacksize);     for (i=0; i<N; i++)       for (j=0; j<N; j++)        A[i][j] = ((i*j)/3.452) + (N-i);     pthread_exit(NULL);  }    int main(int argc, char *argv[])  {     pthread_t threads[NTHREADS];     size_t stacksize;     int rc;     long t;       pthread_attr_init(&attr);     pthread_attr_getstacksize (&attr, &stacksize);     printf(""Default stack size = %li\n"", stacksize);     stacksize = sizeof(double)*N*N+MEGEXTRA;     printf(""Amount of stack needed per thread = %li\n"",stacksize);     pthread_attr_setstacksize (&attr, stacksize);     printf(""Creating threads with stack size = %li bytes\n"",stacksize);     for(t=0; t<NTHREADS; t++){        rc = pthread_create(&threads[t], &attr, dowork, (void *)t);        if (rc){           printf(""ERROR; return code from pthread_create() is %d\n"", rc);           exit(-1);        }     }     printf(""Created %ld threads.\n"", t);     pthread_exit(NULL);  }   Thread Management Miscellaneous Routines pthread_self () pthread_equal (thread1,thread2) pthread_self returns the unique, system assigned thread ID of the calling thread. pthread_equal compares two thread IDs. If the two IDs are different 0 is returned, otherwise a non-zero value is returned. Note that for both of these routines, the thread identifier objects are opaque and can not be easily inspected. Because thread IDs are opaque objects, the C language equivalence operator == should not be used to compare two thread IDs against each other, or to compare a single thread ID against another value. pthread_once (once_control, init_routine) pthread_once executes the init_routine exactly once in a process. The first call to this routine by any thread in the process executes the given init_routine, without parameters. Any subsequent call will have no effect. The init_routine routine is typically an initialization routine. The once_control parameter is a synchronization control structure that requires initialization prior to calling pthread_once. For example: pthread_once_t once_control = PTHREAD_ONCE_INIT; Pthread Exercise 1 Getting Started and Thread Management Routines Overview: Login to an LC cluster using your workshop username and OTP token Copy the exercise files to your home directory Familiarize yourself with LC's Pthreads environment Write a simple ""Hello World"" Pthreads program Successfully compile your program Successfully run your program - several different ways Review, compile, run and/or debug some related Pthreads programs (provided) GO TO THE EXERCISE HERE Mutex Variables Overview Mutex is an abbreviation for ""mutual exclusion"". Mutex variables are one of the primary means of implementing thread synchronization and for protecting shared data when multiple writes occur. A mutex variable acts like a ""lock"" protecting access to a shared data resource. The basic concept of a mutex as used in Pthreads is that only one thread can lock (or own) a mutex variable at any given time. Thus, even if several threads try to lock a mutex only one thread will be successful. No other thread can own that mutex until the owning thread unlocks that mutex. Threads must ""take turns"" accessing protected data. Mutexes can be used to prevent ""race"" conditions. An example of a race condition involving a bank transaction is shown below: Thread 1 Thread 2 Balance Read balance: $1000   $1000   Read balance: $1000 $1000   Deposit $200 $1000 Deposit $200   $1000 Update balance $1000+$200   $1200   Update balance $1000+$200 $1200 In the above example, a mutex should be used to lock the ""Balance"" while a thread is using this shared data resource. Very often the action performed by a thread owning a mutex is the updating of global variables. This is a safe way to ensure that when several threads update the same variable, the final value is the same as what it would be if only one thread performed the update. The variables being updated belong to a ""critical section"". A typical sequence in the use of a mutex is as follows: Create and initialize a mutex variable Several threads attempt to lock the mutex Only one succeeds and that thread owns the mutex The owner thread performs some set of actions The owner unlocks the mutex Another thread acquires the mutex and repeats the process Finally the mutex is destroyed When several threads compete for a mutex, the losers block at that call - an unblocking call is available with ""trylock"" instead of the ""lock"" call. When protecting shared data, it is the programmer's responsibility to make sure every thread that needs to use a mutex does so. For example, if 4 threads are updating the same data, but only one uses a mutex, the data can still be corrupted. Mutex Variables Creating and Destroying Mutexes Routines: pthread_mutex_init (mutex,attr) pthread_mutex_destroy (mutex) pthread_mutexattr_init (attr) pthread_mutexattr_destroy (attr) Usage: Mutex variables must be declared with type pthread_mutex_t, and must be initialized before they can be used. There are two ways to initialize a mutex variable: Statically, when it is declared. For example: pthread_mutex_t mymutex = PTHREAD_MUTEX_INITIALIZER; Dynamically, with the pthread_mutex_init() routine. This method permits setting mutex object attributes, attr. The mutex is initially unlocked. The attr object is used to establish properties for the mutex object, and must be of type pthread_mutexattr_t if used (may be specified as NULL to accept defaults). The Pthreads standard defines three optional mutex attributes: Protocol: Specifies the protocol used to prevent priority inversions for a mutex. Prioceiling: Specifies the priority ceiling of a mutex. Process-shared: Specifies the process sharing of a mutex. Note that not all implementations may provide the three optional mutex attributes. The pthread_mutexattr_init() and pthread_mutexattr_destroy() routines are used to create and destroy mutex attribute objects respectively. pthread_mutex_destroy() should be used to free a mutex object which is no longer needed. Mutex Variables Locking and Unlocking Mutexes Routines: pthread_mutex_lock (mutex) pthread_mutex_trylock (mutex) pthread_mutex_unlock (mutex) Usage: The pthread_mutex_lock() routine is used by a thread to acquire a lock on the specified mutex variable. If the mutex is already locked by another thread, this call will block the calling thread until the mutex is unlocked. pthread_mutex_trylock() will attempt to lock a mutex. However, if the mutex is already locked, the routine will return immediately with a ""busy"" error code. This routine may be useful in preventing deadlock conditions, as in a priority-inversion situation. pthread_mutex_unlock() will unlock a mutex if called by the owning thread. Calling this routine is required after a thread has completed its use of protected data if other threads are to acquire the mutex for their work with the protected data. An error will be returned if: If the mutex was already unlocked If the mutex is owned by another thread There is nothing ""magical"" about mutexes...in fact they are akin to a ""gentlemen's agreement"" between participating threads. It is up to the code writer to insure that the necessary threads all make the the mutex lock and unlock calls correctly. The following scenario demonstrates a logical error:  Thread 1     Thread 2     Thread 3 Lock         Lock          A = 2        A = A+1      A = A*B Unlock       Unlock      Question: When more than one thread is waiting for a locked mutex, which thread will be granted the lock first after it is released? Example: Using Mutexes This example program illustrates the use of mutex variables in a threads program that performs a dot product. The main data is made available to all threads through a globally accessible structure. Each thread works on a different part of the data. The main thread waits for all the threads to complete their computations, and then it prints the resulting sum.      Using Mutexes Example   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138     #include <pthread.h>  #include <stdio.h>  #include <stdlib.h>   /*     The following structure contains the necessary information    to allow the function ""dotprod"" to access its input data and   place its output into the structure.    */   typedef struct    {     double      *a;     double      *b;     double     sum;      int     veclen;    } DOTDATA;   /* Define globally accessible variables and a mutex */   #define NUMTHRDS 4  #define VECLEN 100     DOTDATA dotstr;      pthread_t callThd[NUMTHRDS];     pthread_mutex_t mutexsum;   /*  The function dotprod is activated when the thread is created.  All input to this routine is obtained from a structure   of type DOTDATA and all output from this function is written into  this structure. The benefit of this approach is apparent for the   multi-threaded program: when a thread is created we pass a single  argument to the activated function - typically this argument  is a thread number. All  the other information required by the   function is accessed from the globally accessible structure.   */     void *dotprod(void *arg)  {      /* Define and use local variables for convenience */      int i, start, end, len ;     long offset;     double mysum, *x, *y;     offset = (long)arg;           len = dotstr.veclen;     start = offset*len;     end   = start + len;     x = dotstr.a;     y = dotstr.b;      /*     Perform the dot product and assign result     to the appropriate variable in the structure.      */      mysum = 0;     for (i=start; i<end ; i++)       {        mysum += (x[i] * y[i]);      }      /*     Lock a mutex prior to updating the value in the shared     structure, and unlock it upon updating.     */     pthread_mutex_lock (&mutexsum);     dotstr.sum += mysum;     pthread_mutex_unlock (&mutexsum);      pthread_exit((void*) 0);  }   /*   The main program creates threads which do all the work and then   print out result upon completion. Before creating the threads,  the input data is created. Since all threads update a shared structure,   we need a mutex for mutual exclusion. The main thread needs to wait for  all threads to complete, it waits for each one of the threads. We specify  a thread attribute value that allow the main thread to join with the  threads it creates. Note also that we free up handles when they are  no longer needed.  */   int main (int argc, char *argv[])  {     long i;     double *a, *b;     void *status;     pthread_attr_t attr;        /* Assign storage and initialize values */     a = (double*) malloc (NUMTHRDS*VECLEN*sizeof(double));     b = (double*) malloc (NUMTHRDS*VECLEN*sizeof(double));         for (i=0; i<VECLEN*NUMTHRDS; i++)       {       a[i]=1.0;       b[i]=a[i];       }      dotstr.veclen = VECLEN;      dotstr.a = a;      dotstr.b = b;      dotstr.sum=0;      pthread_mutex_init(&mutexsum, NULL);               /* Create threads to perform the dotproduct  */     pthread_attr_init(&attr);     pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);      for(i=0; i<NUMTHRDS; i++)     {     /*      Each thread works on a different set of data. The offset is specified      by 'i'. The size of the data for each thread is indicated by VECLEN.     */     pthread_create(&callThd[i], &attr, dotprod, (void *)i);     }      pthread_attr_destroy(&attr);      /* Wait on the other threads */     for(i=0; i<NUMTHRDS; i++)        {        pthread_join(callThd[i], &status);        }      /* After joining, print out the results and cleanup */     printf (""Sum =  %f \n"", dotstr.sum);     free (a);     free (b);     pthread_mutex_destroy(&mutexsum);     pthread_exit(NULL);  }      Serial version Pthreads version Condition Variables Overview Condition variables provide yet another way for threads to synchronize. While mutexes implement synchronization by controlling thread access to data, condition variables allow threads to synchronize based upon the actual value of data. Without condition variables, the programmer would need to have threads continually polling (possibly in a critical section), to check if the condition is met. This can be very resource consuming since the thread would be continuously busy in this activity. A condition variable is a way to achieve the same goal without polling. A condition variable is always used in conjunction with a mutex lock. A representative sequence for using condition variables is shown below. Main Thread Declare and initialize global data/variables which require synchronization (such as ""count"") Declare and initialize a condition variable object Declare and initialize an associated mutex Create threads A and B to do work Thread A Do work up to the point where a certain condition must occur (such as ""count"" must reach a specified value) Lock associated mutex and check value of a global variable Call pthread_cond_wait() to perform a blocking wait for signal from Thread-B. Note that a call to pthread_cond_wait() automatically and atomically unlocks the associated mutex variable so that it can be used by Thread-B. When signalled, wake up. Mutex is automatically and atomically locked. Explicitly unlock mutex Continue Thread B Do work Lock associated mutex Change the value of the global variable that Thread-A is waiting upon. Check value of the global Thread-A wait variable. If it fulfills the desired condition, signal Thread-A. Unlock mutex. Continue Main Thread Join / Continue Condition Variables Creating and Destroying Condition Variables Routines: pthread_cond_init (condition,attr) pthread_cond_destroy (condition) pthread_condattr_init (attr) pthread_condattr_destroy (attr) Usage: Condition variables must be declared with type pthread_cond_t, and must be initialized before they can be used. There are two ways to initialize a condition variable: Statically, when it is declared. For example: pthread_cond_t myconvar = PTHREAD_COND_INITIALIZER; Dynamically, with the pthread_cond_init() routine. The ID of the created condition variable is returned to the calling thread through the condition parameter. This method permits setting condition variable object attributes, attr. The optional attr object is used to set condition variable attributes. There is only one attribute defined for condition variables: process-shared, which allows the condition variable to be seen by threads in other processes. The attribute object, if used, must be of type pthread_condattr_t (may be specified as NULL to accept defaults). Note that not all implementations may provide the process-shared attribute. The pthread_condattr_init() and pthread_condattr_destroy() routines are used to create and destroy condition variable attribute objects. pthread_cond_destroy() should be used to free a condition variable that is no longer needed. Condition Variables Waiting and Signaling on Condition Variables Routines: pthread_cond_wait (condition,mutex) pthread_cond_signal (condition) pthread_cond_broadcast (condition) Usage: pthread_cond_wait() blocks the calling thread until the specified condition is signalled. This routine should be called while mutex is locked, and it will automatically release the mutex while it waits. After signal is received and thread is awakened, mutex will be automatically locked for use by the thread. The programmer is then responsible for unlocking mutex when the thread is finished with it. Recommendation: Using a WHILE loop instead of an IF statement (see watch_count routine in example below) to check the waited for condition can help deal with several potential problems, such as: If several threads are waiting for the same wake up signal, they will take turns acquiring the mutex, and any one of them can then modify the condition they all waited for. If the thread received the signal in error due to a program bug The Pthreads library is permitted to issue spurious wake ups to a waiting thread without violating the standard. The pthread_cond_signal() routine is used to signal (or wake up) another thread which is waiting on the condition variable. It should be called after mutex is locked, and must unlock mutex in order for pthread_cond_wait() routine to complete. The pthread_cond_broadcast() routine should be used instead of pthread_cond_signal() if more than one thread is in a blocking wait state. It is a logical error to call pthread_cond_signal() before calling pthread_cond_wait(). Proper locking and unlocking of the associated mutex variable is essential when using these routines. For example: Failing to lock the mutex before calling pthread_cond_wait() may cause it NOT to block. Failing to unlock the mutex after calling pthread_cond_signal() may not allow a matching pthread_cond_wait() routine to complete (it will remain blocked). Example: Using Condition Variables This simple example code demonstrates the use of several Pthread condition variable routines. The main routine creates three threads. Two of the threads perform work and update a ""count"" variable. The third thread waits until the count variable reaches a specified value.      Using Condition Variables Example   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96   #include <pthread.h>  #include <stdio.h>  #include <stdlib.h>   #define NUM_THREADS  3  #define TCOUNT 10  #define COUNT_LIMIT 12   int     count = 0;  int     thread_ids[3] = {0,1,2};  pthread_mutex_t count_mutex;  pthread_cond_t count_threshold_cv;   void *inc_count(void *t)   {    int i;    long my_id = (long)t;     for (i=0; i<TCOUNT; i++) {      pthread_mutex_lock(&count_mutex);      count++;       /*       Check the value of count and signal waiting thread when condition is      reached.  Note that this occurs while mutex is locked.       */      if (count == COUNT_LIMIT) {        pthread_cond_signal(&count_threshold_cv);        printf(""inc_count(): thread %ld, count = %d  Threshold reached.\n"",                my_id, count);        }      printf(""inc_count(): thread %ld, count = %d, unlocking mutex\n"",  	    my_id, count);      pthread_mutex_unlock(&count_mutex);       /* Do some ""work"" so threads can alternate on mutex lock */      sleep(1);      }    pthread_exit(NULL);  }   void *watch_count(void *t)   {    long my_id = (long)t;     printf(""Starting watch_count(): thread %ld\n"", my_id);     /*    Lock mutex and wait for signal.  Note that the pthread_cond_wait     routine will automatically and atomically unlock mutex while it waits.     Also, note that if COUNT_LIMIT is reached before this routine is run by    the waiting thread, the loop will be skipped to prevent pthread_cond_wait    from never returning.     */    pthread_mutex_lock(&count_mutex);    while (count<COUNT_LIMIT) {      pthread_cond_wait(&count_threshold_cv, &count_mutex);      printf(""watch_count(): thread %ld Condition signal received.\n"", my_id);      count += 125;      printf(""watch_count(): thread %ld count now = %d.\n"", my_id, count);      }    pthread_mutex_unlock(&count_mutex);    pthread_exit(NULL);  }   int main (int argc, char *argv[])  {    int i, rc;    long t1=1, t2=2, t3=3;    pthread_t threads[3];    pthread_attr_t attr;     /* Initialize mutex and condition variable objects */    pthread_mutex_init(&count_mutex, NULL);    pthread_cond_init (&count_threshold_cv, NULL);     /* For portability, explicitly create threads in a joinable state */    pthread_attr_init(&attr);    pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);    pthread_create(&threads[0], &attr, watch_count, (void *)t1);    pthread_create(&threads[1], &attr, inc_count, (void *)t2);    pthread_create(&threads[2], &attr, inc_count, (void *)t3);     /* Wait for all threads to complete */    for (i=0; i<NUM_THREADS; i++) {      pthread_join(threads[i], NULL);    }    printf (""Main(): Waited on %d  threads. Done.\n"", NUM_THREADS);     /* Clean up and exit */    pthread_attr_destroy(&attr);    pthread_mutex_destroy(&count_mutex);    pthread_cond_destroy(&count_threshold_cv);    pthread_exit(NULL);   }    Monitoring, Debugging and Performance Analysis Tools for Pthreads Monitoring and Debugging Pthreads: Debuggers vary in their ability to handle Pthreads. The TotalView debugger is LC's recommended debugger for parallel programs. It is well suited for both monitoring and debugging threaded programs. An example screenshot from a TotalView session using a threaded code is shown below. Stack Trace Pane: Displays the call stack of routines that the selected thread is executing. Status Bars: Show status information for the selected thread and its associated process. Stack Frame Pane: Shows a selected thread's stack variables, registers, etc. Source Pane: Shows the source code for the selected thread. Root Window showing all threads Threads Pane: Shows threads associated with the selected process See the TotalView Debugger tutorial for details. The Linux ps command provides several flags for viewing thread information. Some examples are shown below. See the man page for details.  % ps -Lf  UID        PID  PPID   LWP  C NLWP STIME TTY          TIME CMD blaise   22529 28240 22529  0    5 11:31 pts/53   00:00:00 a.out blaise   22529 28240 22530 99    5 11:31 pts/53   00:01:24 a.out blaise   22529 28240 22531 99    5 11:31 pts/53   00:01:24 a.out blaise   22529 28240 22532 99    5 11:31 pts/53   00:01:24 a.out blaise   22529 28240 22533 99    5 11:31 pts/53   00:01:24 a.out  % ps -T    PID  SPID TTY          TIME CMD 22529 22529 pts/53   00:00:00 a.out 22529 22530 pts/53   00:01:49 a.out 22529 22531 pts/53   00:01:49 a.out 22529 22532 pts/53   00:01:49 a.out 22529 22533 pts/53   00:01:49 a.out  % ps -Lm    PID   LWP TTY          TIME CMD 22529     - pts/53   00:18:56 a.out     - 22529 -        00:00:00 -     - 22530 -        00:04:44 -     - 22531 -        00:04:44 -     - 22532 -        00:04:44 -     - 22533 -        00:04:44 -  LC's Linux clusters also provide the top command to monitor processes on a node. If used with the -H flag, the threads contained within a process will be visible. An example of the top -H command is shown below. The parent process is PID 18010 which spawned three threads, shown as PIDs 18012, 18013 and 18014. Performance Analysis Tools: There are a variety of performance analysis tools that can be used with threaded programs. Searching the web will turn up a wealth of information. At LC, the list of supported computing tools can be found at: computing.llnl.gov/code/content/software_tools.php. These tools vary significantly in their complexity, functionality and learning curve. Covering them in detail is beyond the scope of this tutorial. Some tools worth investigating, specifically for threaded codes, include: Open|SpeedShop TAU HPCToolkit PAPI Intel VTune Amplifier ThreadSpotter LLNL Specific Information and Recommendations This section describes details specific to Livermore Computing's systems. Implementations: All LC production systems include a Pthreads implementation that follows draft 10 (final) of the POSIX standard. This is the preferred implementation. Implementations differ in the maximum number of threads that a process may create. They also differ in the default amount of thread stack space. Compiling: LC maintains a number of compilers, and usually several different versions of each - see the LC's Supported Compilers web page. The compiler commands described in the Compiling Threaded Programs section apply to LC systems. Mixing MPI with Pthreads: This is the primary motivation for using Pthreads at LC. Design: Each MPI process typically creates and then manages N threads, where N makes the best use of the available cores/node. Finding the best value for N will vary with the platform and your application's characteristics. In general, there may be problems if multiple threads make MPI calls. The program may fail or behave unexpectedly. If MPI calls must be made from within a thread, they should be made only by one thread. Compiling: Use the appropriate MPI compile command for the platform and language of choice Be sure to include the required Pthreads flag as shown in the Compiling Threaded Programs section. An example code that uses both MPI and Pthreads is available below. The serial, threads-only, MPI-only and MPI-with-threads versions demonstrate one possible progression. Serial Pthreads only MPI only MPI with pthreads makefile Topics Not Covered Several features of the Pthreads API are not covered in this tutorial. These are listed below. See the Pthread Library Routines Reference section for more information. Thread Scheduling Implementations will differ on how threads are scheduled to run. In most cases, the default mechanism is adequate. The Pthreads API provides routines to explicitly set thread scheduling policies and priorities which may override the default mechanisms. The API does not require implementations to support these features. Keys: Thread-Specific Data As threads call and return from different routines, the local data on a thread's stack comes and goes. To preserve stack data you can usually pass it as an argument from one routine to the next, or else store the data in a global variable associated with a thread. Pthreads provides another, possibly more convenient and versatile, way of accomplishing this through keys. Mutex Protocol Attributes and Mutex Priority Management for the handling of ""priority inversion"" problems. Condition Variable Sharing - across processes Thread Cancellation Threads and Signals Synchronization constructs - barriers and locks Pthread Exercise 2 Mutexes, Condition Variables and Hybrid MPI with Pthreads Overview: Login to the LC workshop cluster, if you are not already logged in Mutexes: review and run the provided example codes Condition variables: review and run the provided example codes Hybrid MPI with Pthreads: review and run the provided example codes GO TO THE EXERCISE HERE This completes the tutorial.       Please complete the online evaluation form - unless you are doing the exercise, in which case please complete it at the end of the exercise. Where would you like to go now? Exercise Agenda Back to the top References and More Information Author: Blaise Barney, Livermore Computing. POSIX Standard: www.unix.org/version3/ieee_std.html ""Pthreads Programming"". B. Nichols et al. O'Reilly and Associates. ""Threads Primer"". B. Lewis and D. Berg. Prentice Hall ""Programming With POSIX Threads"". D. Butenhof. Addison Wesley ""Programming With Threads"". S. Kleiman et al. Prentice Hall Appendix A: Pthread Library Routines Reference For convenience, an alphabetical list of Pthread routines, linked to their corresponding man page, is provided below. pthread_atfork pthread_attr_destroy pthread_attr_getdetachstate pthread_attr_getguardsize pthread_attr_getinheritsched pthread_attr_getschedparam pthread_attr_getschedpolicy pthread_attr_getscope pthread_attr_getstack pthread_attr_getstackaddr pthread_attr_getstacksize pthread_attr_init pthread_attr_setdetachstate pthread_attr_setguardsize pthread_attr_setinheritsched pthread_attr_setschedparam pthread_attr_setschedpolicy pthread_attr_setscope pthread_attr_setstack pthread_attr_setstackaddr pthread_attr_setstacksize pthread_barrier_destroy pthread_barrier_init pthread_barrier_wait pthread_barrierattr_destroy pthread_barrierattr_getpshared pthread_barrierattr_init pthread_barrierattr_setpshared pthread_cancel pthread_cleanup_pop pthread_cleanup_push pthread_cond_broadcast pthread_cond_destroy pthread_cond_init pthread_cond_signal pthread_cond_timedwait pthread_cond_wait pthread_condattr_destroy pthread_condattr_getclock pthread_condattr_getpshared pthread_condattr_init pthread_condattr_setclock pthread_condattr_setpshared pthread_create pthread_detach pthread_equal pthread_exit pthread_getconcurrency pthread_getcpuclockid pthread_getschedparam pthread_getspecific pthread_join pthread_key_create pthread_key_delete pthread_kill pthread_mutex_destroy pthread_mutex_getprioceiling pthread_mutex_init pthread_mutex_lock pthread_mutex_setprioceiling pthread_mutex_timedlock pthread_mutex_trylock pthread_mutex_unlock pthread_mutexattr_destroy pthread_mutexattr_getprioceiling pthread_mutexattr_getprotocol pthread_mutexattr_getpshared pthread_mutexattr_gettype pthread_mutexattr_init pthread_mutexattr_setprioceiling pthread_mutexattr_setprotocol pthread_mutexattr_setpshared pthread_mutexattr_settype pthread_once pthread_rwlock_destroy pthread_rwlock_init pthread_rwlock_rdlock pthread_rwlock_timedrdlock pthread_rwlock_timedwrlock pthread_rwlock_tryrdlock pthread_rwlock_trywrlock pthread_rwlock_unlock pthread_rwlock_wrlock pthread_rwlockattr_destroy pthread_rwlockattr_getpshared pthread_rwlockattr_init pthread_rwlockattr_setpshared pthread_self pthread_setcancelstate pthread_setcanceltype pthread_setconcurrency pthread_setschedparam pthread_setschedprio pthread_setspecific pthread_sigmask pthread_spin_destroy pthread_spin_init pthread_spin_lock pthread_spin_trylock pthread_spin_unlock pthread_testcancel"	"null"	"null"	"(a little dated, but most of it is still valid and useful)"	"true"
"Beginner"	"The GNU C Programming Tutorial"	"http://www.crasseux.com/books/ctut.pdf"	"(online PDF)"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"(online PDF)"	"false"
"Beginner"	"Templating in C"	"http://blog.pkh.me/p/20-templating-in-c.html"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Templating in C A small freedom area. Templating in C Sat 28 Feb 2015 prog The question of how to do templating in C is often raised, and I couldn't find a good overview of the different approaches so I'll try to make a relatively exhaustive list here. Note: the methods presented here rely on the C preprocessor, which you can use directly yourself by calling the cpp command, paste your code and see the output by sending an EOS (pressing control + d typically). Simple C macro So the most common method is to dump some code enclosed (or not) into the do { ... } while (0) form: #define DO_RANDOM_STUFF(type) do {      \     int i;                              \     type *p = buf;                      \                                         \     for (i = 0; i < len; i++)           \         p[i] = p[i] * k;                \ } while (0)  ... and using it directly: int func(void *buf, int len, float k, int request) {     if      (request == INT8)   DO_RANDOM_STUFF(int8_t);     else if (request == INT16)  DO_RANDOM_STUFF(int16_t);     else if (request == INT32)  DO_RANDOM_STUFF(int32_t); }  Simple C macro, full function It is also common to create the whole function that way: #define DECLARE_FUNC(n)                                 \ static void func_##n(int##n##_t *p, int len, float k)   \ {                                                       \     int i;                                              \                                                         \     for (i = 0; i < len; i++)                           \         p[i] = p[i] * k;                                \ }  DECLARE_FUNC(8) DECLARE_FUNC(16) DECLARE_FUNC(32)  ... which you will then use by simply calling func_8(), func_16() and func_32(). Alternative function creator So far we used the templating just to avoid typing redundancy, but it is sometimes motivated by performance. Let's observe the following pattern: int process_image(void *img, int width, int height, const int n) {     int x, y;      for (y = 0; y < height; y++) {         for (x = 0; x < width; x++) {             if      (n == 0) foo(img, x, y);             else if (n == 1) bar(img, x, y);             else             baz(img, x, y);         }     } }  We will assume here that foo(), bar() and baz() functions are meant to be inlined for performance reasons (be it justified or not, we assume you do not want a per-pixel function call), so you do not want to use an array of function pointers and do func_lut[n](img, x, y) in the inner loop. We could also consider the scenario where the functions take a completely different set of parameters. Your compiler will sometimes be smart enough to see that the n check in the inner loop can instead enclose the whole logic just as if you had written this: int process_image(void *img, int width, int height, const int n) {     int x, y;      if (n == 0)         for (y = 0; y < height; y++)             for (x = 0; x < width; x++)                 foo(img, x, y);     else if (n == 1)         for (y = 0; y < height; y++)             for (x = 0; x < width; x++)                 bar(img, x, y);     else         for (y = 0; y < height; y++)             for (x = 0; x < width; x++)                 baz(img, x, y); }  Unfortunately, it is very likely that your code is much more complex (otherwise you could even just put the 2 loops into your inner functions) which will cause your compiler not to do it. One solution for this is to create wrapper for each scenario. It would look like this: static inline int process_image(void *img, int width, int height, const int n) {     int x, y;      for (y = 0; y < height; y++) {         for (x = 0; x < width; x++) {             if      (n == 0) foo(img, x, y);             else if (n == 1) bar(img, x, y);             else             baz(img, x, y);         }     } }  int process_image_foo(void *img, int width, int height) {     return process_image(img, width, height, 0); }  int process_image_bar(void *img, int width, int height) {     return process_image(img, width, height, 1); }  int process_image_baz(void *img, int width, int height) {     return process_image(img, width, height, 2); }  Notice how the process_image() function has been marked as static inline in order to make sure it is fully inlined in each wrapper. By doing so, the compiler can very easily see the dead paths (because n is now a constant in the wrappers) and generate 3 standalone functions with zero call nor inner condition. These functions can now be put into a function lookup table mapped to n (process_image_lut[n](img, width, height)). One great thing about this method is that you can also do type-specific code in each of the function (by interpreting img as int16_t, float, uint64_t, etc for example). As a side effect, you will notice that the main logic is not under a huge hardly maintainable macro, and the redundancy overhead is also very small. Note: you might want to rely on __attribute__((always_inline)) if your compiler supports it and you want the inline to be effective at every optimization level. Mixing full functions mechanism and macros If the redundancy overhead in the previous example is still too much for you, you can mix it with a small macro mechanism: static inline int process_image(void *img, int width, int height, const int n) {     int x, y;      for (y = 0; y < height; y++) {         for (x = 0; x < width; x++) {             if      (n == 0) foo(img, x, y);             else if (n == 1) bar(img, x, y);             else             baz(img, x, y);         }     } }  #define DECLARE_PROCESS_IMAGE_FUNC(name, n)                 \ int process_image_##name(void *img, int width, int height)  \ {                                                           \     return process_image(img, width, height, n);            \ }  DECLARE_PROCESS_IMAGE_FUNC(foo, 0) DECLARE_PROCESS_IMAGE_FUNC(bar, 1) DECLARE_PROCESS_IMAGE_FUNC(baz, 2)  This avoids the painful redundancy and still benefits from the same advantages as previously. FFmpeg's XBR filter and paletteuse filter are a few real cases examples. External file One alternative to all of this is to use external files. The logic is pretty simple; let's start with the content of caller.c: #include <stdint.h>  #define TEMPLATE_U16 #include ""evil_template.c"" #undef TEMPLATE_U16  #define TEMPLATE_U32 #include ""evil_template.c"" #undef TEMPLATE_U32  #define TEMPLATE_FLT #include ""evil_template.c"" #undef TEMPLATE_FLT  #define TEMPLATE_DBL #include ""evil_template.c"" #undef TEMPLATE_DBL  The content of evil_template.c could look like something like this: #if defined(TEMPLATE_U16)  #    define RENAME(N)   N ## _u16 #    define TYPE        uint16_t #    define SUM_TYPE    uint32_t #    define XDIV(x, n)  (((x) + ((1<<(n))-1)) >> (n))  #elif defined(TEMPLATE_U32)  #    define RENAME(N)   N ## _u32 #    define TYPE        uint32_t #    define SUM_TYPE    uint64_t #    define XDIV(x, n)  (((x) + ((1<<(n))-1)) >> (n))  #elif defined(TEMPLATE_FLT)  #    define RENAME(N)   N ## _flt #    define TYPE        float #    define SUM_TYPE    float #    define XDIV(x, n)  ((x) / (float)(1<<(n)))  #elif defined(TEMPLATE_DBL)  #    define RENAME(N)   N ## _dbl #    define TYPE        double #    define SUM_TYPE    double #    define XDIV(x, n)  ((x) / (double)(1<<(n)))  #endif  TYPE RENAME(func)(const TYPE *p, int n) {     int i;     SUM_TYPE sum = 0;      for (i = 0; i < 1<<n; i++)         sum += p[i];     return XDIV(sum, n); }  #undef RENAME #undef TYPE #undef SUM_TYPE #undef XDIV  This will produce the following functions: % gcc -Wall -c caller.c -o caller.o && readelf -s caller.o | grep func  9: 0000000000000000   110 FUNC    GLOBAL DEFAULT    1 func_u16 10: 000000000000006e   119 FUNC    GLOBAL DEFAULT    1 func_u32 11: 00000000000000e5   128 FUNC    GLOBAL DEFAULT    1 func_flt 12: 0000000000000165   131 FUNC    GLOBAL DEFAULT    1 func_dbl  This way of templating could be relatively handy if you have a set of functions in the template but can be considered by many as the root of all evils. Nevertheless, this is still a few order of magnitude better than C++ templating. Note: make sure your build system properly handles the dependency of evil_template.c from caller.c. Resampling code in libswresample (which inspired this example) is one of the many real case example. Conclusion Mixing the full functions mechanism and macros covers most of the cases and can lead to very decent code with high level of readability and maintenance. For more complex cases, you also can simply rely on another language, generally a scripting one (but you can use C to generate C as well of course). This can often be the most appropriate approach if the complexity is increasing and your project already has a dependency on such a language. Edit: As pointed by someone on HN, it is also worth mentioning __Generic in C11 that can be used for similar purpose if your project can afford the dependency on C11. index | article raw www/misc | mail+jabber: u pkh.me | irc: ubitux@freenode/yozora"	"null"	"null"	""	"true"
"Intermediate"	"8 gdb tricks you should know"	"https://blogs.oracle.com/ksplice/entry/8_gdb_tricks_you_should"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"8 gdb tricks you should know (Ksplice Blog) Oracle Blogs Home Products & Services Downloads Support Partners Communities About Login Oracle Blog Ksplice Blog Rebooting is obsolete « Coffee shop Internet... | Main | Happy Birthday Kspli... » 8 gdb tricks you should know By Ksplice Post Importer on Jan 24, 2011 Despite its age, gdb remains an amazingly versatile and flexible tool, and mastering it can save you huge amounts of time when trying to debug problems in your code. In this post, I'll share 10 tips and tricks for using GDB to debug most efficiently. I'll be using the Linux kernel for examples throughout this post, not because these examples are necessarily realistic, but because it's a large C codebase that I know and that anyone can download and take a look at. Don't worry if you aren't familiar with Linux's source in particular -- the details of the examples won't matter too much. break WHERE if COND If you've ever used gdb, you almost certainly know about the ""breakpoint"" command, which lets you break at some specified point in the debugged program. But did you know that you can set conditional breakpoints? If you add if CONDITION to a breakpoint command, you can include an expression to be evaluated whenever the program reaches that point, and the program will only be stopped if the condition is fulfilled. Suppose I was debugging the Linux kernel and wanted to stop whenever init got scheduled. I could do: (gdb) break context_switch if next == init_task  Note that the condition is evaluated by gdb, not by the debugged program, so you still pay the cost of the target stopping and switching to gdb every time the breakpoint is hit. As such, they still slow the target down in relation to to how often the target location is hit, not how often the condition is met. command In addition to conditional breakpoints, the command command lets you specify commands to be run every time you hit a breakpoint. This can be used for a number of things, but one of the most basic is to augment points in a program to include debug output, without having to recompile and restart the program. I could get a minimal log of every mmap() operation performed on a system using: (gdb) b do_mmap_pgoff  Breakpoint 1 at 0xffffffff8111a441: file mm/mmap.c, line 940. (gdb) command 1 Type commands for when breakpoint 1 is hit, one per line. End with a line saying just ""end"". >print addr >print len >print prot >end (gdb)  gdb --args This one is simple, but a huge timesaver if you didn't know it. If you just want to start a program under gdb, passing some arguments on the command line, you can just build your command-line like usual, and then put ""gdb --args"" in front to launch gdb with the target program and the argument list both set: [~]$ gdb --args pizzamaker --deep-dish --toppings=pepperoni ... (gdb) show args Argument list to give program being debugged when it is started is   "" --deep-dish --toppings=pepperoni"". (gdb) b main Breakpoint 1 at 0x45467c: file oven.c, line 123. (gdb) run ...  I find this especially useful if I want to debug a project that has some arcane wrapper script that assembles lots of environment variables and possibly arguments before launching the actual binary (I'm looking at you, libtool). Instead of trying to replicate all that state and then launch gdb, simply make a copy of the wrapper, find the final ""exec"" call or similar, and add ""gdb --args"" in front. Finding source files I run Ubuntu, so I can download debug symbols for most of the packages on my system from ddebs.ubuntu.com, and I can get source using apt-get source. But how do I tell gdb to put the two together? If the debug symbols include relative paths, I can use gdb's directory command to add the source directory to my source path: [~/src]$ apt-get source coreutils [~/src]$ sudo apt-get install coreutils-dbgsym [~/src]$ gdb /bin/ls GNU gdb (GDB) 7.1-ubuntu (gdb) list main 1192    ls.c: No such file or directory.     in ls.c (gdb) directory ~/src/coreutils-7.4/src/ Source directories searched: /home/nelhage/src/coreutils-7.4:$cdir:$cwd (gdb) list main 1192        } 1193    } 1194     1195    int 1196    main (int argc, char **argv) 1197    { 1198      int i; 1199      struct pending *thispend; 1200      int n_files; 1201  Sometimes, however, debug symbols end up with absolute paths, such as the kernel's. In that case, I can use set substitute-path to tell gdb how to translate paths: [~/src]$ apt-get source linux-image-2.6.32-25-generic [~/src]$ sudo apt-get install linux-image-2.6.32-25-generic-dbgsym [~/src]$ gdb /usr/lib/debug/boot/vmlinux-2.6.32-25-generic  (gdb) list schedule 5519    /build/buildd/linux-2.6.32/kernel/sched.c: No such file or directory.     in /build/buildd/linux-2.6.32/kernel/sched.c (gdb) set substitute-path /build/buildd/linux-2.6.32 /home/nelhage/src/linux-2.6.32/ (gdb) list schedule 5519     5520    static void put_prev_task(struct rq *rq, struct task_struct *p) 5521    { 5522        u64 runtime = p->se.sum_exec_runtime - p->se.prev_sum_exec_runtime; 5523     5524        update_avg(&p->se.avg_running, runtime); 5525     5526        if (p->state == TASK_RUNNING) { 5527            /* 5528             * In order to avoid avg_overlap growing stale when we are  Debugging macros One of the standard reasons almost everyone will tell you to prefer inline functions over macros is that debuggers tend to be better at dealing with inline functions. And in fact, by default, gdb doesn't know anything at all about macros, even when your project was built with debug symbols: (gdb) p GFP_ATOMIC No symbol ""GFP_ATOMIC"" in current context. (gdb) p task_is_stopped(&init_task) No symbol ""task_is_stopped"" in current context.  However, if you're willing to tell GCC to generate debug symbols specifically optimized for gdb, using -ggdb3, it can preserve this information: $ make KCFLAGS=-ggdb3 ... (gdb) break schedule (gdb) continue (gdb) p/x GFP_ATOMIC $1 = 0x20 (gdb) p task_is_stopped_or_traced(init_task) $2 = 0  You can also use the macro and info macro commands to work with macros from inside your gdb session: (gdb) macro expand task_is_stopped_or_traced(init_task) expands to: ((init_task->state & (4 | 8)) != 0) (gdb) info macro task_is_stopped_or_traced Defined at include/linux/sched.h:218   included at include/linux/nmi.h:7   included at kernel/sched.c:31 #define task_is_stopped_or_traced(task) ((task->state & (__TASK_STOPPED | __TASK_TRACED)) != 0)  Note that gdb actually knows which contexts macros are and aren't visible, so when you have the program stopped inside some function, you can only access macros visible at that point. (You can see that the ""included at"" lines above show you through exactly what path the macro is visible). gdb variables Whenever you print a variable in gdb, it prints this weird $NN = before it in the output: (gdb) p 5+5 $1 = 10  This is actually a gdb variable, that you can use to reference that same variable any time later in your session: (gdb) p $1 $2 = 10  You can also assign your own variables for convenience, using set: (gdb) set $foo = 4 (gdb) p $foo $3 = 4  This can be useful to grab a reference to some complex expression or similar that you'll be referencing many times, or, for example, for simplicity in writing a conditional breakpoint (see tip 1). Register variables In addition to the numeric variables, and any variables you define, gdb exposes your machine's registers as pseudo-variables, including some cross-architecture aliases for common ones, like $sp for the the stack pointer, or $pc for the program counter or instruction pointer. These are most useful when debugging assembly code or code without debugging symbols. Combined with a knowledge of your machine's calling convention, for example, you can use these to inspect function parameters: (gdb) break write if $rsi == 2  will break on all writes to stderr on amd64, where the $rsi register is used to pass the first parameter. The x command Most people who've used gdb know about the print or p command, because of its obvious name, but I've been surprised how many don't know about the power of the x command. x (for ""examine"") is used to output regions of memory in various formats. It takes two arguments in a slightly unusual syntax: x/FMT ADDRESS  ADDRESS, unsurprisingly, is the address to examine; It can be an arbitrary expression, like the argument to print. FMT controls how the memory should be dumped, and consists of (up to) three components: A numeric COUNT of how many elements to dump A single-character FORMAT, indicating how to interpret and display each element A single-character SIZE, indicating the size of each element to display. x displays COUNT elements of length SIZE each, starting from ADDRESS, formatting them according to the FORMAT. There are many valid ""format"" arguments; help x in gdb will give you the full list, so here's my favorites: x/x displays elements in hex, x/d displays them as signed decimals, x/c displays characters, x/i disassembles memory as instructions, and x/s interprets memory as C strings. The SIZE argument can be one of: b, h, w, and g, for one-, two-, four-, and eight-byte blocks, respectively. If you have debug symbols so that GDB knows the types of everything you might want to inspect, p is usually a better choice, but if not, x is invaluable for taking a look at memory. [~]$ grep saved_command /proc/kallsyms ffffffff81946000 B saved_command_line   (gdb) x/s 0xffffffff81946000 ffffffff81946000 <>:     ""root=/dev/sda1 quiet""  x/i is invaluable as a quick way to disassemble memory: (gdb) x/5i schedule    0xffffffff8154804a <schedule>:   push   %rbp    0xffffffff8154804b <schedule+1>: mov    $0x11ac0,%rdx    0xffffffff81548052 <schedule+8>: mov    %gs:0xb588,%rax    0xffffffff8154805b <schedule+17>:    mov    %rsp,%rbp    0xffffffff8154805e <schedule+20>:    push   %r15  If I'm stopped at a segfault in unknown code, one of the first things I try is something like x/20i $ip-40, to get a look at what the code I'm stopped at looks like. A quick-and-dirty but surprisingly effective way to debug memory leaks is to let the leak grow until it consumes most of a program's memory, and then attach gdb and just x random pieces of memory. Since the leaked data is using up most of memory, you'll usually hit it pretty quickly, and can try to interpret what it must have come from. ~nelhage Ksplice is hiring! Do you love tinkering with, exploring, and debugging Linux systems? Does writing Python clones of your favorite childhood computer games sound like a fun weekend project? Have you ever told a joke whose punch line was a git command? Join Ksplice and work on technology that most people will tell you is impossible: updating the Linux kernel while it is running. Help us develop the software and infrastructure to bring rebootless kernel updates to Linux, as well as new operating system kernels and other parts of the software stack. We're hiring backend, frontend, and kernel engineers. Say hello at jobs@ksplice.com! Category: programming Tags: c debugging gdb linux tricks Permanent link to this entry « Coffee shop Internet... | Main | Happy Birthday Kspli... » Comments: One of my favourite GDB tricks: The @ symbol, used to view many elements of an array/STL vector in one go. With C, it is easy to view the full array: If the code is: int a[ 10 ] = { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 }; Then: (gdb) p a $1 = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10} However this is not useful if the array has 1000 entries, and you want to view a handful of entries located somewhere in the middle. Also, this will not work with a C++ vector, because it will dump the vector object's data members. Using the '@' symbol allows us to do both: (gdb) p *&a[0]@10 $1 = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10} This prints the first 10 elements in the vector. Looks ugly, but is not so complicated really: '&a[0]' gets the address of the first element. '*' dereferences the address back to the vector's data type. Finally '@10' pulls out 10 elements. Of course, to view elements 550-553 in a long vector, all you do is 'p *&a[550]@4'. Posted by Niraj on August 28, 2012 at 07:37 AM EDT # Post a Comment: Name: E-Mail: URL: Notify me by email of new comments Remember Information? Your Comment: HTML Syntax: NOT allowed About Tired of rebooting to update systems? So are we -- which is why we invented Ksplice, technology that lets you update the Linux kernel without rebooting. It's currently available as part of Oracle Linux Premier Support, Fedora, and Ubuntu desktop. This blog is our place to ramble about technical topics that we (and hopefully you) think are interesting. Search Enter search term: Search filtering requires JavaScript Recent Posts Fixing Security Vulnerabilities in Linux Ksplice SNMP Plugin CVE-2013-2224: Denial of service in sendmsg(). CVE-2013-2850: Remote heap buffer overflow in iSCSI target subsystem. Ksplice update for CVE-2013-2094 Ksplice Inspector Introducing RedPatch The Ksplice Pointer Challenge Building a physical CPU load meter Improving your social life with git Top Tags 6.828 applet apt arduino arp arping array assembly automation c code contest cve databases debian debugging dpkg elf exploit fedora fun games gcc hello-world http ip kernel ksplice libc linux longest mit mmap networking null objdump optimization pointer python scalability security sipb system-administration systems-administration tcp tweet twitter unix vulnerability wireless Categories Ksplice Oracle Personal computer-architecture databases essays fun networking programming security system-administration uncategorized Archives « July 2016 Sun Mon Tue Wed Thu Fri Sat           1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31             Today Bookmarks Oracle Linux Oracle Linux Support Oracle Linux on OTN Menu Blogs Home Weblog Login Feeds RSS All /Ksplice /Oracle /Personal /computer-architecture /databases /essays /fun /networking /programming /security /system-administration /uncategorized Comments Atom All /Ksplice /Oracle /Personal /computer-architecture /databases /essays /fun /networking /programming /security /system-administration /uncategorized Comments The views expressed on this blog are those of the author and do not necessarily reflect the views of Oracle. Terms of Use | Your Privacy Rights |"	"null"	"null"	""	"true"
"Intermediate"	"10 C99 tricks"	"http://blog.noctua-software.com/c-tricks.html"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Guillaume Chereau Blog - 10 C99 tricks Toggle navigation Guillaume Chereau Blog Home About Rss 10 C99 tricks Here are ten interesting patterns and tricks I sometime use in my C code, some are well known, some not so much. I am sure all of them work with clang and gcc (after fixing the evetual typos). I didn't try with MSVC, but except for no 1 and 5, I think it should also work. [edit]: Here is a link to the hacker news thread. [edit]: Maybe the title is a bit misleading, this is not strictly about C99. Some items in the list are valid C89, and some others would not compile with -std=c99 -pedantic, and there are also gnu extensions. But pragmatically, all of those will compile with recent gcc and clang compiler. 0. Ternary operator without middle operand (gnu extension) // Instead of x = x ? x : 10;  // We can use the shorter form: x = x ?: 10;  // Advantage: if x is an expression it // will be evaluated only once.  1. Unamed struct for smart vector type. typedef union {     struct { float x, y, z; };     struct { vec2_t xy; };     struct { float x_; vec2_t yz; };     float v[3]; } vec3_t; #define VEC3(x, y, z) {{x, y, z}}  ...  vec3_t vec = VEC3(1, 2, 3); // We can access the attributes in different ways. float  x    = vec.x; vec2_t xy   = vec.xy; float  z    = vec.v[2];  2. IS_DEFINED macro // As used in the linux kernel. // A macro that expands to 1 if a preprocessor value // was defined to 1, and 0 if it was not defined or // defined to an other value.  #define IS_DEFINED(macro) IS_DEFINED_(macro) #define MACROTEST_1 , #define IS_DEFINED_(value) IS_DEFINED__(MACROTEST_##value) #define IS_DEFINED__(comma) IS_DEFINED___(comma 1, 0) #define IS_DEFINED___(_, v, ...) v  // Can be used in preprocessor macros: #if IS_DEFINED(SOMETHING)     ... #endif  // Or even directly in the code. // Same effect but looks better. if (IS_DEFINED(SOMETHING)) {     ... }  3. Convenience macro for OpenGL code // Not really special, but so useful I thought // I'll put it here.  Can also be used with other // libraries (OpenAL, OpenSLES, ...) #ifdef DEBUG #  define GL(line) do {                      \        line;                                 \        assert(glGetError() == GL_NO_ERROR);  \    } while(0) #else #  define GL(line) line #endif  // Put GL around all your opengl calls: GL(glClear(GL_COLORS_MASK)); GL(pos_loc = glGetAttribLocation(prog, ""pos""));  4. Array size macro // Is there any C project that does not use it? #define ARRAY_SIZE(x) (sizeof(x) / sizeof((x)[0]))  // Can be used like this: int a[] = {0, 4, 5, 6}; int n = ARRAY_SIZE(a); // n = 4  // Warning: does not work with array arguments to functions: int func(int a[]) {     int nb = ARRAY_SIZE(a); // Would not work! }  5. Safe min macro (uses a gnu extension) #define min(a, b) ({ \       __typeof__ (a) _a = (a); \       __typeof__ (b) _b = (b); \       _a < _b ? _a : _b; \ })  6. Passing pointer to unnamed variables to function. // A func that expects a pointer to three int values. void func(const int *arg);  // Instead of using a local variable. int tmp[] = {10, 20, 30}; func(tmp);  // We can write. func( (const int[]){10, 20, 30} )  // Can be useful with a helper macro. #define VEC(...) ((const int[]){__VA_ARGS__}) func(VEC(10, 20, 30));  // (Also works with struct or any other type).  7. Named initializer, with default values // I use this one all the time when writing // video game.  One of the reason why I // don't like to use C++.  // Let say we have this struct struct obj {     const char *name;     float pos[2];     float color[4]; };  // We can write a macro like this one #define OBJ(_name, ...)             \     (struct obj) {                  \         .name = _name,              \         .color = {1, 1, 1, 1},      \         __VA_ARGS__                 \     };  // Now we can use the macro to create new objects. // This one with color defaulted to {1, 1, 1, 1}. struct obj o1 = OBJ(""o1"", .pos = {0, 10}); // This one with pos defaulted to {0, 0}. struct obj o2 = OBJ(""o2"", .color = {1, 0, 0, 1});  8. X macros // Define this once. #define SPRITES \     X(PLAYER,   ""atlas_0.png"", {0, 0, 128, 128})    \     X(ENEMY0,   ""atlas_0.png"", {128, 0, 128, 128})  \     X(ENEMY1,   ""atlas_2.png"", {0, 0, 64, 64})      \     ...  // Create an enum with all the sprites. emum {     #define X(n, ...) SPR_##n,     SPRITES     #undef X }  // Create an array with all the sprites values. struct {     const char *atlas;     int rect[4]; } sprites[] = {     #define X(n, a, r) [SPR_##n] = {a, r},     SPRITES     #undef X };  // Many other possibilities...  9. State machine helper using __LINE__ // This is a great trick. // Instead of:  int iter(int state) {     switch (state) {     case 0:         printf(""step 0\n"");         return 1;     case 1:         printf(""step 1\n"");         return 2;     case 2:         printf(""step 2\n"");         return 3;     case 3:         return -1;     } }  // We can define: #define START switch(state) { case 0: #define END return -1; } #define YIELD return __LINE__; case __LINE__:;  // And now the function can be written int iter(int state) {     START     printf(""step 0\n"");     YIELD     printf(""step 1\n"");     YIELD     printf(""step 2\n"");     END }  // It is possible to go totally wild with // this one.  Please enable JavaScript to view the comments powered by Disqus."	"null"	"null"	""	"true"
"Intermediate"	"Diving into concurrency: trying out mutexes and atomics"	"http://jvns.ca/blog/2014/12/14/fun-with-threads/"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"18"	"0"	"8"	"GitHub - jvns/fun-with-threads Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 0 Star 18 Fork 8 jvns/fun-with-threads Code Issues 0 Pull requests 0 Pulse Graphs No description or website provided. 22 commits 1 branch 0 releases Fetching contributors C 66.6% Rust 25.4% Makefile 8.0% C Rust Makefile Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Fetching latest commit… Cannot retrieve the latest commit at this time. Permalink Failed to load latest commit information. Makefile c_flamegraph.svg c_mutex_flamegraph.svg counter_race.c counter_with_atomics.c counter_with_mutex.c counter_with_spinlock.c rust_atomics_flamegraph.svg rust_counter_atomics.rs rust_counter_mutex.rs rust_mutex_flamegraph.svg Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/jvns/fun-with-threads"	""	"true"
"Intermediate"	"Introduction to OpenMP"	"https://www.youtube.com/playlist?list=PLLX-Q6B8xqZ8n8bwjGdzBJ25X2utwnoEG"	"(video)"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Introduction to OpenMP - Tim Mattson (Intel)  - YouTube Pomiń nawigację PL Prześlij Zaloguj się Szukaj OpenMP Wideo Playlisty Kanały Dyskusja Informacje Główna Na czasie Najlepsze w YouTube Muzyka Sport Gry Filmy Aktualności Na żywo Film 360° Przeglądaj kanały Zaloguj się, aby zobaczyć swoje kanały i rekomendacje. Zaloguj się Wybierz język. Zamknij Więcej informacji View this message in English Język, w którym oglądasz YouTube, to Polski. Możesz zmienić to ustawienie poniżej. Learn more You're viewing YouTube in Polish. You can change this preference below. Kolejka filmów do obejrzenia Kolejka Kolejka filmów do obejrzeniaKolejka Usuń wszystko Rozłącz Trwa wczytywanie... Kolejka filmów do obejrzenia Kolejka __count__/__total__ OpenMP ARB Website OpenMP SubskrybujSubskrybujeszAnuluj subskrypcję2 230 Trwa wczytywanie... Trwa wczytywanie... Działam... Główna Wideo Playlisty Kanały Dyskusja Informacje ► Odtwórz wszystkie Introduction to OpenMP - Tim Mattson (Intel) OpenMP 27 filmów 249 909 wyświetleń Ostatnia aktualizacja: 17.12.2013 Introduction to OpenMP - Tim Mattson (Intel) The OpenMP ARB thanks the University Program Office at Intel for permission to make this tutorial available. Slides at http://openmp.org/mp-documents/Intro_To_OpenMP_Mattson.pdf Exercise files at http://openmp.org/mp-documents/Mattson_OMP_exercises.zip Outline 􀁺 Unit 1: Getting started with OpenMP 􀂋 --Module 1: Introduction to parallel programming 􀂋 --Module 2: The boring bits: Using an OpenMP compiler (hello world) 􀂋 --Discussion 1: Hello world and how threads work 􀁺 Unit 2: The core features of OpenMP 􀂋 --Module 3: Creating Threads (the Pi program) 􀂋 --Discussion 2: The simple Pi program and why it sucks 􀂋 --Module 4: Synchronization (Pi program revisited) 􀂋 --Discussion 3: Synchronization overhead and eliminating false sharing 􀂋 --Module 5: Parallel Loops (making the Pi program simple) 􀂋 --Discussion 4: Pi program wrap-up 􀁺 Unit 3: Working with OpenMP 􀂋 --Module 6: Synchronize single masters and stuff 􀂋 --Module 7: Data environment 􀂋 --Discussion 5: Debugging OpenMP programs 􀂋 --Module 8: Skills practice ... linked lists and OpenMP 􀂋 --Discussion 6: Different ways to traverse linked lists 􀁺 Unit 4: a few advanced OpenMP topics 􀂋 --Module 9: Tasks (linked lists the easy way) 􀂋 --Discussion 7: Understanding Tasks 􀂋 --Module 10: The scary stuff ... Memory model, atomics, and flush (pairwise synch). 􀂋 --Discussion 8: The pitfalls of pairwise synchronization 􀂋 --Module 11: Threadprivate Data and how to support libraries (Pi again) 􀂋 --Discussion 9: Random number generators 􀁺 Unit 5: Recapitulation mniej Introduction to OpenMP - Tim Mattson (Intel) The OpenMP ARB thanks the University Program Office at Intel for permission to make this tutorial available. Slides at http://openmp.org/mp-documents/Intro_To_OpenMP_Mattson.pdf Exercise files at ... więcej Odtwórz wszystkie Udostępnij Trwa wczytywanie... Zapisz Zaloguj się do YouTube Zaloguj się Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 01 Introduction autor: OpenMP 4:51 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 02 part 1 Module 1 autor: OpenMP 7:55 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 02 part 2 Module 1 autor: OpenMP 7:16 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 03 Module 2 autor: OpenMP 5:17 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 04 Discussion 1 autor: OpenMP 10:10 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 05 Module 3 autor: OpenMP 11:24 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 06 Discussion 2 autor: OpenMP 10:53 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 07 Module 4 autor: OpenMP 8:45 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 08 Discussion 3 autor: OpenMP 5:20 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 09 part 1 Module 5 autor: OpenMP 10:10 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 09 part 2 Module 5 autor: OpenMP 6:57 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 10 Discussion 4 autor: OpenMP 6:33 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 11 part 1 Module 6 autor: OpenMP 10:31 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 11 part 2 Module 6 autor: OpenMP 6:09 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 11 part 3 Module 6 autor: OpenMP 7:23 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 11 part 4 Module 6 autor: OpenMP 6:12 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 12 Module 7 autor: OpenMP 14:56 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 13 Discussion 5 autor: OpenMP 8:51 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 14 Module 8 autor: OpenMP 3:31 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 15 Discussion 6 autor: OpenMP 4:00 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 16 Module 9 autor: OpenMP 10:21 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 17 Discussion 7 autor: OpenMP 6:35 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 18 Module 10 autor: OpenMP 18:01 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 19 Discussion 8 autor: OpenMP 13:10 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 20 Module 11 autor: OpenMP 7:53 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 21 Discussion 9 autor: OpenMP 11:04 Odtwórz jako następny Odtwórz teraz Introduction to OpenMP: 22 Recapitulation autor: OpenMP 11:58 Język: Polski Kraj: Polska Tryb ograniczonego dostępu Wyłączony Historia Pomoc Trwa wczytywanie... Trwa wczytywanie... Trwa wczytywanie... Informacje Centrum prasowe Prawa autorskie Twórcy Reklamy Programiści +YouTube Warunki Prywatność Zasady i bezpieczeństwo Prześlij opinię Spróbuj czegoś nowego! Trwa wczytywanie... Działam... Zaloguj się, by dodać film do listy „Do obejrzenia” Dodaj do Trwa wczytywanie playlist..."	"null"	"null"	"(video)"	"true"
"Intermediate"	"OpenMP tutorial"	"https://computing.llnl.gov/tutorials/openMP/"	"(for the OpenMP3 standard)"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"OpenMP OpenMP Author: Blaise Barney, Lawrence Livermore National Laboratory UCRL-MI-133316 Table of Contents Abstract Introduction OpenMP Programming Model OpenMP API Overview Compiling OpenMP Programs OpenMP Directives Directive Format C/C++ Directive Format Directive Scoping PARALLEL Construct Exercise 1 Work-Sharing Constructs DO / for Directive SECTIONS Directive SINGLE Directive Combined Parallel Work-Sharing Constructs TASK Construct Exercise 2 Synchronization Constructs MASTER Directive CRITICAL Directive BARRIER Directive TASKWAIT Directive ATOMIC Directive FLUSH Directive ORDERED Directive THREADPRIVATE Directive Data Scope Attribute Clauses PRIVATE Clause SHARED Clause DEFAULT Clause FIRSTPRIVATE Clause LASTPRIVATE Clause COPYIN Clause COPYPRIVATE Clause REDUCTION Clause Clauses / Directives Summary Directive Binding and Nesting Rules Run-Time Library Routines Environment Variables Thread Stack Size and Thread Binding Monitoring, Debugging and Performance Analysis Tools for OpenMP Exercise 3 References and More Information Appendix A: Run-Time Library Routines Abstract OpenMP is an Application Program Interface (API), jointly defined by a group of major computer hardware and software vendors. OpenMP provides a portable, scalable model for developers of shared memory parallel applications. The API supports C/C++ and Fortran on a wide variety of architectures. This tutorial covers most of the major features of OpenMP 3.1, including its various constructs and directives for specifying parallel regions, work sharing, synchronization and data environment. Runtime library functions and environment variables are also covered. This tutorial includes both C and Fortran example codes and a lab exercise. Level/Prerequisites: This tutorial is ideal for those who are new to parallel programming with OpenMP. A basic understanding of parallel programming in C or Fortran is required. For those who are unfamiliar with Parallel Programming in general, the material covered in EC3500: Introduction to Parallel Computing would be helpful. Introduction What is OpenMP? OpenMP Is: An Application Program Interface (API) that may be used to explicitly direct multi-threaded, shared memory parallelism. Comprised of three primary API components: Compiler Directives Runtime Library Routines Environment Variables An abbreviation for: Open Multi-Processing OpenMP Is Not: Meant for distributed memory parallel systems (by itself) Necessarily implemented identically by all vendors Guaranteed to make the most efficient use of shared memory Required to check for data dependencies, data conflicts, race conditions, deadlocks, or code sequences that cause a program to be classified as non-conforming Designed to handle parallel I/O. The programmer is responsible for synchronizing input and output. Goals of OpenMP: Standardization: Provide a standard among a variety of shared memory architectures/platforms Jointly defined and endorsed by a group of major computer hardware and software vendors Lean and Mean: Establish a simple and limited set of directives for programming shared memory machines. Significant parallelism can be implemented by using just 3 or 4 directives. This goal is becoming less meaningful with each new release, apparently. Ease of Use: Provide capability to incrementally parallelize a serial program, unlike message-passing libraries which typically require an all or nothing approach Provide the capability to implement both coarse-grain and fine-grain parallelism Portability: The API is specified for C/C++ and Fortran Public forum for API and membership Most major platforms have been implemented including Unix/Linux platforms and Windows History: In the early 90's, vendors of shared-memory machines supplied similar, directive-based, Fortran programming extensions: The user would augment a serial Fortran program with directives specifying which loops were to be parallelized The compiler would be responsible for automatically parallelizing such loops across the SMP processors Implementations were all functionally similar, but were diverging (as usual) First attempt at a standard was the draft for ANSI X3H5 in 1994. It was never adopted, largely due to waning interest as distributed memory machines became popular. However, not long after this, newer shared memory machine architectures started to become prevalent, and interest resumed. The OpenMP standard specification started in the spring of 1997, taking over where ANSI X3H5 had left off. Led by the OpenMP Architecture Review Board (ARB). Original ARB members and contributors are shown below. (Disclaimer: all partner names derived from the OpenMP web site) APR Members Endorsing Application Developers Endorsing Software Vendors Compaq / Digital Hewlett-Packard Company Intel Corporation International Business Machines (IBM) Kuck & Associates, Inc. (KAI) Silicon Graphics, Inc. Sun Microsystems, Inc. U.S. Department of Energy ASCI program ADINA R&D, Inc. ANSYS, Inc. Dash Associates Fluent, Inc. ILOG CPLEX Division Livermore Software Technology Corporation (LSTC) MECALOG SARL Oxford Molecular Group PLC The Numerical Algorithms Group Ltd.(NAG) Absoft Corporation Edinburgh Portable Compilers GENIAS Software GmBH Myrias Computer Technologies, Inc. The Portland Group, Inc. (PGI) For more news and membership information about the OpenMP ARB, visit: openmp.org/wp/about-openmp. Release History OpenMP continues to evolve - new constructs and features are added with each release. Initially, the API specifications were released separately for C and Fortran. Since 2005, they have been released together. The table below chronicles the OpenMP API release history. Date Version Oct 1997 Oct 1998 Nov 1999 Nov 2000 Mar 2002 May 2005 May 2008 Jul 2011 Jul 2013 Nov 2015 Fortran 1.0 C/C++ 1.0 Fortran 1.1 Fortran 2.0 C/C++ 2.0 OpenMP 2.5 OpenMP 3.0 OpenMP 3.1 OpenMP 4.0 OpenMP 4.5 This tutorial refers to OpenMP version 3.1. Syntax and features of newer releases are not currently covered. References: OpenMP website: openmp.org API specifications, FAQ, presentations, discussions, media releases, calendar, membership application and more... Wikipedia: en.wikipedia.org/wiki/OpenMP OpenMP Programming Model Shared Memory Model: OpenMP is designed for multi-processor/core, shared memory machines. The underlying architecture can be shared memory UMA or NUMA. Uniform Memory Access Non-Uniform Memory Access Thread Based Parallelism: OpenMP programs accomplish parallelism exclusively through the use of threads. A thread of execution is the smallest unit of processing that can be scheduled by an operating system. The idea of a subroutine that can be scheduled to run autonomously might help explain what a thread is. Threads exist within the resources of a single process. Without the process, they cease to exist. Typically, the number of threads match the number of machine processors/cores. However, the actual use of threads is up to the application. Explicit Parallelism: OpenMP is an explicit (not automatic) programming model, offering the programmer full control over parallelization. Parallelization can be as simple as taking a serial program and inserting compiler directives.... Or as complex as inserting subroutines to set multiple levels of parallelism, locks and even nested locks. Fork - Join Model: OpenMP uses the fork-join model of parallel execution: All OpenMP programs begin as a single process: the master thread. The master thread executes sequentially until the first parallel region construct is encountered. FORK: the master thread then creates a team of parallel threads. The statements in the program that are enclosed by the parallel region construct are then executed in parallel among the various team threads. JOIN: When the team threads complete the statements in the parallel region construct, they synchronize and terminate, leaving only the master thread. The number of parallel regions and the threads that comprise them are arbitrary. Compiler Directive Based: Most OpenMP parallelism is specified through the use of compiler directives which are imbedded in C/C++ or Fortran source code. Nested Parallelism: The API provides for the placement of parallel regions inside other parallel regions. Implementations may or may not support this feature. Dynamic Threads: The API provides for the runtime environment to dynamically alter the number of threads used to execute parallel regions. Intended to promote more efficient use of resources, if possible. Implementations may or may not support this feature. I/O: OpenMP specifies nothing about parallel I/O. This is particularly important if multiple threads attempt to write/read from the same file. If every thread conducts I/O to a different file, the issues are not as significant. It is entirely up to the programmer to ensure that I/O is conducted correctly within the context of a multi-threaded program. Memory Model: FLUSH Often? OpenMP provides a ""relaxed-consistency"" and ""temporary"" view of thread memory (in their words). In other words, threads can ""cache"" their data and are not required to maintain exact consistency with real memory all of the time. When it is critical that all threads view a shared variable identically, the programmer is responsible for insuring that the variable is FLUSHed by all threads as needed. More on this later... OpenMP API Overview Three Components: The OpenMP API is comprised of three distinct components: Compiler Directives (44) Runtime Library Routines (35) Environment Variables (13) The application developer decides how to employ these components. In the simplest case, only a few of them are needed. Implementations differ in their support of all API components. For example, an implementation may state that it supports nested parallelism, but the API makes it clear that may be limited to a single thread - the master thread. Not exactly what the developer might expect? Compiler Directives: Compiler directives appear as comments in your source code and are ignored by compilers unless you tell them otherwise - usually by specifying the appropriate compiler flag, as discussed in the Compiling section later. OpenMP compiler directives are used for various purposes: Spawning a parallel region Dividing blocks of code among threads Distributing loop iterations between threads Serializing sections of code Synchronization of work among threads Compiler directives have the following syntax: sentinel directive-name [clause, ...] For example: Fortran !$OMP PARALLEL DEFAULT(SHARED) PRIVATE(BETA,PI)  C/C++ #pragma omp parallel default(shared) private(beta,pi)  Compiler directives are covered in detail later. Run-time Library Routines: The OpenMP API includes an ever-growing number of run-time library routines. These routines are used for a variety of purposes: Setting and querying the number of threads Querying a thread's unique identifier (thread ID), a thread's ancestor's identifier, the thread team size Setting and querying the dynamic threads feature Querying if in a parallel region, and at what level Setting and querying nested parallelism Setting, initializing and terminating locks and nested locks Querying wall clock time and resolution For C/C++, all of the run-time library routines are actual subroutines. For Fortran, some are actually functions, and some are subroutines. For example: Fortran INTEGER FUNCTION OMP_GET_NUM_THREADS()  C/C++ #include <omp.h> int omp_get_num_threads(void)  Note that for C/C++, you usually need to include the <omp.h> header file. Fortran routines are not case sensitive, but C/C++ routines are. The run-time library routines are briefly discussed as an overview in the Run-Time Library Routines section, and in more detail in Appendix A. Environment Variables: OpenMP provides several environment variables for controlling the execution of parallel code at run-time. These environment variables can be used to control such things as: Setting the number of threads Specifying how loop interations are divided Binding threads to processors Enabling/disabling nested parallelism; setting the maximum levels of nested parallelism Enabling/disabling dynamic threads Setting thread stack size Setting thread wait policy Setting OpenMP environment variables is done the same way you set any other environment variables, and depends upon which shell you use. For example: csh/tcsh setenv OMP_NUM_THREADS 8  sh/bash export OMP_NUM_THREADS=8  OpenMP environment variables are discussed in the Environment Variables section later. Example OpenMP Code Structure:      Fortran - General Code Structure  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30     PROGRAM HELLO     INTEGER VAR1, VAR2, VAR3     Serial code           .          .          .     Beginning of parallel region. Fork a team of threads.     Specify variable scoping      !$OMP PARALLEL PRIVATE(VAR1, VAR2) SHARED(VAR3)        Parallel region executed by all threads              .       Other OpenMP directives             .       Run-time Library calls             .       All threads join master thread and disband      !$OMP END PARALLEL     Resume serial code           .          .          .     END        C / C++ - General Code Structure  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33     #include <omp.h>     main ()  {     int var1, var2, var3;     Serial code           .          .          .     Beginning of parallel region. Fork a team of threads.    Specify variable scoping      #pragma omp parallel private(var1, var2) shared(var3)       {        Parallel region executed by all threads                   .       Other OpenMP directives                  .       Run-time Library calls                  .       All threads join master thread and disband         }       Resume serial code           .          .          .     }   Compiling OpenMP Programs LC OpenMP Implementations: As of June 2016, the documentation sources for LC's default compilers claim the following OpenMP support: Compiler Version Supports Intel C/C++, Fortran 14.0.3 OpenMP 3.1 GNU C/C++, Fortran 4.4.7 OpenMP 3.0 PGI C/C++, Fortran 8.0.1 OpenMP 3.0 IBM Blue Gene C/C++ 12.1 OpenMP 3.1 IBM Blue Gene Fortran 14.1 OpenMP 3.1 IBM Blue Gene GNU C/C++, Fortran 4.4.7 OpenMP 3.0 OpenMP 4.0 Support (according to vendor and openmp.org documentation): GNU: supported in 4.9 for C/C++ and 4.9.1 for Fortran Intel: 14.0 has ""some"" support; 15.0 supports ""most features""; version 16 supported PGI: not currently available IBM BG/Q: not currently available OpenMP 4.5 Support: Not currently supported on any of LC's production cluster compilers. Supported in a beta version of the Clang compiler on the non-production rzmist and rzhasgpu clusters (June 2016). To view all LC compiler versions, use the command use -l compilers to view compiler packages by version. To view LC's default compiler versions see: https://computing.llnl.gov/?set=code&page=compilers Best place to view OpenMP support by a range of compilers: http://openmp.org/wp/openmp-compilers/. Compiling: All of LC's compilers require you to use the appropriate compiler flag to ""turn on"" OpenMP compilations. The table below shows what to use for each compiler. Compiler / Platform Compiler Flag Intel Linux Opteron/Xeon icc icpc ifort -openmp PGI Linux Opteron/Xeon pgcc pgCC pgf77 pgf90 -mp GNU Linux Opteron/Xeon IBM Blue Gene gcc g++ g77 gfortran -fopenmp IBM Blue Gene bgxlc_r, bgcc_r bgxlC_r, bgxlc++_r bgxlc89_r bgxlc99_r bgxlf_r bgxlf90_r bgxlf95_r bgxlf2003_r  *Be sure to use a thread-safe compiler - its name ends with _r -qsmp=omp Compiler Documentation: IBM BlueGene: www-01.ibm.com/software/awdtools/fortran/ and www-01.ibm.com/software/awdtools/xlcpp Intel: www.intel.com/software/products/compilers/ PGI: www.pgroup.com GNU: gnu.org All: See the relevant man pages and any files that might relate in /usr/local/docs OpenMP Directives Fortran Directives Format Format: (case insensitive) sentinel directive-name [clause ...] All Fortran OpenMP directives must begin with a sentinel. The accepted sentinels depend upon the type of Fortran source. Possible sentinels are:     !$OMP     C$OMP     *$OMP A valid OpenMP directive. Must appear after the sentinel and before any clauses. Optional. Clauses can be in any order, and repeated as necessary unless otherwise restricted. Example:  !$OMP PARALLEL DEFAULT(SHARED) PRIVATE(BETA,PI)   Fixed Form Source: !$OMP C$OMP *$OMP are accepted sentinels and must start in column 1 All Fortran fixed form rules for line length, white space, continuation and comment columns apply for the entire directive line Initial directive lines must have a space/zero in column 6. Continuation lines must have a non-space/zero in column 6. Free Form Source: !$OMP is the only accepted sentinel. Can appear in any column, but must be preceded by white space only. All Fortran free form rules for line length, white space, continuation and comment columns apply for the entire directive line Initial directive lines must have a space after the sentinel. Continuation lines must have an ampersand as the last non-blank character in a line. The following line must begin with a sentinel and then the continuation directives. General Rules: Comments can not appear on the same line as a directive Only one directive-name may be specified per directive Fortran compilers which are OpenMP enabled generally include a command line option which instructs the compiler to activate and interpret all OpenMP directives. Several Fortran OpenMP directives come in pairs and have the form shown below. The ""end"" directive is optional but advised for readability.  !$OMP  directive       [ structured block of code ]  !$OMP end  directive   OpenMP Directives C / C++ Directives Format Format: #pragma omp directive-name [clause, ...] newline Required for all OpenMP C/C++ directives. A valid OpenMP directive. Must appear after the pragma and before any clauses. Optional. Clauses can be in any order, and repeated as necessary unless otherwise restricted. Required. Precedes the structured block which is enclosed by this directive. Example:  #pragma omp parallel default(shared) private(beta,pi)   General Rules: Case sensitive Directives follow conventions of the C/C++ standards for compiler directives Only one directive-name may be specified per directive Each directive applies to at most one succeeding statement, which must be a structured block. Long directive lines can be ""continued"" on succeeding lines by escaping the newline character with a backslash (""\"") at the end of a directive line. OpenMP Directives Directive Scoping Do we do this now...or do it later? Oh well, let's get it over with early... Static (Lexical) Extent: The code textually enclosed between the beginning and the end of a structured block following a directive. The static extent of a directives does not span multiple routines or code files Orphaned Directive: An OpenMP directive that appears independently from another enclosing directive is said to be an orphaned directive. It exists outside of another directive's static (lexical) extent. Will span routines and possibly code files Dynamic Extent: The dynamic extent of a directive includes both its static (lexical) extent and the extents of its orphaned directives. Example:        PROGRAM TEST       ... !$OMP PARALLEL       ... !$OMP DO       DO I=...       ...       CALL SUB1       ...       ENDDO !$OMP END DO       ...       CALL SUB2       ... !$OMP END PARALLEL         SUBROUTINE SUB1       ... !$OMP CRITICAL       ... !$OMP END CRITICAL       END         SUBROUTINE SUB2       ... !$OMP SECTIONS       ... !$OMP END SECTIONS       ...       END  STATIC EXTENT The DO directive occurs within an enclosing parallel region ORPHANED DIRECTIVES The CRITICAL and SECTIONS directives occur outside an enclosing parallel region DYNAMIC EXTENT The CRITICAL and SECTIONS directives occur within the dynamic extent of the DO and PARALLEL directives. Why Is This Important? OpenMP specifies a number of scoping rules on how directives may associate (bind) and nest within each other Illegal and/or incorrect programs may result if the OpenMP binding and nesting rules are ignored See Directive Binding and Nesting Rules for specific details OpenMP Directives PARALLEL Region Construct Purpose: A parallel region is a block of code that will be executed by multiple threads. This is the fundamental OpenMP parallel construct. Format: Fortran  !$OMP PARALLEL [clause ...]                 IF (scalar_logical_expression)                 PRIVATE (list)                 SHARED (list)                 DEFAULT (PRIVATE | FIRSTPRIVATE | SHARED | NONE)                 FIRSTPRIVATE (list)                 REDUCTION (operator: list)                 COPYIN (list)                 NUM_THREADS (scalar-integer-expression)     block  !$OMP END PARALLEL   C/C++  #pragma omp parallel [clause ...]  newline                       if (scalar_expression)                       private (list)                       shared (list)                       default (shared | none)                       firstprivate (list)                       reduction (operator: list)                       copyin (list)                       num_threads (integer-expression)       structured_block   Notes: When a thread reaches a PARALLEL directive, it creates a team of threads and becomes the master of the team. The master is a member of that team and has thread number 0 within that team. Starting from the beginning of this parallel region, the code is duplicated and all threads will execute that code. There is an implied barrier at the end of a parallel region. Only the master thread continues execution past this point. If any thread terminates within a parallel region, all threads in the team will terminate, and the work done up until that point is undefined. How Many Threads? The number of threads in a parallel region is determined by the following factors, in order of precedence: Evaluation of the IF clause Setting of the NUM_THREADS clause Use of the omp_set_num_threads() library function Setting of the OMP_NUM_THREADS environment variable Implementation default - usually the number of CPUs on a node, though it could be dynamic (see next bullet). Threads are numbered from 0 (master thread) to N-1 Dynamic Threads: Use the omp_get_dynamic() library function to determine if dynamic threads are enabled. If supported, the two methods available for enabling dynamic threads are: The omp_set_dynamic() library routine Setting of the OMP_DYNAMIC environment variable to TRUE Nested Parallel Regions: Use the omp_get_nested() library function to determine if nested parallel regions are enabled. The two methods available for enabling nested parallel regions (if supported) are: The omp_set_nested() library routine Setting of the OMP_NESTED environment variable to TRUE If not supported, a parallel region nested within another parallel region results in the creation of a new team, consisting of one thread, by default. Clauses: IF clause: If present, it must evaluate to .TRUE. (Fortran) or non-zero (C/C++) in order for a team of threads to be created. Otherwise, the region is executed serially by the master thread. The remaining clauses are described in detail later, in the Data Scope Attribute Clauses section. Restrictions: A parallel region must be a structured block that does not span multiple routines or code files It is illegal to branch (goto) into or out of a parallel region Only a single IF clause is permitted Only a single NUM_THREADS clause is permitted A program must not depend upon the ordering of the clauses Example: Parallel Region Simple ""Hello World"" program Every thread executes all code enclosed in the parallel region OpenMP library routines are used to obtain thread identifiers and total number of threads      Fortran - Parallel Region Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22          PROGRAM HELLO          INTEGER NTHREADS, TID, OMP_GET_NUM_THREADS,       +   OMP_GET_THREAD_NUM   !     Fork a team of threads with each thread having a private TID variable  !$OMP PARALLEL PRIVATE(TID)   !     Obtain and print thread id        TID = OMP_GET_THREAD_NUM()        PRINT *, 'Hello World from thread = ', TID   !     Only master thread does this        IF (TID .EQ. 0) THEN          NTHREADS = OMP_GET_NUM_THREADS()          PRINT *, 'Number of threads = ', NTHREADS        END IF   !     All threads join master thread and disband  !$OMP END PARALLEL          END        C / C++ - Parallel Region Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24   #include <omp.h>   main(int argc, char *argv[]) {   int nthreads, tid;   /* Fork a team of threads with each thread having a private tid variable */  #pragma omp parallel private(tid)    {     /* Obtain and print thread id */    tid = omp_get_thread_num();    printf(""Hello World from thread = %d\n"", tid);     /* Only master thread does this */    if (tid == 0)       {      nthreads = omp_get_num_threads();      printf(""Number of threads = %d\n"", nthreads);      }     }  /* All threads join master thread and terminate */   }   OpenMP Exercise 1 Getting Started Overview: Login to the workshop cluster using your workshop username and OTP token Copy the exercise files to your home directory Familiarize yourself with LC's OpenMP environment Write a simple ""Hello World"" OpenMP program Successfully compile your program Successfully run your program Modify the number of threads used to run your program GO TO THE EXERCISE HERE Approx. 20 minutes OpenMP Directives Work-Sharing Constructs A work-sharing construct divides the execution of the enclosed code region among the members of the team that encounter it. Work-sharing constructs do not launch new threads There is no implied barrier upon entry to a work-sharing construct, however there is an implied barrier at the end of a work sharing construct. Types of Work-Sharing Constructs: NOTE: The Fortran workshare construct is not shown here. DO / for - shares iterations of a loop across the team. Represents a type of ""data parallelism"". SECTIONS - breaks work into separate, discrete sections. Each section is executed by a thread. Can be used to implement a type of ""functional parallelism"". SINGLE - serializes a section of code Restrictions: A work-sharing construct must be enclosed dynamically within a parallel region in order for the directive to execute in parallel. Work-sharing constructs must be encountered by all members of a team or none at all Successive work-sharing constructs must be encountered in the same order by all members of a team OpenMP Directives Work-Sharing Constructs DO / for Directive Purpose: The DO / for directive specifies that the iterations of the loop immediately following it must be executed in parallel by the team. This assumes a parallel region has already been initiated, otherwise it executes in serial on a single processor. Format: Fortran  !$OMP DO [clause ...]           SCHEDULE (type [,chunk])           ORDERED           PRIVATE (list)           FIRSTPRIVATE (list)           LASTPRIVATE (list)           SHARED (list)           REDUCTION (operator | intrinsic : list)           COLLAPSE (n)      do_loop  !$OMP END DO  [ NOWAIT ]   C/C++  #pragma omp for [clause ...]  newline                  schedule (type [,chunk])                  ordered                 private (list)                  firstprivate (list)                  lastprivate (list)                  shared (list)                  reduction (operator: list)                  collapse (n)                  nowait      for_loop   Clauses: SCHEDULE: Describes how iterations of the loop are divided among the threads in the team. The default schedule is implementation dependent. For a discussion on how one type of scheduling may be more optimal than others, see http://openmp.org/forum/viewtopic.php?f=3&t=83. STATIC Loop iterations are divided into pieces of size chunk and then statically assigned to threads. If chunk is not specified, the iterations are evenly (if possible) divided contiguously among the threads. DYNAMIC Loop iterations are divided into pieces of size chunk, and dynamically scheduled among the threads; when a thread finishes one chunk, it is dynamically assigned another. The default chunk size is 1. GUIDED Iterations are dynamically assigned to threads in blocks as threads request them until no blocks remain to be assigned. Similar to DYNAMIC except that the block size decreases each time a parcel of work is given to a thread. The size of the initial block is proportional to: number_of_iterations / number_of_threads Subsequent blocks are proportional to number_of_iterations_remaining / number_of_threads The chunk parameter defines the minimum block size. The default chunk size is 1. RUNTIME The scheduling decision is deferred until runtime by the environment variable OMP_SCHEDULE. It is illegal to specify a chunk size for this clause. AUTO The scheduling decision is delegated to the compiler and/or runtime system. NO WAIT / nowait: If specified, then threads do not synchronize at the end of the parallel loop. ORDERED: Specifies that the iterations of the loop must be executed as they would be in a serial program. COLLAPSE: Specifies how many loops in a nested loop should be collapsed into one large iteration space and divided according to the schedule clause. The sequential execution of the iterations in all associated loops determines the order of the iterations in the collapsed iteration space. Other clauses are described in detail later, in the Data Scope Attribute Clauses section. Restrictions: The DO loop can not be a DO WHILE loop, or a loop without loop control. Also, the loop iteration variable must be an integer and the loop control parameters must be the same for all threads. Program correctness must not depend upon which thread executes a particular iteration. It is illegal to branch (goto) out of a loop associated with a DO/for directive. The chunk size must be specified as a loop invarient integer expression, as there is no synchronization during its evaluation by different threads. ORDERED, COLLAPSE and SCHEDULE clauses may appear once each. See the OpenMP specification document for additional restrictions. Example: DO / for Directive Simple vector-add program Arrays A, B, C, and variable N will be shared by all threads. Variable I will be private to each thread; each thread will have its own unique copy. The iterations of the loop will be distributed dynamically in CHUNK sized pieces. Threads will not synchronize upon completing their individual pieces of work (NOWAIT).      Fortran - DO Directive Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25         PROGRAM VEC_ADD_DO         INTEGER N, CHUNKSIZE, CHUNK, I        PARAMETER (N=1000)         PARAMETER (CHUNKSIZE=100)         REAL A(N), B(N), C(N)   !     Some initializations        DO I = 1, N          A(I) = I * 1.0          B(I) = A(I)        ENDDO        CHUNK = CHUNKSIZE           !$OMP PARALLEL SHARED(A,B,C,CHUNK) PRIVATE(I)   !$OMP DO SCHEDULE(DYNAMIC,CHUNK)        DO I = 1, N           C(I) = A(I) + B(I)        ENDDO  !$OMP END DO NOWAIT   !$OMP END PARALLEL         END        C / C++ - for Directive Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24   #include <omp.h>  #define N 1000  #define CHUNKSIZE 100   main(int argc, char *argv[]) {   int i, chunk;  float a[N], b[N], c[N];   /* Some initializations */  for (i=0; i < N; i++)    a[i] = b[i] = i * 1.0;  chunk = CHUNKSIZE;   #pragma omp parallel shared(a,b,c,chunk) private(i)    {     #pragma omp for schedule(dynamic,chunk) nowait    for (i=0; i < N; i++)      c[i] = a[i] + b[i];     }   /* end of parallel region */   }   OpenMP Directives Work-Sharing Constructs SECTIONS Directive Purpose: The SECTIONS directive is a non-iterative work-sharing construct. It specifies that the enclosed section(s) of code are to be divided among the threads in the team. Independent SECTION directives are nested within a SECTIONS directive. Each SECTION is executed once by a thread in the team. Different sections may be executed by different threads. It is possible for a thread to execute more than one section if it is quick enough and the implementation permits such. Format: Fortran  !$OMP SECTIONS [clause ...]                 PRIVATE (list)                 FIRSTPRIVATE (list)                 LASTPRIVATE (list)                 REDUCTION (operator | intrinsic : list)   !$OMP  SECTION      block  !$OMP  SECTION       block   !$OMP END SECTIONS  [ NOWAIT ]   C/C++  #pragma omp sections [clause ...]  newline                       private (list)                       firstprivate (list)                       lastprivate (list)                       reduction (operator: list)                       nowait   {    #pragma omp section   newline        structured_block    #pragma omp section   newline        structured_block    }  Clauses: There is an implied barrier at the end of a SECTIONS directive, unless the NOWAIT/nowait clause is used. Clauses are described in detail later, in the Data Scope Attribute Clauses section. Questions: What happens if the number of threads and the number of SECTIONs are different? More threads than SECTIONs? Less threads than SECTIONs?   Which thread executes which SECTION? Restrictions: It is illegal to branch (goto) into or out of section blocks. SECTION directives must occur within the lexical extent of an enclosing SECTIONS directive (no orphan SECTIONs). Example: SECTIONS Directive Simple program demonstrating that different blocks of work will be done by different threads.      Fortran - SECTIONS Directive Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31         PROGRAM VEC_ADD_SECTIONS         INTEGER N, I        PARAMETER (N=1000)        REAL A(N), B(N), C(N), D(N)   !     Some initializations        DO I = 1, N          A(I) = I * 1.5          B(I) = I + 22.35        ENDDO   !$OMP PARALLEL SHARED(A,B,C,D), PRIVATE(I)   !$OMP SECTIONS   !$OMP SECTION        DO I = 1, N           C(I) = A(I) + B(I)        ENDDO   !$OMP SECTION        DO I = 1, N           D(I) = A(I) * B(I)        ENDDO   !$OMP END SECTIONS NOWAIT   !$OMP END PARALLEL         END        C / C++ - sections Directive Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33   #include <omp.h>  #define N 1000   main(int argc, char *argv[]) {   int i;  float a[N], b[N], c[N], d[N];   /* Some initializations */  for (i=0; i < N; i++) {    a[i] = i * 1.5;    b[i] = i + 22.35;    }   #pragma omp parallel shared(a,b,c,d) private(i)    {     #pragma omp sections nowait      {       #pragma omp section      for (i=0; i < N; i++)        c[i] = a[i] + b[i];       #pragma omp section      for (i=0; i < N; i++)        d[i] = a[i] * b[i];       }  /* end of sections */     }  /* end of parallel region */   }   OpenMP Directives Work-Sharing Constructs SINGLE Directive Purpose: The SINGLE directive specifies that the enclosed code is to be executed by only one thread in the team. May be useful when dealing with sections of code that are not thread safe (such as I/O) Format: Fortran  !$OMP SINGLE [clause ...]               PRIVATE (list)               FIRSTPRIVATE (list)      block  !$OMP END SINGLE [ NOWAIT ]   C/C++  #pragma omp single [clause ...]  newline                     private (list)                     firstprivate (list)                     nowait       structured_block   Clauses: Threads in the team that do not execute the SINGLE directive, wait at the end of the enclosed code block, unless a NOWAIT/nowait clause is specified. Clauses are described in detail later, in the Data Scope Attribute Clauses section. Restrictions: It is illegal to branch into or out of a SINGLE block. OpenMP Directives Combined Parallel Work-Sharing Constructs OpenMP provides three directives that are merely conveniences: PARALLEL DO / parallel for PARALLEL SECTIONS PARALLEL WORKSHARE (fortran only) For the most part, these directives behave identically to an individual PARALLEL directive being immediately followed by a separate work-sharing directive. Most of the rules, clauses and restrictions that apply to both directives are in effect. See the OpenMP API for details. An example using the PARALLEL DO / parallel for combined directive is shown below.      Fortran - PARALLEL DO Directive Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25         PROGRAM VECTOR_ADD         INTEGER N, I, CHUNKSIZE, CHUNK        PARAMETER (N=1000)         PARAMETER (CHUNKSIZE=100)         REAL A(N), B(N), C(N)   !     Some initializations        DO I = 1, N          A(I) = I * 1.0          B(I) = A(I)        ENDDO        CHUNK = CHUNKSIZE                !$OMP PARALLEL DO  !$OMP& SHARED(A,B,C,CHUNK) PRIVATE(I)   !$OMP& SCHEDULE(STATIC,CHUNK)         DO I = 1, N           C(I) = A(I) + B(I)        ENDDO   !$OMP END PARALLEL DO         END        C / C++ - parallel for Directive Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20   #include <omp.h>  #define N       1000  #define CHUNKSIZE   100   main(int argc, char *argv[]) {   int i, chunk;  float a[N], b[N], c[N];   /* Some initializations */  for (i=0; i < N; i++)    a[i] = b[i] = i * 1.0;  chunk = CHUNKSIZE;   #pragma omp parallel for \    shared(a,b,c,chunk) private(i) \    schedule(static,chunk)    for (i=0; i < n; i++)      c[i] = a[i] + b[i];  }   OpenMP Directives TASK Construct Purpose: The TASK construct defines an explicit task, which may be executed by the encountering thread, or deferred for execution by any other thread in the team. The data environment of the task is determined by the data sharing attribute clauses. Task execution is subject to task scheduling - see the OpenMP 3.1 specification document for details. Also see the OpenMP 3.1 documentation for the associated taskyield and taskwait directives. Format: Fortran  !$OMP TASK [clause ...]               IF (scalar logical expression)               FINAL (scalar logical expression)               UNTIED              DEFAULT (PRIVATE | FIRSTPRIVATE | SHARED | NONE)              MERGEABLE              PRIVATE (list)               FIRSTPRIVATE (list)               SHARED (list)      block  !$OMP END TASK   C/C++  #pragma omp task [clause ...]  newline                     if (scalar expression)                     final (scalar expression)                     untied                    default (shared | none)                    mergeable                    private (list)                     firstprivate (list)                     shared (list)        structured_block   Clauses and Restrictions: Please consult the OpenMP 3.1 specifications document for details. OpenMP Exercise 2 Work-Sharing Constructs Overview: Login to the LC workshop cluster, if you are not already logged in Work-Sharing DO/for construct examples: review, compile and run Work-Sharing SECTIONS construct example: review, compile and run GO TO THE EXERCISE HERE Approx. 20 minutes OpenMP Directives Synchronization Constructs Consider a simple example where two threads on two different processors are both trying to increment a variable x at the same time (assume x is initially 0): THREAD 1:  increment(x) {     x = x + 1; }  THREAD 1:  10  LOAD A, (x address) 20  ADD A, 1 30  STORE A, (x address)  THREAD 2:  increment(x) {     x = x + 1; }  THREAD 2:  10  LOAD A, (x address) 20  ADD A, 1 30  STORE A, (x address)  One possible execution sequence: Thread 1 loads the value of x into register A. Thread 2 loads the value of x into register A. Thread 1 adds 1 to register A Thread 2 adds 1 to register A Thread 1 stores register A at location x Thread 2 stores register A at location x The resultant value of x will be 1, not 2 as it should be. To avoid a situation like this, the incrementing of x must be synchronized between the two threads to ensure that the correct result is produced. OpenMP provides a variety of Synchronization Constructs that control how the execution of each thread proceeds relative to other team threads. OpenMP Directives Synchronization Constructs MASTER Directive Purpose: The MASTER directive specifies a region that is to be executed only by the master thread of the team. All other threads on the team skip this section of code There is no implied barrier associated with this directive Format: Fortran  !$OMP MASTER     block  !$OMP END MASTER   C/C++  #pragma omp master  newline     structured_block   Restrictions: It is illegal to branch into or out of MASTER block. OpenMP Directives Synchronization Constructs CRITICAL Directive Purpose: The CRITICAL directive specifies a region of code that must be executed by only one thread at a time. Format: Fortran  !$OMP CRITICAL [ name ]     block  !$OMP END CRITICAL [ name ]   C/C++  #pragma omp critical [ name ]  newline     structured_block   Notes: If a thread is currently executing inside a CRITICAL region and another thread reaches that CRITICAL region and attempts to execute it, it will block until the first thread exits that CRITICAL region. The optional name enables multiple different CRITICAL regions to exist: Names act as global identifiers. Different CRITICAL regions with the same name are treated as the same region. All CRITICAL sections which are unnamed, are treated as the same section. Restrictions: It is illegal to branch into or out of a CRITICAL block. Fortran only: The names of critical constructs are global entities of the program. If a name conflicts with any other entity, the behavior of the program is unspecified. Example: CRITICAL Construct All threads in the team will attempt to execute in parallel, however, because of the CRITICAL construct surrounding the increment of x, only one thread will be able to read/increment/write x at any time      Fortran - CRITICAL Directive Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14         PROGRAM CRITICAL         INTEGER X        X = 0   !$OMP PARALLEL SHARED(X)    !$OMP CRITICAL         X = X + 1  !$OMP END CRITICAL    !$OMP END PARALLEL          END        C / C++ - critical Directive Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16   #include <omp.h>   main(int argc, char *argv[]) {   int x;  x = 0;   #pragma omp parallel shared(x)     {     #pragma omp critical     x = x + 1;     }  /* end of parallel region */   }   OpenMP Directives Synchronization Constructs BARRIER Directive Purpose: The BARRIER directive synchronizes all threads in the team. When a BARRIER directive is reached, a thread will wait at that point until all other threads have reached that barrier. All threads then resume executing in parallel the code that follows the barrier. Format: Fortran  !$OMP BARRIER   C/C++  #pragma omp barrier  newline   Restrictions: All threads in a team (or none) must execute the BARRIER region. The sequence of work-sharing regions and barrier regions encountered must be the same for every thread in a team. OpenMP Directives Synchronization Constructs TASKWAIT Directive Purpose: OpenMP 3.1 feature The TASKWAIT construct specifies a wait on the completion of child tasks generated since the beginning of the current task. Format: Fortran  !$OMP TASKWAIT   C/C++  #pragma omp taskwait  newline   Restrictions: Because the taskwait construct does not have a C language statement as part of its syntax, there are some restrictions on its placement within a program. The taskwait directive may be placed only at a point where a base language statement is allowed. The taskwait directive may not be used in place of the statement following an if, while, do, switch, or label. See the OpenMP 3.1 specifications document for details. OpenMP Directives Synchronization Constructs ATOMIC Directive Purpose: The ATOMIC directive specifies that a specific memory location must be updated atomically, rather than letting multiple threads attempt to write to it. In essence, this directive provides a mini-CRITICAL section. Format: Fortran  !$OMP ATOMIC     statement_expression   C/C++  #pragma omp atomic  newline     statement_expression   Restrictions: The directive applies only to a single, immediately following statement An atomic statement must follow a specific syntax. See the most recent OpenMP specs for this. OpenMP Directives Synchronization Constructs FLUSH Directive Purpose: The FLUSH directive identifies a synchronization point at which the implementation must provide a consistent view of memory. Thread-visible variables are written back to memory at this point. There is a fair amount of discussion on this directive within OpenMP circles that you may wish to consult for more information. Some of it is hard to understand? Per the API: If the intersection of the flush-sets of two flushes performed by two different threads is non-empty, then the two flushes must be completed as if in some sequential order, seen by all threads. Say what? To quote from the openmp.org FAQ: Q17: Is the !$omp flush directive necessary on a cache coherent system? A17: Yes the flush directive is necessary. Look in the OpenMP specifications for examples of it's uses. The directive is necessary to instruct the compiler that the variable must be written to/read from the memory system, i.e. that the variable can not be kept in a local CPU register over the flush ""statement"" in your code. Cache coherency makes certain that if one CPU executes a read or write instruction from/to memory, then all other CPUs in the system will get the same value from that memory address when they access it. All caches will show a coherent value. However, in the OpenMP standard there must be a way to instruct the compiler to actually insert the read/write machine instruction and not postpone it. Keeping a variable in a register in a loop is very common when producing efficient machine language code for a loop. Also see the most recent OpenMP specs for details. Format: Fortran  !$OMP FLUSH  (list)   C/C++  #pragma omp flush (list)  newline   Notes: The optional list contains a list of named variables that will be flushed in order to avoid flushing all variables. For pointers in the list, note that the pointer itself is flushed, not the object it points to. Implementations must ensure any prior modifications to thread-visible variables are visible to all threads after this point; ie. compilers must restore values from registers to memory, hardware might need to flush write buffers, etc The FLUSH directive is implied for the directives shown in the table below. The directive is not implied if a NOWAIT clause is present. Fortran C / C++ BARRIER END PARALLEL CRITICAL and END CRITICAL END DO END SECTIONS END SINGLE ORDERED and END ORDERED barrier parallel - upon entry and exit critical - upon entry and exit ordered - upon entry and exit for - upon exit sections - upon exit single - upon exit OpenMP Directives Synchronization Constructs ORDERED Directive Purpose: The ORDERED directive specifies that iterations of the enclosed loop will be executed in the same order as if they were executed on a serial processor. Threads will need to wait before executing their chunk of iterations if previous iterations haven't completed yet. Used within a DO / for loop with an ORDERED clause The ORDERED directive provides a way to ""fine tune"" where ordering is to be applied within a loop. Otherwise, it is not required. Format: Fortran  !$OMP DO ORDERED [clauses...]    (loop region)  !$OMP ORDERED     (block)  !$OMP END ORDERED     (end of loop region) !$OMP END DO   C/C++  #pragma omp for ordered [clauses...]    (loop region)  #pragma omp ordered  newline     structured_block     (endo of loop region)  Restrictions: An ORDERED directive can only appear in the dynamic extent of the following directives: DO or PARALLEL DO (Fortran) for or parallel for (C/C++) Only one thread is allowed in an ordered section at any time It is illegal to branch into or out of an ORDERED block. An iteration of a loop must not execute the same ORDERED directive more than once, and it must not execute more than one ORDERED directive. A loop which contains an ORDERED directive, must be a loop with an ORDERED clause. OpenMP Directives THREADPRIVATE Directive Purpose: The THREADPRIVATE directive is used to make global file scope variables (C/C++) or common blocks (Fortran) local and persistent to a thread through the execution of multiple parallel regions. Format: Fortran  !$OMP THREADPRIVATE (/cb/, ...)  cb is the name of a common block   C/C++  #pragma omp threadprivate (list)   Notes: The directive must appear after the declaration of listed variables/common blocks. Each thread then gets its own copy of the variable/common block, so data written by one thread is not visible to other threads. For example:      Fortran - THREADPRIVATE Directive Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31         PROGRAM THREADPRIV          INTEGER A, B, I, TID, OMP_GET_THREAD_NUM        REAL*4 X        COMMON /C1/ A    !$OMP THREADPRIVATE(/C1/, X)     !     Explicitly turn off dynamic threads        CALL OMP_SET_DYNAMIC(.FALSE.)          PRINT *, '1st Parallel Region:'  !$OMP PARALLEL PRIVATE(B, TID)         TID = OMP_GET_THREAD_NUM()        A = TID        B = TID        X = 1.1 * TID + 1.0        PRINT *, 'Thread',TID,':   A,B,X=',A,B,X  !$OMP END PARALLEL           PRINT *, '************************************'        PRINT *, 'Master thread doing serial work here'        PRINT *, '************************************'          PRINT *, '2nd Parallel Region: '  !$OMP PARALLEL PRIVATE(TID)         TID = OMP_GET_THREAD_NUM()        PRINT *, 'Thread',TID,':   A,B,X=',A,B,X  !$OMP END PARALLEL           END     Output:   1st Parallel Region:  Thread 0 :   A,B,X= 0 0 1.000000000  Thread 1 :   A,B,X= 1 1 2.099999905  Thread 3 :   A,B,X= 3 3 4.300000191  Thread 2 :   A,B,X= 2 2 3.200000048  ************************************  Master thread doing serial work here  ************************************  2nd Parallel Region:   Thread 0 :   A,B,X= 0 0 1.000000000  Thread 2 :   A,B,X= 2 0 3.200000048  Thread 3 :   A,B,X= 3 0 4.300000191  Thread 1 :   A,B,X= 1 0 2.099999905        C/C++ - threadprivate Directive Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34   #include <omp.h>     int  a, b, i, tid;  float x;    #pragma omp threadprivate(a, x)    main(int argc, char *argv[]) {      /* Explicitly turn off dynamic threads */    omp_set_dynamic(0);      printf(""1st Parallel Region:\n"");  #pragma omp parallel private(b,tid)    {    tid = omp_get_thread_num();    a = tid;    b = tid;    x = 1.1 * tid +1.0;    printf(""Thread %d:   a,b,x= %d %d %f\n"",tid,a,b,x);    }  /* end of parallel region */      printf(""************************************\n"");    printf(""Master thread doing serial work here\n"");    printf(""************************************\n"");      printf(""2nd Parallel Region:\n"");  #pragma omp parallel private(tid)    {    tid = omp_get_thread_num();    printf(""Thread %d:   a,b,x= %d %d %f\n"",tid,a,b,x);    }  /* end of parallel region */   }     Output:   1st Parallel Region:  Thread 0:   a,b,x= 0 0 1.000000  Thread 2:   a,b,x= 2 2 3.200000  Thread 3:   a,b,x= 3 3 4.300000  Thread 1:   a,b,x= 1 1 2.100000  ************************************  Master thread doing serial work here  ************************************  2nd Parallel Region:  Thread 0:   a,b,x= 0 0 1.000000  Thread 3:   a,b,x= 3 0 4.300000  Thread 1:   a,b,x= 1 0 2.100000  Thread 2:   a,b,x= 2 0 3.200000   On first entry to a parallel region, data in THREADPRIVATE variables and common blocks should be assumed undefined, unless a COPYIN clause is specified in the PARALLEL directive THREADPRIVATE variables differ from PRIVATE variables (discussed later) because they are able to persist between different parallel regions of a code. Restrictions: Data in THREADPRIVATE objects is guaranteed to persist only if the dynamic threads mechanism is ""turned off"" and the number of threads in different parallel regions remains constant. The default setting of dynamic threads is undefined. The THREADPRIVATE directive must appear after every declaration of a thread private variable/common block. Fortran: only named common blocks can be made THREADPRIVATE. OpenMP Directives Data Scope Attribute Clauses Also called Data-sharing Attribute Clauses An important consideration for OpenMP programming is the understanding and use of data scoping Because OpenMP is based upon the shared memory programming model, most variables are shared by default Global variables include: Fortran: COMMON blocks, SAVE variables, MODULE variables C: File scope variables, static Private variables include: Loop index variables Stack variables in subroutines called from parallel regions Fortran: Automatic variables within a statement block The OpenMP Data Scope Attribute Clauses are used to explicitly define how variables should be scoped. They include: PRIVATE FIRSTPRIVATE LASTPRIVATE SHARED DEFAULT REDUCTION COPYIN Data Scope Attribute Clauses are used in conjunction with several directives (PARALLEL, DO/for, and SECTIONS) to control the scoping of enclosed variables. These constructs provide the ability to control the data environment during execution of parallel constructs. They define how and which data variables in the serial section of the program are transferred to the parallel regions of the program (and back) They define which variables will be visible to all threads in the parallel regions and which variables will be privately allocated to all threads. Data Scope Attribute Clauses are effective only within their lexical/static extent. Important: Please consult the latest OpenMP specs for important details and discussion on this topic. A Clauses / Directives Summary Table is provided for convenience. PRIVATE Clause Purpose: The PRIVATE clause declares variables in its list to be private to each thread. Format: Fortran  PRIVATE (list)   C/C++  private (list)   Notes: PRIVATE variables behave as follows: A new object of the same type is declared once for each thread in the team All references to the original object are replaced with references to the new object Variables declared PRIVATE should be assumed to be uninitialized for each thread Comparison between PRIVATE and THREADPRIVATE:   PRIVATE THREADPRIVATE Data Item C/C++: variable Fortran: variable or common block C/C++: variable Fortran: common block Where Declared At start of region or work-sharing group In declarations of each routine using block or global file scope Persistent? No Yes Extent Lexical only - unless passed as an argument to subroutine Dynamic Initialized Use FIRSTPRIVATE Use COPYIN SHARED Clause Purpose: The SHARED clause declares variables in its list to be shared among all threads in the team. Format: Fortran  SHARED (list)   C/C++  shared (list)   Notes: A shared variable exists in only one memory location and all threads can read or write to that address It is the programmer's responsibility to ensure that multiple threads properly access SHARED variables (such as via CRITICAL sections) DEFAULT Clause Purpose: The DEFAULT clause allows the user to specify a default scope for all variables in the lexical extent of any parallel region. Format: Fortran  DEFAULT (PRIVATE | FIRSTPRIVATE | SHARED | NONE)   C/C++  default (shared | none)   Notes: Specific variables can be exempted from the default using the PRIVATE, SHARED, FIRSTPRIVATE, LASTPRIVATE, and REDUCTION clauses The C/C++ OpenMP specification does not include private or firstprivate as a possible default. However, actual implementations may provide this option. Using NONE as a default requires that the programmer explicitly scope all variables. Restrictions: Only one DEFAULT clause can be specified on a PARALLEL directive FIRSTPRIVATE Clause Purpose: The FIRSTPRIVATE clause combines the behavior of the PRIVATE clause with automatic initialization of the variables in its list. Format: Fortran  FIRSTPRIVATE (list)   C/C++  firstprivate (list)   Notes: Listed variables are initialized according to the value of their original objects prior to entry into the parallel or work-sharing construct. LASTPRIVATE Clause Purpose: The LASTPRIVATE clause combines the behavior of the PRIVATE clause with a copy from the last loop iteration or section to the original variable object. Format: Fortran  LASTPRIVATE (list)   C/C++  lastprivate (list)   Notes: The value copied back into the original variable object is obtained from the last (sequentially) iteration or section of the enclosing construct. For example, the team member which executes the final iteration for a DO section, or the team member which does the last SECTION of a SECTIONS context performs the copy with its own values COPYIN Clause Purpose: The COPYIN clause provides a means for assigning the same value to THREADPRIVATE variables for all threads in the team. Format: Fortran  COPYIN (list)   C/C++  copyin  (list)   Notes: List contains the names of variables to copy. In Fortran, the list can contain both the names of common blocks and named variables. The master thread variable is used as the copy source. The team threads are initialized with its value upon entry into the parallel construct. COPYPRIVATE Clause Purpose: The COPYPRIVATE clause can be used to broadcast values acquired by a single thread directly to all instances of the private variables in the other threads. Associated with the SINGLE directive See the most recent OpenMP specs document for additional discussion and examples. Format: Fortran  COPYPRIVATE (list)   C/C++  copyprivate  (list)   REDUCTION Clause Purpose: The REDUCTION clause performs a reduction on the variables that appear in its list. A private copy for each list variable is created for each thread. At the end of the reduction, the reduction variable is applied to all private copies of the shared variable, and the final result is written to the global shared variable. Format: Fortran  REDUCTION (operator|intrinsic: list)   C/C++  reduction (operator: list)  Example: REDUCTION - Vector Dot Product: Iterations of the parallel loop will be distributed in equal sized blocks to each thread in the team (SCHEDULE STATIC) At the end of the parallel loop construct, all threads will add their values of ""result"" to update the master thread's global copy.      Fortran - REDUCTION Clause Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28          PROGRAM DOT_PRODUCT          INTEGER N, CHUNKSIZE, CHUNK, I         PARAMETER (N=100)         PARAMETER (CHUNKSIZE=10)         REAL A(N), B(N), RESULT   !      Some initializations         DO I = 1, N           A(I) = I * 1.0           B(I) = I * 2.0         ENDDO         RESULT= 0.0         CHUNK = CHUNKSIZE   !$OMP  PARALLEL DO  !$OMP& DEFAULT(SHARED) PRIVATE(I)  !$OMP& SCHEDULE(STATIC,CHUNK)  !$OMP& REDUCTION(+:RESULT)          DO I = 1, N           RESULT = RESULT + (A(I) * B(I))         ENDDO   !$OMP  END PARALLEL DO          PRINT *, 'Final Result= ', RESULT         END        C / C++ - reduction Clause Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27   #include <omp.h>   main(int argc, char *argv[])  {   int   i, n, chunk;  float a[100], b[100], result;   /* Some initializations */  n = 100;  chunk = 10;  result = 0.0;  for (i=0; i < n; i++) {    a[i] = i * 1.0;    b[i] = i * 2.0;    }   #pragma omp parallel for      \      default(shared) private(i)  \      schedule(static,chunk)      \      reduction(+:result)       for (i=0; i < n; i++)      result = result + (a[i] * b[i]);   printf(""Final result= %f\n"",result);   }   Restrictions: Variables in the list must be named scalar variables. They can not be array or structure type variables. They must also be declared SHARED in the enclosing context. Reduction operations may not be associative for real numbers. The REDUCTION clause is intended to be used on a region or work-sharing construct in which the reduction variable is used only in statements which have one of following forms: Fortran C / C++ x = x operator expr x = expr operator x (except subtraction) x = intrinsic(x, expr) x = intrinsic(expr, x) x = x op expr x = expr op x (except subtraction) x binop = expr x++ ++x x-- --x x is a scalar variable in the list expr is a scalar expression that does not reference x intrinsic is one of MAX, MIN, IAND, IOR, IEOR operator is one of +, *, -, .AND., .OR., .EQV., .NEQV. x is a scalar variable in the list expr is a scalar expression that does not reference x op is not overloaded, and is one of +, *, -, /, &, ^, |, &&, || binop is not overloaded, and is one of +, *, -, /, &, ^, | OpenMP Directives Clauses / Directives Summary The table below summarizes which clauses are accepted by which OpenMP directives. Clause Directive PARALLEL DO/for SECTIONS SINGLE PARALLEL DO/for PARALLEL SECTIONS IF       PRIVATE SHARED     DEFAULT       FIRSTPRIVATE LASTPRIVATE     REDUCTION   COPYIN       COPYPRIVATE           SCHEDULE         ORDERED         NOWAIT       The following OpenMP directives do not accept clauses: MASTER CRITICAL BARRIER ATOMIC FLUSH ORDERED THREADPRIVATE Implementations may (and do) differ from the standard in which clauses are supported by each directive. OpenMP Directives Directive Binding and Nesting Rules This section is provided mainly as a quick reference on rules which govern OpenMP directives and binding. Users should consult their implementation documentation and the OpenMP standard for other rules and restrictions. Unless indicated otherwise, rules apply to both Fortran and C/C++ OpenMP implementations. Note: the Fortran API also defines a number of Data Environment rules. Those have not been reproduced here. Directive Binding: The DO/for, SECTIONS, SINGLE, MASTER and BARRIER directives bind to the dynamically enclosing PARALLEL, if one exists. If no parallel region is currently being executed, the directives have no effect. The ORDERED directive binds to the dynamically enclosing DO/for. The ATOMIC directive enforces exclusive access with respect to ATOMIC directives in all threads, not just the current team. The CRITICAL directive enforces exclusive access with respect to CRITICAL directives in all threads, not just the current team. A directive can never bind to any directive outside the closest enclosing PARALLEL. Directive Nesting: A worksharing region may not be closely nested inside a worksharing, explicit task, critical, ordered, atomic, or master region. A barrier region may not be closely nested inside a worksharing, explicit task, critical, ordered, atomic, or master region. A master region may not be closely nested inside a worksharing, atomic, or explicit task region. An ordered region may not be closely nested inside a critical, atomic, or explicit task region. An ordered region must be closely nested inside a loop region (or parallel loop region) with an ordered clause. A critical region may not be nested (closely or otherwise) inside a critical region with the same name. Note that this restriction is not sufficient to prevent deadlock. parallel, flush, critical, atomic, taskyield, and explicit task regions may not be closely nested inside an atomic region. Run-Time Library Routines Overview: The OpenMP API includes an ever-growing number of run-time library routines. These routines are used for a variety of purposes as shown in the table below: Routine Purpose OMP_SET_NUM_THREADS Sets the number of threads that will be used in the next parallel region OMP_GET_NUM_THREADS Returns the number of threads that are currently in the team executing the parallel region from which it is called OMP_GET_MAX_THREADS Returns the maximum value that can be returned by a call to the OMP_GET_NUM_THREADS function OMP_GET_THREAD_NUM Returns the thread number of the thread, within the team, making this call. OMP_GET_THREAD_LIMIT Returns the maximum number of OpenMP threads available to a program OMP_GET_NUM_PROCS Returns the number of processors that are available to the program OMP_IN_PARALLEL Used to determine if the section of code which is executing is parallel or not OMP_SET_DYNAMIC Enables or disables dynamic adjustment (by the run time system) of the number of threads available for execution of parallel regions OMP_GET_DYNAMIC Used to determine if dynamic thread adjustment is enabled or not OMP_SET_NESTED Used to enable or disable nested parallelism OMP_GET_NESTED Used to determine if nested parallelism is enabled or not OMP_SET_SCHEDULE Sets the loop scheduling policy when ""runtime"" is used as the schedule kind in the OpenMP directive OMP_GET_SCHEDULE Returns the loop scheduling policy when ""runtime"" is used as the schedule kind in the OpenMP directive OMP_SET_MAX_ACTIVE_LEVELS Sets the maximum number of nested parallel regions OMP_GET_MAX_ACTIVE_LEVELS Returns the maximum number of nested parallel regions OMP_GET_LEVEL Returns the current level of nested parallel regions OMP_GET_ANCESTOR_THREAD_NUM Returns, for a given nested level of the current thread, the thread number of ancestor thread OMP_GET_TEAM_SIZE Returns, for a given nested level of the current thread, the size of the thread team OMP_GET_ACTIVE_LEVEL Returns the number of nested, active parallel regions enclosing the task that contains the call OMP_IN_FINAL Returns true if the routine is executed in the final task region; otherwise it returns false OMP_INIT_LOCK Initializes a lock associated with the lock variable OMP_DESTROY_LOCK Disassociates the given lock variable from any locks OMP_SET_LOCK Acquires ownership of a lock OMP_UNSET_LOCK Releases a lock OMP_TEST_LOCK Attempts to set a lock, but does not block if the lock is unavailable OMP_INIT_NEST_LOCK Initializes a nested lock associated with the lock variable OMP_DESTROY_NEST_LOCK Disassociates the given nested lock variable from any locks OMP_SET_NEST_LOCK Acquires ownership of a nested lock OMP_UNSET_NEST_LOCK Releases a nested lock OMP_TEST_NEST_LOCK Attempts to set a nested lock, but does not block if the lock is unavailable OMP_GET_WTIME Provides a portable wall clock timing routine OMP_GET_WTICK Returns a double-precision floating point value equal to the number of seconds between successive clock ticks For C/C++, all of the run-time library routines are actual subroutines. For Fortran, some are actually functions, and some are subroutines. For example: Fortran INTEGER FUNCTION OMP_GET_NUM_THREADS()  C/C++ #include <omp.h> int omp_get_num_threads(void)  Note that for C/C++, you usually need to include the <omp.h> header file. Fortran routines are not case sensitive, but C/C++ routines are. For the Lock routines/functions: The lock variable must be accessed only through the locking routines For Fortran, the lock variable should be of type integer and of a kind large enough to hold an address. For C/C++, the lock variable must have type omp_lock_t or type omp_nest_lock_t, depending on the function being used. Implementation notes: Implementations may or may not support all OpenMP API features. For example, if nested parallelism is supported, it may be only nominal, in that a nested parallel region may only have one thread. Consult your implementation's documentation for details - or experiment and find out for yourself if you can't find it in the documentation. The run-time library routines are discussed in more detail in Appendix A. Environment Variables OpenMP provides the following environment variables for controlling the execution of parallel code. All environment variable names are uppercase. The values assigned to them are not case sensitive. OMP_SCHEDULE Applies only to DO, PARALLEL DO (Fortran) and for, parallel for (C/C++) directives which have their schedule clause set to RUNTIME. The value of this variable determines how iterations of the loop are scheduled on processors. For example: setenv OMP_SCHEDULE ""guided, 4"" setenv OMP_SCHEDULE ""dynamic"" OMP_NUM_THREADS Sets the maximum number of threads to use during execution. For example: setenv OMP_NUM_THREADS 8 OMP_DYNAMIC Enables or disables dynamic adjustment of the number of threads available for execution of parallel regions. Valid values are TRUE or FALSE. For example: setenv OMP_DYNAMIC TRUE OMP_PROC_BIND Enables or disables threads binding to processors. Valid values are TRUE or FALSE. For example: setenv OMP_PROC_BIND TRUE OMP_NESTED Enables or disables nested parallelism. Valid values are TRUE or FALSE. For example: setenv OMP_NESTED TRUE OMP_STACKSIZE Controls the size of the stack for created (non-Master) threads. Examples: setenv OMP_STACKSIZE 2000500B setenv OMP_STACKSIZE ""3000 k "" setenv OMP_STACKSIZE 10M setenv OMP_STACKSIZE "" 10 M "" setenv OMP_STACKSIZE ""20 m "" setenv OMP_STACKSIZE "" 1G"" setenv OMP_STACKSIZE 20000 OMP_WAIT_POLICY Provides a hint to an OpenMP implementation about the desired behavior of waiting threads. A compliant OpenMP implementation may or may not abide by the setting of the environment variable. Valid values are ACTIVE and PASSIVE. ACTIVE specifies that waiting threads should mostly be active, i.e., consume processor cycles, while waiting. PASSIVE specifies that waiting threads should mostly be passive, i.e., not consume processor cycles, while waiting. The details of the ACTIVE and PASSIVE behaviors are implementation defined. Examples: setenv OMP_WAIT_POLICY ACTIVE setenv OMP_WAIT_POLICY active setenv OMP_WAIT_POLICY PASSIVE setenv OMP_WAIT_POLICY passive OMP_MAX_ACTIVE_LEVELS Controls the maximum number of nested active parallel regions. The value of this environment variable must be a non-negative integer. The behavior of the program is implementation defined if the requested value of OMP_MAX_ACTIVE_LEVELS is greater than the maximum number of nested active parallel levels an implementation can support, or if the value is not a non-negative integer. Example: setenv OMP_MAX_ACTIVE_LEVELS 2 OMP_THREAD_LIMIT Sets the number of OpenMP threads to use for the whole OpenMP program. The value of this environment variable must be a positive integer. The behavior of the program is implementation defined if the requested value of OMP_THREAD_LIMIT is greater than the number of threads an implementation can support, or if the value is not a positive integer. Example: setenv OMP_THREAD_LIMIT 8 Thread Stack Size and Thread Binding Thread Stack Size: The OpenMP standard does not specify how much stack space a thread should have. Consequently, implementations will differ in the default thread stack size. Default thread stack size can be easy to exhaust. It can also be non-portable between compilers. Using past versions of LC compilers as an example: Compiler Approx. Stack Limit Approx. Array Size (doubles) Linux icc, ifort 4 MB 700 x 700 Linux pgcc, pgf90 8 MB 1000 x 1000 Linux gcc, gfortran 2 MB 500 x 500 Threads that exceed their stack allocation may or may not seg fault. An application may continue to run while data is being corrupted. Statically linked codes may be subject to further stack restrictions. A user's login shell may also restrict stack size If your OpenMP environment supports the OpenMP 3.0 OMP_STACKSIZE environment variable (covered in previous section), you can use it to set the thread stack size prior to program execution. For example: setenv OMP_STACKSIZE 2000500B setenv OMP_STACKSIZE ""3000 k "" setenv OMP_STACKSIZE 10M setenv OMP_STACKSIZE "" 10 M "" setenv OMP_STACKSIZE ""20 m "" setenv OMP_STACKSIZE "" 1G"" setenv OMP_STACKSIZE 20000  Otherwise, at LC, you should be able to use the method below for Linux clusters. The example shows setting the thread stack size to 12 MB, and as a precaution, setting the shell stack size to unlimited. csh/tcsh setenv KMP_STACKSIZE 12000000 limit stacksize unlimited ksh/sh/bash export KMP_STACKSIZE=12000000 ulimit -s unlimited Thread Binding: In some cases, a program will perform better if its threads are bound to processors/cores. ""Binding"" a thread to a processor means that a thread will be scheduled by the operating system to always run on a the same processor. Otherwise, threads can be scheduled to execute on any processor and ""bounce"" back and forth between processors with each time slice. Also called ""thread affinity"" or ""processor affinity"" Binding threads to processors can result in better cache utilization, thereby reducing costly memory accesses. This is the primary motivation for binding threads to processors. Depending upon your platform, operating system, compiler and OpenMP implementation, binding threads to processors can be done several different ways. The OpenMP version 3.1 API provides an environment variable to turn processor binding ""on"" or ""off"". For example: setenv OMP_PROC_BIND  TRUE setenv OMP_PROC_BIND  FALSE At a higher level, processes can also be bound to processors. Detailed information about process and thread binding to processors on LC Linux clusters can be found HERE. Monitoring, Debugging and Performance Analysis Tools for OpenMP Monitoring and Debugging Threads: Debuggers vary in their ability to handle threads. The TotalView debugger is LC's recommended debugger for parallel programs. It is well suited for both monitoring and debugging threaded programs. An example screenshot from a TotalView session using an OpenMP code is shown below. Master thread Stack Trace Pane showing original routine Process/thread status bars differentiating threads Master thread Stack Frame Pane showing shared variables Worker thread Stack Trace Pane showing outlined routine. Worker thread Stack Frame Pane Root Window showing all threads Threads Pane showing all threads plus selected thread See the TotalView Debugger tutorial for details. The Linux ps command provides several flags for viewing thread information. Some examples are shown below. See the man page for details.  % ps -Lf  UID        PID  PPID   LWP  C NLWP STIME TTY          TIME CMD blaise   22529 28240 22529  0    5 11:31 pts/53   00:00:00 a.out blaise   22529 28240 22530 99    5 11:31 pts/53   00:01:24 a.out blaise   22529 28240 22531 99    5 11:31 pts/53   00:01:24 a.out blaise   22529 28240 22532 99    5 11:31 pts/53   00:01:24 a.out blaise   22529 28240 22533 99    5 11:31 pts/53   00:01:24 a.out  % ps -T    PID  SPID TTY          TIME CMD 22529 22529 pts/53   00:00:00 a.out 22529 22530 pts/53   00:01:49 a.out 22529 22531 pts/53   00:01:49 a.out 22529 22532 pts/53   00:01:49 a.out 22529 22533 pts/53   00:01:49 a.out  % ps -Lm    PID   LWP TTY          TIME CMD 22529     - pts/53   00:18:56 a.out     - 22529 -        00:00:00 -     - 22530 -        00:04:44 -     - 22531 -        00:04:44 -     - 22532 -        00:04:44 -     - 22533 -        00:04:44 -  LC's Linux clusters also provide the top command to monitor processes on a node. If used with the -H flag, the threads contained within a process will be visible. An example of the top -H command is shown below. The parent process is PID 18010 which spawned three threads, shown as PIDs 18012, 18013 and 18014. Performance Analysis Tools: There are a variety of performance analysis tools that can be used with OpenMP programs. Searching the web will turn up a wealth of information. At LC, the list of supported computing tools can be found at: computing.llnl.gov/code/content/software_tools.php. These tools vary significantly in their complexity, functionality and learning curve. Covering them in detail is beyond the scope of this tutorial. Some tools worth investigating, specifically for OpenMP codes, include: Open|SpeedShop TAU PAPI Intel VTune Amplifier ThreadSpotter OpenMP Exercise 3 Assorted Overview: Login to the workshop cluster, if you are not already logged in Orphaned directive example: review, compile, run Get OpenMP implementation environment information Check out the ""bug"" programs GO TO THE EXERCISE HERE This completes the tutorial.       Please complete the online evaluation form - unless you are doing the exercise, in which case please complete it at the end of the exercise. Where would you like to go now? Exercise Agenda Back to the top   References and More Information Author: Blaise Barney, Livermore Computing. The OpenMP web site, which includes the C/C++ and Fortran Application Program Interface documents. www.openmp.org Appendix A: Run-Time Library Routines OMP_SET_NUM_THREADS Purpose: Sets the number of threads that will be used in the next parallel region. Must be a postive integer. Format: Fortran  SUBROUTINE OMP_SET_NUM_THREADS(scalar_integer_expression)  C/C++  #include <omp.h> void omp_set_num_threads(int num_threads)  Notes & Restrictions: The dynamic threads mechanism modifies the effect of this routine. Enabled: specifies the maximum number of threads that can be used for any parallel region by the dynamic threads mechanism. Disabled: specifies exact number of threads to use until next call to this routine. This routine can only be called from the serial portions of the code This call has precedence over the OMP_NUM_THREADS environment variable OMP_GET_NUM_THREADS Purpose: Returns the number of threads that are currently in the team executing the parallel region from which it is called. Format: Fortran  INTEGER FUNCTION OMP_GET_NUM_THREADS()  C/C++  #include <omp.h> int omp_get_num_threads(void)  Notes & Restrictions: If this call is made from a serial portion of the program, or a nested parallel region that is serialized, it will return 1. The default number of threads is implementation dependent. OMP_GET_MAX_THREADS Purpose: Returns the maximum value that can be returned by a call to the OMP_GET_NUM_THREADS function. Fortran  INTEGER FUNCTION OMP_GET_MAX_THREADS()  C/C++  #include <omp.h> int omp_get_max_threads(void)  Notes & Restrictions: Generally reflects the number of threads as set by the OMP_NUM_THREADS environment variable or the OMP_SET_NUM_THREADS() library routine. May be called from both serial and parallel regions of code. OMP_GET_THREAD_NUM Purpose: Returns the thread number of the thread, within the team, making this call. This number will be between 0 and OMP_GET_NUM_THREADS-1. The master thread of the team is thread 0 Format: Fortran  INTEGER FUNCTION OMP_GET_THREAD_NUM()  C/C++  #include <omp.h> int omp_get_thread_num(void)  Notes & Restrictions: If called from a nested parallel region, or a serial region, this function will return 0. Examples: Example 1 is the correct way to determine the number of threads in a parallel region. Example 2 is incorrect - the TID variable must be PRIVATE Example 3 is incorrect - the OMP_GET_THREAD_NUM call is outside the parallel region Fortran - determining the number of threads in a parallel region Example 1: Correct        PROGRAM HELLO        INTEGER TID, OMP_GET_THREAD_NUM  !$OMP PARALLEL PRIVATE(TID)        TID = OMP_GET_THREAD_NUM()       PRINT *, 'Hello World from thread = ', TID        ...  !$OMP END PARALLEL        END  Example 2: Incorrect        PROGRAM HELLO        INTEGER TID, OMP_GET_THREAD_NUM  !$OMP PARALLEL         TID = OMP_GET_THREAD_NUM()       PRINT *, 'Hello World from thread = ', TID        ...  !$OMP END PARALLEL        END  Example 3: Incorrect        PROGRAM HELLO        INTEGER TID, OMP_GET_THREAD_NUM        TID = OMP_GET_THREAD_NUM()       PRINT *, 'Hello World from thread = ', TID  !$OMP PARALLEL         ...  !$OMP END PARALLEL        END  OMP_GET_THREAD_LIMIT Purpose: Returns the maximum number of OpenMP threads available to a program. Format: Fortran  INTEGER FUNCTION OMP_GET_THREAD_LIMIT  C/C++  #include <omp.h> int omp_get_thread_limit (void)  Notes: Also see the OMP_THREAD_LIMIT environment variable. OMP_GET_NUM_PROCS Purpose: Returns the number of processors that are available to the program. Format: Fortran  INTEGER FUNCTION OMP_GET_NUM_PROCS()  C/C++  #include <omp.h> int omp_get_num_procs(void)  OMP_IN_PARALLEL Purpose: May be called to determine if the section of code which is executing is parallel or not. Format: Fortran  LOGICAL FUNCTION OMP_IN_PARALLEL()  C/C++  #include <omp.h> int omp_in_parallel(void)  Notes & Restrictions: For Fortran, this function returns .TRUE. if it is called from the dynamic extent of a region executing in parallel, and .FALSE. otherwise. For C/C++, it will return a non-zero integer if parallel, and zero otherwise. OMP_SET_DYNAMIC Purpose: Enables or disables dynamic adjustment (by the run time system) of the number of threads available for execution of parallel regions. Format: Fortran  SUBROUTINE OMP_SET_DYNAMIC(scalar_logical_expression)  C/C++  #include <omp.h> void omp_set_dynamic(int dynamic_threads)  Notes & Restrictions: For Fortran, if called with .TRUE. then the number of threads available for subsequent parallel regions can be adjusted automatically by the run-time environment. If called with .FALSE., dynamic adjustment is disabled. For C/C++, if dynamic_threads evaluates to non-zero, then the mechanism is enabled, otherwise it is disabled. The OMP_SET_DYNAMIC subroutine has precedence over the OMP_DYNAMIC environment variable. The default setting is implementation dependent. Must be called from a serial section of the program. OMP_GET_DYNAMIC Purpose: Used to determine if dynamic thread adjustment is enabled or not. Format: Fortran  LOGICAL FUNCTION OMP_GET_DYNAMIC()  C/C++  #include <omp.h> int omp_get_dynamic(void)  Notes & Restrictions: For Fortran, this function returns .TRUE. if dynamic thread adjustment is enabled, and .FALSE. otherwise. For C/C++, non-zero will be returned if dynamic thread adjustment is enabled, and zero otherwise. OMP_SET_NESTED Purpose: Used to enable or disable nested parallelism. Format: Fortran  SUBROUTINE OMP_SET_NESTED(scalar_logical_expression)  C/C++  #include <omp.h> void omp_set_nested(int nested)  Notes & Restrictions: For Fortran, calling this function with .FALSE. will disable nested parallelism, and calling with .TRUE. will enable it. For C/C++, if nested evaluates to non-zero, nested parallelism is enabled; otherwise it is disabled. The default is for nested parallelism to be disabled. This call has precedence over the OMP_NESTED environment variable OMP_GET_NESTED Purpose: Used to determine if nested parallelism is enabled or not. Format: Fortran  LOGICAL FUNCTION OMP_GET_NESTED  C/C++  #include <omp.h> int omp_get_nested (void)  Notes & Restrictions: For Fortran, this function returns .TRUE. if nested parallelism is enabled, and .FALSE. otherwise. For C/C++, non-zero will be returned if nested parallelism is enabled, and zero otherwise. OMP_SET_SCHEDULE Purpose: This routine sets the schedule type that is applied when the loop directive specifies a runtime schedule. Format: Fortran  SUBROUTINE OMP_SET_SCHEDULE(KIND, MODIFIER) INTEGER (KIND=OMP_SCHED_KIND) KIND INTEGER MODIFIER  C/C++  #include <omp.h> void omp_set_schedule(omp_sched_t kind, int modifier)  OMP_GET_SCHEDULE Purpose: This routine returns the schedule that is applied when the loop directive specifies a runtime schedule. Format: Fortran  SUBROUTINE OMP_GET_SCHEDULE(KIND, MODIFIER) INTEGER (KIND=OMP_SCHED_KIND) KIND INTEGER MODIFIER  C/C++  #include <omp.h> void omp_get_schedule(omp_sched_t * kind, int * modifier )   OMP_SET_MAX_ACTIVE_LEVELS Purpose: This routine limits the number of nested active parallel regions. Format: Fortran  SUBROUTINE OMP_SET_MAX_ACTIVE_LEVELS (MAX_LEVELS) INTEGER MAX_LEVELS  C/C++  #include <omp.h> void omp_set_max_active_levels (int max_levels)   Notes & Restrictions: If the number of parallel levels requested exceeds the number of levels of parallelism supported by the implementation, the value will be set to the number of parallel levels supported by the implementation. This routine has the described effect only when called from the sequential part of the program. When called from within an explicit parallel region, the effect of this routine is implementation defined. OMP_GET_MAX_ACTIVE_LEVELS Purpose: This routine returns the maximum number of nested active parallel regions. Format: Fortran  INTEGER FUNCTION OMP_GET_MAX_ACTIVE_LEVELS()  C/C++  #include <omp.h> int omp_get_max_active_levels(void)   OMP_GET_LEVEL Purpose: This routine returns the number of nested parallel regions enclosing the task that contains the call. Format: Fortran  INTEGER FUNCTION OMP_GET_LEVEL()  C/C++  #include <omp.h> int omp_get_level(void)   Notes & Restrictions: The omp_get_level routine returns the number of nested parallel regions (whether active or inactive) enclosing the task that contains the call, not including the implicit parallel region. The routine always returns a non-negative integer, and returns 0 if it is called from the sequential part of the program. OMP_GET_ANCESTOR_THREAD_NUM Purpose: This routine returns, for a given nested level of the current thread, the thread number of the ancestor or the current thread. Format: Fortran  INTEGER FUNCTION OMP_GET_ANCESTOR_THREAD_NUM(LEVEL) INTEGER LEVEL  C/C++  #include <omp.h> int omp_get_ancestor_thread_num(int level)   Notes & Restrictions: If the requested nest level is outside the range of 0 and the nest level of the current thread, as returned by the omp_get_level routine, the routine returns -1. OMP_GET_TEAM_SIZE Purpose: This routine returns, for a given nested level of the current thread, the size of the thread team to which the ancestor or the current thread belongs. Format: Fortran  INTEGER FUNCTION OMP_GET_TEAM_SIZE(LEVEL) INTEGER LEVEL  C/C++  #include <omp.h> int omp_get_team_size(int level);   Notes & Restrictions: If the requested nested level is outside the range of 0 and the nested level of the current thread, as returned by the omp_get_level routine, the routine returns -1. Inactive parallel regions are regarded like active parallel regions executed with one thread. OMP_GET_ACTIVE_LEVEL Purpose: The omp_get_active_level routine returns the number of nested, active parallel regions enclosing the task that contains the call. Format: Fortran  INTEGER FUNCTION OMP_GET_ACTIVE_LEVEL()  C/C++  #include <omp.h> int omp_get_active_level(void);  Notes & Restrictions: The routine always returns a nonnegative integer, and returns 0 if it is called from the sequential part of the program. OMP_IN_FINAL Purpose: This routine returns true if the routine is executed in a final task region; otherwise, it returns false. Format: Fortran  LOGICAL FUNCTION OMP_IN_FINAL()  C/C++  #include <omp.h> int omp_in_final(void)   OMP_INIT_LOCK OMP_INIT_NEST_LOCK Purpose: This subroutine initializes a lock associated with the lock variable. Format: Fortran  SUBROUTINE OMP_INIT_LOCK(var) SUBROUTINE OMP_INIT_NEST_LOCK(var)  C/C++  #include <omp.h> void omp_init_lock(omp_lock_t *lock) void omp_init_nest_lock(omp_nest_lock_t *lock)  Notes & Restrictions: The initial state is unlocked For Fortran, var must be an integer large enough to hold an address, such as INTEGER*8 on 64-bit systems. OMP_DESTROY_LOCK OMP_DESTROY_NEST_LOCK Purpose: This subroutine disassociates the given lock variable from any locks. Format: Fortran  SUBROUTINE OMP_DESTROY_LOCK(var) SUBROUTINE OMP_DESTROY_NEST_LOCK(var)  C/C++  #include <omp.h> void omp_destroy_lock(omp_lock_t *lock) void omp_destroy_nest_lock(omp_nest_lock_t *lock)  Notes & Restrictions: It is illegal to call this routine with a lock variable that is not initialized. For Fortran, var must be an integer large enough to hold an address, such as INTEGER*8 on 64-bit systems. OMP_SET_LOCK OMP_SET_NEST_LOCK Purpose: This subroutine forces the executing thread to wait until the specified lock is available. A thread is granted ownership of a lock when it becomes available. Format: Fortran  SUBROUTINE OMP_SET_LOCK(var) SUBROUTINE OMP_SET_NEST_LOCK(var)  C/C++  #include <omp.h> void omp_set_lock(omp_lock_t *lock) void omp_set_nest__lock(omp_nest_lock_t *lock)  Notes & Restrictions: It is illegal to call this routine with a lock variable that is not initialized. For Fortran, var must be an integer large enough to hold an address, such as INTEGER*8 on 64-bit systems. OMP_UNSET_LOCK OMP_UNSET_NEST_LOCK Purpose: This subroutine releases the lock from the executing subroutine. Format: Fortran  SUBROUTINE OMP_UNSET_LOCK(var) SUBROUTINE OMP_UNSET_NEST_LOCK(var)  C/C++  #include <omp.h> void omp_unset_lock(omp_lock_t *lock) void omp_unset_nest__lock(omp_nest_lock_t *lock)  Notes & Restrictions: It is illegal to call this routine with a lock variable that is not initialized. For Fortran, var must be an integer large enough to hold an address, such as INTEGER*8 on 64-bit systems. OMP_TEST_LOCK OMP_TEST_NEST_LOCK Purpose: This subroutine attempts to set a lock, but does not block if the lock is unavailable. Format: Fortran  SUBROUTINE OMP_TEST_LOCK(var) SUBROUTINE OMP_TEST_NEST_LOCK(var)  C/C++  #include <omp.h> int omp_test_lock(omp_lock_t *lock) int omp_test_nest__lock(omp_nest_lock_t *lock)  Notes & Restrictions: For Fortran, .TRUE. is returned if the lock was set successfully, otherwise .FALSE. is returned. For Fortran, var must be an integer large enough to hold an address, such as INTEGER*8 on 64-bit systems. For C/C++, non-zero is returned if the lock was set successfully, otherwise zero is returned. It is illegal to call this routine with a lock variable that is not initialized. OMP_GET_WTIME Purpose: Provides a portable wall clock timing routine Returns a double-precision floating point value equal to the number of elapsed seconds since some point in the past. Usually used in ""pairs"" with the value of the first call subtracted from the value of the second call to obtain the elapsed time for a block of code. Designed to be ""per thread"" times, and therefore may not be globally consistent across all threads in a team - depends upon what a thread is doing compared to other threads. Format: Fortran  DOUBLE PRECISION FUNCTION OMP_GET_WTIME()   C/C++  #include <omp.h> double omp_get_wtime(void)   OMP_GET_WTICK Purpose: Provides a portable wall clock timing routine Returns a double-precision floating point value equal to the number of seconds between successive clock ticks. Format: Fortran  DOUBLE PRECISION FUNCTION OMP_GET_WTICK()   C/C++  #include <omp.h> double omp_get_wtick(void)"	"null"	"null"	"(for the OpenMP3 standard)"	"true"
"Intermediate"	"memcpy vs memmove"	"http://www.tedunangst.com/flak/post/memcpy-vs-memmove"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"memcpy vs memmove guest - flak memcpy vs memmove A few notes about memcpy vs memmove and some related items as well. memcpy The C standard specifies two functions for copying memory regions, memcpy and memmove. The important difference is that it is undefined behavior to call memcpy with overlapping regions. One must use memmove for that. As the names imply, memcpy copies data from one region to another, while memmove moves data within a region. (It’s also perfectly acceptable to memmove between different regions.) This subtle but important distinction allows memcpy to be optimized more aggressively. In the case of memmove between overlapping regions, care must be taken not to destroy the contents of the source before they are done copying. This is easiest to see with a naive implementation of a copy loop. int arr[5] = { 11, 22, 33, 44, 55 }; /* shift array backwards one element */ for (int i = 0; i < 4; i++) arr[i] = arr[i + 1]; /* * this works fine * arr == { 22, 33, 44, 55, 55 } */ /* now try shifting array forwards */ for (int i = 0; i < 4; i++) arr[i + 1] = arr[i]; /* * uh, oh, we destroyed the source along the way * arr == { 22, 22, 22, 22, 22 } * the desired result was instead * arr == { 22, 22, 33, 44, 55 } */ In order to operate as desired, the second loop must be changed to for (int i = 3; i >= 0; i--). memmove must implement both loops and decide between them at runtime. bcopy BSD systems also have another copying function, bcopy. It has the same semantics as memmove, but the source and destination arguments are reversed. It also has one other property: the compiler doesn’t know about it. The compiler can optimize and inline calls to standard C functions, but can’t do so when they are misspelled. Some time ago, dlg@ noticed that a couple of the bcopy calls in the network stack were impacting packet forwarding performance. Copying an ethernet header is only six bytes. The compiler could easily inline such a copy, but instead the source code required a call to the bcopy function, which would then perform various overlaps tests, etc. Replacing the bcopy calls with calls to memcpy sped things up considerably. And so began a slow conversion of the many bcopy calls in the kernel to memcpy. This requires inspecting the function arguments to make sure they don’t overlap. If they do, then memmove must be used instead. Before this operation started, there was not a single memmove in the kernel, as evidenced by the fact that several architectures lacked implementations. libkern Two things to note about the kernel implementation of these functions. First, they are almost always implemented in assembly for performance. Sometimes, though, that results in some superultraoptimized code, such as the miracle of modern engineering that is arm memcpy.S. Wowzers. For large copies, finding an optimized path is worth it. But all that code burns icache and causes branch mispredictions. No wonder then that having the compiler inline calls works better than dropping into this behemoth. (For the bold, you may also gaze into the abyss that is sparc64/locore.s for another take on these functions.) Second, on many architectures, the functions share code and overlap. The amd64 memmove.S is easier to read. Long ago, all three functions (memcpy, memmove, bcopy) were the same. And frequently implemented in terms of bcopy. This meant that every call to memcpy or memmove had to reverse the arguments. In accordance with our preference for new code to use the standard functions, this was changed to have bcopy reverse the arguments and fall into memmove. More recently, we’ve also changed the memcpy entry point to occur after the overlap check (but not yet everywhere, as the arm example shows). memmove As mentioned, we’re changing bcopy to memcpy and the occasional memmove. Sometimes that goes wrong, and a memcpy is introduced where memmove is needed. That happened in the PPPOE code as seen here. A MAC address of all ‘A’ or ‘F’? Almost as if memcpy copied two overlapping addresses as seen in the example above. Sure enough, reverting to bcopy solves the problem. Or switching to memmove. In this case, it seemed like the bcopy to memcpy conversion was safe because the destination was freshly allocated by M_PREPEND, and therefore the pointers would be unique. But it turns out the source was actually part of the mbuf to start, and had been chopped off with m_adj earlier in the function. Very sneaky. nop Not long ago, reyk@ noticed that while we use asm versions of these functions in the kernel, libc is built with the stock C versions. Switching to the asm versions gives a nice performance boost. But then something very strange happened. mlarkin@ had an amd64 ramdisk kernel crashing at boot. In bcopy. A poorly assembled version of bcopy. Normally, bcopy is supposed to look something like this: ffffffff811a7060 <bcopy>: ffffffff811a7060: 48 87 fe xchg %rdi,%rsi ffffffff811a7063: 90 nop ffffffff811a7064: 90 nop ffffffff811a7065: 90 nop ffffffff811a7066: 90 nop ffffffff811a7067: 90 nop ffffffff811a7068: 90 nop ffffffff811a7069: 90 nop ffffffff811a706a: 90 nop ffffffff811a706b: 90 nop ffffffff811a706c: 90 nop ffffffff811a706d: 90 nop ffffffff811a706e: 90 nop ffffffff811a706f: 90 nop ffffffff811a7070 <memmove>: ffffffff811a7070: 49 89 fb mov %rdi,%r11 xchg the source and destination registers, and then “nop sled” into memmove. But Mike had a special edition bcopy: ffffffff811a7060 <bcopy>: ffffffff811a7060: 48 87 fe xchg %rdi,%rsi ffffffff811a7063: 90 nop ffffffff811a7064: 90 nop ffffffff811a7065: ff (bad) ffffffff811a7066: ff 90 90 ff ff 90 callq *0xffffffff90ffff90(%rax) ffffffff811a706c: 90 nop ffffffff811a706d: ff (bad) ffffffff811a706e: ff 90 49 89 fb 48 callq *0x48fb8949(%rax) ffffffff811a7070 <memmove>: ffffffff811a7070: 49 89 fb mov %rdi,%r11 Well, that’s certainly different. Perhaps most awesome is that the last callq in bcopy is actually also the first few instructions of memmove, but that’s just coincidence. But how is this possible? The kernel is built from entirely separate sources, unshared with libc. A switch to asm memcpy/memmove in libc can’t possibly affect the same functions in the kernel. Can it? gas Reverting to a previous build of libc and recompiling the kernel corrected the problem. The problem was actually in userland. millert@ quickly found and backported two memcpy fixes for gas. Surely, that’ll fix it. But no. The problem is in the libc asm commit, but not in memcpy or memmove. memset After deraadt@ deduced through some trial and error that memset was the buggy function, naddy@ noticed that the FreeBSD version of this function had one tiny difference. Another diff for the one liner hall of fame. diff -u -r1.3 -r1.4 --- src/sys/lib/libkern/arch/amd64/memset.S 2007/11/24 19:28:25 1.3 +++ src/sys/lib/libkern/arch/amd64/memset.S 2014/11/21 21:30:50 1.4 @@ -8,6 +8,7 @@ ENTRY(memset) movq %rsi,%rax + andq $0xff,%rax movq %rdx,%rcx movq %rdi,%r11 The second argument to memset is of type int, but is expected to be interpreted as an unsigned char. By default, however, the register it’s passed in will be sign extended. 0x90 turns into 0xffffff90 and everything goes sideways. How could a bug like this live in the kernel for so long? The kernel only ever calls memset with three arguments: 0, ' ', 0xff. The first two are positive values, and the last sign extends into itself. cld Related fun fact: the x86 architectures have a direction flag that can be set to cause the processor to run backwards. This is how the backwards copying overlapping memmove is implemented. It’s important for the operating system to keep this flag set to the correct value. If userland sets the flag and then traps into the kernel, it would not be good for the kernel to run in reverse. 900 years ago, bugs of this nature could be exploited for some hilarity. The asm versions of memcpy were until very recently somewhat paranoid about always clearing the direction flag in case it had somehow been forgotten. But guenther@ did an audit and fixed up all the remaining entry points where it was possible it wasn’t set, and then the unnecessary instruction could be removed. libc After the initial libc asm commit was reverted, deraadt@ spent some time polishing and improving it. Mostly untangling the complicated libc build infrastructure. The Makefiles are designed to support asm or C versions of each function, but sometimes they have to be implemented in pairs or with dummy stub files or else too many functions get compiled. And the dependencies were generally wrong. Part of the great restructuring involved temporarily changing all architectures to a special memcpy implementation. It checks for overlap like memmove would, but instead of processing the data, it logs a message and aborts. All within C spec. This will help us verify that programs are using memcpy correctly and memmove where they must. Similar changes should be coming to the kernel. So far a few problems have been identified. Also a bug involving overlapping snprintf buffers. Some in expect. Another in vi. Some of the more surprising bugs caught weren’t just overlaps, but overflows. One in tar and one in postgresql that’s even more interesting. Somewhat relatedly, zero length null pointers and memcpy are also undefined. Posted 2014-12-01 17:16:56 by tedu Updated: 2016-05-12 23:36:00 Tagged: c openbsd programming recent my int is too big ratfucked HP Chromebook 13 convention quote quiz magicians tv best of seven elections true string indices timeline of libexpat random vulnerability select works poorly accidentally nonblocking random selected dead code and butterflies strict posix nonconformance whose xterm is it anyway? subtraction is not comparison tags software openbsd programming rants thoughts security c web review computers moviereview politics bugs gadget magreview quote business philly mailfail project"	"null"	"null"	""	"true"
"Intermediate"	"MPI tutorial"	"https://computing.llnl.gov/tutorials/mpi/"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Message Passing Interface (MPI) Message Passing Interface (MPI) Author: Blaise Barney, Lawrence Livermore National Laboratory UCRL-MI-133316 Table of Contents Abstract What is MPI? LLNL MPI Implementations and Compilers Getting Started Environment Management Routines Exercise 1 Point to Point Communication Routines General Concepts MPI Message Passing Routine Arguments Blocking Message Passing Routines Non-blocking Message Passing Routines Exercise 2 Collective Communication Routines Derived Data Types Group and Communicator Management Routines Virtual Topologies A Brief Word on MPI-2 and MPI-3 Exercise 3 References and More Information Appendix A: MPI-1 Routine Index Abstract The Message Passing Interface Standard (MPI) is a message passing library standard based on the consensus of the MPI Forum, which has over 40 participating organizations, including vendors, researchers, software library developers, and users. The goal of the Message Passing Interface is to establish a portable, efficient, and flexible standard for message passing that will be widely used for writing message passing programs. As such, MPI is the first standardized, vendor independent, message passing library. The advantages of developing message passing software using MPI closely match the design goals of portability, efficiency, and flexibility. MPI is not an IEEE or ISO standard, but has in fact, become the ""industry standard"" for writing message passing programs on HPC platforms. The goal of this tutorial is to teach those unfamiliar with MPI how to develop and run parallel programs according to the MPI standard. The primary topics that are presented focus on those which are the most useful for new MPI programmers. The tutorial begins with an introduction, background, and basic information for getting started with MPI. This is followed by a detailed look at the MPI routines that are most useful for new MPI programmers, including MPI Environment Management, Point-to-Point Communications, and Collective Communications routines. Numerous examples in both C and Fortran are provided, as well as a lab exercise. The tutorial materials also include more advanced topics such as Derived Data Types, Group and Communicator Management Routines, and Virtual Topologies. However, these are not actually presented during the lecture, but are meant to serve as ""further reading"" for those who are interested. Level/Prerequisites: This tutorial is ideal for those who are new to parallel programming with MPI. A basic understanding of parallel programming in C or Fortran is required. For those who are unfamiliar with Parallel Programming in general, the material covered in EC3500: Introduction To Parallel Computing would be helpful. What is MPI? An Interface Specification: M P I = Message Passing Interface MPI is a specification for the developers and users of message passing libraries. By itself, it is NOT a library - but rather the specification of what such a library should be. MPI primarily addresses the message-passing parallel programming model: data is moved from the address space of one process to that of another process through cooperative operations on each process. Simply stated, the goal of the Message Passing Interface is to provide a widely used standard for writing message passing programs. The interface attempts to be: Practical Portable Efficient Flexible The MPI standard has gone through a number of revisions, with the most recent version being MPI-3.x Interface specifications have been defined for C and Fortran90 language bindings: C++ bindings from MPI-1 are removed in MPI-3 MPI-3 also provides support for Fortran 2003 and 2008 features Actual MPI library implementations differ in which version and features of the MPI standard they support. Developers/users will need to be aware of this. Programming Model: Originally, MPI was designed for distributed memory architectures, which were becoming increasingly popular at that time (1980s - early 1990s). As architecture trends changed, shared memory SMPs were combined over networks creating hybrid distributed memory / shared memory systems. MPI implementors adapted their libraries to handle both types of underlying memory architectures seamlessly. They also adapted/developed ways of handling different interconnects and protocols. Today, MPI runs on virtually any hardware platform: Distributed Memory Shared Memory Hybrid The programming model clearly remains a distributed memory model however, regardless of the underlying physical architecture of the machine. All parallelism is explicit: the programmer is responsible for correctly identifying parallelism and implementing parallel algorithms using MPI constructs. Reasons for Using MPI: Standardization - MPI is the only message passing library that can be considered a standard. It is supported on virtually all HPC platforms. Practically, it has replaced all previous message passing libraries. Portability - There is little or no need to modify your source code when you port your application to a different platform that supports (and is compliant with) the MPI standard. Performance Opportunities - Vendor implementations should be able to exploit native hardware features to optimize performance. Any implementation is free to develop optimized algorithms. Functionality - There are over 430 routines defined in MPI-3, which includes the majority of those in MPI-2 and MPI-1.  Most MPI programs can be written using a dozen or less routines Availability - A variety of implementations are available, both vendor and public domain. History and Evolution: (for those interested) MPI has resulted from the efforts of numerous individuals and groups that began in 1992. Some history: 1980s - early 1990s: Distributed memory, parallel computing develops, as do a number of incompatible software tools for writing such programs - usually with tradeoffs between portability, performance, functionality and price. Recognition of the need for a standard arose. Apr 1992: Workshop on Standards for Message Passing in a Distributed Memory Environment, sponsored by the Center for Research on Parallel Computing, Williamsburg, Virginia. The basic features essential to a standard message passing interface were discussed, and a working group established to continue the standardization process. Preliminary draft proposal developed subsequently. Nov 1992: Working group meets in Minneapolis. MPI draft proposal (MPI1) from ORNL presented. Group adopts procedures and organization to form the MPI Forum. It eventually comprised of about 175 individuals from 40 organizations including parallel computer vendors, software writers, academia and application scientists. Nov 1993: Supercomputing 93 conference - draft MPI standard presented. May 1994: Final version of MPI-1.0 released MPI-1.1 (Jun 1995) MPI-1.2 (Jul 1997) MPI-1.3 (May 2008). 1998: MPI-2 picked up where the first MPI specification left off, and addressed topics which went far beyond the MPI-1 specification. MPI-2.1 (Sep 2008) MPI-2.2 (Sep 2009) Sep 2012: The MPI-3.0 standard was approved. MPI-3.1 (Jun 2015) Documentation: Documentation for all versions of the MPI standard is available at: http://www.mpi-forum.org/docs/. LLNL MPI Implementations and Compilers Although the MPI programming interface has been standardized, actual library implementations will differ in which version and features of the standard they support. The way MPI programs are compiled and run on different platforms may also vary. Currently, LC supports three different MPI implementations: MVAPICH - Linux clusters Open MPI - Linux clusters IBM MPI - BG/Q clusters A summary of each is provided below, along with links to additional detailed information. IBM BG/Q Clusters: The IBM MPI library is the only supported implementation on these platforms. Based on MPICH2. Includes MPI-2 functionality minus Dynamic Processes. Thread-safe C, C++, Fortran77/90/95 are supported Compiling and running IBM BG/Q MPI programs: see the BG/Q Tutorial: computing.llnl.gov/tutorials/bgq/ MVAPICH General Info: MVAPICH MPI is developed and supported by the Network-Based Computing Lab at Ohio State University. Available on all of LC's Linux clusters. MVAPICH 1.2 Default version of MPI (as of June 2016) MPI-1 implementation that also includes support for MPI-I/O Based on MPICH-1.2.7 MPI library from Argonne National Laboratory Not thread-safe. All MPI calls should be made by the master thread in a multi-threaded MPI program. See /usr/local/docs/mpi.mvapich.basics for LC usage details. MVAPICH2 Multiple versions available MPI-2 and MPI-3 implementations based on MPICH MPI library from Argonne National Laboratory. Versions 1.9 and later implement MPI-3 according to the developer's documentation. Not currently the default - requires the ""use"" command to load the selected dotkit package: use -l mvapich             (list available packages) use mvapich2-intel-2.1     (use the package of interest) Thread-safe See /usr/local/docs/mpi.mvapich2.basics for LC usage details. Compiling: See the MPI Build Scripts table below. Running: MPI executables are launched using the SLURM srun command with the appropriate options. For example, to launch an 8-process MPI job split across two different nodes in the pdebug pool: srun -N2 -n8 -ppdebug a.out The srun command is discussed in detail in the Running Jobs section of the Linux Clusters Overview tutorial. Documentation: MVAPICH home page: mvapich.cse.ohio-state.edu/ MVAPICH2 User Guides: http://mvapich.cse.ohio-state.edu/userguide/ MVAPICH 1.2 User Guide: available HERE MPICH home page: http://www.mpich.org/ /usr/local/docs on LC's clusters: mpi.basics mpi.mvapich.basics mpi.mvapich2.basics Open MPI General Information: Open MPI is a thread-safe, open source MPI implementation developed and supported by a consortium of academic, research, and industry partners. MPI-3 compliance since Open MPI version 1.7 Available on all LC Linux clusters. However, you'll need to load the desired dotkit package with the use command. For example: use -l openmpi              (list available packages) use openmpi-gnu-1.8.4       (use the package of interest) This ensures that LC's MPI wrapper scripts point to the desired version of Open MPI. See /usr/local/docs/mpi.openmpi.basics for LC usage details. Compiling: See the MPI Build Scripts table below. Running: Be sure to load the same Open MPI dotkit package that you used to build your executable. If you are running a batch job, you will need to load the dotkit package in your batch script. Launching an Open MPI job is done differently than with MVAPICH MPI - the mpiexec command is required. For example, to run a 48 process MPI job: mpiexec -np 48 a.out Documentation: Open MPI home page: http://www.open-mpi.org/ /usr/local/docs/openmpi.basics on LC's clusters: MPI Build Scripts LC developed MPI compiler wrapper scripts are used to compile MPI programs Automatically perform some error checks, include the appropriate MPI #include files, link to the necessary MPI libraries, and pass options to the underlying compiler. For MPICH2 and Open MPI, you must first load the desired dotkit package with the use command. For example: use -l openmpi              (list available packages) use openmpi-gnu-1.8.4       (use the package of interest) Failing to do this will result in getting the MVAPICH 1.2 implementation. For additional information: See the man page (if it exists) Issue the script name with the -help option View the script yourself directly MPI Build Scripts Implementation Language Script Name Underlying Compiler MVAPCH 1.2 C mpicc gcc - GNU mpigcc gcc - GNU mpiicc icc - Intel mpipgcc pgcc - PGI C++ mpiCC g++ - GNU mpig++ g++ - GNU mpiicpc icpc - Intel mpipgCC pgCC - PGI Fortran mpif77 g77 - GNU mpigfortran gfortran - GNU mpiifort ifort - Intel mpipgf77 pgf77 - PGI mpipgf90 pgf90 - PGI MVAPCH2 C mpicc C compiler of dotkit package loaded C++ mpicxx C++ compiler of dotkit package loaded Fortran mpif77 Fortran77 compiler of dotkit package loaded mpif90 Fortran90 compiler of dotkit package loaded Open MPI C mpicc C compiler of dotkit package loaded C++ mpiCC mpic++ mpicxx C++ compiler of dotkit package loaded Fortran mpif77 Fortran77 compiler of dotkit package loaded mpif90 Fortran90 compiler of dotkit package loaded Level of Thread Support MPI libraries vary in their level of thread support: MPI_THREAD_SINGLE - Level 0: Only one thread will execute. MPI_THREAD_FUNNELED - Level 1: The process may be multi-threaded, but only the main thread will make MPI calls - all MPI calls are funneled to the main thread. MPI_THREAD_SERIALIZED - Level 2: The process may be multi-threaded, and multiple threads may make MPI calls, but only one at a time. That is, calls are not made concurrently from two distinct threads as all MPI calls are serialized. MPI_THREAD_MULTIPLE - Level 3: Multiple threads may call MPI with no restrictions. Consult the MPI_Init_thread() man page for details. A simple C language example for determining thread level support is shown below.  #include ""mpi.h"" #include <stdio.h>   int main( int argc, char *argv[] ) {     int provided, claimed;   /*** Select one of the following     MPI_Init_thread( 0, 0, MPI_THREAD_SINGLE, &provided );     MPI_Init_thread( 0, 0, MPI_THREAD_FUNNELED, &provided );     MPI_Init_thread( 0, 0, MPI_THREAD_SERIALIZED, &provided );     MPI_Init_thread( 0, 0, MPI_THREAD_MULTIPLE, &provided ); ***/       MPI_Init_thread(0, 0, MPI_THREAD_MULTIPLE, &provided );     MPI_Query_thread( &claimed );         printf( ""Query thread level= %d  Init_thread level= %d\n"", claimed, provided );       MPI_Finalize(); }   Sample output:  Query thread level= 3  Init_thread level= 3   Getting Started General MPI Program Structure: Header File: Required for all programs that make MPI library calls.      C include file           Fortran include file      #include ""mpi.h"" include 'mpif.h' With MPI-3 Fortran, the USE mpi_f08 module is preferred over using the include file shown above. Format of MPI Calls: C names are case sensitive; Fortran names are not. Programs must not declare variables or functions with names beginning with the prefix MPI_ or PMPI_ (profiling interface). C Binding Format: rc = MPI_Xxxxx(parameter, ... ) Example: rc = MPI_Bsend(&buf,count,type,dest,tag,comm) Error code: Returned as ""rc"". MPI_SUCCESS if successful Fortran Binding Format: CALL MPI_XXXXX(parameter,..., ierr) call mpi_xxxxx(parameter,..., ierr) Example: CALL MPI_BSEND(buf,count,type,dest,tag,comm,ierr) Error code: Returned as ""ierr"" parameter. MPI_SUCCESS if successful Communicators and Groups: MPI uses objects called communicators and groups to define which collection of processes may communicate with each other. Most MPI routines require you to specify a communicator as an argument. Communicators and groups will be covered in more detail later. For now, simply use MPI_COMM_WORLD whenever a communicator is required - it is the predefined communicator that includes all of your MPI processes. Rank: Within a communicator, every process has its own unique, integer identifier assigned by the system when the process initializes. A rank is sometimes also called a ""task ID"". Ranks are contiguous and begin at zero. Used by the programmer to specify the source and destination of messages. Often used conditionally by the application to control program execution (if rank=0 do this / if rank=1 do that). Error Handling: Most MPI routines include a return/error code parameter, as described in the ""Format of MPI Calls"" section above. However, according to the MPI standard, the default behavior of an MPI call is to abort if there is an error. This means you will probably not be able to capture a return/error code other than MPI_SUCCESS (zero). The standard does provide a means to override this default error handler. A discussion on how to do this is available HERE. You can also consult the error handling section of the relevant MPI Standard documentation located at http://www.mpi-forum.org/docs/. The types of errors displayed to the user are implementation dependent. Environment Management Routines This group of routines is used for interrogating and setting the MPI execution environment, and covers an assortment of purposes, such as initializing and terminating the MPI environment, querying a rank's identity, querying the MPI library's version, etc. Most of the commonly used ones are described below. MPI_Init Initializes the MPI execution environment. This function must be called in every MPI program, must be called before any other MPI functions and must be called only once in an MPI program. For C programs, MPI_Init may be used to pass the command line arguments to all processes, although this is not required by the standard and is implementation dependent. MPI_Init (&argc,&argv) MPI_INIT (ierr) MPI_Comm_size Returns the total number of MPI processes in the specified communicator, such as MPI_COMM_WORLD. If the communicator is MPI_COMM_WORLD, then it represents the number of MPI tasks available to your application. MPI_Comm_size (comm,&size) MPI_COMM_SIZE (comm,size,ierr) MPI_Comm_rank Returns the rank of the calling MPI process within the specified communicator. Initially, each process will be assigned a unique integer rank between 0 and number of tasks - 1 within the communicator MPI_COMM_WORLD. This rank is often referred to as a task ID. If a process becomes associated with other communicators, it will have a unique rank within each of these as well. MPI_Comm_rank (comm,&rank) MPI_COMM_RANK (comm,rank,ierr) MPI_Abort Terminates all MPI processes associated with the communicator. In most MPI implementations it terminates ALL processes regardless of the communicator specified. MPI_Abort (comm,errorcode) MPI_ABORT (comm,errorcode,ierr) MPI_Get_processor_name Returns the processor name. Also returns the length of the name. The buffer for ""name"" must be at least MPI_MAX_PROCESSOR_NAME characters in size. What is returned into ""name"" is implementation dependent - may not be the same as the output of the ""hostname"" or ""host"" shell commands. MPI_Get_processor_name (&name,&resultlength) MPI_GET_PROCESSOR_NAME (name,resultlength,ierr) MPI_Get_version Returns the version and subversion of the MPI standard that's implemented by the library. MPI_Get_version (&version,&subversion) MPI_GET_VERSION (version,subversion,ierr) MPI_Initialized Indicates whether MPI_Init has been called - returns flag as either logical true (1) or false(0). MPI requires that MPI_Init be called once and only once by each process. This may pose a problem for modules that want to use MPI and are prepared to call MPI_Init if necessary. MPI_Initialized solves this problem. MPI_Initialized (&flag) MPI_INITIALIZED (flag,ierr) MPI_Wtime Returns an elapsed wall clock time in seconds (double precision) on the calling processor. MPI_Wtime () MPI_WTIME () MPI_Wtick Returns the resolution in seconds (double precision) of MPI_Wtime. MPI_Wtick () MPI_WTICK () MPI_Finalize Terminates the MPI execution environment. This function should be the last MPI routine called in every MPI program - no other MPI routines may be called after it. MPI_Finalize () MPI_FINALIZE (ierr) Examples: Environment Management Routines      C Language - Environment Management Routines  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28      // required MPI include file      #include ""mpi.h""    #include <stdio.h>     int main(int argc, char *argv[]) {    int  numtasks, rank, len, rc;     char hostname[MPI_MAX_PROCESSOR_NAME];     // initialize MPI      MPI_Init(&argc,&argv);     // get number of tasks     MPI_Comm_size(MPI_COMM_WORLD,&numtasks);     // get my rank      MPI_Comm_rank(MPI_COMM_WORLD,&rank);     // this one is obvious      MPI_Get_processor_name(hostname, &len);    printf (""Number of tasks= %d My rank= %d Running on %s\n"", numtasks,rank,hostname);           // do some work with message passing       // done with MPI      MPI_Finalize();    }        Fortran - Environment Management Routines  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29     program simple     ! required MPI include file    include 'mpif.h'     integer numtasks, rank, len, ierr      character(MPI_MAX_PROCESSOR_NAME) hostname     ! initialize MPI    call MPI_INIT(ierr)     ! get number of tasks    call MPI_COMM_SIZE(MPI_COMM_WORLD, numtasks, ierr)     ! get my rank    call MPI_COMM_RANK(MPI_COMM_WORLD, rank, ierr)     ! this one is obvious    call MPI_GET_PROCESSOR_NAME(hostname, len, ierr)    print *, 'Number of tasks=',numtasks,' My rank=',rank,' Running on=',hostname           ! do some work with message passing       ! done with MPI    call MPI_FINALIZE(ierr)     end   MPI Exercise 1 Getting Started Overview: Login to an LC cluster using your workshop username and OTP token Copy the exercise files to your home directory Familiarize yourself with LC's MPI compilers Write a simple ""Hello World"" MPI program using several MPI Environment Management routines Successfully compile your program Successfully run your program - several different ways GO TO THE EXERCISE HERE Approx. 20 minutes Point to Point Communication Routines General Concepts First, a Simple Example: The value of PI can be calculated in a number of ways. Consider the following method of approximating PI Inscribe a circle in a square Randomly generate points in the square Determine the number of points in the square that are also in the circle Let r be the number of points in the circle divided by the number of points in the square PI ~ 4 r Note that the more points generated, the better the approximation Serial pseudo code for this procedure: npoints = 10000 circle_count = 0  do j = 1,npoints   generate 2 random numbers between 0 and 1   xcoordinate = random1   ycoordinate = random2   if (xcoordinate, ycoordinate) inside circle   then circle_count = circle_count + 1 end do  PI = 4.0*circle_count/npoints  Leads to an ""embarassingly parallel"" solution: Break the loop iterations into chunks that can be executed by different tasks simultaneously. Each task executes its portion of the loop a number of times. Each task can do its work without requiring any information from the other tasks (there are no data dependencies). Master task recieves results from other tasks using send/receive point-to-point operations. Pseudo code solution: red highlights changes for parallelism. npoints = 10000 circle_count = 0  p = number of tasks num = npoints/p find out if I am MASTER or WORKER   do j = 1,num    generate 2 random numbers between 0 and 1   xcoordinate = random1   ycoordinate = random2   if (xcoordinate, ycoordinate) inside circle   then circle_count = circle_count + 1 end do  if I am MASTER receive from WORKERS their circle_counts compute PI (use MASTER and WORKER calculations) else if I am WORKER send to MASTER circle_count endif Example MPI Program in C:   mpi_pi_reduce.c Example MPI Program in Fortran:   mpi_pi_reduce.f Key Concept: Divide work between available tasks which communicate data via point-to-point message passing calls. Types of Point-to-Point Operations: MPI point-to-point operations typically involve message passing between two, and only two, different MPI tasks. One task is performing a send operation and the other task is performing a matching receive operation. There are different types of send and receive routines used for different purposes. For example: Synchronous send Blocking send / blocking receive Non-blocking send / non-blocking receive Buffered send Combined send/receive ""Ready"" send Any type of send routine can be paired with any type of receive routine. MPI also provides several routines associated with send - receive operations, such as those used to wait for a message's arrival or probe to find out if a message has arrived. Buffering: In a perfect world, every send operation would be perfectly synchronized with its matching receive. This is rarely the case. Somehow or other, the MPI implementation must be able to deal with storing data when the two tasks are out of sync. Consider the following two cases: A send operation occurs 5 seconds before the receive is ready - where is the message while the receive is pending? Multiple sends arrive at the same receiving task which can only accept one send at a time - what happens to the messages that are ""backing up""? The MPI implementation (not the MPI standard) decides what happens to data in these types of cases. Typically, a system buffer area is reserved to hold data in transit. For example: System buffer space is: Opaque to the programmer and managed entirely by the MPI library A finite resource that can be easy to exhaust Often mysterious and not well documented Able to exist on the sending side, the receiving side, or both Something that may improve program performance because it allows send - receive operations to be asynchronous. User managed address space (i.e. your program variables) is called the application buffer. MPI also provides for a user managed send buffer. Blocking vs. Non-blocking: Most of the MPI point-to-point routines can be used in either blocking or non-blocking mode. Blocking: A blocking send routine will only ""return"" after it is safe to modify the application buffer (your send data) for reuse. Safe means that modifications will not affect the data intended for the receive task. Safe does not imply that the data was actually received - it may very well be sitting in a system buffer. A blocking send can be synchronous which means there is handshaking occurring with the receive task to confirm a safe send. A blocking send can be asynchronous if a system buffer is used to hold the data for eventual delivery to the receive. A blocking receive only ""returns"" after the data has arrived and is ready for use by the program. Non-blocking: Non-blocking send and receive routines behave similarly - they will return almost immediately. They do not wait for any communication events to complete, such as message copying from user memory to system buffer space or the actual arrival of message. Non-blocking operations simply ""request"" the MPI library to perform the operation when it is able. The user can not predict when that will happen. It is unsafe to modify the application buffer (your variable space) until you know for a fact the requested non-blocking operation was actually performed by the library. There are ""wait"" routines used to do this. Non-blocking communications are primarily used to overlap computation with communication and exploit possible performance gains. Blocking Send Non-blocking Send  myvar = 0;  for (i=1; i<ntasks; i++) {    task = i;    MPI_Send (&myvar ... ... task ...);    myvar = myvar + 2     /* do some work */     }    myvar = 0;  for (i=1; i<ntasks; i++) {    task = i;    MPI_Isend (&myvar ... ... task ...);    myvar = myvar + 2;     /* do some work */     MPI_Wait (...);    }   Safe. Why? Unsafe. Why? Order and Fairness: Order: MPI guarantees that messages will not overtake each other. If a sender sends two messages (Message 1 and Message 2) in succession to the same destination, and both match the same receive, the receive operation will receive Message 1 before Message 2. If a receiver posts two receives (Receive 1 and Receive 2), in succession, and both are looking for the same message, Receive 1 will receive the message before Receive 2. Order rules do not apply if there are multiple threads participating in the communication operations. Fairness: MPI does not guarantee fairness - it's up to the programmer to prevent ""operation starvation"". Example: task 0 sends a message to task 2. However, task 1 sends a competing message that matches task 2's receive. Only one of the sends will complete. Point to Point Communication Routines MPI Message Passing Routine Arguments MPI point-to-point communication routines generally have an argument list that takes one of the following formats: Blocking sends MPI_Send(buffer,count,type,dest,tag,comm) Non-blocking sends MPI_Isend(buffer,count,type,dest,tag,comm,request) Blocking receive MPI_Recv(buffer,count,type,source,tag,comm,status) Non-blocking receive MPI_Irecv(buffer,count,type,source,tag,comm,request) Buffer Program (application) address space that references the data that is to be sent or received. In most cases, this is simply the variable name that is be sent/received. For C programs, this argument is passed by reference and usually must be prepended with an ampersand: &var1 Data Count Indicates the number of data elements of a particular type to be sent. Data Type For reasons of portability, MPI predefines its elementary data types. The table below lists those required by the standard. C Data Types Fortran Data Types MPI_CHAR signed char MPI_CHARACTER character(1) MPI_WCHAR wchar_t - wide character     MPI_SHORT signed short int     MPI_INT signed int MPI_INTEGER MPI_INTEGER1 MPI_INTEGER2 MPI_INTEGER4 integer integer*1 integer*2 integer*4 MPI_LONG signed long int     MPI_LONG_LONG_INT MPI_LONG_LONG signed long long int     MPI_SIGNED_CHAR signed char     MPI_UNSIGNED_CHAR unsigned char     MPI_UNSIGNED_SHORT unsigned short int     MPI_UNSIGNED unsigned int     MPI_UNSIGNED_LONG unsigned long int     MPI_UNSIGNED_LONG_LONG unsigned long long int     MPI_FLOAT float MPI_REAL MPI_REAL2 MPI_REAL4 MPI_REAL8 real real*2 real*4 real*8 MPI_DOUBLE double MPI_DOUBLE_PRECISION double precision MPI_LONG_DOUBLE long double     MPI_C_COMPLEX MPI_C_FLOAT_COMPLEX float _Complex MPI_COMPLEX complex MPI_C_DOUBLE_COMPLEX double _Complex MPI_DOUBLE_COMPLEX double complex MPI_C_LONG_DOUBLE_COMPLEX long double _Complex     MPI_C_BOOL _Bool MPI_LOGICAL logical MPI_C_LONG_DOUBLE_COMPLEX long double _Complex     MPI_INT8_T MPI_INT16_T MPI_INT32_T MPI_INT64_T int8_t int16_t int32_t int64_t     MPI_UINT8_T MPI_UINT16_T MPI_UINT32_T MPI_UINT64_T uint8_t uint16_t uint32_t uint64_t     MPI_BYTE 8 binary digits MPI_BYTE 8 binary digits MPI_PACKED data packed or unpacked with MPI_Pack()/ MPI_Unpack MPI_PACKED data packed or unpacked with MPI_Pack()/ MPI_Unpack Notes: Programmers may also create their own data types (see Derived Data Types). MPI_BYTE and MPI_PACKED do not correspond to standard C or Fortran types. Types shown in GRAY FONT are recommended if possible. Some implementations may include additional elementary data types (MPI_LOGICAL2, MPI_COMPLEX32, etc.). Check the MPI header file. Destination An argument to send routines that indicates the process where a message should be delivered. Specified as the rank of the receiving process. Source An argument to receive routines that indicates the originating process of the message. Specified as the rank of the sending process. This may be set to the wild card MPI_ANY_SOURCE to receive a message from any task. Tag Arbitrary non-negative integer assigned by the programmer to uniquely identify a message. Send and receive operations should match message tags. For a receive operation, the wild card MPI_ANY_TAG can be used to receive any message regardless of its tag. The MPI standard guarantees that integers 0-32767 can be used as tags, but most implementations allow a much larger range than this. Communicator Indicates the communication context, or set of processes for which the source or destination fields are valid. Unless the programmer is explicitly creating new communicators, the predefined communicator MPI_COMM_WORLD is usually used. Status For a receive operation, indicates the source of the message and the tag of the message. In C, this argument is a pointer to a predefined structure MPI_Status (ex. stat.MPI_SOURCE stat.MPI_TAG). In Fortran, it is an integer array of size MPI_STATUS_SIZE (ex. stat(MPI_SOURCE) stat(MPI_TAG)). Additionally, the actual number of bytes received is obtainable from Status via the MPI_Get_count routine. The constants MPI_STATUS_IGNORE and MPI_STATUSES_IGNORE can be substituted if a message's source, tag or size will be be queried later. Request Used by non-blocking send and receive operations. Since non-blocking operations may return before the requested system buffer space is obtained, the system issues a unique ""request number"". The programmer uses this system assigned ""handle"" later (in a WAIT type routine) to determine completion of the non-blocking operation. In C, this argument is a pointer to a predefined structure MPI_Request. In Fortran, it is an integer. Point to Point Communication Routines Blocking Message Passing Routines The more commonly used MPI blocking message passing routines are described below. MPI_Send Basic blocking send operation. Routine returns only after the application buffer in the sending task is free for reuse. Note that this routine may be implemented differently on different systems. The MPI standard permits the use of a system buffer but does not require it. Some implementations may actually use a synchronous send (discussed below) to implement the basic blocking send. MPI_Send (&buf,count,datatype,dest,tag,comm) MPI_SEND (buf,count,datatype,dest,tag,comm,ierr) MPI_Recv Receive a message and block until the requested data is available in the application buffer in the receiving task. MPI_Recv (&buf,count,datatype,source,tag,comm,&status) MPI_RECV (buf,count,datatype,source,tag,comm,status,ierr) MPI_Ssend Synchronous blocking send: Send a message and block until the application buffer in the sending task is free for reuse and the destination process has started to receive the message. MPI_Ssend (&buf,count,datatype,dest,tag,comm) MPI_SSEND (buf,count,datatype,dest,tag,comm,ierr) MPI_Sendrecv Send a message and post a receive before blocking. Will block until the sending application buffer is free for reuse and until the receiving application buffer contains the received message. MPI_Sendrecv (&sendbuf,sendcount,sendtype,dest,sendtag, ...... &recvbuf,recvcount,recvtype,source,recvtag, ...... comm,&status) MPI_SENDRECV (sendbuf,sendcount,sendtype,dest,sendtag, ...... recvbuf,recvcount,recvtype,source,recvtag, ...... comm,status,ierr) MPI_Wait MPI_Waitany MPI_Waitall MPI_Waitsome MPI_Wait blocks until a specified non-blocking send or receive operation has completed. For multiple non-blocking operations, the programmer can specify any, all or some completions. MPI_Wait (&request,&status) MPI_Waitany (count,&array_of_requests,&index,&status) MPI_Waitall (count,&array_of_requests,&array_of_statuses) MPI_Waitsome (incount,&array_of_requests,&outcount, ...... &array_of_offsets, &array_of_statuses) MPI_WAIT (request,status,ierr) MPI_WAITANY (count,array_of_requests,index,status,ierr) MPI_WAITALL (count,array_of_requests,array_of_statuses, ...... ierr) MPI_WAITSOME (incount,array_of_requests,outcount, ...... array_of_offsets, array_of_statuses,ierr) MPI_Probe Performs a blocking test for a message. The ""wildcards"" MPI_ANY_SOURCE and MPI_ANY_TAG may be used to test for a message from any source or with any tag. For the C routine, the actual source and tag will be returned in the status structure as status.MPI_SOURCE and status.MPI_TAG. For the Fortran routine, they will be returned in the integer array status(MPI_SOURCE) and status(MPI_TAG). MPI_Probe (source,tag,comm,&status) MPI_PROBE (source,tag,comm,status,ierr) MPI_Get_count Returns the source, tag and number of elements of datatype received. Can be used with both blocking and non-blocking receive operations. For the C routine, the actual source and tag will be returned in the status structure as status.MPI_SOURCE and status.MPI_TAG. For the Fortran routine, they will be returned in the integer array status(MPI_SOURCE) and status(MPI_TAG). MPI_Get_count (&status,datatype,&count) MPI_GET_COUNT (status,datatype,count,ierr) Examples: Blocking Message Passing Routines Task 0 pings task 1 and awaits return ping      C Language - Blocking Message Passing Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35     #include ""mpi.h""    #include <stdio.h>     main(int argc, char *argv[])  {    int numtasks, rank, dest, source, rc, count, tag=1;      char inmsg, outmsg='x';    MPI_Status Stat;   // required variable for receive routines     MPI_Init(&argc,&argv);    MPI_Comm_size(MPI_COMM_WORLD, &numtasks);    MPI_Comm_rank(MPI_COMM_WORLD, &rank);     // task 0 sends to task 1 and waits to receive a return message    if (rank == 0) {      dest = 1;      source = 1;      MPI_Send(&outmsg, 1, MPI_CHAR, dest, tag, MPI_COMM_WORLD);      MPI_Recv(&inmsg, 1, MPI_CHAR, source, tag, MPI_COMM_WORLD, &Stat);      }      // task 1 waits for task 0 message then returns a message    else if (rank == 1) {      dest = 0;      source = 0;      MPI_Recv(&inmsg, 1, MPI_CHAR, source, tag, MPI_COMM_WORLD, &Stat);      MPI_Send(&outmsg, 1, MPI_CHAR, dest, tag, MPI_COMM_WORLD);      }     // query recieve Stat variable and print message details    MPI_Get_count(&Stat, MPI_CHAR, &count);    printf(""Task %d: Received %d char(s) from task %d with tag %d \n"",           rank, count, Stat.MPI_SOURCE, Stat.MPI_TAG);     MPI_Finalize();    }        Fortran - Blocking Message Passing Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36     program ping    include 'mpif.h'     integer numtasks, rank, dest, source, count, tag, ierr    integer stat(MPI_STATUS_SIZE)   ! required variable for receive routines    character inmsg, outmsg    outmsg = 'x'    tag = 1     call MPI_INIT(ierr)    call MPI_COMM_RANK(MPI_COMM_WORLD, rank, ierr)    call MPI_COMM_SIZE(MPI_COMM_WORLD, numtasks, ierr)     ! task 0 sends to task 1 and waits to receive a return message    if (rank .eq. 0) then       dest = 1       source = 1       call MPI_SEND(outmsg, 1, MPI_CHARACTER, dest, tag, MPI_COMM_WORLD, ierr)       call MPI_RECV(inmsg, 1, MPI_CHARACTER, source, tag, MPI_COMM_WORLD, stat, ierr)     ! task 1 waits for task 0 message then returns a message    else if (rank .eq. 1) then       dest = 0       source = 0       call MPI_RECV(inmsg, 1, MPI_CHARACTER, source, tag, MPI_COMM_WORLD, stat, err)       call MPI_SEND(outmsg, 1, MPI_CHARACTER, dest, tag, MPI_COMM_WORLD, err)    endif     ! query recieve Stat variable and print message details    call MPI_GET_COUNT(stat, MPI_CHARACTER, count, ierr)    print *, 'Task ',rank,': Received', count, 'char(s) from task', &             stat(MPI_SOURCE), 'with tag',stat(MPI_TAG)     call MPI_FINALIZE(ierr)     end   Point to Point Communication Routines Non-blocking Message Passing Routines The more commonly used MPI non-blocking message passing routines are described below. MPI_Isend Identifies an area in memory to serve as a send buffer. Processing continues immediately without waiting for the message to be copied out from the application buffer. A communication request handle is returned for handling the pending message status. The program should not modify the application buffer until subsequent calls to MPI_Wait or MPI_Test indicate that the non-blocking send has completed. MPI_Isend (&buf,count,datatype,dest,tag,comm,&request) MPI_ISEND (buf,count,datatype,dest,tag,comm,request,ierr) MPI_Irecv Identifies an area in memory to serve as a receive buffer. Processing continues immediately without actually waiting for the message to be received and copied into the the application buffer. A communication request handle is returned for handling the pending message status. The program must use calls to MPI_Wait or MPI_Test to determine when the non-blocking receive operation completes and the requested message is available in the application buffer. MPI_Irecv (&buf,count,datatype,source,tag,comm,&request) MPI_IRECV (buf,count,datatype,source,tag,comm,request,ierr) MPI_Issend Non-blocking synchronous send. Similar to MPI_Isend(), except MPI_Wait() or MPI_Test() indicates when the destination process has received the message. MPI_Issend (&buf,count,datatype,dest,tag,comm,&request) MPI_ISSEND (buf,count,datatype,dest,tag,comm,request,ierr) MPI_Test MPI_Testany MPI_Testall MPI_Testsome MPI_Test checks the status of a specified non-blocking send or receive operation. The ""flag"" parameter is returned logical true (1) if the operation has completed, and logical false (0) if not. For multiple non-blocking operations, the programmer can specify any, all or some completions. MPI_Test (&request,&flag,&status) MPI_Testany (count,&array_of_requests,&index,&flag,&status) MPI_Testall (count,&array_of_requests,&flag,&array_of_statuses) MPI_Testsome (incount,&array_of_requests,&outcount, ...... &array_of_offsets, &array_of_statuses) MPI_TEST (request,flag,status,ierr) MPI_TESTANY (count,array_of_requests,index,flag,status,ierr) MPI_TESTALL (count,array_of_requests,flag,array_of_statuses,ierr) MPI_TESTSOME (incount,array_of_requests,outcount, ...... array_of_offsets, array_of_statuses,ierr) MPI_Iprobe Performs a non-blocking test for a message. The ""wildcards"" MPI_ANY_SOURCE and MPI_ANY_TAG may be used to test for a message from any source or with any tag. The integer ""flag"" parameter is returned logical true (1) if a message has arrived, and logical false (0) if not. For the C routine, the actual source and tag will be returned in the status structure as status.MPI_SOURCE and status.MPI_TAG. For the Fortran routine, they will be returned in the integer array status(MPI_SOURCE) and status(MPI_TAG). MPI_Iprobe (source,tag,comm,&flag,&status) MPI_IPROBE (source,tag,comm,flag,status,ierr) Examples: Non-blocking Message Passing Routines Nearest neighbor exchange in a ring topology      C Language - Non-blocking Message Passing Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34     #include ""mpi.h""    #include <stdio.h>     main(int argc, char *argv[])  {    int numtasks, rank, next, prev, buf[2], tag1=1, tag2=2;    MPI_Request reqs[4];   // required variable for non-blocking calls    MPI_Status stats[4];   // required variable for Waitall routine     MPI_Init(&argc,&argv);    MPI_Comm_size(MPI_COMM_WORLD, &numtasks);    MPI_Comm_rank(MPI_COMM_WORLD, &rank);        // determine left and right neighbors    prev = rank-1;    next = rank+1;    if (rank == 0)  prev = numtasks - 1;    if (rank == (numtasks - 1))  next = 0;     // post non-blocking receives and sends for neighbors    MPI_Irecv(&buf[0], 1, MPI_INT, prev, tag1, MPI_COMM_WORLD, &reqs[0]);    MPI_Irecv(&buf[1], 1, MPI_INT, next, tag2, MPI_COMM_WORLD, &reqs[1]);     MPI_Isend(&rank, 1, MPI_INT, prev, tag2, MPI_COMM_WORLD, &reqs[2]);    MPI_Isend(&rank, 1, MPI_INT, next, tag1, MPI_COMM_WORLD, &reqs[3]);          // do some work while sends/receives progress in background     // wait for all non-blocking operations to complete    MPI_Waitall(4, reqs, stats);          // continue - do more work     MPI_Finalize();    }        Fortran - Non-blocking Message Passing Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40     program ringtopo    include 'mpif.h'     integer numtasks, rank, next, prev, buf(2), tag1, tag2, ierr    integer reqs(4)   ! required variable for non-blocking calls     integer stats(MPI_STATUS_SIZE,4)   ! required variable for WAITALL routine     tag1 = 1    tag2 = 2     call MPI_INIT(ierr)    call MPI_COMM_RANK(MPI_COMM_WORLD, rank, ierr)    call MPI_COMM_SIZE(MPI_COMM_WORLD, numtasks, ierr)     ! determine left and right neighbors     prev = rank - 1    next = rank + 1    if (rank .eq. 0) then       prev = numtasks - 1    endif    if (rank .eq. numtasks - 1) then       next = 0    endif     ! post non-blocking receives and sends for neighbors     call MPI_IRECV(buf(1), 1, MPI_INTEGER, prev, tag1, MPI_COMM_WORLD, reqs(1), ierr)    call MPI_IRECV(buf(2), 1, MPI_INTEGER, next, tag2, MPI_COMM_WORLD, reqs(2), ierr)     call MPI_ISEND(rank, 1, MPI_INTEGER, prev, tag2, MPI_COMM_WORLD, reqs(3), ierr)    call MPI_ISEND(rank, 1, MPI_INTEGER, next, tag1, MPI_COMM_WORLD, reqs(4), ierr)        ! do some work while sends/receives progress in background     ! wait for all non-blocking operations to complete     call MPI_WAITALL(4, reqs, stats, ierr);        ! continue - do more work     call MPI_FINALIZE(ierr)     end   MPI Exercise 2 Point-to-Point Message Passing Overview: Login to the LC workshop cluster, if you are not already logged in Using your ""Hello World"" MPI program from Exercise 1, add MPI blocking point-to-point routines to send and receive messages Successfully compile your program Successfully run your program - several different ways Try the same thing with nonblocking send/receive routines GO TO THE EXERCISE HERE Approx. 20 minutes Collective Communication Routines Types of Collective Operations: Synchronization - processes wait until all members of the group have reached the synchronization point. Data Movement - broadcast, scatter/gather, all to all. Collective Computation (reductions) - one member of the group collects data from the other members and performs an operation (min, max, add, multiply, etc.) on that data. Scope: Collective communication routines must involve all processes within the scope of a communicator. All processes are by default, members in the communicator MPI_COMM_WORLD. Additional communicators can be defined by the programmer. See the Group and Communicator Management Routines section for details. Unexpected behavior, including program failure, can occur if even one task in the communicator doesn't participate. It is the programmer's responsibility to ensure that all processes within a communicator participate in any collective operations. Programming Considerations and Restrictions: Collective communication routines do not take message tag arguments. Collective operations within subsets of processes are accomplished by first partitioning the subsets into new groups and then attaching the new groups to new communicators (discussed in the Group and Communicator Management Routines section). Can only be used with MPI predefined datatypes - not with MPI Derived Data Types. MPI-2 extended most collective operations to allow data movement between intercommunicators (not covered here). With MPI-3, collective operations can be blocking or non-blocking. Only blocking operations are covered in this tutorial. Collective Communication Routines MPI_Barrier Synchronization operation. Creates a barrier synchronization in a group. Each task, when reaching the MPI_Barrier call, blocks until all tasks in the group reach the same MPI_Barrier call. Then all tasks are free to proceed. MPI_Barrier (comm) MPI_BARRIER (comm,ierr) MPI_Bcast Data movement operation. Broadcasts (sends) a message from the process with rank ""root"" to all other processes in the group. MPI_Bcast (&buffer,count,datatype,root,comm) MPI_BCAST (buffer,count,datatype,root,comm,ierr) MPI_Scatter Data movement operation. Distributes distinct messages from a single source task to each task in the group. MPI_Scatter (&sendbuf,sendcnt,sendtype,&recvbuf, ...... recvcnt,recvtype,root,comm) MPI_SCATTER (sendbuf,sendcnt,sendtype,recvbuf, ...... recvcnt,recvtype,root,comm,ierr) MPI_Gather Data movement operation. Gathers distinct messages from each task in the group to a single destination task. This routine is the reverse operation of MPI_Scatter. MPI_Gather (&sendbuf,sendcnt,sendtype,&recvbuf, ...... recvcount,recvtype,root,comm) MPI_GATHER (sendbuf,sendcnt,sendtype,recvbuf, ...... recvcount,recvtype,root,comm,ierr) MPI_Allgather Data movement operation. Concatenation of data to all tasks in a group. Each task in the group, in effect, performs a one-to-all broadcasting operation within the group. MPI_Allgather (&sendbuf,sendcount,sendtype,&recvbuf, ...... recvcount,recvtype,comm) MPI_ALLGATHER (sendbuf,sendcount,sendtype,recvbuf, ...... recvcount,recvtype,comm,info) MPI_Reduce Collective computation operation. Applies a reduction operation on all tasks in the group and places the result in one task. MPI_Reduce (&sendbuf,&recvbuf,count,datatype,op,root,comm) MPI_REDUCE (sendbuf,recvbuf,count,datatype,op,root,comm,ierr) The predefined MPI reduction operations appear below. Users can also define their own reduction functions by using the MPI_Op_create routine. MPI Reduction Operation C Data Types Fortran Data Type MPI_MAX maximum integer, float integer, real, complex MPI_MIN minimum integer, float integer, real, complex MPI_SUM sum integer, float integer, real, complex MPI_PROD product integer, float integer, real, complex MPI_LAND logical AND integer logical MPI_BAND bit-wise AND integer, MPI_BYTE integer, MPI_BYTE MPI_LOR logical OR integer logical MPI_BOR bit-wise OR integer, MPI_BYTE integer, MPI_BYTE MPI_LXOR logical XOR integer logical MPI_BXOR bit-wise XOR integer, MPI_BYTE integer, MPI_BYTE MPI_MAXLOC max value and location float, double and long double real, complex,double precision MPI_MINLOC min value and location float, double and long double real, complex, double precision MPI_Allreduce Collective computation operation + data movement. Applies a reduction operation and places the result in all tasks in the group. This is equivalent to an MPI_Reduce followed by an MPI_Bcast. MPI_Allreduce (&sendbuf,&recvbuf,count,datatype,op,comm) MPI_ALLREDUCE (sendbuf,recvbuf,count,datatype,op,comm,ierr) MPI_Reduce_scatter Collective computation operation + data movement. First does an element-wise reduction on a vector across all tasks in the group. Next, the result vector is split into disjoint segments and distributed across the tasks. This is equivalent to an MPI_Reduce followed by an MPI_Scatter operation. MPI_Reduce_scatter (&sendbuf,&recvbuf,recvcount,datatype, ...... op,comm) MPI_REDUCE_SCATTER (sendbuf,recvbuf,recvcount,datatype, ...... op,comm,ierr) MPI_Alltoall Data movement operation. Each task in a group performs a scatter operation, sending a distinct message to all the tasks in the group in order by index. MPI_Alltoall (&sendbuf,sendcount,sendtype,&recvbuf, ...... recvcnt,recvtype,comm) MPI_ALLTOALL (sendbuf,sendcount,sendtype,recvbuf, ...... recvcnt,recvtype,comm,ierr) MPI_Scan Performs a scan operation with respect to a reduction operation across a task group. MPI_Scan (&sendbuf,&recvbuf,count,datatype,op,comm) MPI_SCAN (sendbuf,recvbuf,count,datatype,op,comm,ierr) Examples: Collective Communications Perform a scatter operation on the rows of an array      C Language - Collective Communications Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33     #include ""mpi.h""    #include <stdio.h>    #define SIZE 4     main(int argc, char *argv[])  {    int numtasks, rank, sendcount, recvcount, source;    float sendbuf[SIZE][SIZE] = {      {1.0, 2.0, 3.0, 4.0},      {5.0, 6.0, 7.0, 8.0},      {9.0, 10.0, 11.0, 12.0},      {13.0, 14.0, 15.0, 16.0}  };    float recvbuf[SIZE];     MPI_Init(&argc,&argv);    MPI_Comm_rank(MPI_COMM_WORLD, &rank);    MPI_Comm_size(MPI_COMM_WORLD, &numtasks);     if (numtasks == SIZE) {      // define source task and elements to send/receive, then perform collective scatter      source = 1;      sendcount = SIZE;      recvcount = SIZE;      MPI_Scatter(sendbuf,sendcount,MPI_FLOAT,recvbuf,recvcount,                  MPI_FLOAT,source,MPI_COMM_WORLD);       printf(""rank= %d  Results: %f %f %f %f\n"",rank,recvbuf[0],             recvbuf[1],recvbuf[2],recvbuf[3]);      }    else      printf(""Must specify %d processors. Terminating.\n"",SIZE);     MPI_Finalize();    }        Fortran - Collective Communications Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36     program scatter    include 'mpif.h'     integer SIZE    parameter(SIZE=4)    integer numtasks, rank, sendcount, recvcount, source, ierr    real*4 sendbuf(SIZE,SIZE), recvbuf(SIZE)     ! Fortran stores this array in column major order, so the     ! scatter will actually scatter columns, not rows.    data sendbuf /1.0, 2.0, 3.0, 4.0, &                  5.0, 6.0, 7.0, 8.0, &                  9.0, 10.0, 11.0, 12.0, &                  13.0, 14.0, 15.0, 16.0 /     call MPI_INIT(ierr)    call MPI_COMM_RANK(MPI_COMM_WORLD, rank, ierr)    call MPI_COMM_SIZE(MPI_COMM_WORLD, numtasks, ierr)     if (numtasks .eq. SIZE) then       ! define source task and elements to send/receive, then perform collective scatter       source = 1       sendcount = SIZE       recvcount = SIZE       call MPI_SCATTER(sendbuf, sendcount, MPI_REAL, recvbuf, recvcount, MPI_REAL, &                        source, MPI_COMM_WORLD, ierr)        print *, 'rank= ',rank,' Results: ',recvbuf      else       print *, 'Must specify',SIZE,' processors.  Terminating.'     endif     call MPI_FINALIZE(ierr)     end   Sample program output:  rank= 0  Results: 1.000000 2.000000 3.000000 4.000000 rank= 1  Results: 5.000000 6.000000 7.000000 8.000000 rank= 2  Results: 9.000000 10.000000 11.000000 12.000000 rank= 3  Results: 13.000000 14.000000 15.000000 16.000000  Derived Data Types As previously mentioned, MPI predefines its primitive data types: C Data Types Fortran Data Types  MPI_CHAR MPI_WCHAR MPI_SHORT MPI_INT MPI_LONG MPI_LONG_LONG_INT  MPI_LONG_LONG	 	  MPI_SIGNED_CHAR MPI_UNSIGNED_CHAR MPI_UNSIGNED_SHORT MPI_UNSIGNED_LONG MPI_UNSIGNED MPI_FLOAT MPI_DOUBLE MPI_LONG_DOUBLE   MPI_C_COMPLEX MPI_C_FLOAT_COMPLEX MPI_C_DOUBLE_COMPLEX MPI_C_LONG_DOUBLE_COMPLEX	 	  MPI_C_BOOL MPI_LOGICAL MPI_C_LONG_DOUBLE_COMPLEX 	  MPI_INT8_T  MPI_INT16_T MPI_INT32_T  MPI_INT64_T	 	  MPI_UINT8_T  MPI_UINT16_T  MPI_UINT32_T  MPI_UINT64_T MPI_BYTE MPI_PACKED   MPI_CHARACTER MPI_INTEGER MPI_INTEGER1  MPI_INTEGER2 MPI_INTEGER4 MPI_REAL MPI_REAL2  MPI_REAL4 MPI_REAL8 MPI_DOUBLE_PRECISION MPI_COMPLEX MPI_DOUBLE_COMPLEX MPI_LOGICAL MPI_BYTE MPI_PACKED  MPI also provides facilities for you to define your own data structures based upon sequences of the MPI primitive data types. Such user defined structures are called derived data types. Primitive data types are contiguous. Derived data types allow you to specify non-contiguous data in a convenient manner and to treat it as though it was contiguous. MPI provides several methods for constructing derived data types: Contiguous Vector Indexed Struct Derived Data Type Routines MPI_Type_contiguous The simplest constructor. Produces a new data type by making count copies of an existing data type. MPI_Type_contiguous (count,oldtype,&newtype) MPI_TYPE_CONTIGUOUS (count,oldtype,newtype,ierr) MPI_Type_vector MPI_Type_hvector Similar to contiguous, but allows for regular gaps (stride) in the displacements. MPI_Type_hvector is identical to MPI_Type_vector except that stride is specified in bytes. MPI_Type_vector (count,blocklength,stride,oldtype,&newtype) MPI_TYPE_VECTOR (count,blocklength,stride,oldtype,newtype,ierr) MPI_Type_indexed MPI_Type_hindexed An array of displacements of the input data type is provided as the map for the new data type. MPI_Type_hindexed is identical to MPI_Type_indexed except that offsets are specified in bytes. MPI_Type_indexed (count,blocklens[],offsets[],old_type,&newtype) MPI_TYPE_INDEXED (count,blocklens(),offsets(),old_type,newtype,ierr) MPI_Type_struct The new data type is formed according to completely defined map of the component data types. NOTE: This function is deprecated in MPI-2.0 and replaced by MPI_Type_create_struct in MPI-3.0 MPI_Type_struct (count,blocklens[],offsets[],old_types,&newtype) MPI_TYPE_STRUCT (count,blocklens(),offsets(),old_types,newtype,ierr) MPI_Type_extent Returns the size in bytes of the specified data type. Useful for the MPI subroutines that require specification of offsets in bytes. NOTE: This function is deprecated in MPI-2.0 and replaced by MPI_Type_get_extent in MPI-3.0 MPI_Type_extent (datatype,&extent) MPI_TYPE_EXTENT (datatype,extent,ierr) MPI_Type_commit Commits new datatype to the system. Required for all user constructed (derived) datatypes. MPI_Type_commit (&datatype) MPI_TYPE_COMMIT (datatype,ierr) MPI_Type_free Deallocates the specified datatype object. Use of this routine is especially important to prevent memory exhaustion if many datatype objects are created, as in a loop. MPI_Type_free (&datatype) MPI_TYPE_FREE (datatype,ierr) Examples: Contiguous Derived Data Type Create a data type representing a row of an array and distribute a different row to all processes.      C Language - Contiguous Derived Data Type Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43     #include ""mpi.h""    #include <stdio.h>    #define SIZE 4     main(int argc, char *argv[])  {    int numtasks, rank, source=0, dest, tag=1, i;    float a[SIZE][SIZE] =      {1.0, 2.0, 3.0, 4.0,       5.0, 6.0, 7.0, 8.0,       9.0, 10.0, 11.0, 12.0,       13.0, 14.0, 15.0, 16.0};    float b[SIZE];     MPI_Status stat;    MPI_Datatype rowtype;   // required variable     MPI_Init(&argc,&argv);    MPI_Comm_rank(MPI_COMM_WORLD, &rank);    MPI_Comm_size(MPI_COMM_WORLD, &numtasks);     // create contiguous derived data type    MPI_Type_contiguous(SIZE, MPI_FLOAT, &rowtype);    MPI_Type_commit(&rowtype);     if (numtasks == SIZE) {       // task 0 sends one element of rowtype to all tasks       if (rank == 0) {          for (i=0; i<numtasks; i++)            MPI_Send(&a[i][0], 1, rowtype, i, tag, MPI_COMM_WORLD);          }        // all tasks receive rowtype data from task 0       MPI_Recv(b, SIZE, MPI_FLOAT, source, tag, MPI_COMM_WORLD, &stat);       printf(""rank= %d  b= %3.1f %3.1f %3.1f %3.1f\n"",              rank,b[0],b[1],b[2],b[3]);       }    else       printf(""Must specify %d processors. Terminating.\n"",SIZE);     // free datatype when done using it    MPI_Type_free(&rowtype);    MPI_Finalize();    }        Fortran - Contiguous Derived Data Type Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46     program contiguous    include 'mpif.h'     integer SIZE    parameter(SIZE=4)    integer numtasks, rank, source, dest, tag, i,  ierr    real*4 a(0:SIZE-1,0:SIZE-1), b(0:SIZE-1)    integer stat(MPI_STATUS_SIZE)    integer columntype   ! required variable    tag = 1     ! Fortran stores this array in column major order    data a  /1.0, 2.0, 3.0, 4.0, &             5.0, 6.0, 7.0, 8.0, &             9.0, 10.0, 11.0, 12.0, &              13.0, 14.0, 15.0, 16.0 /     call MPI_INIT(ierr)    call MPI_COMM_RANK(MPI_COMM_WORLD, rank, ierr)    call MPI_COMM_SIZE(MPI_COMM_WORLD, numtasks, ierr)     ! create contiguous derived data type    call MPI_TYPE_CONTIGUOUS(SIZE, MPI_REAL, columntype, ierr)    call MPI_TYPE_COMMIT(columntype, ierr)       if (numtasks .eq. SIZE) then       ! task 0 sends one element of columntype to all tasks       if (rank .eq. 0) then          do i=0, numtasks-1          call MPI_SEND(a(0,i), 1, columntype, i, tag, MPI_COMM_WORLD,ierr)          end do       endif        ! all tasks receive columntype data from task 0       source = 0       call MPI_RECV(b, SIZE, MPI_REAL, source, tag, MPI_COMM_WORLD, stat, ierr)       print *, 'rank= ',rank,' b= ',b    else       print *, 'Must specify',SIZE,' processors.  Terminating.'     endif     ! free datatype when done using it    call MPI_TYPE_FREE(columntype, ierr)    call MPI_FINALIZE(ierr)     end   Sample program output:  rank= 0  b= 1.0 2.0 3.0 4.0 rank= 1  b= 5.0 6.0 7.0 8.0 rank= 2  b= 9.0 10.0 11.0 12.0 rank= 3  b= 13.0 14.0 15.0 16.0  Examples: Vector Derived Data Type Create a data type representing a column of an array and distribute different columns to all processes.      C Language - Vector Derived Data Type Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44     #include ""mpi.h""    #include <stdio.h>    #define SIZE 4     main(int argc, char *argv[])  {    int numtasks, rank, source=0, dest, tag=1, i;    float a[SIZE][SIZE] =       {1.0, 2.0, 3.0, 4.0,         5.0, 6.0, 7.0, 8.0,        9.0, 10.0, 11.0, 12.0,      13.0, 14.0, 15.0, 16.0};    float b[SIZE];      MPI_Status stat;    MPI_Datatype columntype;   // required variable      MPI_Init(&argc,&argv);    MPI_Comm_rank(MPI_COMM_WORLD, &rank);    MPI_Comm_size(MPI_COMM_WORLD, &numtasks);        // create vector derived data type    MPI_Type_vector(SIZE, 1, SIZE, MPI_FLOAT, &columntype);    MPI_Type_commit(&columntype);     if (numtasks == SIZE) {       // task 0 sends one element of columntype to all tasks       if (rank == 0) {          for (i=0; i<numtasks; i++)              MPI_Send(&a[0][i], 1, columntype, i, tag, MPI_COMM_WORLD);          }         // all tasks receive columntype data from task 0       MPI_Recv(b, SIZE, MPI_FLOAT, source, tag, MPI_COMM_WORLD, &stat);       printf(""rank= %d  b= %3.1f %3.1f %3.1f %3.1f\n"",              rank,b[0],b[1],b[2],b[3]);       }    else       printf(""Must specify %d processors. Terminating.\n"",SIZE);     // free datatype when done using it    MPI_Type_free(&columntype);    MPI_Finalize();    }        Fortran - Vector Derived Data Type Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46     program vector    include 'mpif.h'     integer SIZE    parameter(SIZE=4)    integer numtasks, rank, source, dest, tag, i,  ierr    real*4 a(0:SIZE-1,0:SIZE-1), b(0:SIZE-1)    integer stat(MPI_STATUS_SIZE)    integer rowtype   ! required variable    tag = 1     ! Fortran stores this array in column major order    data a  /1.0, 2.0, 3.0, 4.0, &             5.0, 6.0, 7.0, 8.0,  &             9.0, 10.0, 11.0, 12.0, &             13.0, 14.0, 15.0, 16.0 /     call MPI_INIT(ierr)    call MPI_COMM_RANK(MPI_COMM_WORLD, rank, ierr)    call MPI_COMM_SIZE(MPI_COMM_WORLD, numtasks, ierr)     ! create vector derived data type    call MPI_TYPE_VECTOR(SIZE, 1, SIZE, MPI_REAL, rowtype, ierr)    call MPI_TYPE_COMMIT(rowtype, ierr)       if (numtasks .eq. SIZE) then       ! task 0 sends one element of rowtype to all tasks       if (rank .eq. 0) then          do i=0, numtasks-1          call MPI_SEND(a(i,0), 1, rowtype, i, tag, MPI_COMM_WORLD, ierr)          end do       endif        ! all tasks receive rowtype data from task 0       source = 0       call MPI_RECV(b, SIZE, MPI_REAL, source, tag, MPI_COMM_WORLD, stat, ierr)       print *, 'rank= ',rank,' b= ',b    else       print *, 'Must specify',SIZE,' processors.  Terminating.'     endif     ! free datatype when done using it    call MPI_TYPE_FREE(rowtype, ierr)    call MPI_FINALIZE(ierr)     end   Sample program output:  rank= 0  b= 1.0 5.0 9.0 13.0 rank= 1  b= 2.0 6.0 10.0 14.0 rank= 2  b= 3.0 7.0 11.0 15.0 rank= 3  b= 4.0 8.0 12.0 16.0  Examples: Indexed Derived Data Type Create a datatype by extracting variable portions of an array and distribute to all tasks.      C Language - Indexed Derived Data Type Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43     #include ""mpi.h""    #include <stdio.h>    #define NELEMENTS 6     main(int argc, char *argv[])  {    int numtasks, rank, source=0, dest, tag=1, i;    int blocklengths[2], displacements[2];    float a[16] =       {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0,        9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0};    float b[NELEMENTS];      MPI_Status stat;    MPI_Datatype indextype;   // required variable     MPI_Init(&argc,&argv);    MPI_Comm_rank(MPI_COMM_WORLD, &rank);    MPI_Comm_size(MPI_COMM_WORLD, &numtasks);     blocklengths[0] = 4;    blocklengths[1] = 2;    displacements[0] = 5;    displacements[1] = 12;        // create indexed derived data type    MPI_Type_indexed(2, blocklengths, displacements, MPI_FLOAT, &indextype);    MPI_Type_commit(&indextype);     if (rank == 0) {      for (i=0; i<numtasks; i++)        // task 0 sends one element of indextype to all tasks         MPI_Send(a, 1, indextype, i, tag, MPI_COMM_WORLD);      }     // all tasks receive indextype data from task 0    MPI_Recv(b, NELEMENTS, MPI_FLOAT, source, tag, MPI_COMM_WORLD, &stat);    printf(""rank= %d  b= %3.1f %3.1f %3.1f %3.1f %3.1f %3.1f\n"",           rank,b[0],b[1],b[2],b[3],b[4],b[5]);        // free datatype when done using it    MPI_Type_free(&indextype);    MPI_Finalize();    }        Fortran - Indexed Derived Data Type Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47     program indexed    include 'mpif.h'     integer NELEMENTS    parameter(NELEMENTS=6)    integer numtasks, rank, source, dest, tag, i,  ierr    integer blocklengths(0:1), displacements(0:1)    real*4 a(0:15), b(0:NELEMENTS-1)    integer stat(MPI_STATUS_SIZE)    integer indextype   ! required variable    tag = 1     data a  /1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, &             9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0 /     call MPI_INIT(ierr)    call MPI_COMM_RANK(MPI_COMM_WORLD, rank, ierr)    call MPI_COMM_SIZE(MPI_COMM_WORLD, numtasks, ierr)     blocklengths(0) = 4    blocklengths(1) = 2    displacements(0) = 5    displacements(1) = 12     ! create indexed derived data type    call MPI_TYPE_INDEXED(2, blocklengths, displacements, MPI_REAL, &                          indextype, ierr)    call MPI_TYPE_COMMIT(indextype, ierr)       if (rank .eq. 0) then       ! task 0 sends one element of indextype to all tasks       do i=0, numtasks-1       call MPI_SEND(a, 1, indextype, i, tag, MPI_COMM_WORLD, ierr)       end do    endif     ! all tasks receive indextype data from task 0    source = 0    call MPI_RECV(b, NELEMENTS, MPI_REAL, source, tag, MPI_COMM_WORLD, &                  stat, ierr)    print *, 'rank= ',rank,' b= ',b     ! free datatype when done using it    call MPI_TYPE_FREE(indextype, ierr)    call MPI_FINALIZE(ierr)     end   Sample program output:  rank= 0  b= 6.0 7.0 8.0 9.0 13.0 14.0 rank= 1  b= 6.0 7.0 8.0 9.0 13.0 14.0 rank= 2  b= 6.0 7.0 8.0 9.0 13.0 14.0 rank= 3  b= 6.0 7.0 8.0 9.0 13.0 14.0  Examples: Struct Derived Data Type Create a data type that represents a particle and distribute an array of such particles to all processes.      C Language - Struct Derived Data Type Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66     #include ""mpi.h""    #include <stdio.h>    #define NELEM 25     main(int argc, char *argv[])  {    int numtasks, rank, source=0, dest, tag=1, i;     typedef struct {      float x, y, z;      float velocity;      int  n, type;      }          Particle;    Particle     p[NELEM], particles[NELEM];    MPI_Datatype particletype, oldtypes[2];   // required variables    int          blockcounts[2];     // MPI_Aint type used to be consistent with syntax of    // MPI_Type_extent routine    MPI_Aint    offsets[2], extent;     MPI_Status stat;     MPI_Init(&argc,&argv);    MPI_Comm_rank(MPI_COMM_WORLD, &rank);    MPI_Comm_size(MPI_COMM_WORLD, &numtasks);      // setup description of the 4 MPI_FLOAT fields x, y, z, velocity    offsets[0] = 0;    oldtypes[0] = MPI_FLOAT;    blockcounts[0] = 4;     // setup description of the 2 MPI_INT fields n, type    // need to first figure offset by getting size of MPI_FLOAT    MPI_Type_extent(MPI_FLOAT, &extent);    offsets[1] = 4 * extent;    oldtypes[1] = MPI_INT;    blockcounts[1] = 2;     // define structured type and commit it    MPI_Type_struct(2, blockcounts, offsets, oldtypes, &particletype);    MPI_Type_commit(&particletype);     // task 0 initializes the particle array and then sends it to each task    if (rank == 0) {      for (i=0; i<NELEM; i++) {         particles[i].x = i * 1.0;         particles[i].y = i * -1.0;         particles[i].z = i * 1.0;          particles[i].velocity = 0.25;         particles[i].n = i;         particles[i].type = i % 2;          }      for (i=0; i<numtasks; i++)          MPI_Send(particles, NELEM, particletype, i, tag, MPI_COMM_WORLD);      }      // all tasks receive particletype data    MPI_Recv(p, NELEM, particletype, source, tag, MPI_COMM_WORLD, &stat);     printf(""rank= %d   %3.2f %3.2f %3.2f %3.2f %d %d\n"", rank,p[3].x,         p[3].y,p[3].z,p[3].velocity,p[3].n,p[3].type);     // free datatype when done using it    MPI_Type_free(&particletype);    MPI_Finalize();    }        Fortan - Struct Derived Data Type Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63     program struct    include 'mpif.h'     integer NELEM    parameter(NELEM=25)    integer numtasks, rank, source, dest, tag, i,  ierr    integer stat(MPI_STATUS_SIZE)     type Particle    sequence    real*4 x, y, z, velocity    integer n, type    end type Particle     type (Particle) p(NELEM), particles(NELEM)    integer particletype, oldtypes(0:1)   ! required variables    integer blockcounts(0:1), offsets(0:1), extent    tag = 1     call MPI_INIT(ierr)    call MPI_COMM_RANK(MPI_COMM_WORLD, rank, ierr)    call MPI_COMM_SIZE(MPI_COMM_WORLD, numtasks, ierr)     ! setup description of the 4 MPI_REAL fields x, y, z, velocity    offsets(0) = 0    oldtypes(0) = MPI_REAL    blockcounts(0) = 4     ! setup description of the 2 MPI_INTEGER fields n, type     ! need to first figure offset by getting size of MPI_REAL    call MPI_TYPE_EXTENT(MPI_REAL, extent, ierr)    offsets(1) = 4 * extent    oldtypes(1) = MPI_INTEGER    blockcounts(1) = 2     ! define structured type and commit it     call MPI_TYPE_STRUCT(2, blockcounts, offsets, oldtypes, &                         particletype, ierr)    call MPI_TYPE_COMMIT(particletype, ierr)       ! task 0 initializes the particle array and then sends it to each task    if (rank .eq. 0) then       do i=0, NELEM-1       particles(i) = Particle ( 1.0*i, -1.0*i, 1.0*i, 0.25, i, mod(i,2) )       end do        do i=0, numtasks-1       call MPI_SEND(particles, NELEM, particletype, i, tag, &                     MPI_COMM_WORLD, ierr)       end do    endif     ! all tasks receive particletype data    source = 0    call MPI_RECV(p, NELEM, particletype, source, tag, &                  MPI_COMM_WORLD, stat, ierr)     print *, 'rank= ',rank,' p(3)= ',p(3)     ! free datatype when done using it    call MPI_TYPE_FREE(particletype, ierr)    call MPI_FINALIZE(ierr)    end   Sample program output:  rank= 0   3.00 -3.00 3.00 0.25 3 1 rank= 2   3.00 -3.00 3.00 0.25 3 1 rank= 1   3.00 -3.00 3.00 0.25 3 1 rank= 3   3.00 -3.00 3.00 0.25 3 1  Group and Communicator Management Routines Groups vs. Communicators: A group is an ordered set of processes. Each process in a group is associated with a unique integer rank. Rank values start at zero and go to N-1, where N is the number of processes in the group. In MPI, a group is represented within system memory as an object. It is accessible to the programmer only by a ""handle"". A group is always associated with a communicator object. A communicator encompasses a group of processes that may communicate with each other. All MPI messages must specify a communicator. In the simplest sense, the communicator is an extra ""tag"" that must be included with MPI calls. Like groups, communicators are represented within system memory as objects and are accessible to the programmer only by ""handles"". For example, the handle for the communicator that comprises all tasks is MPI_COMM_WORLD. From the programmer's perspective, a group and a communicator are one. The group routines are primarily used to specify which processes should be used to construct a communicator. Primary Purposes of Group and Communicator Objects: Allow you to organize tasks, based upon function, into task groups. Enable Collective Communications operations across a subset of related tasks. Provide basis for implementing user defined virtual topologies Provide for safe communications Programming Considerations and Restrictions: Groups/communicators are dynamic - they can be created and destroyed during program execution. Processes may be in more than one group/communicator. They will have a unique rank within each group/communicator. MPI provides over 40 routines related to groups, communicators, and virtual topologies. Typical usage: Extract handle of global group from MPI_COMM_WORLD using MPI_Comm_group Form new group as a subset of global group using MPI_Group_incl Create new communicator for new group using MPI_Comm_create Determine new rank in new communicator using MPI_Comm_rank Conduct communications using any MPI message passing routine When finished, free up new communicator and group (optional) using MPI_Comm_free and MPI_Group_free Group and Communicator Management Routines Create two different process groups for separate collective communications exchange. Requires creating new communicators also.      C Language - Group and Communicator Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43     #include ""mpi.h""    #include <stdio.h>    #define NPROCS 8     main(int argc, char *argv[])  {    int        rank, new_rank, sendbuf, recvbuf, numtasks,               ranks1[4]={0,1,2,3}, ranks2[4]={4,5,6,7};    MPI_Group  orig_group, new_group;   // required variables    MPI_Comm   new_comm;   // required variable     MPI_Init(&argc,&argv);    MPI_Comm_rank(MPI_COMM_WORLD, &rank);    MPI_Comm_size(MPI_COMM_WORLD, &numtasks);     if (numtasks != NPROCS) {      printf(""Must specify MP_PROCS= %d. Terminating.\n"",NPROCS);      MPI_Finalize();      exit(0);      }     sendbuf = rank;     // extract the original group handle    MPI_Comm_group(MPI_COMM_WORLD, &orig_group);     //  divide tasks into two distinct groups based upon rank    if (rank < NPROCS/2) {      MPI_Group_incl(orig_group, NPROCS/2, ranks1, &new_group);      }    else {      MPI_Group_incl(orig_group, NPROCS/2, ranks2, &new_group);      }     // create new new communicator and then perform collective communications    MPI_Comm_create(MPI_COMM_WORLD, new_group, &new_comm);    MPI_Allreduce(&sendbuf, &recvbuf, 1, MPI_INT, MPI_SUM, new_comm);     // get rank in new group    MPI_Group_rank (new_group, &new_rank);    printf(""rank= %d newrank= %d recvbuf= %d\n"",rank,new_rank,recvbuf);     MPI_Finalize();    }        Fortran - Group and Communicator Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42     program group    include 'mpif.h'     integer NPROCS    parameter(NPROCS=8)    integer rank, new_rank, sendbuf, recvbuf, numtasks    integer ranks1(4), ranks2(4), ierr    integer orig_group, new_group, new_comm   ! required variables    data ranks1 /0, 1, 2, 3/, ranks2 /4, 5, 6, 7/     call MPI_INIT(ierr)    call MPI_COMM_RANK(MPI_COMM_WORLD, rank, ierr)    call MPI_COMM_SIZE(MPI_COMM_WORLD, numtasks, ierr)     if (numtasks .ne. NPROCS) then      print *, 'Must specify NPROCS= ',NPROCS,' Terminating.'      call MPI_FINALIZE(ierr)      stop    endif     sendbuf = rank     ! extract the original group handle    call MPI_COMM_GROUP(MPI_COMM_WORLD, orig_group, ierr)     ! divide tasks into two distinct groups based upon rank    if (rank .lt. NPROCS/2) then       call MPI_GROUP_INCL(orig_group, NPROCS/2, ranks1, new_group, ierr)    else        call MPI_GROUP_INCL(orig_group, NPROCS/2, ranks2, new_group, ierr)    endif     ! create new new communicator and then perform collective communications    call MPI_COMM_CREATE(MPI_COMM_WORLD, new_group, new_comm, ierr)    call MPI_ALLREDUCE(sendbuf, recvbuf, 1, MPI_INTEGER, MPI_SUM, new_comm, ierr)     ! get rank in new group    call MPI_GROUP_RANK(new_group, new_rank, ierr)    print *, 'rank= ',rank,' newrank= ',new_rank,' recvbuf= ', recvbuf     call MPI_FINALIZE(ierr)    end   Sample program output:  rank= 7 newrank= 3 recvbuf= 22 rank= 0 newrank= 0 recvbuf= 6 rank= 1 newrank= 1 recvbuf= 6 rank= 2 newrank= 2 recvbuf= 6 rank= 6 newrank= 2 recvbuf= 22 rank= 3 newrank= 3 recvbuf= 6 rank= 4 newrank= 0 recvbuf= 22 rank= 5 newrank= 1 recvbuf= 22  Virtual Topologies What Are They? In terms of MPI, a virtual topology describes a mapping/ordering of MPI processes into a geometric ""shape"". The two main types of topologies supported by MPI are Cartesian (grid) and Graph. MPI topologies are virtual - there may be no relation between the physical structure of the parallel machine and the process topology. Virtual topologies are built upon MPI communicators and groups. Must be ""programmed"" by the application developer. Why Use Them? Convenience Virtual topologies may be useful for applications with specific communication patterns - patterns that match an MPI topology structure. For example, a Cartesian topology might prove convenient for an application that requires 4-way nearest neighbor communications for grid based data. Communication Efficiency Some hardware architectures may impose penalties for communications between successively distant ""nodes"". A particular implementation may optimize process mapping based upon the physical characteristics of a given parallel machine. The mapping of processes into an MPI virtual topology is dependent upon the MPI implementation, and may be totally ignored. Example: A simplified mapping of processes into a Cartesian virtual topology appears below: Virtual Topology Routines Create a 4 x 4 Cartesian topology from 16 processors and have each process exchange its rank with four neighbors.      C Language - Cartesian Virtual Topology Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54     #include ""mpi.h""    #include <stdio.h>    #define SIZE 16    #define UP    0    #define DOWN  1    #define LEFT  2    #define RIGHT 3     main(int argc, char *argv[])  {    int numtasks, rank, source, dest, outbuf, i, tag=1,        inbuf[4]={MPI_PROC_NULL,MPI_PROC_NULL,MPI_PROC_NULL,MPI_PROC_NULL,},        nbrs[4], dims[2]={4,4},        periods[2]={0,0}, reorder=0, coords[2];     MPI_Request reqs[8];    MPI_Status stats[8];    MPI_Comm cartcomm;   // required variable     MPI_Init(&argc,&argv);    MPI_Comm_size(MPI_COMM_WORLD, &numtasks);     if (numtasks == SIZE) {       // create cartesian virtual topology, get rank, coordinates, neighbor ranks       MPI_Cart_create(MPI_COMM_WORLD, 2, dims, periods, reorder, &cartcomm);       MPI_Comm_rank(cartcomm, &rank);       MPI_Cart_coords(cartcomm, rank, 2, coords);       MPI_Cart_shift(cartcomm, 0, 1, &nbrs[UP], &nbrs[DOWN]);       MPI_Cart_shift(cartcomm, 1, 1, &nbrs[LEFT], &nbrs[RIGHT]);        printf(""rank= %d coords= %d %d  neighbors(u,d,l,r)= %d %d %d %d\n"",              rank,coords[0],coords[1],nbrs[UP],nbrs[DOWN],nbrs[LEFT],              nbrs[RIGHT]);        outbuf = rank;        // exchange data (rank) with 4 neighbors       for (i=0; i<4; i++) {          dest = nbrs[i];          source = nbrs[i];          MPI_Isend(&outbuf, 1, MPI_INT, dest, tag,                     MPI_COMM_WORLD, &reqs[i]);          MPI_Irecv(&inbuf[i], 1, MPI_INT, source, tag,                     MPI_COMM_WORLD, &reqs[i+4]);          }        MPI_Waitall(8, reqs, stats);           printf(""rank= %d                  inbuf(u,d,l,r)= %d %d %d %d\n"",              rank,inbuf[UP],inbuf[DOWN],inbuf[LEFT],inbuf[RIGHT]);  }    else       printf(""Must specify %d processors. Terminating.\n"",SIZE);        MPI_Finalize();    }        Fortran - Cartesian Virtual Topology Example  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58     program cartesian    include 'mpif.h'     integer SIZE, UP, DOWN, LEFT, RIGHT    parameter(SIZE=16)    parameter(UP=1)    parameter(DOWN=2)    parameter(LEFT=3)    parameter(RIGHT=4)    integer numtasks, rank, source, dest, outbuf, i, tag, ierr, &            inbuf(4), nbrs(4), dims(2), coords(2), periods(2), reorder    integer stats(MPI_STATUS_SIZE, 8), reqs(8)    integer cartcomm   ! required variable    data inbuf /MPI_PROC_NULL,MPI_PROC_NULL,MPI_PROC_NULL,MPI_PROC_NULL/, &         dims /4,4/, tag /1/, periods /0,0/, reorder /0/      call MPI_INIT(ierr)    call MPI_COMM_SIZE(MPI_COMM_WORLD, numtasks, ierr)       if (numtasks .eq. SIZE) then       ! create cartesian virtual topology, get rank, coordinates, neighbor ranks       call MPI_CART_CREATE(MPI_COMM_WORLD, 2, dims, periods, reorder, &                            cartcomm, ierr)       call MPI_COMM_RANK(cartcomm, rank, ierr)       call MPI_CART_COORDS(cartcomm, rank, 2, coords, ierr)       call MPI_CART_SHIFT(cartcomm, 0, 1, nbrs(UP), nbrs(DOWN), ierr)       call MPI_CART_SHIFT(cartcomm, 1, 1, nbrs(LEFT), nbrs(RIGHT), ierr)        write(*,20) rank,coords(1),coords(2),nbrs(UP),nbrs(DOWN), &                   nbrs(LEFT),nbrs(RIGHT)        ! exchange data (rank) with 4 neighbors       outbuf = rank       do i=1,4          dest = nbrs(i)          source = nbrs(i)          call MPI_ISEND(outbuf, 1, MPI_INTEGER, dest, tag, &                        MPI_COMM_WORLD, reqs(i), ierr)          call MPI_IRECV(inbuf(i), 1, MPI_INTEGER, source, tag, &                        MPI_COMM_WORLD, reqs(i+4), ierr)       enddo        call MPI_WAITALL(8, reqs, stats, ierr)        write(*,30) rank,inbuf     else      print *, 'Must specify',SIZE,' processors.  Terminating.'     endif     call MPI_FINALIZE(ierr)     20 format('rank= ',I3,' coords= ',I2,I2, &              ' neighbors(u,d,l,r)= ',I3,I3,I3,I3 )    30 format('rank= ',I3,'                 ', &              ' inbuf(u,d,l,r)= ',I3,I3,I3,I3 )     end   Sample program output: (partial)  rank=   0 coords=  0 0 neighbors(u,d,l,r)=  -1  4 -1  1 rank=   0                  inbuf(u,d,l,r)=  -1  4 -1  1 rank=   8 coords=  2 0 neighbors(u,d,l,r)=   4 12 -1  9 rank=   8                  inbuf(u,d,l,r)=   4 12 -1  9 rank=   1 coords=  0 1 neighbors(u,d,l,r)=  -1  5  0  2 rank=   1                  inbuf(u,d,l,r)=  -1  5  0  2 rank=  13 coords=  3 1 neighbors(u,d,l,r)=   9 -1 12 14 rank=  13                  inbuf(u,d,l,r)=   9 -1 12 14 ... ... rank=   3 coords=  0 3 neighbors(u,d,l,r)=  -1  7  2 -1 rank=   3                  inbuf(u,d,l,r)=  -1  7  2 -1 rank=  11 coords=  2 3 neighbors(u,d,l,r)=   7 15 10 -1 rank=  11                  inbuf(u,d,l,r)=   7 15 10 -1 rank=  10 coords=  2 2 neighbors(u,d,l,r)=   6 14  9 11 rank=  10                  inbuf(u,d,l,r)=   6 14  9 11 rank=   9 coords=  2 1 neighbors(u,d,l,r)=   5 13  8 10 rank=   9                  inbuf(u,d,l,r)=   5 13  8 10  A Brief Word on MPI-2 and MPI-3 MPI-2: Intentionally, the MPI-1 specification did not address several ""difficult"" issues. For reasons of expediency, these issues were deferred to a second specification, called MPI-2 in 1998. MPI-2 was a major revision to MPI-1 adding new functionality and corrections. Key areas of new functionality in MPI-2: Dynamic Processes - extensions that remove the static process model of MPI. Provides routines to create new processes after job startup. One-Sided Communications - provides routines for one directional communications. Include shared memory operations (put/get) and remote accumulate operations. Extended Collective Operations - allows for the application of collective operations to inter-communicators External Interfaces - defines routines that allow developers to layer on top of MPI, such as for debuggers and profilers. Additional Language Bindings - describes C++ bindings and discusses Fortran-90 issues. Parallel I/O - describes MPI support for parallel I/O. MPI-3: The MPI-3 standard was adopted in 2012, and contains significant extensions to MPI-1 and MPI-2 functionality including: Nonblocking Collective Operations - permits tasks in a collective to perform operations without blocking, possibly offering performance improvements. New One-sided Communication Operations - to better handle different memory models. Neighborhood Collectives - extends the distributed graph and Cartesian process topologies with additional communication power. Fortran 2008 Bindings - expanded from Fortran90 bindings MPIT Tool Interface - allows the MPI implementation to expose certain internal variables, counters, and other states to the user (most likely performance tools). Matched Probe - fixes an old bug in MPI-2 where one could not probe for messages in a multi-threaded environment. More Information on MPI-2 and MPI-3: MPI Standard documents: http://www.mpi-forum.org/docs/ MPI Exercise 3 Your Choice Overview: Login to the LC workshop cluster, if you are not already logged in Following the Exercise 3 instructions will take you through all sorts of MPI programs - pick any/all that are of interest. The intention is review the codes and see what's happening - not just compile and run. Several codes provide serial examples for a comparison with the parallel MPI versions. Check out the ""bug"" programs. GO TO THE EXERCISE HERE This completes the tutorial.       Please complete the online evaluation form - unless you are doing the exercise, in which case please complete it at the end of the exercises. Where would you like to go now? Exercise 3 Agenda Back to the top References and More Information Author: Blaise Barney, Livermore Computing. MPI Standard documents: http://www.mpi-forum.org/docs/ ""Using MPI"", Gropp, Lusk and Skjellum. MIT Press, 1994. MPI Tutorials: www.mcs.anl.gov/research/projects/mpi/tutorial Livermore Computing specific information: Linux Clusters Overview tutorial computing.llnl.gov/tutorials/linux_clusters Using the Dawn BG/P System tutorial computing.llnl.gov/tutorials/bgp Using the Sequoia/Vulcan BG/Q Systems tutorial computing.llnl.gov/tutorials/bgq ""A User's Guide to MPI"", Peter S. Pacheco. Department of Mathematics, University of San Francisco. Appendix A: MPI-1 Routine Index These man pages were derived from the MVAPICH 0.9 implementation of MPI and may differ from the man pages of other implementations. Not all MPI routines are shown * = deprecated in MPI-2.0, replaced in MPI-3.0 The complete MPI-3 standard (2012) defines over 430 routines. Environment Management Routines MPI_Abort MPI_Errhandler_create* MPI_Errhandler_free MPI_Errhandler_get* MPI_Errhandler_set* MPI_Error_class MPI_Error_string MPI_Finalize MPI_Get_processor_name MPI_Get_version MPI_Init MPI_Initialized MPI_Wtick MPI_Wtime     Point-to-Point Communication Routines MPI_Bsend MPI_Bsend_init MPI_Buffer_attach MPI_Buffer_detach MPI_Cancel MPI_Get_count MPI_Get_elements MPI_Ibsend MPI_Iprobe MPI_Irecv MPI_Irsend MPI_Isend MPI_Issend MPI_Probe MPI_Recv MPI_Recv_init MPI_Request_free MPI_Rsend MPI_Rsend_init MPI_Send MPI_Send_init MPI_Sendrecv MPI_Sendrecv_replace MPI_Ssend MPI_Ssend_init MPI_Start MPI_Startall MPI_Test MPI_Test_cancelled MPI_Testall MPI_Testany MPI_Testsome MPI_Wait MPI_Waitall MPI_Waitany MPI_Waitsome Collective Communication Routines MPI_Allgather MPI_Allgatherv MPI_Allreduce MPI_Alltoall MPI_Alltoallv MPI_Barrier MPI_Bcast MPI_Gather MPI_Gatherv MPI_Op_create MPI_Op_free MPI_Reduce MPI_Reduce_scatter MPI_Scan MPI_Scatter MPI_Scatterv Process Group Routines MPI_Group_compare MPI_Group_difference MPI_Group_excl MPI_Group_free MPI_Group_incl MPI_Group_intersection MPI_Group_range_excl MPI_Group_range_incl MPI_Group_rank MPI_Group_size MPI_Group_translate_ranks MPI_Group_union Communicators Routines MPI_Comm_compare MPI_Comm_create MPI_Comm_dup MPI_Comm_free MPI_Comm_group MPI_Comm_rank MPI_Comm_remote_group MPI_Comm_remote_size MPI_Comm_size MPI_Comm_split MPI_Comm_test_inter MPI_Intercomm_create MPI_Intercomm_merge       Derived Types Routines MPI_Type_commit MPI_Type_contiguous MPI_Type_extent* MPI_Type_free MPI_Type_hindexed* MPI_Type_hvector* MPI_Type_indexed MPI_Type_lb MPI_Type_size MPI_Type_struct* MPI_Type_ub* MPI_Type_vector Virtual Topology Routines MPI_Cart_coords MPI_Cart_create MPI_Cart_get MPI_Cart_map MPI_Cart_rank MPI_Cart_shift MPI_Cart_sub MPI_Cartdim_get MPI_Dims_create MPI_Graph_create MPI_Graph_get MPI_Graph_map MPI_Graph_neighbors MPI_Graph_neighbors_count MPI_Graphdims_get MPI_Topo_test Miscellaneous Routines MPI_Address* MPI_Attr_delete* MPI_Attr_get* MPI_Attr_put* MPI_Keyval_create* MPI_Keyval_free* MPI_Pack MPI_Pack_size MPI_Pcontrol MPI_Unpack    "	"null"	"null"	""	"true"
"Intermediate"	"Some unknown features or tricks in C language"	"http://proprogramming.org/some-unknown-features-or-tricks-in-c-language/"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Some unknown features or tricks in C language Pro Programming Professional way of Programming Home C C++ Java Topics Arrays Strings Link Lists Trees Projects Articles Games Shapes Home/c programming / Some unknown features or tricks in C language Some unknown features or tricks in C language July 6, 2015 Nitin Kumar I have found a small list of features or tricks in C language which I assume only few people would know. 1. Add any numbers without using the addition operator Since the printf() function returns the number of characters that it prints, we could use this to add numbers as shown below:  #include <stdio.h>  int add(int a,int b){ if(a!=0&&b!=0) return printf(""%*c%*c"",a,'r',b,'r'); else return a!=0?a:b; }  int main(){ int A = 0, B = 0; printf(""Enter the two numbers to addn""); scanf(""%d %d"",&A,&B); printf(""Required sum is %d"",add(A,B));  return 0; }   Bitwise operators could also be used to achieve the same thing as below: int Add(int x, int y) { if (y == 0) return x; else return Add( x ^ y, (x & y) << 1); }   2. Use of Conditional Operator We mostly use it in the following form: x = (y < 0) ? 10 : 20; But it could also be used as: (y < 0 ? x : y) = 20; 3. Write a return statement in a function that returns void static void foo (void) { } static void bar (void) { return foo(); // Note this return statement. }  int main (void) { bar(); return 0; }   4. The use of comma operator: It is used mostly in statements like: for (int i=0; i<10; i++, doSomethingElse()) { /* whatever */ }     But you can use this operator anywhere. Observe: int j = (printf(""Assigning variable jn""), getValueFromSomewhere());   Each statement is evaluated, but the value of the expression will be that of the last statement evaluated. 5. Initializing structure to zero: struct mystruct a = {0}; this will zero all stucture elements. 6. Multi-character constants int x = 'ABCD'; This sets x to 0x41424344 (or 0x44434241, depending on architecture). 7. Printf in C allows you to use variables for formatting format specifiers themselves #include <stdio.h> int main() { int a = 3; float b = 6.412355; printf(""%.*fn"",a,b); return 0; } the * character achieves this effect. Related Posts Linear Search in Java Hello World Program in Java Java program to find odd or even number Write a Program to reverse a Linked list Java program to print Multiplication Table Program to find GCD and LCM using Euclids Algorithm in C++ Share this: Tweet c programming permalink Post navigation 3 Computer Programs that have changed the world Open a file and store information C++ Leave a Reply Cancel reply Subscribe to Blog via Email Enter your email address to subscribe to this blog and receive notifications of new posts by email. Join 13 other subscribers Email Address Youtube Videos Downloader in PHP Recent Posts Method overloading vs method overriding in C++ Padding and Packing in C Linear Search in Java Java Program to implement Hash Table Program to implement RSA algorithm in C Live Traffic Stats C++ program to implement Stack using Linked List Program to implement Stack in C C++ Heap Sort in C++ Program to implement Queue using Linked List C++ Program to convert Decimal to Hexadecimal C++ © 2016 Pro Programming. All rights reserved."	"null"	"null"	""	"true"
"Intermediate"	"The lost art of C structure packing"	"http://www.catb.org/esr/structure-packing/"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"The Lost Art of C Structure Packing The Lost Art of C Structure Packing Eric S. Raymond<esr@thyrsus.com> Table of Contents 1. Who should read this 2. Why I wrote it 3. Alignment requirements 4. Padding 5. Structure alignment and padding 6. Bitfields 7. Structure reordering 8. Awkward scalar cases 9. Readability and cache locality 10. Other packing techniques 11. Overriding alignment rules 12. Tools 13. Proof and exceptional cases 14. Related Reading 15. Version history 1. Who should read this This page is about a technique for reducing the memory footprint of C programs - manually repacking C structure declarations for reduced size. To read it, you will require basic knowledge of the C programming language. You need to know this technique if you intend to write code for memory-constrained embedded systems, or operating-system kernels. It is useful if you are working with application data sets so large that your programs routinely hit memory limits. It is good to know in any application where you really, really care about minimizing cache-line misses. Finally, knowing this technique is a gateway to other esoteric C topics. You are not an advanced C programmer until you have grasped it. You are not a master of C until you could have written this document yourself and can criticize it intelligently. 2. Why I wrote it This webpage exists because in late 2013 I found myself heavily applying a C optimization technique that I had learned more than two decades previously and not used much since. I needed to reduce the memory footprint of a program that used thousands - sometimes hundreds of thousands - of C struct instances. The program was cvs-fast-export and the problem was that it was dying with out-of-memory errors on large repositories. There are ways to reduce memory usage significantly in situations like this, by rearranging the order of structure members in careful ways. This can lead to dramatic gains - in my case I was able to cut the working-set size by around 40%, enabling the program to handle much larger repositories without dying. But as I worked, and thought about what I was doing, it began to dawn on me that the technique I was using has been more than half forgotten in these latter days. A little web research confirmed that C programmers don’t seem to talk about it much any more, at least not where a search engine can see them. A couple of Wikipedia entries touch the topic, but I found nobody who covered it comprehensively. There are actually reasons for this that aren’t stupid. CS courses (rightly) steer people away from micro-optimization towards finding better algorithms. The plunging price of machine resources has made squeezing memory usage less necessary. And the way hackers used to learn how to do it back in the day was by bumping their noses on strange hardware architectures - a less common experience now. But the technique still has value in important situations, and will as long as memory is finite. This document is intended to save C programmers from having to rediscover the technique, so they can concentrate effort on more important things. 3. Alignment requirements The first thing to understand is that, on modern processors, the way your C compiler lays out basic C datatypes in memory is constrained in order to make memory accesses faster. Storage for the basic C datatypes on an x86 or ARM processor doesn’t normally start at arbitrary byte addresses in memory. Rather, each type except char has an alignment requirement; chars can start on any byte address, but 2-byte shorts must start on an even address, 4-byte ints or floats must start on an address divisible by 4, and 8-byte longs or doubles must start on an address divisible by 8. Signed or unsigned makes no difference. The jargon for this is that basic C types on x86 and ARM are self-aligned. Pointers, whether 32-bit (4-byte) or 64-bit (8-byte) are self-aligned too. Self-alignment makes access faster because it facilitates generating single-instruction fetches and puts of the typed data. Without alignment constraints, on the other hand, the code might end up having to do two or more accesses spanning machine-word boundaries. Characters are a special case; they’re equally expensive from anywhere they live inside a single machine word. That’s why they don’t have a preferred alignment. I said ""on modern processors"" because on some older ones forcing your C program to violate alignment rules (say, by casting an odd address into an int pointer and trying to use it) didn’t just slow your code down, it caused an illegal instruction fault. This was the behavior, for example, on Sun SPARC chips. In fact, with sufficient determination and the right (e18) hardware flag set on the processor, you can still trigger this on x86. Also, self-alignment is not the only possible rule. Historically, some processors (especially those lacking barrel shifters) have had more restrictive ones. If you do embedded systems, you might trip over one of these lurking in the underbrush. Be aware this is possible. 4. Padding Now we’ll look at a simple example of variable layout in memory. Consider the following series of variable declarations in the top level of a C module: char *p; char c; int x; If you didn’t know anything about data alignment, you might assume that these three variables would occupy a continuous span of bytes in memory. That is, on a 32-bit machine 4 bytes of pointer would be immediately followed by 1 byte of char and that immediately followed by 4 bytes of int. And a 64-bit machine would be different only in that the pointer would be 8 bytes. Here’s what actually happens (on an x86 or ARM or anything else with self-aligned types). The storage for p starts on a self-aligned 4- or 8-byte boundary depending on the machine word size. This is pointer alignment - the strictest possible. The storage for c follows immediately. But the 4-byte alignment requirement of x forces a gap in the layout; it comes out as though there were a fourth intervening variable, like this: char *p;      /* 4 or 8 bytes */ char c;       /* 1 byte */ char pad[3];  /* 3 bytes */ int x;        /* 4 bytes */ The pad[3] character array represents the fact that there are three bytes of waste space in the structure. The old-school term for this was ""slop"". The value of the padding bits is undefined; in particular it is not guaranteed that they will be zeroed. Compare what happens if x is a 2-byte short: char *p; char c; short x; In that case, the actual layout will be this: char *p;      /* 4 or 8 bytes */ char c;       /* 1 byte */ char pad[1];  /* 1 byte */ short x;      /* 2 bytes */ On the other hand, if x is a long on a 64-bit machine char *p; char c; long x; we end up with this: char *p;     /* 8 bytes */ char c;      /* 1 byte char pad[7]; /* 7 bytes */ long x;      /* 8 bytes */ If you have been following carefully, you are probably now wondering about the case where the shorter variable declaration comes first: char c; char *p; int x; If the actual memory layout were written like this char c; char pad1[M]; char *p; char pad2[N]; int x; what can we say about M and N? First, in this case N will be zero. The address of x, coming right after p, is guaranteed to be pointer-aligned, which is never less strict than int-aligned. The value of M is less predictable. If the compiler happened to map c to the last byte of a machine word, the next byte (the first of p) would be the first byte of the next one and properly pointer-aligned. M would be zero. It is more likely that c will be mapped to the first byte of a machine word. In that case M will be whatever padding is needed to ensure that p has pointer alignment - 3 on a 32-bit machine, 7 on a 64-bit machine. Intermediate cases are possible. M can be anything from 0 to 7 (0 to 3 on 32-bit) because a char can start on any byte boundary in a machine word. If you wanted to make those variables take up less space, you could get that effect by swapping x with c in the original sequence. char *p;     /* 8 bytes */ long x;      /* 8 bytes */ char c;      /* 1 byte Usually, for the small number of scalar variables in your C programs, bumming out the few bytes you can get by changing the order of declaration won’t save you enough to be significant. The technique becomes more interesting when applied to nonscalar variables - especially structs. Before we get to those, let’s dispose of arrays of scalars. On a platform with self-aligned types, arrays of char/short/int/long/pointer have no internal padding; each member is automatically self-aligned at the end of the next one. In the next section we will see that the same is not necessarily true of structure arrays. 5. Structure alignment and padding In general, a struct instance will have the alignment of its widest scalar member. Compilers do this as the easiest way to ensure that all the members are self-aligned for fast access. Also, in C the address of a struct is the same as the address of its first member - there is no leading padding. Beware: in C++, classes that look like structs may break this rule! (Whether they do or not depends on how base classes and virtual member functions are implemented, and varies by compiler.) (When you’re in doubt about this sort of thing, ANSI C provides an offsetof() macro which can be used to read out structure member offsets.) Consider this struct: struct foo1 {     char *p;     char c;     long x; }; Assuming a 64-bit machine, any instance of struct foo1 will have 8-byte alignment. The memory layout of one of these looks unsurprising, like this: struct foo1 {     char *p;     /* 8 bytes */     char c;      /* 1 byte     char pad[7]; /* 7 bytes */     long x;      /* 8 bytes */ }; It’s laid out exactly as though variables of these types has been separately declared. But if we put c first, that’s no longer true. struct foo2 {     char c;      /* 1 byte */     char pad[7]; /* 7 bytes */     char *p;     /* 8 bytes */     long x;      /* 8 bytes */ }; If the members were separate variables, c could start at any byte boundary and the size of pad might vary. Because struct foo2 has the pointer alignment of its widest member, that’s no longer possible. Now c has to be pointer-aligned, and following padding of 7 bytes is locked in. Now let’s talk about trailing padding on structures. To explain this, I need to introduce a basic concept which I’ll call the stride address of a structure. It is the first address following the structure data that has the same alignment as the structure. The general rule of trailing structure padding is this: the compiler will behave as though the structure has trailing padding out to its stride address. This rule controls what sizeof() will return. Consider this example on a 64-bit x86 or ARM machine: struct foo3 {     char *p;     /* 8 bytes */     char c;      /* 1 byte */ };  struct foo3 singleton; struct foo3 quad[4]; You might think that sizeof(struct foo3) should be 9, but it’s actually 16. The stride address is that of (&p)[2]. Thus, in the quad array, each member has 7 bytes of trailing padding, because the first member of each following struct wants to be self-aligned on an 8-byte boundary. The memory layout is as though the structure had been declared like this: struct foo3 {     char *p;     /* 8 bytes */     char c;      /* 1 byte */     char pad[7]; }; For contrast, consider the following example: struct foo4 {     short s;     /* 2 bytes */     char c;      /* 1 byte */ }; Because s only needs to be 2-byte aligned, the stride address is just one byte after c, and struct foo4 as a whole only needs one byte of trailing padding. It will be laid out like this: struct foo4 {     short s;     /* 2 bytes */     char c;      /* 1 byte */     char pad[1]; }; and sizeof(struct foo4) will return 4. Here’s a last important detail: If your structure has structure members, the inner structs want to have the alignment of longest scalar too. Suppose you write this: struct foo5 {     char c;     struct foo5_inner {         char *p;         short x;     } inner; }; The char *p member in the inner struct forces the outer struct to be pointer-aligned as well as the inner. Actual layout will be like this on a 64-bit machine: struct foo5 {     char c;           /* 1 byte*/     char pad1[7];     /* 7 bytes */     struct foo5_inner {         char *p;      /* 8 bytes */         short x;      /* 2 bytes */         char pad2[6]; /* 6 bytes */     } inner; }; This structure gives us a hint of the savings that might be possible from repacking structures. Of 24 bytes, 13 of them are padding. That’s more than 50% waste space! 6. Bitfields Now let’s consider bitfields. What they give you the ability to do is declare structure fields of smaller than character width, down to 1 bit, like this: struct foo6 {     short s;     char c;     int flip:1;     int nybble:4;     int septet:7; }; The thing to know about bitfields is that they are implemented with word- and byte-level mask and rotate instructions operating on machine words, and cannot cross word boundaries. C99 guarentees that bit-fields will be packed as tightly as possible, provided they don’t cross storage unit boundaries (6.7.2.1 #10). Assuming we’re on a 32-bit machine, that implies that the layout may look like this: struct foo6 {     short s;       /* 2 bytes */     char c;        /* 1 byte */     int flip:1;    /* total 1 bit */     int nybble:4;  /* total 5 bits */     int pad1:3;    /* pad to an 8-bit boundary */     int septet:7;  /* 7 bits */     int pad2:25;   /* pad to 32 bits */ }; But this isn’t the only possibility, because the C standard does not specify that bits are allocated low-to-high. So the layout could look like this: struct foo6 {     short s;       /* 2 bytes */     char c;        /* 1 byte */     int pad1:3;    /* pad to an 8-bit boundary */     int flip:1;    /* total 1 bit */     int nybble:4;  /* total 5 bits */     int pad2:25;   /* pad to 32 bits */     int septet:7;  /* 7 bits */ }; That is, the padding could precede rather than following the payload bits. Note also that, as with normal structure padding, the padding bits are not guaranteed to be zero; C99 mentions this. Note that the base type of a bit field is interpreted for signedness but not necessarily for size. It is up to implementors whether ""short flip:1"" or ""long flip:1"" are supported, and whether those base types change the size of the storage unit the field is packed into. Proceed with caution and check with -Wpadded if you have it available (e.g. under clang). Compilers on exotic hardware, might interpret the C99 rules in surprising ways; older compilers might not quite follow them. The restriction that bitfields cannot cross machine word boundaries means that, while the first two of the following structures pack into one and two 32-bit words as you’d expect, the third (struct foo9) takes up three 32-bit words, in the last of which only one bit is used. struct foo7 {     int bigfield:31;      /* 32-bit word 1 begins */     int littlefield:1; };  struct foo8 {     int bigfield1:31;     /* 32-bit word 1 begins /*     int littlefield1:1;     int bigfield2:31;     /* 32-bit word 2 begins */     int littlefield2:1; };  struct foo9 {     int bigfield1:31;     /* 32-bit word 1 begins */     int bigfield2:31;     /* 32-bit word 2 begins */     int littlefield1:1;     int littlefield2:1;   /* 32-bit word 3 begins */ }; On the other hand, struct foo8 would fit into a single 64-bit word if the machine has those. 7. Structure reordering Now that you know how and why compilers insert padding in and after your structures we’ll examine what you can do to squeeze out the slop. This is the art of structure packing. The first thing to notice is that slop only happens in two places. One is where storage bound to a larger data type (with stricter alignment requirements) follows storage bound to a smaller one. The other is where a struct naturally ends before its stride address, requiring padding so the next one will be properly aligned. The simplest way to eliminate slop is to reorder the structure members by decreasing alignment. That is: make all the pointer-aligned subfields come first, because on a 64-bit machine they will be 8 bytes. Then the 4-byte ints; then the 2-byte shorts; then the character fields. So, for example, consider this simple linked-list structure: struct foo10 {     char c;     struct foo10 *p;     short x; }; With the implied slop made explicit, here it is: struct foo10 {     char c;          /* 1 byte */     char pad1[7];    /* 7 bytes */     struct foo10 *p; /* 8 bytes */     short x;         /* 2 bytes */     char pad2[6];    /* 6 bytes */ }; That’s 24 bytes. If we reorder by size, we get this: struct foo11 {     struct foo11 *p;     short x;     char c; }; Considering self-alignment, we see that none of the data fields need padding. This is because the stride address for a (longer) field with stricter alignment is always a validly-aligned start address for a (shorter) field with less strict requirements. All the repacked struct actually requires is trailing padding: struct foo11 {     struct foo11 *p; /* 8 bytes */     short x;         /* 2 bytes */     char c;          /* 1 byte */     char pad[5];     /* 5 bytes */ }; Our repack transformation drops the size from 24 to 16 bytes. This might not seem like a lot, but suppose you have a linked list of 200K of these? The savings add up fast - especially on memory-constrained embedded systems or in the core part of an OS kernel that has to stay resident. Note that reordering is not guaranteed to produce savings. Applying this technique to an earlier example, struct foo9, we get this: struct foo12 {     struct foo12_inner {         char *p;      /* 8 bytes */         int x;        /* 4 bytes */     } inner;     char c;           /* 1 byte*/ }; With padding written out, this is struct foo12 {     struct foo12_inner {         char *p;      /* 8 bytes */         int x;        /* 4 bytes */         char pad[4];  /* 4 bytes */     } inner;     char c;           /* 1 byte*/     char pad[7];      /* 7 bytes */ }; It’s still 24 bytes because c cannot back into the inner struct’s trailing padding. To collect that gain you would need to redesign your data structures. Since shipping the first version of this guide I have been asked why, if reordering for minimal slop is so simple, C compilers don’t do it automatically. The answer: C is a language originally designed for writing operating systems and other code close to the hardware. Automatic reordering would interfere with a systems programmer’s ability to lay out structures that exactly match the byte and bit-level layout of memory-mapped device control blocks. 8. Awkward scalar cases Using enumerated types instead of #defines is a good idea, if only because symbolic debuggers have those symbols available and can show them rather than raw integers. But, while enums are guaranteed to be compatible with an integral type, the C standard does not specify which underlying integral type is to be used for them. Be aware when repacking your structs that while enumerated-type variables are usually ints, this is compiler-dependent; they could be shorts, longs, or even chars by default. Your compiler may have a pragma or command-line option to force the size. The long double type is a similar trouble spot. Some C platforms implement this in 80 bits, some in 128, and some of the 80-bit platforms pad it to 96 or 128 bits. In both cases it’s best to use sizeof() to check the storage size. Finally, under x86 Linux doubles are sometimes an exception to the self-alignment rule; an 8-byte double may require only 4-byte alignment within a struct even though standalone doubles variables have 8-byte self-alignment. This depends on compiler and options. 9. Readability and cache locality While reordering by size is the simplest way to eliminate slop, it’s not necessarily the right thing. There are two more issues: readability and cache locality. Programs are not just communications to a computer, they are communications to other human beings. Code readability is important even (or especially!) when the audience of the communication is only your future self. A clumsy, mechanical reordering of your structure can harm readability. When possible, it is better to reorder fields so they remain in coherent groups with semantically related pieces of data kept close together. Ideally, the design of your structure should communicate the design of your program. When your program frequently accesses a structure, or parts of a structure, it is helpful for performance if the accesses tend to fit within a cache line - the memory block fetched by your processor when it is told to get any single address within the block. On 64-bit x86 a cache line is 64 bytes beginning on a self-aligned address; on other platforms it is often 32 bytes. The things you should do to preserve readability - grouping related and co-accessed data in adjacent fields - also improve cache-line locality. These are both reasons to reorder intelligently, with awareness of your code’s data-access patterns. If your code does concurrent access to a structure from multiple threads, there’s a third issue: cache line bouncing. To minimize expensive bus traffic, you should arrange your data so that reads come from one cache line and writes go to another in your tighter loops. And yes, this sometimes contradicts the previous guidance about grouping related data in the same cache-line-sized block. Multithreading is hard. Cache-line bouncing and other multithread optimization issues are very advanced topics which deserve an entire tutorial of their own. The best I can do here is make you aware that these issues exist. 10. Other packing techniques Reordering works best when combined with other techniques for slimming your structures. If you have several boolean flags in a struct, for example, consider reducing them to 1-bit bitfields and packing them into a place in the structure that would otherwise be slop. You’ll take a small access-time penalty for this - but if it squeezes the working set enough smaller, that penalty will be swamped by your gains from avoided cache misses. More generally, look for ways to shorten data field sizes. In cvs-fast-export, for example, one squeeze I applied was to use the knowledge that RCS and CVS repositories didn’t exist before 1982. I dropped a 64-bit Unix time_t (zero date at the beginning of 1970) for a 32-bit time offset from 1982-01-01T00:00:00; this will cover dates to 2118. (Note: if you pull a trick like this, do a bounds check whenever you set the field to prevent nasty bugs!) Each such field shortening not only decreases the explicit size of your structure, it may remove slop and/or create additional opportunities for gains from field reordering. Virtuous cascades of such effects are not very hard to trigger. The riskiest form of packing is to use unions. If you know that certain fields in your structure are never used in combination with certain other fields, consider using a union to make them share storage. But be extra careful and verify your work with regression testing, because if your lifetime analysis is even slightly wrong you will get bugs ranging from crashes to (much worse) subtle data corruption. 11. Overriding alignment rules Sometimes you can coerce your compiler into not using the processor’s normal alignment rules by using a pragma, usually #pragma pack. GCC and clang have an attributepacked you can attach to individual structure declarations; GCC has an -fpack-struct option for entire compilations. Do not do this casually, as it forces the generation of more expensive and slower code. Usually you can save as much memory, or almost as much, with the techniques I describe here. The only good reason for #pragma pack is if you have to exactly match your C data layout to some kind of bit-level hardware or protocol requirement, like a memory-mapped hardware port, and violating normal alignment is required for that to work. If you’re in that situation, and you don’t already know everything else I’m writing about here, you’re in deep trouble and I wish you luck. 12. Tools The clang compiler has a -Wpadded option that causes it to generate messages about alignment holes and padding. Some versions also have an undocumented -fdump-record-layouts option that yields more information. I have not used it myself, but several respondents speak well of a program called pahole. This tool cooperates with a compiler to produce reports on your structures that describe padding, alignment, and cache line boundaries. I’ve received a report that a proprietary code auding tool called ""PVS Studio"" can detect structure-packing opportunities. 13. Proof and exceptional cases You can download sourcecode for a little program that demonstrates the assertions about scalar and structure sizes made above. It is packtest.c. If you look through enough strange combinations of compilers, options, and unusual hardware, you will find exceptions to some of the rules I have described. They get more common as you go back in time to older processor designs. The next level beyond knowing these rules is knowing how and when to expect that they will be broken. In the years when I learned them (the early 1980s) we spoke of people who didn’t get this as victims of ""all-the-world’s-a-VAX syndrome"". Remember that not all the world is a PC. 14. Related Reading This section exists to collect pointers to essays on other advanced C topics which I judge to be good companions to this one. A Guide to Undefined Behavior in C and C++ Time, Clock, and Calendar Programming In C 15. Version history 1.14 @ 2015-12-19 Typo correction: -Wpadding → -Wpadded. 1.13 @ 2015-11-23 Be explicit about padding bits being undefined. More about bitfields. 1.12 @ 2015-11-11 Major revision of section on bitfields reflecting C99 rules. 1.11 @ 2015-07-23 Mention the clang -fdump-record-layouts option. 1.10 @ 2015-02-20 Mention attributepacked, -fpack-struct, and PVS Studio. 1.9 @ 2014-10-01 Added link to ""Time, Clock, and Calendar Programming In C"". 1.8 @ 2014-05-20 Improved explanation for the bitfield examples, 1.7 @ 2014-05-17 Correct a minor error in the description of the layout of struct foo8. 1.6 @ 2014-05-14 Emphasize that bitfields cannot cross word boundaries. Idea from Dale Gulledge. 1.5 @ 2014-01-13 Explain why structure member reordering is not done automatically. 1.4 @ 2014-01-04 A note about double under x86 Linux. 1.3 @ 2014-01-03 New sections on awkward scalar cases, readability and cache locality, and tools. 1.2 @ 2014-01-02 Correct an erroneous address calculation. 1.1 @ 2014-01-01 Explain why aligned accesses are faster. Mention offsetof. Various minor fixes, including the packtest.c download link. 1.0 @ 2014-01-01 Initial release."	"null"	"null"	""	"true"
"Intermediate"	"What a C programmer should know about memory"	"http://marek.vavrusa.com/c/memory/2015/02/20/memory/"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"What a C programmer should know about memory – Marek Vavrusa Marek Vavrusa About Contact What a C programmer should know about memory Feb 20, 2015 36 minute read Source: Weapons by T4LLBERG, on Flickr (CC-BY-SA) In 2007, Ulrich Drepper wrote a “What every programmer should know about memory”. Yes, it’s a wee long-winded, but it’s worth its salt. Many years and “every programmer should know about” articles later, the concept of virtual memory is still elusive to many, as if it was a kind of magic. Awww, I couldn’t resist the reference. Even the validity of the original article was questioned many years later. What gives? “North bridge? What is this crap? That ain’t street-fighting.” I’ll try to convey the practical side of things (i.e. what can you do) from “getting your fundamentals on a lock”, to more fun stuff. Think of it as a glue between the original article, and the things that you use every day. The examples are going to be C99 on Linux, but a lot of topics are universal. EDIT: I don’t have much knowledge about Windows, but I’d be thrilled to link an article which explains it. I tried my best to mention which functions are platform-specific, but again I’m only a human. If you find a discrepancy, please let me know. Without further ado, grab a cup of coffee and let’s get to it. Understanding virtual memory - the plot thickens Unless you’re dealing with some embedded systems or kernel-space code, you’re going to be working in protected mode. This is awesome, since your program is guaranteed to have it’s own [virtual] address space. The word “virtual” is important here. This means, among other things, that you’re not bounded by the available memory, but also not entitled to any. In order to use this space, you have to ask the OS to back it with something real, this is called mapping. A backing can be either a physical memory (not necessarily RAM), or a persistent storage. The former is also called an “anonymous mapping”. But hold your horses. The virtual memory allocator (VMA) may give you a memory it doesn’t have, all in a vain hope that you’re not going to use it. Just like banks today. This is called overcommiting, and while it has legitimate applications (sparse arrays), it also means that the memory allocation is not going to simply say “NO”. char *block = malloc(1024 * sizeof(char)); if (block == NULL) {     return -ENOMEM; /* Sad :( */ }  The NULL return value checking is a good practice, but it’s not as powerful as it once was. With the overcommit, the OS may give your memory allocator a valid pointer to memory, but if you’re going to access it - dang*. The dang in this case is platform-specific, but generally an OOM killer killing your process. * — This is an oversimplification, as timbatron noted, and it’s further explained in the “Demand paging explained” section. But I’d like to go through the well-known stuff first before we delve into specifics. Detour - a process memory layout The layout of a process memory is well covered in the Anatomy of a Program in Memory by Gustavo Duarte, so I’m going to quote and reference to the original article, I hope it’s a fair use. I have only a few minor quibbles, for one it covers only a x86-32 memory layout, but fortunately nothing much has changed for x86-64. Except that a process can use much more space — the whopping 48 bits on Linux. Source: Linux address space layout by Gustavo Duarte It also shows the memory mapping segment (MMS) growing down, but that may not always be the case. The MMS usually starts (x86/mm/mmap.c:113 and arch/mm/mmap.c:1953) at a randomized address just below the lowest address of the stack. Usually, because it may start above the stack and grow upwards iff the stack limit is large (or unlimited), or the compatibility layout is enabled. How is this important? It’s not, but it helps to give you an idea about the free address ranges. Looking at the diagram, you can see three possible variable placements: the process data segment (static storage or heap allocation), the memory mapping segment, and the stack. Let’s start with that one. Understanding stack allocation Utility belt: alloca() - allocate memory in the stack frame of the caller getrlimit() - get/set resource limits sigaltstack() - set and/or get signal stack context The stack is kind of easy to digest, everybody knows how to make a variable on the stack right? Here are two: int stairway = 2; int heaven[] = { 6, 5, 4 };  The validity of the variables is limited by scope. In C, that means this: {}. So each time a closing curly bracket comes, a variable dies. And then there’s alloca(), which allocates memory dynamically in the current stack frame. A stack frame is not (entirely) the same thing as memory frame (aka physical page), it’s simply a group of data that gets pushed onto the stack (function, parameters, variables…). Since we’re on the top of the stack, we can use the remaining memory up to the stack size limit. This is how variable-length arrays (VLA), and also alloca() work, with one difference - VLA validity is limited by the scope, alloca’d memory persists until the current function returns (or unwinds if you’re feeling sophisticated). This is no language lawyering, but a real issue if you’re using the alloca inside a loop, as you don’t have any means to free it. void laugh(void) {     for (unsigned i = 0; i < megatron; ++i) {         char *res = alloca(2);         memcpy(res, ""ha"", 2);         char vla[2] = {'h','a'}     } /* vla dies, res lives */ } /* all allocas die */  Neither VLA or alloca play nice with large allocations, because you have almost no control over the available stack memory and the allocation past the stack limits leads to the jolly stack overflow. There are two ways around it, but neither is practical. The first idea is to use a sigaltstack() to catch and handle the SIGSEGV. However this just lets you catch the stack overflow. The other way is to compile with split-stacks. It’s called this way, because it really splits the monolithic stack into a linked-list of smaller stacks called stacklets. As far as I know, GCC and clang support it with the -fsplit-stack option. In theory this also improves memory consumption and reduces the cost of creating threads — because the stack can start really small and grow on demand. In reality, expect compatibility issues, as it needs a split-stack aware linker (i.e. gold) to play nice with the split-stack unaware libraries, and performance issues (the “hot split” problem in Go is nicely explained by Agis Anastasopoulos). Understanding heap allocation Utility belt: brk(), sbrk() - manipulate the data segment size malloc() family - portable libc memory allocator The heap allocation can be as simple as moving a program break and claiming the memory between the old position, and the new position. Up to this point, a heap allocation is as fast as stack allocation (sans the paging, presuming the stack is already locked in memory). But there’s a cat, I mean catch, dammit. char *block = sbrk(1024 * sizeof(char));  ⑴ we can’t reclaim unused memory blocks, ⑵ is not thread-safe since the heap is shared between threads, ⑶ the interface is hardly portable, libraries must not touch the break man 3 sbrk — Various systems use various types for the argument of sbrk(). Common are int, ssizet, ptrdifft, intptr_t. For these reasons libc implements a centralized interface for memory allocation. The implementation varies, but it provides you a thread safe memory allocation of any size … at a cost. The cost is latency, as there is now locking involved, data structures keeping the information about used / free blocks and an extra memory overhead. The heap is not used exclusively either, as the memory mapping segment is often utilised for large blocks as well. man 3 malloc — Normally, malloc() allocates memory from the heap, … when allocating blocks of memory larger than MMAP_THRESHOLD, the glibc malloc() implementation allocates the memory as a private anonymous mapping. As the heap is always contiguous from start_brk to brk, you can’t exactly punch holes through it and reduce the data segment size. Imagine the following scenario: char *truck = malloc(1024 * 1024 * sizeof(char)); char *bike  = malloc(sizeof(char)); free(truck);  The heap [allocator] moves the brk to make space for truck. The same for the bike. But after the truck is freed, the brk can’t be moved down, as it’s the bike that occupies the highest address. The result is that your process can reuse the former truck memory, but it can’t be returned to the system until the bike is freed. But presuming the truck was mmaped, it wouldn’t reside in the heap segment, and couldn’t affect the program break. Still, this trick doesn’t prevent the holes created by small allocations (in another words “cause fragmentation”). Note that the free() doesn’t always try to shrink the data segment, as that is a potentially expensive operation. This is a problem for long-running programs, such as daemons. A GNU extension, called malloc_trim(), exists for releasing memory from the top of the heap, but it can be painfully slow. It hurts real bad for a lot of small objects, so it should be used sparingly. When to bother with a custom allocator There are a few practical use cases where a GP allocator falls short — for example an allocation of a large number of small fixed-size chunks. This might not look like a typical pattern, but it is very frequent. For example, lookup data structures like trees and tries typically require nodes to build hierarchy. In this case, not only the fragmentation is the problem, but also the data locality. A cache-efficient data structure packs the keys together (preferably on the same page), instead of mixing it with data. With the default allocator, there is no guarantee about the locality of the blocks from the subsequent allocations. Even worse is the space overhead for allocating small units. Here comes the solution! Source: Slab by wadem, on Flickr (CC-BY-SA) Slab allocator Utility belt: posix_memalign() - allocate aligned memory The principle of slab allocation was described by Bonwick for a kernel object cache, but it applies for the user-space as well. Oh-kay, we’re not interested in pinning slabs to CPUs, but back to the gist — you ask the allocator for a slab of memory, let’s say a whole page, and you cut it into many fixed-size pieces. Presuming each piece can hold at least a pointer or an integer, you can link them into a list, where the list head points to the first free element. /* Super-simple slab. */ struct slab {     void **head; };  /* Create page-aligned slab */ struct slab *slab = NULL; posix_memalign(&slab, page_size, page_size); slab->head = (void **)((char*)slab + sizeof(struct slab));  /* Create a NULL-terminated slab freelist */ char* item = (char*)slab->head; for(unsigned i = 0; i < item_count; ++i) {     *((void**)item) = item + item_size;     item += item_size; } *((void**)item) = NULL;  Allocation is then as simple as popping a list head. Freeing is equal to as pushing a new list head. There is also a neat trick. If the slab is aligned to the page_size boundary, you can get the slab pointer as cheaply as rounding down to the page_size. /* Free an element */ struct slab *slab = (void *)((size_t)ptr & PAGESIZE_BITS); *((void**)ptr) = (void*)slab->head; slab->head = (void**)ptr;  /* Allocate an element */ if((item = slab->head)) {     slab->head = (void**)*item; } else {     /* No elements left. */ }  Great, but what about binning, variable size storage, cache aliasing and caffeine, …? Peek at my old implementation for Knot DNS to get the idea, or use a library that implements it. For example, *gasp*, the glib implementation has a tidy documentation and calls it “memory slices”. Memory pools Utility belt: obstack_alloc() - allocate memory from object stack As with the slab, you’re going to outsmart the GP allocator by asking it for whole chunks of memory only. Then you just slice the cake until it runs out, and then ask for a new one. And another one. When you’re done with the cakes, you call it a day and free everything in one go. Does it sound obvious and stupid simple? Because it is, but that’s what makes it great for specific use cases. You don’t have to worry about synchronisation, not about freeing either. There are no use-after-free bugs, data locality is much more predictable, there is almost zero overhead for small fragments. The pattern is surprisingly suitable for many tasks, ranging from short-lived repetitive (i.e. “network request processing”), to long-lived immutable data (i.e. “frozen set”). You don’t have to free everything either. If you can make an educated guess on how much memory is needed on average, you can just free the excess memory and reuse. This reduces the memory allocation problem to simple pointer arithmetic. And you’re in luck here, as the GNU libc provides, *whoa*, an actual API for this. It’s called obstacks, as in “stack of objects”. The HTML documentation formatting is a bit underwhelming, but minor quibbles aside — it allows you to do both pool allocation, and full or partial unwinding. /* Define block allocator. */ #define obstack_chunk_alloc malloc #define obstack_chunk_free free  /* Initialize obstack and allocate a bunch of animals. */ struct obstack animal_stack; obstack_init (&animal_stack); char *bob = obstack_alloc(&animal_stack, sizeof(animal)); char *fred = obstack_alloc(&animal_stack, sizeof(animal)); char *roger = obstack_alloc(&animal_stack, sizeof(animal));  /* Free everything after fred (i.e. fred and roger). */ obstack_free(&animal_stack, fred);  /* Free everything. */ obstack_free(&animal_stack, NULL);  There is one more trick to it, you can grow the object on the top of the stack. Think buffering input, variable-length arrays, or just a way to combat the realloc()-strcpy() pattern. /* This is wrong, I better cancel it. */ obstack_grow(&animal_stack, ""long"", 4); obstack_grow(&animal_stack, ""fred"", 5); obstack_free (&animal_stack, obstack_finish(&animal_stack));  /* This time for real. */ obstack_grow(&animal_stack, ""long"", 4); obstack_grow(&animal_stack, ""bob"", 4); char *result = obstack_finish(&animal_stack); printf(""%s\n"", result); /* ""longbob"" */  Demand paging explained Utility belt: mlock() - lock/unlock memory madvise() - give advice about use of memory One of the reasons why the GP memory allocator doesn’t immediately return the memory to the system is, that it’s costly. The system has to do two things: ⑴ establish the mapping of a virtual page to real page, and ⑵ give you a blanked real page. The real page is called frame, now you know the difference. Each frame must be sanitized, because you don’t want the operating system to leak your secrets to another process, would you? But here’s the trick, remember the overcommit? The virtual memory allocator honours the only the first part of the deal, and then plays some “now you see me and now you don’t” shit — instead of pointing you to a real page, it points to a special page 0. Each time you try to access the special page, a page fault occurs, which means that: the kernel pauses process execution and fetches a real page, then it updates the page tables, and resumes like nothing happened. That’s about the best explanation I could muster in one sentence, here’s more detailed one. This is also called “demand paging” or “lazy loading”. The Spock said that “one man cannot summon the future”, but here you can pull the strings. The memory manager is no oracle and it makes very conservative predictions about how you’re going to access memory, but you may know better. You can lock the contiguous memory block in physical memory, avoiding further page faulting: char *block = malloc(1024 * sizeof(char)); mlock(block, 1024 * sizeof(char));  *psst*, you can also give an advise about your memory usage pattern: char *block = malloc(1024 * sizeof(block)); madvise(block, 1024 * sizeof(block), MADV_SEQUENTIAL);  The interpretation of the actual advice is platform-specific, the system may even choose to ignore it altogether, but most of the platforms play nice. Not all advices are well-supported, and some even change semantics (MADV_FREE drops dirty private memory), but the MADV_SEQUENTIAL, MADV_WILLNEED, and MADV_DONTNEED holy trinity is what you’re going to use most. Fun with flags memory mapping Utility belt: sysconf() - get configuration information at run time mmap() - map virtual memory mincore() - determine whether pages are resident in memory shmat() - shared memory operations There are several things that the memory allocator just can’t do, memory maps to to rescue! To pick one, the fact that you can’t choose the allocated address range. For that we’re willing to sacrifice some comfort — we’re going to be working with whole pages from now on. Just to make things clear, a page is usually a 4K block, but you shouldn’t rely on it and use sysconf() to discover it. long page_size = sysconf(_SC_PAGESIZE); /* Slice and dice. */  Side note — even if the platform advertises a uniform page size, it may not do so in the background. For example a Linux has a concept of transparent huge pages (THP) to reduce the cost of address translation and page faulting for contiguous blocks. This is however questionable, as the huge contiguous blocks become scarce when the physical memory gets fragmented. The cost of faulting a huge page also increases with the page size, so it’s not very efficient for “small random I/O” workload. This is unfortunately transparent to you, but there is a Linux-specific mmap option MAP_HUGETLB that allows you to use it explicitly, so you should be aware of the costs. Fixed memory mappings Say you want to do fixed mapping for a poor man’s IPC for example, how do you choose an address? On x86-32 bit it’s a risky proposal, but on the 64-bit, an address around 2/3rds of the TASK_SIZE (highest usable address of the user space process) is a safe bet. You can get away without fixed mapping, but then forget pointers in your shared memory. #define TASK_SIZE 0x800000000000 #define SHARED_BLOCK (void *)(2 * TASK_SIZE / 3)  void *shared_cats = shmat(shm_key, SHARED_BLOCK, 0); if(shared_cats == (void *)-1) {     perror(""shmat""); /* Sad :( */ }  Okay, I get it, this is hardly a portable example, but you get the gist. Mapping a fixed address range is usually considered unsafe at least, as it doesn’t check whether there is something already mapped or not. There is a mincore() function to tell you whether a page is mapped or not, but you’re out of luck in multi-threaded environment. However, fixed-address mapping is not only useful for unused address ranges, but for the used address ranges as well. Remember how the memory allocator used mmap() for bigger chunks? This makes efficient sparse arrays possible thanks to the on-demand paging. Let’s say you have created a sparse array, and now you want to free some data, but how to do that? You can’t exactly free() it, and munmap() would render it unusable. You could use the madvise() MADV_FREE / MADV_DONTNEED to mark the pages free, this is the best solution performance-wise as the pages don’t have to be faulted in, but the semantics of the advice differs is implementation-specific. A portable approach is to map over the sucker. void *array = mmap(NULL, length, PROT_READ|PROT_WRITE,                    MAP_ANONYMOUS, -1, 0);  /* ... some magic gone awry ... */  /* Let's clear some pages. */ mmap(array + offset, length, MAP_FIXED|MAP_ANONYMOUS, -1, 0);  This is equivalent to unmapping the old pages and mapping them again to that special page. How does this affect the perception of the process memory consumption — the process still uses the same amount of virtual memory, but the resident [in physical memory] size lowers. This is as close to memory hole punching as we can get. File-backed memory maps Utility belt: msync() - synchronize a file with memory map ftruncate() - truncate a file to a specified length vmsplice() - splice user pages into a pipe So far we’ve been all about anonymous memory, but it’s the file-backed memory mapping that really shines in the 64 bit address space, as it provides you with intelligent caching, synchronization and copy-on-write. Maybe that’s too much. To most people, LMDB is magic performance sprinkles compared to using the filesystem directly. ;) — Baby_Food on r/programming The file-backed shared memory maps add novel mode MAP_SHARED, which means that the changes you make to the pages will be written back to the file, therefore shared with other processes. The decision of when to synchronize is left up to the memory manager, but fortunately there’s a msync() function to enforce the synchronization with the backing store. This is great for the databases, as it guarantees durability of the written data. But not everyone needs that, it’s perfectly okay not to sync if the durability isn’t required, you’re not going to lose write visibility. This is thanks to the page cache, and it’s good because you can use memory maps for cheap IPC for example. /* Map the contents of a file into memory (shared). */ int fd = open(...); void *db = mmap(NULL, file_size, PROT_READ|PROT_WRITE,                 MAP_SHARED, fd, 0); if (db == (void *)-1) {     /* Mapping failed */ }  /* Write to a page */ char *page = (char *)db; strcpy(page, ""bob""); /* This is going to be a durable page. */ msync(page, 4, MS_SYNC); /* This is going to be a less durable page. */ page = page + PAGE_SIZE; strcpy(page, ""fred""); msync(page, 5, MS_ASYNC);  Note that you can’t map more bytes than the file actually has, so you can’t grow it or shrink it this way. You can however create (or grow) a sparse file in advance with ftruncate(). The downside is, that it makes compaction harder, as the ability to punch holes through a sparse file depends both on the file system, and the platform. The fallocate(FALLOC_FL_PUNCH_HOLE) on Linux is your best chance, but the most portable (and easiest) way is to make a copy of the file without the trimmed stuff. /* Resize the file. */ int fd = open(...); ftruncate(fd, expected_length);  Accessing a file memory map doesn’t exclude using it as a file either. This is useful for implementing a split access, where you map the file read only, but write to the file using a standard file API. This is good for security (as the exposed map is write-protected), but there’s more to it. The msync() implementation is not defined, so the MS_SYNC may very well be just a sequence of synchronous writes. Yuck. In that case, it may be faster to use a regular file APIs to do an asynchronous pwrite() and fsync() / fdatasync() for synchronisation or cache invalidation. As always there is a caveat — the system has to have a unified buffer cache. Historically, a page cache and block device cache (raw blocks) were two different things. This means that writing to a file using a standard API and reading it through a memory map is not coherent1, unless you invalidate buffers after each write. Uh oh. On the other hand, you’re in luck unless you’re running OpenBSD or Linux < 2.4. Copy-on-write So far this was about shared memory mapping. But you can use the memory mapping in another way — to map a shared copy of a file, and make modifications without modifying the backing store. Note that the pages are not duplicated immediately, that wouldn’t make sense, but in the moment you modify them. This is not only useful for forking processes or loading shared libraries, but also for working on a large set of data in-place, from multiple processes at once. int fd = open(...);  /* Copy-on-write mapping */ void *db = mmap(NULL, file_size, PROT_READ|PROT_WRITE,                     MAP_PRIVATE, fd, 0); if (db == (void *)-1) {     /* Mapping failed */ }  /* This page will be copied as soon as we write to it */ char *page = (char *)db; strcpy(page, ""bob"");  Zero-copy streaming Since the file is essentially a memory, you can stream it to pipes (that includes sockets), zero-copy style. Unlike the splice(), this plays well with the copy-on-write modification of the data. Disclaimer: This is for Linux folks only! int sock = get_client(); struct iovec iov = { .iov_base = cat_db, .iov_len = PAGE_SIZE }; int ret = vmsplice(sock, &iov, 1, 0); if (ret != 0) {     /* No streaming :( */ }  When mmap() isn’t the holy grail There are pathological cases where mmapping a file is going to be much worse than the usual approach. A rule of thumb is that handling a page fault is slower than simply reading a file block, on the basis that it has to read the file block and do something more. In reality though, mmapped I/O may be faster as it avoids double or triple caching of the data, and does read-ahead in the background. But there are times when this is going to hurt. One such example is “small random reads in a file larger than available memory”. In this case the system reads ahead blocks that are likely not to be used, and each access is going to page fault instead. You can combat this to a degree with madvise(). Then there’s TLB thrashing. Translation of each virtual page to a frame is hardware-assisted, and the CPU keeps a cache of latest translations — this is the Translation Lookaside Buffer. A random access to a larger number of pages than the cache can hold inevitably leads to “thrashing”, as the system has to do the translation by walking the page tables. For other cases, the solution is to use huge pages, but it’s not going to cut it, as loading megabytes worth of data just to access a few odd bytes has even more detrimental effect. Understanding memory consumption Utility belt: vmtouch - portable virtual memory toucher The concept of shared memory renders the traditional approach — measuring resident size &mdash obsolete, as there’s no just quantification on the amount exclusive for your process. That leads to confusion and horror, which can be two-fold: With mmap’d I/O, our app now uses almost zero memory. — CorporateGuy Helpz! My process writing to shared map leaks so much memory!!1 — HeavyLifter666 There are two states of pages, clean and dirty. The difference is that a dirty page has to be flushed to permanent storage before it can be reclaimed. The MADV_FREE advice uses this as a cheap way to free memory just by clearing the dirty bit instead of updating the page table entry. In addition, each page can be either private or shared, and this is where things get confusing. Both claims are [sort of] true, depending on the perspective. Do pages in the buffer cache count towards the process memory consumption? What about when a process dirties file-backed pages that end up in the buffer cache? How to make something out of this madness? Imagine a process, the_eye, writing to the shared map of mordor. Writing to the shared memory doesn’t count towards Rss, right? $ ps -p $$ -o pid,rss   PID   RSS 17906 1574944 # <-- WTF?  Err, back to the drawing board. PSS (Proportional Set Size) Proportional Set Size counts the private maps and adds a portion of the shared maps. This is as fair as we can get when talking about memory. By “portion”, I mean a size of a shared map, divided by the number of processes sharing it. Let’s see an example, we have an application that does read/write to a shared memory map. $ cat /proc/$$/maps 00400000-00410000         r-xp 0000 08:03 1442958 /tmp/the_eye 00bda000-01a3a000         rw-p 0000 00:00 0       [heap] 7efd09d68000-7f0509d68000 rw-s 0000 08:03 4065561 /tmp/mordor.map 7f0509f69000-7f050a108000 r-xp 0000 08:03 2490410 libc-2.19.so 7fffdc9df000-7fffdca00000 rw-p 0000 00:00 0       [stack] ... snip ...  Here’s the simplified breakdown of each map, the first column is the address range, the second is permissions information, where r stands for read, w stands for write, x means executable — so far the classic stuff — s is shared and p is private. Then there’s offset, device, inode, and finally a pathname. Here’s the documentation, massively comprehensive. I admit I’ve snipped the not-so-interesting bits from the output. Read FAQ (Why is “strict overcommit” a dumb idea?) if you’re interested why the shared libraries are mapped as private, but it’s the map of mordor that interests us: $ grep -A12 mordor.map /proc/$$/smaps Size:           33554432 kB Rss:             1557632 kB Pss:             1557632 kB Shared_Clean:          0 kB Shared_Dirty:          0 kB Private_Clean:   1557632 kB Private_Dirty:         0 kB Referenced:      1557632 kB Anonymous:             0 kB AnonHugePages:         0 kB Swap:                  0 kB KernelPageSize:        4 kB MMUPageSize:           4 kB Locked:                0 kB VmFlags: rd wr sh mr mw me ms sd  Private pages on a shared map — what am I, a wizard? On Linux, even a shared memory is counted as private unless it’s actually shared. Let’s see if it’s in the buffer cache: # Seems like the first part is... $ vmtouch -m 64G -v mordor.map [OOo                                      ] 389440/8388608             Files: 1      Directories: 0   Resident Pages: 389440/8388608  1G/32G  4.64%          Elapsed: 0.27624 seconds  # Let's load it in the cache! $ cat mordor.map > /dev/null $ vmtouch -m 64G -v mordor.map [ooooooooooooooooooooooooo      oooOOOOOOO] 2919606/8388608             Files: 1      Directories: 0   Resident Pages: 2919606/8388608  11G/32G  34.8%          Elapsed: 0.59845 seconds  Whoa, simply reading a file gets it cached? Anyway, how’s our process? ps -p $$ -o pid,rss   PID   RSS 17906 286584 # <-- Wait a bloody minute  A common misconception is that mapping a file consumes memory, whereas reading it using file API does not. One way or another, the pages from that file are going to get in the buffer cache. There is only a small difference, a process has to create the page table entries with mmap way, but the pages themselves are shared. Interestingly our process Rss shrinked, as there was a demand for the process pages. Sometimes all of our thoughts are misgiven The file-backed memory is always reclaimable, the only difference between dirty and clean — the dirty memory has to be cleaned before it can be reclaimed. So should you panick when a process consumes a lot of memory in top? Start panicking (mildly) when a process has a lot of anonymous dirty pages — these can’t be reclaimed. If you see a very large growing anonymous mapping segment, you’re probably in trouble (and make it double). But the Rss or even Pss is not to be blindly trusted. Another common mistake is to assume any relation between the process virtual memory and the memory consumption, or even treating all memory maps equally. Any reclaimable memory, is as good as a free one. To put it simply, it’s not going to fail your next memory allocation, but it may increase latency — let me explain. The memory manager is making hard choices about what to keep in the physical memory, and what not. It may decide to page out a part of the process memory to swap in favour of more space for buffers, so the process has to page in that part on the next access. Fortunately it’s usually configurable. For example, there is an option called swappiness on Linux, that determines when should the kernel start paging out anonymous memory. A value of 0 means “until abso-fucking-lutely necessary”. An end, once and for all If you got here, I salute you! I started this article as a break from actual work, in a hope that simply explaining a thousand times explained concepts in a more accessible way is going to help me to organize thoughts, and help others in the process. It took me longer than expected. Way more. I have nothing but utmost respect for writers, as it’s a tedious hair-pulling process of neverending edits and rewrites. Somewhere, Jeff Atwood has said that the best book about learning how to code is the one about building houses. I can’t remember where it was, so I can’t quote it. I could only add, that book about writing comes next. After all, that’s programming in it’s distilled form — writing stories, clear an concise. EDIT: I’ve fixed the stupid mistakes with alloca() and sizeof(char *) vs sizeof(char), thanks immibis and BonzaiThePenguin. Thanks sWvich for pointing out missing cast in slab + sizeof(struct slab). Obviously I should have run the article through static analysis, but I didn’t — lesson learned. Open question — is there anything better than Markdown code block, where I could show an annotated excerpt with a possibility to download the whole code block? A fancy way to say you’re going to get different data. ↩ Please enable JavaScript to view the comments powered by Disqus. This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. Pixyll theme by John Otander </> available on Github."	"null"	"null"	""	"true"
"Intermediate"	"What every C programmer should know about undefined behaviour"	"http://blog.llvm.org/2011/05/what-every-c-programmer-should-know.html"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"LLVM Project Blog: What Every C Programmer Should Know About Undefined Behavior #1/3 skip to main | skip to sidebar LLVM Project Blog LLVM Project News and Details from the Trenches Friday, May 13, 2011 What Every C Programmer Should Know About Undefined Behavior #1/3 People occasionally ask why LLVM-compiled code sometimes generates SIGTRAP signals when the optimizer is turned on. After digging in, they find that Clang generated a ""ud2"" instruction (assuming X86 code) - the same as is generated by __builtin_trap(). There are several issues at work here, all centering around undefined behavior in C code and how LLVM handles it. This blog post (the first in a series of three) tries to explain some of these issues so that you can better understand the tradeoffs and complexities involved, and perhaps learn a few more of the dark sides of C. It turns out that C is not a ""high level assembler"" like many experienced C programmers (particularly folks with a low-level focus) like to think, and that C++ and Objective-C have directly inherited plenty of issues from it. Introduction to Undefined Behavior Translation available in: Japanese Both LLVM IR and the C programming language have the concept of ""undefined behavior"". Undefined behavior is a broad topic with a lot of nuances. The best introduction I've found to it is a post on John Regehr's Blog. The short version of this excellent article is that many seemingly reasonable things in C actually have undefined behavior, and this is a common source of bugs in programs. Beyond that, any undefined behavior in C gives license to the implementation (the compiler and runtime) to produce code that formats your hard drive, does completely unexpected things, or worse. Again, I would highly recommend reading John's article. Undefined behavior exists in C-based languages because the designers of C wanted it to be an extremely efficient low-level programming language. In contrast, languages like Java (and many other 'safe' languages) have eschewed undefined behavior because they want safe and reproducible behavior across implementations, and willing to sacrifice performance to get it. While neither is ""the right goal to aim for,"" if you're a C programmer you really should understand what undefined behavior is. Before getting into the details, it is worth briefly mentioning what it takes for a compiler to get good performance out a broad range of C apps, because there is no magic bullet. At a very high level, compilers produce high performance apps by a) doing a good job at bread and butter algorithms like register allocation, scheduling, etc. b) knowing lots and lots of ""tricks"" (e.g. peephole optimizations, loop transformations, etc), and applying them whenever profitable. c) being good at eliminating unnecessary abstractions (e.g. redundancy due to macros in C, inlining functions, eliminating temporary objects in C++, etc) and d) not screwing anything up. While any of the optimizations below may sound trivial, it turns out that saving just one cycle out of a critical loop can make some codec run 10% faster or take 10% less power. Advantages of Undefined Behavior in C, with Examples Before getting into the dark side of undefined behavior and LLVM's policy and behavior when used as a C compiler, I thought it would be helpful to consider a few specific cases of undefined behavior, and talk about how each enables better performance than a safe language like Java. You can look at this either as ""optimizations enabled"" by the class of undefined behavior or as the ""overhead avoided"" that would be required to make each case defined. While the compiler optimizer could eliminate some of these overheads some of the time, to do so in general (for every case) would require solving the halting problem and many other ""interesting challenges"". It is also worth pointing out that both Clang and GCC nail down a few behaviors that the C standard leaves undefined. The things I'll describe are both undefined according to the standard and treated as undefined behavior by both of these compilers in their default modes. Use of an uninitialized variable: This is commonly known as source of problems in C programs and there are many tools to catch these: from compiler warnings to static and dynamic analyzers. This improves performance by not requiring that all variables be zero initialized when they come into scope (as Java does). For most scalar variables, this would cause little overhead, but stack arrays and malloc'd memory would incur a memset of the storage, which could be quite costly, particularly since the storage is usually completely overwritten. Signed integer overflow: If arithmetic on an 'int' type (for example) overflows, the result is undefined. One example is that ""INT_MAX+1"" is not guaranteed to be INT_MIN. This behavior enables certain classes of optimizations that are important for some code. For example, knowing that INT_MAX+1 is undefined allows optimizing ""X+1 > X"" to ""true"". Knowing the multiplication ""cannot"" overflow (because doing so would be undefined) allows optimizing ""X*2/2"" to ""X"". While these may seem trivial, these sorts of things are commonly exposed by inlining and macro expansion. A more important optimization that this allows is for ""<="" loops like this: for (i = 0; i <= N; ++i) { ... }  In this loop, the compiler can assume that the loop will iterate exactly N+1 times if ""i"" is undefined on overflow, which allows a broad range of loop optimizations to kick in. On the other hand, if the variable is defined to wrap around on overflow, then the compiler must assume that the loop is possibly infinite (which happens if N is INT_MAX) - which then disables these important loop optimizations. This particularly affects 64-bit platforms since so much code uses ""int"" as induction variables. It is worth noting that unsigned overflow is guaranteed to be defined as 2's complement (wrapping) overflow, so you can always use them. The cost to making signed integer overflow defined is that these sorts of optimizations are simply lost (for example, a common symptom is a ton of sign extensions inside of loops on 64-bit targets). Both Clang and GCC accept the ""-fwrapv"" flag which forces the compiler to treat signed integer overflow as defined (other than divide of INT_MIN by -1). Oversized Shift Amounts: Shifting a uint32_t by 32 or more bits is undefined. My guess is that this originated because the underlying shift operations on various CPUs do different things with this: for example, X86 truncates 32-bit shift amount to 5 bits (so a shift by 32-bits is the same as a shift by 0-bits), but PowerPC truncates 32-bit shift amounts to 6 bits (so a shift by 32 produces zero). Because of these hardware differences, the behavior is completely undefined by C (thus shifting by 32-bits on PowerPC could format your hard drive, it is *not* guaranteed to produce zero). The cost of eliminating this undefined behavior is that the compiler would have to emit an extra operation (like an 'and') for variable shifts, which would make them twice as expensive on common CPUs. Dereferences of Wild Pointers and Out of Bounds Array Accesses: Dereferencing random pointers (like NULL, pointers to free'd memory, etc) and the special case of accessing an array out of bounds is a common bug in C applications which hopefully needs no explanation. To eliminate this source of undefined behavior, array accesses would have to each be range checked, and the ABI would have to be changed to make sure that range information follows around any pointers that could be subject to pointer arithmetic. This would have an extremely high cost for many numerical and other applications, as well as breaking binary compatibility with every existing C library. Dereferencing a NULL Pointer: contrary to popular belief, dereferencing a null pointer in C is undefined. It is not defined to trap, and if you mmap a page at 0, it is not defined to access that page. This falls out of the rules that forbid dereferencing wild pointers and the use of NULL as a sentinel. NULL pointer dereferences being undefined enables a broad range of optimizations: in contrast, Java makes it invalid for the compiler to move a side-effecting operation across any object pointer dereference that cannot be proven by the optimizer to be non-null. This significantly punishes scheduling and other optimizations. In C-based languages, NULL being undefined enables a large number of simple scalar optimizations that are exposed as a result of macro expansion and inlining. If you're using an LLVM-based compiler, you can dereference a ""volatile"" null pointer to get a crash if that's what you're looking for, since volatile loads and stores are generally not touched by the optimizer. There is currently no flag that enables random NULL pointer loads to be treated as valid accesses or to make random loads know that their pointer is ""allowed to be null"". Violating Type Rules: It is undefined behavior to cast an int* to a float* and dereference it (accessing the ""int"" as if it were a ""float""). C requires that these sorts of type conversions happen through memcpy: using pointer casts is not correct and undefined behavior results. The rules for this are quite nuanced and I don't want to go into the details here (there is an exception for char*, vectors have special properties, unions change things, etc). This behavior enables an analysis known as ""Type-Based Alias Analysis"" (TBAA) which is used by a broad range of memory access optimizations in the compiler, and can significantly improve performance of the generated code. For example, this rule allows clang to optimize this function: float *P;  void zero_array() {    int i;    for (i = 0; i < 10000; ++i)      P[i] = 0.0f;  }  into ""memset(P, 0, 40000)"". This optimization also allows many loads to be hoisted out of loops, common subexpressions to be eliminated, etc. This class of undefined behavior can be disabled by passing the -fno-strict-aliasing flag, which disallows this analysis. When this flag is passed, Clang is required to compile this loop into 10000 4-byte stores (which is several times slower), because it has to assume that it is possible for any of the stores to change the value of P, as in something like this: int main() {   P = (float*)&P;  // cast causes TBAA violation in zero_array.   zero_array(); }  This sort of type abuse is pretty uncommon, which is why the standard committee decided that the significant performance wins were worth the unexpected result for ""reasonable"" type casts. It is worth pointing out that Java gets the benefits of type-based optimizations without these drawbacks because it doesn't have unsafe pointer casting in the language at all. Anyway, I hope that this gives you an idea of some of the classes of optimizations enabled by undefined behavior in C. There are many other kinds of course, including sequence point violations like ""foo(i, ++i)"", race conditions in multithreaded programs, violating 'restrict', divide by zero, etc. In our next post, we'll discuss why undefined behavior in C is a pretty scary thing if performance is not your only goal. In our final post in the series, we'll talk about how LLVM and Clang handle it. -Chris Lattner Posted by Chris Lattner at 11:25 AM Labels: Clang, optimization Newer Post Older Post Home LLVM Logo Labels Clang (154) llvmweekly (129) C++ (17) optimization (15) meta (9) MC (7) LLVM-IR (5) devmtg (5) llvm-users (5) new-in-llvm-2.7 (5) new-in-llvm-3.3 (5) LLDB (4) jit (4) sanitizer (4) codegen (3) new-in-llvm-3.0 (3) testing (3) OpenMP (2) Products (2) GHC (1) GSoC (1) KLEE (1) LLVM Foundation (1) LNT (1) SelectionDAG (1) Warnings (1) april-1 (1) asip (1) bugpoint (1) dragonegg (1) eda (1) libc++ (1) lld (1) modernizer (1) new-in-llvm-2.8 (1) new-in-llvm-3.1 (1) new-in-llvm-3.4 (1) tce (1) tta (1) undefined-behavior (1) vliw (1) Blog Archive ►  2016 (30) ►  June (6) ►  May (5) ►  April (6) ►  March (4) ►  February (5) ►  January (4) ►  2015 (62) ►  December (4) ►  November (7) ►  October (4) ►  September (5) ►  August (6) ►  July (4) ►  June (5) ►  May (5) ►  April (6) ►  March (5) ►  February (5) ►  January (6) ►  2014 (56) ►  December (5) ►  November (5) ►  October (4) ►  September (5) ►  August (4) ►  July (6) ►  June (5) ►  May (5) ►  April (5) ►  March (5) ►  February (4) ►  January (3) ►  2013 (23) ►  November (2) ►  October (2) ►  September (3) ►  August (1) ►  July (2) ►  June (2) ►  May (2) ►  April (7) ►  March (2) ►  2012 (4) ►  December (2) ►  November (1) ►  January (1) ▼  2011 (11) ►  December (2) ►  November (2) ►  September (1) ▼  May (5) LLVM @ ""The Architecture of Open Source Applicatio... C++ at Google: Here Be Dragons What Every C Programmer Should Know About Undefine... What Every C Programmer Should Know About Undefine... What Every C Programmer Should Know About Undefine... ►  April (1) ►  2010 (17) ►  December (1) ►  September (1) ►  June (3) ►  May (3) ►  April (5) ►  February (2) ►  January (2) ►  2009 (6) ►  December (6) About The LLVM Blog This blog is intended to be a news feed for information about the LLVM Compiler Infrastructure and related subprojects. We welcome new contributors. If you'd like to write a post, please get in touch with Chris.  "	"null"	"null"	""	"true"
"Advanced"	"Advanced metaprogramming in C"	"http://250bpm.com/blog:56"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Advanced metaprogramming in C - 250bpm 250bpm Home Libmill Nanomsg ZeroMQ Ribosome Publications Contact Create account or Sign in Advanced metaprogramming in C Previous: Let's stop kidding ourselves about APIs Next: Document intent not algorithm: A use case Metaprogramming in C is the art of creating new language constructs, typically using macros. Great introduction to C metaprogramming by Simon Tatham can be found here: Metaprogramming custom control structures in C Recently, however, I've faced a problem that could not be solved by the means outlined in the article. I was implementing a control structure with variable number of clauses, similar to C's 'switch' statement. To be more concrete, I was trying to implement an equivalent of golang's 'select' statement in libmill project. Here's how the statement looks like in golang:  select { case channel1 <- 42:     foo() case i := <- channel2:     bar(i) }  The problem here is that the construct is stateful. It has to collect all the conditions first, then wait till one of them becomes true. At the first sight it looks like the syntax like this cannot be even implemented in C. One's natural instinct is to implement it in idiomatic C way by first creating an array of conditions, then doing the poll and finally executing particular piece of code based on the return value from the poll. Something like this:  int i; struct select_condition conds[2]; conds[0].channel = channel1; conds[0].operation = SELECT_OUT; conds[0].out_value = 42; conds[1].channel = channel2; conds[1].operation = SELECT_IN; conds[1].in_value = &i; switch(do_select(conds, 2)) { case 0:     foo(); case 1:     bar(i); }  However, such syntax is ugly and verbose. You can tolarate it if you are a C programmer, but if you come from a different background you'll find it simply atrocious. Can we make it better in some way? One obvious thougt would be to wrap the initialisation of the pollset into some handy macros:  #define in(conds, index, chan, val)\     conds[index].channel = chan;\     conds[index].operation = SELECT_IN;\     conds[index].in_value = &val;  #define out(conds, index, chan, val)\     conds[index].channel = chan;\     conds[index].operation = SELECT_OUT;\     conds[index].out_value = val;  The user's code would then look a bit simpler:  int i; struct select_condition conds[2]; out(conds, 0, channel1, 42); in(conds, 1, channel2, i); switch(do_select(conds, 2)) { case 0:     foo(); case 1:     bar(i); }  So far, we've done nothing unexpected. But can we go further? Can we somehow not require the user to specify the size of the pollset in advance? It turns out that yes. It can be done using a technique that I am a proud inventor of: We can build a linked list on the stack! EDIT: It have been pointed out that the linked-list-on-the-stack technique have already been around before this. That makes me a proud re-inventor! Yay!  #define concat(x,y) x##y  #define in(conds, chan, val)\     struct select_condition concat(cond,__COUNTER__);     concat(cond,__COUNTER__).channel = chan;\     concat(cond,__COUNTER__).operation = SELECT_IN;\     concat(cond,__COUNTER__).in_value = &val;\     concat(cond,__COUNTER__).next = conds;\     conds = &cond;  #define out(conds, chan, val)\     struct select_condition concat(cond,__COUNTER__);     concat(cond,__COUNTER__).channel = chan;\     concat(cond,__COUNTER__).operation = SELECT_OUT;\     concat(cond,__COUNTER__).out_value = val;\     concat(cond,__COUNTER__).next = conds;\     conds = &cond;  And here's the user's code. Note that do_select() is now getting a linked list as an argument instead of an array. Also note that the linked list doesn't have to be deallocated because it lives on the stack and will be freed automatically at the end of the function:  int i; struct select_condition *conds = NULL; out(conds, channel1, 42); in(conds, channel2, i); switch(do_select(conds)) { case 0:     foo(); case 1:     bar(i); }  At this point we would like to rearrage the code in such a way the actions — foo() and bar() — are collocated with the conditions that trigger them rather then having all the conditions listed first, followed by all the actions. Once again, this looks like it may not be possible. Macros are strictly local. They cannot move pieces of code up or down the source file. But that kind of obstacle cannot stop a dedicated C hacker! If we can't move the code, let's do it in a dynamic fashion. We'll introduce a loop with two iterations. First iteration will build the linked list, second one will execute the action:  int i; int result = -1; struct select_condition *conds = NULL; while(1) {      if(result == - 1) {         out(conds, channel1, 42);     }     if(result == 0) {         foo();         break;     }      if(result == - 1) {         in(conds, channel2, i);     }     if(result == 1) {         bar(i);         break;     }      result = do_select(conds); }  Nice, except that it doesn't work. The problem is that in() and out() macros declare a local variable (select_condition) which gets out of scope when the surrounding if block finishes. Which means that the value can be overwritten at any time. What we need is to get rid of those if blocks. And, yes, we are going to use gotos to accomplish that. Oh boy, this is going to get ugly! But keep calm and follow me!  int i; int result = -1; struct select_condition *conds = NULL; while(1) {      if(result != -1)         goto label0;     out(conds, channel1, 42);     label0:     if(result == 0) {         foo();         break;     }      if(result != -1)         goto label1;     in(conds, channel2, i);     label1:     if(result == 1) {         bar(i);         break;     }      result = do_select(conds); }  Now let's stuff more code into in and out macros to make the user's code simple:  #define select \     int result = -1;\     struct select_condition *conds = NULL;\     while(1)  #define in(chan, val) in_((chan), (val), __COUNTER__) #define in_(chan, val, idx)\     if(result != -1)\         goto concat(label, idx);\     struct select_condition concat(cond, idx) =\         {chan, SELECT_IN, &val, 0, conds};\     conds = &cond;\     concat(label, idx);\     if(result == idx)  #define out(chan, val) out_((chan), (val), __COUNTER__) #define out_(chan, val, idx)\     if(result != -1)\         goto concat(label, idx);\     struct select_condition concat(cond, idx) =\         {chan, SELECT_OUT, NULL, val, conds};\     conds = &cond;     concat(label, idx);\     if(result == idx)  #define end \     result = do_select(conds);  Note that we had to split the macros into two so that we can reuse the same value of __COUNTER__ in multiple places. And here is how the user code looks like:  int i; select {     out(channel1, 42) {         foo();         break;     }     in(channel2, i) {         bar(i);         break;     }     end }  There's some more polishing to do. We can get rid of the break statements by hiding them in the following macro. We can declare 'i' varaible in directly in the out() macro. We should put the whole statement into a code block so that variables like 'conds' don't pollute the surrounding namespace. These final touches are left as an exercise for the reader. (If out of your wits, you can check real-world implementation of the construct here.) Have fun and happy Swiss National Day everyone! Martin Sústrik, August 1st, 2015 Previous: Let's stop kidding ourselves about APIs Next: Document intent not algorithm: A use case Show Comments Hide All Comments Unfold All Fold All Fold zimbatm (guest) 01 Aug 2015 10:53 Isn't it possible to make the channels compatible with select(2) ? Being able to copy the go syntax is nice but I think will prove to be more of a headache in the long run. It's actually an annoyance that I have in go: select doesn't allow to mix channels with IO objects forcing the user to create goroutines to feed the latter into the former. Reply Options Unfold by zimbatm (guest), 01 Aug 2015 10:53 Fold martin_sustrik 01 Aug 2015 11:10 I've actually tried to do that. Note however, that it requires a change to the kernel. More details here: http://250bpm.com/blog:16 TL;DR: I've never got the patch merged to Linux. If you have any free time to spend you may try to push it through yourself. Reply Options Unfold by martin_sustrik, 01 Aug 2015 11:10 Add a New Comment Post preview: Close preview or Sign in as Wikidot user (will not be published) - + Help: wiki text quick reference Permanent Link Edit Delete Help  | Terms of Service  | Privacy  | Report a bug  | Flag as objectionable Powered by Wikidot.com Unless otherwise stated, the content of this page is licensed under Creative Commons Attribution-ShareAlike 3.0 License Click here to edit contents of this page. Click here to toggle editing of individual sections of the page (if possible). Watch headings for an ""edit"" link when available. Append content without editing the whole page source. Check out how this page has evolved in the past. If you want to discuss contents of this page - this is the easiest way to do it. View and manage file attachments for this page. A few useful tools to manage this Site. See pages that link to and include this page. Change the name (also URL address, possibly the category) of the page. View wiki source for this page without editing. View/set parent page (used for creating breadcrumbs and structured layout). Notify administrators if there is objectionable content in this page. Something does not work as expected? Find out what you can do. General Wikidot.com documentation and help section. Wikidot.com Terms of Service - what you can, what you should not etc. Wikidot.com Privacy Policy."	"null"	"null"	""	"true"
"Advanced"	"A quick tutorial on implementing and debugging malloc, free, calloc, and realloc"	"http://danluu.com/malloc-tutorial/"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"27"	"1"	"13"	"GitHub - danluu/malloc-tutorial: A quick tutorial on how to implement malloc/free/calloc/realloc Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 1 Star 27 Fork 13 danluu/malloc-tutorial Code Issues 0 Pull requests 0 Pulse Graphs A quick tutorial on how to implement malloc/free/calloc/realloc 5 commits 1 branch 0 releases Fetching contributors C 95.9% Makefile 4.1% C Makefile Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Latest commit e83fe31 Feb 18, 2015 danluu Merge pull request #1 from thomasballinger/patch-1 … fix link to article Permalink Failed to load latest commit information. test Add initial draft. Nov 29, 2014 Makefile Add initial draft. Nov 29, 2014 README.md fix link to article Feb 18, 2015 malloc.c Add initial draft. Nov 29, 2014 wrapper.c Add initial draft. Nov 29, 2014 README.md See danluu.com/malloc-tutorial :-). Tests and wrapper borrowed from Andrew Roth. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/danluu/malloc-tutorial"	""	"true"
"Advanced"	"Bit twiddling hacks"	"https://graphics.stanford.edu/~seander/bithacks.html"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Bit Twiddling Hacks  Bit Twiddling Hacks By Sean Eron Anderson seander@cs.stanford.edu Individually, the code snippets here are in the public domain (unless otherwise noted) — feel free to use them however you please. The aggregate collection and descriptions are © 1997-2005 Sean Eron Anderson. The code and descriptions are distributed in the hope that they will be useful, but WITHOUT ANY WARRANTY and without even the implied warranty of merchantability or fitness for a particular purpose. As of May 5, 2005, all the code has been tested thoroughly. Thousands of people have read it. Moreover, Professor Randal Bryant, the Dean of Computer Science at Carnegie Mellon University, has personally tested almost everything with his Uclid code verification system. What he hasn't tested, I have checked against all possible inputs on a 32-bit machine. To the first person to inform me of a legitimate bug in the code, I'll pay a bounty of US$10 (by check or Paypal). If directed to a charity, I'll pay US$20. Contents About the operation counting methodology Compute the sign of an integer Detect if two integers have opposite signs Compute the integer absolute value (abs) without branching Compute the minimum (min) or maximum (max) of two integers without branching Determining if an integer is a power of 2 Sign extending Sign extending from a constant bit-width Sign extending from a variable bit-width Sign extending from a variable bit-width in 3 operations Conditionally set or clear bits without branching Conditionally negate a value without branching Merge bits from two values according to a mask Counting bits set Counting bits set, naive way Counting bits set by lookup table Counting bits set, Brian Kernighan's way Counting bits set in 14, 24, or 32-bit words using 64-bit instructions Counting bits set, in parallel Count bits set (rank) from the most-significant bit upto a given position Select the bit position (from the most-significant bit) with the given count (rank) Computing parity (1 if an odd number of bits set, 0 otherwise) Compute parity of a word the naive way Compute parity by lookup table Compute parity of a byte using 64-bit multiply and modulus division Compute parity of word with a multiply Compute parity in parallel Swapping Values Swapping values with subtraction and addition Swapping values with XOR Swapping individual bits with XOR Reversing bit sequences Reverse bits the obvious way Reverse bits in word by lookup table Reverse the bits in a byte with 3 operations (64-bit multiply and modulus division) Reverse the bits in a byte with 4 operations (64-bit multiply, no division) Reverse the bits in a byte with 7 operations (no 64-bit, only 32) Reverse an N-bit quantity in parallel with 5 * lg(N) operations Modulus division (aka computing remainders) Computing modulus division by 1 << s without a division operation (obvious) Computing modulus division by (1 << s) - 1 without a division operation Computing modulus division by (1 << s) - 1 in parallel without a division operation Finding integer log base 2 of an integer (aka the position of the highest bit set) Find the log base 2 of an integer with the MSB N set in O(N) operations (the obvious way) Find the integer log base 2 of an integer with an 64-bit IEEE float Find the log base 2 of an integer with a lookup table Find the log base 2 of an N-bit integer in O(lg(N)) operations Find the log base 2 of an N-bit integer in O(lg(N)) operations with multiply and lookup Find integer log base 10 of an integer Find integer log base 10 of an integer the obvious way Find integer log base 2 of a 32-bit IEEE float Find integer log base 2 of the pow(2, r)-root of a 32-bit IEEE float (for unsigned integer r) Counting consecutive trailing zero bits (or finding bit indices) Count the consecutive zero bits (trailing) on the right linearly Count the consecutive zero bits (trailing) on the right in parallel Count the consecutive zero bits (trailing) on the right by binary search Count the consecutive zero bits (trailing) on the right by casting to a float Count the consecutive zero bits (trailing) on the right with modulus division and lookup Count the consecutive zero bits (trailing) on the right with multiply and lookup Round up to the next highest power of 2 by float casting Round up to the next highest power of 2 Interleaving bits (aka computing Morton Numbers) Interleave bits the obvious way Interleave bits by table lookup Interleave bits with 64-bit multiply Interleave bits by Binary Magic Numbers Testing for ranges of bytes in a word (and counting occurances found) Determine if a word has a zero byte Determine if a word has a byte equal to n Determine if a word has byte less than n Determine if a word has a byte greater than n Determine if a word has a byte between m and n Compute the lexicographically next bit permutation About the operation counting methodology When totaling the number of operations for algorithms here, any C operator is counted as one operation. Intermediate assignments, which need not be written to RAM, are not counted. Of course, this operation counting approach only serves as an approximation of the actual number of machine instructions and CPU time. All operations are assumed to take the same amount of time, which is not true in reality, but CPUs have been heading increasingly in this direction over time. There are many nuances that determine how fast a system will run a given sample of code, such as cache sizes, memory bandwidths, instruction sets, etc. In the end, benchmarking is the best way to determine whether one method is really faster than another, so consider the techniques below as possibilities to test on your target architecture. Compute the sign of an integer  int v;      // we want to find the sign of v int sign;   // the result goes here   // CHAR_BIT is the number of bits per byte (normally 8). sign = -(v < 0);  // if v < 0 then -1, else 0.  // or, to avoid branching on CPUs with flag registers (IA32): sign = -(int)((unsigned int)((int)v) >> (sizeof(int) * CHAR_BIT - 1)); // or, for one less instruction (but not portable): sign = v >> (sizeof(int) * CHAR_BIT - 1);   The last expression above evaluates to sign = v >> 31 for 32-bit integers. This is one operation faster than the obvious way, sign = -(v < 0). This trick works because when signed integers are shifted right, the value of the far left bit is copied to the other bits. The far left bit is 1 when the value is negative and 0 otherwise; all 1 bits gives -1. Unfortunately, this behavior is architecture-specific. Alternatively, if you prefer the result be either -1 or +1, then use:  sign = +1 | (v >> (sizeof(int) * CHAR_BIT - 1));  // if v < 0 then -1, else +1  On the other hand, if you prefer the result be either -1, 0, or +1, then use:  sign = (v != 0) | -(int)((unsigned int)((int)v) >> (sizeof(int) * CHAR_BIT - 1)); // Or, for more speed but less portability: sign = (v != 0) | (v >> (sizeof(int) * CHAR_BIT - 1));  // -1, 0, or +1 // Or, for portability, brevity, and (perhaps) speed: sign = (v > 0) - (v < 0); // -1, 0, or +1  If instead you want to know if something is non-negative, resulting in +1 or else 0, then use:  sign = 1 ^ ((unsigned int)v >> (sizeof(int) * CHAR_BIT - 1)); // if v < 0 then 0, else 1  Caveat: On March 7, 2003, Angus Duggan pointed out that the 1989 ANSI C specification leaves the result of signed right-shift implementation-defined, so on some systems this hack might not work. For greater portability, Toby Speight suggested on September 28, 2005 that CHAR_BIT be used here and throughout rather than assuming bytes were 8 bits long. Angus recommended the more portable versions above, involving casting on March 4, 2006. Rohit Garg suggested the version for non-negative integers on September 12, 2009. Detect if two integers have opposite signs  int x, y;               // input values to compare signs  bool f = ((x ^ y) < 0); // true iff x and y have opposite signs  Manfred Weis suggested I add this entry on November 26, 2009. Compute the integer absolute value (abs) without branching  int v;           // we want to find the absolute value of v unsigned int r;  // the result goes here  int const mask = v >> sizeof(int) * CHAR_BIT - 1;  r = (v + mask) ^ mask;  Patented variation:  r = (v ^ mask) - mask;  Some CPUs don't have an integer absolute value instruction (or the compiler fails to use them). On machines where branching is expensive, the above expression can be faster than the obvious approach, r = (v < 0) ? -(unsigned)v : v, even though the number of operations is the same. On March 7, 2003, Angus Duggan pointed out that the 1989 ANSI C specification leaves the result of signed right-shift implementation-defined, so on some systems this hack might not work. I've read that ANSI C does not require values to be represented as two's complement, so it may not work for that reason as well (on a diminishingly small number of old machines that still use one's complement). On March 14, 2004, Keith H. Duggar sent me the patented variation above; it is superior to the one I initially came up with, r=(+1|(v>>(sizeof(int)*CHAR_BIT-1)))*v, because a multiply is not used. Unfortunately, this method has been patented in the USA on June 6, 2000 by Vladimir Yu Volkonsky and assigned to Sun Microsystems. On August 13, 2006, Yuriy Kaminskiy told me that the patent is likely invalid because the method was published well before the patent was even filed, such as in How to Optimize for the Pentium Processor by Agner Fog, dated November, 9, 1996. Yuriy also mentioned that this document was translated to Russian in 1997, which Vladimir could have read. Moreover, the Internet Archive also has an old link to it. On January 30, 2007, Peter Kankowski shared with me an abs version he discovered that was inspired by Microsoft's Visual C++ compiler output. It is featured here as the primary solution. On December 6, 2007, Hai Jin complained that the result was signed, so when computing the abs of the most negative value, it was still negative. On April 15, 2008 Andrew Shapira pointed out that the obvious approach could overflow, as it lacked an (unsigned) cast then; for maximum portability he suggested (v < 0) ? (1 + ((unsigned)(-1-v))) : (unsigned)v. But citing the ISO C99 spec on July 9, 2008, Vincent Lefèvre convinced me to remove it becasue even on non-2s-complement machines -(unsigned)v will do the right thing. The evaluation of -(unsigned)v first converts the negative value of v to an unsigned by adding 2**N, yielding a 2s complement representation of v's value that I'll call U. Then, U is negated, giving the desired result, -U = 0 - U = 2**N - U = 2**N - (v+2**N) = -v = abs(v). Compute the minimum (min) or maximum (max) of two integers without branching  int x;  // we want to find the minimum of x and y int y;    int r;  // the result goes here   r = y ^ ((x ^ y) & -(x < y)); // min(x, y)  On some rare machines where branching is very expensive and no condition move instructions exist, the above expression might be faster than the obvious approach, r = (x < y) ? x : y, even though it involves two more instructions. (Typically, the obvious approach is best, though.) It works because if x < y, then -(x < y) will be all ones, so r = y ^ (x ^ y) & ~0 = y ^ x ^ y = x. Otherwise, if x >= y, then -(x < y) will be all zeros, so r = y ^ ((x ^ y) & 0) = y. On some machines, evaluating (x < y) as 0 or 1 requires a branch instruction, so there may be no advantage. To find the maximum, use:  r = x ^ ((x ^ y) & -(x < y)); // max(x, y)  Quick and dirty versions: If you know that INT_MIN <= x - y <= INT_MAX, then you can use the following, which are faster because (x - y) only needs to be evaluated once.  r = y + ((x - y) & ((x - y) >> (sizeof(int) * CHAR_BIT - 1))); // min(x, y) r = x - ((x - y) & ((x - y) >> (sizeof(int) * CHAR_BIT - 1))); // max(x, y)  Note that the 1989 ANSI C specification doesn't specify the result of signed right-shift, so these aren't portable. If exceptions are thrown on overflows, then the values of x and y should be unsigned or cast to unsigned for the subtractions to avoid unnecessarily throwing an exception, however the right-shift needs a signed operand to produce all one bits when negative, so cast to signed there. On March 7, 2003, Angus Duggan pointed out the right-shift portability issue. On May 3, 2005, Randal E. Bryant alerted me to the need for the precondition, INT_MIN <= x - y <= INT_MAX, and suggested the non-quick and dirty version as a fix. Both of these issues concern only the quick and dirty version. Nigel Horspoon observed on July 6, 2005 that gcc produced the same code on a Pentium as the obvious solution because of how it evaluates (x < y). On July 9, 2008 Vincent Lefèvre pointed out the potential for overflow exceptions with subtractions in r = y + ((x - y) & -(x < y)), which was the previous version. Timothy B. Terriberry suggested using xor rather than add and subract to avoid casting and the risk of overflows on June 2, 2009. Determining if an integer is a power of 2  unsigned int v; // we want to see if v is a power of 2 bool f;         // the result goes here   f = (v & (v - 1)) == 0;  Note that 0 is incorrectly considered a power of 2 here. To remedy this, use:  f = v && !(v & (v - 1));  Sign extending from a constant bit-width Sign extension is automatic for built-in types, such as chars and ints. But suppose you have a signed two's complement number, x, that is stored using only b bits. Moreover, suppose you want to convert x to an int, which has more than b bits. A simple copy will work if x is positive, but if negative, the sign must be extended. For example, if we have only 4 bits to store a number, then -3 is represented as 1101 in binary. If we have 8 bits, then -3 is 11111101. The most-significant bit of the 4-bit representation is replicated sinistrally to fill in the destination when we convert to a representation with more bits; this is sign extending. In C, sign extension from a constant bit-width is trivial, since bit fields may be specified in structs or unions. For example, to convert from 5 bits to an full integer:  int x; // convert this from using 5 bits to a full int int r; // resulting sign extended number goes here struct {signed int x:5;} s; r = s.x = x;  The following is a C++ template function that uses the same language feature to convert from B bits in one operation (though the compiler is generating more, of course).  template <typename T, unsigned B> inline T signextend(const T x) {   struct {T x:B;} s;   return s.x = x; }  int r = signextend<signed int,5>(x);  // sign extend 5 bit number x to r  John Byrd caught a typo in the code (attributed to html formatting) on May 2, 2005. On March 4, 2006, Pat Wood pointed out that the ANSI C standard requires that the bitfield have the keyword ""signed"" to be signed; otherwise, the sign is undefined. Sign extending from a variable bit-width Sometimes we need to extend the sign of a number but we don't know a priori the number of bits, b, in which it is represented. (Or we could be programming in a language like Java, which lacks bitfields.)  unsigned b; // number of bits representing the number in x int x;      // sign extend this b-bit number to r int r;      // resulting sign-extended number int const m = 1U << (b - 1); // mask can be pre-computed if b is fixed  x = x & ((1U << b) - 1);  // (Skip this if bits in x above position b are already zero.) r = (x ^ m) - m;  The code above requires four operations, but when the bitwidth is a constant rather than variable, it requires only two fast operations, assuming the upper bits are already zeroes. A slightly faster but less portable method that doesn't depend on the bits in x above position b being zero is:  int const m = CHAR_BIT * sizeof(x) - b; r = (x << m) >> m;  Sean A. Irvine suggested that I add sign extension methods to this page on June 13, 2004, and he provided m = (1 << (b - 1)) - 1; r = -(x & ~m) | x; as a starting point from which I optimized to get m = 1U << (b - 1); r = -(x & m) | x. But then on May 11, 2007, Shay Green suggested the version above, which requires one less operation than mine. Vipin Sharma suggested I add a step to deal with situations where x had possible ones in bits other than the b bits we wanted to sign-extend on Oct. 15, 2008. On December 31, 2009 Chris Pirazzi suggested I add the faster version, which requires two operations for constant bit-widths and three for variable widths. Sign extending from a variable bit-width in 3 operations The following may be slow on some machines, due to the effort required for multiplication and division. This version is 4 operations. If you know that your initial bit-width, b, is greater than 1, you might do this type of sign extension in 3 operations by using r = (x * multipliers[b]) / multipliers[b], which requires only one array lookup.  unsigned b; // number of bits representing the number in x int x;      // sign extend this b-bit number to r int r;      // resulting sign-extended number #define M(B) (1U << ((sizeof(x) * CHAR_BIT) - B)) // CHAR_BIT=bits/byte static int const multipliers[] =  {   0,     M(1),  M(2),  M(3),  M(4),  M(5),  M(6),  M(7),   M(8),  M(9),  M(10), M(11), M(12), M(13), M(14), M(15),   M(16), M(17), M(18), M(19), M(20), M(21), M(22), M(23),   M(24), M(25), M(26), M(27), M(28), M(29), M(30), M(31),   M(32) }; // (add more if using more than 64 bits) static int const divisors[] =  {   1,    ~M(1),  M(2),  M(3),  M(4),  M(5),  M(6),  M(7),   M(8),  M(9),  M(10), M(11), M(12), M(13), M(14), M(15),   M(16), M(17), M(18), M(19), M(20), M(21), M(22), M(23),   M(24), M(25), M(26), M(27), M(28), M(29), M(30), M(31),   M(32) }; // (add more for 64 bits) #undef M r = (x * multipliers[b]) / divisors[b];  The following variation is not portable, but on architectures that employ an arithmetic right-shift, maintaining the sign, it should be fast.  const int s = -b; // OR:  sizeof(x) * CHAR_BIT - b; r = (x << s) >> s;  Randal E. Bryant pointed out a bug on May 3, 2005 in an earlier version (that used multipliers[] for divisors[]), where it failed on the case of x=1 and b=1. Conditionally set or clear bits without branching  bool f;         // conditional flag unsigned int m; // the bit mask unsigned int w; // the word to modify:  if (f) w |= m; else w &= ~m;   w ^= (-f ^ w) & m;  // OR, for superscalar CPUs: w = (w & ~m) | (-f & m);  On some architectures, the lack of branching can more than make up for what appears to be twice as many operations. For instance, informal speed tests on an AMD Athlon™ XP 2100+ indicated it was 5-10% faster. An Intel Core 2 Duo ran the superscalar version about 16% faster than the first. Glenn Slayden informed me of the first expression on December 11, 2003. Marco Yu shared the superscalar version with me on April 3, 2007 and alerted me to a typo 2 days later. Conditionally negate a value without branching If you need to negate only when a flag is false, then use the following to avoid branching:  bool fDontNegate;  // Flag indicating we should not negate v. int v;             // Input value to negate if fDontNegate is false. int r;             // result = fDontNegate ? v : -v;  r = (fDontNegate ^ (fDontNegate - 1)) * v;  If you need to negate only when a flag is true, then use this:  bool fNegate;  // Flag indicating if we should negate v. int v;         // Input value to negate if fNegate is true. int r;         // result = fNegate ? -v : v;  r = (v ^ -fNegate) + fNegate;  Avraham Plotnitzky suggested I add the first version on June 2, 2009. Motivated to avoid the multiply, I came up with the second version on June 8, 2009. Alfonso De Gregorio pointed out that some parens were missing on November 26, 2009, and received a bug bounty. Merge bits from two values according to a mask  unsigned int a;    // value to merge in non-masked bits unsigned int b;    // value to merge in masked bits unsigned int mask; // 1 where bits from b should be selected; 0 where from a. unsigned int r;    // result of (a & ~mask) | (b & mask) goes here  r = a ^ ((a ^ b) & mask);   This shaves one operation from the obvious way of combining two sets of bits according to a bit mask. If the mask is a constant, then there may be no advantage. Ron Jeffery sent this to me on February 9, 2006. Counting bits set (naive way)  unsigned int v; // count the number of bits set in v unsigned int c; // c accumulates the total bits set in v  for (c = 0; v; v >>= 1) {   c += v & 1; }  The naive approach requires one iteration per bit, until no more bits are set. So on a 32-bit word with only the high set, it will go through 32 iterations. Counting bits set by lookup table  static const unsigned char BitsSetTable256[256] =  { #   define B2(n) n,     n+1,     n+1,     n+2 #   define B4(n) B2(n), B2(n+1), B2(n+1), B2(n+2) #   define B6(n) B4(n), B4(n+1), B4(n+1), B4(n+2)     B6(0), B6(1), B6(1), B6(2) };  unsigned int v; // count the number of bits set in 32-bit value v unsigned int c; // c is the total bits set in v  // Option 1: c = BitsSetTable256[v & 0xff] +      BitsSetTable256[(v >> 8) & 0xff] +      BitsSetTable256[(v >> 16) & 0xff] +      BitsSetTable256[v >> 24];   // Option 2: unsigned char * p = (unsigned char *) &v; c = BitsSetTable256[p[0]] +      BitsSetTable256[p[1]] +      BitsSetTable256[p[2]] +	     BitsSetTable256[p[3]];   // To initially generate the table algorithmically: BitsSetTable256[0] = 0; for (int i = 0; i < 256; i++) {   BitsSetTable256[i] = (i & 1) + BitsSetTable256[i / 2]; }  On July 14, 2009 Hallvard Furuseth suggested the macro compacted table. Counting bits set, Brian Kernighan's way  unsigned int v; // count the number of bits set in v unsigned int c; // c accumulates the total bits set in v for (c = 0; v; c++) {   v &= v - 1; // clear the least significant bit set }  Brian Kernighan's method goes through as many iterations as there are set bits. So if we have a 32-bit word with only the high bit set, then it will only go once through the loop. Published in 1988, the C Programming Language 2nd Ed. (by Brian W. Kernighan and Dennis M. Ritchie) mentions this in exercise 2-9. On April 19, 2006 Don Knuth pointed out to me that this method ""was first published by Peter Wegner in CACM 3 (1960), 322. (Also discovered independently by Derrick Lehmer and published in 1964 in a book edited by Beckenbach.)"" Counting bits set in 14, 24, or 32-bit words using 64-bit instructions  unsigned int v; // count the number of bits set in v unsigned int c; // c accumulates the total bits set in v  // option 1, for at most 14-bit values in v: c = (v * 0x200040008001ULL & 0x111111111111111ULL) % 0xf;  // option 2, for at most 24-bit values in v: c =  ((v & 0xfff) * 0x1001001001001ULL & 0x84210842108421ULL) % 0x1f; c += (((v & 0xfff000) >> 12) * 0x1001001001001ULL & 0x84210842108421ULL)       % 0x1f;  // option 3, for at most 32-bit values in v: c =  ((v & 0xfff) * 0x1001001001001ULL & 0x84210842108421ULL) % 0x1f; c += (((v & 0xfff000) >> 12) * 0x1001001001001ULL & 0x84210842108421ULL) %       0x1f; c += ((v >> 24) * 0x1001001001001ULL & 0x84210842108421ULL) % 0x1f;  This method requires a 64-bit CPU with fast modulus division to be efficient. The first option takes only 3 operations; the second option takes 10; and the third option takes 15. Rich Schroeppel originally created a 9-bit version, similiar to option 1; see the Programming Hacks section of Beeler, M., Gosper, R. W., and Schroeppel, R. HAKMEM. MIT AI Memo 239, Feb. 29, 1972. His method was the inspiration for the variants above, devised by Sean Anderson. Randal E. Bryant offered a couple bug fixes on May 3, 2005. Bruce Dawson tweaked what had been a 12-bit version and made it suitable for 14 bits using the same number of operations on Feburary 1, 2007. Counting bits set, in parallel  unsigned int v; // count bits set in this (32-bit value) unsigned int c; // store the total here static const int S[] = {1, 2, 4, 8, 16}; // Magic Binary Numbers static const int B[] = {0x55555555, 0x33333333, 0x0F0F0F0F, 0x00FF00FF, 0x0000FFFF};  c = v - ((v >> 1) & B[0]); c = ((c >> S[1]) & B[1]) + (c & B[1]); c = ((c >> S[2]) + c) & B[2]; c = ((c >> S[3]) + c) & B[3]; c = ((c >> S[4]) + c) & B[4];  The B array, expressed as binary, is:  B[0] = 0x55555555 = 01010101 01010101 01010101 01010101 B[1] = 0x33333333 = 00110011 00110011 00110011 00110011 B[2] = 0x0F0F0F0F = 00001111 00001111 00001111 00001111 B[3] = 0x00FF00FF = 00000000 11111111 00000000 11111111 B[4] = 0x0000FFFF = 00000000 00000000 11111111 11111111  We can adjust the method for larger integer sizes by continuing with the patterns for the Binary Magic Numbers, B and S. If there are k bits, then we need the arrays S and B to be ceil(lg(k)) elements long, and we must compute the same number of expressions for c as S or B are long. For a 32-bit v, 16 operations are used. The best method for counting bits in a 32-bit integer v is the following:  v = v - ((v >> 1) & 0x55555555);                    // reuse input as temporary v = (v & 0x33333333) + ((v >> 2) & 0x33333333);     // temp c = ((v + (v >> 4) & 0xF0F0F0F) * 0x1010101) >> 24; // count  The best bit counting method takes only 12 operations, which is the same as the lookup-table method, but avoids the memory and potential cache misses of a table. It is a hybrid between the purely parallel method above and the earlier methods using multiplies (in the section on counting bits with 64-bit instructions), though it doesn't use 64-bit instructions. The counts of bits set in the bytes is done in parallel, and the sum total of the bits set in the bytes is computed by multiplying by 0x1010101 and shifting right 24 bits. A generalization of the best bit counting method to integers of bit-widths upto 128 (parameterized by type T) is this:  v = v - ((v >> 1) & (T)~(T)0/3);                           // temp v = (v & (T)~(T)0/15*3) + ((v >> 2) & (T)~(T)0/15*3);      // temp v = (v + (v >> 4)) & (T)~(T)0/255*15;                      // temp c = (T)(v * ((T)~(T)0/255)) >> (sizeof(T) - 1) * CHAR_BIT; // count  See Ian Ashdown's nice newsgroup post for more information on counting the number of bits set (also known as sideways addition). The best bit counting method was brought to my attention on October 5, 2005 by Andrew Shapira; he found it in pages 187-188 of Software Optimization Guide for AMD Athlon™ 64 and Opteron™ Processors. Charlie Gordon suggested a way to shave off one operation from the purely parallel version on December 14, 2005, and Don Clugston trimmed three more from it on December 30, 2005. I made a typo with Don's suggestion that Eric Cole spotted on January 8, 2006. Eric later suggested the arbitrary bit-width generalization to the best method on November 17, 2006. On April 5, 2007, Al Williams observed that I had a line of dead code at the top of the first method. Count bits set (rank) from the most-significant bit upto a given position The following finds the the rank of a bit, meaning it returns the sum of bits that are set to 1 from the most-signficant bit downto the bit at the given position.    uint64_t v;       // Compute the rank (bits set) in v from the MSB to pos.   unsigned int pos; // Bit position to count bits upto.   uint64_t r;       // Resulting rank of bit at pos goes here.    // Shift out bits after given position.   r = v >> (sizeof(v) * CHAR_BIT - pos);   // Count set bits in parallel.   // r = (r & 0x5555...) + ((r >> 1) & 0x5555...);   r = r - ((r >> 1) & ~0UL/3);   // r = (r & 0x3333...) + ((r >> 2) & 0x3333...);   r = (r & ~0UL/5) + ((r >> 2) & ~0UL/5);   // r = (r & 0x0f0f...) + ((r >> 4) & 0x0f0f...);   r = (r + (r >> 4)) & ~0UL/17;   // r = r % 255;   r = (r * (~0UL/255)) >> ((sizeof(v) - 1) * CHAR_BIT);  Juha Järvi sent this to me on November 21, 2009 as an inverse operation to the computing the bit position with the given rank, which follows. Select the bit position (from the most-significant bit) with the given count (rank) The following 64-bit code selects the position of the rth 1 bit when counting from the left. In other words if we start at the most significant bit and proceed to the right, counting the number of bits set to 1 until we reach the desired rank, r, then the position where we stop is returned. If the rank requested exceeds the count of bits set, then 64 is returned. The code may be modified for 32-bit or counting from the right.    uint64_t v;          // Input value to find position with rank r.   unsigned int r;      // Input: bit's desired rank [1-64].   unsigned int s;      // Output: Resulting position of bit with rank r [1-64]   uint64_t a, b, c, d; // Intermediate temporaries for bit count.   unsigned int t;      // Bit count temporary.    // Do a normal parallel bit count for a 64-bit integer,                        // but store all intermediate steps.                                           // a = (v & 0x5555...) + ((v >> 1) & 0x5555...);   a =  v - ((v >> 1) & ~0UL/3);   // b = (a & 0x3333...) + ((a >> 2) & 0x3333...);   b = (a & ~0UL/5) + ((a >> 2) & ~0UL/5);   // c = (b & 0x0f0f...) + ((b >> 4) & 0x0f0f...);   c = (b + (b >> 4)) & ~0UL/0x11;   // d = (c & 0x00ff...) + ((c >> 8) & 0x00ff...);   d = (c + (c >> 8)) & ~0UL/0x101;   t = (d >> 32) + (d >> 48);   // Now do branchless select!                                                   s  = 64;   // if (r > t) {s -= 32; r -= t;}   s -= ((t - r) & 256) >> 3; r -= (t & ((t - r) >> 8));   t  = (d >> (s - 16)) & 0xff;   // if (r > t) {s -= 16; r -= t;}   s -= ((t - r) & 256) >> 4; r -= (t & ((t - r) >> 8));   t  = (c >> (s - 8)) & 0xf;   // if (r > t) {s -= 8; r -= t;}   s -= ((t - r) & 256) >> 5; r -= (t & ((t - r) >> 8));   t  = (b >> (s - 4)) & 0x7;   // if (r > t) {s -= 4; r -= t;}   s -= ((t - r) & 256) >> 6; r -= (t & ((t - r) >> 8));   t  = (a >> (s - 2)) & 0x3;   // if (r > t) {s -= 2; r -= t;}   s -= ((t - r) & 256) >> 7; r -= (t & ((t - r) >> 8));   t  = (v >> (s - 1)) & 0x1;   // if (r > t) s--;   s -= ((t - r) & 256) >> 8;   s = 65 - s;  If branching is fast on your target CPU, consider uncommenting the if-statements and commenting the lines that follow them. Juha Järvi sent this to me on November 21, 2009. Computing parity the naive way  unsigned int v;       // word value to compute the parity of bool parity = false;  // parity will be the parity of v  while (v) {   parity = !parity;   v = v & (v - 1); }   The above code uses an approach like Brian Kernigan's bit counting, above. The time it takes is proportional to the number of bits set. Compute parity by lookup table  static const bool ParityTable256[256] =  { #   define P2(n) n, n^1, n^1, n #   define P4(n) P2(n), P2(n^1), P2(n^1), P2(n) #   define P6(n) P4(n), P4(n^1), P4(n^1), P4(n)     P6(0), P6(1), P6(1), P6(0) };  unsigned char b;  // byte value to compute the parity of bool parity = ParityTable256[b];  // OR, for 32-bit words: unsigned int v; v ^= v >> 16; v ^= v >> 8; bool parity = ParityTable256[v & 0xff];  // Variation: unsigned char * p = (unsigned char *) &v; parity = ParityTable256[p[0] ^ p[1] ^ p[2] ^ p[3]];   Randal E. Bryant encouraged the addition of the (admittedly) obvious last variation with variable p on May 3, 2005. Bruce Rawles found a typo in an instance of the table variable's name on September 27, 2005, and he received a $10 bug bounty. On October 9, 2006, Fabrice Bellard suggested the 32-bit variations above, which require only one table lookup; the previous version had four lookups (one per byte) and were slower. On July 14, 2009 Hallvard Furuseth suggested the macro compacted table. Compute parity of a byte using 64-bit multiply and modulus division  unsigned char b;  // byte value to compute the parity of bool parity =    (((b * 0x0101010101010101ULL) & 0x8040201008040201ULL) % 0x1FF) & 1;  The method above takes around 4 operations, but only works on bytes. Compute parity of word with a multiply The following method computes the parity of the 32-bit value in only 8 operations using a multiply.      unsigned int v; // 32-bit word     v ^= v >> 1;     v ^= v >> 2;     v = (v & 0x11111111U) * 0x11111111U;     return (v >> 28) & 1;  Also for 64-bits, 8 operations are still enough.      unsigned long long v; // 64-bit word     v ^= v >> 1;     v ^= v >> 2;     v = (v & 0x1111111111111111UL) * 0x1111111111111111UL;     return (v >> 60) & 1;  Andrew Shapira came up with this and sent it to me on Sept. 2, 2007. Compute parity in parallel  unsigned int v;  // word value to compute the parity of v ^= v >> 16; v ^= v >> 8; v ^= v >> 4; v &= 0xf; return (0x6996 >> v) & 1;  The method above takes around 9 operations, and works for 32-bit words. It may be optimized to work just on bytes in 5 operations by removing the two lines immediately following ""unsigned int v;"". The method first shifts and XORs the eight nibbles of the 32-bit value together, leaving the result in the lowest nibble of v. Next, the binary number 0110 1001 1001 0110 (0x6996 in hex) is shifted to the right by the value represented in the lowest nibble of v. This number is like a miniature 16-bit parity-table indexed by the low four bits in v. The result has the parity of v in bit 1, which is masked and returned. Thanks to Mathew Hendry for pointing out the shift-lookup idea at the end on Dec. 15, 2002. That optimization shaves two operations off using only shifting and XORing to find the parity. Swapping values with subtraction and addition  #define SWAP(a, b) ((&(a) == &(b)) || \                     (((a) -= (b)), ((b) += (a)), ((a) = (b) - (a))))  This swaps the values of a and b without using a temporary variable. The initial check for a and b being the same location in memory may be omitted when you know this can't happen. (The compiler may omit it anyway as an optimization.) If you enable overflows exceptions, then pass unsigned values so an exception isn't thrown. The XOR method that follows may be slightly faster on some machines. Don't use this with floating-point numbers (unless you operate on their raw integer representations). Sanjeev Sivasankaran suggested I add this on June 12, 2007. Vincent Lefèvre pointed out the potential for overflow exceptions on July 9, 2008 Swapping values with XOR  #define SWAP(a, b) (((a) ^= (b)), ((b) ^= (a)), ((a) ^= (b)))  This is an old trick to exchange the values of the variables a and b without using extra space for a temporary variable. On January 20, 2005, Iain A. Fleming pointed out that the macro above doesn't work when you swap with the same memory location, such as SWAP(a[i], a[j]) with i == j. So if that may occur, consider defining the macro as (((a) == (b)) || (((a) ^= (b)), ((b) ^= (a)), ((a) ^= (b)))). On July 14, 2009, Hallvard Furuseth suggested that on some machines, (((a) ^ (b)) && ((b) ^= (a) ^= (b), (a) ^= (b))) might be faster, since the (a) ^ (b) expression is reused. Swapping individual bits with XOR  unsigned int i, j; // positions of bit sequences to swap unsigned int n;    // number of consecutive bits in each sequence unsigned int b;    // bits to swap reside in b unsigned int r;    // bit-swapped result goes here  unsigned int x = ((b >> i) ^ (b >> j)) & ((1U << n) - 1); // XOR temporary r = b ^ ((x << i) | (x << j));  As an example of swapping ranges of bits suppose we have have b = 00101111 (expressed in binary) and we want to swap the n = 3 consecutive bits starting at i = 1 (the second bit from the right) with the 3 consecutive bits starting at j = 5; the result would be r = 11100011 (binary). This method of swapping is similar to the general purpose XOR swap trick, but intended for operating on individual bits.  The variable x stores the result of XORing the pairs of bit values we want to swap, and then the bits are set to the result of themselves XORed with x.  Of course, the result is undefined if the sequences overlap. On July 14, 2009 Hallvard Furuseth suggested that I change the 1 << n to 1U << n because the value was being assigned to an unsigned and to avoid shifting into a sign bit. Reverse bits the obvious way  unsigned int v;     // input bits to be reversed unsigned int r = v; // r will be reversed bits of v; first get LSB of v int s = sizeof(v) * CHAR_BIT - 1; // extra shift needed at end  for (v >>= 1; v; v >>= 1) {      r <<= 1;   r |= v & 1;   s--; } r <<= s; // shift when v's highest bits are zero  On October 15, 2004, Michael Hoisie pointed out a bug in the original version. Randal E. Bryant suggested removing an extra operation on May 3, 2005. Behdad Esfabod suggested a slight change that eliminated one iteration of the loop on May 18, 2005. Then, on February 6, 2007, Liyong Zhou suggested a better version that loops while v is not 0, so rather than iterating over all bits it stops early. Reverse bits in word by lookup table  static const unsigned char BitReverseTable256[256] =  { #   define R2(n)     n,     n + 2*64,     n + 1*64,     n + 3*64 #   define R4(n) R2(n), R2(n + 2*16), R2(n + 1*16), R2(n + 3*16) #   define R6(n) R4(n), R4(n + 2*4 ), R4(n + 1*4 ), R4(n + 3*4 )     R6(0), R6(2), R6(1), R6(3) };  unsigned int v; // reverse 32-bit value, 8 bits at time unsigned int c; // c will get v reversed  // Option 1: c = (BitReverseTable256[v & 0xff] << 24) |      (BitReverseTable256[(v >> 8) & 0xff] << 16) |      (BitReverseTable256[(v >> 16) & 0xff] << 8) |     (BitReverseTable256[(v >> 24) & 0xff]);  // Option 2: unsigned char * p = (unsigned char *) &v; unsigned char * q = (unsigned char *) &c; q[3] = BitReverseTable256[p[0]];  q[2] = BitReverseTable256[p[1]];  q[1] = BitReverseTable256[p[2]];  q[0] = BitReverseTable256[p[3]];  The first method takes about 17 operations, and the second takes about 12, assuming your CPU can load and store bytes easily. On July 14, 2009 Hallvard Furuseth suggested the macro compacted table. Reverse the bits in a byte with 3 operations (64-bit multiply and modulus division): unsigned char b; // reverse this (8-bit) byte   b = (b * 0x0202020202ULL & 0x010884422010ULL) % 1023;  The multiply operation creates five separate copies of the 8-bit byte pattern to fan-out into a 64-bit value. The AND operation selects the bits that are in the correct (reversed) positions, relative to each 10-bit groups of bits. The multiply and the AND operations copy the bits from the original byte so they each appear in only one of the 10-bit sets. The reversed positions of the bits from the original byte coincide with their relative positions within any 10-bit set. The last step, which involves modulus division by 2^10 - 1, has the effect of merging together each set of 10 bits (from positions 0-9, 10-19, 20-29, ...) in the 64-bit value. They do not overlap, so the addition steps underlying the modulus division behave like or operations. This method was attributed to Rich Schroeppel in the Programming Hacks section of Beeler, M., Gosper, R. W., and Schroeppel, R. HAKMEM. MIT AI Memo 239, Feb. 29, 1972. Reverse the bits in a byte with 4 operations (64-bit multiply, no division): unsigned char b; // reverse this byte   b = ((b * 0x80200802ULL) & 0x0884422110ULL) * 0x0101010101ULL >> 32;  The following shows the flow of the bit values with the boolean variables a, b, c, d, e, f, g, and h, which comprise an 8-bit byte. Notice how the first multiply fans out the bit pattern to multiple copies, while the last multiply combines them in the fifth byte from the right.                                                                                          abcd efgh (-> hgfe dcba) *                                                      1000 0000  0010 0000  0000 1000  0000 0010 (0x80200802) -------------------------------------------------------------------------------------------------                                             0abc defg  h00a bcde  fgh0 0abc  defg h00a  bcde fgh0 &                                           0000 1000  1000 0100  0100 0010  0010 0001  0001 0000 (0x0884422110) -------------------------------------------------------------------------------------------------                                             0000 d000  h000 0c00  0g00 00b0  00f0 000a  000e 0000 *                                           0000 0001  0000 0001  0000 0001  0000 0001  0000 0001 (0x0101010101) -------------------------------------------------------------------------------------------------                                             0000 d000  h000 0c00  0g00 00b0  00f0 000a  000e 0000                                  0000 d000  h000 0c00  0g00 00b0  00f0 000a  000e 0000                       0000 d000  h000 0c00  0g00 00b0  00f0 000a  000e 0000            0000 d000  h000 0c00  0g00 00b0  00f0 000a  000e 0000 0000 d000  h000 0c00  0g00 00b0  00f0 000a  000e 0000 ------------------------------------------------------------------------------------------------- 0000 d000  h000 dc00  hg00 dcb0  hgf0 dcba  hgfe dcba  hgfe 0cba  0gfe 00ba  00fe 000a  000e 0000 >> 32 -------------------------------------------------------------------------------------------------                                             0000 d000  h000 dc00  hg00 dcb0  hgf0 dcba  hgfe dcba   &                                                                                       1111 1111 -------------------------------------------------------------------------------------------------                                                                                         hgfe dcba  Note that the last two steps can be combined on some processors because the registers can be accessed as bytes; just multiply so that a register stores the upper 32 bits of the result and the take the low byte. Thus, it may take only 6 operations. Devised by Sean Anderson, July 13, 2001. Reverse the bits in a byte with 7 operations (no 64-bit): b = ((b * 0x0802LU & 0x22110LU) | (b * 0x8020LU & 0x88440LU)) * 0x10101LU >> 16;   Make sure you assign or cast the result to an unsigned char to remove garbage in the higher bits. Devised by Sean Anderson, July 13, 2001. Typo spotted and correction supplied by Mike Keith, January 3, 2002. Reverse an N-bit quantity in parallel in 5 * lg(N) operations: unsigned int v; // 32-bit word to reverse bit order  // swap odd and even bits v = ((v >> 1) & 0x55555555) | ((v & 0x55555555) << 1); // swap consecutive pairs v = ((v >> 2) & 0x33333333) | ((v & 0x33333333) << 2); // swap nibbles ...  v = ((v >> 4) & 0x0F0F0F0F) | ((v & 0x0F0F0F0F) << 4); // swap bytes v = ((v >> 8) & 0x00FF00FF) | ((v & 0x00FF00FF) << 8); // swap 2-byte long pairs v = ( v >> 16             ) | ( v               << 16);  The following variation is also O(lg(N)), however it requires more operations to reverse v. Its virtue is in taking less slightly memory by computing the constants on the fly.  unsigned int s = sizeof(v) * CHAR_BIT; // bit size; must be power of 2  unsigned int mask = ~0;          while ((s >>= 1) > 0)  {   mask ^= (mask << s);   v = ((v >> s) & mask) | ((v << s) & ~mask); }  These methods above are best suited to situations where N is large. If you use the above with 64-bit ints (or larger), then you need to add more lines (following the pattern); otherwise only the lower 32 bits will be reversed and the result will be in the lower 32 bits. See Dr. Dobb's Journal 1983, Edwin Freed's article on Binary Magic Numbers for more information. The second variation was suggested by Ken Raeburn on September 13, 2005. Veldmeijer mentioned that the first version could do without ANDS in the last line on March 19, 2006. Compute modulus division by 1 << s without a division operator  const unsigned int n;          // numerator const unsigned int s; const unsigned int d = 1U << s; // So d will be one of: 1, 2, 4, 8, 16, 32, ... unsigned int m;                // m will be n % d m = n & (d - 1);   Most programmers learn this trick early, but it was included for the sake of completeness. Compute modulus division by (1 << s) - 1 without a division operator  unsigned int n;                      // numerator const unsigned int s;                // s > 0 const unsigned int d = (1 << s) - 1; // so d is either 1, 3, 7, 15, 31, ...). unsigned int m;                      // n % d goes here.  for (m = n; n > d; n = m) {   for (m = 0; n; n >>= s)   {     m += n & d;   } } // Now m is a value from 0 to d, but since with modulus division // we want m to be 0 when it is d. m = m == d ? 0 : m;  This method of modulus division by an integer that is one less than a power of 2 takes at most 5 + (4 + 5 * ceil(N / s)) * ceil(lg(N / s)) operations, where N is the number of bits in the numerator. In other words, it takes at most O(N * lg(N)) time. Devised by Sean Anderson, August 15, 2001. Before Sean A. Irvine corrected me on June 17, 2004, I mistakenly commented that we could alternatively assign m = ((m + 1) & d) - 1; at the end. Michael Miller spotted a typo in the code April 25, 2005. Compute modulus division by (1 << s) - 1 in parallel without a division operator   // The following is for a word size of 32 bits!  static const unsigned int M[] =  {   0x00000000, 0x55555555, 0x33333333, 0xc71c71c7,     0x0f0f0f0f, 0xc1f07c1f, 0x3f03f03f, 0xf01fc07f,    0x00ff00ff, 0x07fc01ff, 0x3ff003ff, 0xffc007ff,   0xff000fff, 0xfc001fff, 0xf0003fff, 0xc0007fff,   0x0000ffff, 0x0001ffff, 0x0003ffff, 0x0007ffff,    0x000fffff, 0x001fffff, 0x003fffff, 0x007fffff,   0x00ffffff, 0x01ffffff, 0x03ffffff, 0x07ffffff,   0x0fffffff, 0x1fffffff, 0x3fffffff, 0x7fffffff };  static const unsigned int Q[][6] =  {   { 0,  0,  0,  0,  0,  0}, {16,  8,  4,  2,  1,  1}, {16,  8,  4,  2,  2,  2},   {15,  6,  3,  3,  3,  3}, {16,  8,  4,  4,  4,  4}, {15,  5,  5,  5,  5,  5},   {12,  6,  6,  6 , 6,  6}, {14,  7,  7,  7,  7,  7}, {16,  8,  8,  8,  8,  8},   { 9,  9,  9,  9,  9,  9}, {10, 10, 10, 10, 10, 10}, {11, 11, 11, 11, 11, 11},   {12, 12, 12, 12, 12, 12}, {13, 13, 13, 13, 13, 13}, {14, 14, 14, 14, 14, 14},   {15, 15, 15, 15, 15, 15}, {16, 16, 16, 16, 16, 16}, {17, 17, 17, 17, 17, 17},   {18, 18, 18, 18, 18, 18}, {19, 19, 19, 19, 19, 19}, {20, 20, 20, 20, 20, 20},   {21, 21, 21, 21, 21, 21}, {22, 22, 22, 22, 22, 22}, {23, 23, 23, 23, 23, 23},   {24, 24, 24, 24, 24, 24}, {25, 25, 25, 25, 25, 25}, {26, 26, 26, 26, 26, 26},   {27, 27, 27, 27, 27, 27}, {28, 28, 28, 28, 28, 28}, {29, 29, 29, 29, 29, 29},   {30, 30, 30, 30, 30, 30}, {31, 31, 31, 31, 31, 31} };  static const unsigned int R[][6] =  {   {0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000},   {0x0000ffff, 0x000000ff, 0x0000000f, 0x00000003, 0x00000001, 0x00000001},   {0x0000ffff, 0x000000ff, 0x0000000f, 0x00000003, 0x00000003, 0x00000003},   {0x00007fff, 0x0000003f, 0x00000007, 0x00000007, 0x00000007, 0x00000007},   {0x0000ffff, 0x000000ff, 0x0000000f, 0x0000000f, 0x0000000f, 0x0000000f},   {0x00007fff, 0x0000001f, 0x0000001f, 0x0000001f, 0x0000001f, 0x0000001f},   {0x00000fff, 0x0000003f, 0x0000003f, 0x0000003f, 0x0000003f, 0x0000003f},   {0x00003fff, 0x0000007f, 0x0000007f, 0x0000007f, 0x0000007f, 0x0000007f},   {0x0000ffff, 0x000000ff, 0x000000ff, 0x000000ff, 0x000000ff, 0x000000ff},   {0x000001ff, 0x000001ff, 0x000001ff, 0x000001ff, 0x000001ff, 0x000001ff},    {0x000003ff, 0x000003ff, 0x000003ff, 0x000003ff, 0x000003ff, 0x000003ff},    {0x000007ff, 0x000007ff, 0x000007ff, 0x000007ff, 0x000007ff, 0x000007ff},    {0x00000fff, 0x00000fff, 0x00000fff, 0x00000fff, 0x00000fff, 0x00000fff},    {0x00001fff, 0x00001fff, 0x00001fff, 0x00001fff, 0x00001fff, 0x00001fff},    {0x00003fff, 0x00003fff, 0x00003fff, 0x00003fff, 0x00003fff, 0x00003fff},    {0x00007fff, 0x00007fff, 0x00007fff, 0x00007fff, 0x00007fff, 0x00007fff},    {0x0000ffff, 0x0000ffff, 0x0000ffff, 0x0000ffff, 0x0000ffff, 0x0000ffff},    {0x0001ffff, 0x0001ffff, 0x0001ffff, 0x0001ffff, 0x0001ffff, 0x0001ffff},    {0x0003ffff, 0x0003ffff, 0x0003ffff, 0x0003ffff, 0x0003ffff, 0x0003ffff},    {0x0007ffff, 0x0007ffff, 0x0007ffff, 0x0007ffff, 0x0007ffff, 0x0007ffff},   {0x000fffff, 0x000fffff, 0x000fffff, 0x000fffff, 0x000fffff, 0x000fffff},    {0x001fffff, 0x001fffff, 0x001fffff, 0x001fffff, 0x001fffff, 0x001fffff},    {0x003fffff, 0x003fffff, 0x003fffff, 0x003fffff, 0x003fffff, 0x003fffff},    {0x007fffff, 0x007fffff, 0x007fffff, 0x007fffff, 0x007fffff, 0x007fffff},    {0x00ffffff, 0x00ffffff, 0x00ffffff, 0x00ffffff, 0x00ffffff, 0x00ffffff},   {0x01ffffff, 0x01ffffff, 0x01ffffff, 0x01ffffff, 0x01ffffff, 0x01ffffff},    {0x03ffffff, 0x03ffffff, 0x03ffffff, 0x03ffffff, 0x03ffffff, 0x03ffffff},    {0x07ffffff, 0x07ffffff, 0x07ffffff, 0x07ffffff, 0x07ffffff, 0x07ffffff},   {0x0fffffff, 0x0fffffff, 0x0fffffff, 0x0fffffff, 0x0fffffff, 0x0fffffff},   {0x1fffffff, 0x1fffffff, 0x1fffffff, 0x1fffffff, 0x1fffffff, 0x1fffffff},    {0x3fffffff, 0x3fffffff, 0x3fffffff, 0x3fffffff, 0x3fffffff, 0x3fffffff},    {0x7fffffff, 0x7fffffff, 0x7fffffff, 0x7fffffff, 0x7fffffff, 0x7fffffff} };  unsigned int n;       // numerator const unsigned int s; // s > 0 const unsigned int d = (1 << s) - 1; // so d is either 1, 3, 7, 15, 31, ...). unsigned int m;       // n % d goes here.  m = (n & M[s]) + ((n >> s) & M[s]);  for (const unsigned int * q = &Q[s][0], * r = &R[s][0]; m > d; q++, r++) {   m = (m >> *q) + (m & *r); } m = m == d ? 0 : m; // OR, less portably: m = m & -((signed)(m - d) >> s);  This method of finding modulus division by an integer that is one less than a power of 2 takes at most O(lg(N)) time, where N is the number of bits in the numerator (32 bits, for the code above). The number of operations is at most 12 + 9 * ceil(lg(N)). The tables may be removed if you know the denominator at compile time; just extract the few relevent entries and unroll the loop. It may be easily extended to more bits. It finds the result by summing the values in base (1 << s) in parallel. First every other base (1 << s) value is added to the previous one. Imagine that the result is written on a piece of paper. Cut the paper in half, so that half the values are on each cut piece. Align the values and sum them onto a new piece of paper. Repeat by cutting this paper in half (which will be a quarter of the size of the previous one) and summing, until you cannot cut further. After performing lg(N/s/2) cuts, we cut no more; just continue to add the values and put the result onto a new piece of paper as before, while there are at least two s-bit values. Devised by Sean Anderson, August 20, 2001. A typo was spotted by Randy E. Bryant on May 3, 2005 (after pasting the code, I had later added ""unsinged"" to a variable declaration). As in the previous hack, I mistakenly commented that we could alternatively assign m = ((m + 1) & d) - 1; at the end, and Don Knuth corrected me on April 19, 2006 and suggested m = m & -((signed)(m - d) >> s). On June 18, 2009 Sean Irvine proposed a change that used ((n >> s) & M[s]) instead of ((n & ~M[s]) >> s), which typically requires fewer operations because the M[s] constant is already loaded. Find the log base 2 of an integer with the MSB N set in O(N) operations (the obvious way)  unsigned int v; // 32-bit word to find the log base 2 of unsigned int r = 0; // r will be lg(v)  while (v >>= 1) // unroll for more speed... {   r++; }  The log base 2 of an integer is the same as the position of the highest bit set (or most significant bit set, MSB). The following log base 2 methods are faster than this one. Find the integer log base 2 of an integer with an 64-bit IEEE float  int v; // 32-bit integer to find the log base 2 of int r; // result of log_2(v) goes here union { unsigned int u[2]; double d; } t; // temp  t.u[__FLOAT_WORD_ORDER==LITTLE_ENDIAN] = 0x43300000; t.u[__FLOAT_WORD_ORDER!=LITTLE_ENDIAN] = v; t.d -= 4503599627370496.0; r = (t.u[__FLOAT_WORD_ORDER==LITTLE_ENDIAN] >> 20) - 0x3FF;  The code above loads a 64-bit (IEEE-754 floating-point) double with a 32-bit integer (with no paddding bits) by storing the integer in the mantissa while the exponent is set to 252. From this newly minted double, 252 (expressed as a double) is subtracted, which sets the resulting exponent to the log base 2 of the input value, v. All that is left is shifting the exponent bits into position (20 bits right) and subtracting the bias, 0x3FF (which is 1023 decimal). This technique only takes 5 operations, but many CPUs are slow at manipulating doubles, and the endianess of the architecture must be accommodated. Eric Cole sent me this on January 15, 2006. Evan Felix pointed out a typo on April 4, 2006. Vincent Lefèvre told me on July 9, 2008 to change the endian check to use the float's endian, which could differ from the integer's endian. Find the log base 2 of an integer with a lookup table  static const char LogTable256[256] =  { #define LT(n) n, n, n, n, n, n, n, n, n, n, n, n, n, n, n, n     -1, 0, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,     LT(4), LT(5), LT(5), LT(6), LT(6), LT(6), LT(6),     LT(7), LT(7), LT(7), LT(7), LT(7), LT(7), LT(7), LT(7) };  unsigned int v; // 32-bit word to find the log of unsigned r;     // r will be lg(v) register unsigned int t, tt; // temporaries  if (tt = v >> 16) {   r = (t = tt >> 8) ? 24 + LogTable256[t] : 16 + LogTable256[tt]; } else  {   r = (t = v >> 8) ? 8 + LogTable256[t] : LogTable256[v]; }  The lookup table method takes only about 7 operations to find the log of a 32-bit value. If extended for 64-bit quantities, it would take roughly 9 operations. Another operation can be trimmed off by using four tables, with the possible additions incorporated into each. Using int table elements may be faster, depending on your architecture. The code above is tuned to uniformly distributed output values. If your inputs are evenly distributed across all 32-bit values, then consider using the following:  if (tt = v >> 24)  {   r = 24 + LogTable256[tt]; }  else if (tt = v >> 16)  {   r = 16 + LogTable256[tt]; }  else if (tt = v >> 8)  {   r = 8 + LogTable256[tt]; }  else  {   r = LogTable256[v]; }  To initially generate the log table algorithmically:  LogTable256[0] = LogTable256[1] = 0; for (int i = 2; i < 256; i++)  {   LogTable256[i] = 1 + LogTable256[i / 2]; } LogTable256[0] = -1; // if you want log(0) to return -1  Behdad Esfahbod and I shaved off a fraction of an operation (on average) on May 18, 2005. Yet another fraction of an operation was removed on November 14, 2006 by Emanuel Hoogeveen. The variation that is tuned to evenly distributed input values was suggested by David A. Butterfield on September 19, 2008. Venkat Reddy told me on January 5, 2009 that log(0) should return -1 to indicate an error, so I changed the first entry in the table to that. Find the log base 2 of an N-bit integer in O(lg(N)) operations  unsigned int v;  // 32-bit value to find the log2 of  const unsigned int b[] = {0x2, 0xC, 0xF0, 0xFF00, 0xFFFF0000}; const unsigned int S[] = {1, 2, 4, 8, 16}; int i;  register unsigned int r = 0; // result of log2(v) will go here for (i = 4; i >= 0; i--) // unroll for speed... {   if (v & b[i])   {     v >>= S[i];     r |= S[i];   }  }   // OR (IF YOUR CPU BRANCHES SLOWLY):  unsigned int v;	         // 32-bit value to find the log2 of  register unsigned int r; // result of log2(v) will go here register unsigned int shift;  r =     (v > 0xFFFF) << 4; v >>= r; shift = (v > 0xFF  ) << 3; v >>= shift; r |= shift; shift = (v > 0xF   ) << 2; v >>= shift; r |= shift; shift = (v > 0x3   ) << 1; v >>= shift; r |= shift;                                         r |= (v >> 1);   // OR (IF YOU KNOW v IS A POWER OF 2):  unsigned int v;  // 32-bit value to find the log2 of  static const unsigned int b[] = {0xAAAAAAAA, 0xCCCCCCCC, 0xF0F0F0F0,                                   0xFF00FF00, 0xFFFF0000}; register unsigned int r = (v & b[0]) != 0; for (i = 4; i > 0; i--) // unroll for speed... {   r |= ((v & b[i]) != 0) << i; }  Of course, to extend the code to find the log of a 33- to 64-bit number, we would append another element, 0xFFFFFFFF00000000, to b, append 32 to S, and loop from 5 to 0. This method is much slower than the earlier table-lookup version, but if you don't want big table or your architecture is slow to access memory, it's a good choice. The second variation involves slightly more operations, but it may be faster on machines with high branch costs (e.g. PowerPC). The second version was sent to me by Eric Cole on January 7, 2006. Andrew Shapira subsequently trimmed a few operations off of it and sent me his variation (above) on Sept. 1, 2007. The third variation was suggested to me by John Owens on April 24, 2002; it's faster, but it is only suitable when the input is known to be a power of 2. On May 25, 2003, Ken Raeburn suggested improving the general case by using smaller numbers for b[], which load faster on some architectures (for instance if the word size is 16 bits, then only one load instruction may be needed). These values work for the general version, but not for the special-case version below it, where v is a power of 2; Glenn Slayden brought this oversight to my attention on December 12, 2003. Find the log base 2 of an N-bit integer in O(lg(N)) operations with multiply and lookup  uint32_t v; // find the log base 2 of 32-bit v int r;      // result goes here  static const int MultiplyDeBruijnBitPosition[32] =  {   0, 9, 1, 10, 13, 21, 2, 29, 11, 14, 16, 18, 22, 25, 3, 30,   8, 12, 20, 28, 15, 17, 24, 7, 19, 27, 23, 6, 26, 5, 4, 31 };  v |= v >> 1; // first round down to one less than a power of 2  v |= v >> 2; v |= v >> 4; v |= v >> 8; v |= v >> 16;  r = MultiplyDeBruijnBitPosition[(uint32_t)(v * 0x07C4ACDDU) >> 27];  The code above computes the log base 2 of a 32-bit integer with a small table lookup and multiply. It requires only 13 operations, compared to (up to) 20 for the previous method. The purely table-based method requires the fewest operations, but this offers a reasonable compromise between table size and speed. If you know that v is a power of 2, then you only need the following:  static const int MultiplyDeBruijnBitPosition2[32] =  {   0, 1, 28, 2, 29, 14, 24, 3, 30, 22, 20, 15, 25, 17, 4, 8,    31, 27, 13, 23, 21, 19, 16, 7, 26, 12, 18, 6, 11, 5, 10, 9 }; r = MultiplyDeBruijnBitPosition2[(uint32_t)(v * 0x077CB531U) >> 27];  Eric Cole devised this January 8, 2006 after reading about the entry below to round up to a power of 2 and the method below for computing the number of trailing bits with a multiply and lookup using a DeBruijn sequence. On December 10, 2009, Mark Dickinson shaved off a couple operations by requiring v be rounded up to one less than the next power of 2 rather than the power of 2. Find integer log base 10 of an integer  unsigned int v; // non-zero 32-bit integer value to compute the log base 10 of  int r;          // result goes here int t;          // temporary  static unsigned int const PowersOf10[] =      {1, 10, 100, 1000, 10000, 100000,      1000000, 10000000, 100000000, 1000000000};  t = (IntegerLogBase2(v) + 1) * 1233 >> 12; // (use a lg2 method from above) r = t - (v < PowersOf10[t]);  The integer log base 10 is computed by first using one of the techniques above for finding the log base 2. By the relationship log10(v) = log2(v) / log2(10), we need to multiply it by 1/log2(10), which is approximately 1233/4096, or 1233 followed by a right shift of 12. Adding one is needed because the IntegerLogBase2 rounds down. Finally, since the value t is only an approximation that may be off by one, the exact value is found by subtracting the result of v < PowersOf10[t]. This method takes 6 more operations than IntegerLogBase2. It may be sped up (on machines with fast memory access) by modifying the log base 2 table-lookup method above so that the entries hold what is computed for t (that is, pre-add, -mulitply, and -shift). Doing so would require a total of only 9 operations to find the log base 10, assuming 4 tables were used (one for each byte of v). Eric Cole suggested I add a version of this on January 7, 2006. Find integer log base 10 of an integer the obvious way  unsigned int v; // non-zero 32-bit integer value to compute the log base 10 of  int r;          // result goes here  r = (v >= 1000000000) ? 9 : (v >= 100000000) ? 8 : (v >= 10000000) ? 7 :      (v >= 1000000) ? 6 : (v >= 100000) ? 5 : (v >= 10000) ? 4 :      (v >= 1000) ? 3 : (v >= 100) ? 2 : (v >= 10) ? 1 : 0;  This method works well when the input is uniformly distributed over 32-bit values because 76% of the inputs are caught by the first compare, 21% are caught by the second compare, 2% are caught by the third, and so on (chopping the remaining down by 90% with each comparision). As a result, less than 2.6 operations are needed on average. On April 18, 2007, Emanuel Hoogeveen suggested a variation on this where the conditions used divisions, which were not as fast as simple comparisons. Find integer log base 2 of a 32-bit IEEE float  const float v; // find int(log2(v)), where v > 0.0 && finite(v) && isnormal(v) int c;         // 32-bit int c gets the result;  c = *(const int *) &v;  // OR, for portability:  memcpy(&c, &v, sizeof c); c = (c >> 23) - 127;  The above is fast, but IEEE 754-compliant architectures utilize subnormal (also called denormal) floating point numbers. These have the exponent bits set to zero (signifying pow(2,-127)), and the mantissa is not normalized, so it contains leading zeros and thus the log2 must be computed from the mantissa. To accomodate for subnormal numbers, use the following:  const float v;              // find int(log2(v)), where v > 0.0 && finite(v) int c;                      // 32-bit int c gets the result; int x = *(const int *) &v;  // OR, for portability:  memcpy(&x, &v, sizeof x);  c = x >> 23;            if (c) {   c -= 127; } else { // subnormal, so recompute using mantissa: c = intlog2(x) - 149;   register unsigned int t; // temporary   // Note that LogTable256 was defined earlier   if (t = x >> 16)   {     c = LogTable256[t] - 133;   }   else   {     c = (t = x >> 8) ? LogTable256[t] - 141 : LogTable256[x] - 149;   } }  On June 20, 2004, Sean A. Irvine suggested that I include code to handle subnormal numbers. On June 11, 2005, Falk Hüffner pointed out that ISO C99 6.5/7 specified undefined behavior for the common type punning idiom *(int *)&, though it has worked on 99.9% of C compilers. He proposed using memcpy for maximum portability or a union with a float and an int for better code generation than memcpy on some compilers. Find integer log base 2 of the pow(2, r)-root of a 32-bit IEEE float (for unsigned integer r)  const int r; const float v; // find int(log2(pow((double) v, 1. / pow(2, r)))),                 // where isnormal(v) and v > 0 int c;         // 32-bit int c gets the result;  c = *(const int *) &v;  // OR, for portability:  memcpy(&c, &v, sizeof c); c = ((((c - 0x3f800000) >> r) + 0x3f800000) >> 23) - 127;  So, if r is 0, for example, we have c = int(log2((double) v)). If r is 1, then we have c = int(log2(sqrt((double) v))). If r is 2, then we have c = int(log2(pow((double) v, 1./4))). On June 11, 2005, Falk Hüffner pointed out that ISO C99 6.5/7 left the type punning idiom *(int *)& undefined, and he suggested using memcpy. Count the consecutive zero bits (trailing) on the right linearly  unsigned int v;  // input to count trailing zero bits int c;  // output: c will count v's trailing zero bits,         // so if v is 1101000 (base 2), then c will be 3 if (v) {   v = (v ^ (v - 1)) >> 1;  // Set v's trailing 0s to 1s and zero rest   for (c = 0; v; c++)   {     v >>= 1;   } } else {   c = CHAR_BIT * sizeof(v); }  The average number of trailing zero bits in a (uniformly distributed) random binary number is one, so this O(trailing zeros) solution isn't that bad compared to the faster methods below. Jim Cole suggested I add a linear-time method for counting the trailing zeros on August 15, 2007. On October 22, 2007, Jason Cunningham pointed out that I had neglected to paste the unsigned modifier for v. Count the consecutive zero bits (trailing) on the right in parallel  unsigned int v;      // 32-bit word input to count zero bits on right unsigned int c = 32; // c will be the number of zero bits on the right v &= -signed(v); if (v) c--; if (v & 0x0000FFFF) c -= 16; if (v & 0x00FF00FF) c -= 8; if (v & 0x0F0F0F0F) c -= 4; if (v & 0x33333333) c -= 2; if (v & 0x55555555) c -= 1;  Here, we are basically doing the same operations as finding the log base 2 in parallel, but we first isolate the lowest 1 bit, and then proceed with c starting at the maximum and decreasing. The number of operations is at most 3 * lg(N) + 4, roughly, for N bit words. Bill Burdick suggested an optimization, reducing the time from 4 * lg(N) on February 4, 2011. Count the consecutive zero bits (trailing) on the right by binary search  unsigned int v;     // 32-bit word input to count zero bits on right unsigned int c;     // c will be the number of zero bits on the right,                     // so if v is 1101000 (base 2), then c will be 3 // NOTE: if 0 == v, then c = 31. if (v & 0x1)  {   // special case for odd v (assumed to happen half of the time)   c = 0; } else {   c = 1;   if ((v & 0xffff) == 0)    {       v >>= 16;       c += 16;   }   if ((v & 0xff) == 0)    {       v >>= 8;       c += 8;   }   if ((v & 0xf) == 0)    {       v >>= 4;     c += 4;   }   if ((v & 0x3) == 0)    {       v >>= 2;     c += 2;   }   c -= v & 0x1; }	  The code above is similar to the previous method, but it computes the number of trailing zeros by accumulating c in a manner akin to binary search. In the first step, it checks if the bottom 16 bits of v are zeros, and if so, shifts v right 16 bits and adds 16 to c, which reduces the number of bits in v to consider by half. Each of the subsequent conditional steps likewise halves the number of bits until there is only 1. This method is faster than the last one (by about 33%) because the bodies of the if statements are executed less often. Matt Whitlock suggested this on January 25, 2006. Andrew Shapira shaved a couple operations off on Sept. 5, 2007 (by setting c=1 and unconditionally subtracting at the end). Count the consecutive zero bits (trailing) on the right by casting to a float  unsigned int v;            // find the number of trailing zeros in v int r;                     // the result goes here float f = (float)(v & -v); // cast the least significant bit in v to a float r = (*(uint32_t *)&f >> 23) - 0x7f;  Although this only takes about 6 operations, the time to convert an integer to a float can be high on some machines. The exponent of the 32-bit IEEE floating point representation is shifted down, and the bias is subtracted to give the position of the least significant 1 bit set in v. If v is zero, then the result is -127. Count the consecutive zero bits (trailing) on the right with modulus division and lookup  unsigned int v;  // find the number of trailing zeros in v int r;           // put the result in r static const int Mod37BitPosition[] = // map a bit value mod 37 to its position {   32, 0, 1, 26, 2, 23, 27, 0, 3, 16, 24, 30, 28, 11, 0, 13, 4,   7, 17, 0, 25, 22, 31, 15, 29, 10, 12, 6, 0, 21, 14, 9, 5,   20, 8, 19, 18 }; r = Mod37BitPosition[(-v & v) % 37];  The code above finds the number of zeros that are trailing on the right, so binary 0100 would produce 2. It makes use of the fact that the first 32 bit position values are relatively prime with 37, so performing a modulus division with 37 gives a unique number from 0 to 36 for each. These numbers may then be mapped to the number of zeros using a small lookup table. It uses only 4 operations, however indexing into a table and performing modulus division may make it unsuitable for some situations. I came up with this independently and then searched for a subsequence of the table values, and found it was invented earlier by Reiser, according to Hacker's Delight. Count the consecutive zero bits (trailing) on the right with multiply and lookup  unsigned int v;  // find the number of trailing zeros in 32-bit v  int r;           // result goes here static const int MultiplyDeBruijnBitPosition[32] =  {   0, 1, 28, 2, 29, 14, 24, 3, 30, 22, 20, 15, 25, 17, 4, 8,    31, 27, 13, 23, 21, 19, 16, 7, 26, 12, 18, 6, 11, 5, 10, 9 }; r = MultiplyDeBruijnBitPosition[((uint32_t)((v & -v) * 0x077CB531U)) >> 27];  Converting bit vectors to indices of set bits is an example use for this. It requires one more operation than the earlier one involving modulus division, but the multiply may be faster. The expression (v & -v) extracts the least significant 1 bit from v. The constant 0x077CB531UL is a de Bruijn sequence, which produces a unique pattern of bits into the high 5 bits for each possible bit position that it is multiplied against. When there are no bits set, it returns 0. More information can be found by reading the paper Using de Bruijn Sequences to Index 1 in a Computer Word by Charles E. Leiserson, Harald Prokof, and Keith H. Randall. On October 8, 2005 Andrew Shapira suggested I add this. Dustin Spicuzza asked me on April 14, 2009 to cast the result of the multiply to a 32-bit type so it would work when compiled with 64-bit ints. Round up to the next highest power of 2 by float casting  unsigned int const v; // Round this 32-bit value to the next highest power of 2 unsigned int r;       // Put the result here. (So v=3 -> r=4; v=8 -> r=8)  if (v > 1)  {   float f = (float)v;   unsigned int const t = 1U << ((*(unsigned int *)&f >> 23) - 0x7f);   r = t << (t < v); } else  {   r = 1; }  The code above uses 8 operations, but works on all v <= (1<<31). Quick and dirty version, for domain of 1 < v < (1<<25):  float f = (float)(v - 1);   r = 1U << ((*(unsigned int*)(&f) >> 23) - 126);  Although the quick and dirty version only uses around 6 operations, it is roughly three times slower than the technique below (which involves 12 operations) when benchmarked on an Athlon™ XP 2100+ CPU. Some CPUs will fare better with it, though. On September 27, 2005 Andi Smithers suggested I include a technique for casting to floats to find the lg of a number for rounding up to a power of 2. Similar to the quick and dirty version here, his version worked with values less than (1<<25), due to mantissa rounding, but it used one more operation. Round up to the next highest power of 2  unsigned int v; // compute the next highest power of 2 of 32-bit v  v--; v |= v >> 1; v |= v >> 2; v |= v >> 4; v |= v >> 8; v |= v >> 16; v++;  In 12 operations, this code computes the next highest power of 2 for a 32-bit integer. The result may be expressed by the formula 1U << (lg(v - 1) + 1). Note that in the edge case where v is 0, it returns 0, which isn't a power of 2; you might append the expression v += (v == 0) to remedy this if it matters. It would be faster by 2 operations to use the formula and the log base 2 method that uses a lookup table, but in some situations, lookup tables are not suitable, so the above code may be best. (On a Athlon™ XP 2100+ I've found the above shift-left and then OR code is as fast as using a single BSR assembly language instruction, which scans in reverse to find the highest set bit.) It works by copying the highest set bit to all of the lower bits, and then adding one, which results in carries that set all of the lower bits to 0 and one bit beyond the highest set bit to 1. If the original number was a power of 2, then the decrement will reduce it to one less, so that we round up to the same original value. You might alternatively compute the next higher power of 2 in only 8 or 9 operations using a lookup table for floor(lg(v)) and then evaluating 1<<(1+floor(lg(v))); Atul Divekar suggested I mention this on September 5, 2010. Devised by Sean Anderson, Sepember 14, 2001. Pete Hart pointed me to a couple newsgroup posts by him and William Lewis in February of 1997, where they arrive at the same algorithm. Interleave bits the obvious way  unsigned short x;   // Interleave bits of x and y, so that all of the unsigned short y;   // bits of x are in the even positions and y in the odd; unsigned int z = 0; // z gets the resulting Morton Number.  for (int i = 0; i < sizeof(x) * CHAR_BIT; i++) // unroll for more speed... {   z |= (x & 1U << i) << i | (y & 1U << i) << (i + 1); }  Interleaved bits (aka Morton numbers) are useful for linearizing 2D integer coordinates, so x and y are combined into a single number that can be compared easily and has the property that a number is usually close to another if their x and y values are close. Interleave bits by table lookup  static const unsigned short MortonTable256[256] =  {   0x0000, 0x0001, 0x0004, 0x0005, 0x0010, 0x0011, 0x0014, 0x0015,    0x0040, 0x0041, 0x0044, 0x0045, 0x0050, 0x0051, 0x0054, 0x0055,    0x0100, 0x0101, 0x0104, 0x0105, 0x0110, 0x0111, 0x0114, 0x0115,    0x0140, 0x0141, 0x0144, 0x0145, 0x0150, 0x0151, 0x0154, 0x0155,    0x0400, 0x0401, 0x0404, 0x0405, 0x0410, 0x0411, 0x0414, 0x0415,    0x0440, 0x0441, 0x0444, 0x0445, 0x0450, 0x0451, 0x0454, 0x0455,    0x0500, 0x0501, 0x0504, 0x0505, 0x0510, 0x0511, 0x0514, 0x0515,    0x0540, 0x0541, 0x0544, 0x0545, 0x0550, 0x0551, 0x0554, 0x0555,    0x1000, 0x1001, 0x1004, 0x1005, 0x1010, 0x1011, 0x1014, 0x1015,    0x1040, 0x1041, 0x1044, 0x1045, 0x1050, 0x1051, 0x1054, 0x1055,    0x1100, 0x1101, 0x1104, 0x1105, 0x1110, 0x1111, 0x1114, 0x1115,    0x1140, 0x1141, 0x1144, 0x1145, 0x1150, 0x1151, 0x1154, 0x1155,    0x1400, 0x1401, 0x1404, 0x1405, 0x1410, 0x1411, 0x1414, 0x1415,    0x1440, 0x1441, 0x1444, 0x1445, 0x1450, 0x1451, 0x1454, 0x1455,    0x1500, 0x1501, 0x1504, 0x1505, 0x1510, 0x1511, 0x1514, 0x1515,    0x1540, 0x1541, 0x1544, 0x1545, 0x1550, 0x1551, 0x1554, 0x1555,    0x4000, 0x4001, 0x4004, 0x4005, 0x4010, 0x4011, 0x4014, 0x4015,    0x4040, 0x4041, 0x4044, 0x4045, 0x4050, 0x4051, 0x4054, 0x4055,    0x4100, 0x4101, 0x4104, 0x4105, 0x4110, 0x4111, 0x4114, 0x4115,    0x4140, 0x4141, 0x4144, 0x4145, 0x4150, 0x4151, 0x4154, 0x4155,    0x4400, 0x4401, 0x4404, 0x4405, 0x4410, 0x4411, 0x4414, 0x4415,    0x4440, 0x4441, 0x4444, 0x4445, 0x4450, 0x4451, 0x4454, 0x4455,    0x4500, 0x4501, 0x4504, 0x4505, 0x4510, 0x4511, 0x4514, 0x4515,    0x4540, 0x4541, 0x4544, 0x4545, 0x4550, 0x4551, 0x4554, 0x4555,    0x5000, 0x5001, 0x5004, 0x5005, 0x5010, 0x5011, 0x5014, 0x5015,    0x5040, 0x5041, 0x5044, 0x5045, 0x5050, 0x5051, 0x5054, 0x5055,    0x5100, 0x5101, 0x5104, 0x5105, 0x5110, 0x5111, 0x5114, 0x5115,    0x5140, 0x5141, 0x5144, 0x5145, 0x5150, 0x5151, 0x5154, 0x5155,    0x5400, 0x5401, 0x5404, 0x5405, 0x5410, 0x5411, 0x5414, 0x5415,    0x5440, 0x5441, 0x5444, 0x5445, 0x5450, 0x5451, 0x5454, 0x5455,    0x5500, 0x5501, 0x5504, 0x5505, 0x5510, 0x5511, 0x5514, 0x5515,    0x5540, 0x5541, 0x5544, 0x5545, 0x5550, 0x5551, 0x5554, 0x5555 };  unsigned short x; // Interleave bits of x and y, so that all of the unsigned short y; // bits of x are in the even positions and y in the odd; unsigned int z;   // z gets the resulting 32-bit Morton Number.  z = MortonTable256[y >> 8]   << 17 |      MortonTable256[x >> 8]   << 16 |     MortonTable256[y & 0xFF] <<  1 |      MortonTable256[x & 0xFF];   For more speed, use an additional table with values that are MortonTable256 pre-shifted one bit to the left. This second table could then be used for the y lookups, thus reducing the operations by two, but almost doubling the memory required. Extending this same idea, four tables could be used, with two of them pre-shifted by 16 to the left of the previous two, so that we would only need 11 operations total. Interleave bits with 64-bit multiply In 11 operations, this version interleaves bits of two bytes (rather than shorts, as in the other versions), but many of the operations are 64-bit multiplies so it isn't appropriate for all machines. The input parameters, x and y, should be less than 256.  unsigned char x;  // Interleave bits of (8-bit) x and y, so that all of the unsigned char y;  // bits of x are in the even positions and y in the odd; unsigned short z; // z gets the resulting 16-bit Morton Number.  z = ((x * 0x0101010101010101ULL & 0x8040201008040201ULL) *       0x0102040810204081ULL >> 49) & 0x5555 |     ((y * 0x0101010101010101ULL & 0x8040201008040201ULL) *       0x0102040810204081ULL >> 48) & 0xAAAA;  Holger Bettag was inspired to suggest this technique on October 10, 2004 after reading the multiply-based bit reversals here. Interleave bits by Binary Magic Numbers  static const unsigned int B[] = {0x55555555, 0x33333333, 0x0F0F0F0F, 0x00FF00FF}; static const unsigned int S[] = {1, 2, 4, 8};  unsigned int x; // Interleave lower 16 bits of x and y, so the bits of x unsigned int y; // are in the even positions and bits from y in the odd; unsigned int z; // z gets the resulting 32-bit Morton Number.                   // x and y must initially be less than 65536.  x = (x | (x << S[3])) & B[3]; x = (x | (x << S[2])) & B[2]; x = (x | (x << S[1])) & B[1]; x = (x | (x << S[0])) & B[0];  y = (y | (y << S[3])) & B[3]; y = (y | (y << S[2])) & B[2]; y = (y | (y << S[1])) & B[1]; y = (y | (y << S[0])) & B[0];  z = x | (y << 1);  Determine if a word has a zero byte  // Fewer operations: unsigned int v; // 32-bit word to check if any 8-bit byte in it is 0 bool hasZeroByte = ~((((v & 0x7F7F7F7F) + 0x7F7F7F7F) | v) | 0x7F7F7F7F);  The code above may be useful when doing a fast string copy in which a word is copied at a time; it uses 5 operations. On the other hand, testing for a null byte in the obvious ways (which follow) have at least 7 operations (when counted in the most sparing way), and at most 12.  // More operations: bool hasNoZeroByte = ((v & 0xff) && (v & 0xff00) && (v & 0xff0000) && (v & 0xff000000)) // OR: unsigned char * p = (unsigned char *) &v;   bool hasNoZeroByte = *p && *(p + 1) && *(p + 2) && *(p + 3);  The code at the beginning of this section (labeled ""Fewer operations"") works by first zeroing the high bits of the 4 bytes in the word. Subsequently, it adds a number that will result in an overflow to the high bit of a byte if any of the low bits were initialy set. Next the high bits of the original word are ORed with these values; thus, the high bit of a byte is set iff any bit in the byte was set. Finally, we determine if any of these high bits are zero by ORing with ones everywhere except the high bits and inverting the result. Extending to 64 bits is trivial; simply increase the constants to be 0x7F7F7F7F7F7F7F7F. For an additional improvement, a fast pretest that requires only 4 operations may be performed to determine if the word may have a zero byte. The test also returns true if the high byte is 0x80, so there are occasional false positives, but the slower and more reliable version above may then be used on candidates for an overall increase in speed with correct output.  bool hasZeroByte = ((v + 0x7efefeff) ^ ~v) & 0x81010100; if (hasZeroByte) // or may just have 0x80 in the high byte {   hasZeroByte = ~((((v & 0x7F7F7F7F) + 0x7F7F7F7F) | v) | 0x7F7F7F7F); }  There is yet a faster method — use hasless(v, 1), which is defined below; it works in 4 operations and requires no subsquent verification. It simplifies to #define haszero(v) (((v) - 0x01010101UL) & ~(v) & 0x80808080UL) The subexpression (v - 0x01010101UL), evaluates to a high bit set in any byte whenever the corresponding byte in v is zero or greater than 0x80. The sub-expression ~v & 0x80808080UL evaluates to high bits set in bytes where the byte of v doesn't have its high bit set (so the byte was less than 0x80). Finally, by ANDing these two sub-expressions the result is the high bits set where the bytes in v were zero, since the high bits set due to a value greater than 0x80 in the first sub-expression are masked off by the second. Paul Messmer suggested the fast pretest improvement on October 2, 2004. Juha Järvi later suggested hasless(v, 1) on April 6, 2005, which he found on Paul Hsieh's Assembly Lab; previously it was written in a newsgroup post on April 27, 1987 by Alan Mycroft. Determine if a word has a byte equal to n We may want to know if any byte in a word has a specific value. To do so, we can XOR the value to test with a word that has been filled with the byte values in which we're interested. Because XORing a value with itself results in a zero byte and nonzero otherwise, we can pass the result to haszero.  #define hasvalue(x,n) \ (haszero((x) ^ (~0UL/255 * (n))))  Stephen M Bennet suggested this on December 13, 2009 after reading the entry for haszero. Determine if a word has a byte less than n Test if a word x contains an unsigned byte with value < n. Specifically for n=1, it can be used to find a 0-byte by examining one long at a time, or any byte by XORing x with a mask first. Uses 4 arithmetic/logical operations when n is constant. Requirements: x>=0; 0<=n<=128  #define hasless(x,n) (((x)-~0UL/255*(n))&~(x)&~0UL/255*128)  To count the number of bytes in x that are less than n in 7 operations, use  #define countless(x,n) \ (((~0UL/255*(127+(n))-((x)&~0UL/255*127))&~(x)&~0UL/255*128)/128%255)  Juha Järvi sent this clever technique to me on April 6, 2005. The countless macro was added by Sean Anderson on April 10, 2005, inspired by Juha's countmore, below. Determine if a word has a byte greater than n Test if a word x contains an unsigned byte with value > n. Uses 3 arithmetic/logical operations when n is constant. Requirements: x>=0; 0<=n<=127  #define hasmore(x,n) (((x)+~0UL/255*(127-(n))|(x))&~0UL/255*128)  To count the number of bytes in x that are more than n in 6 operations, use:  #define countmore(x,n) \ (((((x)&~0UL/255*127)+~0UL/255*(127-(n))|(x))&~0UL/255*128)/128%255)  The macro hasmore was suggested by Juha Järvi on April 6, 2005, and he added countmore on April 8, 2005. Determine if a word has a byte between m and n When m < n, this technique tests if a word x contains an unsigned byte value, such that m < value < n. It uses 7 arithmetic/logical operations when n and m are constant. Note: Bytes that equal n can be reported by likelyhasbetween as false positives, so this should be checked by character if a certain result is needed. Requirements: x>=0; 0<=m<=127; 0<=n<=128  #define likelyhasbetween(x,m,n) \ ((((x)-~0UL/255*(n))&~(x)&((x)&~0UL/255*127)+~0UL/255*(127-(m)))&~0UL/255*128)  This technique would be suitable for a fast pretest. A variation that takes one more operation (8 total for constant m and n) but provides the exact answer is:  #define hasbetween(x,m,n) \ ((~0UL/255*(127+(n))-((x)&~0UL/255*127)&~(x)&((x)&~0UL/255*127)+~0UL/255*(127-(m)))&~0UL/255*128)  To count the number of bytes in x that are between m and n (exclusive) in 10 operations, use:  #define countbetween(x,m,n) (hasbetween(x,m,n)/128%255)  Juha Järvi suggested likelyhasbetween on April 6, 2005. From there, Sean Anderson created hasbetween and countbetween on April 10, 2005. Compute the lexicographically next bit permutation Suppose we have a pattern of N bits set to 1 in an integer and we want the next permutation of N 1 bits in a lexicographical sense. For example, if N is 3 and the bit pattern is 00010011, the next patterns would be 00010101, 00010110, 00011001,00011010, 00011100, 00100011, and so forth. The following is a fast way to compute the next permutation.  unsigned int v; // current permutation of bits  unsigned int w; // next permutation of bits  unsigned int t = v | (v - 1); // t gets v's least significant 0 bits set to 1 // Next set to 1 the most significant bit to change,  // set to 0 the least significant ones, and add the necessary 1 bits. w = (t + 1) | (((~t & -~t) - 1) >> (__builtin_ctz(v) + 1));    The __builtin_ctz(v) GNU C compiler intrinsic for x86 CPUs returns the number of trailing zeros. If you are using Microsoft compilers for x86, the intrinsic is _BitScanForward. These both emit a bsf instruction, but equivalents may be available for other architectures. If not, then consider using one of the methods for counting the consecutive zero bits mentioned earlier. Here is another version that tends to be slower because of its division operator, but it does not require counting the trailing zeros.  unsigned int t = (v | (v - 1)) + 1;   w = t | ((((t & -t) / (v & -v)) >> 1) - 1);    Thanks to Dario Sneidermanis of Argentina, who provided this on November 28, 2009. A Belorussian translation (provided by Webhostingrating) is available."	"null"	"null"	""	"true"
"Advanced"	"I do not know C"	"http://kukuruku.co/hub/programming/i-do-not-know-c"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"I Do Not Know C Please click here if you are not redirected within a few seconds. ☰ Home Hubs Companies Stream Become an author / Sign in I Do Not Know C Written by Dmitri Gribenko | 3 March 2015 | Original Source Tweet The purpose of this article is to make everyone (especially C programmers) say: “I do not know C”. I want to show that the dark corners of C are much closer than it seems, and even trivial code lines may contain undefined behavior. The article is organized as a set of questions and answers. All the examples are separate files of the source code. 1. int i; int i = 10; Q: Is this code correct? (Will there occur an error related to the fact that the variable is defined twice? Reminding you that it’s a separate source file and not a part of the function body or compound statement) Answer A: Yes, this code is correct. The first line is the tentative definition that becomes the «definition» after the compiler processes the definition (the second line). 2. extern void bar(void); void foo(int *x) {   int y = *x;  /* (1) */   if(!x)       /* (2) */   {     return;    /* (3) */   }   bar();   return; } Q: Turns out, bar() is invoked even when x is the null pointer (and the program does not crash). Is it the optimizer’s error, or is everything correct? Answer A: Everything’s correct. If x is the null pointer, undefined behavior occurs in line (1), and no one owes anything the programmer: the program does not have to crash in line (1), or make a return in line (2) in case it has managed to execute line (1). If we talk about the rules the compiler has been guided by, it all happens the following way. After the analysis of line (1), the compiler thinks that x cannot be a null pointer, and eliminates (2) and (3) as the dead code. Variable y is removed as unused. Reading from memory is also eliminated, since the *x type is not qualified as volatile. That’s how the unused variable has removed the check for the null pointer. 3. There was a function: #define ZP_COUNT 10 void func_original(int *xp, int *yp, int *zp) {   int i;   for(i = 0; i < ZP_COUNT; i++)   {     *zp++ = *xp + *yp;   } } They wanted to optimize it this way: void func_optimized(int *xp, int *yp, int *zp) {   int tmp = *xp + *yp;   int i;   for(i = 0; i < ZP_COUNT; i++)   {     *zp++ = tmp;   } } Q: Is it possible to call the original function and the optimized one, so as to obtain different results in zp? Answer A: It is possible, let yp == zp. 4. double f(double x) {   assert(x != 0.);   return 1. / x; } Q: Can this function return inf? Assume that floating-point numbers are implemented according to IEEE 754 (most machines), and assert is enabled (NDEBUG is not defined). Answer A: Yes, it can. It’s enough to pass a denormalized x, like 1e-309. 5. int my_strlen(const char *x) {   int res = 0;   while(*x)   {     res++;     x++;   }   return res; } Q: The provided above function should return the length of the null-terminated line. Find a bug. Answer A: The use of the int type for storing sizes of objects is wrong, as it is not guaranteed that int will be able to store the size of any object. We should use size_t 6. #include <stdio.h> #include <string.h> int main() {   const char *str = ""hello"";   size_t length = strlen(str);   size_t i;   for(i = length - 1; i >= 0; i--)   {     putchar(str[i]);   }   putchar('\n');   return 0; } Q: The loop is infinite. How come? Answer A: size_t is the unsigned type. If i is unsigned, then i >= 0 is always true. 7. #include <stdio.h> void f(int *i, long *l) {   printf(""1. v=%ld\n"", *l); /* (1) */   *i = 11;                  /* (2) */   printf(""2. v=%ld\n"", *l); /* (3) */ } int main() {   long a = 10;   f((int *) &a, &a);   printf(""3. v=%ld\n"", a);   return 0; } This program is compiled by two different compilers and run on a little-endian machine. Two different results were obtained: 1. v=10    2. v=11    3. v=11 1. v=10    2. v=10    3. v=11 Q: How can you explain the second result? Answer A: The given program has undefined behavior. Namely, strict aliasing rules are violated. int is being changed in line (2). Therefore, we can assume that any long has not changed. (We cannot dereference the pointer that aliases another pointer of an incompatible type). That’s why the compiler can pass the same long (line (3)) that has been read during the execution of line (1). 8. #include <stdio.h> int main() {   int array[] = { 0, 1, 2 };   printf(""%d %d %d\n"", 10, (5, array[1, 2]), 10); } Q: Is this code correct? If there is no undefined behavior, what does it print then? Answer A: Yes, the comma operator is used here. First, the left argument of the comma is calculated and discarded. Then, the right argument is calculated and used as the value of the entire operator. The output is 10 2 10. Note that the comma symbol in the function call (for example, f(a(), b())) is not the comma operator, and, therefore, it does not guarantee the order of calculations: a(), b() can be called in any order. 9. unsigned int add(unsigned int a, unsigned int b) {   return a + b; } Q: What is the result of add(UINT_MAX, 1)? Answer A: The overflow of unsigned numbers is defined, it is calculated by 2^(CHAR_BIT * sizeof(unsigned int)). The result is 0. 10. int add(int a, int b) {   return a + b; } Q: What is the result of add(INT_MAX, 1)? Answer A: The overflow of signed numbers – the undefined behavior. 11. int neg(int a) {   return -a; } Q: Is undefined behavior possible here? If so, under what arguments? Answer A: neg(INT_MIN). If the ECM represents negative numbers in the additional code (two's complement), the absolute value of INT_MIN is more by one than the absolute values of INT_MAX. In this case, -INT_MIN invokes the signed overflow, which is the undefined behavior. 12. int div(int a, int b) {   assert(b != 0);   return a / b; } Q: Is undefined behavior possible here? If so, under what arguments? Answer A: If the ECM represents negative numbers in the additional code, then div(INT_MIN, -1) – refer to the previous question. — Dmitri Gribenko <gribozavr@gmail.com> This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License. START WRITING AT KUKURUKU HUB Become an Author #undefined behavior #aliasing #overflow #floating point #clang #programming 115235 20 Y Published by Kukuruku Hub RATING: 15.51 Follow Published in Programming We all love programming and this hub is all about it. 5  Written by Dmitri Gribenko 20 Y RECOMMENDED Algorithms Exact Maximum Clique for Large or Massive Real Graphs Algorithms Julia Set C++ Lock-Free Data Structures. Yet Another Treatise Game Development How I built my first Android Game and realized creativity is all about iterations DIY USB Killer Functional Programming Clojure. Transducers, Reducers and Other Stuff Write your own articles at Kukuruku Hub Start writing now 20 comments raphael 4 March 2015, 12:02 AM ↓ +1 I don't know C! andrew 4 March 2015, 12:04 AM ↓    uh, gave a few wrongs answers… andrew 4 March 2015, 12:04 AM ↑ ↓    wrong s karl 4 March 2015, 2:49 AM ↓    I don't even know what ECM stands for… And I'm not having luck googling it, any hints? Khurram 4 March 2015, 11:16 AM ↑ ↓ +1 ECM stands for Electronic Computing Machine. jam lee 4 March 2015, 2:50 AM ↓    Could you show the result of those question? I couldn't believe that. so crazy.!!! Out Of Time Man 4 March 2015, 3:43 AM ↓    Well, just as i suspected. I do not know c. lmm 4 March 2015, 5:13 AM ↓ +1 I know C. These really aren't that hard. I would argue that a modern programming language shouldn't require you to memorize such trivia (and I avoid C wherever possible), but it's very much possible. Dmitry Ivanov 4 March 2015, 5:36 AM ↓    I know C :P Khurram 4 March 2015, 11:25 AM ↓    I know 1/4th C? Only 3 out of 12. Mikhail Mukovnikov 4 March 2015, 11:57 AM ↓ +1 I do know C. Petteri Halonen 4 March 2015, 1:15 PM ↓    I know C. georgef 4 March 2015, 4:41 PM ↓    I know C. Keith Thompson 4 March 2015, 4:53 PM ↓ +1 (Sorry if this comment appears twice.) I suggest using «int main(void)» rather than the old-style «int main()». Every C compiler I've seen will accept both, but I've argued that a strict reading of the C standard indicates that «int main()» has undefined behavior. Stuart Brady (Zub) 4 March 2015, 5:04 PM ↓    Regarding Q9, the answer is indeed 0, but note the words of the C99 standard: “For unsigned integer types other than unsigned char, the bits of the object representation shall be divided into two groups: value bits and padding bits (there need not be any of the latter).” I am not sure of the situation in C90. Stuart Brady (Zub) 4 March 2015, 5:09 PM ↑ ↓    I don’t mean to complain that ‘Someone on the Internet is Wrong’ (http://xkcd.com/386/) but hopefully this is informative to someone. I do also mean to make the point that, yes, I agree: I do not know C, you do not know C, and we do not know C, as it would seem C is unknowable… but then, the same could be said of JavaScript and of many other languages. 賴建宏 4 March 2015, 8:05 PM ↓    Reasonable and funky title, me either! I don't know C. Ibrahim Akyel 5 March 2015, 2:35 AM ↓ +1 I know C. 9/12 is good enough i think! :D wilhelmtell 5 March 2015, 3:09 PM ↓    I don't understand the answer for Q1. The two lines are an int definitions. One also has an initialize ruin, but they are both definitions all the same. A good compiler would yield a warning but it doesn't have to. At any rate this will not link, because of the one definition rule. maze 10 March 2015, 11:37 AM ↓    Well, these where some interesting facts, and yes… I don't know C! × Upload image From PC From internet File Align No Left Right Center Title Submit Cancel Image URL Align No Left Right Center Title Insert as external link or Upload Cancel Preview Comment Read Next The Sunset of C and C++ 4307 C++ What is Rust for? 7123 Rust A MIDI Player on Eight Floppy Drives 18761 DIY About Rules Privacy Policy Contact us · Twitter Facebook × Log In Remember me Forgot password? Log In ﻿ or Sign in with Github Sign in with Twitter Sign in with Facebook We'll never post to your Twitter, Facebook or Github account without your permission. Don't have an account? Sign up now × Sign Up Create Account ﻿ or Sign in with Github Sign in with Twitter Sign in with Facebook We'll never post to your Twitter, Facebook or Github account without your permission. Already have an account? Log in here × Reset Password Enter the email address associated with your account, and we'll email you a link to reset your password. Send Reset Link Already have an account? Log in here"	"null"	"null"	""	"true"
"Advanced"	"Implementing smart pointers for the C programming language"	"https://snai.pe/c/c-smart-pointers/"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"556"	"38"	"35"	"GitHub - Snaipe/libcsptr: Smart pointers for the (GNU) C programming language Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 38 Star 556 Fork 35 Snaipe/libcsptr Code Issues 1 Pull requests 0 Pulse Graphs Smart pointers for the (GNU) C programming language http://snaipe.me/c/c-smart-pointers/ 143 commits 2 branches 10 releases Fetching contributors CMake 67.5% C 23.3% Shell 9.2% CMake C Shell Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags criterion-tests master Nothing to show v2.0.4 v2.0.3 v2.0.2 v2.0.1 v2.0.0 v1.0 v0.3.1 v0.3 v0.2 v0.1 Nothing to show New pull request Latest commit 0de5889 Jan 1, 2016 Snaipe We're in 2016. Permalink Failed to load latest commit information. .cmake Removed generation of empty libcsptr deb package Nov 28, 2015 check Switched build system to CMake Jul 31, 2015 doc [v2.0.0] Stable release Mar 18, 2015 include/csptr We're in 2016. Jan 6, 2016 src We're in 2016. Jan 6, 2016 .gitignore Added project compilation instructions. Nov 8, 2015 .travis.yml Manually added coveralls repo token in travis environment Jul 31, 2015 CMakeLists.txt Removed generation of empty libcsptr deb package Nov 28, 2015 ChangeLog Changed smalloc prototype to used named parameters Mar 21, 2015 HEADER We're in 2016. Jan 6, 2016 INSTALL.md Added project compilation instructions. Nov 8, 2015 LICENSE We're in 2016. Jan 6, 2016 README.md Fixed formatting for deb installation block in README Nov 28, 2015 debian.copyright Fixed placeholder project url in debian.copyright Nov 28, 2015 description.txt Added missing debian files Nov 28, 2015 README.md C Smart Pointers What this is This project is a tentative attempt to bring smart pointer constructs to the (GNU) C programming language. Features unique_ptr, shared_ptr macros, and smart type attribute Destructor support for cleanup Custom variable metadata on allocation Cross-platform: tested under linux 3.18.6-1, Mac OS X Yosemite 10.10, and Windows 7 (with MinGW and the Cygwin port of GCC) Installing With a package manager Mac OS X: brew install snaipe/soft/libcsptr AUR: yaourt -S libcsptr Ubuntu: $ sudo add-apt-repository ppa:snaipewastaken/ppa $ sudo apt-get update $ sudo apt-get install libcsptr-dev Building from source Prerequisites To compile the library, GCC 4.6+ is needed. Installation Clone this repository run mkdir build && cd $_ && cmake -DCMAKE_INSTALL_PREFIX=$HOME .. && make && make install from the project root for a local install, or run mkdir build && cd $_ && cmake -DCMAKE_INSTALL_PREFIX=/usr .. && make && sudo make install for a global install. Examples Simple unique_ptr: simple1.c: #include <stdio.h> #include <csptr/smart_ptr.h>  int main(void) {     // some_int is an unique_ptr to an int with a value of 1.     smart int *some_int = unique_ptr(int, 1);      printf(""%p = %d\n"", some_int, *some_int);      // some_int is destroyed here     return 0; } Shell session: $ gcc -std=c99 -o simple1 simple1.c -lcsptr $ valgrind ./simple1 ==3407== Memcheck, a memory error detector ==3407== Copyright (C) 2002-2013, and GNU GPL\'d, by Julian Seward et al. ==3407== Using Valgrind-3.10.0 and LibVEX; rerun with -h for copyright info ==3407== Command: ./test1 ==3407== 0x53db068 = 1 ==3407== ==3407== HEAP SUMMARY: ==3407==     in use at exit: 0 bytes in 0 blocks ==3407==   total heap usage: 1 allocs, 1 frees, 48 bytes allocated ==3407== ==3407== All heap blocks were freed -- no leaks are possible ==3407== ==3407== For counts of detected and suppressed errors, rerun with: -v ==3407== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0) Simple unique_ptr with destructor: #include <unistd.h> #include <fcntl.h> #include <csptr/smart_ptr.h>  struct log_file {     int fd;     // ... };  void cleanup_log_file(void *ptr, void *meta) {     (void) meta;     close(((struct log_file *) ptr)->fd); }  int main(void) {     smart struct log_file *log = unique_ptr(struct log_file, {             .fd = open(""/dev/null"", O_WRONLY | O_APPEND),             // ...         }, cleanup_log_file);      write(log->fd, ""Hello"", 5);      // cleanup_log_file is called, then log is freed     return 0; } Allocating a smart array and printing its contents before destruction: #include <stdio.h> #include <csptr/smart_ptr.h> #include <csptr/array.h>  void print_int(void *ptr, void *meta) {     (void) meta;     // ptr points to the current element     // meta points to the array metadata (global to the array), if any.     printf(""%d\n"", *(int*) ptr); }  int main(void) {     // Destructors for array types are run on every element of the     // array before destruction.     smart int *ints = unique_ptr(int[5], {5, 4, 3, 2, 1}, print_int);     // ints == {5, 4, 3, 2, 1}      // Smart arrays are length-aware     for (size_t i = 0; i < array_length(ints); ++i) {         ints[i] = i + 1;     }     // ints == {1, 2, 3, 4, 5}      return 0; } More examples Using a different memory allocator (although most will replace malloc/free): #include <csptr/smart_ptr.h>  void *some_allocator(size_t); void some_deallocator(void *);  int main(void) {     smalloc_allocator = (s_allocator) {some_allocator, some_deallocator};     // ...     return 0; } Automatic cleanup on error cases: #include <unistd.h> #include <fcntl.h> #include <csptr/smart_ptr.h>  struct log_file {     int fd;     // ... };  static void close_log(void *ptr, void *meta) {     (void) meta;     struct log_file *log = ptr;     if (log->fd != -1)         close(log->fd); }  struct log_file *open_log(const char *path) {     smart struct log_file *log = shared_ptr(struct log_file, {0}, close_log);     if (!log) // failure to allocate         return NULL; // nothing happens, destructor is not called      log->fd = open(path, O_WRONLY | O_APPEND | O_CREAT, 0644);     if (log->fd == -1) // failure to open         return NULL; // log gets destroyed, file descriptor is not closed since fd == -1.      return sref(log); // a new reference on log is returned, it does not get destoyed }  int main(void) {     smart struct log_file *log = open_log(""/dev/null"");     // ...     return 0; // file descriptor is closed, log is freed } Using named parameters: #include <csptr/smart_ptr.h>  void nothing(void *ptr, void *meta) {}  int main(void) {     struct { int a; } m = { 1 };      smart int *i = unique_ptr(int,             .dtor = nothing,             .value = 42,             .meta = { &m, sizeof (m) }         );      return 0; } FAQ Q. Why didn't you use C++ you moron ? A. Because when I first started this, I was working on a C project. Also, because it's fun. Q. Can I use this on a serious project ? A. Yes, but as this project has not been widely used, there might be some bugs. Beware! Q. How did you make this ? A. Here's a link to my blog post on the matter. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/Snaipe/c-smart-pointers"	""	"true"
"Advanced"	"Inline functions in C"	"http://www.greenend.org.uk/rjk/tech/inline.html"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Inline Functions In C Inline Functions In C Introduction GNU C (and some other compilers) had inline functions long before standard C introduced them (in the 1999 standard); this page summarizes the rules they use, and makes some suggestions as to how to actually use inline functions. The point of making a function inline is to hint to the compiler that it is worth making some form of extra effort to call the function faster than it would otherwise - generally by substituting the code of the function into its caller. As well as eliminating the need for a call and return sequence, it might allow the compiler to perform certain optimizations between the bodies of both functions. Sometimes it is necessary for the compiler to emit a stand-alone copy of the object code for a function even though it is an inline function - for instance if it is necessary to take the address of the function, or if it can't be inlined in some particular context, or (perhaps) if optimization has been turned off. (And of course, if you use a compiler that doesn't understand inline, you'll need a stand-alone copy of the object code so that all the calls actually work at all.) There are various ways to define inline functions; any given kind of definition might definitely emit stand-alone object code, definitely not emit stand-alone object code, or only emit stand-alone object code if it is known to be needed. Sometimes this can lead to duplication of object code, which is a potential problem for following reasons: It wastes space. It can cause pointers to what is apparently the same function to compare not equal to one another. It might reduce the effectiveness of the instruction cache. (Although inlining might do that in other ways too.) If any of these are a problem for you then you will want to use a strategy that avoids duplication. These are discussed below. C99 inline rules The specification for inline is section 6.7.4 of the C99 standard (ISO/IEC 9899:1999). Unfortunately this isn't freely available. The following possibilities exist: A function where all the declarations (including the definition) mention inline and never extern. There must be a definition in the same translation unit. The standard refers to this as an inline definition. No stand-alone object code is emitted, so this definition can't be called from another translation unit. You can1 have a separate (not inline) definition in another translation unit, and the compiler might choose either that or the inline definition. Such functions may not contain modifiable static variables, and may not refer to static variables or functions elsewhere in the source file where they are declared. In this example, all the declarations and definitions use inline but not extern: // a declaration mentioning inline inline int max(int a, int b);  // a definition mentioning inline inline int max(int a, int b) {   return a > b ? a : b; } The function won't be callable from other files; if another file has a definition that might be used instead. 1 The standard is vague on this point. It says that the inline definition does not forbid an external definition elsewhere, but then that it provides an alternative to an external definition. Unfortunately this doesn't really make clear whether this external definition must actually exist. In practice unless you are torture-testing your compiler it will exist: if you wanted to keep your inline function entirely private to one translation unit, you make it static inline. A function where at least one declaration mentions inline, but where some declaration doesn't mention inline or does mention extern. There must be a definition in the same translation unit. Stand-alone object code is emitted (just like a normal function) and can be called from other translation units in your program. The same constraint about statics above applies here, too. In this example all the declarations and definitions use inline but one adds extern: // a declaration mentioning extern and inline extern inline int max(int a, int b);  // a definition mentioning inline inline int max(int a, int b) {   return a > b ? a : b; } In this example, one of the declarations does not mention inline: // a declaration not mentioning inline int max(int a, int b);  // a definition mentioning inline inline int max(int a, int b) {   return a > b ? a : b; } In either example, the function will be callable from other files. A function defined static inline. A local definition may be emitted if required. You can have multiple definitions in your program, in different translation units, and it will still work. Just dropping the inline reduces the program to a portable one (again, all other things being equal). This is probably useful primarily for small functions that you might otherwise use macros for. If the function isn't always inlined then you get duplicate copies of the object code, with the problems described above. A sensible approach would be to put the static inline functions in either a header file if they are to be widely used or just in the source files that use them if they are only ever used from one file. In this example the function is defined static inline: // a definition using static inline static inline int max(int a, int b) {   return a > b ? a : b; } The first two possibilities go together naturally. You either write inline everywhere and extern in one place to request a stand-alone definition, or write inline almost everywhere but omit it exactly once to get the stand-alone definition. main is not allowed to be an inline function. (If you think I've misinterpreted these rules, please let me know!) (C++ is stricter: a function which is inline anywhere must be inline everywhere and must be defined identically in all the translation units that use it.) GNU C inline rules The GNU C rules are described in the GNU C manual, which is included with the compiler. This is freely available if you follow links from e.g. http://gcc.gnu.org. The following possibilities exist: A function defined with inline on its own. Stand-alone object code is always emitted. You can only write one definition like this in your entire program. If you want to use it from other translation units to the one where it is defined, you put a declaration in a header file; but it would not be inlined in those translation units. This is of rather limited use: if you only want to use the function from one translation unit then static inline below makes more sense, if not the you probably want some form that allows the function to be inlined in more than one translation unit. However it does have the advantage that by defining away the inline keyword, the program reduces to a portable program with the same meaning (provided no other non-portable constructions are used). A function defined with extern inline. Stand-alone object code is never emitted. You can have multiple such definitions and your program will still work. However, you should add a non-inline definition somewhere too, in case the function is not inlined everywhere. This provides sensible semantics (you can avoid duplicate copies of the functions' object code) but is a bit inconvenient to use. One approach to using this would be to put the definitions in a header file, surrounded by a #if that expands to true either when using GNU C, or when the header has been included from the file that is contain the emitted definitions (whether or not using GNU C). In the latter case the extern is omitted (for instance writing EXTERN and #define-ing that to either extern or nothing). The #else branch would contain just declarations of the functions, for non-GNU compilers. A function defined with static inline. Stand-alone object code may be emitted if required. You can have multiple definitions in your program, in different translation units, and it will still work. This is the same as the C99 rules. As of release 4.3, GNU C supports the C99 inline rules described above and defaults to them with the -std=c99 or -std=gnu99 options. The old rules can be requested in new compilers with the -gnu89-inline option or via the gnu_inline function attribute. If the C99 rules are in force then GCC will define the __GNUC_STDC_INLINE__ macro. Since GCC 4.1.3, it will define __GNUC_GNU_INLINE__ if the GCC-only rules are in use, but older compilers use these rules without defining either macro. You could normalize the situation with a fragment like this: #if defined __GNUC__ && !defined __GNUC_STDC_INLINE__ && !defined __GNUC_GNU_INLINE__ # define __GNUC_GNU_INLINE__ 1 #endif Strategies for using inline functions These rules suggest several possible models for using inline functions in more or less portable ways. A simple portable model. Use static inline (either in a common header file or just in one file). If the compiler needs to emit a definition (e.g. to take its address, or because it doesn't want to inline some call) then you waste a bit of space; if you take the address of the function in two translation units then the result won't compare equal. For instance, in a header file: static inline int max(int a, int b) {   return a > b ? a : b; } You can support legacy compilers (i.e. anything without inline) via -Dinline="""", although this may waste space if the compiler does not optimize out unused functions.. A GNU C model. Use extern inline in a common header and provide a definition in a .c file somewhere, perhaps using macros to ensure that the same code is used in each case. For instance, in the header file: #ifndef INLINE # define INLINE extern inline #endif INLINE int max(int a, int b) {   return a > b ? a : b; }  ...and in exactly one source file: #define INLINE #include ""header.h"" Supporting legacy compilers is awkward unless you don't mind wasting space and having multiple addresses for the same function; you need to restrict the definitions to a in single translation unit (with INLINE defined to the empty string) and add some external declarations in the header file. A C99 model. Use inline in a common header, and provide definitions in a .c file somewhere, via extern declarations. For instance, in the header file: inline int max(int a, int b) {   return a > b ? a : b; } ...and in exactly one source file: #include ""header.h"" extern int max(int a, int b); To support legacy compilers, you have to swap the whole thing around so that the declarations are visible in the common header and the definitions are restricted to a single translation unit, with inline defined away. A complicated portable model. Use macros to choose either extern inline for GNU C, inline for C99, or neither for a definition. For instance, in the header: #ifndef INLINE # if __GNUC__ && !__GNUC_STDC_INLINE__ #  define INLINE extern inline # else #  define INLINE inline # endif #endif INLINE int max(int a, int b) {   return a > b ? a : b; }  ...and in exactly one source file: #define INLINE #include ""header.h"" Supporting legacy compilers has the same issues as the GNU C model. Please report any errors. RJK | Contents"	"null"	"null"	""	"true"
"Advanced"	"Metaprogramming custom control structures in C"	"http://www.chiark.greenend.org.uk/~sgtatham/mp/"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Metaprogramming custom control structures in C Metaprogramming custom control structures in C by Simon Tatham This article describes a technique for using the C preprocessor to implement a form of metaprogramming in C, allowing a programmer to define custom looping and control constructions which behave syntactically like C's own for, while and if but manage control flow in a user-defined way. The technique is almost all portable C89, except that some constructions need the feature (available in both C99 and C++) of defining a variable in the initialiser of a for statement. Sample code is provided. 1. Motivation The existing control constructions in C need no introduction. Every C programmer is familiar with if, while, do…while, and for statements, and their effects on control flow. Every so often, though, you might come across a situation in which it might be nice to be able to invent slightly different control mechanisms. As one example, if you're iterating over a circularly linked list without a distinguished head element, you might find it inconvenient that for does its test at the head of the loop, because the apparently obvious way to iterate over such a list (comparing your current-element pointer to the list head in the test clause) will execute zero times. So you might like a variant of for that does its test at the end of the loop: for_after (elephant *e = head; e != head; e = e->next)     do_stuff_with(e);  or, better still, one that has a separate test for the first iteration, so you can also check if the list is completely empty: for_general (elephant *e = head; e != NULL; e != head; e = e->next)     do_stuff_with(e);  There's also a lot of scope for program-specific control constructions, if you find yourself writing some particular kind of loop a lot in a specific code base. For instance, suppose you have some kind of API for retrieving a list of things, and the API requires a lot of setup and teardown and function calls. You might find that even the simplest of loops to actually do something with your list looks a bit like this: {     hippo_retrieval_context *hc;     hc = new_hippo_retrieval_context();     while (hippo_available(hc)) {         hippo *h = get_hippo(hc);         printf(""We have a hippo called %s\n"", h->name);         free_hippo(hc, h);     }     free_hippo_retrieval_context(hc); }  and if you find yourself needing to iterate over these lists a lot, then your program will become tediously full of copies of that kind of boilerplate. In such a program you might feel that it would be nice to wrap all that machinery up into a macro defined in your own program's headers, so that you could write just the part of the loop that needed to change every time: FOR_EACH_HIPPO (hippo *h)     printf(""We have a hippo called %s\n"", h->name);  If you were doing it like this, you'd probably also like to arrange that break statements were handled sensibly. In the above example, if the code which actually deals with a list element wants to terminate the loop, it probably has to make sure to write a second copy of the free_hippo call before its break statement, because the copy at the end of the while loop body will be skipped by the break. If you were inventing a custom loop construction, you'd like to arrange that break had configurable handling, so that it automatically cleaned up this sort of thing. It's easy to imagine that if you felt strongly enough about wanting this sort of thing in your language, you could do it by inventing a sort of secondary preprocessor, which ran after the standard C preprocessor and knew enough about C syntax to be able to recognise things like statements, blocks, declarations and expressions. Then you could define ‘macros’ which looked rather like additional grammar rules, and implement your extra loop constructions as those. But in fact, one need not go that far. There is already a way to implement almost exactly the above control constructions in standard C, if you're prepared to be devious enough with the existing C preprocessor. In this article, I'll show how, and provide sample code. (I say ‘almost’, because due to limitations of C macro syntax, the one thing in the above snippets that can't be arranged is the separation of clauses in for_after and for_general with semicolons rather than commas.) 2. Mechanism If we're going to build custom loop constructions of this type, then how can we do it? If we want our finished loop construction to be used by means of syntax like this: MY_LOOP_KEYWORD (parameters)     statement or braced block  then it's clear that we're going to have to define MY_LOOP_KEYWORD as a macro, and also that the macro must expand to a statement prefix: that is, something which you can put on the front of a valid C statement to yield another valid C statement. So what do those constraints allow us to do? Well, there are several types of statement prefix in the C syntax: a label while (stuff) for (stuff; stuff; stuff) if (stuff) {stuff} else more than one of the above, one after another. (There's also switch (stuff) and case labels, but we'd like to avoid those if possible because of their side effect of interfering with case labels from an outer switch. It turns out we don't need them anyway; the above list is sufficient.) So we're going to explore the range of possibilities allowed by defining a macro to expand to a chain of those types of thing, and then prefixing it to a user-supplied statement. The critical component in the list above is the if…else statement prefix, because it allows us to provide a braced statement block of our own, in which we can put code of our choice. This will of course be vital for any loop construction which has to run specialist code at the start and end, or between iterations. So, to begin with, here's a construction that lets us run code of our choice and then run the user's code. Suppose we define our macro so that, when followed by a statement or block, it expands to this: if (1) {     /* code of our choice */     goto body; } else     body:         { /* block following the expanded macro */ }  You can see how this works by following the control flow through from the top. We come into the if statement; the condition is always true, so we execute the ‘code of our choice’ section first; then we reach the goto, which conveniently lets us get into the else clause of the same if statement even though that would not otherwise have been executed at all. So we execute our code, and then the user's code. That was nice and easy. Now what if we want to run code of our choice after the user's loop body? Well, we certainly can't do that using only if and labels, because those can't stop execution from falling off the end of the user's block and on to the following code. The code we want to run afterwards has to be written above the user's code, which means control flow has to move backwards in the source file – and to do that, we have to use a loop statement. So we can do this, for example: if (1)     goto body; else     while (1)         if (1) {             /* code of our choice */             break;         } else             body:                 { /* block following the expanded macro */ }  As before, we first go into the then-clause of the outermost if, which contains a goto that jumps us directly to the user's block. We execute that block, but then what? Well, that block is enclosed in a while (1) statement, so we now go back round to the top of the while and enter the then-clause of the inner if – where we then run code of our choice, and after that, execute the break statement which terminates the loop. So we've successfully injected code to be run after the user's code has been executed. And still the whole construction consists solely of a chain of statement prefixes prepended to the user's block, so we could feasibly define a macro to expand to all but the last line of the above snippet. So this is beginning to look pretty promising. We can use both of the techniques above to get code to run before and after the user's code; we can further mess about with the control flow by scattering extra labels all over the place and have our inserted code blocks test conditions, think hard about what to do, and then issue an appropriate goto. Another thing we may well want to do is to bring variable declarations into scope, so that they can be accessed both by our added code in if blocks and by the user's code itself. This is unfortunately not feasible in old-style C89, since in that you can only open a new scope with an open brace character, and that would mean the user would have to provide an extra closing brace after their statement, which would look ugly and (worse still) confuse editors' automatic C indentation policies. But if you're willing to allow yourself the one extra language feature of being able to use a declaration as the initialiser clause of a for statement (which is legal in both C99 and C++, so the chances are that your compiler probably has some mode that supports it), then suddenly it becomes possible to bring any declaration you like into scope. So an obvious approach is to put the declaration in a for, and then use exactly the same technique as above to stop the for from actually causing a loop: i.e. repeat exactly the previous code snippet but replace the while with a for. That's not quite ideal, though, because execution jumps over the declaration rather than passing through it. If the declaration doesn't include an initialiser, that makes no difference; but you might want to declare and initialise the declaration in one go. One reason for that might be if you're working in C++ and need the constructor to be called; another reason might be if the user was providing a parameter to the loop macro which you wanted to treat as part of a combined declaration and initialiser, such as the ‘hippo *h’ in one of the examples in section 1. (If the user provides a macro parameter of the form ‘type *var’, then we can put that parameter before an assignment to produce a declaration-with-initialiser, but we can't extract the variable name on its own in order to do the declaration and initialisation separately.) So, can we fix that? Well, we'll have to do two things. One is to recover control after the user's block runs (but we can do that using the while-based construction above), and the other is to find a way to transfer control back out of the for without falling into the trap of writing a break which is executed in the context of the while. For this, a helpful trick is to put a label inside an if (0). Like this: if (0)     finished: ; else     for (/* declaration of our choice */ ;;)         if (1)             goto body;         else             while (1)                 if (1)                     goto finished;                 else                     body:                         { /* block following the expanded macro */ }  So the initial if (0) is ignored and we begin executing the for statement, including its declaration. The construction inside the for should now be familiar from the previous example: its job is to execute the user's block and then loop back round to the goto finished statement, which transfers control into the then-clause of the outermost if. From there, control bypasses the whole else-clause and drops out of the bottom. So this approach to declarations works. Now what about handling break? If you think about what would happen to some of the above snippets if the suffixed block executes break, you find that the first one (that executes code of our choice before the user's code) doesn't interfere with break at all, so that it would still terminate the next outermost loop or switch; but the other two, in which the user's code is embedded in a while or a for, both have the side effect of changing the meaning of break within the suffixed block so that it just terminates the while or for. This will be nasty if we have to embed either of those constructs inside an actual loop (by which I mean one intended to execute the user's code multiple times, unlike the above dummy loops that we always break out of after one iteration), because then a break in the user's code won't terminate the real loop, only the current iteration of the loop body – in other words, it'll become synonymous with continue, which isn't very useful. At first sight one is inclined to think that since the problem arose due to a side effect of using a C loop keyword, we surely can't solve the problem except by removing the loop. But in fact, we head in the other direction: we can recover useful handling of break by adding another layer of loop! Specifically, we put the user's code inside two nested while loops, like this: if (1)     goto body; else     while (1)         if (1) {             /* we reach here if the block terminated by break */         } else             while (1)                 if (1) {                     /* we reach here if the block terminated normally */                 } else                     body:                         { /* block following the expanded macro */ }  As in the previous examples, the outermost if jumps us into the innermost loop and executes the user's code block. If that block terminates normally, then we loop round to the top of the inner while, and execute a code snippet of our own choice. But if the user's block terminated by means of a break statement, that will terminate the inner while and cause us to loop round to the top of the other one. So we've now arranged for control flow to go to different places based on whether the user issued a break or not; and of course each of the code snippets we provide above can act on that information as it sees fit, including in particular jumping to a location of its choice via goto. 3. Handling else clauses I've shown that it's possible to write an almost arbitrary control structure by this mechanism which expects a single block of code after it and arranges to call that block in a user-defined looping setup. What if you want to pass more than one block of code to your control structure, as you can with the built-in if…else? For instance, Python allows an else clause on the end of a for loop, which is executed if the loop terminates normally but skipped if it terminates by break. This is ideal for situations in which the for loop is searching for a suitable element of a list, and you want special-case handling if no such element turned out to exist. If C had that feature too, then you'd be able to write things like: for (i = 0; i < n; i++) {     if (array[i] == the_droid_we_are_looking_for)         break; } else {     /* only executed if no array element matched */     move_along(); }  whereas currently you have to do this by testing after the loop to see if i==n, or if the loop conditions weren't as simple as that then you might resort to something even uglier like declaring an extra flag variable. Or you might make up your own constructions. I occasionally feel that it would be nice to put an else clause on a while loop, with the semantics (this time not like Python's) that the else clause is executed if and only if the main loop body was run zero times. This would be handy, for example, in cases where you're printing a message to the user every time you go round the loop but you feel it would be unfriendly not to print anything if you're not going round at all: while ((p = get_a_thing()) != NULL) {     printf(""Processing %s\n"", p->name);     do_stuff_with(p); } else {     /* only executed if the condition was false the first time */     printf(""No things to process\n""); }  Again, to do this in standard C you have to do something fairly ugly, such as putting the while inside an if with the same condition, and also turning it into a do…while if the condition (like this one) has side effects that you need to avoid duplicating the first time round the loop. Another output-related example is that of printing a collection of strings with commas between them, so that however many actual output values you're printing (at least, if it was non-zero) you print one comma fewer. I've always done that by means of a variable storing a separator string: sep = """";    /* the first value has nothing before it */ while ((p = get_a_thing()) != NULL) {     printf(""%s%d"", sep, p->value);     sep = "","";   /* all subsequent values are preceded by a comma */ }  But it would be cute if you could avoid the extra variable declaration, by writing something like while_interleaved ((p = get_a_thing()) != NULL)     printf(""%d"", p->value); and_in_between     putchar(',');  and relying on the loop construct to do the job of arranging to run the second block one fewer times than the first. All of these types of control structure can be implemented by extending the mechanism described in section 2. If we want to define a loop macro whose invocation has a syntactic form like this: MY_LOOP_KEYWORD (parameters)     statement or braced block else     statement or braced block  then all we have to do is to insert an unmatched if statement somewhere in our chain of statement prefixes, and then it will match an else written by the user after their first statement or block. A reasonably general way to arrange this is by using an if (0) with a label on each side, like this: else_clause:     if (0)         then_clause:             { /* first block following the expanded macro */ }     else         { /* second block following the expanded macro */ }  (In case it's becoming unclear, our macro in this case would expand to everything up to and including the then_clause label; everything after that is code written by the user following the invocation of our control macro.) Now we place other control constructions outside that one which can execute either goto then_clause (which will jump straight to the user's main loop body) or goto else_clause (which will jump to just before the if (0), and therefore head for the else clause). Doing that has the unfortunate effect that control flow will go to the same place after executing either of the user's blocks. To get around that, we can put additional control constructions just before or after the then_clause label; those will only be run for one of the two clauses, so now we can arrange (by the techniques shown above) to redirect control to a different place after each one. For example, a general approach might look like this: while (1)     if (1) {         /* we reach here after the user's else clause */         goto somewhere;     } else         else_clause:             if (0)                 while (1)                     if (1) {                         /* we reach here after the then clause */                         goto somewhere_else;                     } else                         then_clause:                             { /* user's first block */ }             else                 { /* user's second block */ }  I'm assuming that code further up will jump to either the then_clause label or the else_clause one. If the former, we immediately execute the user's then-clause, then we go round to the top of the inner while and reach one of our two code snippets. If the latter, then we execute the if (0), which drops us through to the user's else clause (shown above with indentation reflecting its place in the real syntactic structure, though of course the user will indent it rather differently), and since that's not inside the inner while at all, we would then loop round to the top of the outer while and execute a different snippet. So that demonstrates how to make use of two code blocks provided by the user. They will have to be separated by the keyword else, or else none of this trickery will work; but of course you can always trivially #define some synonyms for else to make the code look nicer, such as and_in_between in the last example above. 4. Construction kit Hopefully the previous sections have shown that the general technique of expanding a macro into a well-chosen collection of statement prefixes is surprisingly powerful, and contains all the needed functionality to implement a wide range of looping constructions. However, actually doing it by chaining together ifs and whiles and labels is a bit of a headache, and if you were trying to define a custom loop construction in a particular application to cope with some inconvenient piece of API (as in one of my motivating examples above) then you might very well run out of patience before getting the sequence of bits and pieces quite right. It would be nicer to have a pre-packaged collection of the snippets in the previous sections, in a form that was reasonably easy for a user to put together into whatever loop construct was most useful to them that day. A sort of ‘loop construction kit’. Well, all of the trickery shown above has a nice property: because it's all in the form of statement prefixes, it's all composable. So you could quite feasibly define macros to do jobs like ‘execute this code before the suffixed block’, ‘execute this code after the suffixed block’, ‘bring this declaration into scope’, ‘catch and handle break’, and so on, and have each of those macros expand to a statement prefix. Then a user could define a loop macro simply by means of chaining together a collection of those prefixes. So I've written one of these, and it's available for download at the bottom of this page. I won't document it in full in this article, because the main documentation is in comments in the header file itself and it's easier not to try to keep it in sync in two places; but here's an example of it in use. The following definition, if you've included my header file first, constructs exactly the FOR_EACH_HIPPO loop type described in an earlier secion: #define FOR_EACH_HIPPO(loopvar)                                 \     MPP_DECLARE(1, hippo_retrieval_context *_hc)                \     MPP_BEFORE(2, _hc = new_hippo_retrieval_context())          \     MPP_AFTER(3, free_hippo_retrieval_context(_hc))             \     MPP_WHILE(4, hippo_available(_hc))                          \     MPP_BREAK_CATCH(5)                                          \     MPP_DECLARE(6, hippo *_h = get_hippo(_hc))                  \     MPP_DECLARE(7, loopvar = _h)                                \     MPP_BREAK_THROW(5)                                          \     MPP_FINALLY(8, free_hippo(_hc, _h))  I hope you'll agree that that sort of thing is a lot easier to write (and read) than the elaborate constructions in the previous sections! And yet it achieves more, by pasting together many things of about the size of the above snippets. Most of the example should be reasonably clear, but I'll talk through it anyway just in case: MPP_DECLARE brings a declaration into scope, specifically the hippo_retrieval_context that the original version of the loop had to instantiate surrounding the loop as a whole. MPP_BEFORE and MPP_AFTER arrange to run the supplied pieces of code before and after the code that follows, i.e. before and after the whole loop. So the hippo_retrieval_context is allocated at the start of the loop, and freed when the loop terminates. MPP_WHILE is the loop itself, and includes the termination condition. The next two MPP_DECLAREs declare variables with scope inside the loop, holding the actual value retrieved by get_hippo. The second one refers to loopvar, the macro parameter passed in by the user. MPP_BREAK_CATCH and MPP_BREAK_THROW are used to get round the problem discussed in section 2, where using a for loop to bring a declaration into scope has the side effect of causing break to do something unhelpful. MPP_BREAK_THROW is a macro which detects when the user's code has issued a break (by the technique shown in section 2), and responds by issuing a goto to a label defined by the corresponding MPP_BREAK_CATCH, which in turn issues another break statement. So any break written by the user will be propagated past the two dangerous MPP_DECLAREs, and instead will terminate the MPP_WHILE loop as the user really wanted. MPP_FINALLY is another break-handling macro. It arranges that the free_hippo call takes place no matter whether the user exited the block naturally (by falling off the end) or by break. The numbers used as the first parameter to each MPP_ macro are called ‘label IDs’. Most of those macros have to define labels somewhere in their structure and jump to them using gotos, as you can see in the code snippets in the previous sections. Those code snippets use fixed label names for simplicity; but of course in serious use you can't do that, or else you'd never be able to use the same MPP_ macro even twice in the same function, let alone twice in the same loop macro (as we do above, with three instances of MPP_DECLARE). We get round this by constructing label names using the C preprocessor's token-pasting operator ##: each label includes __LINE__ to ensure that multiple invocations of the same loop macro define different labels, and also includes the label ID passed to the macro defining the label. So the constraint is just that each separate MPP_ macro used in a loop construct definition must have a different label ID, to stop them colliding with each other. But it doesn't matter what the label IDs actually are; I use numbers above for brevity, but you could use descriptive names if you prefer. (One exception to the unique-IDs rule is that corresponding instances of MPP_BREAK_THROW and MPP_BREAK_CATCH must have the same number, so that one can jump to a label defined in the other. In more complex macros you might have to use two instances of each, and then the numbering makes it clear how they match up.) You might notice that the variable names invented by the above macro begin with underscores (_hc and _h). This is just a convention I chose to make it unlikely that they'll clash with variable names used by the end user calling the loop macro. You don't have to follow the same convention, of course, but I'd suggest that some convention along those lines is probably useful. Also on the subject of variable declarations, here's a useful feature of MPP_DECLARE. It places the declaration you give it in the initialisation clause of a for statement – but there's no actual need for the thing in a for statement to be a declaration. So MPP_DECLARE can take a declaration or an ordinary assignment. This is useful in the case where we're assigning to a macro parameter passed in by the user, as in the declaration above assigning to loopvar. It means that the user can call the loop macro as either FOR_EACH_HIPPO(hippo *h), declaring a new variable with scope limited to the loop body, or if they prefer they could instead call it as just FOR_EACH_HIPPO(h) where h is some variable of the right type which was already in scope. By writing the loop macro in the above form, we can arrange for both uses to work. Another thing in the above code that needs explaining is the distinction between MPP_AFTER and MPP_FINALLY, and why I had to use both in the above definition. Both arrange for code to be run after the suffixed statement terminates, but they have different semantics. Firstly, MPP_AFTER only executes its code snippet if the suffixed statement terminated normally, not by break, whereas MPP_FINALLY executes its statement either way. But the suffixed statement of MPP_AFTER, in the above, is a loop, so any break will stop there. So why wouldn't MPP_FINALLY have done just as well? The answer is that MPP_FINALLY doesn't just handle break by running some code: it also reissues the break, so that it continues propagating upwards and (in the above example) eventually terminates the loop. That means that MPP_FINALLY expands to a statement prefix which includes a break statement that's not contained in any loop – so it would be illegal C to use MPP_FINALLY in any context where there wasn't a surrounding loop. So I can't use MPP_FINALLY at the top level of my loop construction, even if the break statement in it would never actually be reached. All of this is documented more fully in comments in the header file itself, along with some additional macros to the ones shown, including ones that absorb a following else clause as discussed in section 3. But the example above should give you an idea of what sort of thing this system can do. 5. Use with coroutines For my pièce de résistance, here's a mechanism for implementing something very similar to Ruby's ‘iterator method’ mechanism, in which you can define an arbitrary function which is called with a suffixed block of code and can ‘call’ that block, with arguments, anywhere in its own control flow. If you combine the loop-definition macros described above with my other C preprocessor hack to implement coroutines, you can achieve pretty much the same thing in standard C99! As an example, let's write some code that generates a sequence of integers: specifically, all those integers which are either a power of 2 or three times a power of 2, in increasing order. If we just wanted to print those numbers, we could use the following snippet of code: void twothree_up_to(int limit) {     int i, tmp;     for (i = 1; i < limit; i *= 2) {         printf(""%d\n"", i); /* a power of 2 */         if (i > 1) {             tmp = i + (i >> 1);             if (tmp < limit)                 printf(""%d\n"", tmp); /* 3 times a power of 2 */         }     } }  I've deliberately picked an example with slightly fiddly control flow, to show off the technique to the full. It's more convenient to call printf twice in each loop iteration, printing first a power of two and then one-and-a-half times that value, than to fiddle with the loop conditions to arrange exactly one iteration per output number; we also need to allow for the special case that when the power of two is 1 we have to skip the one-and-a-half value, and we must also check the second number printed in each iteration against the provided limit to avoid overrunning by one. So now let's rewrite that as an ‘iterator’ with more or less Rubyish semantics. First we must define a set of coroutine macros. For full details of the general technique, see my article ‘Coroutines in C’. Here I'll just observe that the details have to be adjusted from the ones in that article to allow for the state structure being allocated on the stack of the calling function rather than being either dynamically allocated or static: #define MPCR_BEGIN switch (s->_line) { case 0: #define MPCR_END(dummyval) s->_line = -1; } #define MPCR_YIELD(value) do                    \     {                                           \         s->_line = __LINE__;                    \         s->_val = (value);                      \         return;                                 \       case __LINE__:;                           \     } while (0)  These macros expect to be used in a function which takes a parameter called ‘s’, which is a pointer to a structure that contains the coroutine's state. The state structure must in turn contain a member called _line, which tracks the coroutine's next resumption point (and is initialised to zero, and set to the special value -1 to indicate that the coroutine has finished and isn't yielding another value), and another member called _val which is the value passed out of the coroutine to the user's code block in each yield operation. So now we can rewrite the above function as an iterator using those macros. Of course any local variable in the above function which has to persist across a yield must become an extra field in the state structure, which in the above case means that ‘limit’ and ‘i’ must move but ‘tmp’ is OK as it is: struct twothree_state {     int _line, _val;     int limit;     int i; }; void twothree_iterator(struct twothree_state *s) {     int tmp;     MPCR_BEGIN;     for (s->i = 1; s->i < s->limit; s->i *= 2) {         MPCR_YIELD(s->i);         if (s->i > 1) {             tmp = s->i + (s->i >> 1);             if (tmp < s->limit)                 MPCR_YIELD(tmp);         }     }     MPCR_END(0); }  Now the other end of the mechanism has to be a loop macro which declares an instance of struct twothree_state to keep the iterator's persistent state in, then repeatedly calls the iterator function on that state structure to get an output value, and stops when it terminates. We can build such a macro without any difficulty using the loop construction kit discussed in section 4: #define TWOTHREE_UP_TO(loopvar, limitval)               \     MPP_DECLARE(1, struct twothree_state _state)        \     MPP_BEFORE(2, _state._line = 0;                     \                _state.limit = limitval;                 \                twothree_iterator(&_state))              \     MPP_WHILE(3, _state._line >= 0)                     \     MPP_BREAK_CATCH(4)                                  \     MPP_AFTER(5, twothree_iterator(&_state))            \     MPP_DECLARE(6, loopvar = _state._val)               \     MPP_BREAK_THROW(4)  (So we have to declare the coroutine's state; set it all up and call the iterator to get the first value; loop until the _line field becomes negative, which happens as a result of reaching MPCR_END and is the signal to terminate the loop; arrange to call the iterator again after executing the loop body; assign the yielded value into the user's specified loop variable; and finally handle break by propagating it past the MPP_AFTER and MPP_DECLARE macros. All of this is more or less the same as the example in section 4.) After all those definitions, we can now call our loop macro with a statement or block of our choice: TWOTHREE_UP_TO(int k, 1000)     printf(""%d\n"", k);  6. Limitations Of course, whenever you use macros to extend C's syntax, the mechanism comes with a few extra constraints. Only a proper language extension, implemented in the compiler itself, would be able to avoid that. To begin with, though, here are some things that aren't limitations. Loops constructed by this mechanism are valid standard C99, or valid standard C++. If you avoid using declarations in for loops (so no MPP_DECLARE, if you're using my construction-kit header) then they're valid C89 as well. All of these macros are switch/case safe, in the sense that a case label inside the user's block will still be associated with a switch completely outside the loop construction. (That's a consequence of not having used switch in the macros themselves.) Of course, jumping into a loop like that will skip any implicit initialisations and allocations and so on that might be hidden in the loop macro, but nothing in the macros themselves forbids the technique. All of these macros can handle being followed by either a single statement or a braced block, just like C's built-in loop statements. They're if/else safe (in the sense that you can put an unbraced if…else inside one, or put an unbraced one inside if...else, without causing syntactic confusion), unless of course you've deliberately set them up to eat a following else clause. Those are the good points. Now for the actual limitations of the technique. As discussed in the previous sections, the loop-construction macros use goto with labels constructed programmatically using __LINE__. So don't put two loop macros defined using these building blocks on the same source line, or they'll most likely define the same labels twice and cause a compile error. Loops defined using these macros have no way to control the handling of continue. Fortunately, the default handling is probably the right one anyway: in any loop defined using this system, continue will be equivalent to a jump to just before the end of the loop body. (So any post-loop machinery concealed in the loop macro will still be run.) The mechanism for catching break can only catch break, and won't catch any other kinds of non-local exit from the loop body such as return, goto, longjmp() or exit(). The fact that I called one of my component macros MPP_FINALLY should not mislead you into thinking it's as good as a ‘real’ finally. So if you define a loop by this mechanism which sets up state that has to be cleaned up when the loop finishes, don't write any returns (or anything else on the above list) in the loop body. The mechanism for accepting an else clause relies on the C syntax rule that every else binds to the nearest unmatched if. This isn't a problem per se, in that no compiler I've ever heard of gets that rule wrong, but unfortunately some compilers (e.g. GCC) give a warning whenever you write code that actually depends on the rule. So although in principle else clauses on constructions defined like this are optional, you might find that in practice they're mandatory to avoid those annoying warnings. And last but not least, if you use this sort of trickery in code you write for your employer, don't be surprised if your next performance review contains a raised eyebrow or two! 7. Downloads The header file I describe above is available here: mp.h. You can also download a test program that uses that header file: mptest.c. If compiled normally, that file sets up a number of these loops and test-runs them in various ways; if compiled with the macro EXPECTED defined, it instead compiles to equivalent ‘normal’ C code, so you can check that the two versions give the same output. Compile with C89 defined as well to cut out all the tests that depend on declaring variables in for statements. Copyright © 2012 Simon Tatham. This document is OpenContent. You may copy and use the text under the terms of the OpenContent Licence. Please send comments and criticism on this article to anakin@pobox.com."	"null"	"null"	""	"true"
"Advanced"	"Solving the temporary storage problem of C macros"	"http://www.samnip.ps/thought/macro-storage-for-inverse-comma"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Sam Nipps Home Projects Thoughts Contact Solving the temporary storage problem of C macros, to implement an inverse comma operator Tags: c programming NOTE: I was mistaken when I said that the initializer order is guaranteed, see here. Bear that in mind. Motivation We often want to write macros that store some temporary data. Take the standard way of implementing swap: #define swap(x, y) \ do { \ typeof(x) __swap__tmp = x; \ x = y; \ y = __swap__tmp; \ } while (0) This is icky because any variable name we choose could clash with one already in the caller namespace. What's more, we have to stick it in this do while thing which (1) prevents the macro being used as an expression, and (2) stops the value itself escaping out (i.e. returning a value). (We use a do while so that the macro behaves more like a regular statement, see here.) Overview We can implement swap much better using an inline struct declaration along with a compound initializer. I start by implementing an operator of my own invention, fst, the comma operator's complement1. fst evaluates its first operand, evaluates its second, then returns the value of the first. #define fst(x, y) \ ((struct { \ __typeof__(x) first; \ __typeof__(y) second; \ }) { \ .first = (x), \ .second = (y) \ }.first) An explanation of fst The first three lines of the macro define an unnamed struct with fields for the operands. We then use compound literal syntax to declare an unnamed stack variable of this struct, initialize it and then return one of its fields. The order of evaluation is guaranteed to be the order of the initializers (edit: This might not be true. Discuss it on reddit). This is the core technique which in general allows us to store and return temporary data in a macro. swap The fst primitive lets us write the dreaded swap macro very easily, without any temporary variables. #define swap(x, y) \ ((void)((x) = fst((y), \ (y) = (x)))) In action: int main(void) {     char *x = ""first"", *y = ""second"";     swap(x, y);     printf(""%s %s\n"", x, y);     return 0; }  Result: (with an online compiler, if you don't believe me!) second first  Further uses In C we have to clean up our resources manually. I often find myself wanting to directly return the result of some string operation, only to have to put that in a temporary before cleaning up the string itself. Let's say a function constructs and prints a string, returning how many characters it printed.     char* str = malloc(...);     ...     int tmp = printf(""<a format involving %s>"", str);     free(str);     return tmp;  This can be transformed to:     char* str = malloc(...);     ...     return fst(printf(""<a format involving %s>"", str),                free(str));  Portability notes __typeof__ is an extension from GCC and Clang, and maybe more. You could avoid it by passing the type name(s) to the macro, or using some devious sizeof magic. Apart from that, compound literals are standard C99. They're even supported by MSVC. The comma operator evaluates its operands in order, and returns the second. What I mean by the complement of the comma operator is this. In designing what the comma operator does, there were two choices: return the first or the second. The comma chooses the second, `fst` chooses the first."	"null"	"null"	""	"true"
"Advanced"	"Some dark corners of C"	"https://docs.google.com/presentation/d/1h49gY3TSiayLMXYmRMaAEMl05FaJ-Z6jDOWOz3EsqqQ/edit?pli=1#slide=id.gaf50702c_0153"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Some dark corners of C - Prezentacje Google Język JavaScript nie jest włączony w przeglądarce, dlatego nie można otworzyć tego pliku. Włącz JavaScript i wczytaj ponownie. Zaloguj się Some dark corners of C      Wyświetl prezentację    Udostępnij Ta wersja Google Chrome nie jest już obsługiwana. Uaktualnij przeglądarkę do obsługiwanej wersji.Zamknij Plik Edycja Widok Pomoc Ułatwienia dostępu Debuguj Pokaż nowe zmiany             Ułatwienia dostępu    Tylko wyświetlanie           Widok HTML prezentacji"	"null"	"null"	""	"true"
"Advanced"	"Writing efficient C and C code optimization"	"http://www.codeproject.com/Articles/6154/Writing-Efficient-C-and-C-Code-Optimization"	""	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Writing Efficient C and  C Code Optimization - CodeProject 12,382,745 members (68,908 online) Sign in Email Password   Forgot your password? Sign in using Search within: Articles Quick Answers Messages home articles Chapters and Sections> Search Latest Articles Latest Tips/Tricks Top Articles Beginner Articles Technical Blogs Posting/Update Guidelines Article Help Forum Article Competition Submit an article or tip Post your Blog quick answersQ&A Ask a Question about this article Ask a Question View Unanswered Questions View All Questions... C# questions ASP.NET questions SQL questions VB.NET questions C#3.5 questions discussionsforums All Message Boards... Application Lifecycle> Running a Business Sales / Marketing Collaboration / Beta Testing Work Issues Design and Architecture ASP.NET JavaScript C / C++ / MFC> ATL / WTL / STL Managed C++/CLI C# Free Tools Objective-C and Swift Database Hardware & Devices> System Admin Hosting and Servers Java .NET Framework Android iOS Mobile SharePoint Silverlight / WPF Visual Basic Web Development Site Bugs / Suggestions Spam and Abuse Watch features Competitions News The Insider Newsletter The Daily Build Newsletter Newsletter archive Surveys Product Showcase Research Library CodeProject Stuff communitylounge Who's Who Most Valuable Professionals The Lounge   The Insider News The Weird & The Wonderful The Soapbox Press Releases Non-English Language > General Indian Topics General Chinese Topics help What is 'CodeProject'? General FAQ Ask a Question Bugs and Suggestions Article Help Forum Site Map Advertise with us Employment Opportunities About Us Articles » Languages » C / C++ Language » General   Article Browse Code Stats Revisions Alternatives Comments (80) Add your own alternative version Tagged as VC7VC7.1C++VC6WinXPWin2003WindowsWin2KVisual-StudioDev Stats 524.2K views 2 downloads 157 bookmarked Posted 21 Feb 2004 Writing Efficient C and C Code Optimization Koushik Ghosh, 26 Feb 2004    4.73 (83 votes) 1 2 3 4 5 4.73/5 - 83 votes 11 removed μ 4.27, σa 1.75 [?] Rate this: Please Sign up or sign in to vote. In this article, I have gathered all the experiences and information, which can be applied to make a C code optimized for speed as well as memory. Introduction During a project for developing a light JPEG library which is enough to run on a mobile device without compromising quality graphics on a mobile device, I have seen and worked out a number of ways in which a given computer program can be made to run faster. In this article, I have gathered all the experiences and information, which can be applied to make a C code optimized for speed as well as memory. Although a number of guidelines are available for C code optimization, there is no substitute for having a thorough knowledge of the compiler and machine for which you are programming. Often, speeding up a program can also cause the code's size to increase. This increment in code size can also have an adverse effect on a program's complexity and readability. It will not be acceptable if you are programming for small device like mobiles, PDAs etc., which have strict memory restrictions. So, during optimization, our motto should be to write the code in such a way that memory and speed both will be optimized. Declaration Actually, during my project, I have used the tips from this for optimization ARM because my project was on ARM platform, but I have also used many other articles from Internet. All tips of every article do not work well, so I collect only those tips together, which are very useful and very efficient. Also, I have modified some of them in such a way that they are almost applicable for all the environments apart from ARM. What I did is just make a collection of the information from various sites but mostly from that PDF file I mentioned above. I never claimed that these are my own discoveries. I have mentioned all information sources in the References section at the end of this article. Where it is needed? Without this point, no discussion can be started. First and the most important part of optimizing a computer program is to find out where to optimize, which portion or which module of the program is running slow or using huge memory. If each part is separately being optimized then the total program will be automatically faster. The optimizations should be done on those parts of the program that are run the most, especially those methods which are called repeatedly by various inner loops that the program can have. For an experienced programmer, it will usually be quite easy to find out the portions where a program requires the most optimization attention. But there are a lot of tools also available for detecting those parts of a program. I have used Visual C ++ IDE's in-built profiler to find out where the program spends most click tricks. Another tool I have used is Intel Vtune, which is a very good profiler for detecting the slowest parts of a program. In my experience, it will usually be a particular inner or nested loop, or a call to some third party library methods, which is the main culprit for running the program slow. Integers We should use unsigned int instead of int if we know the value will never be negative. Some processors can handle unsigned integer arithmetic considerably faster than signed (this is also good practice, and helps make for self-documenting code). So, the best declaration for an int variable in a tight loop would be: register unsigned int variable_name; although, it is not guaranteed that the compiler will take any notice of register, and unsigned may make no difference to the processor. But it may not be applicable for all compilers. Remember, integer arithmetic is much faster than floating-point arithmetic, as it can usually be done directly by the processor, rather than relying on external FPUs or floating point math libraries. We need to be accurate to two decimal places (e.g. in a simple accounting package), scale everything up by 100, and convert it back to floating point as late as possible. Division and Remainder In standard processors, depending on the numerator and denominator, a 32 bit division takes 20-140 cycles to execute. The division function takes a constant time plus a time for each bit to divide. Time (numerator / denominator) = C0 + C1* log2 (numerator / denominator)      = C0 + C1 * (log2 (numerator) - log2 (denominator)). The current version takes about 20 + 4.3N cycles for an ARM processor. As an expensive operation, it is desirable to avoid it where possible. Sometimes, such expressions can be rewritten by replacing the division by a multiplication. For example, (a / b) > c can be rewritten as a > (c * b) if it is known that b is positive and b *c fits in an integer. It will be better to use unsigned division by ensuring that one of the operands is unsigned, as this is faster than signed division. Combining division and remainder Both dividend (x / y) and remainder (x % y) are needed in some cases. In such cases, the compiler can combine both by calling the division function once because as it always returns both dividend and remainder. If both are needed, we can write them together like this example: int func_div_and_mod (int a, int b) {          return (a / b) + (a % b);     } Division and remainder by powers of two We can make a division more optimized if the divisor in a division operation is a power of two. The compiler uses a shift to perform the division. Therefore, we should always arrange, where possible, for scaling factors to be powers of two (for example, 64 rather than 66). And if it is unsigned, then it will be more faster than the signed division. typedef unsigned int uint;      uint div32u (uint a) {      return a / 32;     }     int div32s (int a){      return a / 32;     } Both divisions will avoid calling the division function and the unsigned division will take fewer instructions than the signed division. The signed division will take more time to execute because it rounds towards zero, while a shift rounds towards minus infinity. An alternative for modulo arithmetic We use remainder operator to provide modulo arithmetic. But it is sometimes possible to rewrite the code using if statement checks. Consider the following two examples: uint modulo_func1 (uint count) {    return (++count % 60); }  uint modulo_func2 (uint count) {    if (++count >= 60)   count = 0;   return (count); }  The use of the if statement, rather than the remainder operator, is preferable, as it produces much faster code. Note that the new version only works if it is known that the range of count on input is 0-59. Using array indices If you wished to set a variable to a particular character, depending upon the value of something, you might do this: switch ( queue ) { case 0 :   letter = 'W';    break; case 1 :   letter = 'S';    break; case 2 :   letter = 'U';    break; }  Or maybe: if ( queue == 0 )   letter = 'W'; else if ( queue == 1 )   letter = 'S'; else   letter = 'U';  A neater (and quicker) method is to simply use the value as an index into a character array, e.g.: static char *classes=""WSU"";  letter = classes[queue]; Global variables Global variables are never allocated to registers. Global variables can be changed by assigning them indirectly using a pointer, or by a function call. Hence, the compiler cannot cache the value of a global variable in a register, resulting in extra (often unnecessary) loads and stores when globals are used. We should therefore not use global variables inside critical loops. If a function uses global variables heavily, it is beneficial to copy those global variables into local variables so that they can be assigned to registers. This is possible only if those global variables are not used by any of the functions which are called. For example: int f(void); int g(void); int errs; void test1(void) {   errs += f();   errs += g(); }  void test2(void) {   int localerrs = errs;   localerrs += f();   localerrs += g();   errs = localerrs; }  Note that test1 must load and store the global errs value each time it is incremented, whereas test2 stores localerrs in a register and needs only a single instruction. Using Aliases Consider the following example - void func1( int *data ) {     int i;      for(i=0; i<10; i++)     {           anyfunc( *data, i);     } }  Even though *data may never change, the compiler does not know that anyfunc () did not alter it, and so the program must read it from memory each time it is used - it may be an alias for some other variable that is altered elsewhere. If we know it won't be altered, we could code it like this instead: void func1( int *data ) {     int i;     int localdata;      localdata = *data;     for(i=0; i<10; i++)     {           anyfunc ( localdata, i);     } }  This gives the compiler better opportunity for optimization. Live variables and spilling As any processor has a fixed set of registers, there is a limit to the number of variables that can be kept in registers at any one point in the program. Some compilers support live-range splitting, where a variable can be allocated to different registers as well as to memory in different parts of the function. The live-range of a variable is defined as all statements between the last assignment to the variable, and the last usage of the variable before the next assignment. In this range, the value of the variable is valid, thus it is alive. In between live ranges, the value of a variable is not needed: it is dead, so its register can be used for other variables, allowing the compiler to allocate more variables to registers. The number of registers needed for register-allocatable variables is at least the number of overlapping live-ranges at each point in a function. If this exceeds the number of registers available, some variables must be stored to memory temporarily. This process is called spilling. The compiler spills the least frequently used variables first, so as to minimize the cost of spilling. Spilling of variables can be avoided by: Limiting the maximum number of live variables: this is typically achieved by keeping expressions simple and small, and not using too many variables in a function. Subdividing large functions into smaller, simpler ones might also help. Using register for frequently-used variables: this tells the compiler that the register variable is going to be frequently used, so it should be allocated to a register with a very high priority. However, such a variable may still be spilled in some circumstances. Variable Types The C compilers support the basic types char, short, int and long (signed and unsigned), float and double. Using the most appropriate type for variables is very important, as it can reduce code and data size and increase performance considerably. Local variables Where possible, it is best to avoid using char and short as local variables. For the types char and short, the compiler needs to reduce the size of the local variable to 8 or 16 bits after each assignment. This is called sign-extending for signed variables and zero extending for unsigned variables. It is implemented by shifting the register left by 24 or 16 bits, followed by a signed or unsigned shift right by the same amount, taking two instructions (zero-extension of an unsigned char takes one instruction). These shifts can be avoided by using int and unsigned int for local variables. This is particularly important for calculations which first load data into local variables and then process the data inside the local variables. Even if data is input and output as 8- or 16-bit quantities, it is worth considering processing them as 32-bit quantities. Consider the following three example functions: int wordinc (int a) {    return a + 1; } short shortinc (short a) {     return a + 1; } char charinc (char a) {     return a + 1; }  The results will be identical, but the first code segment will run faster than others. Pointers If possible, we should pass structures by reference, that is pass a pointer to the structure, otherwise the whole thing will be copied onto the stack and passed, which will slow things down. I've seen programs that pass structures several Kilo Bytes in size by value, when a simple pointer will do the same thing. Functions receiving pointers to structures as arguments should declare them as pointer to constant if the function is not going to alter the contents of the structure. As an example: void print_data_of_a_structure ( const Thestruct  *data_pointer) {     ...printf contents of the structure... }  This example informs the compiler that the function does not alter the contents (as it is using a pointer to constant structure) of the external structure, and does not need to keep re-reading the contents each time they are accessed. It also ensures that the compiler will trap any accidental attempts by your code to write to the read-only structure and give an additional protection to the content of the structure. Pointer chains Pointer chains are frequently used to access information in structures. For example, a common code sequence is: typedef struct { int x, y, z; } Point3; typedef struct { Point3 *pos, *direction; } Object;  void InitPos1(Object *p) {    p->pos->x = 0;    p->pos->y = 0;    p->pos->z = 0; }  However, this code must reload p->pos for each assignment, because the compiler does not know that p->pos->x is not an alias for p->pos. A better version would cache p->pos in a local variable: void InitPos2(Object *p) {    Point3 *pos = p->pos;    pos->x = 0;    pos->y = 0;    pos->z = 0; }  Another possibility is to include the Point3 structure in the Object structure, thereby avoiding pointers completely. Conditional Execution Conditional execution is applied mostly in the body of if statements, but it is also used while evaluating complex expressions with relational (<, ==, > and so on) or boolean operators (&&, !, and so on). Conditional execution is disabled for code sequences which contain function calls, as on function return the flags are destroyed. It is therefore beneficial to keep the bodies of if and else statements as simple as possible, so that they can be conditionalized. Relational expressions should be grouped into blocks of similar conditions. The following example shows how the compiler uses conditional execution: int g(int a, int b, int c, int d) {    if (a > 0 && b > 0 && c < 0 && d < 0)    //  grouped conditions tied up together//       return a + b + c + d;    return -1; }  As the conditions were grouped, the compiler was able to conditionalize them. Boolean Expressions & Range checking A common boolean expression is used to check whether a variable lies within a certain range, for example, to check whether a graphics co-ordinate lies within a window: bool PointInRectangelArea (Point p, Rectangle *r) {    return (p.x >= r->xmin && p.x < r->xmax &&                       p.y >= r->ymin && p.y < r->ymax); }  There is a faster way to implement this: (x >= min && x < max) can be transformed into (unsigned)(x-min) < (max-min). This is especially beneficial if min is zero. The same example after this optimization: bool PointInRectangelArea (Point p, Rectangle *r) {     return ((unsigned) (p.x - r->xmin) < r->xmax &&    (unsigned) (p.y - r->ymin) < r->ymax);  }  Boolean Expressions & Compares with zero The Processor flags are set after a compare (i.e. CMP) instruction. The flags can also be set by other operations, such as MOV, ADD, AND, MUL, which are the basic arithmetic and logical instructions (the data processing instructions). If a data processing instruction sets the flags, the N and Z flags are set the same way as if the result was compared with zero. The N flag indicates whether the result is negative, the Z flag indicates that the result is zero. The N and Z flags on the processor correspond to the signed relational operators x < 0, x >= 0, x == 0, x != 0, and unsigned x == 0, x != 0 (or x > 0) in C. Each time a relational operator is used in C, the compiler emits a compare instruction. If the operator is one of the above, the compiler can remove the compare if a data processing operation preceded the compare. For example: int aFunction(int x, int y) {    if (x + y < 0)       return 1;   else      return 0; }  If possible, arrange for critical routines to test the above conditions. This often allows you to save compares in critical loops, leading to reduced code size and increased performance. The C language has no concept of a carry flag or overflow flag, so it is not possible to test the C or V flag bits directly without using inline assembler. However, the compiler supports the carry flag (unsigned overflow). For example: int sum(int x, int y) {    int res;    res = x + y;    if ((unsigned) res < (unsigned) x) // carry set?  //      res++;    return res; }  Lazy Evaluation Exploitation In a if(a>10 && b=4) type of thing, make sure that the first part of the AND expression is the most likely to give a false answer (or the easiest/quickest to calculate), therefore the second part will be less likely to be executed. switch() instead of if...else... For large decisions involving if...else...else..., like this: if( val == 1)     dostuff1(); else if (val == 2)     dostuff2(); else if (val == 3)     dostuff3();  It may be faster to use a switch: switch( val ) {     case 1: dostuff1(); break;      case 2: dostuff2(); break;      case 3: dostuff3(); break; }  In the if() statement, if the last case is required, all the previous ones will be tested first. The switch lets us cut out this extra work. If you have to use a big if..else.. statement, test the most likely cases first. Binary Breakdown Break things down in a binary fashion, e.g. do not have a list of: if(a==1) { } else if(a==2) { } else if(a==3) { } else if(a==4) { } else if(a==5) { } else if(a==6) { } else if(a==7) { } else if(a==8)  { }  Have instead: if(a<=4) {     if(a==1)     {     }  else if(a==2)  {     }  else if(a==3)  {     }  else if(a==4)   {      } } else {     if(a==5)  {     } else if(a==6)   {     } else if(a==7)  {     } else if(a==8)  {     } }  Or even: if(a<=4) {     if(a<=2)     {         if(a==1)         {             /* a is 1 */         }         else         {             /* a must be 2 */         }     }     else     {         if(a==3)         {             /* a is 3 */         }         else         {             /* a must be 4 */         }     } } else {     if(a<=6)     {         if(a==5)         {             /* a is 5 */         }         else         {             /* a must be 6 */         }     }     else     {         if(a==7)         {             /* a is 7 */         }         else         {             /* a must be 8 */         }     } }  Slow and Inefficient Fast and Efficient c=getch(); switch(c){     case 'A':     {         do something;         break;     }     case 'H':     {         do something;         break;     }     case 'Z':     {         do something;         break;     } }  c=getch(); switch(c){     case 0:     {         do something;         break;     }     case 1:     {         do something;         break;     }     case 2:     {         do something;         break;     } }  Compare between the two Case statements Switch statement vs. lookup tables The switch statement is typically used for one of the following reasons: To call to one of several functions. To set a variable or return a value. To execute one of several fragments of code. If the case labels are dense, in the first two uses of switch statements, they could be implemented more efficiently using a lookup table. For example, two implementations of a routine that disassembles condition codes to strings: char * Condition_String1(int condition) {   switch(condition) {      case 0: return ""EQ"";      case 1: return ""NE"";      case 2: return ""CS"";      case 3: return ""CC"";      case 4: return ""MI"";      case 5: return ""PL"";      case 6: return ""VS"";      case 7: return ""VC"";      case 8: return ""HI"";      case 9: return ""LS"";      case 10: return ""GE"";      case 11: return ""LT"";      case 12: return ""GT"";      case 13: return ""LE"";      case 14: return """";      default: return 0;   } }  char * Condition_String2(int condition) {    if ((unsigned) condition >= 15) return 0;       return       ""EQ\0NE\0CS\0CC\0MI\0PL\0VS\0VC\0HI\0LS\0GE\0LT\0GT\0LE\0\0"" +        3 * condition; }  The first routine needs a total of 240 bytes, the second only 72 bytes. Loops Loops are a common construct in most programs; a significant amount of the execution time is often spent in loops. It is therefore worthwhile to pay attention to time-critical loops. Loop termination The loop termination condition can cause significant overhead if written without caution. We should always write count-down-to-zero loops and use simple termination conditions. The execution will take less time if the termination conditions are simple. Take the following two sample routines, which calculate n!. The first implementation uses an incrementing loop, the second a decrementing loop. int fact1_func (int n) {     int i, fact = 1;     for (i = 1; i <= n; i++)       fact *= i;     return (fact); }  int fact2_func(int n) {     int i, fact = 1;     for (i = n; i != 0; i--)        fact *= i;     return (fact); }  As a result, the second one fact2_func"" will be more faster than the first one. Faster for() loops It is a simple concept but effective. Ordinarily, we used to code a simple for() loop like this: for( i=0;  i<10;  i++){ ... } [ i loops through the values 0,1,2,3,4,5,6,7,8,9 ] If we needn't care about the order of the loop counter, we can do this instead: for( i=10; i--; ) { ... } Using this code, i loops through the values 9,8,7,6,5,4,3,2,1,0, and the loop should be faster. This works because it is quicker to process i-- as the test condition, which says ""Is i non-zero? If so, decrement it and continue"". For the original code, the processor has to calculate ""Subtract i from 10. Is the result non-zero? If so, increment i and continue."". In tight loops, this makes a considerable difference. The syntax is a little strange, put is perfectly legal. The third statement in the loop is optional (an infinite loop would be written as for( ; ; )). The same effect could also be gained by coding: for(i=10; i; i--){} or (to expand it further): for(i=10; i!=0; i--){} The only things we have to be careful of are remembering that the loop stops at 0 (so if it is needed to loop from 50-80, this wouldn't work), and the loop counter goes backwards. It's easy to get caught out if your code relies on an ascending loop counter. We can also use register allocation, which leads to more efficient code elsewhere in the function. This technique of initializing the loop counter to the number of iterations required and then decrementing down to zero, also applies to while and do statements. Loop jamming Never use two loops where one will suffice. But if you do a lot of work in the loop, it might not fit into your processor's instruction cache. In this case, two separate loops may actually be faster as each one can run completely in the cache. Here is an example. //Original Code :   for(i=0; i<100; i++){     stuff(); }  for(i=0; i<100; i++){     morestuff(); }  //It would be better to do:    for(i=0; i<100; i++){     stuff();     morestuff(); }  Function Looping Functions always have a certain performance overhead when they are called. Not only does the program pointer have to change, but in-use variables have to be pushed onto a stack, and new variables allocated. There is much that can be done then to the structure of a program's functions in order to improve a program's performance. Care must be taken though to maintain the readability of the program whilst keeping the size of the program manageable. If a function is often called from within a loop, it may be possible to put that loop inside the function to cut down the overhead of calling the function repeatedly, e.g.: for(i=0 ; i<100 ; i++) {     func(t,i); } - - - void func(int w,d) {     lots of stuff. }  Could become.... func(t); - - - void func(w) {     for(i=0 ; i<100 ; i++)     {         //lots of stuff.      } }  Loop unrolling Small loops can be unrolled for higher performance, with the disadvantage of increased code size. When a loop is unrolled, a loop counter needs to be updated less often and fewer branches are executed. If the loop iterates only a few times, it can be fully unrolled, so that the loop overhead completely disappears. This can make a big difference. It is well known that unrolling loops can produce considerable savings, e.g.: for(i=0; i<3; i++){     something(i); }  //is less efficient than  something(0); something(1); something(2);  because the code has to check and increment the value of i each time round the loop. Compilers will often unroll simple loops like this, where a fixed number of iterations is involved, but something like: for(i=0;i< limit;i++) { ... } is unlikely to be unrolled, as we don't know how many iterations there will be. It is, however, possible to unroll this sort of loop and take advantage of the speed savings that can be gained. The following code (Example 1) is obviously much larger than a simple loop, but is much more efficient. The block-size of 8 was chosen just for demo purposes, as any suitable size will do - we just have to repeat the ""loop-contents"" the same amount. In this example, the loop-condition is tested once every 8 iterations, instead of on each one. If we know that we will be working with arrays of a certain size, you could make the block size the same size as (or divisible into the size of) the array. But, this block size depends on the size of the machine's cache.     //Example 1      #include<STDIO.H>       #define BLOCKSIZE (8)       void main(void)     {      int i = 0;      int limit = 33;  /* could be anything */      int blocklimit;       /* The limit may not be divisible by BLOCKSIZE,       * go as near as we can first, then tidy up.      */      blocklimit = (limit / BLOCKSIZE) * BLOCKSIZE;       /* unroll the loop in blocks of 8 */      while( i < blocklimit )      {          printf(""process(%d)\n"", i);          printf(""process(%d)\n"", i+1);          printf(""process(%d)\n"", i+2);          printf(""process(%d)\n"", i+3);          printf(""process(%d)\n"", i+4);          printf(""process(%d)\n"", i+5);          printf(""process(%d)\n"", i+6);          printf(""process(%d)\n"", i+7);           /* update the counter */          i += 8;       }       /*       * There may be some left to do.      * This could be done as a simple for() loop,       * but a switch is faster (and more interesting)       */       if( i < limit )      {          /* Jump into the case at the place that will allow          * us to finish off the appropriate number of items.           */           switch( limit - i )          {              case 7 : printf(""process(%d)\n"", i); i++;              case 6 : printf(""process(%d)\n"", i); i++;              case 5 : printf(""process(%d)\n"", i); i++;              case 4 : printf(""process(%d)\n"", i); i++;              case 3 : printf(""process(%d)\n"", i); i++;              case 2 : printf(""process(%d)\n"", i); i++;              case 1 : printf(""process(%d)\n"", i);          }     }       } Population count - counting the number of bits set This example 1 efficiently tests a single bit by extracting the lowest bit and counting it, after which the bit is shifted out. The example 2 was first unrolled four times, after which an optimization could be applied by combining the four shifts of n into one. Unrolling frequently provides new opportunities for optimization. //Example - 1  int countbit1(uint n) {   int bits = 0;   while (n != 0)   {     if (n & 1) bits++;     n >>= 1;    }   return bits; }   //Example - 2  int countbit2(uint n) {    int bits = 0;    while (n != 0)    {       if (n & 1) bits++;       if (n & 2) bits++;       if (n & 4) bits++;       if (n & 8) bits++;       n >>= 4;    }    return bits; }  Early loop breaking It is often not necessary to process the entirety of a loop. For example, if we are searching an array for a particular item, break out of the loop as soon as we have got what we need. Example: this loop searches a list of 10000 numbers to see if there is a -99 in it. found = FALSE; for(i=0;i<10000;i++) {     if( list[i] == -99 )     {         found = TRUE;     } }  if( found ) printf(""Yes, there is a -99. Hooray!\n"");  This works well, but will process the entire array, no matter where the search item occurs in it. A better way is to abort the search as soon as we've found the desired entry. found = FALSE; for(i=0; i<10000; i++) {     if( list[i] == -99 )     {         found = TRUE;         break;     } } if( found ) printf(""Yes, there is a -99. Hooray!\n"");  If the item is at, say position 23, the loop will stop there and then, and skip the remaining 9977 iterations. Function Design It is a good idea to keep functions small and simple. This enables the compiler to perform other optimizations, such as register allocation, more efficiently. Function call overhead Function call overhead on the processor is small, and is often small in proportion to the work performed by the called function. There are some limitations up to which words of arguments can be passed to a function in registers. These arguments can be integer-compatible (char, shorts, ints and floats all take one word), or structures of up to four words (including the 2-word doubles and long longs). If the argument limitation is 4, then the fifth and subsequent words are passed on the stack. This increases the cost of storing these words in the calling function and reloading them in the called function. In the following sample code: int f1(int a, int b, int c, int d) {    return a + b + c + d; }  int g1(void) {    return f1(1, 2, 3, 4); }   int f2(int a, int b, int c, int d, int e, int f) {   return a + b + c + d + e + f; }  ing g2(void) {  return f2(1, 2, 3, 4, 5, 6); }  the fifth and sixth parameters are stored on the stack in g2, and reloaded in f2, costing two memory accesses per parameter. Minimizing parameter passing overhead To minimize the overhead of passing parameters to functions: Try to ensure that small functions take four or fewer arguments. These will not use the stack for argument passing. If a function needs more than four arguments, try to ensure that it does a significant amount of work, so that the cost of passing the stacked arguments is outweighed. Pass pointers to structures instead of passing the structure itself. Put related arguments in a structure, and pass a pointer to the structure to functions. This will reduce the number of parameters and increase readability. Minimize the number of long parameters, as these take two argument words. This also applies to doubles if software floating-point is enabled. Avoid functions with a parameter that is passed partially in a register and partially on the stack (split-argument). This is not handled efficiently by the current compilers: all register arguments are pushed on the stack. Avoid functions with a variable number of parameters. Those functions effectively pass all their arguments on the stack. Leaf functions A function which does not call any other functions is known as a leaf function. In many applications, about half of all function calls made are to leaf functions. Leaf functions are compiled very efficiently on every platform, as they often do not need to perform the usual saving and restoring of registers. The cost of pushing some registers on entry and popping them on exit is very small compared to the cost of the useful work done by a leaf function that is complicated enough to need more than four or five registers. If possible, we should try to arrange for frequently-called functions to be leaf functions. The number of times a function is called can be determined by using the profiling facility. There are several ways to ensure that a function is compiled as a leaf function: Avoid calling other functions: this includes any operations which are converted to calls to the C-library (such as division, or any floating-point operation when the software floating-point library is used). Use __inline for small functions which are called from it (inline functions discussed next). Inline functions Function inlining is disabled for all debugging options. Functions with the keyword __inline results in each call to an inline function being substituted by its body, instead of a normal call. This results in faster code, but it adversely affects code size, particularly if the inline function is large and used often.     __inline int square(int x) {        return x * x;     }      #include <MATH.H>      double length(int x, int y){         return sqrt(square(x) + square(y));     } There are several advantages to using inline functions: No function call overhead. As the code is substituted directly, there is no overhead, like saving and restoring registers. Lower argument evaluation overhead. The overhead of parameter passing is generally lower, since it is not necessary to copy variables. If some of the parameters are constants, the compiler can optimize the resulting code even further. The big disadvantage of inline functions is that the code sizes increase if the function is used in many places. This can vary significantly depending on the size of the function, and the number of places where it is used. It is wise to only inline a few critical functions. Note that when done wisely, inlining may decrease the size of the code: a call takes usually a few instructions, but the optimized version of the inlined code might translate to even less instructions. Using Lookup Tables A function can often be approximated using a lookup table, which increases performance significantly. A table lookup is usually less accurate than calculating the value properly, but for many applications, this does not matter. Many signal processing applications (for example, modem demodulator software) make heavy use of sin and cos functions, which are computationally expensive to calculate. For real-time systems where accuracy is not very important, sin/cos lookup tables might be essential. When using lookup tables, try to combine as many adjacent operations as possible into a single lookup table. This is faster and uses less space than multiple lookup tables. Floating-Point Arithmetic Although floating point operations are time consuming for any kind of processors, sometimes we need to used it in case of implementing signal processing applications. However, when writing floating-point code, keep the following things in mind: Floating-point division is slow. Division is typically twice as slow as addition or multiplication. Rewrite divisions by a constant into a multiplication with the inverse (For example, x = x / 3.0 becomes x = x * (1.0/3.0). The constant is calculated during compilation.). Use floats instead of doubles. Float variables consume less memory and fewer registers, and are more efficient because of their lower precision. Use floats whenever their precision is good enough. Avoid using transcendental functions. Transcendental functions, like sin, exp and log are implemented using series of multiplications and additions (using extended precision). As a result, these operations are at least ten times slower than a normal multiply. Simplify floating-point expressions. The compiler cannot apply many optimizations which are performed on integers to floating-point values. For example, 3 * (x / 3) cannot be optimized to x, since floating-point operations generally lead to loss of precision. Even the order of evaluation is important: (a + b) + c is not the same as a + (b + c). Therefore, it is beneficial to perform floating-point optimizations manually if it is known they are correct. However, it is still possible that the floating performance will not reach the required level for a particular application. In such a case, the best approach may be to change from using floating-point to fixed point arithmetic. When the range of values needed is sufficiently small, fixed-point arithmetic is more accurate and much faster than floating-point arithmetic. Misc tips In general, savings can be made by trading off memory for speed. If you can cache any often used data rather than recalculating or reloading it, it will help. Examples of this would be sine/cosine tables, or tables of pseudo-random numbers (calculate 1000 once at the start, and just reuse them if you don't need truly random numbers). Avoid using ++ and -- etc. within loop expressions. E.g.: while(n--){}, as this can sometimes be harder to optimize. Minimize the use of global variables. Declare anything within a file (external to functions) as static, unless it is intended to be global. Use word-size variables if you can, as the machine can work with these better (instead of char, short, double, bit fields etc.). Don't use recursion. Recursion can be very elegant and neat, but creates many more function calls which can become a large overhead. Avoid the sqrt() square root function in loops - calculating square roots is very CPU intensive. Single dimension arrays are faster than multi-dimension arrays. Compilers can often optimize a whole file - avoid splitting off closely related functions into separate files, the compiler will do better if it can see both of them together (it might be able to inline the code, for example). Single precision math may be faster than double precision - there is often a compiler switch for this. Floating point multiplication is often faster than division - use val * 0.5 instead of val / 2.0. Addition is quicker than multiplication - use val + val + val instead of val * 3. puts() is quicker than printf(), although less flexible. Use #defined macros instead of commonly used tiny functions - sometimes the bulk of CPU usage can be tracked down to a small external function being called thousands of times in a tight loop. Replacing it with a macro to perform the same job will remove the overhead of all those function calls, and allow the compiler to be more aggressive in its optimization.. Binary/unformatted file access is faster than formatted access, as the machine does not have to convert between human-readable ASCII and machine-readable binary. If you don't actually need to read the data in a file yourself, consider making it a binary file. If your library supports the mallopt() function (for controlling malloc), use it. The MAXFAST setting can make significant improvements to code that does a lot of malloc work. If a particular structure is created/destroyed many times a second, try setting the mallopt options to work best with that size. Last, but definitely not least - turn compiler optimization on! Seems obvious, but is often forgotten in that last minute rush to get the product out on time. The compiler will be able to optimize at a much lower level than can be done in the source code, and perform optimizations specific to the target processor. References Writing Efficient C for ARM Document number: ARM DAI 0034A Issued: January 1998 Copyright Advanced RISC Machines Ltd. (ARM) 1998 Richard's C Optimization page OR: How to make your C, C++ or Java program run faster with little effort. Code Optimization Using the GNU C Compiler By Rahul U Joshi. Compile C Faster on Linux [Christopher W. Fraser (Microsoft Research), David R. Hanson (Princeton University)] CODE OPTIMIZATION - COMPILER [1] [2] [Thanks to Craig Burley for the excellent comments. Thanks to Timothy Prince for the note on architectures with Instruction Level Parallelism]. An Evolutionary Analysis of GNU C Optimizations [Using Natural Selection to Investigate Software Complexities by Scott Robert Ladd. Updated: 16 December 2003] Other URLs http://www.xs4all.nl/~ekonijn/loopy.html http://www.public.asu.edu/~sshetty/Optimizing_Code_Manual.doc http://www.abarnett.demon.co.uk/tutorial.html License This article has no explicit license attached to it but may contain usage terms in the article text or the download files themselves. If in doubt please contact the author via the discussion board below. A list of licenses authors might use can be found here Share email twitter facebook linkedin reddit google+ About the Author Koushik Ghosh Software Developer (Senior) ibm India No Biography provided You may also be interested in... 10 Ways to Boost COBOL Application Development SAPrefs - Netscape-like Preferences Dialog Visual COBOL New Release: Small point. Big deal Generate and add keyword variations using AdWords API Creating User Interface in SharePoint Online with Kendo UI Window Tabs (WndTabs) Add-In for DevStudio Comments and Discussions   You must Sign In to use this message board. Search Comments   Profile popups    Spacing RelaxedCompactTight   Layout NormalOpen TopicsOpen AllThread View   Per page 102550     First PrevNext Error paulushi17-Sep-15 20:17 paulushi 17-Sep-15 20:17  You have an error in the code bool PointInRectangelArea (Point p, Rectangle *r) {     return ((unsigned) (p.x - r->xmin) < r->xmax &&    (unsigned) (p.y - r->ymin) < r->ymax); } And it should be: bool PointInRectangelArea (Point p, Rectangle *r) {     return ((unsigned) (p.x - r->xmin) < r->xmax - r->xmin &&    (unsigned) (p.y - r->ymin) < r->ymax - r->ymin); } Or even: bool PointInRectangelArea (Point p, Rectangle *r) {     return ((unsigned) (p.x - r->xmin) < r->xdif &&    (unsigned) (p.y - r->ymin) < r->ydif); } Sign In·View Thread·Permalink You rock! Full 5! paulushi9-Sep-15 22:51 paulushi 9-Sep-15 22:51  This is the best article about performance in C! Sign In·View Thread·Permalink Revisit this? bearvarine15-Oct-14 6:35 bearvarine 15-Oct-14 6:35  Hi Koushik, This was an exceptionally well-written and useful post. Since it has been 10 years from when you first posted it, perhaps it is time to update it? Certainly you must have developed more ideas since 2004. Have you considered writing a similar article for C++? Best, -Bearvarine Sign In·View Thread·Permalink switch case statements. sid2x4-Jul-14 20:29 sid2x 4-Jul-14 20:29  A comprehensive and well written article, however I've a small doubt about the switch case statements where in you say that, case 'A' is slower as compared to `case 0:`, how are the 2 statements similar? case 'A' as far as i know would be translated to case 65: (A equals 65 in ASCII), `case 0` will just check if c is a null character which obviously isn't what the programmer wanted in the first place. My vote of 4/5! Sign In·View Thread·Permalink References and links are obselete Member 1043254223-Mar-14 18:42 Member 10432542 23-Mar-14 18:42  All the links and references given in this article are obselete. They are throwing HTTP 404 errors. Please do upadate the same if possible. Thanks!! Sign In·View Thread·Permalink Tips for beginners Nipun Parikh13-Feb-14 3:29 Nipun Parikh 13-Feb-14 3:29  Here are my tips for beginners: http://virtual-lexicon.blogspot.com/2014/02/write-efficient-c-cplusplus-programs.html[^] Sign In·View Thread·Permalink My vote of 4 Fuxymaxy18-Jun-13 7:56 Fuxymaxy 18-Jun-13 7:56  Wonderful tips, clearly explained! Amount of methods is a bit small, but its a personal experience! Sign In·View Thread·Permalink My vote of 5 Member 857608121-May-12 2:57 Member 8576081 21-May-12 2:57  Nicely compiled and a very knowledgeable article.. Thanks for sharing! Sign In·View Thread·Permalink My vote of 5 Ram VR4-Apr-12 8:29 Ram VR 4-Apr-12 8:29  Good compilation of useful tips. Sign In·View Thread·Permalink My vote of 5 manoj kumar choubey9-Feb-12 23:19 manoj kumar choubey 9-Feb-12 23:19  Nice Sign In·View Thread·Permalink Awesome ajay_t27-Jan-12 0:11 ajay_t 27-Jan-12 0:11  Very Good Article Thanks a lot.. Sign In·View Thread·Permalink Cool!!! P1119r1m2-Jun-11 10:10 P1119r1m 2-Jun-11 10:10  It is very nice article taking into consideration that we haven't a lot of articles about performance optimization for ARM processors. My thanks to the author Koushik Ghosh! Sign In·View Thread·Permalink OPTIMIZE THIS CODE AND OPTIMIZE MAINLY ""DoMultiplication"" FUNCTION MAINLY..URGENT nithin.bg6-Aug-08 18:55 nithin.bg 6-Aug-08 18:55  #include <stdio.h> #include <stdlib.h> #include <math.h> #include <string.h> #include <dos.h> #include <time.h> #define PI 3.14159265 /*Value of Mathematical Constant PI*/ typedef struct COMPLEX /* Structure to hold the complex data-REAL part & IMAGINARY part */ { float real; float imag; }COMPLEX; typedef struct MATRIX /* Structure to hold information about the MATRIX D & VECTOR X & Y */ { COMPLEX** comp; int nRows; /*Number of rows*/ int nCols; /*Number of columns*/ }MATRIX; typedef struct VECTOR /* Structure to hold information about the MATRIX D & VECTOR X & Y */ { COMPLEX* comp; int nElements; /*Number of Elements*/ }VECTOR; void CreateMatrix(MATRIX* , int , int );/*Function to create MATRIX D */ void CreateVector(VECTOR* , int);/*Function to create VECTOR X & Y*/ void CalculateDMatrix(MATRIX*);/*Function to calculate MATRIX D */ void InitXVector(VECTOR*);/*Function to initialise vector X */ void DoMultiplication(const MATRIX* ,const VECTOR* , VECTOR*);/*Function to multiply MATRIX D & VECTOR X storing the result in VECTOR Y*/ void PrintMatrix(const MATRIX*);/*Function to Print Matrix D ,Vector X & Y */ void PrintVector(const VECTOR*);/*Function to Print Matrix D ,Vector X & Y */ ****************************end of header*********************************************** #include ""time_vect_mat_mult.h"" int main(void) { clock_t start, finish; /* Used for calculating the time taken for calculation */ double duration; MATRIX matD;/* Defining matD of type MATRIX_VECTOR */ VECTOR vecX;/* Defining vecX of type MATRIX_VECTOR */ VECTOR vecY;/* Defining vecY of type MATRIX_VECTOR */ /*DMA done here*/ CreateMatrix(&matD,1024,1024); /* Matrix D of order = 1024*1024 */ CreateVector(&vecX,1024); /* Vector X & no of element = 1024 */ CreateVector(&vecY,1024); /* Vector Y & no of element = 1024 */ /*D matrix is calculated according to given expression*/ CalculateDMatrix(&matD); /*X matrix is initialsed according to given data */ InitXVector(&vecX);/*Function to initialise vector X */ start = clock(); DoMultiplication(&matD, &vecX, &vecY);/*Function to multiply MATRIX D & VECTOR X*/ finish = clock(); duration = (double)(finish - start) / CLOCKS_PER_SEC; printf( ""Using clock_t: %f seconds\n"", duration ); getchar(); return 0; } void CreateMatrix(MATRIX* temp, int nRows, int nCols)/*Function to create MATRIX D */ { int i; temp->nRows = nRows; temp->nCols = nCols; temp->comp = (COMPLEX **)malloc(sizeof(COMPLEX *) * temp->nRows); for(i=0;i<temp->nRows;i++) temp->comp[i] = (COMPLEX *)malloc(sizeof(COMPLEX) * temp->nCols); } void CreateVector(VECTOR* temp, int nElements)/*Function to create VECTOR X & VECTOR Y */ { temp->nElements = nElements; temp->comp = (COMPLEX *)malloc(sizeof(COMPLEX) * temp->nElements); } void CalculateDMatrix(MATRIX* temp)/*Function to calculate the Real & Imaginary part of MATRIX D*/ { int i,j; for(i=0 ; i<temp->nRows ; i++) { for(j=0 ; j<temp->nCols ; j++) { temp->comp[i][j].real = (float)cos(-PI*i*j/2); temp->comp[i][j].imag = (float)sin(-PI*i*j/2); } } } void InitXVector(VECTOR* temp)/*Function to initialise Real & Imaginary part of vector X */ { int i; for(i=0;i<temp->nElements;i++) { temp->comp[i].real = 0.01f; temp->comp[i].imag = 0.00f; } } void DoMultiplication(const MATRIX* matA,const VECTOR* vectB, VECTOR* vectC)/*Function to multiply MATRIX D & VECTOR X storing the result in VECTOR Y*/ { int i,k; for(i=0 ; i<vectC->nElements ; ++i) { vectC->comp[i].real = 0; vectC->comp[i].imag = 0; for(k=0 ; k<matA->nCols ; ++k) { vectC->comp[i].real += matA->comp[i][k].real * vectB->comp[k].real - matA->comp[i][k].imag * vectB->comp[k].imag; vectC->comp[i].imag += matA->comp[i][k].real * vectB->comp[k].imag + matA->comp[i][k].imag * vectB->comp[k].real; } } } Sign In·View Thread·Permalink Optimization samgupt11-Jun-08 2:57 samgupt 11-Jun-08 2:57  some time condition if (0 == a) is better than if (a == 0)where a is the variable. Can you please tell the reason ? thanks Sign In·View Thread·Permalink Re: Optimization Koushik Ghosh11-Jun-08 6:31 Koushik Ghosh 11-Jun-08 6:31  May be it won't be a better option, as I found both are using same asm code. int main (void) { int a = 20; if (a == 0) { a = 11; } return 0; } _main: pushl %ebp movl %esp, %ebp subl $8, %esp andl $-16, %esp movl $0, %eax addl $15, %eax addl $15, %eax shrl $4, %eax sall $4, %eax movl %eax, -8(%ebp) movl -8(%ebp), %eax call __alloca call ___main movl $20, -4(%ebp) cmpl $0, -4(%ebp) jne L2 movl $11, -4(%ebp) L2: movl $0, %eax leave ret if (0 == a) { a = 11; } call ___main movl $20, -4(%ebp) cmpl $0, -4(%ebp) jne L2 movl $11, -4(%ebp) L2: movl $0, %eax leave ret Sign In·View Thread·Permalink Re: Optimization pushkar.chitnis@gmail.com4-Mar-11 9:54 pushkar.chitnis@gmail.com 4-Mar-11 9:54  Old thread but just wanted this out there. 0 == a does not provide perf improvements. It just ensures that users avoid the common error of missing one '=' in the equals condition. Say you want to write a condition if(a==1) but you accidently miss a '=' and enter if(a=1). Many old compilers will consider this statement valid or at max give a warning. This issue will never arrise if you use (1==a) notation because missing a '=' would cause compilation error and flag the issue right away. Sign In·View Thread·Permalink Re: Optimization samgupt9-Mar-11 1:31 samgupt 9-Mar-11 1:31  Thanks for your answer. I think this might be the reason for it. Sign In·View Thread·Permalink using goto statements for efficiency (forbidden by all my colledge professors) iojefoiejo1-Jun-06 4:27 iojefoiejo 1-Jun-06 4:27  i use codewarrior to compile a long C program ive been working on for over 10 years. i program runs for hours so its important to make it efficient. i found the codewarrior compiler crashed at about 15000 lines of C code. however, i could compile more lines by eliminating compound if statements and for loops, instead using goto statements. my question is if goto runs more effiently than if and for statements. since there is such dogma against using goto statements, which i strongly disagree with, i cant find anywhere on the entire internet addressing using goto instead of other structures for effeciency. my colledge professors would automatically fail code that used even one goto, and would get quite indignant when i would bring up this forbidden topic in class. anyway, speciffically would if(test!=1) goto endtest; //1000 lines of code// endtest: run more efficiently then if(test==1){ //1000 lines of code } also would beginfor: //1000 lines of code if(test<10000)goto beginfor; be more efficient then for( i=1000; i--; ){ //1000 lines of code } thanks to anyone who can comment on this (forbidden) topic. code warrior doesn't seem to have any method of testing code efficiency, such as telling how many steps the code has taken, and using the clock is unreliable since it clocks everything, not just the running codewarrior code, so i havent been able to test efficiency myself. michael brown michael brown Sign In·View Thread·Permalink Re: using goto statements for efficiency (forbidden by all my colledge professors) Kevin Drzycimski21-Jul-10 3:05 Kevin Drzycimski 21-Jul-10 3:05  i dont mind using a goto where it makes the code clearer or even faster! there was this paper from dijkstra considering goto harmful...well that was back in time where there was only goto - now we have structured, functional and object-oriented programming. if in a single function there is a goto which actual makes good sense - just do it! Sign In·View Thread·Permalink Faster for loops??? [modified] Lyra Belacqua24-May-06 0:08 Lyra Belacqua 24-May-06 0:08  Correct me if I'm wrong or someone else mentioned it before but in my opinion: for(i=10;i--; ) is not a loop running the values 9,8,7,6,5,4,3,2,1,0 but it's running 10,9,8,7,6,5,4,3,2,1 which is not a small difference taking the fact that most loops working on arrays, need to work on index 0 of the array also. So this optimization is not very useful because seldom applicable. -- modified at 6:08 Wednesday 24th May, 2006 Sign In·View Thread·Permalink Re: Faster for loops??? Ricky Lung1-Sep-07 20:33 Ricky Lung 1-Sep-07 20:33  i-- get executed and tested against zero before the loop body being executed the first time. Sign In·View Thread·Permalink Re: Faster for loops??? [modified] Member 115581966-Sep-15 21:12 Member 11558196 6-Sep-15 21:12  In the code below, the ""i"" variable is checked first, then decremented. On the first run, i is checked as being 10, then its immediately decremented to 9 before being used in an expression; so it won't cause an out-of-range error if used in a 10 element array. On the very last run, i is checked as being 1 before being decremented to zero and used in an expression; so the expressions that follow ultimately start from 9 and end at 0. i may decrement to -1 before the loop closes, but not before the loop reads i as being 0 (boolean equivalent of false) which signals the loop to close. #include <stdio.h>  int main(int argc, char *argv[]){         int i;         char userName[10] = ""gmCarlson"";           // For loop         for(i = 10; i--;){                 printf(""%c"", username[i]);         }         // Output: noslraCmg          return 0; } In this case, iterating through the array elements backwards would also print my user name backwards, so that wouldn't produce favorable results; but if you're just copying string data from one string to another, it works just as well. Sign In·View Thread·Permalink More on loop unrolling Tomer Margolin18-Oct-05 6:57 Tomer Margolin 18-Oct-05 6:57  Many say that the most dramatic use of loop unrolling was by Tom Duff. His code innovation is even called ""Duff's Device"". A Short Explaination Sign In·View Thread·Permalink Re: More on loop unrolling samgupt9-Mar-11 1:29 samgupt 9-Mar-11 1:29  At first glance code look weird but its perfectly working code. gr8 piece of code Sign In·View Thread·Permalink Global variables marius124321-Sep-04 1:26 marius1243 21-Sep-04 1:26  Thank You for great, great article, VERY useful information In the article we can read about minimizing the use of global variables. Is is about those variables declared outside the window procedure ? How about those declared in window procedure but before main switch statement? Does space is allocated for those global variables every time window procedure is called ? (even when procedure is called with message that doesn't use most of those variables?) In this case is it better to declare them seperately in each case(message)??????? Or maybe space for those global variables inside window procedure is allocated only once at the begining ??? PLEEEAAASE could explain it to me Sign In·View Thread·Permalink Last Visit: 31-Dec-99 18:00     Last Update: 15-Jul-16 7:40 Refresh 1234 Next » General    News    Suggestion    Question    Bug    Answer    Joke    Praise    Rant    Admin    Use Ctrl+Left/Right to switch messages, Ctrl+Up/Down to switch threads, Ctrl+Shift+Left/Right to switch pages. Go to top Permalink | Advertise | Privacy | Terms of Use | Mobile Web02 | 2.8.160714.1 | Last Updated 27 Feb 2004 Article Copyright 2004 by Koushik Ghosh Everything else Copyright © CodeProject, 1999-2016 Layout: fixed | fluid"	"null"	"null"	""	"true"
"Beginner"	"C Primer Plus 6E"	"https://www.pearsonhighered.com/program/Prata-C-Primer-Plus-6th-Edition/PGM4399.html"	"A complete tutorial on programming in C11."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Prata, C Primer Plus, 6th Edition Available Products & Services COURSE CONTENT & DIGITAL RESOURCES Interactive Learning & Assessment REVEL™ MyLab™ & Mastering™ Online Courses CourseConnect™ Pearson Workforce Education Propero® Learning Applications Acclaim Digital Badging Learning Catalytics™ MediaShare Pearson Writer StatCrunch Course Content MyCourseTools Textbooks & eTexts Pearson Collections INSTITUTIONAL SERVICES & SOLUTIONS Pearson helps administrators tackle some of the biggest challenges facing colleges and universities by providing content, technology, and service expertise. Learn about our service capabilities and solutions Disciplines HUMANITIES & SOCIAL SCIENCES Anthropology Art Communication, Film & Theatre English History Interdisciplinary Studies Music Philosophy Political Science Psychology Religion Social Work / Family Therapy / Human Services Sociology World Languages MATH & SCIENCE Anatomy & Physiology Biology & Microbiology Chemistry Environmental Science Geography & Atmospheric Sciences Geology & Oceanography Health & Kinesiology Mathematics Nutrition Physics & Astronomy Statistics PROFESSIONAL & CAREER Business Business Statistics Communication Sciences & Disorders Computer Science Counseling Criminal Justice Culinary, Hospitality, Travel & Tourism Deaf Studies & Deaf Education Economics Education EMS & Fire Science (Brady) Engineering Fashion & Interior Design Health Professions Information Technology Legal Studies & Paralegal Nursing Student Success & Career Development Trades & Technology Your Role Tell us who you are and we'll point you to resources and information just for you. Educator Student Academic Dean Administrator College Reseller Private Sector Education Workforce Director Support We're committed to providing you with the service and support you need. Download instructor resources Support for Educators & Institutions Support for Students Bookbag Search USA HIGHER EDUCATION > Computer Science > C Programming > C Primer Plus, 6th Edition View Larger C Primer Plus, 6th Edition Stephen Prata ©2014  |&nbspAddison-Wesley Professional  | Available Educator Order Info Preview this title online Request a printed copy Download instructor resources Additional order info Student Order Info Buy this product Buy or rent an eText Additional order info Overview Features Contents Authors Resources Order Info Packages Overview Previous Edition(s) Courses Overview Description C Primer Plus is a carefully tested, well-crafted, and complete tutorial on a subject core to programmers and developers. This computer science classic teaches principles of programming, including structured code and top-down design. The sixth edition of this book has been updated and expanded to cover the latest developments in C as well as to take a detailed look at the new C11 standard. Previous Edition(s) C Primer Plus, 5th Edition Prata ©2005  | Sams Publishing  | Paper  | 984 pp  | ISBN-13: 9780672326967 More info Courses This title is appropriate for the following courses. Select a course to see additional titles C Programming(Computer Science) C/C++ Programming(Electronics & Electricity Technology) Features New to This Edition Features Solutions to the exercises in the text are available in the IRC. New to This Edition This sixth edition contains: ·         New coverage of the C11 standard ·         Updated information about the latest C compilers for Windows, OS X, and Linux ·         New material on C programming for mobile and game development ·         New material on C-based object-oriented programming languages (e.g., Objective-C)   Table of Contents Preface xxvii 1 Getting Ready 1     Whence C? 1     Why C? 2         Design Features 2         Efficiency 3         Portability 3         Power and Flexibility 3         Programmer Oriented 3         Shortcomings 4     Whither C? 4     What Computers Do 5     High-level Computer Languages and Compilers 6     Language Standards 7         The First ANSI/ISO C Standard 8         The C99 Standard 8         The C11 Standard 9     Using C: Seven Steps 9         Step 1: Define the Program Objectives 10         Step 2: Design the Program 10         Step 3: Write the Code 11         Step 4: Compile 11         Step 5: Run the Program 12         Step 6: Test and Debug the Program 12         Step 7: Maintain and Modify the Program 13         Commentary 13     Programming Mechanics 13         Object Code Files, Executable Files, and Libraries 14         Unix System 16         The GNU Compiler Collection and the LLVM Project 18         Linux Systems 18         Command-Line Compilers for the PC 19         Integrated Development Environments (Windows) 19         The Windows/Linux Option 21         C on the Macintosh 21     How This Book Is Organized 22     Conventions Used in This Book 22         Typeface 22         Program Output 23         Special Elements 24     Summary 24     Review Questions 25     Programming Exercise 25 2 Introducing C 27     A Simple Example of C 27     The Example Explained 28         Pass 1: Quick Synopsis 30         Pass 2: Program Details 31     The Structure of a Simple Program 40     Tips on Making Your Programs Readable 41     Taking Another Step in Using C 42         Documentation 43         Multiple Declarations 43         Multiplication 43         Printing Multiple Values 43     While You’re at It–Multiple Functions 44     Introducing Debugging 46         Syntax Errors 46         Semantic Errors 47         Program State 49     Keywords and Reserved Identifiers 49     Key Concepts 50     Summary 51     Review Questions 51     Programming Exercises 53 3 Data and C 55     A Sample Program 55         What’s New in This Program? 57     Data Variables and Constants 59     Data: Data-Type Keywords 59         Integer Versus Floating-Point Types 60         The Integer 61         The Floating-Point Number 61     Basic C Data Types 62         The int Type 62         Other Integer Types 66         Using Characters: Type char 71         The _Bool Type 77         Portable Types: stdint.h and inttypes.h 77         Types float, double, and long double 79         Complex and Imaginary Types 85         Beyond the Basic Types 85         Type Sizes 87     Using Data Types 88     Arguments and Pitfalls 89     One More Example: Escape Sequences 91     What Happens When the Program Runs 91         Flushing the Output 92     Key Concepts 93     Summary 93     Review Questions 94     Programming Exercises 97 4 Character Strings and Formatted Input/Output 99     Introductory Program 99     Character Strings: An Introduction 101         Type char Arrays and the Null Character 101         Using Strings 102         The strlen() Function 103     Constants and the C Preprocessor 106         The const Modifier 109         Manifest Constants on the Job 109     Exploring and Exploiting printf() and scanf() 112         The printf() Function 112         Using printf() 113         Conversion Specification Modifiers for printf() 115         What Does a Conversion Specification Convert? 122         Using scanf() 128         The * Modifier with printf() and scanf() 133         Usage Tips for printf() 135     Key Concepts 136     Summary 137     Review Questions 138     Programming Exercises 140 5 Operators, Expressions, and Statements 143     Introducing Loops 144     Fundamental Operators 146         Assignment Operator: = 146         Addition Operator: + 149         Subtraction Operator: — 149         Sign Operators: — and + 150         Multiplication Operator: * 151         Division Operator: / 153         Operator Precedence 154         Precedence and the Order of Evaluation 156     Some Additional Operators 157         The sizeof Operator and the size_t Type 158         Modulus Operator: % 159         Increment and Decrement Operators: ++ and -- 160         Decrementing: -- 164         Precedence 165         Don’t Be Too Clever 166     Expressions and Statements 167         Expressions 167         Statements 168         Compound Statements (Blocks) 171     Type Conversions 174         The Cast Operator 176     Function with Arguments 177     A Sample Program 180     Key Concepts 182     Summary 182     Review Questions 183     Programming Exercises 187 6 C Control Statements: Looping 189     Revisiting the while Loop 190         Program Comments 191         C-Style Reading Loop 192     The while Statement 193         Terminating a while Loop 194         When a Loop Terminates 194         while: An Entry-Condition Loop 195         Syntax Points 195     Which Is Bigger: Using Relational Operators and Expressions 197         What Is Truth? 199         What Else Is True? 200         Troubles with Truth 201         The New _Bool Type 203         Precedence of Relational Operators 205     Indefinite Loops and Counting Loops 207     The for Loop 208         Using for for Flexibility 210     More Assignment Operators: +=, -=, *=, /=, %= 215     The Comma Operator 215         Zeno Meets the for Loop 218     An Exit-Condition Loop: do while 220     Which Loop? 223     Nested Loops 224     Program Discussion 225         A Nested Variation 225     Introducing Arrays 226         Using a for Loop with an Array 228     A Loop Example Using a Function Return Value 230         Program Discussion 232         Using Functions with Return Values 233     Key Concepts 234     Summary 235     Review Questions 236     Programming Exercises 241 7 C Control Statements: Branching and Jumps 245     The if Statement 246     Adding else to the if Statement 248         Another Example: Introducing getchar() and putchar() 250         The ctype.h Family of Character Functions 252         Multiple Choice else if 254         Pairing else with if 257         More Nested ifs 259     Let’s Get Logical 263         Alternate Spellings: The iso646.h Header File 265         Precedence 265         Order of Evaluation 266         Ranges 267     A Word-Count Program 268     The Conditional Operator: ?: 271     Loop Aids: continue and break 274         The continue Statement 274         The break Statement 277     Multiple Choice: switch and break 280         Using the switch Statement 281         Reading Only the First Character of a Line 283         Multiple Labels 284         switch and if else 286     The goto Statement 287         Avoiding goto 287     Key Concepts 291     Summary 291     Review Questions 292     Programming Exercises 296 8 Character Input/Output and Input Validation 299     Single-Character I/O: getchar() and putchar() 300     Buffers 301     Terminating Keyboard Input 302         Files, Streams, and Keyboard Input 303         The End of File 304     Redirection and Files 307         Unix, Linux, and Windows Command Prompt Redirection 307     Creating a Friendlier User Interface 312         Working with Buffered Input 312         Mixing Numeric and Character Input 314     Input Validation 317         Analyzing the Program 322         The Input Stream and Numbers 323     Menu Browsing 324         Tasks 324         Toward a Smoother Execution 325         Mixing Character and Numeric Input 327     Key Concepts 330     Summary 331     Review Questions 331     Programming Exercises 332 9 Functions 335     Reviewing Functions 335         Creating and Using a Simple Function 337         Analyzing the Program 338         Function Arguments 340         Defining a Function with an Argument: Formal Parameters 342         Prototyping a Function with Arguments 343         Calling a Function with an Argument: Actual Arguments 343         The Black-Box Viewpoint 345         Returning a Value from a Function with return 345         Function Types 348     ANSI C Function Prototyping 349         The Problem 350         The ANSI C Solution 351         No Arguments and Unspecified Arguments 352         Hooray for Prototypes 353     Recursion 353         Recursion Revealed 354         Recursion Fundamentals 355         Tail Recursion 356         Recursion and Reversal 358         Recursion Pros and Cons 360     Compiling Programs with Two or More Source Code Files 361         Unix 362         Linux 362         DOS Command-Line Compilers 362         Windows and Apple IDE Compilers 362         Using Header Files 363     Finding Addresses: The & Operator 367     Altering Variables in the Calling Function 369     Pointers: A First Look 371         The Indirection Operator: * 371         Declaring Pointers 372         Using Pointers to Communicate Between Functions 373     Key Concepts 378     Summary 378     Review Questions 379     Programming Exercises 380 10 Arrays and Pointers 383     Arrays 383         Initialization 384         Designated Initializers (C99) 388         Assigning Array Values 390         Array Bounds 390         Specifying an Array Size 392     Multidimensional Arrays 393         Initializing a Two-Dimensional Array 397         More Dimensions 398     Pointers and Arrays 398     Functions, Arrays, and Pointers 401         Using Pointer Parameters 404         Comment: Pointers and Arrays 407     Pointer Operations 407     Protecting Array Contents 412         Using const with Formal Parameters 413         More About const 415     Pointers and Multidimensional Arrays 417         Pointers to Multidimensional Arrays 420         Pointer Compatibility 421         Functions and Multidimensional Arrays 423     Variable-Length Arrays (VLAs) 427     Compound Literals 431     Key Concepts 434     Summary 435     Review Questions 436     Programming Exercises 439 11 Character Strings and String Functions 441     Representing Strings and String I/O 441         Defining Strings Within a Program 442         Pointers and Strings 451     String Input 453         Creating Space 453         The Unfortunate gets() Function 453         The Alternatives to gets() 455         The scanf() Function 462     String Output 464         The puts() Function 464         The fputs() Function 465         The printf() Function 466     The Do-It-Yourself Option 466     String Functions 469         The strlen() Function 469         The strcat() Function 471         The strncat() Function 473         The strcmp() Function 475         The strcpy() and strncpy() Functions 482         The sprintf() Function 487         Other String Functions 489     A String Example: Sorting Strings 491         Sorting Pointers Instead of Strings 493         The Selection Sort Algorithm 494     The ctype.h Character Functions and Strings 495     Command-Line Arguments 497         Command-Line Arguments in Integrated Environments 500         Command-Line Arguments with the Macintosh 500     String-to-Number Conversions 500     Key Concepts 504     Summary 504     Review Questions 505     Programming Exercises 508 12 Storage Classes, Linkage, and Memory Management 511     Storage Classes 511         Scope 513         Linkage 515         Storage Duration 516         Automatic Variables 518         Register Variables 522         Static Variables with Block Scope 522         Static Variables with External Linkage 524         Static Variables with Internal Linkage 529         Multiple Files 530         Storage-Class Specifier Roundup 530         Storage Classes and Functions 533         Which Storage Class? 534     A Random-Number Function and a Static Variable 534     Roll ’Em 538     Allocated Memory: malloc() and free() 543         The Importance of free() 547         The calloc() Function 548         Dynamic Memory Allocation and Variable-Length Arrays 548         Storage Classes and Dynamic Memory Allocation 549     ANSI C Type Qualifiers 551         The const Type Qualifier 552         The volatile Type Qualifier 554         The restrict Type Qualifier 555         The _Atomic Type Qualifier (C11) 556         New Places for Old Keywords 557     Key Concepts 558     Summary 558     Review Questions 559     Programming Exercises 561 13 File Input/Output 565     Communicating with Files 565         What Is a File? 566         The Text Mode and the Binary Mode 566         Levels of I/O 568         Standard Files 568     Standard I/O 568         Checking for Command-Line Arguments 569         The fopen() Function 570         The getc() and putc() Functions 572         End-of-File 572         The fclose() Function 574         Pointers to the Standard Files 574     A Simple-Minded File-Condensing Program 574     File I/O: fprintf(), fscanf(), fgets(), and fputs() 576         The fprintf() and fscanf() Functions 576         The fgets() and fputs() Functions 578     Adventures in Random Access: fseek() and ftell() 579         How fseek() and ftell() Work 580         Binary Versus Text Mode 582         Portability 582         The fgetpos() and fsetpos() Functions 583     Behind the Scenes with Standard I/O 583     Other Standard I/O Functions 584         The int ungetc(int c, FILE *fp) Function 585         The int fflush() Function 585         The int setvbuf() Function 585         Binary I/O: fread() and fwrite() 586         The size_t fwrite() Function 588         The size_t fread() Function 588         The int feof(FILE *fp) and int ferror(FILE *fp) Functions 589         An fread() and fwrite() Example 589         Random Access with Binary I/O 593     Key Concepts 594     Summary 595     Review Questions 596     Programming Exercises 598 14 Structures and Other Data Forms 601     Sample Problem: Creating an Inventory of Books 601     Setting Up the Structure Declaration 604     Defining a Structure Variable 604         Initializing a Structure 606         Gaining Access to Structure Members 607         Initializers for Structures 607     Arrays of Structures 608         Declaring an Array of Structures 611         Identifying Members of an Array of Structures 612     Program Discussion 612     Nested Structures 613     Pointers to Structures 615         Declaring and Initializing a Structure Pointer 617         Member Access by Pointer 617     Telling Functions About Structures 618         Passing Structure Members 618         Using the Structure Address 619         Passing a Structure as an Argument 621         More on Structure Features 622         Structures or Pointer to Structures? 626         Character Arrays or Character Pointers in a Structure 627         Structure, Pointers, and malloc() 628         Compound Literals and Structures (C99) 631         Flexible Array Members (C99) 633         Anonymous Structures (C11) 636         Functions Using an Array of Structures 637     Saving the Structure Contents in a File 639         A Structure-Saving Example 640         Program Points 643     Structures: What Next? 644     Unions: A Quick Look 645         Using Unions 646         Anonymous Unions (C11) 647     Enumerated Types 649         enum Constants 649         Default Values 650         Assigned Values 650         enum Usage 650         Shared Namespaces 652     typedef: A Quick Look 653     Fancy Declarations 655     Functions and Pointers 657     Key Concepts 665     Summary 665     Review Questions 666     Programming Exercises 669 15 Bit Fiddling 673     Binary Numbers, Bits, and Bytes 674         Binary Integers 674         Signed Integers 675         Binary Floating Point 676     Other Number Bases 676         Octal 677         Hexadecimal 677     C’s Bitwise Operators 678         Bitwise Logical Operators 678         Usage: Masks 680         Usage: Turning Bits On (Setting Bits) 681         Usage: Turning Bits Off (Clearing Bits) 682         Usage: Toggling Bits 683         Usage: Checking the Value of a Bit 683         Bitwise Shift Operators 684         Programming Example 685         Another Example 688     Bit Fields 690         Bit-Field Example 692         Bit Fields and Bitwise Operators 696     Alignment Features (C11) 703     Key Concepts 705     Summary 706     Review Questions 706     Programming Exercises 708 16 The C Preprocessor and the C Library 711     First Steps in Translating a Program 712     Manifest Constants: #define 713         Tokens 717         Redefining Constants 717     Using Arguments with #define 718         Creating Strings from Macro Arguments: The # Operator 721         Preprocessor Glue: The ## Operator 722         Variadic Macros: ... and __VA_ARGS__ 723     Macro or Function? 725     File Inclusion: #include 726         Header Files: An Example 727         Uses for Header Files 729     Other Directives 730         The #undef Directive 731         Being Defined–The C Preprocessor Perspective 731         Conditional Compilation 731         Predefined Macros 737         #line and #error 738         #pragma 739         Generic Selection (C11) 740     Inline Functions (C99) 741     _Noreturn Functions (C11) 744     The C Library 744         Gaining Access to the C Library 745         Using the Library Descriptions 746     The Math Library 747         A Little Trigonometry 748         Type Variants 750         The tgmath.h Library (C99) 752     The General Utilities Library 753         The exit() and atexit() Functions 753         The qsort() Function 755     The Assert Library 760         Using assert 760         _Static_assert (C11) 762     memcpy() and memmove() from the string.h Library 763     Variable Arguments: stdarg.h 765     Key Concepts 768     Summary 768     Review Questions 768     Programming Exercises 770 17 Advanced Data Representation 773     Exploring Data Representation 774     Beyond the Array to the Linked List 777         Using a Linked List 781         Afterthoughts 786     Abstract Data Types (ADTs) 786         Getting Abstract 788         Building an Interface 789         Using the Interface 793         Implementing the Interface 796     Getting Queued with an ADT 804         Defining the Queue Abstract Data Type 804         Defining an Interface 805         Implementing the Interface Data Representation 806     Testing the Queue 815     Simulating with a Queue 818     The Linked List Versus the Array 824     Binary Search Trees 828         A Binary Tree ADT 829         The Binary Search Tree Interface 830         The Binary Tree Implementation 833         Trying the Tree 849         Tree Thoughts 854     Other Directions 856     Key Concepts 856     Summary 857     Review Questions 857     Programming Exercises 858 A Answers to the Review Questions 861 B Reference Section 905 9780321928429, TOC, 11/5/2013   About the Author(s) Stephen Prata , now retired, taught astronomy, physics, and programming at the College of Marin in Kentfield, California. He received his B.S. from the California Institute of Technology and his Ph.D. from the University of California, Berkeley. His association with computers began with the computer modeling of star clusters. Stephen as authored or coauthored over a dozen books, including C++ Primer Plus and Unix Primer Plus. Resources Instructor Resources Instructor Resources C Primer Plus - Example Source Code, 6th Edition Prata ©2014  | On-line Supplement  | ISBN-13:&nbsp9780133887792 |  More info Live Example Source Code (application/zip) (0.1MB) C Primer Plus - Solutions to Programming Exercises, 6th Edition Prata ©2014  | On-line Supplement  | ISBN-13:&nbsp9780133887808 |  More info Live Solutions to Programming Exercises (application/zip) (0.7MB) Ordering Information C Primer Plus, 6th Edition Prata ©2014 | ePub | ISBN-13: 9780133432381 | More info Online purchase price: $47.99 | Students, buy or rent this eText Live C Primer Plus, 6th Edition Prata ©2014 | Paper | ISBN-13: 9780321928429 | More info Suggested retail price: $59.99 | Students, buy this product Available Packages Our most popular packages are listed under Order Options. Pearson offers special pricing when you choose to package your text with other student resources. If you're interested in creating a cost-saving package for your students, browse our available packages below, or contact your Pearson rep to create your own package. Pearson offers special pricing when you choose to package your text with other student resources. If you're interested in creating a cost-saving package for your students contact your Pearson rep. Sign In We're sorry! We don't recognize your username or password. Please try again. Username Password Forgot your username or password? Sign Up Already have an access code? Instructor resource file download The work is protected by local and international copyright laws and is provided solely for the use of instructors in teaching their courses and assessing student learning. Cancel Signed out You have successfully signed out and will be required to sign back in should you need to download more resources. HIGHER EDUCATION Facebook Twitter YouTube Pinterest ABOUT US Efficacy & Educator Studies Success Stories PRODUCTS & SERVICES Course Content & Digital Resources Institutional Services & Solutions DISCIPLINES YOUR ROLE Educators Students Academic Deans College Resellers Administrators Private Sector Education Workforce Directors SUPPORT Download instructor resources For Educators & Institutions For Students CONTACT US Educators, find your rep CAREERS NEWS EVENTS BLOG Copyright © 2016 Pearson Education. All rights reserved. Terms of Use Privacy Policy Permissions Report Piracy Accessibility Other Pearson Sites"	"null"	"null"	"A complete tutorial on programming in C11."	"true"
"Beginner"	"C Programming: A Modern Approach"	"http://knking.com/books/c2/index.html"	"An excellent book to learn the basics from C from."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"C Programming: A Modern Approach - Second Edition     Home Books by K. N. King Short courses Recommended books Recommended links FAQ K. N. King Georgia State University ISBN-10: 0-393-97950-4 ISBN-13: 978-0-393-97950-3 Paper 832 pages April 2008 Where to Get a Copy: The new edition is available at online bookstores worldwide, including the following Amazon sites: Amazon.com (U.S.) Amazon.ca (Canada) Amazon.de (Germany) Amazon.fr (France) Amazon.jp (Japan) Amazon.uk (U.K.) With so many C programming textbooks to choose from, it can be hard to find one that's engaging and readable. The first edition of C Programming: A Modern Approach was a hit with instructors and students alike because of its clarity and comprehensiveness as well as its trademark Q&A sections. The book's spiral approach made the first edition accessible to a broad range of readers, from beginners to more advanced students. The first edition was used at over 225 colleges, making it one of the leading C textbooks of the last ten years. It was also popular among software developers, engineers, and other professionals who use C on the job. Features of the Second Edition Complete coverage of both the C89 standard and the C99 standard, with all C99 changes clearly marked Includes a quick reference to all C89 and C99 library functions Expanded coverage of GCC New coverage of abstract data types Expanded coverage of international features Updated to reflect today's CPUs and operating systems 60% more exercises and programming projects Solutions to one-third of the exercises and programming projects available to all readers at this web site Password-protected instructor resource site containing solutions to the remaining exercises and projects as well as PowerPoint presentations for most chapters Reviews of the Second Edition ""The author of this book has obvious and deep roots in teaching."" Free Software Magazine ""A comprehensive textbook and reference book."" Times Higher Education ""Excellent... Highly recommended."" Choice What Readers Are Saying ""KNK is now the logical heir to K&R ... In short, get this book."" ""By far the most thorough, accurate, and carefully thought out book on C I have ever read, possibly even the best programming book I have read."" ""Your book is wonderful and marvelous."" ""It was the best textbook I have ever read."" ""Thank you for writing a great text. I find it fun, challenging and yet easy to read."" ""I wish all computer text books were this good!"" ""Many of the concepts that I have been struggling to comprehend through other books are all now so crystal-clear to me."" Read more Praise for the First Edition I assign C Programming to first-year engineering students. It is concise, clear, accessible to the beginner, and yet also covers all aspects of the language. Professor Markus Bussmann, Department of Mechanical and Industrial Engineering, University of Toronto Reviews of the first edition Comments by instructors and readers Information about the Book Preface Table of contents About the cover Resources Programs from the book: browse or download zip file Answers to selected exercises and programming projects Feedback from Readers General comments Errata Suggested improvements For the Instructor Examination copies: visit the W. W. Norton website or call (800) 233-4830 Instructor resource site Questions? Please email me. Published by W. W. Norton & Company   Web knking.com Copyright © 1999-2009 K. N. King. All rights reserved."	"null"	"null"	"An excellent book to learn the basics from C from."	"true"
"Beginner"	"Head First C"	"http://shop.oreilly.com/product/0636920015482.do"	"A 'head-first' style book for learning C."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Head First C - O'Reilly Media <img height=""1"" width=""1"" style=""display: none"" src=""https://www.facebook.com/tr?id=1732687426968531&amp;ev=PageView&amp;noscript=1""> Your Account Shopping Cart 0 items $0.00 Your shopping cart is empty. Home Shop Video Training & Books Radar Safari Books Online Conferences Browse Subjects Apple Apple Apple Apps Apple Programming iOS Programming iPad, iPhone, & iPod Mac Apps & Software Apps & Software Apple Apps Design Apps Office & SharePoint Photoshop & Photo Apps Web & Mobile Apps Audio & Video Audio & Video Audio Video Business Business Accounting & Finance Agile & Lean Business Management & Leadership Career Development Entrepreneurship IT Leadership Project Management Sales & Marketing Society & Culture Certification Certification Cisco Certification Linux Certification Microsoft Certification & Training PMP Other Certification Data Data Data Analysis & Visualization Data Topics Non-Relational Databases SAS Oracle Relational Databases SQL Server Data Science Starter Kit The tools you need to get started with data, from basic statistics to complex modeling and large-scale analytics. Data Science for Business Learning Spark Hadoop Fundamentals for Data Scientists and 6 more > Get all 9 titles for a 60% savings. See the Full Kit Design Design Animation Design Apps Digital Publishing Game Design & Development Information Architecture Mobile Design & Development Product Design User Experience Web Design Engineering, Math, & Science Engineering, Math, & Science Bioinformatics Electrical Engineering Hardware Engineering Math Science Health & Wellness Health & Wellness Cancer Disorders & Diseases Health IT Mind & Body IoT (Internet of Things) IoT (Internet of Things) DIY Projects Electronics Hardware Hacking Lego & Robotics Make & Craft Microsoft Microsoft .NET & Windows Programming Microsoft Business Solutions Microsoft Certification & Training Microsoft Servers Microsoft Software Development Microsoft Web Design & Development Office & Sharepoint Windows Windows Administration Windows Phone Windows Phone Programming Mobile & Ereader Devices Mobile & Ereader Devices Android iPad, iPhone, & iPad Kindle Nook Windows Phone Other Devices Networking Networking Cisco Cloud & Network Security Home Networking Network Administration Networking Topics Personal Computing Personal Computing Home Networking Mac PC Windows Personal Growth Personal Growth Business Management & Leadership Career Development Mind & Body Personal Finance Photography Photography Camera Guides Digital Photography Photoshop & Photo Apps Find Inspiration Photographic Visions By 1x.com Programming Programming .NET & Windows Agile Android Apple C/C++ C# Design Patterns Game Design & Development Graphics & Multimedia iOS Java JavaScript Perl Mobile Design & Development PHP Python R Ruby & Rails Secure Software Engineering Testing Windows Phone Other Languages Security & Cryptography Security & Cryptography Cloud & Network Security Computer Security Cryptography Secure Programming System Administration System Administration Cloud Administration Email Administration Linux & Unix Microsoft Servers Performance System Admin & Ops Windows Administration Tech Culture Tech Culture Game Strategy Tech Culture Web Development Web Development HTML & CSS JavaScript Performance PHP Ruby & Rails SEM & SEO Web Content Management Web Design Web Development Learning Paths Video Training New Upcoming Early Release Bestselling Ebooks 1-800-889-8969 / 707-827-7019 / orders@oreilly.com Search Inside and Read Larger Cover Head First C By David Griffiths, Dawn Griffiths Publisher: O'Reilly Media Final Release Date: April 2012 Pages: 632 Ever wished you could learn C from a book? Head First C provides a complete learning experience for C and structured imperative programming. With a unique method that goes beyond syntax and how-to manuals, this guide not only teaches you the language, it helps you understand how to be a great programmer. You'll learn key areas such as language basics, pointers and pointer arithmetic, and dynamic memory management. Advanced topics include multi-threading and network programming—topics typically covered on a college-level course. This book also features labs: in-depth projects intended to stretch your abilities, test your new skills, and build confidence. Head First C mimics the style of college-level C courses, making it ideal as an accessible textbook for students. We think your time is too valuable to waste struggling with new concepts. Using the latest research in cognitive science and learning theory to craft a multi-sensory learning experience, Head First C uses a visually rich format designed for the way your brain works, not a text-heavy approach that puts you to sleep. Chapter 1 Getting Started with C: Diving in C is a language for small, fast programs But what does a complete C program look like? But how do you run the program? Two types of command Here’s the code so far Card counting? In C? There’s more to booleans than equals... What’s the code like now? Pulling the ol’ switcheroo Sometimes once is not enough... Loops often follow the same structure... You use break to break out... Your C Toolbox Chapter 2 Memory and Pointers: What are you pointing at? C code includes pointers Digging into memory Set sail with pointers Set sail sou’east, Cap’n Try passing a pointer to the variable Using memory pointers How do you pass a string to a function? Array variables are like pointers... What the computer thinks when it runs your code But array variables aren’t quite pointers Why arrays really start at 0 Why pointers have types Using pointers for data entry Be careful with scanf() fgets() is an alternative to scanf() Anyone for three-card monte? Oops...there’s a memory problem... String literals can never be updated If you’re going to change a string, make a copy Memory memorizer Your C Toolbox Chapter 2.5 Strings: String theory Desperately seeking Susan Frank Create an array of arrays Find strings containing the search text Using the strstr() function It’s time for a code review Array of arrays vs. array of pointers Your C Toolbox Chapter 3 Creating Small Tools: Do one thing and do it well Small tools can solve big problems Here’s how the program should work But you’re not using files... You can use redirection You can redirect the Standard Input with <... ...and redirect the Standard Output with > But there’s a problem with some of the data... Introducing the Standard Error By default, the Standard Error is sent to the display fprintf() prints to a data stream Let’s update the code to use fprintf() Small tools are flexible Don’t change the geo2json tool A different task needs a different tool Connect your input and output with a pipe The bermuda tool But what if you want to output to more than one file? Roll your own data streams There’s more to main() Overheard at the Head First Pizzeria Let the library do the work for you Your C Toolbox Chapter 4 Using Multiple Source Files: Break it down, build it up Don’t put something big into something small Use casting to put floats into whole numbers Oh no...it’s the out-of-work actors... Let’s see what’s happened to the code Compilers don’t like surprises Split the declaration from the definition Creating your first header file If you have common features... You can split the code into separate files Compilation behind the scenes The shared code needs its own header file It’s not rocket science...or is it? Don’t recompile every file First, compile the source into object files It’s hard to keep track of the files Automate your builds with the make tool How make works Tell make about your code with a makefile Your C Toolbox C Lab 1: Arduino Chapter 5 Structs, Unions, and Bitfields: Roll your own structures Sometimes you need to hand around a lot of data Cubicle conversation Create your own structured data types with a struct Just give them the fish Read a struct’s fields with the “.” operator Can you put one struct inside another? How do you update a struct? The code is cloning the turtle You need a pointer to the struct (*t).age vs. *t.age Sometimes the same type of thing needs different types of data A union lets you reuse memory space How do you use a union? An enum variable stores a symbol Sometimes you want control at the bit level Bitfields store a custom number of bits Your C Toolbox Chapter 6 Data Structures and Dynamic Memory: Building bridges Do you need flexible storage? Linked lists are like chains of data Linked lists allow inserts Create a recursive structure Create islands in C... Inserting values into the list Use the heap for dynamic storage Give the memory back when you’re done Ask for memory with malloc()... Oh, no! It’s the out-of-work actors... Let’s fix the code using the strdup() function Free the memory when you’re done Exhibit A: the source code An overview of the SPIES system Software forensics: using valgrind Use valgrind repeatedly to gather more evidence Look at the evidence The fix on trial Your C Toolbox Chapter 7 Advanced Functions: Turn your functions up to 11 Looking for Mr. Right... Pass code to a function You need to tell find() the name of a function Every function name is a pointer to the function... ...but there’s no function data type How to create function pointers Get it sorted with the C Standard Library Use function pointers to set the order Automating the Dear John letters Create an array of function pointers Make your functions streeeeeetchy Your C Toolbox Chapter 8 Static and Dynamic Libraries: Hot-swappable code Code you can take to the bank Angle brackets are for standard headers But what if you want to share code? Sharing .h header files Share .o object files by using the full pathname An archive contains .o files Create an archive with the ar command... Finally, compile your other programs The Head First Gym is going global Calculating calories But things are a bit more complex... Programs are made out of lots of pieces... Dynamic linking happens at runtime Can you link .a at runtime? First, create an object file What you call your dynamic library depends on your platform Your C Toolbox C Lab 2: OpenCV Chapter 9 Processes and System Calls: Breaking boundaries System calls are your hotline to the OS Then someone busted into the system... Security’s not the only problem The exec() functions give you more control There are many exec() functions The array functions: execv(), execvp(), execve() Passing environment variables Most system calls go wrong in the same way Read the news with RSS exec() is the end of the line for your program Running a child process with fork() + exec() Your C Toolbox Chapter 10 Interprocess Communication: It’s good to talk Redirecting input and output A look inside a typical process Redirection just replaces data streams fileno() tells you the descriptor Sometimes you need to wait... Stay in touch with your child Connect your processes with pipes Case study: opening stories in a browser In the child In the parent Opening a web page in a browser The death of a process Catching signals and running your own code sigactions are registered with sigaction() Rewriting the code to use a signal handler Use kill to send signals Sending your code a wake-up call Your C Toolbox Chapter 11 Sockets and Networking: There’s no place like 127.0.0.1 The Internet knock-knock server Knock-knock server overview BLAB: how servers talk to the Internet A socket’s not your typical data stream Sometimes the server doesn’t start properly Why your mom always told you to check for errors Reading from the client The server can only talk to one person at a time You can fork() a process for each client Writing a web client Clients are in charge Create a socket for an IP address getaddrinfo() gets addresses for domains Your C Toolbox Chapter 12 Threads: It’s a parallel world Tasks are sequential...or not... ...and processes are not always the answer Simple processes do one thing at a time Employ extra staff: use threads How do you create threads? Create threads with pthread_create The code is not thread-safe You need to add traffic signals Use a mutex as a traffic signal Your C Toolbox C Lab 3: Blasteroids Appendix Leftovers: The top ten things (we didn’t cover) #1. Operators #2. Preprocessor directives #3. The static keyword #4. How big stuff is #5. Automated testing #6. More on gcc #7. More on make #8. Development tools #9. Creating GUIs #10. Reference material Appendix C Topics: Revision roundup Basics Pointers and memory Strings Data streams Data types Multiple files Structs Unions and bitfields Data structures Dynamic memory Advanced functions Static and dynamic libraries Processes and communication Sockets and networking Threads Title: Head First C By: David Griffiths, Dawn Griffiths Publisher: O'Reilly Media Formats: Print Ebook Safari Books Online Print: April 2012 Ebook: April 2012 Pages: 632 Print ISBN: 978-1-4493-9991-7 | ISBN 10: 1-4493-9991-6 Ebook ISBN: 978-1-4493-9990-0 | ISBN 10: 1-4493-9990-8 David Griffiths David Griffiths began programming at age 12, after being inspired by a documentary on the work of Seymour Papert. At age 15 he wrote an implementation of Papert's computer language LOGO. After studying Pure Mathematics at University, he began writing code for computers and magazine articles for humans and he is currently an agile coach with Exoftware in the UK, helping people to create simpler, more valuable software. He spends his free time traveling and time with his lovely wife, Dawn. View David Griffiths's full profile page. Dawn Griffiths Dawn Griffiths started life as a mathematician at a top UK university where she was awarded a First-Class Honours degree in Mathematics. She went on to pursue a career in software development, and has over 15 years experience working in the IT industry. Dawn has written several books, including Head First C, Head First Statistics and Head First 2D Geometry. View Dawn Griffiths's full profile page. Table of Contents Product Details About the Author Recommended for You Related Content Customer Reviews REVIEW SNAPSHOT®by PowerReviews oreillyHead First C  3.7 (based on 19 reviews) Ratings Distribution 5 Stars   (8) 4 Stars   (5) 3 Stars   (1) 2 Stars   (2) 1 Stars   (3) 71% of respondents would recommend this to a friend. Ratings Distribution 5 Stars   (8) 4 Stars   (5) 3 Stars   (1) 2 Stars   (2) 1 Stars   (3) Pros Easy to understand (11) Helpful examples (9) Well-written (9) Accurate (5) Concise (5) Cons Not comprehensive enough (8) Best Uses Intermediate (11) Student (7) Novice (6) Reviewer Profile: Developer (8), Educator (5), Student (3) Write a Review Reviewed by 19 customers Sort byNewestOldestHighest ratingLowest ratingMost helpfulLeast helpful Clear all filters Displaying reviews 1-10 Back to top Previous | Next » 12/13/2015 (0 of 1 customers found this review helpful)  3.0 Not for beginner By ponghissimo from Turin, Italy About Me Developer, Educator, Programmer Pros Easy to understand Fun Helpful examples Lot Of Images Cons Difficult to understand Many Things For Granted Not comprehensive enough Not For Beginner Best Uses Intermediate Comments about oreilly Head First C: This book is fun to read, because the topic is so playful, and is full of images. But this is a book for those who already know the material and wants to re-study. It is not a book to start, because the topics are treated briefly, and many things are considered as already known. This book introduces some commands / instructions without explaining, and this causes confusion in the reader. In short, this book is not a step by step approach, but the arguments are exhibited together, and then explained briefly, leaving many things for granted. This book brings together many concepts at once, that a student novice is hard to digest. However, for those who already know a little the topic, this is a good book, and it is also fun. But it is not for start. Bottom Line No, I would not recommend this to a friend (0 of 1 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 10/18/2015 (1 of 1 customers found this review helpful)  5.0 a must have c book By you-know-who from Columbus, OH Pros Accurate Concise Easy to understand Helpful examples Well-written Cons Not comprehensive enough Best Uses Student Comments about oreilly Head First C: I learned a lot of cool stuff from this book like valgrind, makefiles, linker... It's a very nice book to read; not boring. Very attractive. Highly recommended. Bottom Line Yes, I would recommend this to a friend (1 of 1 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 6/20/2015 (1 of 1 customers found this review helpful)  5.0 Must have book for BEGINNERS By Prashant from India About Me Developer, Student Pros Accurate Concise Easy to understand Helpful examples Well-written Cons Best Uses Novice Student Comments about oreilly Head First C: A must have book for beginners.After reading this one can go for ""C programming by Denis"" :) Bottom Line Yes, I would recommend this to a friend (1 of 1 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 8/16/2014 (2 of 2 customers found this review helpful)  4.0 Loved It By yask123 from New Delhi , India About Me Developer, Educator Pros Accurate Concise Easy to understand Helpful examples Well-written Cons Not comprehensive enough Best Uses Intermediate Comments about oreilly Head First C: Somehow I never learnt how to program in C and was using Python , Java extensively but wanted to learn C quickly.This book was interesting and explained some difficult concepts very beautifully! Bottom Line Yes, I would recommend this to a friend (2 of 2 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 8/13/2014 (0 of 4 customers found this review helpful)  2.0 not for beginners By Nox Viator from Abu Dhabi, UAE About Me Student Pros Helpful examples Cons Difficult to understand Best Uses Intermediate Comments about oreilly Head First C: This was my first book about programming but I don't think it's ideal for beginners. The title Head First made me think so unluckily. The book doesn't come cheap though, and it's quite obscure and deal with some concepts superfast. It almost convinced me to give up with the matter. The bright side of its difficulty to understand is that it made me doing many researches and focus a lot so the other books were easier eventually.....books much more better written and found online for free! Bottom Line No, I would not recommend this to a friend Merchant response: Greetings Nox, Thank you for reviewing Head First C . We are sorry that this book was a disappointment, but we appreciate your feedback. We wanted to make sure that you know that we have a 100% satisfaction guarantee. If you would like a refund, you can find the details at http://oreilly.com/go/guarantee Please let us know if we can help with any questions about our products or services. Best Regards, Paul O'Reilly Media Customer Service Team 707.827.7019 800.889.8969 orders@oreilly.com (0 of 4 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 6/25/2014 (1 of 1 customers found this review helpful)  5.0 Just coool! By skywalker from Turkey About Me Researcher Pros Easy to understand Helpful examples Well-written Cons Order Of Contents Best Uses Intermediate Comments about oreilly Head First C: Its desing is perfect. This book is the best for learning C if you have a general programming knowledge. Bottom Line Yes, I would recommend this to a friend (1 of 1 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 1/31/2014 (0 of 3 customers found this review helpful)  1.0 Not Recommended By nooninm from Pittsburgh About Me Developer Pros Easy to understand Cons Not comprehensive enough Best Uses Student Comments about oreilly Head First C: Bad: You should already know some C before reading this book. Also, it is Linux/Unix centric in spite of claiming otherwise. Good: There were many topics that were touched upon, such as pipes, posix, system, and interprocess communication, that lets you know such things exist. Overall: It seems the book was put together just to have a C book to sell. Definitely not up to par with the other Head First books I've read. Bottom Line No, I would not recommend this to a friend (0 of 3 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 9/13/2013 (3 of 3 customers found this review helpful)  5.0 Best C book for anyone By Adib from Tehran, IRAN Comments about oreilly Head First C: I like the way this book organized and specially the interview parts was so funny and helpful for getting the main idea. I think anyone who want to be a good programmer should know C and reading this book is really the best choice for them. Bottom Line Yes, I would recommend this to a friend (3 of 3 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 6/18/2013  5.0 I am very happy with Head First C! By Leam from Radford, VA About Me Developer, Sys Admin, Syseng Pros Easy to understand Helpful examples Well-written Cons Best Uses Intermediate Comments about oreilly Head First C: Shifting from the standard O'Reilly book to the Head First style took some faith. However, I've melted my brain trying to re-learn C. Head First C style really made the job fun and gave me lots of ideas for my own programs. Head First C does not teach programming but it covers a lot of ground so you can be using C in a variety of ways. Bottom Line Yes, I would recommend this to a friend Was this review helpful? Yes / No  - You may also flag this review 4/30/2013  5.0 Cover all C basics! By Uilian from Brazil Comments about oreilly Head First C: Code, Jokes and Photos were a great mix for this book. Was this review helpful? Yes / No  - You may also flag this review Displaying reviews 1-10 Back to top Previous | Next »   Immediate Access - Go Digital what's this? Ebook:  $42.99 Formats:  DAISY, ePub, Mobi, PDF Print & Ebook:  $54.99 This item is not available. Print:  $49.99 The shipment of this item may be delayed. Safari Books Online - Read now > Available in Multiple Languages Deutsch Essential Links Download Example Code Register Your Book View/Submit Errata Media Praise Ask a Question Bulk Discounts & Licensing   Twitter YouTube Slideshare Facebook Google Plus RSS View All RSS Feeds > © 2016, O'Reilly Media, Inc. (707) 827-7019(800) 889-8969 All trademarks and registered trademarks appearing on oreilly.com are the property of their respective owners. About O'Reilly Academic Solutions Jobs Contacts Corporate Information Press Room Privacy Policy Terms of Service Writing for O'Reilly Community Authors Community & Featured Users Forums Membership Newsletters O'Reilly Answers RSS Feeds User Groups O'Reilly Chimera (beta) Partner Sites makezine.com makerfaire.com craftzine.com Ignite Talks O'Reilly Insights on Forbes.com Shop O'Reilly Customer Service Contact Us Shipping Information Ordering & Payment Affiliate Program The O'Reilly Guarantee"	"null"	"null"	"A 'head-first' style book for learning C."	"true"
"Intermediate"	"21st Century C"	"http://shop.oreilly.com/product/0636920033677.do"	"A very good programming book on C."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"21st Century C, 2nd Edition - O'Reilly Media <img height=""1"" width=""1"" style=""display: none"" src=""https://www.facebook.com/tr?id=1732687426968531&amp;ev=PageView&amp;noscript=1""> Your Account Shopping Cart 0 items $0.00 Your shopping cart is empty. Home Shop Video Training & Books Radar Safari Books Online Conferences Browse Subjects Apple Apple Apple Apps Apple Programming iOS Programming iPad, iPhone, & iPod Mac Apps & Software Apps & Software Apple Apps Design Apps Office & SharePoint Photoshop & Photo Apps Web & Mobile Apps Audio & Video Audio & Video Audio Video Business Business Accounting & Finance Agile & Lean Business Management & Leadership Career Development Entrepreneurship IT Leadership Project Management Sales & Marketing Society & Culture Certification Certification Cisco Certification Linux Certification Microsoft Certification & Training PMP Other Certification Data Data Data Analysis & Visualization Data Topics Non-Relational Databases SAS Oracle Relational Databases SQL Server Data Science Starter Kit The tools you need to get started with data, from basic statistics to complex modeling and large-scale analytics. Data Science for Business Learning Spark Hadoop Fundamentals for Data Scientists and 6 more > Get all 9 titles for a 60% savings. See the Full Kit Design Design Animation Design Apps Digital Publishing Game Design & Development Information Architecture Mobile Design & Development Product Design User Experience Web Design Engineering, Math, & Science Engineering, Math, & Science Bioinformatics Electrical Engineering Hardware Engineering Math Science Health & Wellness Health & Wellness Cancer Disorders & Diseases Health IT Mind & Body IoT (Internet of Things) IoT (Internet of Things) DIY Projects Electronics Hardware Hacking Lego & Robotics Make & Craft Microsoft Microsoft .NET & Windows Programming Microsoft Business Solutions Microsoft Certification & Training Microsoft Servers Microsoft Software Development Microsoft Web Design & Development Office & Sharepoint Windows Windows Administration Windows Phone Windows Phone Programming Mobile & Ereader Devices Mobile & Ereader Devices Android iPad, iPhone, & iPad Kindle Nook Windows Phone Other Devices Networking Networking Cisco Cloud & Network Security Home Networking Network Administration Networking Topics Personal Computing Personal Computing Home Networking Mac PC Windows Personal Growth Personal Growth Business Management & Leadership Career Development Mind & Body Personal Finance Photography Photography Camera Guides Digital Photography Photoshop & Photo Apps Find Inspiration Photographic Visions By 1x.com Programming Programming .NET & Windows Agile Android Apple C/C++ C# Design Patterns Game Design & Development Graphics & Multimedia iOS Java JavaScript Perl Mobile Design & Development PHP Python R Ruby & Rails Secure Software Engineering Testing Windows Phone Other Languages Security & Cryptography Security & Cryptography Cloud & Network Security Computer Security Cryptography Secure Programming System Administration System Administration Cloud Administration Email Administration Linux & Unix Microsoft Servers Performance System Admin & Ops Windows Administration Tech Culture Tech Culture Game Strategy Tech Culture Web Development Web Development HTML & CSS JavaScript Performance PHP Ruby & Rails SEM & SEO Web Content Management Web Design Web Development Learning Paths Video Training New Upcoming Early Release Bestselling Ebooks 1-800-889-8969 / 707-827-7019 / orders@oreilly.com Search Inside and Read Larger Cover 21st Century C, 2nd Edition C Tips from the New School By Ben Klemens Publisher: O'Reilly Media Final Release Date: September 2014 Pages: 408 Throw out your old ideas about C and get to know a programming language that’s substantially outgrown its origins. With this revised edition of 21st Century C, you’ll discover up-to-date techniques missing from other C tutorials, whether you’re new to the language or just getting reacquainted. C isn’t just the foundation of modern programming languages; it is a modern language, ideal for writing efficient, state-of-the-art applications. Get past idioms that made sense on mainframes and learn the tools you need to work with this evolved and aggressively simple language. No matter what programming language you currently favor, you’ll quickly see that 21st century C rocks. Set up a C programming environment with shell facilities, makefiles, text editors, debuggers, and memory checkers Use Autotools, C’s de facto cross-platform package manager Learn about the problematic C concepts too useful to discard Solve C’s string-building problems with C-standard functions Use modern syntactic features for functions that take structured inputs Build high-level, object-based libraries and programs Perform advanced math, talk to internet servers, and run databases with existing C libraries This edition also includes new material on concurrent threads, virtual tables, C99 numeric types, and other features. Title: 21st Century C, 2nd Edition By: Ben Klemens Publisher: O'Reilly Media Formats: Print Ebook Safari Books Online Print: October 2014 Ebook: September 2014 Pages: 408 Print ISBN: 978-1-4919-0389-6 | ISBN 10: 1-4919-0389-9 Ebook ISBN: 978-1-4919-0388-9 | ISBN 10: 1-4919-0388-0 Ben Klemens Ben Klemens has been doing statistical analysis and computationally-intensive modeling of populations ever since getting his PhD in Social Sciences from Caltech. He is of the opinion that writing code should be fun, and has had a grand time writing analyses and models (mostly in C) for the Brookings Institution, the World Bank, National Institute of Mental Health, et al. As a Nonresident Fellow at Brookings and with the Free Software Foundation, he has done work on ensuring that creative authors retain the right to use the software they write. He currently works for the United States FederalGovernment. View Ben Klemens's full profile page. Colophon The animal on the cover of 21st Century C is the common spotted cuscus (Spilocuscusmaculatus), a marsupial that lives in the rainforests and mangroves of Australia, NewGuinea, and nearby smaller islands. It has a round head, small hidden ears, thick fur,and a prehensile tail to aid in climbing. The curled tail is a distinctive characteristic;the upper part of the tail closest to the body is covered in fur, while the lower half iscovered in rough scales on the inside surface to grip branches. Its eyes range in colorfrom yellows and oranges to reds, and are slit much like a snake’s. The common spotted cuscus is typically very shy, so it is rarely seen by humans. It isnocturnal, hunting and feeding at night and sleeping during the day on self-madeplatforms in tree branches. It is slow moving and somewhat sluggish—sometimesmistaken for sloths, other possums, or even monkeys. Cuscuses are typically solitary creatures, feeding and nesting alone. Interactions withothers, especially between competing males, can be aggressive and confrontational.Male cuscuses scent-mark their territory to warn off other males, emitting a penetratingmusk odor both from their bodies and scent gland excretions. They distribute salivaon branches and twigs of trees to inform others of their territory and mediatesocial interactions. If they encounter another male in their area, they make barking,snarling, and hissing noises, and stand upright to defend their territory. The common spotted cuscus has an unspecialized dentition, allowing it to eat a widevariety of plant products. It is also known to eat flowers, small animals, and occasionallyeggs. Predators of the common spotted cuscus include pythons and some birds ofprey. Product Details About the Author Colophon Recommended for You Related Content Customer Reviews REVIEW SNAPSHOT®by PowerReviews oreilly21st Century C, 2nd Edition  4.5 (based on 6 reviews) Ratings Distribution 5 Stars   (4) 4 Stars   (1) 3 Stars   (1) 2 Stars   (0) 1 Stars   (0) 83% of respondents would recommend this to a friend. Ratings Distribution 5 Stars   (4) 4 Stars   (1) 3 Stars   (1) 2 Stars   (0) 1 Stars   (0) Pros Concise (6) Easy to understand (5) Helpful examples (5) Accurate (4) Well-written (3) Cons No Cons Best Uses Intermediate (4) Student (3) Reviewer Profile: Developer (6) Write a Review Reviewed by 6 customers Sort byNewestOldestHighest ratingLowest ratingMost helpfulLeast helpful Clear all filters Displaying reviews 1-6 Back to top 5/5/2016  5.0 Practical, well written and easy to follow By lyderic from London, UK About Me Developer, Sys Admin Pros Accurate Concise Easy to understand Helpful examples Well-written Cons Best Uses Expert Intermediate Comments about oreilly 21st Century C, 2nd Edition: This book is a must-have if you want some good knowledge on how C is used today. Bottom Line Yes, I would recommend this to a friend Was this review helpful? Yes / No  - You may also flag this review 4/14/2016  5.0 Fantastic By Gavin Henry from Aberdeen, Scotland About Me Developer Pros Accurate Concise Easy to understand Helpful examples Intermediate Cons Best Uses Intermediate Student Comments about oreilly 21st Century C, 2nd Edition: I've been using this book whilst studying www.cs.manchester.ac.uk/study/professional-development/study-options/distance-learning/foundation/course-modules/programming-in-c/ and all the ""extra"" information not found in ""core books"" is brilliant. The Makefile section, debugging and what things you use in the real world. Money well spent. Bottom Line Yes, I would recommend this to a friend Was this review helpful? Yes / No  - You may also flag this review 12/19/2015 (1 of 1 customers found this review helpful)  5.0 Changed my view on the C language By Tapio T from Espoo, Finland About Me Architect, Developer Pros Concise Easy to understand Fun Helpful examples Well-written Cons Skims Over Many Topics Best Uses Expert Intermediate Comments about oreilly 21st Century C, 2nd Edition: This is a great book on C that changed my view on the language. Let's say that I had missed some of the latest developments in the language and the libraries. The author does a good job in choosing the best parts of C and telling which features are not worth using. As an example, I have thought for a long time that string manipulation in C is just painful, so there is a lot of focus in the book on how to do string processing in a 21st century way. The book is also written in a humorous style and the author is not afraid to express his own opinions. Bottom Line Yes, I would recommend this to a friend (1 of 1 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 11/20/2015 (1 of 2 customers found this review helpful)  3.0 Not a good book for system programmers. By farrokhi from Queens, NY About Me Developer Pros Concise Cons Too basic Best Uses Novice Student Comments about oreilly 21st Century C, 2nd Edition: If you are coming from a php, ruby or python background, this would be a good book to learn and practice C. But if you care about performance, you will find most of the advices in the book disappointing. Bottom Line No, I would not recommend this to a friend (1 of 2 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 7/22/2015 (2 of 2 customers found this review helpful)  4.0 Excellent Book By wmprice1240 from Nashua, NH About Me Developer Pros Accurate Concise Easy to understand Helpful examples Well-written Cons Best Uses Intermediate Student Comments about oreilly 21st Century C, 2nd Edition: It's refreshing to see a new book on the C language that dives right in and gives you great details on modern usage, idioms etc and isn't just the same standard treatment of data types, pointers, flow control etc. The book is well written with a bit of humor here and there. The author seem extremely knowledgeable and comfortable with the subject matter. Only issues I have found is in some of the sample code, actually the compilation. Compiler options for c99 are listed as: CFLAGS = -g -Wall -O3 in the Makefile example. On Mac OS, the c99 -W command line option does not apply to warnings, but the pointer size for compiled code. Simply change the option of use a different compiler, i.e. clang orc clang++ to resolve the issue. All in all a great resource that every C developer should at least read once. Bottom Line Yes, I would recommend this to a friend (2 of 2 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 11/20/2014 (6 of 8 customers found this review helpful)  5.0 Great book By Bob from Chiang Mai Thailand About Me Developer Pros Accurate Concise Easy to understand Helpful examples Cons Best Uses Comments about oreilly 21st Century C, 2nd Edition: I'm working through it rather slowly. But for a C programmer it is a must have. Bottom Line Yes, I would recommend this to a friend (6 of 8 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review Displaying reviews 1-6 Back to top   Immediate Access - Go Digital what's this? Ebook:  $42.99 Formats:  ePub, Mobi, PDF Print & Ebook:  $54.99 Print:  $49.99 Safari Books Online - Read now > Essential Links Register Your Book View/Submit Errata Media Praise Ask a Question Bulk Discounts & Licensing   Twitter YouTube Slideshare Facebook Google Plus RSS View All RSS Feeds > © 2016, O'Reilly Media, Inc. (707) 827-7019(800) 889-8969 All trademarks and registered trademarks appearing on oreilly.com are the property of their respective owners. About O'Reilly Academic Solutions Jobs Contacts Corporate Information Press Room Privacy Policy Terms of Service Writing for O'Reilly Community Authors Community & Featured Users Forums Membership Newsletters O'Reilly Answers RSS Feeds User Groups O'Reilly Chimera (beta) Partner Sites makezine.com makerfaire.com craftzine.com Ignite Talks O'Reilly Insights on Forbes.com Shop O'Reilly Customer Service Contact Us Shipping Information Ordering & Payment Affiliate Program The O'Reilly Guarantee"	"null"	"null"	"A very good programming book on C."	"true"
"Intermediate"	"Understanding and Using C Pointers"	"http://shop.oreilly.com/product/0636920028000.do"	"An in-depth resource on pointers in C."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Understanding and Using C Pointers - O'Reilly Media <img height=""1"" width=""1"" style=""display: none"" src=""https://www.facebook.com/tr?id=1732687426968531&amp;ev=PageView&amp;noscript=1""> Your Account Shopping Cart 0 items $0.00 Your shopping cart is empty. Home Shop Video Training & Books Radar Safari Books Online Conferences Browse Subjects Apple Apple Apple Apps Apple Programming iOS Programming iPad, iPhone, & iPod Mac Apps & Software Apps & Software Apple Apps Design Apps Office & SharePoint Photoshop & Photo Apps Web & Mobile Apps Audio & Video Audio & Video Audio Video Business Business Accounting & Finance Agile & Lean Business Management & Leadership Career Development Entrepreneurship IT Leadership Project Management Sales & Marketing Society & Culture Certification Certification Cisco Certification Linux Certification Microsoft Certification & Training PMP Other Certification Data Data Data Analysis & Visualization Data Topics Non-Relational Databases SAS Oracle Relational Databases SQL Server Data Science Starter Kit The tools you need to get started with data, from basic statistics to complex modeling and large-scale analytics. Data Science for Business Learning Spark Hadoop Fundamentals for Data Scientists and 6 more > Get all 9 titles for a 60% savings. See the Full Kit Design Design Animation Design Apps Digital Publishing Game Design & Development Information Architecture Mobile Design & Development Product Design User Experience Web Design Engineering, Math, & Science Engineering, Math, & Science Bioinformatics Electrical Engineering Hardware Engineering Math Science Health & Wellness Health & Wellness Cancer Disorders & Diseases Health IT Mind & Body IoT (Internet of Things) IoT (Internet of Things) DIY Projects Electronics Hardware Hacking Lego & Robotics Make & Craft Microsoft Microsoft .NET & Windows Programming Microsoft Business Solutions Microsoft Certification & Training Microsoft Servers Microsoft Software Development Microsoft Web Design & Development Office & Sharepoint Windows Windows Administration Windows Phone Windows Phone Programming Mobile & Ereader Devices Mobile & Ereader Devices Android iPad, iPhone, & iPad Kindle Nook Windows Phone Other Devices Networking Networking Cisco Cloud & Network Security Home Networking Network Administration Networking Topics Personal Computing Personal Computing Home Networking Mac PC Windows Personal Growth Personal Growth Business Management & Leadership Career Development Mind & Body Personal Finance Photography Photography Camera Guides Digital Photography Photoshop & Photo Apps Find Inspiration Photographic Visions By 1x.com Programming Programming .NET & Windows Agile Android Apple C/C++ C# Design Patterns Game Design & Development Graphics & Multimedia iOS Java JavaScript Perl Mobile Design & Development PHP Python R Ruby & Rails Secure Software Engineering Testing Windows Phone Other Languages Security & Cryptography Security & Cryptography Cloud & Network Security Computer Security Cryptography Secure Programming System Administration System Administration Cloud Administration Email Administration Linux & Unix Microsoft Servers Performance System Admin & Ops Windows Administration Tech Culture Tech Culture Game Strategy Tech Culture Web Development Web Development HTML & CSS JavaScript Performance PHP Ruby & Rails SEM & SEO Web Content Management Web Design Web Development Learning Paths Video Training New Upcoming Early Release Bestselling Ebooks 1-800-889-8969 / 707-827-7019 / orders@oreilly.com Search Inside and Read Larger Cover Understanding and Using C Pointers Core techniques for memory management By Richard M Reese Publisher: O'Reilly Media Final Release Date: May 2013 Pages: 226 Improve your programming through a solid understanding of C pointers and memory management. With this practical book, you’ll learn how pointers provide the mechanism to dynamically manipulate memory, enhance support for data structures, and enable access to hardware. Author Richard Reese shows you how to use pointers with arrays, strings, structures, and functions, using memory models throughout the book. Difficult to master, pointers provide C with much flexibility and power—yet few resources are dedicated to this data type. This comprehensive book has the information you need, whether you’re a beginner or an experienced C or C++ programmer or developer. Get an introduction to pointers, including the declaration of different pointer types Learn about dynamic memory allocation, de-allocation, and alternative memory management techniques Use techniques for passing or returning data to and from functions Understand the fundamental aspects of arrays as they relate to pointers Explore the basics of strings and how pointers are used to support them Examine why pointers can be the source of security problems, such as buffer overflow Learn several pointer techniques, such as the use of opaque pointers, bounded pointers and, the restrict keyword Chapter 1 Introduction Pointers and Memory Pointer Size and Types Pointer Operators Common Uses of Pointers Summary Chapter 2 Dynamic Memory Management in C Dynamic Memory Allocation Dynamic Memory Allocation Functions Deallocating Memory Using the free Function Dangling Pointers Dynamic Memory Allocation Technologies Summary Chapter 3 Pointers and Functions Program Stack and Heap Passing and Returning by Pointer Function Pointers Summary Chapter 4 Pointers and Arrays Quick Review of Arrays Pointer Notation and Arrays Using malloc to Create a One-Dimensional Array Using the realloc Function to Resize an Array Passing a One-Dimensional Array Using a One-Dimensional Array of Pointers Pointers and Multidimensional Arrays Passing a Multidimensional Array Dynamically Allocating a Two-Dimensional Array Jagged Arrays and Pointers Summary Chapter 5 Pointers and Strings String Fundamentals Standard String Operations Passing Strings Returning Strings Function Pointers and Strings Summary Chapter 6 Pointers and Structures Introduction Structure Deallocation Issues Avoiding malloc/free Overhead Using Pointers to Support Data Structures Chapter 7 Security Issues and the Improper Use of Pointers Pointer Declaration and Initialization Pointer Usage Issues Memory Deallocation Issues Using Static Analysis Tools Summary Chapter 8 Odds and Ends Casting Pointers Aliasing, Strict Aliasing, and the restrict Keyword Threads and Pointers Object-Oriented Techniques Summary Colophon Title: Understanding and Using C Pointers By: Richard M Reese Publisher: O'Reilly Media Formats: Print Ebook Safari Books Online Print: May 2013 Ebook: May 2013 Pages: 226 Print ISBN: 978-1-4493-4418-4 | ISBN 10: 1-4493-4418-6 Ebook ISBN: 978-1-4493-4417-7 | ISBN 10: 1-4493-4417-8 Richard M Reese Richard Reese has worked in the industry and academics for the past 29 years. For 10 years he provided software development support at Lockheed and at one point developed a C based network application. He was a contract instructor providing software training to industry for 5 years. Richard is currently an Associate Professor at Tarleton State University in Stephenville Texas. View Richard M Reese's full profile page. Colophon The animal on the cover of Understanding and Using C Pointers is the piping crow-shrike,or Australian magpie (Cracticus tibicen). Not to be confused with the piping crow found in Indonesia, the Australian magpie is not a crow at all; it is related to butcherbirds and is native to Australia and southern New Guinea. There were once three separate species of Australian magpie, but interbreeding has resulted in the coalescence of their three species into one. Australian magpies have black heads and bodies with varied black and white plumage on their backs, wings, and tails. The Australian magpie is also called the piping crowshrike due to its multi-tonal, complex vocalizations. Like true crows, the Australian magpie is omnivorous, though it prefers to eat insect larvae and other invertebrates. It lives in groups of up to two dozen, and all members generally defend the group territory. During springtime, however, some breeding males will become defensive of their nests and will engage in swooping attacks on passersby, including human and their pets. This magpie is a non-migratory bird and has adapted to human environments, as well as to a mix of forested and open areas. For that reason, it is not endangered, and although it is considered a pest species in neighboring New Zealand, the magpie may be very useful in Australia for keeping the invasive cane toad in check. When introduced to Australia, the cane toad had no natural predators, and its toxic secretions ensured the multiplication of its numbers. However, the highly intelligent magpie has learned to flip over the cane toad, pierce its underbelly, and use its long beak to eat the toad’s organs, thus bypassing the poisonous skin. Researchers are hopeful that the Australian magpiewill become a natural predator of the cane toad and aid in population control. The cover image is from Wood’s Animate Creation. The cover font is Adobe ITC Garamond.The text font is Adobe Minion Pro; the heading font is Adobe Myriad Condensed; and the code font is Dalton Maag’s Ubuntu Mono. Table of Contents Product Details About the Author Colophon Recommended for You Related Content Customer Reviews REVIEW SNAPSHOT®by PowerReviews oreillyUnderstanding and Using C Pointers  4.4 (based on 12 reviews) Ratings Distribution 5 Stars   (7) 4 Stars   (4) 3 Stars   (0) 2 Stars   (1) 1 Stars   (0) 100% of respondents would recommend this to a friend. Ratings Distribution 5 Stars   (7) 4 Stars   (4) 3 Stars   (0) 2 Stars   (1) 1 Stars   (0) Pros Easy to understand (10) Accurate (8) Well-written (7) Helpful examples (6) Concise (4) Cons No Cons Best Uses Intermediate (10) Student (6) Novice (5) Expert (3) Reviewer Profile: Developer (7) Write a Review Reviewed by 12 customers Sort byNewestOldestHighest ratingLowest ratingMost helpfulLeast helpful Clear all filters Displaying reviews 1-10 Back to top Previous | Next » 8/14/2014 (1 of 1 customers found this review helpful)  5.0 Very good book about pointers By Martin from Drummondville, QC Pros Easy to understand Cons Best Uses Intermediate Comments about oreilly Understanding and Using C Pointers: I always liked programming in C. But I always had trouble with pointers. This book helps alot in learning and using them. Bottom Line Yes, I would recommend this to a friend (1 of 1 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 7/27/2014 (0 of 3 customers found this review helpful)  2.0 Good for a beginner to intermediate By Alan Rickman's Answering Machine from Alan Rickman's house, AR About Me Developer Pros Accurate Concise Easy to understand Cons Too basic Best Uses Novice Comments about oreilly Understanding and Using C Pointers: I found the book to be like dry white bread; filling, palatable, and underwhelming. Everything is very clear and well laid out, but it never goes to the depth that would have made this topic interesting. Many times a subject or solution that could be interesting (e.g. implementing RAII in C without using the GNU extension) is simply stated to be possible without any further information. There are hyperlinks links scattered throughout the text, pointing to sites where further information can be found. This wouldn't be a problem if some of them weren't to the moving target that is Wikipedia. Indeed since the book's publication at least one of these has changed and the section originally linked to is no longer present. Basically the book reads like a set of source examples that are very well documented. I could see it being helpful to someone who's been hacking around in C/C++ for a few months and is ready to integrate their experience with pointers/the C memory model and really learn the fundamentals, but for anyone more experienced this won't offer much new. 3 stars for a solid (if dry) book laying out the basics of pointers and memory management in C, minus one for having broken links to Wikipedia (0 of 3 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 6/12/2014 (1 of 1 customers found this review helpful)  5.0 Excellent material on C pointers By HF.. from Melbourne , AU About Me Developer Pros Accurate Easy to understand Well-written Cons Best Uses Intermediate Novice Student Comments about oreilly Understanding and Using C Pointers: I personally like this ebook. It's hard to find a C book that will focus mainly on Pointers, luckily I found this one. Thank you O'Reilly and special thanks to the author Richard Reese for his great efforts in writing this material. Bottom Line Yes, I would recommend this to a friend (1 of 1 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 11/1/2013 (5 of 5 customers found this review helpful)  4.0 Good Book on Pointers By Andy from Germany About Me Developer Pros Cons Best Uses Expert Intermediate Comments about oreilly Understanding and Using C Pointers: There have been many books written about the C Programming language. But this one is different. Why? Because this book focuses on pointers to convey a deeper understanding on C. It covers important memory management technology involving the stack and the heap along with the use of pointers in this context. It helps you to understand pointers and shows you how they work and how they should be managed. Reese assumes that the reader has a minimal understanding of C. The audience are developers that are learning C or experienced C or C++ programmers. For C# or Java developers this book should help to better understand C and get an insight into how object-oriented languages deal with the stack and the heap. IMHO the reader need a bit more than a minimal understanding of C. The book shows only code snippets (which will make it more difficult for novice programmers). So the reader need to know how to write a complete program in C and how to compile it. Further the reader need some understanding of common data structures like linked lists. If you are a C# or Java developer and don't have any C background this book won't be of much use for you. The Book uses a lot of references to later chapters (forward references), which makes it sometimes difficult to read. What I really liked on this book is the representation of the memory (as small boxes) along with the source code. It visually shows the reader what is happening in memory. This book really helped me to get a better understanding of Pointers and memory management. Bottom Line Yes, I would recommend this to a friend (5 of 5 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 6/30/2013 (2 of 2 customers found this review helpful)  4.0 A book for a novice and a master By Joaquin from La Plata, Argentina About Me Curious, Developer, Educator Pros Easy to understand Helpful examples Well-written Cons Best Uses Expert Intermediate Novice Student Comments about oreilly Understanding and Using C Pointers: The book give a list of very usefull examples. I use them in class and clarify a wide variety of common mistakes. Bottom Line Yes, I would recommend this to a friend (2 of 2 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 6/30/2013 (2 of 2 customers found this review helpful)  5.0 Very good books on Pointers By lakpa from London About Me Developer Pros Accurate Concise Easy to understand Helpful examples Well-written Cons Best Uses Intermediate Comments about oreilly Understanding and Using C Pointers: The book covers the every aspect of using pointer. The book can be a good reference for every C programmer as perfection in pointer what makes you an efficient programmer. Bottom Line Yes, I would recommend this to a friend (2 of 2 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 6/30/2013 (4 of 4 customers found this review helpful)  5.0 It is what it says to be By Riesje007 from Amsterdam, The Netherlands About Me Developer, Maker, Sys Admin Pros Accurate Concise Easy to understand Well-written Cons Only Small Code Snippets Best Uses Intermediate Student Comments about oreilly Understanding and Using C Pointers: The explanation of the subject of pointers is very clear and very helpful in further understanding the subject. The examples are very clear and the short code snippets supplied were useful. For less experienced users it may be a better idea to supply complete working programs as examples, but for me this was just fine. One thing however you must know if you use Microsoft Visual Studio compiler: define your variables in the first lines of every function and below them add the code, otherwise it doesn't compile and the error messages of the compiler aren't clear about this sequence. Bottom Line Yes, I would recommend this to a friend (4 of 4 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 6/30/2013 (1 of 1 customers found this review helpful)  4.0 Unleash the power of C! By Alessandro Costantini from Venezia, Italia Pros Accurate Easy to understand Helpful examples Well-written Cons Best Uses Intermediate Student Comments about oreilly Understanding and Using C Pointers: This extremely useful book is the one that will let you understand pointers and their usage. Many books fail on pointers, many books don't stress enough the role pointers have in C. This succeds. Not for absolute beginners, a must if you actually want to use C for real world applications. Bottom Line Yes, I would recommend this to a friend (1 of 1 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 6/23/2013 (4 of 4 customers found this review helpful)  4.0 Pointers straight to the point By mko from Poland Pros Accurate Easy to understand Helpful examples Cons Not comprehensive enough Best Uses Intermediate Novice Comments about oreilly Understanding and Using C Pointers: Pointers are the nemesis of most of newcomers to C. There are few issues related to this topic. Pointers arithmetics is confusing, people get confused when it comes to characters and strings, array based arithmetics using pointers will not make any beginner happy. And, after all of that, comes pointers to functions and issues related to security (e.g. stack overflow). So far, I haven't found book so much focused on the topics as Understanding and Using C Pointers is. Typically, C related books try to cover all the aspects of the language, here on the contrary, we have different approach. What you get here are pointer related topics only. This means that you should be already familiar with C (at least in the way you are able to compile and run C based code). Various topics discussed in the book cover almost all of the aspects of the pointers. You will learn how pointers arithmetics work, how to allocate memory, how to deal with multidimensional arrays using pointers and dynamic allocation. Apart from typical usage of pointers you will also lear how to use them in context of functions (function pointers). I have found this book very useful, however, I think it might be still an issue to follow all the odds and ends by C newcomers. Some topics (e.g. arrays of function pointers) are explained such way it might be confusing. The problem here is that reader must understand and follow three different aspects of the problem at the same time: function pointer, array, character as indexes of arrays and, most confusing, why the hell do we declare 128 elements array if we only use two of them. I perfectly understand author's point of view, however, it is still confusing. Another issue is that illustrations in the book sometimes miss the proper description and explanation (in my opinion Kochan's C language book makes better use of them). Anyway, I still think that buying this book is an idea worth considering. If you know C, but would like to get familiar with odds and ends of pointers you should consider buying this one. (4 of 4 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 6/22/2013 (2 of 2 customers found this review helpful)  5.0 A good read for a serious C programmer. By Satyajit from Pune, India Comments about oreilly Understanding and Using C Pointers: The book is well written, short that you can complete it quickly. As the author rightly points out in the preface many C books offer a broad coverage of the language and they seem to address only the tip of the iceberg named pointers. They often give you just a brief chapter on Pointers. But the fact is, in C, pointers are the most important concept. If you get that right you will start writing efficient C programs. The book starts with the basics of pointers to those who are not familiar with them. It moves on to explain dynamic memory management in C, using function pointers, pointer arithmetic and arrays, how to use structures and pointers. The good part of the book is at almost the end where the Author talks about common security issues and the improper uses of pointers. He talks a length about dangling pointers, accessing memory outside the bounds of an array. One might ask is it necessary to have a book on Pointers? I would say a definite yes. Memory management is a must if you want to go past the examples given in most C text books. I do not see any other book just dealing with pointers. So if you want to improve your C skills this book is a good read. Bottom Line Yes, I would recommend this to a friend (2 of 2 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review Displaying reviews 1-10 Back to top Previous | Next »   Immediate Access - Go Digital what's this? Ebook:  $33.99 Formats:  DAISY, ePub, Mobi, PDF Print & Ebook:  $43.99 Print:  $39.99 Safari Books Online - Read now > Essential Links Register Your Book View/Submit Errata Media Praise Ask a Question Bulk Discounts & Licensing   Twitter YouTube Slideshare Facebook Google Plus RSS View All RSS Feeds > © 2016, O'Reilly Media, Inc. (707) 827-7019(800) 889-8969 All trademarks and registered trademarks appearing on oreilly.com are the property of their respective owners. About O'Reilly Academic Solutions Jobs Contacts Corporate Information Press Room Privacy Policy Terms of Service Writing for O'Reilly Community Authors Community & Featured Users Forums Membership Newsletters O'Reilly Answers RSS Feeds User Groups O'Reilly Chimera (beta) Partner Sites makezine.com makerfaire.com craftzine.com Ignite Talks O'Reilly Insights on Forbes.com Shop O'Reilly Customer Service Contact Us Shipping Information Ordering & Payment Affiliate Program The O'Reilly Guarantee"	"null"	"null"	"An in-depth resource on pointers in C."	"true"
"Intermediate"	"ZeroMQ"	"http://shop.oreilly.com/product/0636920026136.do"	"A book for using ZeroMQ with C."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"ZeroMQ - O'Reilly Media <img height=""1"" width=""1"" style=""display: none"" src=""https://www.facebook.com/tr?id=1732687426968531&amp;ev=PageView&amp;noscript=1""> Your Account Shopping Cart 0 items $0.00 Your shopping cart is empty. Home Shop Video Training & Books Radar Safari Books Online Conferences Browse Subjects Apple Apple Apple Apps Apple Programming iOS Programming iPad, iPhone, & iPod Mac Apps & Software Apps & Software Apple Apps Design Apps Office & SharePoint Photoshop & Photo Apps Web & Mobile Apps Audio & Video Audio & Video Audio Video Business Business Accounting & Finance Agile & Lean Business Management & Leadership Career Development Entrepreneurship IT Leadership Project Management Sales & Marketing Society & Culture Certification Certification Cisco Certification Linux Certification Microsoft Certification & Training PMP Other Certification Data Data Data Analysis & Visualization Data Topics Non-Relational Databases SAS Oracle Relational Databases SQL Server Data Science Starter Kit The tools you need to get started with data, from basic statistics to complex modeling and large-scale analytics. Data Science for Business Learning Spark Hadoop Fundamentals for Data Scientists and 6 more > Get all 9 titles for a 60% savings. See the Full Kit Design Design Animation Design Apps Digital Publishing Game Design & Development Information Architecture Mobile Design & Development Product Design User Experience Web Design Engineering, Math, & Science Engineering, Math, & Science Bioinformatics Electrical Engineering Hardware Engineering Math Science Health & Wellness Health & Wellness Cancer Disorders & Diseases Health IT Mind & Body IoT (Internet of Things) IoT (Internet of Things) DIY Projects Electronics Hardware Hacking Lego & Robotics Make & Craft Microsoft Microsoft .NET & Windows Programming Microsoft Business Solutions Microsoft Certification & Training Microsoft Servers Microsoft Software Development Microsoft Web Design & Development Office & Sharepoint Windows Windows Administration Windows Phone Windows Phone Programming Mobile & Ereader Devices Mobile & Ereader Devices Android iPad, iPhone, & iPad Kindle Nook Windows Phone Other Devices Networking Networking Cisco Cloud & Network Security Home Networking Network Administration Networking Topics Personal Computing Personal Computing Home Networking Mac PC Windows Personal Growth Personal Growth Business Management & Leadership Career Development Mind & Body Personal Finance Photography Photography Camera Guides Digital Photography Photoshop & Photo Apps Find Inspiration Photographic Visions By 1x.com Programming Programming .NET & Windows Agile Android Apple C/C++ C# Design Patterns Game Design & Development Graphics & Multimedia iOS Java JavaScript Perl Mobile Design & Development PHP Python R Ruby & Rails Secure Software Engineering Testing Windows Phone Other Languages Security & Cryptography Security & Cryptography Cloud & Network Security Computer Security Cryptography Secure Programming System Administration System Administration Cloud Administration Email Administration Linux & Unix Microsoft Servers Performance System Admin & Ops Windows Administration Tech Culture Tech Culture Game Strategy Tech Culture Web Development Web Development HTML & CSS JavaScript Performance PHP Ruby & Rails SEM & SEO Web Content Management Web Design Web Development Learning Paths Video Training New Upcoming Early Release Bestselling Ebooks 1-800-889-8969 / 707-827-7019 / orders@oreilly.com Search Inside and Read Larger Cover ZeroMQ Messaging for Many Applications By Pieter Hintjens Publisher: O'Reilly Media Final Release Date: March 2013 Pages: 516 Dive into ØMQ (aka ZeroMQ), the smart socket library that gives you fast, easy, message-based concurrency for your applications. With this quick-paced guide, you’ll learn hands-on how to use this scalable, lightweight, and highly flexible networking tool for exchanging messages among clusters, the cloud, and other multi-system environments. ØMQ maintainer Pieter Hintjens takes you on a tour of real-world applications, using extended examples in C to help you work with ØMQ’s API, sockets, and patterns. Learn how to use specific ØMQ programming techniques, build multithreaded applications, and create your own messaging architectures. You’ll discover how ØMQ works with several programming languages and most operating systems—with little or no cost. Learn ØMQ’s main patterns: request-reply, publish-subscribe, and pipeline Work with ØMQ sockets and patterns by building several small applications Explore advanced uses of ØMQ’s request-reply pattern through working examples Build reliable request-reply patterns that keep working when code or hardware fails Extend ØMQ’s core pub-sub patterns for performance, reliability, state distribution, and monitoring Learn techniques for building a distributed architecture with ØMQ Discover what’s required to build a general-purpose framework for distributed applications Learning to Work with ØMQ Chapter 1 Basics Fixing the World Audience for This Book Getting the Examples Ask and Ye Shall Receive A Minor Note on Strings Version Reporting Getting the Message Out Divide and Conquer Programming with ØMQ Why We Needed ØMQ Socket Scalability Upgrading from ØMQ v2.2 to ØMQ v3.2 Warning: Unstable Paradigms! Chapter 2 Sockets and Patterns The Socket API Messaging Patterns Handling Errors and ETERM Handling Interrupt Signals Detecting Memory Leaks Multithreading with ØMQ Signaling Between Threads (PAIR Sockets) Node Coordination Zero-Copy Pub-Sub Message Envelopes High-Water Marks Missing Message Problem Solver Chapter 3 Advanced Request-Reply Patterns The Request-Reply Mechanisms Request-Reply Combinations Exploring ROUTER Sockets The Load-Balancing Pattern A High-Level API for ØMQ The Asynchronous Client/Server Pattern Worked Example: Inter-Broker Routing Chapter 4 Reliable Request-Reply Patterns What Is “Reliability”? Designing Reliability Client-Side Reliability (Lazy Pirate Pattern) Basic Reliable Queuing (Simple Pirate Pattern) Robust Reliable Queuing (Paranoid Pirate Pattern) Heartbeating Contracts and Protocols Service-Oriented Reliable Queuing (Majordomo Pattern) Asynchronous Majordomo Pattern Service Discovery Idempotent Services Disconnected Reliability (Titanic Pattern) High-Availability Pair (Binary Star Pattern) Brokerless Reliability (Freelance Pattern) Conclusion Chapter 5 Advanced Publish-Subscribe Patterns Pros and Cons of Publish-Subscribe Pub-Sub Tracing (Espresso Pattern) Last Value Caching Slow Subscriber Detection (Suicidal Snail Pattern) High-Speed Subscribers (Black Box Pattern) Reliable Publish-Subscribe (Clone Pattern) Software Engineering Using ØMQ Chapter 6 The ØMQ Community Architecture of the ØMQ Community How to Make Really Large Architectures The ØMQ Process: C4 A Real-Life Example Git Branches Considered Harmful Designing for Innovation Burnout Patterns for Success Chapter 7 Advanced Architecture Using ØMQ Message-Oriented Pattern for Elastic Design Unprotocols Serializing Your Data Transferring Files State Machines Authentication Using SASL Large-Scale File Publishing: FileMQ Getting an Official Port Number Chapter 8 A Framework for Distributed Computing Design for the Real World The Secret Life of WiFi Discovery Spinning Off a Library Project Point-to-Point Messaging Group Messaging Testing and Simulation Distributed Logging and Monitoring Content Distribution Writing the Unprotocol Conclusions Chapter 9 Postface Tales from Out There How This Book Happened Removing Friction Licensing Colophon Title: ZeroMQ By: Pieter Hintjens Publisher: O'Reilly Media Formats: Print Ebook Safari Books Online Print: March 2013 Ebook: March 2013 Pages: 516 Print ISBN: 978-1-4493-3406-2 | ISBN 10: 1-4493-3406-7 Ebook ISBN: 978-1-4493-3404-8 | ISBN 10: 1-4493-3404-0 Pieter Hintjens Pieter Hintjens started his first business making video games 30 yearsago and has been building software products since then. Taking as hisprinciple, ""the real physics of software is the physics of people"", hefocuses now on building communities through ""Social Architecture"",writing, and helping others use ZeroMQ profitably. For two years he was president of the FFII, a large NGO fightingsoftware patents. He was CEO of Wikidot, founder of the EuropeanPatent Conference, and founder of the Digital Standards Organization. Pieter speaks English, French, Dutch, and bits and pieces of a dozenother languages. He plays with a West African drum group in Brusselsand is becoming a licensed NRA pistol instructor in Texas. Pieterlives with his beautiful wife and three lovely children in Brussels,Belgium and travels extensively. View Pieter Hintjens's full profile page. Colophon The animal on the cover of ZeroMQ is the fourhorn sculpin (Myoxocephalus quadricornis).The fourhorn sculpin is mostly found in arctic coastal waters around NorthAmerica and northern Eurasia, but it can also be found in some freshwater lakes inEurope. This fish is named for its four bony protuberances on its head.The fourhorn sculpin has a dark and slightly flattened body with eyes close to the topof its heads, a large pelvis, and a distinctive large mouth. It usually reaches about 30 cmin length. One way to distinguish between males and females of this species is that maleshave a yellowish brown belly and females have a white belly. This fish mostly feeds onorganisms at the bottom of the sea, crustaceans, and fish eggs.The fourhorn sculpin reproduces in the winter. During this time males will typically diga pit that females will put all their eggs into. Once eggs are laid into a pit, males willguard the eggs during the three month incubation period.The cover image is from Johnson’s Natural History. The cover font is Adobe ITC Garamond.The text font is Adobe Minion Pro; the heading font is Adobe Myriad Condensed;and the code font is Dalton Maag’s Ubuntu Mono. Table of Contents Product Details About the Author Colophon Recommended for You Customer Reviews REVIEW SNAPSHOT®by PowerReviews oreillyZeroMQ  5.0 (based on 6 reviews) Ratings Distribution 5 Stars   (6) 4 Stars   (0) 3 Stars   (0) 2 Stars   (0) 1 Stars   (0) 100% of respondents would recommend this to a friend. Ratings Distribution 5 Stars   (6) 4 Stars   (0) 3 Stars   (0) 2 Stars   (0) 1 Stars   (0) Pros Accurate (5) Well-written (5) Helpful examples (4) Easy to understand (3) Cons No Cons Best Uses Intermediate (5) Reviewer Profile: Developer (5) Write a Review Reviewed by 6 customers Sort byNewestOldestHighest ratingLowest ratingMost helpfulLeast helpful Clear all filters Displaying reviews 1-6 Back to top 3/5/2015  5.0 good book By Shrek from San Francisco, CA About Me Developer Pros Accurate Well-written Cons Best Uses Intermediate Comments about oreilly ZeroMQ: I am trying to integrate a legacy system, and i tried ActiveMQ+Camel, but it just add to many dependencies for the legacy system. then turned to ZeroMQ. it's very simple, and out of box working! This book is a good book to teach how to use ZeroMQ. and talks a lot about general message patterns. good for people looking for distributed, scalable system design ideas. only thing i am not quite comfortable is that the examples are in c. Bottom Line Yes, I would recommend this to a friend Was this review helpful? Yes / No  - You may also flag this review 4/17/2014 (1 of 3 customers found this review helpful)  5.0 Exceptional book a must read By Nils from Stockholm Sweden Comments about oreilly ZeroMQ: Excellent description Of zero MQ but the real value is the description Of how to Build a community Bottom Line Yes, I would recommend this to a friend (1 of 3 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 8/21/2013 (7 of 7 customers found this review helpful)  5.0 Distributed Systems and Communities By Alejandro Cabrera from Duluth, GA, USA About Me Developer Pros Accurate Helpful examples Well-written Cons Best Uses Expert Intermediate Student Comments about oreilly ZeroMQ: I was pleasantly surprised by this book. I came in expecting to learn about the magic of ZeroMQ, and I came out knowing not only more about ZeroMQ itself, but also distributed systems and community building. The first chapter primes the rest of the text, preparing the reader to not only learn more about the world of distributed computing, but also begins instilling a certain excitement about how things could be so much easier, and how ZeroMQ enables this. This is surprising, as very few technical texts manage to become page-turners so quickly. The next four chapters are a deep dive into ZeroMQ (and distributed systems) best practices. Heartbeats, publish/subscribe, request/reply, round-robin task distribution, and then composing all of these patterns and more. It's a collection of best practices without seeming like a dictionary. I could spend a few months practicing and studying these best practices and I'd feel like I knew more about how to build reliable systems. The last half of the book is all about how to build communities and processes that last. Building distributed systems requires effective communication. There's a wealth of knowledge in the last portion of the book about how to enable that. Some great advice includes: - separate maintainers from contributors - use Github (which can be interpreted as: make issue tracking, persistent comments, and code review *really* easy) A good chunk of the community building device is available as the ZMQ C4 guide. It's elaborated on much more deeply in this book, which I appreciate. C4 is the contract; this book is the rationale. If you're interested or need to build a system that's highly concurrent, has high reliability and/or performance requirements, and even if you can't use ZMQ to build said system, get this book anyway. You'll learn a lot in the process that you can apply to making network (and team) communication much more effective. Bottom Line Yes, I would recommend this to a friend (7 of 7 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 5/23/2013 (6 of 6 customers found this review helpful)  5.0 ""ZeroMQ"" by Pieter Hintjens; O'Reilly Me By Munish K Gupta from Bangalore, India About Me Developer Pros Accurate Easy to understand Helpful examples Well-written Cons Best Uses Expert Intermediate Comments about oreilly ZeroMQ: Pieter Hintjens, one of pioneers of the distributed computing and author of ZeroMQ library explains the basic premise behind ZeroMQ design and community. He covers fundamentals of designing large distributed applications using ZeroMQ library. First and foremost, the book is meant for intermediate to advanced programmers. You need to be aware of the networking concepts. All examples are in C, so you should have good enough grounding in the language. Once you are past these, understanding the concepts in the book is fairly easy. First part of the book is about Learning to work with ZeroMQ. This section covers all the patterns – Request-Reply, Dealer-Router, Pub-Sub, Proxy, Load Balancing and their combination and usage with each other. The example scenarios detail the scenario's where these patterns fit in. This section also covers how to build reliability and availability as part of the distributed application. Second part of the book is about Software Engineering with ZeroMQ. This section covers the basic philosophy behind the ZeroMQ community, advanced architecture using ZeroMQ. The advanced architecture covers things like Contract definition, Protocols, Security, State machines and Data serialization. The author takes a sample application FileMQ – ability to exchange files between two devices la Dropbox and works through the design of the API and Protocol. We also see how to simulate real life scenario's to test the application. Overall, ZeroMQ is a must have book on your shelf if you are building or ready to build distributed applications. (6 of 6 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 5/13/2013 (4 of 4 customers found this review helpful)  5.0 Comprehensive guide to ZeroMQ By Przemysław from Kraków About Me Developer Pros Accurate Concise Easy to understand Helpful examples Well-written Cons Best Uses Intermediate Novice Student Comments about oreilly ZeroMQ: Book has two parts: ""Learning to work with ØMQ"" & ""Software Engineering Using ØMQ"". In first part author presents basics, socket and a lot of different different patterns. Examples are quite easy to grasp, many of them are continuations of others or they are different approach solving particular problem. Second part covers more advanced stuff (advanced architecture, framework for distributed computing). I really like chapter devoted to ZeroMQ community — it contains tips how to handle open source project, choose good license, make life easier for contributors, etc. Book contains a lot of code written in C, but feel free to check this repository: https://github.com/imatix/zguide. There are examples written in many different languages. I really like author's sense of humour, grasping different concepts is much more pleasant if written in funny, entertaining way. Bottom Line Yes, I would recommend this to a friend (4 of 4 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review 4/4/2013 (3 of 3 customers found this review helpful)  5.0 Hard to imagine a better intro to 0MQ By N.O. from Germany About Me Designer, Developer Pros Accurate Easy to understand Helpful examples Well-written Cons Best Uses Intermediate Novice Comments about oreilly ZeroMQ: If you need to handle any kind message passing or deal with raw TCP sockets, ZeroMQ should be given a serious consideration, and this book is a great place to start. It takes you from the basic concepts over a number of common usage patterns to some fairly advanced applications. Very informative, easy to understand, and, as a special bonus, highly entertaining. Bottom Line Yes, I would recommend this to a friend (3 of 3 customers found this review helpful) Was this review helpful? Yes / No  - You may also flag this review Displaying reviews 1-6 Back to top   Immediate Access - Go Digital what's this? Ebook:  $45.99 Formats:  DAISY, ePub, Mobi, PDF Print & Ebook:  $54.99 Print:  $49.99 Safari Books Online - Read now > Essential Links Register Your Book View/Submit Errata Media Praise Ask a Question Bulk Discounts & Licensing   Twitter YouTube Slideshare Facebook Google Plus RSS View All RSS Feeds > © 2016, O'Reilly Media, Inc. (707) 827-7019(800) 889-8969 All trademarks and registered trademarks appearing on oreilly.com are the property of their respective owners. About O'Reilly Academic Solutions Jobs Contacts Corporate Information Press Room Privacy Policy Terms of Service Writing for O'Reilly Community Authors Community & Featured Users Forums Membership Newsletters O'Reilly Answers RSS Feeds User Groups O'Reilly Chimera (beta) Partner Sites makezine.com makerfaire.com craftzine.com Ignite Talks O'Reilly Insights on Forbes.com Shop O'Reilly Customer Service Contact Us Shipping Information Ordering & Payment Affiliate Program The O'Reilly Guarantee"	"null"	"null"	"A book for using ZeroMQ with C."	"true"
"Advanced"	"Expert C Programming: Deep C Secrets"	"http://dl.acm.org/citation.cfm?id=179241"	"An interesting, in-depth and look at the innards of C."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Expert C programming SIGN IN   SIGN UP   Expert C programming: deep C secrets Author: Peter van der Linden Publication:   · Book Expert C programming: deep C secrets Prentice-Hall, Inc. Upper Saddle River, NJ, USA ©1994 ISBN:0-13-177429-8 1994 Book   Bibliometrics · Downloads (6 Weeks): 0 · Downloads (12 Months): 0 · Downloads (cumulative): 0 · Citation Count: 3 Tools and Resources Save to Binder Export Formats: BibTeX EndNote ACM Ref Read this e-Book at: Online Book Share: | Author Tags design language types languages software development techniques Contact Us | Switch to single page view (no tabs) **Javascript is not enabled and is required for the ""tabbed view"" or switch to the single page view** Advertisements Powered by The ACM Digital Library is published by the Association for Computing Machinery. Copyright © 2016 ACM, Inc. Terms of Usage   Privacy Policy   Code of Ethics   Contact Us Useful downloads: Adobe Reader    QuickTime    Windows Media Player    Real Player Did you know the ACM DL App is now available? Did you know your Organization can subscribe to the ACM Digital Library? The ACM Guide to Computing Literature All Tags Export Formats     Save to Binder"	"null"	"null"	"An interesting, in-depth and look at the innards of C."	"true"
"Multimedia"	"FFMPEG"	"https://www.ffmpeg.org/"	"A complete, cross-platform solution to record, convert and stream audio and video. or later, with some parts under or later."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"null"	"null"	"null"	"FFmpeg FFmpeg About News Download Documentation Community Mailing Lists IRC Forums Bug Reports Wiki Developers Source Code Contribute FATE Code Coverage More Donate Hire Developers Contact Security Legal FFmpeg A complete, cross-platform solution to record, convert and stream audio and video. Download Converting video and audio has never been so easy. $ ffmpeg -i input.mp4 output.avi Discover more       News July 10th, 2016, ffserver program being dropped After thorough deliberation, we're announcing that we're about to drop the ffserver program from the project starting with the next release. ffserver has been a problematic program to maintain due to its use of internal APIs, which complicated the recent cleanups to the libavformat library, and block further cleanups and improvements which are desired by API users and will be easier to maintain. Furthermore the program has been hard for users to deploy and run due to reliability issues, lack of knowledgable people to help and confusing configuration file syntax. Current users and members of the community are invited to write a replacement program to fill the same niche that ffserver did using the new APIs and to contact us so we may point users to test and contribute to its development. July 1st, 2016, FFmpeg 3.1.1 ""Laplace"" FFmpeg 3.1.1, a new point release from the 3.1 release branch, is now available! It mainly deals with a few ABI issues introduced in the previous release. We strongly recommend users, distributors, and system integrators, especially those who experienced issues upgrading from 3.0, to upgrade unless they use current git master. June 27th, 2016, FFmpeg 3.1 ""Laplace"" FFmpeg 3.1 ""Laplace"", a new major release, is now available! Some of the highlights: DXVA2-accelerated HEVC Main10 decoding fieldhint filter loop video filter and aloop audio filter Bob Weaver deinterlacing filter firequalizer filter datascope filter bench and abench filters ciescope filter protocol blacklisting API MediaCodec H264 decoding VC-2 HQ RTP payload format (draft v1) depacketizer and packetizer VP9 RTP payload format (draft v2) packetizer AudioToolbox audio decoders AudioToolbox audio encoders coreimage filter (GPU based image filtering on OSX) libdcadec removed bitstream filter for extracting DTS core ADPCM IMA DAT4 decoder musx demuxer aix demuxer remap filter hash and framehash muxers colorspace filter hdcd filter readvitc filter VAAPI-accelerated format conversion and scaling libnpp/CUDA-accelerated format conversion and scaling Duck TrueMotion 2.0 Real Time decoder Wideband Single-bit Data (WSD) demuxer VAAPI-accelerated H.264/HEVC/MJPEG encoding DTS Express (LBR) decoder Generic OpenMAX IL encoder with support for Raspberry Pi IFF ANIM demuxer & decoder Direct Stream Transfer (DST) decoder loudnorm filter MTAF demuxer and decoder MagicYUV decoder OpenExr improvements (tile data and B44/B44A support) BitJazz SheerVideo decoder CUDA CUVID H264/HEVC decoder 10-bit depth support in native utvideo decoder libutvideo wrapper removed YUY2 Lossless Codec decoder VideoToolbox H.264 encoder We strongly recommend users, distributors, and system integrators to upgrade unless they use current git master. March 16th, 2016, Google Summer of Code FFmpeg has been accepted as a Google Summer of Code open source organization. If you wish to participate as a student see our project ideas page. You can already get in contact with mentors and start working on qualification tasks as well as register at google and submit your project proposal draft. Good luck! February 15th, 2016, FFmpeg 3.0 ""Einstein"" FFmpeg 3.0 ""Einstein"", a new major release, is now available! Some of the highlights: The native FFmpeg AAC encoder has seen extensive improvements and is no longer considered experimental Removed support for libvo-aacenc and libaacplus Over 30 new filters have been added Many ASM optimizations VP9 Hardware Acceleration (DXVA2 and VA-API) Cineform HD decoder New DCA decoder based on libdcadec with full support for DTS-HD extensions As with all major releases expect major backward incompatible API/ABI changes See the Changelog for a list of more updates We strongly recommend users, distributors, and system integrators to upgrade unless they use current git master. January 30, 2016, Removing support for two external AAC encoders We have just removed support for VisualOn AAC encoder (libvo-aacenc) and libaacplus in FFmpeg master. Even before marking our internal AAC encoder as stable, it was known that libvo-aacenc was of an inferior quality compared to our native one for most samples. However, the VisualOn encoder was used extensively by the Android Open Source Project, and we would like to have a tested-and-true stable option in our code base. When first committed in 2011, libaacplus filled in the gap of encoding High Efficiency AAC formats (HE-AAC and HE-AACv2), which was not supported by any of the encoders in FFmpeg at that time. The circumstances for both have changed. After the work spearheaded by Rostislav Pehlivanov and Claudio Freire, the now-stable FFmpeg native AAC encoder is ready to compete with much more mature encoders. The Fraunhofer FDK AAC Codec Library for Android was added in 2012 as the fourth supported external AAC encoder, and the one with the best quality and the most features supported, including HE-AAC and HE-AACv2. Therefore, we have decided that it is time to remove libvo-aacenc and libaacplus. If you are currently using libvo-aacenc, prepare to transition to the native encoder (aac) when updating to the next version of FFmpeg. In most cases it is as simple as merely swapping the encoder name. If you are currently using libaacplus, start using FDK AAC (libfdk_aac) with an appropriate profile option to select the exact AAC profile that fits your needs. In both cases, you will enjoy an audible quality improvement and as well as fewer licensing headaches. Enjoy! January 16, 2016, FFmpeg 2.8.5, 2.7.5, 2.6.7, 2.5.10 We have made several new point releases (2.8.5, 2.7.5, 2.6.7, 2.5.10). They fix various bugs, as well as CVE-2016-1897 and CVE-2016-1898. Please see the changelog for each release for more details. We recommend users, distributors and system integrators to upgrade unless they use current git master. December 5th, 2015, The native FFmpeg AAC encoder is now stable! After seven years the native FFmpeg AAC encoder has had its experimental flag removed and declared as ready for general use. The encoder is transparent at 128kbps for most samples tested with artifacts only appearing in extreme cases. Subjective quality tests put the encoder to be of equal or greater quality than most of the other encoders available to the public. Licensing has always been an issue with encoding AAC audio as most of the encoders have had a license making FFmpeg unredistributable if compiled with support for them. The fact that there now exists a fully open and truly free AAC encoder integrated directly within the project means a lot to those who wish to use accepted and widespread standards. The majority of the work done to bring the encoder up to quality was started during this year's GSoC by developer Claudio Freire and Rostislav Pehlivanov. Both continued to work on the encoder with the latter joining as a developer and mainainer, working on other parts of the project as well. Also, thanks to Kamedo2 who does comparisons and tests, the original authors and all past and current contributors to the encoder. Users are suggested and encouraged to use the encoder and provide feedback or breakage reports through our bug tracker. October 13th, 2015, Telepoint & MediaHub are now supporting our project A big thank you note goes to our newest supporters: MediaHub and Telepoint. Both companies have donated a dedicated server with free of charge internet connectivity. Here is a little bit about them in their own words: Telepoint is the biggest carrier-neutral data center in Bulgaria. Located in the heart of Sofia on a cross-road of many Bulgarian and International networks, the facility is a fully featured Tier 3 data center that provides flexible customer-oriented colocation solutions (ranging from a server to a private collocation hall) and a high level of security. MediaHub Ltd. is a Bulgarian IPTV platform and services provider which uses FFmpeg heavily since it started operating a year ago. ""Donating to help keep FFmpeg online is our way of giving back to the community"" . Thanks Telepoint and MediaHub for their support! September 29th, 2015, GSoC 2015 results FFmpeg participated to the latest edition of the Google Summer of Code Project. FFmpeg got a total of 8 assigned projects, and 7 of them were successful. We want to thank Google, the participating students, and especially the mentors who joined this effort. We're looking forward to participating in the next GSoC edition! Below you can find a brief description of the final outcome of each single project. Basic servers for network protocols, mentee: Stephan Holljes, mentor: Nicolas George Stephan Holljes's project for this session of Google Summer of Code was to implement basic HTTP server features for libavformat, to complement the already present HTTP client and RTMP and RTSP server code. The first part of the project was to make the HTTP code capable of accepting a single client; it was completed partly during the qualification period and partly during the first week of the summer. Thanks to this work, it is now possible to make a simple HTTP stream using the following commands:      ffmpeg -i /dev/video0 -listen 1 -f matroska \     -c:v libx264 -preset fast -tune zerolatency http://:8080     ffplay http://localhost:8080/   The next part of the project was to extend the code to be able to accept several clients, simultaneously or consecutively. Since libavformat did not have an API for that kind of task, it was necessary to design one. This part was mostly completed before the midterm and applied shortly afterwards. Since the ffmpeg command-line tool is not ready to serve several clients, the test ground for that new API is an example program serving hard-coded content. The last and most ambitious part of the project was to update ffserver to make use of the new API. It would prove that the API is usable to implement real HTTP servers, and expose the points where more control was needed. By the end of the summer, a first working patch series was undergoing code review. Browsing content on the server, mentee: Mariusz Szczepańczyk, mentor: Lukasz Marek Mariusz finished an API prepared by the FFmpeg community and implemented Samba directory listing as qualification task. During the program he extended the API with the possibility to remove and rename files on remote servers. He completed the implementation of these features for file, Samba, SFTP, and FTP protocols. At the end of the program, Mariusz provided a sketch of an implementation for HTTP directory listening. Directshow digital video capture, mentee: Mate Sebok, mentor: Roger Pack Mate was working on directshow input from digital video sources. He got working input from ATSC input sources, with specifiable tuner. The code has not been committed, but a patch of it was sent to the ffmpeg-devel mailing list for future use. The mentor plans on cleaning it up and committing it, at least for the ATSC side of things. Mate and the mentor are still working trying to finally figure out how to get DVB working. Implementing full support for 3GPP Timed Text Subtitles, mentee: Niklesh Lalwani, mentor: Philip Langdale Niklesh's project was to expand our support for 3GPP Timed Text subtitles. This is the native subtitle format for mp4 containers, and is interesting because it's usually the only subtitle format supported by the stock playback applications on iOS and Android devices. ffmpeg already had basic support for these subtitles which ignored all formatting information - it just provided basic plain-text support. Niklesh did work to add support on both the encode and decode side for text formatting capabilities, such as font size/colour and effects like bold/italics, highlighting, etc. The main challenge here is that Timed Text handles formatting in a very different way from most common subtitle formats. It uses a binary encoding (based on mp4 boxes, naturally) and stores information separately from the text itself. This requires additional work to track which parts of the text formatting applies to, and explicitly dealing with overlapping formatting (which other formats support but Timed Text does not) so it requires breaking the overlapping sections into separate non-overlapping ones with different formatting. Finally, Niklesh had to be careful about not trusting any size information in the subtitles - and that's no joke: the now infamous Android stagefright bug was in code for parsing Timed Text subtitles. All of Niklesh's work is committed and was released in ffmpeg 2.8. libswscale refactoring, mentee: Pedro Arthur, mentors: Michael Niedermayer, Ramiro Polla Pedro Arthur has modularized the vertical and horizontal scalers. To do this he designed and implemented a generic filter framework and moved the existing scaler code into it. These changes now allow easily adding removing, splitting or merging processing steps. The implementation was benchmarked and several alternatives were tried to avoid speed loss. He also added gamma corrected scaling support. An example to use gamma corrected scaling would be:      ffmpeg -i input -vf scale=512:384:gamma=1 output   Pedro has done impressive work considering the short time available, and he is a FFmpeg committer now. He continues to contribute to FFmpeg, and has fixed some bugs in libswscale after GSoC has ended. AAC Encoder Improvements, mentee: Rostislav Pehlivanov, mentor: Claudio Freire Rostislav Pehlivanov has implemented PNS, TNS, I/S coding and main prediction on the native AAC encoder. Of all those extensions, only TNS was left in a less-than-usable state, but the implementation has been pushed (disabled) anyway since it's a good basis for further improvements. PNS replaces noisy bands with a single scalefactor representing the energy of that band, gaining in coding efficiency considerably, and the quality improvements on low bitrates are impressive for such a simple feature. TNS still needs some polishing, but has the potential to reduce coding artifacts by applying noise shaping in the temporal domain (something that is a source of annoying, notable distortion on low-entropy bands). Intensity Stereo coding (I/S) can double coding efficiency by exploiting strong correlation between stereo channels, most effective on pop-style tracks that employ panned mixing. The technique is not as effective on classic X-Y recordings though. Finally, main prediction improves coding efficiency by exploiting correlation among successive frames. While the gains have not been huge at this point, Rostislav has remained active even after the GSoC, and is polishing both TNS and main prediction, as well as looking for further improvements to make. In the process, the MIPS port of the encoder was broken a few times, something he's also working to fix. Animated Portable Network Graphics (APNG), mentee: Donny Yang, mentor: Paul B Mahol Donny Yang implemented basic keyframe only APNG encoder as the qualification task. Later he wrote interframe compression via various blend modes. The current implementation tries all blend modes and picks one which takes the smallest amount of memory. Special care was taken to make sure that the decoder plays correctly all files found in the wild and that the encoder produces files that can be played in browsers that support APNG. During his work he was tasked to fix any encountered bug in the decoder due to the fact that it doesn't match APNG specifications. Thanks to this work, a long standing bug in the PNG decoder has been fixed. For latter work he plans to continue working on the encoder, making it possible to select which blend modes will be used in the encoding process. This could speed up encoding of APNG files. September 9th, 2015, FFmpeg 2.8 We published release 2.8 as new major version. It contains all features and bug fixes of the git master branch from September 8th. Please see the changelog for a list of the most important changes. We recommend users, distributors and system integrators to upgrade unless they use current git master. August 1st, 2015, A message from the FFmpeg project Dear multimedia community, The resignation of Michael Niedermayer as leader of FFmpeg yesterday has come by surprise. He has worked tirelessly on the FFmpeg project for many years and we must thank him for the work that he has done. We hope that in the future he will continue to contribute to the project. In the coming weeks, the FFmpeg project will be managed by the active contributors. The last four years have not been easy for our multimedia community - both contributors and users. We should now look to the future, try to find solutions to these issues, and to have reconciliation between the forks, which have split the community for so long. Unfortunately, much of the disagreement has taken place in inappropriate venues so far, which has made finding common ground and solutions difficult. We aim to discuss this in our communities online over the coming weeks, and in person at the VideoLAN Developer Days in Paris in September: a neutral venue for the entire open source multimedia community. The FFmpeg project. July 4th, 2015, FFmpeg needs a new host UPDATE: We have received more than 7 offers for hosting and servers, thanks a lot to everyone! After graciously hosting our projects (FFmpeg, MPlayer and rtmpdump) for 4 years, Arpi (our hoster) has informed us that we have to secure a new host somewhere else immediately. If you want to host an open source project, please let us know, either on ffmpeg-devel mailing list or irc.freenode.net #ffmpeg-devel. We use about 4TB of storage and at least 4TB of bandwidth / month for various mailing lists, trac, samples repo, svn, etc. March 16, 2015, FFmpeg 2.6.1 We have made a new major release (2.6) and now one week afterward 2.6.1. It contains all features and bugfixes of the git master branch from the 6th March. Please see the Release Notes for a list of note-worthy changes. We recommend users, distributors and system integrators to upgrade unless they use current git master. March 4, 2015, Google Summer of Code FFmpeg has been accepted as a Google Summer of Code Project. If you wish to participate as a student see our project ideas page. You can already get in contact with mentors and start working on qualification tasks. Registration at Google for students will open March 16th. Good luck! March 1, 2015, Chemnitzer Linux-Tage We happily announce that FFmpeg will be represented at Chemnitzer Linux-Tage (CLT) in Chemnitz, Germany. The event will take place on 21st and 22nd of March. More information can be found here We demonstrate usage of FFmpeg, answer your questions and listen to your problems and wishes. If you have media files that cannot be processed correctly with FFmpeg, be sure to have a sample with you so we can have a look! For the first time in our CLT history, there will be an FFmpeg workshop! You can read the details here. The workshop is targeted at FFmpeg beginners. First the basics of multimedia will be covered. Thereafter you will learn how to use that knowledge and the FFmpeg CLI tools to analyse and process media files. The workshop is in German language only and prior registration is necessary. The workshop will be on Saturday starting at 10 o'clock. We are looking forward to meet you (again)! December 5, 2014, FFmpeg 2.5 We have made a new major release (2.5) It contains all features and bugfixes of the git master branch from the 4th December. Please see the Release Notes for a list of note-worthy changes. We recommend users, distributors and system integrators to upgrade unless they use current git master. October 10, 2014, FFmpeg is in Debian unstable again We wanted you to know there are FFmpeg packages in Debian unstable again. A big thank-you to Andreas Cadhalpun and all the people that made it possible. It has been anything but simple. Unfortunately that was already the easy part of this news. The bad news is the packages probably won't migrate to Debian testing to be in the upcoming release codenamed jessie. Read the argumentation over at Debian. However things will come out in the end, we hope for your continued remarkable support! October 8, 2014, FFmpeg secured a place in OPW! Thanks to a generous 6K USD donation by Samsung (Open Source Group), FFmpeg will be welcoming at least 1 ""Outreach Program for Women"" intern to work with our community for an initial period starting December 2014 (through March 2015). We all know FFmpeg is used by the industry, but even while there are countless products building on our code, it is not at all common for companies to step up and help us out when needed. So a big thank-you to Samsung and the OPW program committee! If you are thinking on participating in OPW as an intern, please take a look at our OPW wiki page for some initial guidelines. The page is still a work in progress, but there should be enough information there to get you started. If you, on the other hand, are thinking on sponsoring work on FFmpeg through the OPW program, please get in touch with us at opw@ffmpeg.org. With your help, we might be able to secure some extra intern spots for this round! September 15, 2014, FFmpeg 2.4 We have made a new major release (2.4) It contains all features and bugfixes of the git master branch from the 14th September. Please see the Release Notes for a list of note-worthy changes. We recommend users, distributors and system integrators to upgrade unless they use current git master. August 20, 2014, FFmpeg 2.3.3, 2.2.7, 1.2.8 We have made several new point releases (2.3.3, 2.2.7, 1.2.8). They fix various bugs, as well as CVE-2014-5271 and CVE-2014-5272. Please see the changelog for more details. We recommend users, distributors and system integrators to upgrade unless they use current git master. July 29, 2014, Help us out securing our spot in OPW Following our previous post regarding our participation on this year's OPW (Outreach Program for Women), we are now reaching out to our users (both individuals and companies) to help us gather the needed money to secure our spot in the program. We need to put together 6K USD as a minimum but securing more funds would help us towards getting more than one intern. You can donate by credit card using Click&Pledge and selecting the ""OPW"" option. If you would like to donate by money transfer or by check, please get in touch by e-mail and we will get back to you with instructions. Thanks! July 20, 2014, New website The FFmpeg project is proud to announce a brand new version of the website made by db0. While this was initially motivated by the need for a larger menu, the whole website ended up being redesigned, and most pages got reworked to ease navigation. We hope you'll enjoy browsing it. July 17, 2014, FFmpeg 2.3 We have made a new major release (2.3) It contains all features and bugfixes of the git master branch from the 16th July. Please see the Release Notes for a list of note-worthy changes. We recommend users, distributors and system integrators to upgrade unless they use current git master. July 3, 2014, FFmpeg and the Outreach Program For Women FFmpeg has started the process to become an OPW includer organization for the next round of the program, with internships starting December 9. The OPW aims to ""Help women (cis and trans) and genderqueer to get involved in free and open source software"". Part of the process requires securing funds to support at least one internship (6K USD), so if you were holding on your donation to FFmpeg, this is a great chance for you to come forward, get in touch and help both the project and a great initiative! We have set up an email address you can use to contact us about donations and general inquires regarding our participation in the program. Hope to hear from you soon! June 29, 2014, FFmpeg 2.2.4, 2.1.5, 2.0.5, 1.2.7, 1.1.12, 0.10.14 We have made several new point releases (2.2.4, 2.1.5, 2.0.5, 1.2.7, 1.1.12, 0.10.14). They fix a security issue in the LZO implementation, as well as several other bugs. See the git log for details. We recommend users, distributors and system integrators to upgrade unless they use current git master. May 1, 2014, LinuxTag Once again FFmpeg will be represented at LinuxTag in Berlin, Germany. The event will take place from 8th to 10th of May. Please note that this year's LinuxTag is at a different location closer to the city center. We will have a shared booth with XBMC and VideoLAN. If you have media files that cannot be processed correctly with FFmpeg, be sure to have a sample with you so we can have a look! More information about LinuxTag can be found here We are looking forward to see you in Berlin! April 18, 2014, OpenSSL Heartbeat bug Our server hosting the Trac issue tracker was vulnerable to the attack against OpenSSL known as ""heartbleed"". The OpenSSL software library was updated on 7th of April, shortly after the vulnerability was publicly disclosed. We have changed the private keys (and certificates) for all FFmpeg servers. The details were sent to the mailing lists by Alexander Strasser, who is part of the project server team. Here is a link to the user mailing list archive . We encourage you to read up on ""OpenSSL heartbleed"". It is possible that login data for the issue tracker was exposed to people exploiting this security hole. You might want to change your password in the tracker and everywhere else you used that same password. April 11, 2014, FFmpeg 2.2.1 We have made a new point releases (2.2.1). It contains bug fixes for Tickets #2893, #3432, #3469, #3486, #3495 and #3540 as well as several other fixes. See the git log for details. March 24, 2014, FFmpeg 2.2 We have made a new major release (2.2) It contains all features and bugfixes of the git master branch from 1st March. A partial list of new stuff is below:      - HNM version 4 demuxer and video decoder     - Live HDS muxer     - setsar/setdar filters now support variables in ratio expressions     - elbg filter     - string validation in ffprobe     - support for decoding through VDPAU in ffmpeg (the -hwaccel option)     - complete Voxware MetaSound decoder     - remove mp3_header_compress bitstream filter     - Windows resource files for shared libraries     - aeval filter     - stereoscopic 3d metadata handling     - WebP encoding via libwebp     - ATRAC3+ decoder     - VP8 in Ogg demuxing     - side & metadata support in NUT     - framepack filter     - XYZ12 rawvideo support in NUT     - Exif metadata support in WebP decoder     - OpenGL device     - Use metadata_header_padding to control padding in ID3 tags (currently used in     MP3, AIFF, and OMA files), FLAC header, and the AVI ""junk"" block.     - Mirillis FIC video decoder     - Support DNx444     - libx265 encoder     - dejudder filter     - Autodetect VDA like all other hardware accelerations   We recommend users, distributors and system integrators to upgrade unless they use current git master. February 3, 2014, Chemnitzer Linux-Tage We happily announce that FFmpeg will be represented at `Chemnitzer Linux-Tage' in Chemnitz, Germany. The event will take place on 15th and 16th of March. More information can be found here We invite you to visit us at our booth located in the Linux-Live area! There we will demonstrate usage of FFmpeg, answer your questions and listen to your problems and wishes. If you have media files that cannot be processed correctly with FFmpeg, be sure to have a sample with you so we can have a look! We are looking forward to meet you (again)! February 9, 2014, trac.ffmpeg.org / trac.mplayerhq.hu Security Breach The server on which FFmpeg and MPlayer Trac issue trackers were installed was compromised. The affected server was taken offline and has been replaced and all software reinstalled. FFmpeg Git, releases, FATE, web and mailinglists are on other servers and were not affected. We believe that the original compromise happened to a server, unrelated to FFmpeg and MPlayer, several months ago. That server was used as a source to clone the VM that we recently moved Trac to. It is not known if anyone used the backdoor that was found. We recommend all users to change their passwords. Especially users who use a password on Trac that they also use elsewhere, should change that password at least elsewhere. November 12, 2013, FFmpeg RFP in Debian Since the splitting of Libav the Debian/Ubuntu maintainers have followed the Libav fork. Many people have requested the packaging of ffmpeg in Debian, as it is more feature-complete and in many cases less buggy. Rogério Brito, a Debian developer, has proposed a Request For Package (RFP) in the Debian bug tracking system. Please let the Debian and Ubuntu developers know that you support packaging of the real FFmpeg! See Debian ticket #729203 for more details. October 28, 2013, FFmpeg 2.1 We have made a new major release (2.1) It contains all features and bugfixes of the git master branch from 28th October. A partial list of new stuff is below:      - aecho filter     - perspective filter ported from libmpcodecs     - ffprobe -show_programs option     - compand filter     - RTMP seek support     - when transcoding with ffmpeg (i.e. not streamcopying), -ss is now accurate     even when used as an input option. Previous behavior can be restored with     the -noaccurate_seek option.     - ffmpeg -t option can now be used for inputs, to limit the duration of     data read from an input file     - incomplete Voxware MetaSound decoder     - read EXIF metadata from JPEG     - DVB teletext decoder     - phase filter ported from libmpcodecs     - w3fdif filter     - Opus support in Matroska     - FFV1 version 1.3 is stable and no longer experimental     - FFV1: YUVA(444,422,420) 9, 10 and 16 bit support     - changed DTS stream id in lavf mpeg ps muxer from 0x8a to 0x88, to be     more consistent with other muxers.     - adelay filter     - pullup filter ported from libmpcodecs     - ffprobe -read_intervals option     - Lossless and alpha support for WebP decoder     - Error Resilient AAC syntax (ER AAC LC) decoding     - Low Delay AAC (ER AAC LD) decoding     - mux chapters in ASF files     - SFTP protocol (via libssh)     - libx264: add ability to encode in YUVJ422P and YUVJ444P     - Fraps: use BT.709 colorspace by default for yuv, as reference fraps decoder does     - make decoding alpha optional for prores, ffv1 and vp6 by setting     the skip_alpha flag.     - ladspa wrapper filter     - native VP9 decoder     - dpx parser     - max_error_rate parameter in ffmpeg     - PulseAudio output device     - ReplayGain scanner     - Enhanced Low Delay AAC (ER AAC ELD) decoding (no LD SBR support)     - Linux framebuffer output device     - HEVC decoder, raw HEVC demuxer, HEVC demuxing in TS, Matroska and MP4     - mergeplanes filter   We recommend users, distributors and system integrators to upgrade unless they use current git master. Past news"	"null"	"null"	"A complete, cross-platform solution to record, convert and stream audio and video. or later, with some parts under or later."	"true"
"Multimedia"	"GStreamer"	"https://gstreamer.freedesktop.org/"	"A framework for audio and visual media. only."	"null"	"null"	"null"	"GNU LGPL2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"null"	"null"	"null"	"GStreamer: open source multimedia framework Home Features News Annual Conference Planet (Blogs) Download Applications Developers Documentation Mailing Lists File a Bug Bug Lists Artwork Follow @gstreamer on Twitter News - GStreamer Core, Plugins, RTSP Server, Editing Services, Python, Validate 1.9.1 unstable release (binaries) Pre-built binary images of the 1.9.1 unstable release of GStreamer are now available for Windows 32/64-bit, iOS and Mac OS X and Android. The builds are available for download from: Android, iOS, Mac OS X and Windows. 2016-07-12 7:00 Recent older news: GStreamer Core, Plugins, RTSP Server, Editing Services, Python, Validate, VAAPI, OMX 1.9.1 unstable release 2016-07-06 12:00 GStreamer Core, Plugins, RTSP Server, Editing Services, Validate 1.8.2 stable release (binaries) 2016-06-17 14:00 Click for even older news... News feeds: [RSS 1.0] Release feeds: [RSS 1.0][RSS 2.0][iCal] What is GStreamer? GStreamer is a library for constructing graphs of media-handling components. The applications it supports range from simple Ogg/Vorbis playback, audio/video streaming to complex audio (mixing) and video (non-linear editing) processing. Applications can take advantage of advances in codec and filter technology transparently. Developers can add new codecs and filters by writing a simple plugin with a clean, generic interface. Read more ... GStreamer is released under the LGPL. The 1.x series is API and ABI stable and supersedes the previous stable 0.10 series. Both can be installed in parallel. Report a problem on this page."	"null"	"null"	"A framework for audio and visual media. only."	"true"
"Multimedia"	"lodepng"	"http://lodev.org/lodepng/"	"A simple PNG image decoder and encoder, requiring no other dependencies.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"380"	"41"	"78"	"GitHub - lvandeve/lodepng: PNG encoder and decoder in C and C++. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 41 Star 380 Fork 78 lvandeve/lodepng Code Issues 13 Pull requests 3 Pulse Graphs PNG encoder and decoder in C and C++. 81 commits 1 branch 0 releases Fetching contributors C++ 100.0% C++ Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Latest commit a71964e Jul 12, 2016 lvandeve add a todo Permalink Failed to load latest commit information. examples Made load_file function return error if file can't be opened Dec 9, 2015 README.md Create README.md Aug 24, 2014 lodepng.cpp fix relying on integer underflow May 3, 2016 lodepng.h add a todo Jul 12, 2016 lodepng_benchmark.cpp boundary package merge Apr 19, 2015 lodepng_unittest.cpp Update lodepng_unittest.cpp Apr 21, 2016 lodepng_util.cpp ignore invalid data past IEND in chunk util Mar 29, 2016 lodepng_util.h add example and dev files to LodePNG repository Aug 24, 2014 pngdetail.cpp show background color in pngdetail Mar 23, 2016 README.md LodePNG PNG encoder and decoder in C and C++. Home page: http://lodev.org/lodepng/ Only two files are needed to allow your program to read and write PNG files: lodepng.cpp and lodepng.h. The other files in the project are just examples, unit tests, etc... Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/lvandeve/lodepng"	"A simple PNG image decoder and encoder, requiring no other dependencies.."	"true"
"Networking and Internet"	"asnlc"	"http://lionet.info/asn1c/compiler.html"	"A compiler of ASN.1 specifications into C source code.."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"null"	"null"	"null"	"Open Source ASN.1 Compiler: asn1c 0.9.24 Home → ASN.1 √ ASN.1 Blog √ ASN.1 Basics √ ASN.1 Compiler √ Documentation √ FAQ √ Examples √ Download √ Users say... Open Source ASN.1 Compiler The asn1c is a free, open source compiler of ASN.1 specifications into C source code. It supports a range of ASN.1 syntaxes, including ISO/IEC/ITU ASN.1 1988, '94, '97, 2002 and later amendments. The supported sets of encoding rules are BER: ITU-T Rec. X.690 | ISO/IEC 8825-1 (2002) (BER/DER/CER) PER: X.691|8825-2 (2002) (PER). XER: X.693|8825-3 (2001) (BASIC-XER/CXER). The compiler was written specifically to address security concerns while providing streaming decoding capabilities. Feature asn1c Restartable/stream decoding1 YES, for BER and XER families BER (Basic Encoding Rules) YES DER (a canonical BER subset) YES CER (another canonical BER subset) yes, read-only2 BASIC-XER (XML Encoding Rules) YES CXER (""Canonical"" XER) YES EXTENDED-XER no PER (Packed Encoding Rules) YES, UNALIGNED BASIC PER Subtype constraints YES3 Information Object Classes basic support C target language YES C++ target language YES4 Java target language no Compiled code portability  LP64: Linux/alpha, Linux/amd64 ILP32: MacOS X/powerpc (big-endian), Solaris 9/sparc (big-endian);    Solaris/x86, FreeBSD/x86, OpenBSD/x86, NetBSD/x86, Linux/x86 (consistency for above platforms is ensured by automated daily testing) ILP32: Windows-CYGWIN, Windows-MSVC++ (minor manual tweaking required for MS platforms) EBCDIC support provisioned5 License BSD Cost $0 1) A decoder does not have to have the whole data sequence to start parsing. If it receives less data then required, it will process as much as possible and may be invoked again later, when the next chunk of data becomes available. Question: How to use streaming? 2) Encoding has not been required so far. Please ask for support. 3) The code generator automatically generates constraints checking procedures for PER-visible constraints. 4) C++ compatible C code. No OOP yet. 5) Code has been designed to support EBCDIC charset, but no formal testing has been made yet. The ASN.1 Compiler Copyright © 2003—2013 Lev Walkin <vlm@lionet.info>"	"null"	"null"	"A compiler of ASN.1 specifications into C source code.."	"true"
"Networking and Internet"	"czmq"	"https://github.com/zeromq/czmq"	"A high-level binding for ZeroMQ."	"null"	"null"	"null"	"MPL2.0"	"https://www.gnu.org/licenses/license-list.html#MPL-2.0"	"null"	"null"	"479"	"92"	"307"	"GitHub - zeromq/czmq: High-level C binding for ØMQ Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 92 Star 479 Fork 307 zeromq/czmq Code Issues 40 Pull requests 0 Pulse Graphs High-level C binding for ØMQ http://czmq.zeromq.org 3,613 commits 1 branch 15 releases 124 contributors C 38.2% C++ 27.2% Ruby 12.5% Python 11.1% Java 5.1% Batchfile 1.5% Other 4.4% C C++ Ruby Python Java Batchfile Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show v3.0.2 v3.0.1 v3.0.0 v2.2.0 v2.1.0 v2.0.2 v2.0.1 v2.0.0 v1.4.1 v1.4.0 v1.3.2 v1.3.1 v1.2.0 v1.1.0 v1.0.0 Nothing to show New pull request Latest commit 704256b Jul 12, 2016 somdoron committed on GitHub Merge pull request #1485 from twhittock/master … Python tests Permalink Failed to load latest commit information. api Problem: [zhashx] cannot (un)pack anything but string values Jun 17, 2016 bindings Problem: Python bindings not executed by CI system. Jul 11, 2016 builds Problem: Python bindings not executed by CI system. Jul 11, 2016 doc Problem: czmq docs and mvcs are out of sync (zproject has evolved!) Jun 28, 2016 examples/security Probelm: zpubsub has been removed thus the examples shall be removed as Oct 29, 2014 images Problem: czmq docs and mvcs are out of sync (zproject has evolved!) Jun 28, 2016 include Problem: zdir.c, zmsg.c and test_zgossip.h are still LGPL3 licensed Jul 10, 2016 issues Refactoring conditional directives for incomplete if conditions. Dec 4, 2015 model Problem: Confusing duplication of zproject-like files in CZMQ. Feb 13, 2015 packaging Problem: out of sync with zproject Jun 4, 2016 src Problem: zdir.c, zmsg.c and test_zgossip.h are still LGPL3 licensed Jul 10, 2016 .gitattributes Problem: CZMQ not built using lastest ZPROJECT gsls Apr 5, 2016 .gitignore Gitignore windows build outputs. May 4, 2016 .travis.yml Problem: Python bindings not executed by CI system. Jul 11, 2016 AUTHORS embed zsock_* option functions into zsock XML API Nov 20, 2015 CMakeLists.txt Problem: cmake configs are out of date (zproject has evolved!) Jul 11, 2016 CONTRIBUTING.md Update CONTRIBUTING.md Oct 31, 2014 Dockerfile Problem: czmq is out of sync (zproject has evolved!) Jun 14, 2016 Findlibsodium.cmake Problem: CMake find package support was broken Jan 20, 2016 Findlibzmq.cmake Problem: cmake configs are out of date (zproject has evolved!) Jul 11, 2016 Findsystemd.cmake Problem: cmake configs are out of date (zproject has evolved!) Jul 11, 2016 Finduuid.cmake Problem: cmake configs are out of date (zproject has evolved!) Jul 11, 2016 INSTALL.cygwin Implement a definitive czmq build for cygwin targets. Dec 29, 2014 ISSUES.cygwin Implement a definitive czmq build for cygwin targets. Dec 30, 2014 LICENSE Relicensed CZMQ to MPLv2 Apr 3, 2014 Makefile.am Problem: autotools out of sync (zproject has evolved!) May 24, 2016 NEWS Updated NEWS for 3.0.2 Jun 8, 2015 README.cygwin Implement a definitive czmq build for cygwin targets. Dec 30, 2014 README.md Problem: README is too vague about pkg-config Jul 2, 2016 README.txt Problem: README is too vague about pkg-config Jul 2, 2016 acinclude.m4 Warning instead of error if cannot link pthread Jul 28, 2015 appveyor.yml Problem: Windows CI does not add zmakecert.exe to artefict Apr 20, 2016 autogen.sh Problem: CZMQ not using latest ZPROJECT gsls Apr 7, 2016 ci_build.sh Problem: out of sync with zproject May 24, 2016 ci_deploy.sh Problem: czmq out of sync (zproject has evolved!) Jun 10, 2016 configure.ac Fix compilation with mingw64 using autotools Jun 1, 2016 license.xml Problem: api/zdir_patch.xml does not build Nov 27, 2015 mkdoc Problem: API generation no longer done here (it's in ztools) Dec 8, 2014 project.gyp Problem: code out of date with project.xml Feb 9, 2016 project.xml Problem: Dockerfile is not generated by zproject Jun 14, 2016 setup.py Problem: czmq is out of sync (zproject has evolved!) Jun 14, 2016 version.sh Problem: need to bump version number after release Jun 8, 2015 README.md CZMQ - High-level C binding for ØMQ Linux & MacOSX Windows Chat Contents Overview Scope and Goals Ownership and License Using CZMQ Building and Installing Building on Windows Linking with an Application Use from Other Languages API v3 Summary zactor - simple actor framework zauth - authentication for ZeroMQ security mechanisms zbeacon - LAN discovery and presence zcert - work with CURVE security certificates zcertstore - work with CURVE security certificate stores zchunk - work with memory chunks zclock - millisecond clocks and delays zconfig - work with config files written in rfc.zeromq.org/spec:4/ZPL. zdigest - provides hashing functions (SHA-1 at present) zdir - work with file-system directories zdir_patch - work with directory patches zfile - provides methods to work with files in a portable fashion. zframe - working with single message frames zgossip - decentralized configuration management zhash - simple generic hash container zhashx - extended generic hash container ziflist - list of network interfaces available on system zlist - simple generic list container zlistx - extended generic list container zloop - event-driven reactor zmonitor - socket event monitor zmsg - working with multipart messages zpoller - trivial socket poller class zproc - process configuration and status zproxy - run a steerable proxy in the background zrex - work with regular expressions zsock - high-level socket API that hides libzmq contexts and sockets zstr - sending and receiving strings zsys - system-level methods ztimerset - timer set ztrie - simple trie for tokenizable strings zuuid - UUID support class API v2 Summary zauth_v2 - authentication for ZeroMQ servers (deprecated) zctx - working with ØMQ contexts (deprecated) zmonitor_v2 - socket event monitor (deprecated) zmutex - working with mutexes (deprecated) zproxy_v2 - run a steerable proxy in the background (deprecated) zsocket - working with ØMQ sockets (deprecated) zsockopt - get/set ØMQ socket options (deprecated) zthread - working with system threads (deprecated) Error Handling CZMQ Actors Under the Hood Adding a New Class Documentation Development Porting CZMQ Hints to Contributors Code Generation This Document Overview Scope and Goals CZMQ has these goals: To wrap the ØMQ core API in semantics that lead to shorter, more readable applications. To hide as far as possible the differences between different versions of ØMQ (2.x, 3.x, 4.x). To provide a space for development of more sophisticated API semantics. To wrap the ØMQ security features with high-level tools and APIs. To become the basis for other language bindings built on top of CZMQ. CZMQ grew out of concepts developed in ØMQ - The Guide. Ownership and License The contributors are listed in AUTHORS. This project uses the MPL v2 license, see LICENSE. CZMQ uses the C4.1 (Collective Code Construction Contract) process for contributions. CZMQ uses the CLASS (C Language Style for Scalabilty) guide for code style. To report an issue, use the CZMQ issue tracker at github.com. Using CZMQ Building and Installing To start with, you need at least these packages: {{git-all}} -- git is how we share code with other people. {{build-essential}}, {{libtool}}, {{pkg-config}} - the C compiler and related tools. {{autotools-dev}}, {{autoconf}}, {{automake}} - the GNU autoconf makefile generators. {{cmake}} - the CMake makefile generators (an alternative to autoconf). Plus some others: {{uuid-dev}}, {{libpcre3-dev}} - utility libraries. {{valgrind}} - a useful tool for checking your code. {{pkg-config}} - an optional useful tool to make building with dependencies easier. Which we install like this (using the Debian-style apt-get package manager): sudo apt-get update sudo apt-get install -y \     git-all build-essential libtool \     pkg-config autotools-dev autoconf automake cmake \     uuid-dev libpcre3-dev valgrind  # only execute this next line if interested in updating the man pages as well (adds to build time): sudo apt-get install -y asciidoc  Here's how to build CZMQ from GitHub (building from packages is very similar, you don't clone a repo but unpack a tarball), including the libzmq (ZeroMQ core) library: git clone git://github.com/zeromq/libzmq.git cd libzmq ./autogen.sh # do not specify ""--with-libsodium"" if you prefer to use internal tweetnacl security implementation (recommended for development) ./configure --with-libsodium make check sudo make install sudo ldconfig cd ..  git clone git://github.com/zeromq/czmq.git cd czmq ./autogen.sh && ./configure && make check sudo make install sudo ldconfig cd ..  In general CZMQ works best with the latest libzmq master. If you already have an older version of libzmq installed on your system, e.g. in /usr/, then you can install libzmq master to your home directory ($HOME/local): #   Building libzmq in our home directory ./configure --prefix=$HOME/local  And then to build CZMQ against this installation of libzmq: export CFLAGS=-I$HOME/local/include export LDFLAGS=-L$HOME/local/lib64 export PKG_CONFIG_PATH=$HOME/local/lib64/pkgconfig ./configure  NOTE: the PKG_CONFIG_PATH is not mandatory, and the actual directory might be different. If you cannot or do not want to use pkg-config, please make sure to MANUALLY add all the necessary CFLAGS and LDFLAGS from all dependencies (for example -DZMQ_BUILD_DRAFT_API=1 if you want the DRAFT APIs). You will need the pkg-config, libtool, and autoreconf packages. After building, run the CZMQ selftests: make check  Building on Windows To start with, you need MS Visual Studio (C/C++). The free community edition works well. Then, install git, and make sure it works from a DevStudio command prompt: git  Now let's build CZMQ from GitHub:     git clone --depth 1 -b stable https://github.com/jedisct1/libsodium.git     cd libsodium\builds\msvc\build     buildall.bat     cd ..\..\..\..      :: if libsodium is on disk, the Windows build of libzmq will automatically use it     git clone git://github.com/zeromq/libzmq.git     cd libzmq\builds\msvc     configure.bat     cd build     buildall.bat     cd ..\..\..\..      git clone git://github.com/zeromq/czmq.git     cd czmq\builds\msvc     configure.bat     cd build     buildall.bat     cd ..\..\..\..  Let's test by running czmq_selftest:    czmq>dir/s/b czmq_selftest.exe    czmq\builds\msvc\vs2013\DebugDEXE\czmq_selftest.exe    czmq\builds\msvc\vs2013\DebugLEXE\czmq_selftest.exe    czmq\builds\msvc\vs2013\DebugSEXE\czmq_selftest.exe    czmq\builds\msvc\vs2013\ReleaseDEXE\czmq_selftest.exe    czmq\builds\msvc\vs2013\ReleaseLEXE\czmq_selftest.exe    czmq\builds\msvc\vs2013\ReleaseSEXE\czmq_selftest.exe    czmq\builds\msvc\vs2013\x64\DebugDEXE\czmq_selftest.exe    czmq\builds\msvc\vs2013\x64\DebugLEXE\czmq_selftest.exe    czmq\builds\msvc\vs2013\x64\DebugSEXE\czmq_selftest.exe    czmq\builds\msvc\vs2013\x64\ReleaseDEXE\czmq_selftest.exe    czmq\builds\msvc\vs2013\x64\ReleaseLEXE\czmq_selftest.exe    czmq\builds\msvc\vs2013\x64\ReleaseSEXE\czmq_selftest.exe      :: select your choice and run it     czmq\builds\msvc\vs2013\x64\ReleaseDEXE\czmq_selftest.exe  Linking with an Application Include czmq.h in your application and link with libczmq. Here is a typical gcc link command: gcc myapp.c -o myapp -lczmq -lzmq  Use from Other Languages This is a list of known higher-level wrappers around CZMQ: https://github.com/1100110/CZMQ - D bindings https://github.com/methodmissing/rbczmq - Ruby https://github.com/zeromq/pyczmq - Python https://github.com/lhope/cl-czmq - Common Lisp https://github.com/fmp88/ocaml-czmq - Ocaml https://github.com/gar1t/erlang-czmq - Erlang https://github.com/mtortonesi/ruby-czmq-ffi - Ruby FFI https://github.com/zeromq/goczmq - Go API v3 Summary This is the API provided by CZMQ v3.x, in alphabetical order. zactor - simple actor framework The zactor class provides a simple actor framework. It replaces the CZMQ zthread class, which had a complex API that did not fit the CLASS standard. A CZMQ actor is implemented as a thread plus a PAIR-PAIR pipe. The constructor and destructor are always synchronized, so the caller can be sure all resources are created, and destroyed, when these calls complete. (This solves a major problem with zthread, that a caller could not be sure when a child thread had finished.) A zactor_t instance acts like a zsock_t and you can pass it to any CZMQ method that would take a zsock_t argument, including methods in zframe, zmsg, zstr, and zpoller. (zloop somehow escaped and needs catching.) An actor function MUST call zsock_signal (pipe) when initialized and MUST listen to pipe and exit on $TERM command. Please add @discuss section in ../src/zactor.c. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     // Actors get a pipe and arguments from caller     typedef void (zactor_fn) (         zsock_t *pipe, void *args);      //  Create a new actor passing arbitrary arguments reference.     CZMQ_EXPORT zactor_t *         zactor_new (zactor_fn task, void *args);      //  Destroy an actor.     CZMQ_EXPORT void         zactor_destroy (zactor_t **self_p);      //  Send a zmsg message to the actor, take ownership of the message     //  and destroy when it has been sent.                                  CZMQ_EXPORT int         zactor_send (zactor_t *self, zmsg_t **msg_p);      //  Receive a zmsg message from the actor. Returns NULL if the actor      //  was interrupted before the message could be received, or if there     //  was a timeout on the actor.                                           //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zmsg_t *         zactor_recv (zactor_t *self);      //  Probe the supplied object, and report if it looks like a zactor_t.     CZMQ_EXPORT bool         zactor_is (void *self);      //  Probe the supplied reference. If it looks like a zactor_t instance,     //  return the underlying libzmq actor handle; else if it looks like        //  a libzmq actor handle, return the supplied value.                       CZMQ_EXPORT void *         zactor_resolve (void *self);      //  Return the actor's zsock handle. Use this when you absolutely need     //  to work with the zsock instance rather than the actor.                 CZMQ_EXPORT zsock_t *         zactor_sock (zactor_t *self);      //  Self test of this class.     CZMQ_EXPORT void         zactor_test (bool verbose);  This is the class self test code:     zactor_t *actor = zactor_new (echo_actor, ""Hello, World"");     assert (actor);     zstr_sendx (actor, ""ECHO"", ""This is a string"", NULL);     char *string = zstr_recv (actor);     assert (streq (string, ""This is a string""));     free (string);     zactor_destroy (&actor); zauth - authentication for ZeroMQ security mechanisms A zauth actor takes over authentication for all incoming connections in its context. You can whitelist or blacklist peers based on IP address, and define policies for securing PLAIN, CURVE, and GSSAPI connections. This class replaces zauth_v2, and is meant for applications that use the CZMQ v3 API (meaning, zsock). This is the class interface:     #define CURVE_ALLOW_ANY ""*""      //  CZMQ v3 API (for use with zsock, not zsocket, which is deprecated).     //     //  Create new zauth actor instance. This installs authentication on all      //  zsock sockets. Until you add policies, all incoming NULL connections are     //  allowed (classic ZeroMQ behaviour), and all PLAIN and CURVE connections     //  are denied:     //       //      zactor_t *auth = zactor_new (zauth, NULL);     //     //  Destroy zauth instance. This removes authentication and allows all     //  connections to pass, without authentication:     //       //      zactor_destroy (&auth);     //     //  Note that all zauth commands are synchronous, so your application always     //  waits for a signal from the actor after each command.     //     //  Enable verbose logging of commands and activity. Verbose logging can help     //  debug non-trivial authentication policies:     //     //      zstr_send (auth, ""VERBOSE"");     //      zsock_wait (auth);     //     //  Allow (whitelist) a list of IP addresses. For NULL, all clients from     //  these addresses will be accepted. For PLAIN and CURVE, they will be     //  allowed to continue with authentication. You can call this method     //  multiple times to whitelist more IP addresses. If you whitelist one     //  or nmore addresses, any non-whitelisted addresses are treated as     //  blacklisted:     //       //      zstr_sendx (auth, ""ALLOW"", ""127.0.0.1"", ""127.0.0.2"", NULL);     //      zsock_wait (auth);     //       //  Deny (blacklist) a list of IP addresses. For all security mechanisms,     //  this rejects the connection without any further authentication. Use     //  either a whitelist, or a blacklist, not not both. If you define both     //  a whitelist and a blacklist, only the whitelist takes effect:     //       //      zstr_sendx (auth, ""DENY"", ""192.168.0.1"", ""192.168.0.2"", NULL);     //      zsock_wait (auth);     //     //  Configure PLAIN authentication using a plain-text password file. You can     //  modify the password file at any time; zauth will reload it automatically     //  if modified externally:     //       //      zstr_sendx (auth, ""PLAIN"", filename, NULL);     //      zsock_wait (auth);     //     //  Configure CURVE authentication, using a directory that holds all public     //  client certificates, i.e. their public keys. The certificates must be in     //  zcert_save format. You can add and remove certificates in that directory     //  at any time. To allow all client keys without checking, specify     //  CURVE_ALLOW_ANY for the directory name:     //     //      zstr_sendx (auth, ""CURVE"", directory, NULL);     //      zsock_wait (auth);     //     //  Configure GSSAPI authentication, using an underlying mechanism (usually     //  Kerberos) to establish a secure context and perform mutual authentication:     //     //      zstr_sendx (auth, ""GSSAPI"", NULL);     //      zsock_wait (auth);     //     //  This is the zauth constructor as a zactor_fn:     CZMQ_EXPORT void         zauth (zsock_t *pipe, void *certstore);      //  Selftest     CZMQ_EXPORT void         zauth_test (bool verbose); This is the class self test code:     //  Create temporary directory for test files     #   define TESTDIR "".test_zauth""     zsys_dir_create (TESTDIR);      //  Check there's no authentication     zsock_t *server = zsock_new (ZMQ_PULL);     assert (server);     zsock_t *client = zsock_new (ZMQ_PUSH);     assert (client);     bool success = s_can_connect (&server, &client, true);     assert (success);      //  Install the authenticator     zactor_t *auth = zactor_new (zauth, NULL);     assert (auth);     if (verbose) {         zstr_sendx (auth, ""VERBOSE"", NULL);         zsock_wait (auth);     }     //  Check there's no authentication on a default NULL server     success = s_can_connect (&server, &client, true);     assert (success);      //  When we set a domain on the server, we switch on authentication     //  for NULL sockets, but with no policies, the client connection     //  will be allowed.     zsock_set_zap_domain (server, ""global"");     success = s_can_connect (&server, &client, true);     assert (success);      //  Blacklist 127.0.0.1, connection should fail     zsock_set_zap_domain (server, ""global"");     zstr_sendx (auth, ""DENY"", ""127.0.0.1"", NULL);     zsock_wait (auth);     success = s_can_connect (&server, &client, true);     assert (!success);      //  Whitelist our address, which overrides the blacklist     zsock_set_zap_domain (server, ""global"");     zstr_sendx (auth, ""ALLOW"", ""127.0.0.1"", NULL);     zsock_wait (auth);     success = s_can_connect (&server, &client, true);     assert (success);      //  Try PLAIN authentication     zsock_set_plain_server (server, 1);     zsock_set_plain_username (client, ""admin"");     zsock_set_plain_password (client, ""Password"");     success = s_can_connect (&server, &client, true);     assert (!success);      FILE *password = fopen (TESTDIR ""/password-file"", ""w"");     assert (password);     fprintf (password, ""admin=Password\n"");     fclose (password);     zsock_set_plain_server (server, 1);     zsock_set_plain_username (client, ""admin"");     zsock_set_plain_password (client, ""Password"");     zstr_sendx (auth, ""PLAIN"", TESTDIR ""/password-file"", NULL);     zsock_wait (auth);     success = s_can_connect (&server, &client, true);     assert (success);      zsock_set_plain_server (server, 1);     zsock_set_plain_username (client, ""admin"");     zsock_set_plain_password (client, ""Bogus"");     success = s_can_connect (&server, &client, true);     assert (!success);      if (zsys_has_curve ()) {         //  Try CURVE authentication         //  We'll create two new certificates and save the client public         //  certificate on disk; in a real case we'd transfer this securely         //  from the client machine to the server machine.         zcert_t *server_cert = zcert_new ();         assert (server_cert);         zcert_t *client_cert = zcert_new ();         assert (client_cert);         const char *server_key = zcert_public_txt (server_cert);          //  Test without setting-up any authentication         zcert_apply (server_cert, server);         zcert_apply (client_cert, client);         zsock_set_curve_server (server, 1);         zsock_set_curve_serverkey (client, server_key);         success = s_can_connect (&server, &client, true);         assert (!success);          //  Test CURVE_ALLOW_ANY         zcert_apply (server_cert, server);         zcert_apply (client_cert, client);         zsock_set_curve_server (server, 1);         zsock_set_curve_serverkey (client, server_key);         zstr_sendx (auth, ""CURVE"", CURVE_ALLOW_ANY, NULL);         zsock_wait (auth);         success = s_can_connect (&server, &client, true);         assert (success);          //  Test full client authentication using certificates         zcert_set_meta (client_cert, ""Hello"", ""%s"", ""World!"");         zcert_apply (server_cert, server);         zcert_apply (client_cert, client);         zsock_set_curve_server (server, 1);         zsock_set_curve_serverkey (client, server_key);         zcert_save_public (client_cert, TESTDIR ""/mycert.txt"");         zstr_sendx (auth, ""CURVE"", TESTDIR, NULL);         zsock_wait (auth);         success = s_can_connect (&server, &client, false);         assert (success);      #if (ZMQ_VERSION >= ZMQ_MAKE_VERSION (4, 1, 0))         // Test send/recv certificate metadata         zframe_t *frame = zframe_recv (server);         assert (frame != NULL);         const char *meta = zframe_meta (frame, ""Hello"");         assert (meta != NULL);         assert (streq (meta, ""World!""));         zframe_destroy (&frame);         s_renew_sockets(&server, &client);     #endif          zcert_destroy (&server_cert);         zcert_destroy (&client_cert);          // Test custom zcertstore         zcertstore_t *certstore = zcertstore_new (NULL);         zcertstore_set_loader (certstore, s_test_loader, NULL, NULL);         zactor_destroy(&auth);         auth = zactor_new (zauth, certstore);         assert (auth);         if (verbose) {             zstr_sendx (auth, ""VERBOSE"", NULL);             zsock_wait (auth);         }          byte public_key [32] = { 105, 76, 150, 58, 214, 191, 218, 65, 50, 172,                                  131, 188, 247, 211, 136, 170, 227, 26, 57, 170,                                  185, 63, 246, 225, 177, 230, 12, 8, 134, 136,                                  105, 106 };         byte secret_key [32] = { 245, 217, 172, 73, 106, 28, 195, 17, 218, 132,                                  135, 209, 99, 240, 98, 232, 7, 137, 244, 100,                                  242, 23, 29, 114, 70, 223, 83, 1, 113, 207,                                  132, 149 };         zcert_t *shared_cert = zcert_new_from (public_key, secret_key);         assert (shared_cert);         zcert_apply (shared_cert, server);         zcert_apply (shared_cert, client);         zsock_set_curve_server (server, 1);         zsock_set_curve_serverkey (client, ""x?T*N/1Y{8goubv{Ts}#&#f}TXJ//DVe#D2HkoLU"");         success = s_can_connect (&server, &client, true);         assert (success);         zcert_destroy (&shared_cert);     }     //  Remove the authenticator and check a normal connection works     zactor_destroy (&auth);     success = s_can_connect (&server, &client, true);     assert (success);      zsock_destroy (&client);     zsock_destroy (&server);      //  Delete all test files     zdir_t *dir = zdir_new (TESTDIR, NULL);     assert (dir);     zdir_remove (dir, true);     zdir_destroy (&dir); zbeacon - LAN discovery and presence The zbeacon class implements a peer-to-peer discovery service for local networks. A beacon can broadcast and/or capture service announcements using UDP messages on the local area network. This implementation uses IPv4 UDP broadcasts. You can define the format of your outgoing beacons, and set a filter that validates incoming beacons. Beacons are sent and received asynchronously in the background. This class replaces zbeacon_v2, and is meant for applications that use the CZMQ v3 API (meaning, zsock). This is the class interface:     //  Create new zbeacon actor instance:     //     //      zactor_t *beacon = zactor_new (zbeacon, NULL);     //     //  Destroy zbeacon instance:     //     //      zactor_destroy (&beacon);     //     //  Enable verbose logging of commands and activity:     //     //      zstr_send (beacon, ""VERBOSE"");     //     //  Configure beacon to run on specified UDP port, and return the name of     //  the host, which can be used as endpoint for incoming connections. To     //  force the beacon to operate on a given interface, set the environment     //  variable ZSYS_INTERFACE, or call zsys_set_interface() before creating     //  the beacon. If the system does not support UDP broadcasts (lacking a     //  workable interface), returns an empty hostname:     //     //      //  Pictures: 's' = C string, 'i' = int     //      zsock_send (beacon, ""si"", ""CONFIGURE"", port_number);     //      char *hostname = zstr_recv (beacon);     //     //  Start broadcasting a beacon at a specified interval in msec. The beacon     //  data can be at most UDP_FRAME_MAX bytes; this constant is defined in     //  zsys.h to be 255:     //     //      //  Pictures: 'b' = byte * data + size_t size     //      zsock_send (beacon, ""sbi"", ""PUBLISH"", data, size, interval);     //     //  Stop broadcasting the beacon:     //     //      zstr_sendx (beacon, ""SILENCE"", NULL);     //     //  Start listening to beacons from peers. The filter is used to do a prefix     //  match on received beacons, to remove junk. Note that any received data     //  that is identical to our broadcast beacon_data is discarded in any case.     //  If the filter size is zero, we get all peer beacons:     //       //      zsock_send (beacon, ""sb"", ""SUBSCRIBE"", filter_data, filter_size);     //     //  Stop listening to other peers     //     //      zstr_sendx (beacon, ""UNSUBSCRIBE"", NULL);     //     //  Receive next beacon from a peer. Received beacons are always a 2-frame     //  message containing the ipaddress of the sender, and then the binary     //  beacon data as published by the sender:     //     //      zmsg_t *msg = zmsg_recv (beacon);     //     //  This is the zbeacon constructor as a zactor_fn:     CZMQ_EXPORT void         zbeacon (zsock_t *pipe, void *unused);      //  Self test of this class     CZMQ_EXPORT void         zbeacon_test (bool verbose); This is the class self test code:     //  Test 1 - two beacons, one speaking, one listening     //  Create speaker beacon to broadcast our service     zactor_t *speaker = zactor_new (zbeacon, NULL);     assert (speaker);     if (verbose)         zstr_sendx (speaker, ""VERBOSE"", NULL);      zsock_send (speaker, ""si"", ""CONFIGURE"", 9999);     char *hostname = zstr_recv (speaker);     if (!*hostname) {         printf (""OK (skipping test, no UDP broadcasting)\n"");         zactor_destroy (&speaker);         free (hostname);         return;     }     free (hostname);      //  Create listener beacon on port 9999 to lookup service     zactor_t *listener = zactor_new (zbeacon, NULL);     assert (listener);     if (verbose)         zstr_sendx (listener, ""VERBOSE"", NULL);     zsock_send (listener, ""si"", ""CONFIGURE"", 9999);     hostname = zstr_recv (listener);     assert (*hostname);     free (hostname);      //  We will broadcast the magic value 0xCAFE     byte announcement [2] = { 0xCA, 0xFE };     zsock_send (speaker, ""sbi"", ""PUBLISH"", announcement, 2, 100);     //  We will listen to anything (empty subscription)     zsock_send (listener, ""sb"", ""SUBSCRIBE"", """", 0);      //  Wait for at most 1/2 second if there's no broadcasting     zsock_set_rcvtimeo (listener, 500);     char *ipaddress = zstr_recv (listener);     if (ipaddress) {         zframe_t *content = zframe_recv (listener);         assert (zframe_size (content) == 2);         assert (zframe_data (content) [0] == 0xCA);         assert (zframe_data (content) [1] == 0xFE);         zframe_destroy (&content);         zstr_free (&ipaddress);         zstr_sendx (speaker, ""SILENCE"", NULL);     }     zactor_destroy (&listener);     zactor_destroy (&speaker);      //  Test subscription filter using a 3-node setup     zactor_t *node1 = zactor_new (zbeacon, NULL);     assert (node1);     zsock_send (node1, ""si"", ""CONFIGURE"", 5670);     hostname = zstr_recv (node1);     assert (*hostname);     free (hostname);      zactor_t *node2 = zactor_new (zbeacon, NULL);     assert (node2);     zsock_send (node2, ""si"", ""CONFIGURE"", 5670);     hostname = zstr_recv (node2);     assert (*hostname);     free (hostname);      zactor_t *node3 = zactor_new (zbeacon, NULL);     assert (node3);     zsock_send (node3, ""si"", ""CONFIGURE"", 5670);     hostname = zstr_recv (node3);     assert (*hostname);     free (hostname);      zsock_send (node1, ""sbi"", ""PUBLISH"", ""NODE/1"", 6, 250);     zsock_send (node2, ""sbi"", ""PUBLISH"", ""NODE/2"", 6, 250);     zsock_send (node3, ""sbi"", ""PUBLISH"", ""RANDOM"", 6, 250);     zsock_send (node1, ""sb"", ""SUBSCRIBE"", ""NODE"", 4);      //  Poll on three API sockets at once     zpoller_t *poller = zpoller_new (node1, node2, node3, NULL);     assert (poller);     int64_t stop_at = zclock_mono () + 1000;     while (zclock_mono () < stop_at) {         long timeout = (long) (stop_at - zclock_mono ());         if (timeout < 0)             timeout = 0;         void *which = zpoller_wait (poller, timeout * ZMQ_POLL_MSEC);         if (which) {             assert (which == node1);             char *ipaddress, *received;             zstr_recvx (node1, &ipaddress, &received, NULL);             assert (streq (received, ""NODE/2""));             zstr_free (&ipaddress);             zstr_free (&received);         }     }     zpoller_destroy (&poller);      //  Stop listening     zstr_sendx (node1, ""UNSUBSCRIBE"", NULL);      //  Stop all node broadcasts     zstr_sendx (node1, ""SILENCE"", NULL);     zstr_sendx (node2, ""SILENCE"", NULL);     zstr_sendx (node3, ""SILENCE"", NULL);      //  Destroy the test nodes     zactor_destroy (&node1);     zactor_destroy (&node2);     zactor_destroy (&node3); zcert - work with CURVE security certificates The zcert class provides a way to create and work with security certificates for the ZMQ CURVE mechanism. A certificate contains a public + secret key pair, plus metadata. It can be used as a temporary object in memory, or persisted to disk. On disk, a certificate is stored as two files. One is public and contains only the public key. The second is secret and contains both keys. The two have the same filename, with the secret file adding ""_secret"". To exchange certificates, send the public file via some secure route. Certificates are not signed but are text files that can be verified by eye. Certificates are stored in the ZPL (ZMQ RFC 4) format. They have two sections, ""metadata"" and ""curve"". The first contains a list of 'name = value' pairs, one per line. Values may be enclosed in quotes. The curve section has a 'public-key = keyvalue' and, for secret certificates, a 'secret-key = keyvalue' line. The keyvalue is a Z85-encoded CURVE key. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     //  This class has draft methods, which may change over time. They are not     //  in stable releases, by default. Use --enable-drafts to enable.     //  This class has legacy methods, which will be removed over time. You     //  should not use them, and migrate any code that is still using them.     //  Create and initialize a new certificate in memory     CZMQ_EXPORT zcert_t *         zcert_new (void);      //  Accepts public/secret key pair from caller     CZMQ_EXPORT zcert_t *         zcert_new_from (const byte *public_key, const byte *secret_key);      //  Load certificate from file     CZMQ_EXPORT zcert_t *         zcert_load (const char *filename);      //  Destroy a certificate in memory     CZMQ_EXPORT void         zcert_destroy (zcert_t **self_p);      //  Return public part of key pair as 32-byte binary string     CZMQ_EXPORT const byte *         zcert_public_key (zcert_t *self);      //  Return secret part of key pair as 32-byte binary string     CZMQ_EXPORT const byte *         zcert_secret_key (zcert_t *self);      //  Return public part of key pair as Z85 armored string     CZMQ_EXPORT const char *         zcert_public_txt (zcert_t *self);      //  Return secret part of key pair as Z85 armored string     CZMQ_EXPORT const char *         zcert_secret_txt (zcert_t *self);      //  Set certificate metadata from formatted string.     CZMQ_EXPORT void         zcert_set_meta (zcert_t *self, const char *name, const char *format, ...);      //  Get metadata value from certificate; if the metadata value doesn't     //  exist, returns NULL.                                                   CZMQ_EXPORT const char *         zcert_meta (zcert_t *self, const char *name);      //  Get list of metadata fields from certificate. Caller is responsible for     //  destroying list. Caller should not modify the values of list items.         CZMQ_EXPORT zlist_t *         zcert_meta_keys (zcert_t *self);      //  Save full certificate (public + secret) to file for persistent storage       //  This creates one public file and one secret file (filename + ""_secret"").     CZMQ_EXPORT int         zcert_save (zcert_t *self, const char *filename);      //  Save public certificate only to file for persistent storage     CZMQ_EXPORT int         zcert_save_public (zcert_t *self, const char *filename);      //  Save secret certificate only to file for persistent storage     CZMQ_EXPORT int         zcert_save_secret (zcert_t *self, const char *filename);      //  Apply certificate to socket, i.e. use for CURVE security on socket.     //  If certificate was loaded from public file, the secret key will be      //  undefined, and this certificate will not work successfully.             CZMQ_EXPORT void         zcert_apply (zcert_t *self, void *socket);      //  Return copy of certificate; if certificate is NULL or we exhausted     //  heap memory, returns NULL.                                             //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zcert_t *         zcert_dup (zcert_t *self);      //  Return true if two certificates have the same keys     CZMQ_EXPORT bool         zcert_eq (zcert_t *self, zcert_t *compare);      //  Print certificate contents to stdout     CZMQ_EXPORT void         zcert_print (zcert_t *self);      //  *** Deprecated method, slated for removal: avoid using it ***     //  Print certificate contents to open stream. This method is deprecated     //  and you should use the print method.                                     CZMQ_EXPORT void         zcert_fprint (zcert_t *self, FILE *file);      //  Self test of this class     CZMQ_EXPORT void         zcert_test (bool verbose);      #ifdef CZMQ_BUILD_DRAFT_API     //  *** Draft method, for development use, may change without warning ***     //  Unset certificate metadata.     CZMQ_EXPORT void         zcert_unset_meta (zcert_t *self, const char *name);      #endif // CZMQ_BUILD_DRAFT_API This is the class self test code:     //  Create temporary directory for test files     #   define TESTDIR "".test_zcert""     zsys_dir_create (TESTDIR);      //  Create a simple certificate with metadata     zcert_t *cert = zcert_new ();     assert (cert);     zcert_set_meta (cert, ""email"", ""ph@imatix.com"");     zcert_set_meta (cert, ""name"", ""Pieter Hintjens"");     zcert_set_meta (cert, ""organization"", ""iMatix Corporation"");     zcert_set_meta (cert, ""version"", ""%d"", 1);     zcert_set_meta (cert, ""delete_me"", ""now"");     zcert_unset_meta (cert, ""delete_me"");     assert (streq (zcert_meta (cert, ""email""), ""ph@imatix.com""));     zlist_t *keys = zcert_meta_keys (cert);     assert (zlist_size (keys) == 4);     zlist_destroy (&keys);      //  Check the dup and eq methods     zcert_t *shadow = zcert_dup (cert);     assert (zcert_eq (cert, shadow));     zcert_destroy (&shadow);      //  Check we can save and load certificate     zcert_save (cert, TESTDIR ""/mycert.txt"");     assert (zsys_file_exists (TESTDIR ""/mycert.txt""));     assert (zsys_file_exists (TESTDIR ""/mycert.txt_secret""));      //  Load certificate, will in fact load secret one     shadow = zcert_load (TESTDIR ""/mycert.txt"");     assert (shadow);     assert (zcert_eq (cert, shadow));     zcert_destroy (&shadow);      //  Delete secret certificate, load public one     int rc = zsys_file_delete (TESTDIR ""/mycert.txt_secret"");     assert (rc == 0);     shadow = zcert_load (TESTDIR ""/mycert.txt"");      //  32-byte null key encodes as 40 '0' characters     assert (streq (zcert_secret_txt (shadow), FORTY_ZEROES));      zcert_destroy (&shadow);     zcert_destroy (&cert);      //  Delete all test files     zdir_t *dir = zdir_new (TESTDIR, NULL);     assert (dir);     zdir_remove (dir, true);     zdir_destroy (&dir); zcertstore - work with CURVE security certificate stores To authenticate new clients using the ZeroMQ CURVE security mechanism, we have to check that the client's public key matches a key we know and accept. There are numerous ways to store accepted client public keys. The mechanism CZMQ implements is ""certificates"" (plain text files) held in a ""certificate store"" (a disk directory). This class works with such certificate stores, and lets you easily load them from disk, and check if a given client public key is known or not. The zcert class does the work of managing a single certificate. The certificate store can be memory-only, in which case you can load it yourself by inserting certificate objects one by one, or it can be loaded from disk, in which case you can add, modify, or remove certificates on disk at any time, and the store will detect such changes and refresh itself automatically. In most applications you won't use this class directly but through the zauth class, which provides a high-level API for authentication (and manages certificate stores for you). To actually create certificates on disk, use the zcert class in code, or the tools/zmakecert.c command line tool, or any text editor. The format of a certificate file is defined in the zcert man page. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     //  This class has draft methods, which may change over time. They are not     //  in stable releases, by default. Use --enable-drafts to enable.     //  This class has legacy methods, which will be removed over time. You     //  should not use them, and migrate any code that is still using them.     //  Create a new certificate store from a disk directory, loading and             //  indexing all certificates in that location. The directory itself may be       //  absent, and created later, or modified at any time. The certificate store     //  is automatically refreshed on any zcertstore_lookup() call. If the            //  location is specified as NULL, creates a pure-memory store, which you         //  can work with by inserting certificates at runtime.                           CZMQ_EXPORT zcertstore_t *         zcertstore_new (const char *location);      //  Destroy a certificate store object in memory. Does not affect anything     //  stored on disk.                                                            CZMQ_EXPORT void         zcertstore_destroy (zcertstore_t **self_p);      //  Look up certificate by public key, returns zcert_t object if found,     //  else returns NULL. The public key is provided in Z85 text format.       CZMQ_EXPORT zcert_t *         zcertstore_lookup (zcertstore_t *self, const char *public_key);      //  Insert certificate into certificate store in memory. Note that this     //  does not save the certificate to disk. To do that, use zcert_save()     //  directly on the certificate. Takes ownership of zcert_t object.         CZMQ_EXPORT void         zcertstore_insert (zcertstore_t *self, zcert_t **cert_p);      //  Print list of certificates in store to logging facility     CZMQ_EXPORT void         zcertstore_print (zcertstore_t *self);      //  *** Deprecated method, slated for removal: avoid using it ***     //  Print list of certificates in store to open stream. This method is     //  deprecated, and you should use the print method.                       CZMQ_EXPORT void         zcertstore_fprint (zcertstore_t *self, FILE *file);      //  Self test of this class     CZMQ_EXPORT void         zcertstore_test (bool verbose);      #ifdef CZMQ_BUILD_DRAFT_API     // Loaders retrieve certificates from an arbitrary source.     typedef void (zcertstore_loader) (         zcertstore_t *self);      // Destructor for loader state.     typedef void (zcertstore_destructor) (         void **self_p);      //  *** Draft method, for development use, may change without warning ***     //  Override the default disk loader with a custom loader fn.     CZMQ_EXPORT void         zcertstore_set_loader (zcertstore_t *self, zcertstore_loader loader, zcertstore_destructor destructor, void *state);      //  *** Draft method, for development use, may change without warning ***     //  Empty certificate hashtable. This wrapper exists to be friendly to bindings,     //  which don't usually have access to struct internals.                             CZMQ_EXPORT void         zcertstore_empty (zcertstore_t *self);      #endif // CZMQ_BUILD_DRAFT_API This is the class self test code:     //  Create temporary directory for test files     #   define TESTDIR "".test_zcertstore""     zsys_dir_create (TESTDIR);      //  Load certificate store from disk; it will be empty     zcertstore_t *certstore = zcertstore_new (TESTDIR);     assert (certstore);      //  Create a single new certificate and save to disk     zcert_t *cert = zcert_new ();     assert (cert);     char *client_key = strdup (zcert_public_txt (cert));     assert (client_key);     zcert_set_meta (cert, ""name"", ""John Doe"");     zcert_save (cert, TESTDIR ""/mycert.txt"");     zcert_destroy (&cert);      //  Check that certificate store refreshes as expected     cert = zcertstore_lookup (certstore, client_key);     assert (cert);     assert (streq (zcert_meta (cert, ""name""), ""John Doe""));      //  Test custom loader     test_loader_state *state = (test_loader_state *) zmalloc (sizeof (test_loader_state));     state->index = 0;     zcertstore_set_loader (certstore, s_test_loader, s_test_destructor, (void *)state);     #if (ZMQ_VERSION_MAJOR >= 4)     cert = zcertstore_lookup (certstore, client_key);     assert (cert == NULL);     cert = zcertstore_lookup (certstore, ""abcdefghijklmnopqrstuvwxyzabcdefghijklmn"");     assert (cert);     #endif      free (client_key);      if (verbose)         zcertstore_print (certstore);     zcertstore_destroy (&certstore);      //  Delete all test files     zdir_t *dir = zdir_new (TESTDIR, NULL);     assert (dir);     zdir_remove (dir, true);     zdir_destroy (&dir); zchunk - work with memory chunks The zchunk class works with variable sized blobs. Not as efficient as ZeroMQ's messages but they do less weirdness and so are easier to understand. The chunk class has methods to read and write chunks from disk. Please add @discuss section in ../src/zchunk.c. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     //  Create a new chunk of the specified size. If you specify the data, it        //  is copied into the chunk. If you do not specify the data, the chunk is       //  allocated and left empty, and you can then add data using zchunk_append.     CZMQ_EXPORT zchunk_t *         zchunk_new (const void *data, size_t size);      //  Destroy a chunk     CZMQ_EXPORT void         zchunk_destroy (zchunk_t **self_p);      //  Resizes chunk max_size as requested; chunk_cur size is set to zero     CZMQ_EXPORT void         zchunk_resize (zchunk_t *self, size_t size);      //  Return chunk cur size     CZMQ_EXPORT size_t         zchunk_size (zchunk_t *self);      //  Return chunk max size     CZMQ_EXPORT size_t         zchunk_max_size (zchunk_t *self);      //  Return chunk data     CZMQ_EXPORT byte *         zchunk_data (zchunk_t *self);      //  Set chunk data from user-supplied data; truncate if too large. Data may     //  be null. Returns actual size of chunk                                       CZMQ_EXPORT size_t         zchunk_set (zchunk_t *self, const void *data, size_t size);      //  Fill chunk data from user-supplied octet     CZMQ_EXPORT size_t         zchunk_fill (zchunk_t *self, byte filler, size_t size);      //  Append user-supplied data to chunk, return resulting chunk size. If the      //  data would exceeded the available space, it is truncated. If you want to     //  grow the chunk to accommodate new data, use the zchunk_extend method.        CZMQ_EXPORT size_t         zchunk_append (zchunk_t *self, const void *data, size_t size);      //  Append user-supplied data to chunk, return resulting chunk size. If the     //  data would exceeded the available space, the chunk grows in size.           CZMQ_EXPORT size_t         zchunk_extend (zchunk_t *self, const void *data, size_t size);      //  Copy as much data from 'source' into the chunk as possible; returns the       //  new size of chunk. If all data from 'source' is used, returns exhausted       //  on the source chunk. Source can be consumed as many times as needed until     //  it is exhausted. If source was already exhausted, does not change chunk.      CZMQ_EXPORT size_t         zchunk_consume (zchunk_t *self, zchunk_t *source);      //  Returns true if the chunk was exhausted by consume methods, or if the     //  chunk has a size of zero.                                                 CZMQ_EXPORT bool         zchunk_exhausted (zchunk_t *self);      //  Read chunk from an open file descriptor     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zchunk_t *         zchunk_read (FILE *handle, size_t bytes);      //  Write chunk to an open file descriptor     CZMQ_EXPORT int         zchunk_write (zchunk_t *self, FILE *handle);      //  Try to slurp an entire file into a chunk. Will read up to maxsize of       //  the file. If maxsize is 0, will attempt to read the entire file and        //  fail with an assertion if that cannot fit into memory. Returns a new       //  chunk containing the file data, or NULL if the file could not be read.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zchunk_t *         zchunk_slurp (const char *filename, size_t maxsize);      //  Create copy of chunk, as new chunk object. Returns a fresh zchunk_t        //  object, or null if there was not enough heap memory. If chunk is null,     //  returns null.                                                              //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zchunk_t *         zchunk_dup (zchunk_t *self);      //  Return chunk data encoded as printable hex string. Caller must free     //  string when finished with it.                                           //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zchunk_strhex (zchunk_t *self);      //  Return chunk data copied into freshly allocated string     //  Caller must free string when finished with it.             //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zchunk_strdup (zchunk_t *self);      //  Return TRUE if chunk body is equal to string, excluding terminator     CZMQ_EXPORT bool         zchunk_streq (zchunk_t *self, const char *string);      //  Transform zchunk into a zframe that can be sent in a message.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zframe_t *         zchunk_pack (zchunk_t *self);      //  Transform a zframe into a zchunk.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zchunk_t *         zchunk_unpack (zframe_t *frame);      //  Calculate SHA1 digest for chunk, using zdigest class.     CZMQ_EXPORT const char *         zchunk_digest (zchunk_t *self);      //  Dump chunk to FILE stream, for debugging and tracing.     CZMQ_EXPORT void         zchunk_fprint (zchunk_t *self, FILE *file);      //  Dump message to stderr, for debugging and tracing.     //  See zchunk_fprint for details                          CZMQ_EXPORT void         zchunk_print (zchunk_t *self);      //  Probe the supplied object, and report if it looks like a zchunk_t.     CZMQ_EXPORT bool         zchunk_is (void *self);      //  Self test of this class.     CZMQ_EXPORT void         zchunk_test (bool verbose);  This is the class self test code:     zchunk_t *chunk = zchunk_new (""1234567890"", 10);     assert (chunk);     assert (zchunk_size (chunk) == 10);     assert (memcmp (zchunk_data (chunk), ""1234567890"", 10) == 0);     zchunk_destroy (&chunk);      chunk = zchunk_new (NULL, 10);     assert (chunk);     zchunk_append (chunk, ""12345678"", 8);     zchunk_append (chunk, ""90ABCDEF"", 8);     zchunk_append (chunk, ""GHIJKLMN"", 8);     assert (memcmp (zchunk_data (chunk), ""1234567890"", 10) == 0);     assert (zchunk_size (chunk) == 10);     assert (zchunk_streq (chunk, ""1234567890""));     assert (streq (zchunk_digest (chunk), ""01B307ACBA4F54F55AAFC33BB06BBBF6CA803E9A""));     char *string = zchunk_strdup (chunk);     assert (streq (string, ""1234567890""));     free (string);     string = zchunk_strhex (chunk);     assert (streq (string, ""31323334353637383930""));     free (string);      zframe_t *frame = zchunk_pack (chunk);     assert (frame);      zchunk_t *chunk2 = zchunk_unpack (frame);     assert (chunk2);     assert (memcmp (zchunk_data (chunk2), ""1234567890"", 10) == 0);     zframe_destroy (&frame);     zchunk_destroy (&chunk2);      zchunk_t *copy = zchunk_dup (chunk);     assert (copy);     assert (memcmp (zchunk_data (copy), ""1234567890"", 10) == 0);     assert (zchunk_size (copy) == 10);     zchunk_destroy (&copy);     zchunk_destroy (&chunk);      chunk = zchunk_new (NULL, 0);     zchunk_extend (chunk, ""12345678"", 8);     zchunk_extend (chunk, ""90ABCDEF"", 8);     zchunk_extend (chunk, ""GHIJKLMN"", 8);     assert (zchunk_size (chunk) == 24);     assert (zchunk_streq (chunk, ""1234567890ABCDEFGHIJKLMN""));     zchunk_destroy (&chunk);      copy = zchunk_new (""1234567890abcdefghij"", 20);     assert (copy);     chunk = zchunk_new (NULL, 8);     assert (chunk);     zchunk_consume (chunk, copy);     assert (!zchunk_exhausted (copy));     assert (memcmp (zchunk_data (chunk), ""12345678"", 8) == 0);     zchunk_set (chunk, NULL, 0);     zchunk_consume (chunk, copy);     assert (!zchunk_exhausted (copy));     assert (memcmp (zchunk_data (chunk), ""90abcdef"", 8) == 0);     zchunk_set (chunk, NULL, 0);     zchunk_consume (chunk, copy);     assert (zchunk_exhausted (copy));     assert (zchunk_size (chunk) == 4);     assert (memcmp (zchunk_data (chunk), ""ghij"", 4) == 0);     zchunk_destroy (&copy);     zchunk_destroy (&chunk); zclock - millisecond clocks and delays The zclock class provides essential sleep and system time functions, used to slow down threads for testing, and calculate timers for polling. Wraps the non-portable system calls in a simple portable API. The Win32 Sleep() call defaults to 16ms resolution unless the system timer resolution is increased with a call to timeBeginPeriod() permitting 1ms granularity. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     //  Sleep for a number of milliseconds     CZMQ_EXPORT void         zclock_sleep (int msecs);      //  Return current system clock as milliseconds. Note that this clock can       //  jump backwards (if the system clock is changed) so is unsafe to use for     //  timers and time offsets. Use zclock_mono for that instead.                  CZMQ_EXPORT int64_t         zclock_time (void);      //  Return current monotonic clock in milliseconds. Use this when you compute     //  time offsets. The monotonic clock is not affected by system changes and       //  so will never be reset backwards, unlike a system clock.                      CZMQ_EXPORT int64_t         zclock_mono (void);      //  Return current monotonic clock in microseconds. Use this when you compute     //  time offsets. The monotonic clock is not affected by system changes and       //  so will never be reset backwards, unlike a system clock.                      CZMQ_EXPORT int64_t         zclock_usecs (void);      //  Return formatted date/time as fresh string. Free using zstr_free().     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zclock_timestr (void);      //  Self test of this class.     CZMQ_EXPORT void         zclock_test (bool verbose);  This is the class self test code:     int64_t start = zclock_time ();     zclock_sleep (10);     assert ((zclock_time () - start) >= 10);     start = zclock_mono ();     int64_t usecs = zclock_usecs ();     zclock_sleep (10);     assert ((zclock_mono () - start) >= 10);     assert ((zclock_usecs () - usecs) >= 10000);     char *timestr = zclock_timestr ();     if (verbose)         puts (timestr);     free (timestr); zconfig - work with config files written in rfc.zeromq.org/spec:4/ZPL. Lets applications load, work with, and save configuration files. This implements rfc.zeromq.org/spec:4/ZPL, which is a simple structured text format for configuration files. Here is an example ZPL stream and corresponding config structure: context     iothreads = 1     verbose = 1      #   Ask for a trace main     type = zqueue    #  ZMQ_DEVICE type     frontend         option             hwm = 1000             swap = 25000000     #  25MB         bind = 'inproc://addr1'         bind = 'ipc://addr2'     backend         bind = inproc://addr3  root                    Down = child |                     Across = next v context-->main |         | |         v |       type=queue-->frontend-->backend |                      |          | |                      |          v |                      |        bind=inproc://addr3 |                      v |                    option-->bind=inproc://addr1-->bind=ipc://addr2 |                      | |                      v |                    hwm=1000-->swap=25000000 v iothreads=1-->verbose=false  This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     //      typedef int (zconfig_fct) (         zconfig_t *self, void *arg, int level);      //  Create new config item     CZMQ_EXPORT zconfig_t *         zconfig_new (const char *name, zconfig_t *parent);      //  Load a config tree from a specified ZPL text file; returns a zconfig_t       //  reference for the root, if the file exists and is readable. Returns NULL     //  if the file does not exist.                                                  CZMQ_EXPORT zconfig_t *         zconfig_load (const char *filename);      //  Equivalent to zconfig_load, taking a format string instead of a fixed     //  filename.                                                                 CZMQ_EXPORT zconfig_t *         zconfig_loadf (const char *format, ...);      //  Destroy a config item and all its children     CZMQ_EXPORT void         zconfig_destroy (zconfig_t **self_p);      //  Return name of config item     CZMQ_EXPORT char *         zconfig_name (zconfig_t *self);      //  Return value of config item     CZMQ_EXPORT char *         zconfig_value (zconfig_t *self);      //  Insert or update configuration key with value     CZMQ_EXPORT void         zconfig_put (zconfig_t *self, const char *path, const char *value);      //  Equivalent to zconfig_put, accepting a format specifier and variable     //  argument list, instead of a single string value.                         CZMQ_EXPORT void         zconfig_putf (zconfig_t *self, const char *path, const char *format, ...);      //  Get value for config item into a string value; leading slash is optional     //  and ignored.                                                                 CZMQ_EXPORT char *         zconfig_get (zconfig_t *self, const char *path, const char *default_value);      //  Set config item name, name may be NULL     CZMQ_EXPORT void         zconfig_set_name (zconfig_t *self, const char *name);      //  Set new value for config item. The new value may be a string, a printf       //  format, or NULL. Note that if string may possibly contain '%', or if it      //  comes from an insecure source, you must use '%s' as the format, followed     //  by the string.                                                               CZMQ_EXPORT void         zconfig_set_value (zconfig_t *self, const char *format, ...);      //  Find our first child, if any     CZMQ_EXPORT zconfig_t *         zconfig_child (zconfig_t *self);      //  Find our first sibling, if any     CZMQ_EXPORT zconfig_t *         zconfig_next (zconfig_t *self);      //  Find a config item along a path; leading slash is optional and ignored.     CZMQ_EXPORT zconfig_t *         zconfig_locate (zconfig_t *self, const char *path);      //  Locate the last config item at a specified depth     CZMQ_EXPORT zconfig_t *         zconfig_at_depth (zconfig_t *self, int level);      //  Execute a callback for each config item in the tree; returns zero if     //  successful, else -1.                                                     CZMQ_EXPORT int         zconfig_execute (zconfig_t *self, zconfig_fct handler, void *arg);      //  Add comment to config item before saving to disk. You can add as many     //  comment lines as you like. If you use a null format, all comments are     //  deleted.                                                                  CZMQ_EXPORT void         zconfig_set_comment (zconfig_t *self, const char *format, ...);      //  Return comments of config item, as zlist.     CZMQ_EXPORT zlist_t *         zconfig_comments (zconfig_t *self);      //  Save a config tree to a specified ZPL text file, where a filename     //  ""-"" means dump to standard output.                                    CZMQ_EXPORT int         zconfig_save (zconfig_t *self, const char *filename);      //  Equivalent to zconfig_save, taking a format string instead of a fixed     //  filename.                                                                 CZMQ_EXPORT int         zconfig_savef (zconfig_t *self, const char *format, ...);      //  Report filename used during zconfig_load, or NULL if none     CZMQ_EXPORT const char *         zconfig_filename (zconfig_t *self);      //  Reload config tree from same file that it was previously loaded from.     //  Returns 0 if OK, -1 if there was an error (and then does not change       //  existing data).                                                           CZMQ_EXPORT int         zconfig_reload (zconfig_t **self_p);      //  Load a config tree from a memory chunk     CZMQ_EXPORT zconfig_t *         zconfig_chunk_load (zchunk_t *chunk);      //  Save a config tree to a new memory chunk     CZMQ_EXPORT zchunk_t *         zconfig_chunk_save (zconfig_t *self);      //  Load a config tree from a null-terminated string     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zconfig_t *         zconfig_str_load (const char *string);      //  Save a config tree to a new null terminated string     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zconfig_str_save (zconfig_t *self);      //  Return true if a configuration tree was loaded from a file and that     //  file has changed in since the tree was loaded.                          CZMQ_EXPORT bool         zconfig_has_changed (zconfig_t *self);      //  Print the config file to open stream     CZMQ_EXPORT void         zconfig_fprint (zconfig_t *self, FILE *file);      //  Print properties of object     CZMQ_EXPORT void         zconfig_print (zconfig_t *self);      //  Self test of this class     CZMQ_EXPORT void         zconfig_test (bool verbose);  This is the class self test code:     //  Create temporary directory for test files     #   define TESTDIR "".test_zconfig""     zsys_dir_create (TESTDIR);      zconfig_t *root = zconfig_new (""root"", NULL);     assert (root);     zconfig_t *section, *item;      section = zconfig_new (""headers"", root);     assert (section);     item = zconfig_new (""email"", section);     assert (item);     zconfig_set_value (item, ""some@random.com"");     item = zconfig_new (""name"", section);     assert (item);     zconfig_set_value (item, ""Justin Kayce"");     zconfig_putf (root, ""/curve/secret-key"", ""%s"", ""Top Secret"");     zconfig_set_comment (root, ""   CURVE certificate"");     zconfig_set_comment (root, ""   -----------------"");     assert (zconfig_comments (root));     zconfig_save (root, TESTDIR ""/test.cfg"");     zconfig_destroy (&root);     root = zconfig_load (TESTDIR ""/test.cfg"");     if (verbose)         zconfig_save (root, ""-"");     assert (streq (zconfig_filename (root), TESTDIR ""/test.cfg""));      char *email = zconfig_get (root, ""/headers/email"", NULL);     assert (email);     assert (streq (email, ""some@random.com""));     char *passwd = zconfig_get (root, ""/curve/secret-key"", NULL);     assert (passwd);     assert (streq (passwd, ""Top Secret""));      zconfig_savef (root, ""%s/%s"", TESTDIR, ""test.cfg"");     assert (!zconfig_has_changed (root));     int rc = zconfig_reload (&root);     assert (rc == 0);     assert (!zconfig_has_changed (root));     zconfig_destroy (&root);      //  Test chunk load/save     root = zconfig_new (""root"", NULL);     assert (root);     section = zconfig_new (""section"", root);     assert (section);     item = zconfig_new (""value"", section);     assert (item);     zconfig_set_value (item, ""somevalue"");     zconfig_t *search = zconfig_locate (root, ""section/value"");     assert (search == item);     zchunk_t *chunk = zconfig_chunk_save (root);     assert (strlen ((char *) zchunk_data (chunk)) == 32);     char *string = zconfig_str_save (root);     assert (string);     assert (streq (string, (char *) zchunk_data (chunk)));     free (string);     assert (chunk);     zconfig_destroy (&root);      root = zconfig_chunk_load (chunk);     assert (root);     char *value = zconfig_get (root, ""/section/value"", NULL);     assert (value);     assert (streq (value, ""somevalue""));      //  Test config can't be saved to a file in a path that doesn't     //  exist or isn't writable     rc = zconfig_savef (root, ""%s/path/that/doesnt/exist/%s"", TESTDIR, ""test.cfg"");     assert (rc == -1);      zconfig_destroy (&root);     zchunk_destroy (&chunk);      //  Delete all test files     zdir_t *dir = zdir_new (TESTDIR, NULL);     assert (dir);     zdir_remove (dir, true);     zdir_destroy (&dir); zdigest - provides hashing functions (SHA-1 at present) The zdigest class generates a hash from zchunks of data. The current algorithm is SHA-1, chosen for speed. We are aiming to generate a unique digest for a file, and there are no security issues in this use case. The current code depends on OpenSSL, which might be replaced by hard coded SHA-1 implementation to reduce build dependencies. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     //  Constructor - creates new digest object, which you use to build up a     //  digest by repeatedly calling zdigest_update() on chunks of data.         CZMQ_EXPORT zdigest_t *         zdigest_new (void);      //  Destroy a digest object     CZMQ_EXPORT void         zdigest_destroy (zdigest_t **self_p);      //  Add buffer into digest calculation     CZMQ_EXPORT void         zdigest_update (zdigest_t *self, const byte *buffer, size_t length);      //  Return final digest hash data. If built without crypto support,     //  returns NULL.                                                       CZMQ_EXPORT const byte *         zdigest_data (zdigest_t *self);      //  Return final digest hash size     CZMQ_EXPORT size_t         zdigest_size (zdigest_t *self);      //  Return digest as printable hex string; caller should not modify nor        //  free this string. After calling this, you may not use zdigest_update()     //  on the same digest. If built without crypto support, returns NULL.         CZMQ_EXPORT char *         zdigest_string (zdigest_t *self);      //  Self test of this class.     CZMQ_EXPORT void         zdigest_test (bool verbose);  This is the class self test code:     byte *buffer = (byte *) zmalloc (1024);     memset (buffer, 0xAA, 1024);      zdigest_t *digest = zdigest_new ();     assert (digest);     zdigest_update (digest, buffer, 1024);     const byte *data = zdigest_data (digest);     assert (data [0] == 0xDE);     assert (data [1] == 0xB2);     assert (data [2] == 0x38);     assert (data [3] == 0x07);     assert (streq (zdigest_string (digest),                    ""DEB23807D4FE025E900FE9A9C7D8410C3DDE9671""));     zdigest_destroy (&digest);     free (buffer); zdir - work with file-system directories The zdir class gives access to the file system index. It will load a directory tree (a directory plus all child directories) into a zdir structure and then let you navigate that structure. It exists mainly to wrap non-portable OS functions to do this. Please add @discuss section in ../src/zdir.c. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     //  Create a new directory item that loads in the full tree of the specified     //  path, optionally located under some parent path. If parent is ""-"", then      //  loads only the top-level directory, and does not use parent as a path.       CZMQ_EXPORT zdir_t *         zdir_new (const char *path, const char *parent);      //  Destroy a directory tree and all children it contains.     CZMQ_EXPORT void         zdir_destroy (zdir_t **self_p);      //  Return directory path     CZMQ_EXPORT const char *         zdir_path (zdir_t *self);      //  Return last modification time for directory.     CZMQ_EXPORT time_t         zdir_modified (zdir_t *self);      //  Return total hierarchy size, in bytes of data contained in all files     //  in the directory tree.                                                   CZMQ_EXPORT off_t         zdir_cursize (zdir_t *self);      //  Return directory count     CZMQ_EXPORT size_t         zdir_count (zdir_t *self);      //  Returns a sorted list of zfile objects; Each entry in the list is a pointer     //  to a zfile_t item already allocated in the zdir tree. Do not destroy the        //  original zdir tree until you are done with this list.                           //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zlist_t *         zdir_list (zdir_t *self);      //  Remove directory, optionally including all files that it contains, at       //  all levels. If force is false, will only remove the directory if empty.     //  If force is true, will remove all files and all subdirectories.             CZMQ_EXPORT void         zdir_remove (zdir_t *self, bool force);      //  Calculate differences between two versions of a directory tree.         //  Returns a list of zdir_patch_t patches. Either older or newer may       //  be null, indicating the directory is empty/absent. If alias is set,     //  generates virtual filename (minus path, plus alias).                    //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zlist_t *         zdir_diff (zdir_t *older, zdir_t *newer, const char *alias);      //  Return full contents of directory as a zdir_patch list.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zlist_t *         zdir_resync (zdir_t *self, const char *alias);      //  Load directory cache; returns a hash table containing the SHA-1 digests     //  of every file in the tree. The cache is saved between runs in .cache.       //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zhash_t *         zdir_cache (zdir_t *self);      //  Print contents of directory to open stream     CZMQ_EXPORT void         zdir_fprint (zdir_t *self, FILE *file, int indent);      //  Print contents of directory to stdout     CZMQ_EXPORT void         zdir_print (zdir_t *self, int indent);      //  Create a new zdir_watch actor instance:                            //                                                                     //      zactor_t *watch = zactor_new (zdir_watch, NULL);               //                                                                     //  Destroy zdir_watch instance:                                       //                                                                     //      zactor_destroy (&watch);                                       //                                                                     //  Enable verbose logging of commands and activity:                   //                                                                     //      zstr_send (watch, ""VERBOSE"");                                  //                                                                     //  Subscribe to changes to a directory path:                          //                                                                     //      zsock_send (watch, ""ss"", ""SUBSCRIBE"", ""directory_path"");       //                                                                     //  Unsubscribe from changes to a directory path:                      //                                                                     //      zsock_send (watch, ""ss"", ""UNSUBSCRIBE"", ""directory_path"");     //                                                                     //  Receive directory changes:                                         //      zsock_recv (watch, ""sp"", &path, &patches);                     //                                                                     //      // Delete the received data.                                   //      free (path);                                                   //      zlist_destroy (&patches);                                      CZMQ_EXPORT void         zdir_watch (zsock_t *pipe, void *unused);      //  Self test of this class.     CZMQ_EXPORT void         zdir_test (bool verbose);  This is the class self test code:     // need to create a file in the test directory we're watching     // in order to ensure the directory exists     zfile_t *initfile = zfile_new (""./zdir-test-dir"", ""initial_file"");     assert (initfile);     zfile_output (initfile);     fprintf (zfile_handle (initfile), ""initial file\n"");     zfile_close (initfile);     zfile_destroy (&initfile);      zdir_t *older = zdir_new (""zdir-test-dir"", NULL);     assert (older);     if (verbose) {         printf (""\n"");         zdir_dump (older, 0);     }     zdir_t *newer = zdir_new (""."", NULL);     assert (newer);     zlist_t *patches = zdir_diff (older, newer, ""/"");     assert (patches);     while (zlist_size (patches)) {         zdir_patch_t *patch = (zdir_patch_t *) zlist_pop (patches);         zdir_patch_destroy (&patch);     }     zlist_destroy (&patches);     zdir_destroy (&older);     zdir_destroy (&newer);      zdir_t *nosuch = zdir_new (""does-not-exist"", NULL);     assert (nosuch == NULL);      // zdir_watch test:     zactor_t *watch = zactor_new (zdir_watch, NULL);     assert (watch);      if (verbose) {         zsock_send (watch, ""s"", ""VERBOSE"");         assert (zsock_wait (watch) == 0);     }      zclock_sleep (1001); // wait for initial file to become 'stable'      zsock_send (watch, ""si"", ""TIMEOUT"", 100);     assert (zsock_wait (watch) == 0);      zsock_send (watch, ""ss"", ""SUBSCRIBE"", ""zdir-test-dir"");     assert (zsock_wait (watch) == 0);      zsock_send (watch, ""ss"", ""UNSUBSCRIBE"", ""zdir-test-dir"");     assert (zsock_wait (watch) == 0);      zsock_send (watch, ""ss"", ""SUBSCRIBE"", ""zdir-test-dir"");     assert (zsock_wait (watch) == 0);      zfile_t *newfile = zfile_new (""zdir-test-dir"", ""test_abc"");     zfile_output (newfile);     fprintf (zfile_handle (newfile), ""test file\n"");     zfile_close (newfile);      zpoller_t *watch_poll = zpoller_new (watch, NULL);      // poll for a certain timeout before giving up and failing the test.     assert (zpoller_wait (watch_poll, 1001) == watch);      // wait for notification of the file being added     char *path;     int rc = zsock_recv (watch, ""sp"", &path, &patches);     assert (rc == 0);      assert (streq (path, ""zdir-test-dir""));     free (path);      assert (zlist_size (patches) == 1);      zdir_patch_t *patch = (zdir_patch_t *) zlist_pop (patches);     assert (streq (zdir_patch_path (patch), ""zdir-test-dir""));      zfile_t *patch_file = zdir_patch_file (patch);     assert (streq (zfile_filename (patch_file, """"), ""zdir-test-dir/test_abc""));      zdir_patch_destroy (&patch);     zlist_destroy (&patches);      // remove the file     zfile_remove (newfile);     zfile_destroy (&newfile);      // poll for a certain timeout before giving up and failing the test.     assert (zpoller_wait (watch_poll, 1001) == watch);      // wait for notification of the file being removed     rc = zsock_recv (watch, ""sp"", &path, &patches);     assert (rc == 0);      assert (streq (path, ""zdir-test-dir""));     free (path);      assert (zlist_size (patches) == 1);      patch = (zdir_patch_t *) zlist_pop (patches);     assert (streq (zdir_patch_path (patch), ""zdir-test-dir""));      patch_file = zdir_patch_file (patch);     assert (streq (zfile_filename (patch_file, """"), ""zdir-test-dir/test_abc""));      zdir_patch_destroy (&patch);     zlist_destroy (&patches);      zpoller_destroy (&watch_poll);     zactor_destroy (&watch);      // clean up by removing the test directory.     zdir_t *testdir = zdir_new (""zdir-test-dir"", NULL);     zdir_remove (testdir, true);     zdir_destroy (&testdir); zdir_patch - work with directory patches The zdir_patch class works with one patch, which says ""create this file"" or ""delete this file"" (referring to a zfile item each time). Please add @discuss section in ../src/zdir_patch.c. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     #define ZDIR_PATCH_CREATE 1                 // Creates a new file     #define ZDIR_PATCH_DELETE 2                 // Delete a file      //  Create new patch     CZMQ_EXPORT zdir_patch_t *         zdir_patch_new (const char *path, zfile_t *file, int op, const char *alias);      //  Destroy a patch     CZMQ_EXPORT void         zdir_patch_destroy (zdir_patch_t **self_p);      //  Create copy of a patch. If the patch is null, or memory was exhausted,     //  returns null.                                                              //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zdir_patch_t *         zdir_patch_dup (zdir_patch_t *self);      //  Return patch file directory path     CZMQ_EXPORT const char *         zdir_patch_path (zdir_patch_t *self);      //  Return patch file item     CZMQ_EXPORT zfile_t *         zdir_patch_file (zdir_patch_t *self);      //  Return operation     CZMQ_EXPORT int         zdir_patch_op (zdir_patch_t *self);      //  Return patch virtual file path     CZMQ_EXPORT const char *         zdir_patch_vpath (zdir_patch_t *self);      //  Calculate hash digest for file (create only)     CZMQ_EXPORT void         zdir_patch_digest_set (zdir_patch_t *self);      //  Return hash digest for patch file     CZMQ_EXPORT const char *         zdir_patch_digest (zdir_patch_t *self);      //  Self test of this class.     CZMQ_EXPORT void         zdir_patch_test (bool verbose);  This is the class self test code:     zfile_t *file = zfile_new (""."", ""bilbo"");     assert (file);     zdir_patch_t *patch = zdir_patch_new (""."", file, patch_create, ""/"");     assert (patch);     zfile_destroy (&file);      file = zdir_patch_file (patch);     assert (file);     assert (streq (zfile_filename (file, "".""), ""bilbo""));     assert (streq (zdir_patch_vpath (patch), ""/bilbo""));     zdir_patch_destroy (&patch); zfile - provides methods to work with files in a portable fashion. The zfile class provides methods to work with disk files. A file object provides the modified date, current size, and type of the file. You can create a file object for a filename that does not yet exist. To read or write data from the file, use the input and output methods, and then read and write chunks. The output method lets you both read and write chunks, at any offset. Finally, this class provides portable symbolic links. If a filename ends in "".ln"", the first line of text in the file is read, and used as the underlying file for read/write operations. This lets you manipulate (e.g.) copy symbolic links without copying the perhaps very large files they point to. This class is a new API, deprecating the old zfile class (which still exists but is implemented in zsys now). This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     //  If file exists, populates properties. CZMQ supports portable symbolic     //  links, which are files with the extension "".ln"". A symbolic link is a     //  text file containing one line, the filename of a target file. Reading     //  data from the symbolic link actually reads from the target file. Path     //  may be NULL, in which case it is not used.                                CZMQ_EXPORT zfile_t *         zfile_new (const char *path, const char *name);      //  Destroy a file item     CZMQ_EXPORT void         zfile_destroy (zfile_t **self_p);      //  Duplicate a file item, returns a newly constructed item. If the file     //  is null, or memory was exhausted, returns null.                          //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zfile_t *         zfile_dup (zfile_t *self);      //  Return file name, remove path if provided     CZMQ_EXPORT const char *         zfile_filename (zfile_t *self, const char *path);      //  Refresh file properties from disk; this is not done automatically        //  on access methods, otherwise it is not possible to compare directory     //  snapshots.                                                               CZMQ_EXPORT void         zfile_restat (zfile_t *self);      //  Return when the file was last modified. If you want this to reflect the     //  current situation, call zfile_restat before checking this property.         CZMQ_EXPORT time_t         zfile_modified (zfile_t *self);      //  Return the last-known size of the file. If you want this to reflect the     //  current situation, call zfile_restat before checking this property.         CZMQ_EXPORT off_t         zfile_cursize (zfile_t *self);      //  Return true if the file is a directory. If you want this to reflect        //  any external changes, call zfile_restat before checking this property.     CZMQ_EXPORT bool         zfile_is_directory (zfile_t *self);      //  Return true if the file is a regular file. If you want this to reflect     //  any external changes, call zfile_restat before checking this property.     CZMQ_EXPORT bool         zfile_is_regular (zfile_t *self);      //  Return true if the file is readable by this process. If you want this to     //  reflect any external changes, call zfile_restat before checking this         //  property.                                                                    CZMQ_EXPORT bool         zfile_is_readable (zfile_t *self);      //  Return true if the file is writeable by this process. If you want this      //  to reflect any external changes, call zfile_restat before checking this     //  property.                                                                   CZMQ_EXPORT bool         zfile_is_writeable (zfile_t *self);      //  Check if file has stopped changing and can be safely processed.     //  Updates the file statistics from disk at every call.                CZMQ_EXPORT bool         zfile_is_stable (zfile_t *self);      //  Return true if the file was changed on disk since the zfile_t object     //  was created, or the last zfile_restat() call made on it.                 CZMQ_EXPORT bool         zfile_has_changed (zfile_t *self);      //  Remove the file from disk     CZMQ_EXPORT void         zfile_remove (zfile_t *self);      //  Open file for reading                                  //  Returns 0 if OK, -1 if not found or not accessible     CZMQ_EXPORT int         zfile_input (zfile_t *self);      //  Open file for writing, creating directory if needed                    //  File is created if necessary; chunks can be written to file at any     //  location. Returns 0 if OK, -1 if error.                                CZMQ_EXPORT int         zfile_output (zfile_t *self);      //  Read chunk from file at specified position. If this was the last chunk,     //  sets the eof property. Returns a null chunk in case of error.               //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zchunk_t *         zfile_read (zfile_t *self, size_t bytes, off_t offset);      //  Returns true if zfile_read() just read the last chunk in the file.     CZMQ_EXPORT bool         zfile_eof (zfile_t *self);      //  Write chunk to file at specified position     //  Return 0 if OK, else -1                       CZMQ_EXPORT int         zfile_write (zfile_t *self, zchunk_t *chunk, off_t offset);      //  Read next line of text from file. Returns a pointer to the text line,     //  or NULL if there was nothing more to read from the file.                  CZMQ_EXPORT const char *         zfile_readln (zfile_t *self);      //  Close file, if open     CZMQ_EXPORT void         zfile_close (zfile_t *self);      //  Return file handle, if opened     CZMQ_EXPORT FILE *         zfile_handle (zfile_t *self);      //  Calculate SHA1 digest for file, using zdigest class.     CZMQ_EXPORT const char *         zfile_digest (zfile_t *self);      //  Self test of this class.     CZMQ_EXPORT void         zfile_test (bool verbose);      //  These methods are deprecated, and now moved to zsys class.     CZMQ_EXPORT bool         zfile_exists (const char *filename);     CZMQ_EXPORT ssize_t         zfile_size   (const char *filename);     CZMQ_EXPORT mode_t         zfile_mode   (const char *filename);     CZMQ_EXPORT int         zfile_delete (const char *filename);     CZMQ_EXPORT bool         zfile_stable (const char *filename);     CZMQ_EXPORT int         zfile_mkdir  (const char *pathname);     CZMQ_EXPORT int         zfile_rmdir  (const char *pathname);     CZMQ_EXPORT void         zfile_mode_private (void);     CZMQ_EXPORT void         zfile_mode_default (void); This is the class self test code:     zfile_t *file = zfile_new (NULL, ""bilbo"");     assert (file);     assert (streq (zfile_filename (file, "".""), ""bilbo""));     assert (zfile_is_readable (file) == false);     zfile_destroy (&file);      //  Create a test file in some random subdirectory     file = zfile_new (""./this/is/a/test"", ""bilbo"");     assert (file);     int rc = zfile_output (file);     assert (rc == 0);     zchunk_t *chunk = zchunk_new (NULL, 100);     assert (chunk);     zchunk_fill (chunk, 0, 100);      //  Write 100 bytes at position 1,000,000 in the file     rc = zfile_write (file, chunk, 1000000);     assert (rc == 0);     zchunk_destroy (&chunk);     zfile_close (file);     assert (zfile_is_readable (file));     assert (zfile_cursize (file) == 1000100);     assert (!zfile_is_stable (file));     assert (zfile_digest (file));      //  Now truncate file from outside     int handle = open (""./this/is/a/test/bilbo"", O_WRONLY | O_TRUNC | O_BINARY, 0);     assert (handle >= 0);     rc = write (handle, ""Hello, World\n"", 13);     assert (rc == 13);     close (handle);     assert (zfile_has_changed (file));     zclock_sleep (1001);     assert (zfile_has_changed (file));      assert (!zfile_is_stable (file));     zfile_restat (file);     assert (zfile_is_stable (file));     assert (streq (zfile_digest (file), ""4AB299C8AD6ED14F31923DD94F8B5F5CB89DFB54""));      //  Check we can read from file     rc = zfile_input (file);     assert (rc == 0);     chunk = zfile_read (file, 1000100, 0);     assert (chunk);     assert (zchunk_size (chunk) == 13);     zchunk_destroy (&chunk);     zfile_close (file);      //  Check we can read lines from file     rc = zfile_input (file);     assert (rc == 0);     const char *line = zfile_readln (file);     assert (streq (line, ""Hello, World""));     line = zfile_readln (file);     assert (line == NULL);     zfile_close (file);      //  Try some fun with symbolic links     zfile_t *link = zfile_new (""./this/is/a/test"", ""bilbo.ln"");     assert (link);     rc = zfile_output (link);     assert (rc == 0);     fprintf (zfile_handle (link), ""./this/is/a/test/bilbo\n"");     zfile_destroy (&link);      link = zfile_new (""./this/is/a/test"", ""bilbo.ln"");     assert (link);     rc = zfile_input (link);     assert (rc == 0);     chunk = zfile_read (link, 1000100, 0);     assert (chunk);     assert (zchunk_size (chunk) == 13);     zchunk_destroy (&chunk);     zfile_destroy (&link);      //  Remove file and directory     zdir_t *dir = zdir_new (""./this"", NULL);     assert (dir);     assert (zdir_cursize (dir) == 26);     zdir_remove (dir, true);     assert (zdir_cursize (dir) == 0);     zdir_destroy (&dir);      //  Check we can no longer read from file     assert (zfile_is_readable (file));     zfile_restat (file);     assert (!zfile_is_readable (file));     rc = zfile_input (file);     assert (rc == -1);     zfile_destroy (&file);      file = zfile_new (""./"", ""eof_checkfile"");     assert (file);     //  1. Write something first     rc = zfile_output (file);     assert (rc == 0);     chunk = zchunk_new (""123456789"", 9);     assert (chunk);      rc = zfile_write (file, chunk, 0);     assert (rc == 0);     zchunk_destroy (&chunk);     zfile_close (file);     assert (zfile_cursize (file) == 9);      // 2. Read the written something     rc = zfile_input (file);     assert (rc != -1);     // try to read more bytes than there is in the file     chunk = zfile_read (file, 1000, 0);     assert (zfile_eof(file));     assert (zchunk_streq (chunk, ""123456789""));     zchunk_destroy (&chunk);      // reading is ok     chunk = zfile_read (file, 5, 0);     assert (!zfile_eof(file));     assert (zchunk_streq (chunk, ""12345""));     zchunk_destroy (&chunk);      // read from non zero offset until the end     chunk = zfile_read (file, 5, 5);     assert (zfile_eof(file));     assert (zchunk_streq (chunk, ""6789""));     zchunk_destroy (&chunk);     zfile_remove (file); zframe - working with single message frames The zframe class provides methods to send and receive single message frames across ØMQ sockets. A 'frame' corresponds to one zmq_msg_t. When you read a frame from a socket, the zframe_more() method indicates if the frame is part of an unfinished multipart message. The zframe_send method normally destroys the frame, but with the ZFRAME_REUSE flag, you can send the same frame many times. Frames are binary, and this class has no special support for text data. Please add @discuss section in ../src/zframe.c. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     //  This class has draft methods, which may change over time. They are not     //  in stable releases, by default. Use --enable-drafts to enable.     #define ZFRAME_MORE 1                       //      #define ZFRAME_REUSE 2                      //      #define ZFRAME_DONTWAIT 4                   //       //  Create a new frame. If size is not null, allocates the frame data     //  to the specified size. If additionally, data is not null, copies      //  size octets from the specified data into the frame body.              CZMQ_EXPORT zframe_t *         zframe_new (const void *data, size_t size);      //  Create an empty (zero-sized) frame     CZMQ_EXPORT zframe_t *         zframe_new_empty (void);      //  Create a frame with a specified string content.     CZMQ_EXPORT zframe_t *         zframe_from (const char *string);      //  Receive frame from socket, returns zframe_t object or NULL if the recv       //  was interrupted. Does a blocking recv, if you want to not block then use     //  zpoller or zloop.                                                            CZMQ_EXPORT zframe_t *         zframe_recv (void *source);      //  Destroy a frame     CZMQ_EXPORT void         zframe_destroy (zframe_t **self_p);      //  Send a frame to a socket, destroy frame after sending.     //  Return -1 on error, 0 on success.                          CZMQ_EXPORT int         zframe_send (zframe_t **self_p, void *dest, int flags);      //  Return number of bytes in frame data     CZMQ_EXPORT size_t         zframe_size (zframe_t *self);      //  Return address of frame data     CZMQ_EXPORT byte *         zframe_data (zframe_t *self);      //  Return meta data property for frame                //  Caller must free string when finished with it.     CZMQ_EXPORT const char *         zframe_meta (zframe_t *self, const char *property);      //  Create a new frame that duplicates an existing frame. If frame is null,     //  or memory was exhausted, returns null.                                      //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zframe_t *         zframe_dup (zframe_t *self);      //  Return frame data encoded as printable hex string, useful for ØMQ UUIDs.     //  Caller must free string when finished with it.                               //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zframe_strhex (zframe_t *self);      //  Return frame data copied into freshly allocated string     //  Caller must free string when finished with it.             //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zframe_strdup (zframe_t *self);      //  Return TRUE if frame body is equal to string, excluding terminator     CZMQ_EXPORT bool         zframe_streq (zframe_t *self, const char *string);      //  Return frame MORE indicator (1 or 0), set when reading frame from socket     //  or by the zframe_set_more() method                                           CZMQ_EXPORT int         zframe_more (zframe_t *self);      //  Set frame MORE indicator (1 or 0). Note this is NOT used when sending     //  frame to socket, you have to specify flag explicitly.                     CZMQ_EXPORT void         zframe_set_more (zframe_t *self, int more);      //  Return TRUE if two frames have identical size and data     //  If either frame is NULL, equality is always false.         CZMQ_EXPORT bool         zframe_eq (zframe_t *self, zframe_t *other);      //  Set new contents for frame     CZMQ_EXPORT void         zframe_reset (zframe_t *self, const void *data, size_t size);      //  Send message to zsys log sink (may be stdout, or system facility as            //  configured by zsys_set_logstream). Prefix shows before frame, if not null.     CZMQ_EXPORT void         zframe_print (zframe_t *self, const char *prefix);      //  Probe the supplied object, and report if it looks like a zframe_t.     CZMQ_EXPORT bool         zframe_is (void *self);      //  Self test of this class.     CZMQ_EXPORT void         zframe_test (bool verbose);      #ifdef CZMQ_BUILD_DRAFT_API     //  *** Draft method, for development use, may change without warning ***     //  Return frame routing ID, if the frame came from a ZMQ_SERVER socket.     //  Else returns zero.                                                       CZMQ_EXPORT uint32_t         zframe_routing_id (zframe_t *self);      //  *** Draft method, for development use, may change without warning ***     //  Set routing ID on frame. This is used if/when the frame is sent to a     //  ZMQ_SERVER socket.                                                       CZMQ_EXPORT void         zframe_set_routing_id (zframe_t *self, uint32_t routing_id);      //  *** Draft method, for development use, may change without warning ***     //  Return frame group of radio-dish pattern.     CZMQ_EXPORT const char *         zframe_group (zframe_t *self);      //  *** Draft method, for development use, may change without warning ***     //  Set group on frame. This is used if/when the frame is sent to a     //  ZMQ_RADIO socket.                                                   //  Return -1 on error, 0 on success.                                   CZMQ_EXPORT int         zframe_set_group (zframe_t *self, const char *group);      #endif // CZMQ_BUILD_DRAFT_API This is the class self test code:     //  Create two PAIR sockets and connect over inproc     zsock_t *output = zsock_new_pair (""@tcp://127.0.0.1:9001"");     assert (output);     zsock_t *input = zsock_new_pair ("">tcp://127.0.0.1:9001"");     assert (input);      //  Send five different frames, test ZFRAME_MORE     int frame_nbr;     for (frame_nbr = 0; frame_nbr < 5; frame_nbr++) {         frame = zframe_new (""Hello"", 5);         assert (frame);         rc = zframe_send (&frame, output, ZFRAME_MORE);         assert (rc == 0);     }     //  Send same frame five times, test ZFRAME_REUSE     frame = zframe_new (""Hello"", 5);     assert (frame);     for (frame_nbr = 0; frame_nbr < 5; frame_nbr++) {         rc = zframe_send (&frame, output, ZFRAME_MORE + ZFRAME_REUSE);         assert (rc == 0);     }     assert (frame);     zframe_t *copy = zframe_dup (frame);     assert (zframe_eq (frame, copy));     zframe_destroy (&frame);     assert (!zframe_eq (frame, copy));     assert (zframe_size (copy) == 5);     zframe_destroy (&copy);     assert (!zframe_eq (frame, copy));      //  Test zframe_new_empty     frame = zframe_new_empty ();     assert (frame);     assert (zframe_size (frame) == 0);     zframe_destroy (&frame);      //  Send END frame     frame = zframe_new (""NOT"", 3);     assert (frame);     zframe_reset (frame, ""END"", 3);     char *string = zframe_strhex (frame);     assert (streq (string, ""454E44""));     free (string);     string = zframe_strdup (frame);     assert (streq (string, ""END""));     free (string);     rc = zframe_send (&frame, output, 0);     assert (rc == 0);      //  Read and count until we receive END     frame_nbr = 0;     for (frame_nbr = 0;; frame_nbr++) {         zframe_t *frame = zframe_recv (input);         if (zframe_streq (frame, ""END"")) {             zframe_destroy (&frame);             break;         }         assert (zframe_more (frame));         zframe_set_more (frame, 0);         assert (zframe_more (frame) == 0);         zframe_destroy (&frame);     }     assert (frame_nbr == 10);      #if (ZMQ_VERSION >= ZMQ_MAKE_VERSION (4, 1, 0))     // Test zframe_meta     frame = zframe_new (""Hello"", 5);     assert (frame);     rc = zframe_send (&frame, output, 0);     assert (rc == 0);     frame = zframe_recv (input);     const char *meta = zframe_meta (frame, ""Socket-Type"");     assert (meta != NULL);     assert (streq (meta, ""PAIR""));     assert (zframe_meta (frame, ""nonexistent"") == NULL);     zframe_destroy (&frame);     #endif      zsock_destroy (&input);     zsock_destroy (&output);      #if defined (ZMQ_SERVER)     //  Create server and client sockets and connect over inproc     zsock_t *server = zsock_new_server (""inproc://zframe-test-routing"");     assert (server);     zsock_t *client = zsock_new_client (""inproc://zframe-test-routing"");     assert (client);      //  Send request from client to server     zframe_t *request = zframe_new (""Hello"", 5);     assert (request);     rc = zframe_send (&request, client, 0);     assert (rc == 0);     assert (!request);      //  Read request and send reply     request = zframe_recv (server);     assert (request);     assert (zframe_streq (request, ""Hello""));     assert (zframe_routing_id (request));      zframe_t *reply = zframe_new (""World"", 5);     assert (reply);     zframe_set_routing_id (reply, zframe_routing_id (request));     rc = zframe_send (&reply, server, 0);     assert (rc == 0);     zframe_destroy (&request);      //  Read reply     reply = zframe_recv (client);     assert (zframe_streq (reply, ""World""));     assert (zframe_routing_id (reply) == 0);     zframe_destroy (&reply);      //  Client and server disallow multipart     frame = zframe_new (""Hello"", 5);     rc = zframe_send (&frame, client, ZFRAME_MORE);     assert (rc == -1);     rc = zframe_send (&frame, server, ZFRAME_MORE);     assert (rc == -1);     zframe_destroy (&frame);      zsock_destroy (&client);     zsock_destroy (&server);     #endif      #ifdef ZMQ_RADIO     //  Create radio and dish sockets and connect over inproc     zsock_t *radio = zsock_new_radio (""inproc://zframe-test-radio"");     assert (radio);     zsock_t *dish = zsock_new_dish (""inproc://zframe-test-radio"");     assert (dish);      //  Join the group     rc = zsock_join (dish, ""World"");     assert (rc == 0);      //  Publish message from radio     zframe_t *message = zframe_new (""Hello"", 5);     assert (message);     rc = zframe_set_group (message, ""World"");     assert (rc == 0);     rc = zframe_send (&message, radio, 0);     assert (rc == 0);     assert (!message);      //  Receive the message from dish     message = zframe_recv (dish);     assert (message);     assert (zframe_streq (message, ""Hello""));     assert (strcmp(""World"", zframe_group (message)) == 0);     zframe_destroy (&message);      zsock_destroy (&dish);     zsock_destroy (&radio);     #endif  zgossip - decentralized configuration management Implements a gossip protocol for decentralized configuration management. Your applications nodes form a loosely connected network (which can have cycles), and publish name/value tuples. Each node re-distributes the new tuples it receives, so that the entire network eventually achieves a consistent state. The current design does not expire tuples. Provides these commands (sent as multipart strings to the actor): BIND endpoint -- binds the gossip service to specified endpoint PORT -- returns the last TCP port, if any, used for binding LOAD configfile -- load configuration from specified file SET configpath value -- set configuration path = value SAVE configfile -- save configuration to specified file CONNECT endpoint -- connect the gossip service to the specified peer PUBLISH key value -- publish a key/value pair to the gossip cluster STATUS -- return number of key/value pairs held by gossip service Returns these messages: PORT number -- reply to PORT command STATUS number -- reply to STATUS command DELIVER key value -- new tuple delivered from network The gossip protocol distributes information around a loosely-connected network of gossip services. The information consists of name/value pairs published by applications at any point in the network. The goal of the gossip protocol is to create eventual consistency between all the using applications. The name/value pairs (tuples) can be used for configuration data, for status updates, for presence, or for discovery. When used for discovery, the gossip protocol works as an alternative to e.g. UDP beaconing. The gossip network consists of a set of loosely-coupled nodes that exchange tuples. Nodes can be connected across arbitrary transports, so the gossip network can have nodes that communicate over inproc, over IPC, and/or over TCP, at the same time. Each node runs the same stack, which is a server-client hybrid using a modified Harmony pattern (from Chapter 8 of the Guide): http://zguide.zeromq.org/page:all#True-Peer-Connectivity-Harmony-Pattern Each node provides a ROUTER socket that accepts client connections on an key defined by the application via a BIND command. The state machine for these connections is in zgossip.xml, and the generated code is in zgossip_engine.inc. Each node additionally creates outbound connections via DEALER sockets to a set of servers (""remotes""), and under control of the calling app, which sends CONNECT commands for each configured remote. The messages between client and server are defined in zgossip_msg.xml. We built this stack using the zeromq/zproto toolkit. To join the gossip network, a node connects to one or more peers. Each peer acts as a forwarder. This loosely-coupled network can scale to thousands of nodes. However the gossip protocol is NOT designed to be efficient, and should not be used for application data, as the same tuples may be sent many times across the network. The basic logic of the gossip service is to accept PUBLISH messages from its owning application, and to forward these to every remote, and every client it talks to. When a node gets a duplicate tuple, it throws it away. When a node gets a new tuple, it stores it, and fowards it as just described. At any point the application can access the node's set of tuples. At present there is no way to expire tuples from the network. The assumptions in this design are: The data set is slow-changing. Thus, the cost of the gossip protocol is irrelevant with respect to other traffic. This is the class interface:     //  To work with zgossip, use the CZMQ zactor API:     //     //  Create new zgossip instance, passing logging prefix:     //     //      zactor_t *zgossip = zactor_new (zgossip, ""myname"");     //     //  Destroy zgossip instance     //     //      zactor_destroy (&zgossip);     //     //  Enable verbose logging of commands and activity:     //     //      zstr_send (zgossip, ""VERBOSE"");     //     //  Bind zgossip to specified endpoint. TCP endpoints may specify     //  the port number as ""*"" to aquire an ephemeral port:     //     //      zstr_sendx (zgossip, ""BIND"", endpoint, NULL);     //     //  Return assigned port number, specifically when BIND was done using an     //  an ephemeral port:     //     //      zstr_sendx (zgossip, ""PORT"", NULL);     //      char *command, *port_str;     //      zstr_recvx (zgossip, &command, &port_str, NULL);     //      assert (streq (command, ""PORT""));     //     //  Specify configuration file to load, overwriting any previous loaded     //  configuration file or options:     //     //      zstr_sendx (zgossip, ""LOAD"", filename, NULL);     //     //  Set configuration path value:     //     //      zstr_sendx (zgossip, ""SET"", path, value, NULL);     //     //  Save configuration data to config file on disk:     //     //      zstr_sendx (zgossip, ""SAVE"", filename, NULL);     //     //  Send zmsg_t instance to zgossip:     //     //      zactor_send (zgossip, &msg);     //     //  Receive zmsg_t instance from zgossip:     //     //      zmsg_t *msg = zactor_recv (zgossip);     //     //  This is the zgossip constructor as a zactor_fn:     //     CZMQ_EXPORT void         zgossip (zsock_t *pipe, void *args);      //  Self test of this class     CZMQ_EXPORT void         zgossip_test (bool verbose); This is the class self test code:     //  Test basic client-to-server operation of the protocol     zactor_t *server = zactor_new (zgossip, ""server"");     assert (server);     if (verbose)         zstr_send (server, ""VERBOSE"");     zstr_sendx (server, ""BIND"", ""inproc://zgossip"", NULL);      zsock_t *client = zsock_new (ZMQ_DEALER);     assert (client);     zsock_set_rcvtimeo (client, 2000);     int rc = zsock_connect (client, ""inproc://zgossip"");     assert (rc == 0);      //  Send HELLO, which gets no message     zgossip_msg_t *message = zgossip_msg_new ();     zgossip_msg_set_id (message, ZGOSSIP_MSG_HELLO);     zgossip_msg_send (message, client);      //  Send PING, expect PONG back     zgossip_msg_set_id (message, ZGOSSIP_MSG_PING);     zgossip_msg_send (message, client);     zgossip_msg_recv (message, client);     assert (zgossip_msg_id (message) == ZGOSSIP_MSG_PONG);     zgossip_msg_destroy (&message);      zactor_destroy (&server);     zsock_destroy (&client);      //  Test peer-to-peer operations     zactor_t *base = zactor_new (zgossip, ""base"");     assert (base);     if (verbose)         zstr_send (base, ""VERBOSE"");     //  Set a 100msec timeout on clients so we can test expiry     zstr_sendx (base, ""SET"", ""server/timeout"", ""100"", NULL);     zstr_sendx (base, ""BIND"", ""inproc://base"", NULL);      zactor_t *alpha = zactor_new (zgossip, ""alpha"");     assert (alpha);     zstr_sendx (alpha, ""CONNECT"", ""inproc://base"", NULL);     zstr_sendx (alpha, ""PUBLISH"", ""inproc://alpha-1"", ""service1"", NULL);     zstr_sendx (alpha, ""PUBLISH"", ""inproc://alpha-2"", ""service2"", NULL);      zactor_t *beta = zactor_new (zgossip, ""beta"");     assert (beta);     zstr_sendx (beta, ""CONNECT"", ""inproc://base"", NULL);     zstr_sendx (beta, ""PUBLISH"", ""inproc://beta-1"", ""service1"", NULL);     zstr_sendx (beta, ""PUBLISH"", ""inproc://beta-2"", ""service2"", NULL);      //  got nothing     zclock_sleep (200);      zactor_destroy (&base);     zactor_destroy (&alpha);     zactor_destroy (&beta);  zhash - simple generic hash container zhash is an expandable hash table container. This is a simple container. For heavy-duty applications we recommend using zhashx. Note that it's relatively slow (~50K insertions/deletes per second), so don't do inserts/updates on the critical path for message I/O. It can do ~2.5M lookups per second for 16-char keys. Timed on a 1.6GHz CPU. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     //  This class has legacy methods, which will be removed over time. You     //  should not use them, and migrate any code that is still using them.     // Callback function for zhash_freefn method     typedef void (zhash_free_fn) (         void *data);      // Callback function for zhash_foreach method. Deprecated.     typedef int (zhash_foreach_fn) (         const char *key, void *item, void *argument);      //  Create a new, empty hash container     CZMQ_EXPORT zhash_t *         zhash_new (void);      //  Unpack binary frame into a new hash table. Packed data must follow format     //  defined by zhash_pack. Hash table is set to autofree. An empty frame          //  unpacks to an empty hash table.                                               CZMQ_EXPORT zhash_t *         zhash_unpack (zframe_t *frame);      //  Destroy a hash container and all items in it     CZMQ_EXPORT void         zhash_destroy (zhash_t **self_p);      //  Insert item into hash table with specified key and item.                    //  If key is already present returns -1 and leaves existing item unchanged     //  Returns 0 on success.                                                       CZMQ_EXPORT int         zhash_insert (zhash_t *self, const char *key, void *item);      //  Update item into hash table with specified key and item.                 //  If key is already present, destroys old item and inserts new one.        //  Use free_fn method to ensure deallocator is properly called on item.     CZMQ_EXPORT void         zhash_update (zhash_t *self, const char *key, void *item);      //  Remove an item specified by key from the hash table. If there was no such     //  item, this function does nothing.                                             CZMQ_EXPORT void         zhash_delete (zhash_t *self, const char *key);      //  Return the item at the specified key, or null     CZMQ_EXPORT void *         zhash_lookup (zhash_t *self, const char *key);      //  Reindexes an item from an old key to a new key. If there was no such     //  item, does nothing. Returns 0 if successful, else -1.                    CZMQ_EXPORT int         zhash_rename (zhash_t *self, const char *old_key, const char *new_key);      //  Set a free function for the specified hash table item. When the item is     //  destroyed, the free function, if any, is called on that item.               //  Use this when hash items are dynamically allocated, to ensure that          //  you don't have memory leaks. You can pass 'free' or NULL as a free_fn.      //  Returns the item, or NULL if there is no such item.                         CZMQ_EXPORT void *         zhash_freefn (zhash_t *self, const char *key, zhash_free_fn free_fn);      //  Return the number of keys/items in the hash table     CZMQ_EXPORT size_t         zhash_size (zhash_t *self);      //  Make copy of hash table; if supplied table is null, returns null.         //  Does not copy items themselves. Rebuilds new table so may be slow on      //  very large tables. NOTE: only works with item values that are strings     //  since there's no other way to know how to duplicate the item value.       //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zhash_t *         zhash_dup (zhash_t *self);      //  Return keys for items in table     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zlist_t *         zhash_keys (zhash_t *self);      //  Simple iterator; returns first item in hash table, in no given order,      //  or NULL if the table is empty. This method is simpler to use than the      //  foreach() method, which is deprecated. To access the key for this item     //  use zhash_cursor(). NOTE: do NOT modify the table while iterating.         CZMQ_EXPORT void *         zhash_first (zhash_t *self);      //  Simple iterator; returns next item in hash table, in no given order,      //  or NULL if the last item was already returned. Use this together with     //  zhash_first() to process all items in a hash table. If you need the       //  items in sorted order, use zhash_keys() and then zlist_sort(). To         //  access the key for this item use zhash_cursor(). NOTE: do NOT modify      //  the table while iterating.                                                CZMQ_EXPORT void *         zhash_next (zhash_t *self);      //  After a successful first/next method, returns the key for the item that     //  was returned. This is a constant string that you may not modify or          //  deallocate, and which lasts as long as the item in the hash. After an       //  unsuccessful first/next, returns NULL.                                      CZMQ_EXPORT const char *         zhash_cursor (zhash_t *self);      //  Add a comment to hash table before saving to disk. You can add as many        //  comment lines as you like. These comment lines are discarded when loading     //  the file. If you use a null format, all comments are deleted.                 CZMQ_EXPORT void         zhash_comment (zhash_t *self, const char *format, ...);      //  Serialize hash table to a binary frame that can be sent in a message.     //  The packed format is compatible with the 'dictionary' type defined in     //  http://rfc.zeromq.org/spec:35/FILEMQ, and implemented by zproto:          //                                                                            //     ; A list of name/value pairs                                           //     dictionary      = dict-count *( dict-name dict-value )                 //     dict-count      = number-4                                             //     dict-value      = longstr                                              //     dict-name       = string                                               //                                                                            //     ; Strings are always length + text contents                            //     longstr         = number-4 *VCHAR                                      //     string          = number-1 *VCHAR                                      //                                                                            //     ; Numbers are unsigned integers in network byte order                  //     number-1        = 1OCTET                                               //     number-4        = 4OCTET                                               //                                                                            //  Comments are not included in the packed data. Item values MUST be         //  strings.                                                                  //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zframe_t *         zhash_pack (zhash_t *self);      //  Save hash table to a text file in name=value format. Hash values must be     //  printable strings; keys may not contain '=' character. Returns 0 if OK,      //  else -1 if a file error occurred.                                            CZMQ_EXPORT int         zhash_save (zhash_t *self, const char *filename);      //  Load hash table from a text file in name=value format; hash table must      //  already exist. Hash values must printable strings; keys may not contain     //  '=' character. Returns 0 if OK, else -1 if a file was not readable.         CZMQ_EXPORT int         zhash_load (zhash_t *self, const char *filename);      //  When a hash table was loaded from a file by zhash_load, this method will     //  reload the file if it has been modified since, and is ""stable"", i.e. not     //  still changing. Returns 0 if OK, -1 if there was an error reloading the      //  file.                                                                        CZMQ_EXPORT int         zhash_refresh (zhash_t *self);      //  Set hash for automatic value destruction     CZMQ_EXPORT void         zhash_autofree (zhash_t *self);      //  *** Deprecated method, slated for removal: avoid using it ***     //  Apply function to each item in the hash table. Items are iterated in no     //  defined order. Stops if callback function returns non-zero and returns      //  final return code from callback function (zero = success). Deprecated.      CZMQ_EXPORT int         zhash_foreach (zhash_t *self, zhash_foreach_fn callback, void *argument);      //  Self test of this class.     CZMQ_EXPORT void         zhash_test (bool verbose);  This is the class self test code:     zhash_t *hash = zhash_new ();     assert (hash);     assert (zhash_size (hash) == 0);     assert (zhash_first (hash) == NULL);     assert (zhash_cursor (hash) == NULL);      //  Insert some items     int rc;     rc = zhash_insert (hash, ""DEADBEEF"", ""dead beef"");     char *item = (char *) zhash_first (hash);     assert (streq (zhash_cursor (hash), ""DEADBEEF""));     assert (streq (item, ""dead beef""));     assert (rc == 0);     rc = zhash_insert (hash, ""ABADCAFE"", ""a bad cafe"");     assert (rc == 0);     rc = zhash_insert (hash, ""C0DEDBAD"", ""coded bad"");     assert (rc == 0);     rc = zhash_insert (hash, ""DEADF00D"", ""dead food"");     assert (rc == 0);     assert (zhash_size (hash) == 4);      //  Look for existing items     item = (char *) zhash_lookup (hash, ""DEADBEEF"");     assert (streq (item, ""dead beef""));     item = (char *) zhash_lookup (hash, ""ABADCAFE"");     assert (streq (item, ""a bad cafe""));     item = (char *) zhash_lookup (hash, ""C0DEDBAD"");     assert (streq (item, ""coded bad""));     item = (char *) zhash_lookup (hash, ""DEADF00D"");     assert (streq (item, ""dead food""));      //  Look for non-existent items     item = (char *) zhash_lookup (hash, ""foo"");     assert (item == NULL);      //  Try to insert duplicate items     rc = zhash_insert (hash, ""DEADBEEF"", ""foo"");     assert (rc == -1);     item = (char *) zhash_lookup (hash, ""DEADBEEF"");     assert (streq (item, ""dead beef""));      //  Some rename tests      //  Valid rename, key is now LIVEBEEF     rc = zhash_rename (hash, ""DEADBEEF"", ""LIVEBEEF"");     assert (rc == 0);     item = (char *) zhash_lookup (hash, ""LIVEBEEF"");     assert (streq (item, ""dead beef""));      //  Trying to rename an unknown item to a non-existent key     rc = zhash_rename (hash, ""WHATBEEF"", ""NONESUCH"");     assert (rc == -1);      //  Trying to rename an unknown item to an existing key     rc = zhash_rename (hash, ""WHATBEEF"", ""LIVEBEEF"");     assert (rc == -1);     item = (char *) zhash_lookup (hash, ""LIVEBEEF"");     assert (streq (item, ""dead beef""));      //  Trying to rename an existing item to another existing item     rc = zhash_rename (hash, ""LIVEBEEF"", ""ABADCAFE"");     assert (rc == -1);     item = (char *) zhash_lookup (hash, ""LIVEBEEF"");     assert (streq (item, ""dead beef""));     item = (char *) zhash_lookup (hash, ""ABADCAFE"");     assert (streq (item, ""a bad cafe""));      //  Test keys method     zlist_t *keys = zhash_keys (hash);     assert (zlist_size (keys) == 4);     zlist_destroy (&keys);      //  Test dup method     zhash_t *copy = zhash_dup (hash);     assert (zhash_size (copy) == 4);     item = (char *) zhash_lookup (copy, ""LIVEBEEF"");     assert (item);     assert (streq (item, ""dead beef""));     zhash_destroy (&copy);      //  Test pack/unpack methods     zframe_t *frame = zhash_pack (hash);     copy = zhash_unpack (frame);     zframe_destroy (&frame);     assert (zhash_size (copy) == 4);     item = (char *) zhash_lookup (copy, ""LIVEBEEF"");     assert (item);     assert (streq (item, ""dead beef""));     zhash_destroy (&copy);      //  Test save and load     zhash_comment (hash, ""This is a test file"");     zhash_comment (hash, ""Created by %s"", ""czmq_selftest"");     zhash_save (hash, "".cache"");     copy = zhash_new ();     assert (copy);     zhash_load (copy, "".cache"");     item = (char *) zhash_lookup (copy, ""LIVEBEEF"");     assert (item);     assert (streq (item, ""dead beef""));     zhash_destroy (&copy);     zsys_file_delete ("".cache"");      //  Delete a item     zhash_delete (hash, ""LIVEBEEF"");     item = (char *) zhash_lookup (hash, ""LIVEBEEF"");     assert (item == NULL);     assert (zhash_size (hash) == 3);      //  Check that the queue is robust against random usage     struct {         char name [100];         bool exists;     } testset [200];     memset (testset, 0, sizeof (testset));     int testmax = 200, testnbr, iteration;      srandom ((unsigned) time (NULL));     for (iteration = 0; iteration < 25000; iteration++) {         testnbr = randof (testmax);         if (testset [testnbr].exists) {             item = (char *) zhash_lookup (hash, testset [testnbr].name);             assert (item);             zhash_delete (hash, testset [testnbr].name);             testset [testnbr].exists = false;         }         else {             sprintf (testset [testnbr].name, ""%x-%x"", rand (), rand ());             if (zhash_insert (hash, testset [testnbr].name, """") == 0)                 testset [testnbr].exists = true;         }     }     //  Test 10K lookups     for (iteration = 0; iteration < 10000; iteration++)         item = (char *) zhash_lookup (hash, ""DEADBEEFABADCAFE"");      //  Destructor should be safe to call twice     zhash_destroy (&hash);     zhash_destroy (&hash);     assert (hash == NULL);      // Test autofree; automatically copies and frees string values     hash = zhash_new ();     assert (hash);     zhash_autofree (hash);     char value [255];     strcpy (value, ""This is a string"");     rc = zhash_insert (hash, ""key1"", value);     assert (rc == 0);     strcpy (value, ""Inserting with the same key will fail"");     rc = zhash_insert (hash, ""key1"", value);     assert (rc == -1);     strcpy (value, ""Ring a ding ding"");     rc = zhash_insert (hash, ""key2"", value);     assert (rc == 0);     assert (streq ((char *) zhash_lookup (hash, ""key1""), ""This is a string""));     assert (streq ((char *) zhash_lookup (hash, ""key2""), ""Ring a ding ding""));     zhash_destroy (&hash); zhashx - extended generic hash container zhashx is an extended hash table container with more functionality than zhash, its simpler cousin. The hash table always has a size that is prime and roughly doubles its size when 75% full. In case of hash collisions items are chained in a linked list. The hash table size is increased slightly (up to 5 times before roughly doubling the size) when an overly long chain (between 1 and 63 items depending on table size) is detected. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     //  This class has draft methods, which may change over time. They are not     //  in stable releases, by default. Use --enable-drafts to enable.     //  This class has legacy methods, which will be removed over time. You     //  should not use them, and migrate any code that is still using them.     // Destroy an item     typedef void (zhashx_destructor_fn) (         void **item);      // Duplicate an item     typedef void * (zhashx_duplicator_fn) (         const void *item);      // Compare two items, for sorting     typedef int (zhashx_comparator_fn) (         const void *item1, const void *item2);      // compare two items, for sorting     typedef void (zhashx_free_fn) (         void *data);      // compare two items, for sorting     typedef size_t (zhashx_hash_fn) (         const void *key);      // Serializes an item to a longstr.                            // The caller takes ownership of the newly created object.     typedef char * (zhashx_serializer_fn) (         const void *item);      // Deserializes a longstr into an item.                        // The caller takes ownership of the newly created object.     typedef void * (zhashx_deserializer_fn) (         const char *item_str);      // Callback function for zhashx_foreach method.                                   // This callback is deprecated and you should use zhashx_first/_next instead.     typedef int (zhashx_foreach_fn) (         const char *key, void *item, void *argument);      //  Create a new, empty hash container     CZMQ_EXPORT zhashx_t *         zhashx_new (void);      //  Unpack binary frame into a new hash table. Packed data must follow format     //  defined by zhashx_pack. Hash table is set to autofree. An empty frame         //  unpacks to an empty hash table.                                               CZMQ_EXPORT zhashx_t *         zhashx_unpack (zframe_t *frame);      //  Destroy a hash container and all items in it     CZMQ_EXPORT void         zhashx_destroy (zhashx_t **self_p);      //  Insert item into hash table with specified key and item.                    //  If key is already present returns -1 and leaves existing item unchanged     //  Returns 0 on success.                                                       CZMQ_EXPORT int         zhashx_insert (zhashx_t *self, const void *key, void *item);      //  Update or insert item into hash table with specified key and item. If the     //  key is already present, destroys old item and inserts new one. If you set     //  a container item destructor, this is called on the old value. If the key      //  was not already present, inserts a new item. Sets the hash cursor to the      //  new item.                                                                     CZMQ_EXPORT void         zhashx_update (zhashx_t *self, const void *key, void *item);      //  Remove an item specified by key from the hash table. If there was no such     //  item, this function does nothing.                                             CZMQ_EXPORT void         zhashx_delete (zhashx_t *self, const void *key);      //  Delete all items from the hash table. If the key destructor is       //  set, calls it on every key. If the item destructor is set, calls     //  it on every item.                                                    CZMQ_EXPORT void         zhashx_purge (zhashx_t *self);      //  Return the item at the specified key, or null     CZMQ_EXPORT void *         zhashx_lookup (zhashx_t *self, const void *key);      //  Reindexes an item from an old key to a new key. If there was no such     //  item, does nothing. Returns 0 if successful, else -1.                    CZMQ_EXPORT int         zhashx_rename (zhashx_t *self, const void *old_key, const void *new_key);      //  Set a free function for the specified hash table item. When the item is     //  destroyed, the free function, if any, is called on that item.               //  Use this when hash items are dynamically allocated, to ensure that          //  you don't have memory leaks. You can pass 'free' or NULL as a free_fn.      //  Returns the item, or NULL if there is no such item.                         CZMQ_EXPORT void *         zhashx_freefn (zhashx_t *self, const void *key, zhashx_free_fn free_fn);      //  Return the number of keys/items in the hash table     CZMQ_EXPORT size_t         zhashx_size (zhashx_t *self);      //  Return a zlistx_t containing the keys for the items in the            //  table. Uses the key_duplicator to duplicate all keys and sets the     //  key_destructor as destructor for the list.                            //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zlistx_t *         zhashx_keys (zhashx_t *self);      //  Return a zlistx_t containing the values for the items in the       //  table. Uses the duplicator to duplicate all items and sets the     //  destructor as destructor for the list.                             //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zlistx_t *         zhashx_values (zhashx_t *self);      //  Simple iterator; returns first item in hash table, in no given order,      //  or NULL if the table is empty. This method is simpler to use than the      //  foreach() method, which is deprecated. To access the key for this item     //  use zhashx_cursor(). NOTE: do NOT modify the table while iterating.        CZMQ_EXPORT void *         zhashx_first (zhashx_t *self);      //  Simple iterator; returns next item in hash table, in no given order,      //  or NULL if the last item was already returned. Use this together with     //  zhashx_first() to process all items in a hash table. If you need the      //  items in sorted order, use zhashx_keys() and then zlistx_sort(). To       //  access the key for this item use zhashx_cursor(). NOTE: do NOT modify     //  the table while iterating.                                                CZMQ_EXPORT void *         zhashx_next (zhashx_t *self);      //  After a successful first/next method, returns the key for the item that     //  was returned. This is a constant string that you may not modify or          //  deallocate, and which lasts as long as the item in the hash. After an       //  unsuccessful first/next, returns NULL.                                      CZMQ_EXPORT const void *         zhashx_cursor (zhashx_t *self);      //  Add a comment to hash table before saving to disk. You can add as many        //  comment lines as you like. These comment lines are discarded when loading     //  the file. If you use a null format, all comments are deleted.                 CZMQ_EXPORT void         zhashx_comment (zhashx_t *self, const char *format, ...);      //  Save hash table to a text file in name=value format. Hash values must be     //  printable strings; keys may not contain '=' character. Returns 0 if OK,      //  else -1 if a file error occurred.                                            CZMQ_EXPORT int         zhashx_save (zhashx_t *self, const char *filename);      //  Load hash table from a text file in name=value format; hash table must      //  already exist. Hash values must printable strings; keys may not contain     //  '=' character. Returns 0 if OK, else -1 if a file was not readable.         CZMQ_EXPORT int         zhashx_load (zhashx_t *self, const char *filename);      //  When a hash table was loaded from a file by zhashx_load, this method will     //  reload the file if it has been modified since, and is ""stable"", i.e. not      //  still changing. Returns 0 if OK, -1 if there was an error reloading the       //  file.                                                                         CZMQ_EXPORT int         zhashx_refresh (zhashx_t *self);      //  Serialize hash table to a binary frame that can be sent in a message.     //  The packed format is compatible with the 'dictionary' type defined in     //  http://rfc.zeromq.org/spec:35/FILEMQ, and implemented by zproto:          //                                                                            //     ; A list of name/value pairs                                           //     dictionary      = dict-count *( dict-name dict-value )                 //     dict-count      = number-4                                             //     dict-value      = longstr                                              //     dict-name       = string                                               //                                                                            //     ; Strings are always length + text contents                            //     longstr         = number-4 *VCHAR                                      //     string          = number-1 *VCHAR                                      //                                                                            //     ; Numbers are unsigned integers in network byte order                  //     number-1        = 1OCTET                                               //     number-4        = 4OCTET                                               //                                                                            //  Comments are not included in the packed data. Item values MUST be         //  strings.                                                                  //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zframe_t *         zhashx_pack (zhashx_t *self);      //  Make a copy of the list; items are duplicated if you set a duplicator      //  for the list, otherwise not. Copying a null reference returns a null       //  reference. Note that this method's behavior changed slightly for CZMQ      //  v3.x, as it does not set nor respect autofree. It does however let you     //  duplicate any hash table safely. The old behavior is in zhashx_dup_v2.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zhashx_t *         zhashx_dup (zhashx_t *self);      //  Set a user-defined deallocator for hash items; by default items are not     //  freed when the hash is destroyed.                                           CZMQ_EXPORT void         zhashx_set_destructor (zhashx_t *self, zhashx_destructor_fn destructor);      //  Set a user-defined duplicator for hash items; by default items are not     //  copied when the hash is duplicated.                                        CZMQ_EXPORT void         zhashx_set_duplicator (zhashx_t *self, zhashx_duplicator_fn duplicator);      //  Set a user-defined deallocator for keys; by default keys are freed     //  when the hash is destroyed using free().                               CZMQ_EXPORT void         zhashx_set_key_destructor (zhashx_t *self, zhashx_destructor_fn destructor);      //  Set a user-defined duplicator for keys; by default keys are duplicated     //  using strdup.                                                              CZMQ_EXPORT void         zhashx_set_key_duplicator (zhashx_t *self, zhashx_duplicator_fn duplicator);      //  Set a user-defined comparator for keys; by default keys are     //  compared using strcmp.                                          CZMQ_EXPORT void         zhashx_set_key_comparator (zhashx_t *self, zhashx_comparator_fn comparator);      //  Set a user-defined comparator for keys; by default keys are     //  compared using strcmp.                                          CZMQ_EXPORT void         zhashx_set_key_hasher (zhashx_t *self, zhashx_hash_fn hasher);      //  Make copy of hash table; if supplied table is null, returns null.         //  Does not copy items themselves. Rebuilds new table so may be slow on      //  very large tables. NOTE: only works with item values that are strings     //  since there's no other way to know how to duplicate the item value.       CZMQ_EXPORT zhashx_t *         zhashx_dup_v2 (zhashx_t *self);      //  *** Deprecated method, slated for removal: avoid using it ***     //  Set hash for automatic value destruction. This method is deprecated     //  and you should use set_destructor instead.                              CZMQ_EXPORT void         zhashx_autofree (zhashx_t *self);      //  *** Deprecated method, slated for removal: avoid using it ***     //  Apply function to each item in the hash table. Items are iterated in no     //  defined order. Stops if callback function returns non-zero and returns      //  final return code from callback function (zero = success). This method      //  is deprecated and you should use zhashx_first/_next instead.                CZMQ_EXPORT int         zhashx_foreach (zhashx_t *self, zhashx_foreach_fn callback, void *argument);      //  Self test of this class.     CZMQ_EXPORT void         zhashx_test (bool verbose);      #ifdef CZMQ_BUILD_DRAFT_API     //  *** Draft method, for development use, may change without warning ***     //  Same as unpack but uses a user-defined deserializer function to convert     //  a longstr back into item format.                                            CZMQ_EXPORT zhashx_t *         zhashx_unpack_own (zframe_t *frame, zhashx_deserializer_fn deserializer);      //  *** Draft method, for development use, may change without warning ***     //  Same as pack but uses a user-defined serializer function to convert items     //  into longstr.                                                                 //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zframe_t *         zhashx_pack_own (zhashx_t *self, zhashx_serializer_fn serializer);      #endif // CZMQ_BUILD_DRAFT_API This is the class self test code:     zhashx_t *hash = zhashx_new ();     assert (hash);     assert (zhashx_size (hash) == 0);     assert (zhashx_first (hash) == NULL);     assert (zhashx_cursor (hash) == NULL);      //  Insert some items     int rc;     rc = zhashx_insert (hash, ""DEADBEEF"", ""dead beef"");     char *item = (char *) zhashx_first (hash);     assert (streq ((char *) zhashx_cursor (hash), ""DEADBEEF""));     assert (streq (item, ""dead beef""));     assert (rc == 0);     rc = zhashx_insert (hash, ""ABADCAFE"", ""a bad cafe"");     assert (rc == 0);     rc = zhashx_insert (hash, ""C0DEDBAD"", ""coded bad"");     assert (rc == 0);     rc = zhashx_insert (hash, ""DEADF00D"", ""dead food"");     assert (rc == 0);     assert (zhashx_size (hash) == 4);      //  Look for existing items     item = (char *) zhashx_lookup (hash, ""DEADBEEF"");     assert (streq (item, ""dead beef""));     item = (char *) zhashx_lookup (hash, ""ABADCAFE"");     assert (streq (item, ""a bad cafe""));     item = (char *) zhashx_lookup (hash, ""C0DEDBAD"");     assert (streq (item, ""coded bad""));     item = (char *) zhashx_lookup (hash, ""DEADF00D"");     assert (streq (item, ""dead food""));      //  Look for non-existent items     item = (char *) zhashx_lookup (hash, ""foo"");     assert (item == NULL);      //  Try to insert duplicate items     rc = zhashx_insert (hash, ""DEADBEEF"", ""foo"");     assert (rc == -1);     item = (char *) zhashx_lookup (hash, ""DEADBEEF"");     assert (streq (item, ""dead beef""));      //  Some rename tests      //  Valid rename, key is now LIVEBEEF     rc = zhashx_rename (hash, ""DEADBEEF"", ""LIVEBEEF"");     assert (rc == 0);     item = (char *) zhashx_lookup (hash, ""LIVEBEEF"");     assert (streq (item, ""dead beef""));      //  Trying to rename an unknown item to a non-existent key     rc = zhashx_rename (hash, ""WHATBEEF"", ""NONESUCH"");     assert (rc == -1);      //  Trying to rename an unknown item to an existing key     rc = zhashx_rename (hash, ""WHATBEEF"", ""LIVEBEEF"");     assert (rc == -1);     item = (char *) zhashx_lookup (hash, ""LIVEBEEF"");     assert (streq (item, ""dead beef""));      //  Trying to rename an existing item to another existing item     rc = zhashx_rename (hash, ""LIVEBEEF"", ""ABADCAFE"");     assert (rc == -1);     item = (char *) zhashx_lookup (hash, ""LIVEBEEF"");     assert (streq (item, ""dead beef""));     item = (char *) zhashx_lookup (hash, ""ABADCAFE"");     assert (streq (item, ""a bad cafe""));      //  Test keys method     zlistx_t *keys = zhashx_keys (hash);     assert (zlistx_size (keys) == 4);     zlistx_destroy (&keys);      zlistx_t *values = zhashx_values(hash);     assert (zlistx_size (values) == 4);     zlistx_destroy (&values);      //  Test dup method     zhashx_t *copy = zhashx_dup (hash);     assert (zhashx_size (copy) == 4);     item = (char *) zhashx_lookup (copy, ""LIVEBEEF"");     assert (item);     assert (streq (item, ""dead beef""));     zhashx_destroy (&copy);      //  Test pack/unpack methods     zframe_t *frame = zhashx_pack (hash);     copy = zhashx_unpack (frame);     zframe_destroy (&frame);     assert (zhashx_size (copy) == 4);     item = (char *) zhashx_lookup (copy, ""LIVEBEEF"");     assert (item);     assert (streq (item, ""dead beef""));     zhashx_destroy (&copy);      #ifdef CZMQ_BUILD_DRAFT_API     //  Test own pack/unpack methods     zhashx_t *own_hash = zhashx_new ();     zhashx_set_destructor (own_hash, s_test_destroy_int);     assert (own_hash);     int *val1 = (int *) zmalloc (sizeof (int));     int *val2 = (int *) zmalloc (sizeof (int));     *val1 = 25;     *val2 = 100;     zhashx_insert (own_hash, ""val1"", val1);     zhashx_insert (own_hash, ""val2"", val2);     frame = zhashx_pack_own (own_hash, s_test_serialize_int);     copy = zhashx_unpack_own (frame, s_test_deserialze_int);     zhashx_set_destructor (copy, s_test_destroy_int);     zframe_destroy (&frame);     assert (zhashx_size (copy) == 2);     assert (*((int *) zhashx_lookup (copy, ""val1"")) == 25);     assert (*((int *) zhashx_lookup (copy, ""val2"")) == 100);     zhashx_destroy (&copy);     zhashx_destroy (&own_hash);     #endif // CZMQ_BUILD_DRAFT_API      //  Test save and load     zhashx_comment (hash, ""This is a test file"");     zhashx_comment (hash, ""Created by %s"", ""czmq_selftest"");     zhashx_save (hash, "".cache"");     copy = zhashx_new ();     assert (copy);     zhashx_load (copy, "".cache"");     item = (char *) zhashx_lookup (copy, ""LIVEBEEF"");     assert (item);     assert (streq (item, ""dead beef""));     zhashx_destroy (&copy);     zsys_file_delete ("".cache"");      //  Delete a item     zhashx_delete (hash, ""LIVEBEEF"");     item = (char *) zhashx_lookup (hash, ""LIVEBEEF"");     assert (item == NULL);     assert (zhashx_size (hash) == 3);      //  Check that the queue is robust against random usage     struct {         char name [100];         bool exists;     } testset [200];     memset (testset, 0, sizeof (testset));     int testmax = 200, testnbr, iteration;      srandom ((unsigned) time (NULL));     for (iteration = 0; iteration < 25000; iteration++) {         testnbr = randof (testmax);         if (testset [testnbr].exists) {             item = (char *) zhashx_lookup (hash, testset [testnbr].name);             assert (item);             zhashx_delete (hash, testset [testnbr].name);             testset [testnbr].exists = false;         }         else {             sprintf (testset [testnbr].name, ""%x-%x"", rand (), rand ());             if (zhashx_insert (hash, testset [testnbr].name, """") == 0)                 testset [testnbr].exists = true;         }     }     //  Test 10K lookups     for (iteration = 0; iteration < 10000; iteration++)         item = (char *) zhashx_lookup (hash, ""DEADBEEFABADCAFE"");      //  Destructor should be safe to call twice     zhashx_destroy (&hash);     zhashx_destroy (&hash);     assert (hash == NULL);      //  Test autofree; automatically copies and frees string values     hash = zhashx_new ();     assert (hash);     zhashx_autofree (hash);     char value [255];     strcpy (value, ""This is a string"");     rc = zhashx_insert (hash, ""key1"", value);     assert (rc == 0);     strcpy (value, ""Ring a ding ding"");     rc = zhashx_insert (hash, ""key2"", value);     assert (rc == 0);     assert (streq ((char *) zhashx_lookup (hash, ""key1""), ""This is a string""));     assert (streq ((char *) zhashx_lookup (hash, ""key2""), ""Ring a ding ding""));     zhashx_destroy (&hash); ziflist - list of network interfaces available on system The ziflist class takes a snapshot of the network interfaces that the system currently supports (this can change arbitrarily, especially on mobile devices). The caller can then access the network interface information using an iterator that works like zlistx. Only stores those interfaces with broadcast capability, and ignores the loopback interface. Please add @discuss section in ../src/ziflist.c. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     //  Get a list of network interfaces currently defined on the system     CZMQ_EXPORT ziflist_t *         ziflist_new (void);      //  Destroy a ziflist instance     CZMQ_EXPORT void         ziflist_destroy (ziflist_t **self_p);      //  Reload network interfaces from system     CZMQ_EXPORT void         ziflist_reload (ziflist_t *self);      //  Return the number of network interfaces on system     CZMQ_EXPORT size_t         ziflist_size (ziflist_t *self);      //  Get first network interface, return NULL if there are none     CZMQ_EXPORT const char *         ziflist_first (ziflist_t *self);      //  Get next network interface, return NULL if we hit the last one     CZMQ_EXPORT const char *         ziflist_next (ziflist_t *self);      //  Return the current interface IP address as a printable string     CZMQ_EXPORT const char *         ziflist_address (ziflist_t *self);      //  Return the current interface broadcast address as a printable string     CZMQ_EXPORT const char *         ziflist_broadcast (ziflist_t *self);      //  Return the current interface network mask as a printable string     CZMQ_EXPORT const char *         ziflist_netmask (ziflist_t *self);      //  Return the list of interfaces.     CZMQ_EXPORT void         ziflist_print (ziflist_t *self);      //  Self test of this class.     CZMQ_EXPORT void         ziflist_test (bool verbose);  This is the class self test code:     ziflist_t *iflist = ziflist_new ();     assert (iflist);      size_t items = ziflist_size (iflist);      if (verbose) {         printf (""ziflist: interfaces=%zu\n"", ziflist_size (iflist));         const char *name = ziflist_first (iflist);         while (name) {             printf ("" - name=%s address=%s netmask=%s broadcast=%s\n"",                     name, ziflist_address (iflist), ziflist_netmask (iflist), ziflist_broadcast (iflist));             name = ziflist_next (iflist);         }     }     ziflist_reload (iflist);     assert (items == ziflist_size (iflist));     ziflist_destroy (&iflist); zlist - simple generic list container Provides a generic container implementing a fast singly-linked list. You can use this to construct multi-dimensional lists, and other structures together with other generic containers like zhash. This is a simple class. For demanding applications we recommend using zlistx. To iterate through a list, use zlist_first to get the first item, then loop while not null, and do zlist_next at the end of each iteration. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     // Comparison function e.g. for sorting and removing.     typedef int (zlist_compare_fn) (         void *item1, void *item2);      // Callback function for zlist_freefn method     typedef void (zlist_free_fn) (         void *data);      //  Create a new list container     CZMQ_EXPORT zlist_t *         zlist_new (void);      //  Destroy a list container     CZMQ_EXPORT void         zlist_destroy (zlist_t **self_p);      //  Return the item at the head of list. If the list is empty, returns NULL.     //  Leaves cursor pointing at the head item, or NULL if the list is empty.       CZMQ_EXPORT void *         zlist_first (zlist_t *self);      //  Return the next item. If the list is empty, returns NULL. To move to     //  the start of the list call zlist_first (). Advances the cursor.          CZMQ_EXPORT void *         zlist_next (zlist_t *self);      //  Return the item at the tail of list. If the list is empty, returns NULL.     //  Leaves cursor pointing at the tail item, or NULL if the list is empty.       CZMQ_EXPORT void *         zlist_last (zlist_t *self);      //  Return first item in the list, or null, leaves the cursor     CZMQ_EXPORT void *         zlist_head (zlist_t *self);      //  Return last item in the list, or null, leaves the cursor     CZMQ_EXPORT void *         zlist_tail (zlist_t *self);      //  Return the current item of list. If the list is empty, returns NULL.          //  Leaves cursor pointing at the current item, or NULL if the list is empty.     CZMQ_EXPORT void *         zlist_item (zlist_t *self);      //  Append an item to the end of the list, return 0 if OK or -1 if this       //  failed for some reason (out of memory). Note that if a duplicator has     //  been set, this method will also duplicate the item.                       CZMQ_EXPORT int         zlist_append (zlist_t *self, void *item);      //  Push an item to the start of the list, return 0 if OK or -1 if this       //  failed for some reason (out of memory). Note that if a duplicator has     //  been set, this method will also duplicate the item.                       CZMQ_EXPORT int         zlist_push (zlist_t *self, void *item);      //  Pop the item off the start of the list, if any     CZMQ_EXPORT void *         zlist_pop (zlist_t *self);      //  Checks if an item already is present. Uses compare method to determine if      //  items are equal. If the compare method is NULL the check will only compare     //  pointers. Returns true if item is present else false.                          CZMQ_EXPORT bool         zlist_exists (zlist_t *self, void *item);      //  Remove the specified item from the list if present     CZMQ_EXPORT void         zlist_remove (zlist_t *self, void *item);      //  Make a copy of list. If the list has autofree set, the copied list will       //  duplicate all items, which must be strings. Otherwise, the list will hold     //  pointers back to the items in the original list. If list is null, returns     //  NULL.                                                                         //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zlist_t *         zlist_dup (zlist_t *self);      //  Purge all items from list     CZMQ_EXPORT void         zlist_purge (zlist_t *self);      //  Return number of items in the list     CZMQ_EXPORT size_t         zlist_size (zlist_t *self);      //  Sort the list. If the compare function is null, sorts the list by          //  ascending key value using a straight ASCII comparison. If you specify      //  a compare function, this decides how items are sorted. The sort is not     //  stable, so may reorder items with the same keys. The algorithm used is     //  combsort, a compromise between performance and simplicity.                 CZMQ_EXPORT void         zlist_sort (zlist_t *self, zlist_compare_fn compare);      //  Set list for automatic item destruction; item values MUST be strings.      //  By default a list item refers to a value held elsewhere. When you set      //  this, each time you append or push a list item, zlist will take a copy     //  of the string value. Then, when you destroy the list, it will free all     //  item values automatically. If you use any other technique to allocate      //  list values, you must free them explicitly before destroying the list.     //  The usual technique is to pop list items and destroy them, until the       //  list is empty.                                                             CZMQ_EXPORT void         zlist_autofree (zlist_t *self);      //  Sets a compare function for this list. The function compares two items.     //  It returns an integer less than, equal to, or greater than zero if the      //  first item is found, respectively, to be less than, to match, or be         //  greater than the second item.                                               //  This function is used for sorting, removal and exists checking.             CZMQ_EXPORT void         zlist_comparefn (zlist_t *self, zlist_compare_fn fn);      //  Set a free function for the specified list item. When the item is          //  destroyed, the free function, if any, is called on that item.              //  Use this when list items are dynamically allocated, to ensure that         //  you don't have memory leaks. You can pass 'free' or NULL as a free_fn.     //  Returns the item, or NULL if there is no such item.                        CZMQ_EXPORT void *         zlist_freefn (zlist_t *self, void *item, zlist_free_fn fn, bool at_tail);      //  Self test of this class.     CZMQ_EXPORT void         zlist_test (bool verbose);  This is the class self test code:     zlist_t *list = zlist_new ();     assert (list);     assert (zlist_size (list) == 0);      //  Three items we'll use as test data     //  List items are void *, not particularly strings     char *cheese = ""boursin"";     char *bread = ""baguette"";     char *wine = ""bordeaux"";      zlist_append (list, cheese);     assert (zlist_size (list) == 1);     assert ( zlist_exists (list, cheese));     assert (!zlist_exists (list, bread));     assert (!zlist_exists (list, wine));     zlist_append (list, bread);     assert (zlist_size (list) == 2);     assert ( zlist_exists (list, cheese));     assert ( zlist_exists (list, bread));     assert (!zlist_exists (list, wine));     zlist_append (list, wine);     assert (zlist_size (list) == 3);     assert ( zlist_exists (list, cheese));     assert ( zlist_exists (list, bread));     assert ( zlist_exists (list, wine));      assert (zlist_head (list) == cheese);     assert (zlist_next (list) == cheese);      assert (zlist_first (list) == cheese);     assert (zlist_tail (list) == wine);     assert (zlist_next (list) == bread);      assert (zlist_first (list) == cheese);     assert (zlist_next (list) == bread);     assert (zlist_next (list) == wine);     assert (zlist_next (list) == NULL);     //  After we reach end of list, next wraps around     assert (zlist_next (list) == cheese);     assert (zlist_size (list) == 3);      zlist_remove (list, wine);     assert (zlist_size (list) == 2);      assert (zlist_first (list) == cheese);     zlist_remove (list, cheese);     assert (zlist_size (list) == 1);     assert (zlist_first (list) == bread);      zlist_remove (list, bread);     assert (zlist_size (list) == 0);      zlist_append (list, cheese);     zlist_append (list, bread);     assert (zlist_last (list) == bread);     zlist_remove (list, bread);     assert (zlist_last (list) == cheese);     zlist_remove (list, cheese);     assert (zlist_last (list) == NULL);      zlist_push (list, cheese);     assert (zlist_size (list) == 1);     assert (zlist_first (list) == cheese);      zlist_push (list, bread);     assert (zlist_size (list) == 2);     assert (zlist_first (list) == bread);     assert (zlist_item (list) == bread);      zlist_append (list, wine);     assert (zlist_size (list) == 3);     assert (zlist_first (list) == bread);      zlist_t *sub_list = zlist_dup (list);     assert (sub_list);     assert (zlist_size (sub_list) == 3);      zlist_sort (list, NULL);     char *item;     item = (char *) zlist_pop (list);     assert (item == bread);     item = (char *) zlist_pop (list);     assert (item == wine);     item = (char *) zlist_pop (list);     assert (item == cheese);     assert (zlist_size (list) == 0);      assert (zlist_size (sub_list) == 3);     zlist_push (list, sub_list);     zlist_t *sub_list_2 = zlist_dup (sub_list);     zlist_append (list, sub_list_2);     assert (zlist_freefn (list, sub_list, &s_zlist_free, false) == sub_list);     assert (zlist_freefn (list, sub_list_2, &s_zlist_free, true) == sub_list_2);     zlist_destroy (&list);      //  Test autofree functionality     list = zlist_new ();     assert (list);     zlist_autofree (list);     //  Set equals function otherwise equals will not work as autofree copies strings     zlist_comparefn (list, (zlist_compare_fn *) strcmp);     zlist_push (list, bread);     zlist_append (list, cheese);     assert (zlist_size (list) == 2);     zlist_append (list, wine);     assert (zlist_exists (list, wine));     zlist_remove (list, wine);     assert (!zlist_exists (list, wine));     assert (streq ((const char *) zlist_first (list), bread));     item = (char *) zlist_pop (list);     assert (streq (item, bread));     free (item);     item = (char *) zlist_pop (list);     assert (streq (item, cheese));     free (item);      zlist_destroy (&list);     assert (list == NULL); zlistx - extended generic list container Provides a generic doubly-linked list container. This container provides hooks for duplicator, comparator, and destructor functions. These tie into CZMQ and standard C semantics, so e.g. for string items you can use strdup, strcmp, and zstr_free. To store custom objects, define your own duplicator and comparator, and use the standard object destructor. This is a reworking of the simpler zlist container. It is faster to insert and delete items anywhere in the list, and to keep ordered lists. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     // Destroy an item     typedef void (zlistx_destructor_fn) (         void **item);      // Duplicate an item     typedef void * (zlistx_duplicator_fn) (         const void *item);      // Compare two items, for sorting     typedef int (zlistx_comparator_fn) (         const void *item1, const void *item2);      //  Create a new, empty list.     CZMQ_EXPORT zlistx_t *         zlistx_new (void);      //  Destroy a list. If an item destructor was specified, all items in the     //  list are automatically destroyed as well.                                 CZMQ_EXPORT void         zlistx_destroy (zlistx_t **self_p);      //  Add an item to the head of the list. Calls the item duplicator, if any,     //  on the item. Resets cursor to list head. Returns an item handle on          //  success, NULL if memory was exhausted.                                      CZMQ_EXPORT void *         zlistx_add_start (zlistx_t *self, void *item);      //  Add an item to the tail of the list. Calls the item duplicator, if any,     //  on the item. Resets cursor to list head. Returns an item handle on          //  success, NULL if memory was exhausted.                                      CZMQ_EXPORT void *         zlistx_add_end (zlistx_t *self, void *item);      //  Return the number of items in the list     CZMQ_EXPORT size_t         zlistx_size (zlistx_t *self);      //  Return first item in the list, or null, leaves the cursor     CZMQ_EXPORT void *         zlistx_head (zlistx_t *self);      //  Return last item in the list, or null, leaves the cursor     CZMQ_EXPORT void *         zlistx_tail (zlistx_t *self);      //  Return the item at the head of list. If the list is empty, returns NULL.     //  Leaves cursor pointing at the head item, or NULL if the list is empty.       CZMQ_EXPORT void *         zlistx_first (zlistx_t *self);      //  Return the next item. At the end of the list (or in an empty list),          //  returns NULL. Use repeated zlistx_next () calls to work through the list     //  from zlistx_first (). First time, acts as zlistx_first().                    CZMQ_EXPORT void *         zlistx_next (zlistx_t *self);      //  Return the previous item. At the start of the list (or in an empty list),     //  returns NULL. Use repeated zlistx_prev () calls to work through the list      //  backwards from zlistx_last (). First time, acts as zlistx_last().             CZMQ_EXPORT void *         zlistx_prev (zlistx_t *self);      //  Return the item at the tail of list. If the list is empty, returns NULL.     //  Leaves cursor pointing at the tail item, or NULL if the list is empty.       CZMQ_EXPORT void *         zlistx_last (zlistx_t *self);      //  Returns the value of the item at the cursor, or NULL if the cursor is     //  not pointing to an item.                                                  CZMQ_EXPORT void *         zlistx_item (zlistx_t *self);      //  Returns the handle of the item at the cursor, or NULL if the cursor is     //  not pointing to an item.                                                   CZMQ_EXPORT void *         zlistx_cursor (zlistx_t *self);      //  Returns the item associated with the given list handle, or NULL if passed          //  in handle is NULL. Asserts that the passed in handle points to a list element.     CZMQ_EXPORT void *         zlistx_handle_item (void *handle);      //  Find an item in the list, searching from the start. Uses the item          //  comparator, if any, else compares item values directly. Returns the        //  item handle found, or NULL. Sets the cursor to the found item, if any.     CZMQ_EXPORT void *         zlistx_find (zlistx_t *self, void *item);      //  Detach an item from the list, using its handle. The item is not modified,      //  and the caller is responsible for destroying it if necessary. If handle is     //  null, detaches the first item on the list. Returns item that was detached,     //  or null if none was. If cursor was at item, moves cursor to previous item,     //  so you can detach items while iterating forwards through a list.               CZMQ_EXPORT void *         zlistx_detach (zlistx_t *self, void *handle);      //  Detach item at the cursor, if any, from the list. The item is not modified,     //  and the caller is responsible for destroying it as necessary. Returns item      //  that was detached, or null if none was. Moves cursor to previous item, so       //  you can detach items while iterating forwards through a list.                   CZMQ_EXPORT void *         zlistx_detach_cur (zlistx_t *self);      //  Delete an item, using its handle. Calls the item destructor is any is      //  set. If handle is null, deletes the first item on the list. Returns 0      //  if an item was deleted, -1 if not. If cursor was at item, moves cursor     //  to previous item, so you can delete items while iterating forwards         //  through a list.                                                            CZMQ_EXPORT int         zlistx_delete (zlistx_t *self, void *handle);      //  Move an item to the start of the list, via its handle.     CZMQ_EXPORT void         zlistx_move_start (zlistx_t *self, void *handle);      //  Move an item to the end of the list, via its handle.     CZMQ_EXPORT void         zlistx_move_end (zlistx_t *self, void *handle);      //  Remove all items from the list, and destroy them if the item destructor     //  is set.                                                                     CZMQ_EXPORT void         zlistx_purge (zlistx_t *self);      //  Sort the list. If an item comparator was set, calls that to compare         //  items, otherwise compares on item value. The sort is not stable, so may     //  reorder equal items.                                                        CZMQ_EXPORT void         zlistx_sort (zlistx_t *self);      //  Create a new node and insert it into a sorted list. Calls the item             //  duplicator, if any, on the item. If low_value is true, starts searching        //  from the start of the list, otherwise searches from the end. Use the item      //  comparator, if any, to find where to place the new node. Returns a handle      //  to the new node, or NULL if memory was exhausted. Resets the cursor to the     //  list head.                                                                     CZMQ_EXPORT void *         zlistx_insert (zlistx_t *self, void *item, bool low_value);      //  Move an item, specified by handle, into position in a sorted list. Uses      //  the item comparator, if any, to determine the new location. If low_value     //  is true, starts searching from the start of the list, otherwise searches     //  from the end.                                                                CZMQ_EXPORT void         zlistx_reorder (zlistx_t *self, void *handle, bool low_value);      //  Make a copy of the list; items are duplicated if you set a duplicator     //  for the list, otherwise not. Copying a null reference returns a null      //  reference.                                                                CZMQ_EXPORT zlistx_t *         zlistx_dup (zlistx_t *self);      //  Set a user-defined deallocator for list items; by default items are not     //  freed when the list is destroyed.                                           CZMQ_EXPORT void         zlistx_set_destructor (zlistx_t *self, zlistx_destructor_fn destructor);      //  Set a user-defined duplicator for list items; by default items are not     //  copied when the list is duplicated.                                        CZMQ_EXPORT void         zlistx_set_duplicator (zlistx_t *self, zlistx_duplicator_fn duplicator);      //  Set a user-defined comparator for zlistx_find and zlistx_sort; the method      //  must return -1, 0, or 1 depending on whether item1 is less than, equal to,     //  or greater than, item2.                                                        CZMQ_EXPORT void         zlistx_set_comparator (zlistx_t *self, zlistx_comparator_fn comparator);      //  Self test of this class.     CZMQ_EXPORT void         zlistx_test (bool verbose);  This is the class self test code:     zlistx_t *list = zlistx_new ();     assert (list);     assert (zlistx_size (list) == 0);      //  Test operations on an empty list     assert (zlistx_first (list) == NULL);     assert (zlistx_last (list) == NULL);     assert (zlistx_next (list) == NULL);     assert (zlistx_prev (list) == NULL);     assert (zlistx_find (list, ""hello"") == NULL);     assert (zlistx_delete (list, NULL) == -1);     assert (zlistx_detach (list, NULL) == NULL);     assert (zlistx_delete (list, NULL) == -1);     assert (zlistx_detach (list, NULL) == NULL);     zlistx_purge (list);     zlistx_sort (list);      //  Use item handlers     zlistx_set_destructor (list, (zlistx_destructor_fn *) zstr_free);     zlistx_set_duplicator (list, (zlistx_duplicator_fn *) strdup);     zlistx_set_comparator (list, (zlistx_comparator_fn *) strcmp);      //  Try simple insert/sort/delete/next     assert (zlistx_next (list) == NULL);     zlistx_add_end (list, ""world"");     assert (streq ((char *) zlistx_next (list), ""world""));     zlistx_add_end (list, ""hello"");     assert (streq ((char *) zlistx_prev (list), ""hello""));     zlistx_sort (list);     assert (zlistx_size (list) == 2);     void *handle = zlistx_find (list, ""hello"");     char *item1 = (char *) zlistx_item (list);     char *item2 = (char *) zlistx_handle_item (handle);     assert (item1 == item2);     assert (streq (item1, ""hello""));     zlistx_delete (list, handle);     assert (zlistx_size (list) == 1);     char *string = (char *) zlistx_detach (list, NULL);     assert (streq (string, ""world""));     free (string);     assert (zlistx_size (list) == 0);      //  Check next/back work     //  Now populate the list with items     zlistx_add_start (list, ""five"");     zlistx_add_end   (list, ""six"");     zlistx_add_start (list, ""four"");     zlistx_add_end   (list, ""seven"");     zlistx_add_start (list, ""three"");     zlistx_add_end   (list, ""eight"");     zlistx_add_start (list, ""two"");     zlistx_add_end   (list, ""nine"");     zlistx_add_start (list, ""one"");     zlistx_add_end   (list, ""ten"");      //  Test our navigation skills     assert (zlistx_size (list) == 10);     assert (streq ((char *) zlistx_last (list), ""ten""));     assert (streq ((char *) zlistx_prev (list), ""nine""));     assert (streq ((char *) zlistx_prev (list), ""eight""));     assert (streq ((char *) zlistx_prev (list), ""seven""));     assert (streq ((char *) zlistx_prev (list), ""six""));     assert (streq ((char *) zlistx_prev (list), ""five""));     assert (streq ((char *) zlistx_first (list), ""one""));     assert (streq ((char *) zlistx_next (list), ""two""));     assert (streq ((char *) zlistx_next (list), ""three""));     assert (streq ((char *) zlistx_next (list), ""four""));      //  Sort by alphabetical order     zlistx_sort (list);     assert (streq ((char *) zlistx_first (list), ""eight""));     assert (streq ((char *) zlistx_last (list), ""two""));      //  Moving items around     handle = zlistx_find (list, ""six"");     zlistx_move_start (list, handle);     assert (streq ((char *) zlistx_first (list), ""six""));     zlistx_move_end (list, handle);     assert (streq ((char *) zlistx_last (list), ""six""));     zlistx_sort (list);     assert (streq ((char *) zlistx_last (list), ""two""));      //  Copying a list     zlistx_t *copy = zlistx_dup (list);     assert (copy);     assert (zlistx_size (copy) == 10);     assert (streq ((char *) zlistx_first (copy), ""eight""));     assert (streq ((char *) zlistx_last (copy), ""two""));     zlistx_destroy (&copy);      //  Delete items while iterating     string = (char *) zlistx_first (list);     assert (streq (string, ""eight""));     string = (char *) zlistx_next (list);     assert (streq (string, ""five""));     zlistx_delete (list, zlistx_cursor (list));     string = (char *) zlistx_next (list);     assert (streq (string, ""four""));      zlistx_purge (list);     zlistx_destroy (&list); zloop - event-driven reactor The zloop class provides an event-driven reactor pattern. The reactor handles zmq_pollitem_t items (pollers or writers, sockets or fds), and once-off or repeated timers. Its resolution is 1 msec. It uses a tickless timer to reduce CPU interrupts in inactive processes. Please add @discuss section in ../src/zloop.c. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     //  This class has draft methods, which may change over time. They are not     //  in stable releases, by default. Use --enable-drafts to enable.     // Callback function for reactor socket activity     typedef int (zloop_reader_fn) (         zloop_t *loop, zsock_t *reader, void *arg);      // Callback function for reactor events (low-level)     typedef int (zloop_fn) (         zloop_t *loop, zmq_pollitem_t *item, void *arg);      // Callback for reactor timer events     typedef int (zloop_timer_fn) (         zloop_t *loop, int timer_id, void *arg);      //  Create a new zloop reactor     CZMQ_EXPORT zloop_t *         zloop_new (void);      //  Destroy a reactor     CZMQ_EXPORT void         zloop_destroy (zloop_t **self_p);      //  Register socket reader with the reactor. When the reader has messages,      //  the reactor will call the handler, passing the arg. Returns 0 if OK, -1     //  if there was an error. If you register the same socket more than once,      //  each instance will invoke its corresponding handler.                        CZMQ_EXPORT int         zloop_reader (zloop_t *self, zsock_t *sock, zloop_reader_fn handler, void *arg);      //  Cancel a socket reader from the reactor. If multiple readers exist for     //  same socket, cancels ALL of them.                                          CZMQ_EXPORT void         zloop_reader_end (zloop_t *self, zsock_t *sock);      //  Configure a registered reader to ignore errors. If you do not set this,     //  then readers that have errors are removed from the reactor silently.        CZMQ_EXPORT void         zloop_reader_set_tolerant (zloop_t *self, zsock_t *sock);      //  Register low-level libzmq pollitem with the reactor. When the pollitem       //  is ready, will call the handler, passing the arg. Returns 0 if OK, -1        //  if there was an error. If you register the pollitem more than once, each     //  instance will invoke its corresponding handler. A pollitem with              //  socket=NULL and fd=0 means 'poll on FD zero'.                                CZMQ_EXPORT int         zloop_poller (zloop_t *self, zmq_pollitem_t *item, zloop_fn handler, void *arg);      //  Cancel a pollitem from the reactor, specified by socket or FD. If both     //  are specified, uses only socket. If multiple poll items exist for same     //  socket/FD, cancels ALL of them.                                            CZMQ_EXPORT void         zloop_poller_end (zloop_t *self, zmq_pollitem_t *item);      //  Configure a registered poller to ignore errors. If you do not set this,     //  then poller that have errors are removed from the reactor silently.         CZMQ_EXPORT void         zloop_poller_set_tolerant (zloop_t *self, zmq_pollitem_t *item);      //  Register a timer that expires after some delay and repeats some number of     //  times. At each expiry, will call the handler, passing the arg. To run a       //  timer forever, use 0 times. Returns a timer_id that is used to cancel the     //  timer in the future. Returns -1 if there was an error.                        CZMQ_EXPORT int         zloop_timer (zloop_t *self, size_t delay, size_t times, zloop_timer_fn handler, void *arg);      //  Cancel a specific timer identified by a specific timer_id (as returned by     //  zloop_timer).                                                                 CZMQ_EXPORT int         zloop_timer_end (zloop_t *self, int timer_id);      //  Register a ticket timer. Ticket timers are very fast in the case where        //  you use a lot of timers (thousands), and frequently remove and add them.      //  The main use case is expiry timers for servers that handle many clients,      //  and which reset the expiry timer for each message received from a client.     //  Whereas normal timers perform poorly as the number of clients grows, the      //  cost of ticket timers is constant, no matter the number of clients. You       //  must set the ticket delay using zloop_set_ticket_delay before creating a      //  ticket. Returns a handle to the timer that you should use in                  //  zloop_ticket_reset and zloop_ticket_delete.                                   CZMQ_EXPORT void *         zloop_ticket (zloop_t *self, zloop_timer_fn handler, void *arg);      //  Reset a ticket timer, which moves it to the end of the ticket list and     //  resets its execution time. This is a very fast operation.                  CZMQ_EXPORT void         zloop_ticket_reset (zloop_t *self, void *handle);      //  Delete a ticket timer. We do not actually delete the ticket here, as         //  other code may still refer to the ticket. We mark as deleted, and remove     //  later and safely.                                                            CZMQ_EXPORT void         zloop_ticket_delete (zloop_t *self, void *handle);      //  Set the ticket delay, which applies to all tickets. If you lower the        //  delay and there are already tickets created, the results are undefined.     CZMQ_EXPORT void         zloop_set_ticket_delay (zloop_t *self, size_t ticket_delay);      //  Set hard limit on number of timers allowed. Setting more than a small       //  number of timers (10-100) can have a dramatic impact on the performance     //  of the reactor. For high-volume cases, use ticket timers. If the hard       //  limit is reached, the reactor stops creating new timers and logs an         //  error.                                                                      CZMQ_EXPORT void         zloop_set_max_timers (zloop_t *self, size_t max_timers);      //  Set verbose tracing of reactor on/off. The default verbose setting is     //  off (false).                                                              CZMQ_EXPORT void         zloop_set_verbose (zloop_t *self, bool verbose);      //  Start the reactor. Takes control of the thread and returns when the ØMQ       //  context is terminated or the process is interrupted, or any event handler     //  returns -1. Event handlers may register new sockets and timers, and           //  cancel sockets. Returns 0 if interrupted, -1 if canceled by a handler.        CZMQ_EXPORT int         zloop_start (zloop_t *self);      //  Self test of this class.     CZMQ_EXPORT void         zloop_test (bool verbose);      #ifdef CZMQ_BUILD_DRAFT_API     //  *** Draft method, for development use, may change without warning ***     //  By default the reactor stops if the process receives a SIGINT or SIGTERM      //  signal. This makes it impossible to shut-down message based architectures     //  like zactors. This method lets you switch off break handling. The default     //  nonstop setting is off (false).                                               CZMQ_EXPORT void         zloop_set_nonstop (zloop_t *self, bool nonstop);      #endif // CZMQ_BUILD_DRAFT_API This is the class self test code:     //  Create two PAIR sockets and connect over inproc     zsock_t *output = zsock_new (ZMQ_PAIR);     assert (output);     zsock_bind (output, ""inproc://zloop.test"");      zsock_t *input = zsock_new (ZMQ_PAIR);     assert (input);     zsock_connect (input, ""inproc://zloop.test"");      zloop_t *loop = zloop_new ();     assert (loop);     zloop_set_verbose (loop, verbose);      //  Create a timer that will be cancelled     int timer_id = zloop_timer (loop, 1000, 1, s_timer_event, NULL);     zloop_timer (loop, 5, 1, s_cancel_timer_event, &timer_id);      //  After 20 msecs, send a ping message to output3     zloop_timer (loop, 20, 1, s_timer_event, output);      //  Set up some tickets that will never expire     zloop_set_ticket_delay (loop, 10000);     void *ticket1 = zloop_ticket (loop, s_timer_event, NULL);     void *ticket2 = zloop_ticket (loop, s_timer_event, NULL);     void *ticket3 = zloop_ticket (loop, s_timer_event, NULL);      //  When we get the ping message, end the reactor     rc = zloop_reader (loop, input, s_socket_event, NULL);     assert (rc == 0);     zloop_reader_set_tolerant (loop, input);     zloop_start (loop);      zloop_ticket_delete (loop, ticket1);     zloop_ticket_delete (loop, ticket2);     zloop_ticket_delete (loop, ticket3);      //  Check whether loop properly ignores zsys_interrupted flag     //  when asked to     zloop_destroy (&loop);     loop = zloop_new ();      bool timer_event_called = false;     zloop_timer (loop, 1, 1, s_timer_event3, &timer_event_called);      zsys_interrupted = 1;     zloop_start (loop);     //  zloop returns immediately without giving any handler a chance to run     assert (!timer_event_called);      zloop_set_nonstop (loop, true);     zloop_start (loop);     //  zloop runs the handler which will terminate the loop     assert (timer_event_called);     zsys_interrupted = 0;      //  cleanup     zloop_destroy (&loop);     assert (loop == NULL);      zsock_destroy (&input);     zsock_destroy (&output); zmonitor - socket event monitor The zmonitor actor provides an API for obtaining socket events such as connected, listen, disconnected, etc. Socket events are only available for sockets connecting or bound to ipc:// and tcp:// endpoints. This class wraps the ZMQ socket monitor API, see zmq_socket_monitor for details. Works on all versions of libzmq from 3.2 onwards. This class replaces zproxy_v2, and is meant for applications that use the CZMQ v3 API (meaning, zsock). This is the class interface:     //  Create new zmonitor actor instance to monitor a zsock_t socket:     //     //      zactor_t *monitor = zactor_new (zmonitor, mysocket);     //     //  Destroy zmonitor instance.     //     //      zactor_destroy (&monitor);     //     //  Enable verbose logging of commands and activity.     //     //      zstr_send (monitor, ""VERBOSE"");     //     //  Listen to monitor event type (zero or types, ending in NULL):     //      zstr_sendx (monitor, ""LISTEN"", type, ..., NULL);     //       //      Events:     //      CONNECTED     //      CONNECT_DELAYED     //      CONNECT_RETRIED     //      LISTENING     //      BIND_FAILED     //      ACCEPTED     //      ACCEPT_FAILED     //      CLOSED     //      CLOSE_FAILED     //      DISCONNECTED     //      MONITOR_STOPPED     //      ALL     //     //  Start monitor; after this, any further LISTEN commands are ignored.     //     //      zstr_send (monitor, ""START"");     //      zsock_wait (monitor);     //     //  Receive next monitor event:     //     //      zmsg_t *msg = zmsg_recv (monitor);     //     //  This is the zmonitor constructor as a zactor_fn; the argument can be     //  a zactor_t, zsock_t, or libzmq void * socket:     CZMQ_EXPORT void         zmonitor (zsock_t *pipe, void *sock);      //  Selftest     CZMQ_EXPORT void         zmonitor_test (bool verbose); This is the class self test code:     zsock_t *client = zsock_new (ZMQ_DEALER);     assert (client);     zactor_t *clientmon = zactor_new (zmonitor, client);     assert (clientmon);     if (verbose)         zstr_sendx (clientmon, ""VERBOSE"", NULL);     zstr_sendx (clientmon, ""LISTEN"", ""LISTENING"", ""ACCEPTED"", NULL);     zstr_sendx (clientmon, ""START"", NULL);     zsock_wait (clientmon);      zsock_t *server = zsock_new (ZMQ_DEALER);     assert (server);     zactor_t *servermon = zactor_new (zmonitor, server);     assert (servermon);     if (verbose)         zstr_sendx (servermon, ""VERBOSE"", NULL);     zstr_sendx (servermon, ""LISTEN"", ""CONNECTED"", ""DISCONNECTED"", NULL);     zstr_sendx (servermon, ""START"", NULL);     zsock_wait (servermon);      //  Allow a brief time for the message to get there...     zmq_poll (NULL, 0, 200);      //  Check client is now listening     int port_nbr = zsock_bind (client, ""tcp://127.0.0.1:*"");     assert (port_nbr != -1);     s_assert_event (clientmon, ""LISTENING"");      //  Check server connected to client     zsock_connect (server, ""tcp://127.0.0.1:%d"", port_nbr);     s_assert_event (servermon, ""CONNECTED"");      //  Check client accepted connection     s_assert_event (clientmon, ""ACCEPTED"");      zactor_destroy (&clientmon);     zactor_destroy (&servermon);     zsock_destroy (&client);     zsock_destroy (&server);     #endif zmsg - working with multipart messages The zmsg class provides methods to send and receive multipart messages across ØMQ sockets. This class provides a list-like container interface, with methods to work with the overall container. zmsg_t messages are composed of zero or more zframe_t frames. Please add @discuss section in ../src/zmsg.c. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     //  This class has draft methods, which may change over time. They are not     //  in stable releases, by default. Use --enable-drafts to enable.     //  Create a new empty message object     CZMQ_EXPORT zmsg_t *         zmsg_new (void);      //  Receive message from socket, returns zmsg_t object or NULL if the recv        //  was interrupted. Does a blocking recv. If you want to not block then use      //  the zloop class or zmsg_recv_nowait or zmq_poll to check for socket input     //  before receiving.                                                             CZMQ_EXPORT zmsg_t *         zmsg_recv (void *source);      //  Load/append an open file into new message, return the message.     //  Returns NULL if the message could not be loaded.                   CZMQ_EXPORT zmsg_t *         zmsg_load (FILE *file);      //  Decodes a serialized message frame created by zmsg_encode () and returns     //  a new zmsg_t object. Returns NULL if the frame was badly formatted or        //  there was insufficient memory to work.                                       CZMQ_EXPORT zmsg_t *         zmsg_decode (zframe_t *frame);      //  Generate a signal message encoding the given status. A signal is a short     //  message carrying a 1-byte success/failure code (by convention, 0 means       //  OK). Signals are encoded to be distinguishable from ""normal"" messages.       CZMQ_EXPORT zmsg_t *         zmsg_new_signal (byte status);      //  Destroy a message object and all frames it contains     CZMQ_EXPORT void         zmsg_destroy (zmsg_t **self_p);      //  Send message to destination socket, and destroy the message after sending     //  it successfully. If the message has no frames, sends nothing but destroys     //  the message anyhow. Nullifies the caller's reference to the message (as       //  it is a destructor).                                                          CZMQ_EXPORT int         zmsg_send (zmsg_t **self_p, void *dest);      //  Send message to destination socket as part of a multipart sequence, and      //  destroy the message after sending it successfully. Note that after a         //  zmsg_sendm, you must call zmsg_send or another method that sends a final     //  message part. If the message has no frames, sends nothing but destroys       //  the message anyhow. Nullifies the caller's reference to the message (as      //  it is a destructor).                                                         CZMQ_EXPORT int         zmsg_sendm (zmsg_t **self_p, void *dest);      //  Return size of message, i.e. number of frames (0 or more).     CZMQ_EXPORT size_t         zmsg_size (zmsg_t *self);      //  Return total size of all frames in message.     CZMQ_EXPORT size_t         zmsg_content_size (zmsg_t *self);      //  Push frame to the front of the message, i.e. before all other frames.       //  Message takes ownership of frame, will destroy it when message is sent.     //  Returns 0 on success, -1 on error. Deprecates zmsg_push, which did not      //  nullify the caller's frame reference.                                       CZMQ_EXPORT int         zmsg_prepend (zmsg_t *self, zframe_t **frame_p);      //  Add frame to the end of the message, i.e. after all other frames.           //  Message takes ownership of frame, will destroy it when message is sent.     //  Returns 0 on success. Deprecates zmsg_add, which did not nullify the        //  caller's frame reference.                                                   CZMQ_EXPORT int         zmsg_append (zmsg_t *self, zframe_t **frame_p);      //  Remove first frame from message, if any. Returns frame, or NULL.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zframe_t *         zmsg_pop (zmsg_t *self);      //  Push block of memory to front of message, as a new frame.     //  Returns 0 on success, -1 on error.                            CZMQ_EXPORT int         zmsg_pushmem (zmsg_t *self, const void *data, size_t size);      //  Add block of memory to the end of the message, as a new frame.     //  Returns 0 on success, -1 on error.                                 CZMQ_EXPORT int         zmsg_addmem (zmsg_t *self, const void *data, size_t size);      //  Push string as new frame to front of message.     //  Returns 0 on success, -1 on error.                CZMQ_EXPORT int         zmsg_pushstr (zmsg_t *self, const char *string);      //  Push string as new frame to end of message.     //  Returns 0 on success, -1 on error.              CZMQ_EXPORT int         zmsg_addstr (zmsg_t *self, const char *string);      //  Push formatted string as new frame to front of message.     //  Returns 0 on success, -1 on error.                          CZMQ_EXPORT int         zmsg_pushstrf (zmsg_t *self, const char *format, ...);      //  Push formatted string as new frame to end of message.     //  Returns 0 on success, -1 on error.                        CZMQ_EXPORT int         zmsg_addstrf (zmsg_t *self, const char *format, ...);      //  Pop frame off front of message, return as fresh string. If there were     //  no more frames in the message, returns NULL.                              //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zmsg_popstr (zmsg_t *self);      //  Push encoded message as a new frame. Message takes ownership of         //  submessage, so the original is destroyed in this call. Returns 0 on     //  success, -1 on error.                                                   CZMQ_EXPORT int         zmsg_addmsg (zmsg_t *self, zmsg_t **msg_p);      //  Remove first submessage from message, if any. Returns zmsg_t, or NULL if     //  decoding was not successful.                                                 //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zmsg_t *         zmsg_popmsg (zmsg_t *self);      //  Remove specified frame from list, if present. Does not destroy frame.     CZMQ_EXPORT void         zmsg_remove (zmsg_t *self, zframe_t *frame);      //  Set cursor to first frame in message. Returns frame, or NULL, if the     //  message is empty. Use this to navigate the frames as a list.             CZMQ_EXPORT zframe_t *         zmsg_first (zmsg_t *self);      //  Return the next frame. If there are no more frames, returns NULL. To move     //  to the first frame call zmsg_first(). Advances the cursor.                    CZMQ_EXPORT zframe_t *         zmsg_next (zmsg_t *self);      //  Return the last frame. If there are no frames, returns NULL.     CZMQ_EXPORT zframe_t *         zmsg_last (zmsg_t *self);      //  Save message to an open file, return 0 if OK, else -1. The message is       //  saved as a series of frames, each with length and data. Note that the       //  file is NOT guaranteed to be portable between operating systems, not        //  versions of CZMQ. The file format is at present undocumented and liable     //  to arbitrary change.                                                        CZMQ_EXPORT int         zmsg_save (zmsg_t *self, FILE *file);      //  Serialize multipart message to a single message frame. Use this method     //  to send structured messages across transports that do not support          //  multipart data. Allocates and returns a new frame containing the           //  serialized message. To decode a serialized message frame, use              //  zmsg_decode ().                                                            //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zframe_t *         zmsg_encode (zmsg_t *self);      //  Create copy of message, as new message object. Returns a fresh zmsg_t     //  object. If message is null, or memory was exhausted, returns null.        //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT zmsg_t *         zmsg_dup (zmsg_t *self);      //  Send message to zsys log sink (may be stdout, or system facility as     //  configured by zsys_set_logstream).                                      CZMQ_EXPORT void         zmsg_print (zmsg_t *self);      //  Return true if the two messages have the same number of frames and each       //  frame in the first message is identical to the corresponding frame in the     //  other message. As with zframe_eq, return false if either message is NULL.     CZMQ_EXPORT bool         zmsg_eq (zmsg_t *self, zmsg_t *other);      //  Return signal value, 0 or greater, if message is a signal, -1 if not.     CZMQ_EXPORT int         zmsg_signal (zmsg_t *self);      //  Probe the supplied object, and report if it looks like a zmsg_t.     CZMQ_EXPORT bool         zmsg_is (void *self);      //  Self test of this class.     CZMQ_EXPORT void         zmsg_test (bool verbose);      #ifdef CZMQ_BUILD_DRAFT_API     //  *** Draft method, for development use, may change without warning ***     //  Return message routing ID, if the message came from a ZMQ_SERVER socket.     //  Else returns zero.                                                           CZMQ_EXPORT uint32_t         zmsg_routing_id (zmsg_t *self);      //  *** Draft method, for development use, may change without warning ***     //  Set routing ID on message. This is used if/when the message is sent to a     //  ZMQ_SERVER socket.                                                           CZMQ_EXPORT void         zmsg_set_routing_id (zmsg_t *self, uint32_t routing_id);      #endif // CZMQ_BUILD_DRAFT_API This is the class self test code:     //  Create two PAIR sockets and connect over inproc     zsock_t *output = zsock_new_pair (""@inproc://zmsg.test"");     assert (output);     zsock_t *input = zsock_new_pair ("">inproc://zmsg.test"");     assert (input);      //  Test send and receive of single-frame message     zmsg_t *msg = zmsg_new ();     assert (msg);     zframe_t *frame = zframe_new (""Hello"", 5);     assert (frame);     zmsg_prepend (msg, &frame);     assert (zmsg_size (msg) == 1);     assert (zmsg_content_size (msg) == 5);     rc = zmsg_send (&msg, output);     assert (msg == NULL);     assert (rc == 0);      msg = zmsg_recv (input);     assert (msg);     assert (zmsg_size (msg) == 1);     assert (zmsg_content_size (msg) == 5);     zmsg_destroy (&msg);      //  Test send and receive of multi-frame message     msg = zmsg_new ();     assert (msg);     rc = zmsg_addmem (msg, ""Frame0"", 6);     assert (rc == 0);     rc = zmsg_addmem (msg, ""Frame1"", 6);     assert (rc == 0);     rc = zmsg_addmem (msg, ""Frame2"", 6);     assert (rc == 0);     rc = zmsg_addmem (msg, ""Frame3"", 6);     assert (rc == 0);     rc = zmsg_addmem (msg, ""Frame4"", 6);     assert (rc == 0);     rc = zmsg_addmem (msg, ""Frame5"", 6);     assert (rc == 0);     rc = zmsg_addmem (msg, ""Frame6"", 6);     assert (rc == 0);     rc = zmsg_addmem (msg, ""Frame7"", 6);     assert (rc == 0);     rc = zmsg_addmem (msg, ""Frame8"", 6);     assert (rc == 0);     rc = zmsg_addmem (msg, ""Frame9"", 6);     assert (rc == 0);     zmsg_t *copy = zmsg_dup (msg);     assert (copy);     rc = zmsg_send (&copy, output);     assert (rc == 0);     rc = zmsg_send (&msg, output);     assert (rc == 0);      copy = zmsg_recv (input);     assert (copy);     assert (zmsg_size (copy) == 10);     assert (zmsg_content_size (copy) == 60);     zmsg_destroy (&copy);      msg = zmsg_recv (input);     assert (msg);     assert (zmsg_size (msg) == 10);     assert (zmsg_content_size (msg) == 60);      //  Save to a file, read back     FILE *file = fopen (""zmsg.test"", ""w"");     assert (file);     rc = zmsg_save (msg, file);     assert (rc == 0);     fclose (file);      file = fopen (""zmsg.test"", ""r"");     rc = zmsg_save (msg, file);     assert (rc == -1);     fclose (file);     zmsg_destroy (&msg);      file = fopen (""zmsg.test"", ""r"");     msg = zmsg_load (file);     assert (msg);     fclose (file);     remove (""zmsg.test"");     assert (zmsg_size (msg) == 10);     assert (zmsg_content_size (msg) == 60);      //  Remove all frames except first and last     int frame_nbr;     for (frame_nbr = 0; frame_nbr < 8; frame_nbr++) {         zmsg_first (msg);         frame = zmsg_next (msg);         zmsg_remove (msg, frame);         zframe_destroy (&frame);     }     //  Test message frame manipulation     assert (zmsg_size (msg) == 2);     frame = zmsg_last (msg);     assert (zframe_streq (frame, ""Frame9""));     assert (zmsg_content_size (msg) == 12);     frame = zframe_new (""Address"", 7);     assert (frame);     zmsg_prepend (msg, &frame);     assert (zmsg_size (msg) == 3);     rc = zmsg_addstr (msg, ""Body"");     assert (rc == 0);     assert (zmsg_size (msg) == 4);     frame = zmsg_pop (msg);     zframe_destroy (&frame);     assert (zmsg_size (msg) == 3);     char *body = zmsg_popstr (msg);     assert (streq (body, ""Frame0""));     free (body);     zmsg_destroy (&msg);      //  Test encoding/decoding     msg = zmsg_new ();     assert (msg);     byte *blank = (byte *) zmalloc (100000);     assert (blank);     rc = zmsg_addmem (msg, blank, 0);     assert (rc == 0);     rc = zmsg_addmem (msg, blank, 1);     assert (rc == 0);     rc = zmsg_addmem (msg, blank, 253);     assert (rc == 0);     rc = zmsg_addmem (msg, blank, 254);     assert (rc == 0);     rc = zmsg_addmem (msg, blank, 255);     assert (rc == 0);     rc = zmsg_addmem (msg, blank, 256);     assert (rc == 0);     rc = zmsg_addmem (msg, blank, 65535);     assert (rc == 0);     rc = zmsg_addmem (msg, blank, 65536);     assert (rc == 0);     rc = zmsg_addmem (msg, blank, 65537);     assert (rc == 0);     free (blank);     assert (zmsg_size (msg) == 9);     frame = zmsg_encode (msg);     zmsg_destroy (&msg);     msg = zmsg_decode (frame);     assert (msg);     zmsg_destroy (&msg);     zframe_destroy (&frame);      //  Test submessages     msg = zmsg_new ();     assert (msg);     zmsg_t *submsg = zmsg_new ();     zmsg_pushstr (msg, ""matr"");     zmsg_pushstr (submsg, ""joska"");     rc = zmsg_addmsg (msg, &submsg);     assert (rc == 0);     assert (submsg == NULL);     submsg = zmsg_popmsg (msg);     assert (submsg == NULL);   // string ""matr"" is not encoded zmsg_t, so was discarded     submsg = zmsg_popmsg (msg);     assert (submsg);     body = zmsg_popstr (submsg);     assert (streq (body, ""joska""));     free (body);     zmsg_destroy (&submsg);     frame = zmsg_pop (msg);     assert (frame == NULL);     zmsg_destroy (&msg);      //  Test comparison of two messages     msg = zmsg_new ();     zmsg_addstr (msg, ""One"");     zmsg_addstr (msg, ""Two"");     zmsg_addstr (msg, ""Three"");     zmsg_t *msg_other = zmsg_new ();     zmsg_addstr (msg_other, ""One"");     zmsg_addstr (msg_other, ""Two"");     zmsg_addstr (msg_other, ""One-Hundred"");     zmsg_t *msg_dup = zmsg_dup (msg);     zmsg_t *empty_msg = zmsg_new ();     zmsg_t *empty_msg_2 = zmsg_new ();     assert (zmsg_eq (msg, msg_dup));     assert (!zmsg_eq (msg, msg_other));     assert (zmsg_eq (empty_msg, empty_msg_2));     assert (!zmsg_eq (msg, NULL));     assert (!zmsg_eq (NULL, empty_msg));     assert (!zmsg_eq (NULL, NULL));     zmsg_destroy (&msg);     zmsg_destroy (&msg_other);     zmsg_destroy (&msg_dup);     zmsg_destroy (&empty_msg);     zmsg_destroy (&empty_msg_2);      //  Test signal messages     msg = zmsg_new_signal (0);     assert (zmsg_signal (msg) == 0);     zmsg_destroy (&msg);     msg = zmsg_new_signal (-1);     assert (zmsg_signal (msg) == 255);     zmsg_destroy (&msg);      //  Now try methods on an empty message     msg = zmsg_new ();     assert (msg);     assert (zmsg_size (msg) == 0);     assert (zmsg_unwrap (msg) == NULL);     assert (zmsg_first (msg) == NULL);     assert (zmsg_last (msg) == NULL);     assert (zmsg_next (msg) == NULL);     assert (zmsg_pop (msg) == NULL);     //  Sending an empty message is valid and destroys the message     assert (zmsg_send (&msg, output) == 0);     assert (!msg);      zsock_destroy (&input);     zsock_destroy (&output);      #if defined (ZMQ_SERVER)     //  Create server and client sockets and connect over inproc     zsock_t *server = zsock_new_server (""inproc://zmsg-test-routing"");     assert (server);     zsock_t *client = zsock_new_client (""inproc://zmsg-test-routing"");     assert (client);      //  Send request from client to server     zmsg_t *request = zmsg_new ();     assert (request);     zmsg_addstr (request, ""Hello"");     rc = zmsg_send (&request, client);     assert (rc == 0);     assert (!request);      //  Read request and send reply     request = zmsg_recv (server);     assert (request);     char *string = zmsg_popstr (request);     assert (streq (string, ""Hello""));     assert (zmsg_routing_id (request));     zstr_free (&string);      zmsg_t *reply = zmsg_new ();     assert (reply);     zmsg_addstr (reply, ""World"");     zmsg_set_routing_id (reply, zmsg_routing_id (request));     rc = zmsg_send (&reply, server);     assert (rc == 0);     zmsg_destroy (&request);      //  Read reply     reply = zmsg_recv (client);     string = zmsg_popstr (reply);     assert (streq (string, ""World""));     assert (zmsg_routing_id (reply) == 0);     zmsg_destroy (&reply);     zstr_free (&string);      //  Client and server disallow multipart     msg = zmsg_new ();     zmsg_addstr (msg, ""One"");     zmsg_addstr (msg, ""Two"");     rc = zmsg_send (&msg, client);     assert (rc == -1);     assert (zmsg_size (msg) == 2);     rc = zmsg_send (&msg, server);     assert (rc == -1);     assert (zmsg_size (msg) == 2);     zmsg_destroy (&msg);      zsock_destroy (&client);     zsock_destroy (&server);     #endif zpoller - trivial socket poller class The zpoller class provides a minimalist interface to ZeroMQ's zmq_poll API, for the very common case of reading from a number of sockets. It does not provide polling for output, nor polling on file handles. If you need either of these, use the zmq_poll API directly. The class implements the poller using the zmq_poller API if that exists, else does the work itself. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     //  This class has draft methods, which may change over time. They are not     //  in stable releases, by default. Use --enable-drafts to enable.     //  Create new poller, specifying zero or more readers. The list of      //  readers ends in a NULL. Each reader can be a zsock_t instance, a     //  zactor_t instance, a libzmq socket (void *), or a file handle.       CZMQ_EXPORT zpoller_t *         zpoller_new (void *reader, ...);      //  Destroy a poller     CZMQ_EXPORT void         zpoller_destroy (zpoller_t **self_p);      //  Add a reader to be polled. Returns 0 if OK, -1 on failure. The reader may     //  be a libzmq void * socket, a zsock_t instance, or a zactor_t instance.        CZMQ_EXPORT int         zpoller_add (zpoller_t *self, void *reader);      //  Remove a reader from the poller; returns 0 if OK, -1 on failure. The reader     //  must have been passed during construction, or in an zpoller_add () call.        CZMQ_EXPORT int         zpoller_remove (zpoller_t *self, void *reader);      //  Poll the registered readers for I/O, return first reader that has input.       //  The reader will be a libzmq void * socket, or a zsock_t or zactor_t            //  instance as specified in zpoller_new/zpoller_add. The timeout should be        //  zero or greater, or -1 to wait indefinitely. Socket priority is defined        //  by their order in the poll list. If you need a balanced poll, use the low      //  level zmq_poll method directly. If the poll call was interrupted (SIGINT),     //  or the ZMQ context was destroyed, or the timeout expired, returns NULL.        //  You can test the actual exit condition by calling zpoller_expired () and       //  zpoller_terminated (). The timeout is in msec.                                 CZMQ_EXPORT void *         zpoller_wait (zpoller_t *self, int timeout);      //  Return true if the last zpoller_wait () call ended because the timeout     //  expired, without any error.                                                CZMQ_EXPORT bool         zpoller_expired (zpoller_t *self);      //  Return true if the last zpoller_wait () call ended because the process     //  was interrupted, or the parent context was destroyed.                      CZMQ_EXPORT bool         zpoller_terminated (zpoller_t *self);      //  Self test of this class.     CZMQ_EXPORT void         zpoller_test (bool verbose);      #ifdef CZMQ_BUILD_DRAFT_API     //  *** Draft method, for development use, may change without warning ***     //  By default the poller stops if the process receives a SIGINT or SIGTERM       //  signal. This makes it impossible to shut-down message based architectures     //  like zactors. This method lets you switch off break handling. The default     //  nonstop setting is off (false).                                               CZMQ_EXPORT void         zpoller_set_nonstop (zpoller_t *self, bool nonstop);      #endif // CZMQ_BUILD_DRAFT_API This is the class self test code:     //  Create a few sockets     zsock_t *vent = zsock_new (ZMQ_PUSH);     assert (vent);     int port_nbr = zsock_bind (vent, ""tcp://127.0.0.1:*"");     assert (port_nbr != -1);     zsock_t *sink = zsock_new (ZMQ_PULL);     assert (sink);     int rc = zsock_connect (sink, ""tcp://127.0.0.1:%d"", port_nbr);     assert (rc != -1);     zsock_t *bowl = zsock_new (ZMQ_PULL);     assert (bowl);     zsock_t *dish = zsock_new (ZMQ_PULL);     assert (dish);      //  Set up poller     zpoller_t *poller = zpoller_new (bowl, dish, NULL);     assert (poller);      // Add a reader to the existing poller     rc = zpoller_add (poller, sink);     assert (rc == 0);      zstr_send (vent, ""Hello, World"");      //  We expect a message only on the sink     zsock_t *which = (zsock_t *) zpoller_wait (poller, -1);     assert (which == sink);     assert (zpoller_expired (poller) == false);     assert (zpoller_terminated (poller) == false);     char *message = zstr_recv (which);     assert (streq (message, ""Hello, World""));     zstr_free (&message);      //  Stop polling reader     rc = zpoller_remove (poller, sink);     assert (rc == 0);      //  Check we can poll an FD     rc = zsock_connect (bowl, ""tcp://127.0.0.1:%d"", port_nbr);     assert (rc != -1);     SOCKET fd = zsock_fd (bowl);     rc = zpoller_add (poller, (void *) &fd);     assert (rc != -1);     zstr_send (vent, ""Hello again, world"");     assert (zpoller_wait (poller, 500) == &fd);      // Check zpoller_set_nonstop ()     zsys_interrupted = 1;     zpoller_wait (poller, 0);     assert (zpoller_terminated (poller));     zpoller_set_nonstop (poller, true);     zpoller_wait (poller, 0);     assert (!zpoller_terminated (poller));     zsys_interrupted = 0;      zpoller_destroy (&poller);     zsock_destroy (&vent);     zsock_destroy (&sink);     zsock_destroy (&bowl);     zsock_destroy (&dish);      #ifdef ZMQ_SERVER     //  Check thread safe sockets     zpoller_destroy (&poller);     zsock_t *client = zsock_new (ZMQ_CLIENT);     assert (client);     zsock_t *server = zsock_new (ZMQ_SERVER);     assert (server);     poller = zpoller_new (client, server, NULL);     assert (poller);     port_nbr = zsock_bind (server, ""tcp://127.0.0.1:*"");     assert (port_nbr != -1);     rc = zsock_connect (client, ""tcp://127.0.0.1:%d"", port_nbr);     assert (rc != -1);      zstr_send (client, ""Hello, World"");      //  We expect a message only on the server     which = (zsock_t *) zpoller_wait (poller, -1);     assert (which == server);     assert (zpoller_expired (poller) == false);     assert (zpoller_terminated (poller) == false);     message = zstr_recv (which);     assert (streq (message, ""Hello, World""));     zstr_free (&message);      zpoller_destroy (&poller);     zsock_destroy (&client);     zsock_destroy (&server);     #endif zproc - process configuration and status zproc - process configuration and status Please add @discuss section in ../src/zproc.c. This is the class interface:     //  This is a draft class, and may change without notice. It is disabled in     //  stable builds by default. If you use this in applications, please ask     //  for it to be pushed to stable state. Use --enable-drafts to enable.     #ifdef CZMQ_BUILD_DRAFT_API     //  *** Draft method, for development use, may change without warning ***     //  Returns CZMQ version as a single 6-digit integer encoding the major     //  version (x 10000), the minor version (x 100) and the patch.             CZMQ_EXPORT int         zproc_czmq_version (void);      //  *** Draft method, for development use, may change without warning ***     //  Returns true if the process received a SIGINT or SIGTERM signal.     //  It is good practice to use this method to exit any infinite loop     //  processing messages.                                                 CZMQ_EXPORT bool         zproc_interrupted (void);      //  *** Draft method, for development use, may change without warning ***     //  Returns true if the underlying libzmq supports CURVE security.     CZMQ_EXPORT bool         zproc_has_curve (void);      //  *** Draft method, for development use, may change without warning ***     //  Return current host name, for use in public tcp:// endpoints.     //  If the host name is not resolvable, returns NULL.                 //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zproc_hostname (void);      //  *** Draft method, for development use, may change without warning ***     //  Move the current process into the background. The precise effect          //  depends on the operating system. On POSIX boxes, moves to a specified     //  working directory (if specified), closes all file handles, reopens        //  stdin, stdout, and stderr to the null device, and sets the process to     //  ignore SIGHUP. On Windows, does nothing. Returns 0 if OK, -1 if there     //  was an error.                                                             CZMQ_EXPORT void         zproc_daemonize (const char *workdir);      //  *** Draft method, for development use, may change without warning ***     //  Drop the process ID into the lockfile, with exclusive lock, and        //  switch the process to the specified group and/or user. Any of the      //  arguments may be null, indicating a no-op. Returns 0 on success,       //  -1 on failure. Note if you combine this with zsys_daemonize, run       //  after, not before that method, or the lockfile will hold the wrong     //  process ID.                                                            CZMQ_EXPORT void         zproc_run_as (const char *lockfile, const char *group, const char *user);      //  *** Draft method, for development use, may change without warning ***     //  Configure the number of I/O threads that ZeroMQ will use. A good       //  rule of thumb is one thread per gigabit of traffic in or out. The      //  default is 1, sufficient for most applications. If the environment     //  variable ZSYS_IO_THREADS is defined, that provides the default.        //  Note that this method is valid only before any socket is created.      CZMQ_EXPORT void         zproc_set_io_threads (size_t io_threads);      //  *** Draft method, for development use, may change without warning ***     //  Configure the number of sockets that ZeroMQ will allow. The default       //  is 1024. The actual limit depends on the system, and you can query it     //  by using zsys_socket_limit (). A value of zero means ""maximum"".           //  Note that this method is valid only before any socket is created.         CZMQ_EXPORT void         zproc_set_max_sockets (size_t max_sockets);      //  *** Draft method, for development use, may change without warning ***     //  Set network interface name to use for broadcasts, particularly zbeacon.         //  This lets the interface be configured for test environments where required.     //  For example, on Mac OS X, zbeacon cannot bind to 255.255.255.255 which is       //  the default when there is no specified interface. If the environment            //  variable ZSYS_INTERFACE is set, use that as the default interface name.         //  Setting the interface to ""*"" means ""use all available interfaces"".              CZMQ_EXPORT void         zproc_set_biface (const char *value);      //  *** Draft method, for development use, may change without warning ***     //  Return network interface to use for broadcasts, or """" if none was set.     CZMQ_EXPORT const char *         zproc_biface (void);      //  *** Draft method, for development use, may change without warning ***     //  Set log identity, which is a string that prefixes all log messages sent     //  by this process. The log identity defaults to the environment variable      //  ZSYS_LOGIDENT, if that is set.                                              CZMQ_EXPORT void         zproc_set_log_ident (const char *value);      //  *** Draft method, for development use, may change without warning ***     //  Sends log output to a PUB socket bound to the specified endpoint. To        //  collect such log output, create a SUB socket, subscribe to the traffic      //  you care about, and connect to the endpoint. Log traffic is sent as a       //  single string frame, in the same format as when sent to stdout. The         //  log system supports a single sender; multiple calls to this method will     //  bind the same sender to multiple endpoints. To disable the sender, call     //  this method with a null argument.                                           CZMQ_EXPORT void         zproc_set_log_sender (const char *endpoint);      //  *** Draft method, for development use, may change without warning ***     //  Enable or disable logging to the system facility (syslog on POSIX boxes,     //  event log on Windows). By default this is disabled.                          CZMQ_EXPORT void         zproc_set_log_system (bool logsystem);      //  *** Draft method, for development use, may change without warning ***     //  Log error condition - highest priority     CZMQ_EXPORT void         zproc_log_error (const char *format, ...);      //  *** Draft method, for development use, may change without warning ***     //  Log warning condition - high priority     CZMQ_EXPORT void         zproc_log_warning (const char *format, ...);      //  *** Draft method, for development use, may change without warning ***     //  Log normal, but significant, condition - normal priority     CZMQ_EXPORT void         zproc_log_notice (const char *format, ...);      //  *** Draft method, for development use, may change without warning ***     //  Log informational message - low priority     CZMQ_EXPORT void         zproc_log_info (const char *format, ...);      //  *** Draft method, for development use, may change without warning ***     //  Log debug-level message - lowest priority     CZMQ_EXPORT void         zproc_log_debug (const char *format, ...);      //  *** Draft method, for development use, may change without warning ***     //  Self test of this class.     CZMQ_EXPORT void         zproc_test (bool verbose);      #endif // CZMQ_BUILD_DRAFT_API This is the class self test code: Please add @selftest section in ../src/zproc.c. zproxy - run a steerable proxy in the background A zproxy actor switches messages between a frontend and a backend socket. It acts much like the zmq_proxy_steerable method, though it makes benefit of CZMQ's facilities, to be somewhat simpler to set-up. This class replaces zproxy_v2, and is meant for applications that use the CZMQ v3 API (meaning, zsock). This is the class interface:     //  Create new zproxy actor instance. The proxy switches messages between     //  a frontend socket and a backend socket; use the FRONTEND and BACKEND     //  commands to configure these:     //     //      zactor_t *proxy = zactor_new (zproxy, NULL);     //     //  Destroy zproxy instance. This destroys the two sockets and stops any     //  message flow between them:     //     //      zactor_destroy (&proxy);     //     //  Note that all zproxy commands are synchronous, so your application always     //  waits for a signal from the actor after each command.     //     //  Enable verbose logging of commands and activity:     //     //      zstr_send (proxy, ""VERBOSE"");     //      zsock_wait (proxy);     //     //  Specify frontend socket type -- see zsock_type_str () -- and attach to     //  endpoints, see zsock_attach (). Note that a proxy socket is always     //  serverish:     //     //      zstr_sendx (proxy, ""FRONTEND"", ""XSUB"", endpoints, NULL);     //      zsock_wait (proxy);     //     //  Specify backend socket type -- see zsock_type_str () -- and attach to     //  endpoints, see zsock_attach (). Note that a proxy socket is always     //  serverish:     //     //      zstr_sendx (proxy, ""BACKEND"", ""XPUB"", endpoints, NULL);     //      zsock_wait (proxy);     //     //  Capture all proxied messages; these are delivered to the application     //  via an inproc PULL socket that you have already bound to the specified     //  endpoint:     //     //      zstr_sendx (proxy, ""CAPTURE"", endpoint, NULL);     //      zsock_wait (proxy);     //     //  Pause the proxy. A paused proxy will cease processing messages, causing     //  them to be queued up and potentially hit the high-water mark on the     //  frontend or backend socket, causing messages to be dropped, or writing     //  applications to block:     //     //      zstr_sendx (proxy, ""PAUSE"", NULL);     //      zsock_wait (proxy);     //     //  Resume the proxy. Note that the proxy starts automatically as soon as it     //  has a properly attached frontend and backend socket:     //     //      zstr_sendx (proxy, ""RESUME"", NULL);     //      zsock_wait (proxy);     //     //  Configure an authentication domain for the ""FRONTEND"" or ""BACKEND"" proxy     //  socket -- see zsock_set_zap_domain (). Call before binding socket:     //     //      zstr_sendx (proxy, ""DOMAIN"", ""FRONTEND"", ""global"", NULL);     //      zsock_wait (proxy);     //     //  Configure PLAIN authentication for the ""FRONTEND"" or ""BACKEND"" proxy     //  socket -- see zsock_set_plain_server (). Call before binding socket:     //     //      zstr_sendx (proxy, ""PLAIN"", ""BACKEND"", NULL);     //      zsock_wait (proxy);     //     //  Configure CURVE authentication for the ""FRONTEND"" or ""BACKEND"" proxy     //  socket -- see zsock_set_curve_server () -- specifying both the public and     //  secret keys of a certificate as Z85 armored strings -- see     //  zcert_public_txt () and zcert_secret_txt (). Call before binding socket:     //     //      zstr_sendx (proxy, ""CURVE"", ""FRONTEND"", public_txt, secret_txt, NULL);     //      zsock_wait (proxy);     //     //  This is the zproxy constructor as a zactor_fn; the argument is a     //  character string specifying frontend and backend socket types as two     //  uppercase strings separated by a hyphen:     CZMQ_EXPORT void         zproxy (zsock_t *pipe, void *unused);      //  Selftest     CZMQ_EXPORT void         zproxy_test (bool verbose); This is the class self test code:     //  Create and configure our proxy     zactor_t *proxy = zactor_new (zproxy, NULL);     assert (proxy);     if (verbose) {         zstr_sendx (proxy, ""VERBOSE"", NULL);         zsock_wait (proxy);     }     zstr_sendx (proxy, ""FRONTEND"", ""PULL"", ""inproc://frontend"", NULL);     zsock_wait (proxy);     zstr_sendx (proxy, ""BACKEND"", ""PUSH"", ""inproc://backend"", NULL);     zsock_wait (proxy);      //  Connect application sockets to proxy     zsock_t *faucet = zsock_new_push ("">inproc://frontend"");     assert (faucet);     zsock_t *sink = zsock_new_pull ("">inproc://backend"");     assert (sink);      //  Send some messages and check they arrived     char *hello, *world;     zstr_sendx (faucet, ""Hello"", ""World"", NULL);     zstr_recvx (sink, &hello, &world, NULL);     assert (streq (hello, ""Hello""));     assert (streq (world, ""World""));     zstr_free (&hello);     zstr_free (&world);      //  Test pause/resume functionality     zstr_sendx (proxy, ""PAUSE"", NULL);     zsock_wait (proxy);     zstr_sendx (faucet, ""Hello"", ""World"", NULL);     zsock_set_rcvtimeo (sink, 100);     zstr_recvx (sink, &hello, &world, NULL);     assert (!hello && !world);      zstr_sendx (proxy, ""RESUME"", NULL);     zsock_wait (proxy);     zstr_recvx (sink, &hello, &world, NULL);     assert (streq (hello, ""Hello""));     assert (streq (world, ""World""));     zstr_free (&hello);     zstr_free (&world);      //  Test capture functionality     zsock_t *capture = zsock_new_pull (""inproc://capture"");     assert (capture);      //  Switch on capturing, check that it works     zstr_sendx (proxy, ""CAPTURE"", ""inproc://capture"", NULL);     zsock_wait (proxy);     zstr_sendx (faucet, ""Hello"", ""World"", NULL);     zstr_recvx (sink, &hello, &world, NULL);     assert (streq (hello, ""Hello""));     assert (streq (world, ""World""));     zstr_free (&hello);     zstr_free (&world);      zstr_recvx (capture, &hello, &world, NULL);     assert (streq (hello, ""Hello""));     assert (streq (world, ""World""));     zstr_free (&hello);     zstr_free (&world);      zsock_destroy (&faucet);     zsock_destroy (&sink);     zsock_destroy (&capture);     zactor_destroy (&proxy);      //  Test socket creation dependency     proxy = zactor_new (zproxy, NULL);     assert (proxy);      sink = zsock_new_sub ("">ipc://backend"", ""whatever"");     assert (sink);      zstr_sendx (proxy, ""BACKEND"", ""XPUB"", ""ipc://backend"", NULL);     zsock_wait (proxy);      zsock_destroy(&sink);     zactor_destroy(&proxy);      #if (ZMQ_VERSION_MAJOR == 4)     // Test authentication functionality     #   define TESTDIR "".test_zproxy""      //  Create temporary directory for test files     zsys_dir_create (TESTDIR);      char *frontend = NULL;     char *backend = NULL;      //  Check there's no authentication     s_create_test_sockets (&proxy, &faucet, &sink, verbose);     s_bind_test_sockets (proxy, &frontend, &backend);     bool success = s_can_connect (&proxy, &faucet, &sink, frontend, backend, verbose);     assert (success);      //  Install the authenticator     zactor_t *auth = zactor_new (zauth, NULL);     assert (auth);     if (verbose) {         zstr_sendx (auth, ""VERBOSE"", NULL);         zsock_wait (auth);     }      //  Check there's no authentication on a default NULL server     s_bind_test_sockets (proxy, &frontend, &backend);     success = s_can_connect (&proxy, &faucet, &sink, frontend, backend, verbose);     assert (success);      //  When we set a domain on the server, we switch on authentication     //  for NULL sockets, but with no policies, the client connection     //  will be allowed.     zstr_sendx (proxy, ""DOMAIN"", ""FRONTEND"", ""global"", NULL);     zsock_wait (proxy);     s_bind_test_sockets (proxy, &frontend, &backend);     success = s_can_connect (&proxy, &faucet, &sink, frontend, backend, verbose);     assert (success);      //  Blacklist 127.0.0.1, connection should fail     zstr_sendx (proxy, ""DOMAIN"", ""FRONTEND"", ""global"", NULL);     zsock_wait (proxy);     s_bind_test_sockets (proxy, &frontend, &backend);     zstr_sendx (auth, ""DENY"", ""127.0.0.1"", NULL);     zsock_wait (auth);     success = s_can_connect (&proxy, &faucet, &sink, frontend, backend, verbose);     assert (!success);      //  Whitelist our address, which overrides the blacklist     zstr_sendx (proxy, ""DOMAIN"", ""FRONTEND"", ""global"", NULL);     zsock_wait (proxy);     zstr_sendx (proxy, ""DOMAIN"", ""BACKEND"", ""global"", NULL);     zsock_wait (proxy);     s_bind_test_sockets (proxy, &frontend, &backend);     zstr_sendx (auth, ""ALLOW"", ""127.0.0.1"", NULL);     zsock_wait (auth);     success = s_can_connect (&proxy, &faucet, &sink, frontend, backend, verbose);     assert (success);      //  Try PLAIN authentication      //  Test negative case (no server-side passwords defined)     zstr_sendx (proxy, ""PLAIN"", ""FRONTEND"", NULL);     zsock_wait (proxy);     s_bind_test_sockets (proxy, &frontend, &backend);     zsock_set_plain_username (faucet, ""admin"");     zsock_set_plain_password (faucet, ""Password"");     success = s_can_connect (&proxy, &faucet, &sink, frontend, backend, verbose);     assert (!success);      //  Test positive case (server-side passwords defined)     FILE *password = fopen (TESTDIR ""/password-file"", ""w"");     assert (password);     fprintf (password, ""admin=Password\n"");     fclose (password);     zstr_sendx (proxy, ""PLAIN"", ""FRONTEND"", NULL);     zsock_wait (proxy);     zstr_sendx (proxy, ""PLAIN"", ""BACKEND"", NULL);     zsock_wait (proxy);     s_bind_test_sockets (proxy, &frontend, &backend);     zsock_set_plain_username (faucet, ""admin"");     zsock_set_plain_password (faucet, ""Password"");     zsock_set_plain_username (sink, ""admin"");     zsock_set_plain_password (sink, ""Password"");     zstr_sendx (auth, ""PLAIN"", TESTDIR ""/password-file"", NULL);     zsock_wait (auth);     success = s_can_connect (&proxy, &faucet, &sink, frontend, backend, verbose);     assert (success);      //  Test negative case (bad client password)     zstr_sendx (proxy, ""PLAIN"", ""FRONTEND"", NULL);     zsock_wait (proxy);     s_bind_test_sockets (proxy, &frontend, &backend);     zsock_set_plain_username (faucet, ""admin"");     zsock_set_plain_password (faucet, ""Bogus"");     success = s_can_connect (&proxy, &faucet, &sink, frontend, backend, verbose);     assert (!success);      if (zsys_has_curve ()) {         //  We'll create two new certificates and save the client public         //  certificate on disk         zcert_t *server_cert = zcert_new ();         assert (server_cert);         zcert_t *client_cert = zcert_new ();         assert (client_cert);         const char *public_key = zcert_public_txt (server_cert);         const char *secret_key = zcert_secret_txt (server_cert);          //  Try CURVE authentication          //  Test without setting-up any authentication         zstr_sendx (proxy, ""CURVE"", ""FRONTEND"", public_key, secret_key, NULL);         zsock_wait (proxy);         s_bind_test_sockets (proxy, &frontend, &backend);         zcert_apply (client_cert, faucet);         zsock_set_curve_serverkey (faucet, public_key);         success = s_can_connect (&proxy, &faucet, &sink, frontend, backend, verbose);         assert (!success);          //  Test CURVE_ALLOW_ANY         zstr_sendx (proxy, ""CURVE"", ""FRONTEND"", public_key, secret_key, NULL);         zsock_wait (proxy);         s_bind_test_sockets (proxy, &frontend, &backend);         zcert_apply (client_cert, faucet);         zsock_set_curve_serverkey (faucet, public_key);         zstr_sendx (auth, ""CURVE"", CURVE_ALLOW_ANY, NULL);         zsock_wait (auth);         success = s_can_connect (&proxy, &faucet, &sink, frontend, backend, verbose);         assert (success);          //  Test with client certificate file in authentication folder         zstr_sendx (proxy, ""CURVE"", ""FRONTEND"", public_key, secret_key, NULL);         zsock_wait (proxy);         zstr_sendx (proxy, ""CURVE"", ""BACKEND"", public_key, secret_key, NULL);         zsock_wait (proxy);         s_bind_test_sockets (proxy, &frontend, &backend);         zcert_apply (client_cert, faucet);         zsock_set_curve_serverkey (faucet, public_key);         zcert_apply (client_cert, sink);         zsock_set_curve_serverkey (sink, public_key);         zcert_save_public (client_cert, TESTDIR ""/mycert.txt"");         zstr_sendx (auth, ""CURVE"", TESTDIR, NULL);         zsock_wait (auth);         success = s_can_connect (&proxy, &faucet, &sink, frontend, backend, verbose);         assert (success);          zcert_destroy (&server_cert);         zcert_destroy (&client_cert);     }      //  Remove the authenticator and check a normal connection works     zactor_destroy (&auth);     s_bind_test_sockets (proxy, &frontend, &backend);     success = s_can_connect (&proxy, &faucet, &sink, frontend, backend, verbose);     assert (success);      //  Cleanup     zsock_destroy (&faucet);     zsock_destroy (&sink);     zactor_destroy (&proxy);     zstr_free (&frontend);     zstr_free (&backend);      //  Delete temporary directory and test files     zsys_file_delete (TESTDIR ""/password-file"");     zsys_file_delete (TESTDIR ""/mycert.txt"");     zsys_dir_delete (TESTDIR);     #endif zrex - work with regular expressions Wraps a very simple regular expression library (SLRE) as a CZMQ class. Supports this syntax: ^               Match beginning of a buffer $               Match end of a buffer ()              Grouping and substring capturing [...]           Match any character from set [^...]          Match any character but ones from set .               Match any character \s              Match whitespace \S              Match non-whitespace \d              Match decimal digit \D              Match non decimal digit \a              Match alphabetic character \A              Match non-alphabetic character \w              Match alphanumeric character \W              Match non-alphanumeric character \r              Match carriage return \n              Match newline +               Match one or more times (greedy) +?              Match one or more times (non-greedy) *               Match zero or more times (greedy) *?              Match zero or more times (non-greedy) ?               Match zero or once \xDD            Match byte with hex value 0xDD \meta           Match one of the meta character: ^$().[*+?\  Please add @discuss section in ../src/zrex.c. This is the class interface:     //  Constructor. Optionally, sets an expression against which we can match     //  text and capture hits. If there is an error in the expression, reports     //  zrex_valid() as false and provides the error in zrex_strerror(). If you     //  set a pattern, you can call zrex_matches() to test it against text.     CZMQ_EXPORT zrex_t *         zrex_new (const char *expression);      //  Destructor     CZMQ_EXPORT void         zrex_destroy (zrex_t **self_p);      //  Return true if the expression was valid and compiled without errors.     CZMQ_EXPORT bool         zrex_valid (zrex_t *self);      //  Return the error message generated during compilation of the expression.     CZMQ_EXPORT const char *         zrex_strerror (zrex_t *self);      //  Returns true if the text matches the previously compiled expression.     //  Use this method to compare one expression against many strings.     CZMQ_EXPORT bool         zrex_matches (zrex_t *self, const char *text);      //  Returns true if the text matches the supplied expression. Use this     //  method to compare one string against several expressions.     CZMQ_EXPORT bool         zrex_eq (zrex_t *self, const char *text, const char *expression);      //  Returns number of hits from last zrex_matches or zrex_eq. If the text     //  matched, returns 1 plus the number of capture groups. If the text did     //  not match, returns zero. To retrieve individual capture groups, call     //  zrex_hit ().     CZMQ_EXPORT int         zrex_hits (zrex_t *self);      //  Returns the Nth capture group from the last expression match, where     //  N is 0 to the value returned by zrex_hits(). Capture group 0 is the     //  whole matching string. Sequence 1 is the first capture group, if any,     //  and so on.     CZMQ_EXPORT const char *         zrex_hit (zrex_t *self, uint index);      //  Fetches hits into string variables provided by caller; this makes for     //  nicer code than accessing hits by index. Caller should not modify nor     //  free the returned values. Returns number of strings returned. This     //  method starts at hit 1, i.e. first capture group, as hit 0 is always     //  the original matched string.     CZMQ_EXPORT int         zrex_fetch (zrex_t *self, const char **string_p, ...);      //  Self test of this class     CZMQ_EXPORT void         zrex_test (bool verbose); This is the class self test code:     //  This shows the pattern of matching many lines to a single pattern     zrex_t *rex = zrex_new (""\\d+-\\d+-\\d+"");     assert (rex);     assert (zrex_valid (rex));     bool matches = zrex_matches (rex, ""123-456-789"");     assert (matches);     assert (zrex_hits (rex) == 1);     assert (streq (zrex_hit (rex, 0), ""123-456-789""));     assert (zrex_hit (rex, 1) == NULL);     zrex_destroy (&rex);      //  Here we pick out hits using capture groups     rex = zrex_new (""(\\d+)-(\\d+)-(\\d+)"");     assert (rex);     assert (zrex_valid (rex));     matches = zrex_matches (rex, ""123-456-ABC"");     assert (!matches);     matches = zrex_matches (rex, ""123-456-789"");     assert (matches);     assert (zrex_hits (rex) == 4);     assert (streq (zrex_hit (rex, 0), ""123-456-789""));     assert (streq (zrex_hit (rex, 1), ""123""));     assert (streq (zrex_hit (rex, 2), ""456""));     assert (streq (zrex_hit (rex, 3), ""789""));     zrex_destroy (&rex);      //  This shows the pattern of matching one line against many     //  patterns and then handling the case when it hits     rex = zrex_new (NULL);      //  No initial pattern     assert (rex);     char *input = ""Mechanism: CURVE"";     matches = zrex_eq (rex, input, ""Version: (.+)"");     assert (!matches);     assert (zrex_hits (rex) == 0);     matches = zrex_eq (rex, input, ""Mechanism: (.+)"");     assert (matches);     assert (zrex_hits (rex) == 2);     const char *mechanism;     zrex_fetch (rex, &mechanism, NULL);     assert (streq (zrex_hit (rex, 1), ""CURVE""));     assert (streq (mechanism, ""CURVE""));     zrex_destroy (&rex);  zsock - high-level socket API that hides libzmq contexts and sockets The zsock class wraps the libzmq socket handle (a void *) with a proper structure that follows the CLASS rules for construction and destruction. Some zsock methods take a void * ""polymorphic"" reference, which can be either a zsock_t or a zactor_t reference, or a libzmq void *. Please add @discuss section in ../src/zsock.c. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     //  This class has draft methods, which may change over time. They are not     //  in stable releases, by default. Use --enable-drafts to enable.     //  Create a new socket. Returns the new socket, or NULL if the new socket     //  could not be created. Note that the symbol zsock_new (and other            //  constructors/destructors for zsock) are redirected to the *_checked        //  variant, enabling intelligent socket leak detection. This can have         //  performance implications if you use a LOT of sockets. To turn off this     //  redirection behaviour, define ZSOCK_NOCHECK.                               CZMQ_EXPORT zsock_t *         zsock_new (int type);      //  Create a PUB socket. Default action is bind.     CZMQ_EXPORT zsock_t *         zsock_new_pub (const char *endpoint);      //  Create a SUB socket, and optionally subscribe to some prefix string. Default     //  action is connect.                                                               CZMQ_EXPORT zsock_t *         zsock_new_sub (const char *endpoint, const char *subscribe);      //  Create a REQ socket. Default action is connect.     CZMQ_EXPORT zsock_t *         zsock_new_req (const char *endpoint);      //  Create a REP socket. Default action is bind.     CZMQ_EXPORT zsock_t *         zsock_new_rep (const char *endpoint);      //  Create a DEALER socket. Default action is connect.     CZMQ_EXPORT zsock_t *         zsock_new_dealer (const char *endpoint);      //  Create a ROUTER socket. Default action is bind.     CZMQ_EXPORT zsock_t *         zsock_new_router (const char *endpoint);      //  Create a PUSH socket. Default action is connect.     CZMQ_EXPORT zsock_t *         zsock_new_push (const char *endpoint);      //  Create a PULL socket. Default action is bind.     CZMQ_EXPORT zsock_t *         zsock_new_pull (const char *endpoint);      //  Create an XPUB socket. Default action is bind.     CZMQ_EXPORT zsock_t *         zsock_new_xpub (const char *endpoint);      //  Create an XSUB socket. Default action is connect.     CZMQ_EXPORT zsock_t *         zsock_new_xsub (const char *endpoint);      //  Create a PAIR socket. Default action is connect.     CZMQ_EXPORT zsock_t *         zsock_new_pair (const char *endpoint);      //  Create a STREAM socket. Default action is connect.     CZMQ_EXPORT zsock_t *         zsock_new_stream (const char *endpoint);      //  Destroy the socket. You must use this for any socket created via the     //  zsock_new method.                                                        CZMQ_EXPORT void         zsock_destroy (zsock_t **self_p);      //  Bind a socket to a formatted endpoint. For tcp:// endpoints, supports        //  ephemeral ports, if you specify the port number as ""*"". By default           //  zsock uses the IANA designated range from C000 (49152) to FFFF (65535).      //  To override this range, follow the ""*"" with ""[first-last]"". Either or        //  both first and last may be empty. To bind to a random port within the        //  range, use ""!"" in place of ""*"".                                              //                                                                               //  Examples:                                                                    //      tcp://127.0.0.1:*           bind to first free port from C000 up         //      tcp://127.0.0.1:!           bind to random port from C000 to FFFF        //      tcp://127.0.0.1:*[60000-]   bind to first free port from 60000 up        //      tcp://127.0.0.1:![-60000]   bind to random port from C000 to 60000       //      tcp://127.0.0.1:![55000-55999]                                           //                                  bind to random port from 55000 to 55999      //                                                                               //  On success, returns the actual port number used, for tcp:// endpoints,       //  and 0 for other transports. On failure, returns -1. Note that when using     //  ephemeral ports, a port may be reused by different services without          //  clients being aware. Protocols that run on ephemeral ports should take       //  this into account.                                                           CZMQ_EXPORT int         zsock_bind (zsock_t *self, const char *format, ...);      //  Returns last bound endpoint, if any.     CZMQ_EXPORT const char *         zsock_endpoint (zsock_t *self);      //  Unbind a socket from a formatted endpoint.                          //  Returns 0 if OK, -1 if the endpoint was invalid or the function     //  isn't supported.                                                    CZMQ_EXPORT int         zsock_unbind (zsock_t *self, const char *format, ...);      //  Connect a socket to a formatted endpoint             //  Returns 0 if OK, -1 if the endpoint was invalid.     CZMQ_EXPORT int         zsock_connect (zsock_t *self, const char *format, ...);      //  Disconnect a socket from a formatted endpoint                       //  Returns 0 if OK, -1 if the endpoint was invalid or the function     //  isn't supported.                                                    CZMQ_EXPORT int         zsock_disconnect (zsock_t *self, const char *format, ...);      //  Attach a socket to zero or more endpoints. If endpoints is not null,          //  parses as list of ZeroMQ endpoints, separated by commas, and prefixed by      //  '@' (to bind the socket) or '>' (to connect the socket). Returns 0 if all     //  endpoints were valid, or -1 if there was a syntax error. If the endpoint      //  does not start with '@' or '>', the serverish argument defines whether        //  it is used to bind (serverish = true) or connect (serverish = false).         CZMQ_EXPORT int         zsock_attach (zsock_t *self, const char *endpoints, bool serverish);      //  Returns socket type as printable constant string.     CZMQ_EXPORT const char *         zsock_type_str (zsock_t *self);      //  Send a 'picture' message to the socket (or actor). The picture is a        //  string that defines the type of each frame. This makes it easy to send     //  a complex multiframe message in one call. The picture can contain any      //  of these characters, each corresponding to one or two arguments:           //                                                                             //      i = int (signed)                                                       //      1 = uint8_t                                                            //      2 = uint16_t                                                           //      4 = uint32_t                                                           //      8 = uint64_t                                                           //      s = char *                                                             //      b = byte *, size_t (2 arguments)                                       //      c = zchunk_t *                                                         //      f = zframe_t *                                                         //      h = zhashx_t *                                                         //      U = zuuid_t *                                                          //      p = void * (sends the pointer value, only meaningful over inproc)      //      m = zmsg_t * (sends all frames in the zmsg)                            //      z = sends zero-sized frame (0 arguments)                               //      u = uint (deprecated)                                                  //                                                                             //  Note that s, b, c, and f are encoded the same way and the choice is        //  offered as a convenience to the sender, which may or may not already       //  have data in a zchunk or zframe. Does not change or take ownership of      //  any arguments. Returns 0 if successful, -1 if sending failed for any       //  reason.                                                                    CZMQ_EXPORT int         zsock_send (void *self, const char *picture, ...);      //  Send a 'picture' message to the socket (or actor). This is a va_list      //  version of zsock_send (), so please consult its documentation for the     //  details.                                                                  CZMQ_EXPORT int         zsock_vsend (void *self, const char *picture, va_list argptr);      //  Receive a 'picture' message to the socket (or actor). See zsock_send for     //  the format and meaning of the picture. Returns the picture elements into     //  a series of pointers as provided by the caller:                              //                                                                               //      i = int * (stores signed integer)                                        //      4 = uint32_t * (stores 32-bit unsigned integer)                          //      8 = uint64_t * (stores 64-bit unsigned integer)                          //      s = char ** (allocates new string)                                       //      b = byte **, size_t * (2 arguments) (allocates memory)                   //      c = zchunk_t ** (creates zchunk)                                         //      f = zframe_t ** (creates zframe)                                         //      U = zuuid_t * (creates a zuuid with the data)                            //      h = zhashx_t ** (creates zhashx)                                         //      p = void ** (stores pointer)                                             //      m = zmsg_t ** (creates a zmsg with the remaing frames)                   //      z = null, asserts empty frame (0 arguments)                              //      u = uint * (stores unsigned integer, deprecated)                         //                                                                               //  Note that zsock_recv creates the returned objects, and the caller must       //  destroy them when finished with them. The supplied pointers do not need      //  to be initialized. Returns 0 if successful, or -1 if it failed to recv       //  a message, in which case the pointers are not modified. When message         //  frames are truncated (a short message), sets return values to zero/null.     //  If an argument pointer is NULL, does not store any value (skips it).         //  An 'n' picture matches an empty frame; if the message does not match,        //  the method will return -1.                                                   CZMQ_EXPORT int         zsock_recv (void *self, const char *picture, ...);      //  Receive a 'picture' message from the socket (or actor). This is a         //  va_list version of zsock_recv (), so please consult its documentation     //  for the details.                                                          CZMQ_EXPORT int         zsock_vrecv (void *self, const char *picture, va_list argptr);      //  Send a binary encoded 'picture' message to the socket (or actor). This      //  method is similar to zsock_send, except the arguments are encoded in a      //  binary format that is compatible with zproto, and is designed to reduce     //  memory allocations. The pattern argument is a string that defines the       //  type of each argument. Supports these argument types:                       //                                                                              //   pattern    C type                  zproto type:                            //      1       uint8_t                 type = ""number"" size = ""1""              //      2       uint16_t                type = ""number"" size = ""2""              //      4       uint32_t                type = ""number"" size = ""3""              //      8       uint64_t                type = ""number"" size = ""4""              //      s       char *, 0-255 chars     type = ""string""                         //      S       char *, 0-2^32-1 chars  type = ""longstr""                        //      c       zchunk_t *              type = ""chunk""                          //      f       zframe_t *              type = ""frame""                          //      u       zuuid_t *               type = ""uuid""                           //      m       zmsg_t *                type = ""msg""                            //      p       void *, sends pointer value, only over inproc                   //                                                                              //  Does not change or take ownership of any arguments. Returns 0 if            //  successful, -1 if sending failed for any reason.                            CZMQ_EXPORT int         zsock_bsend (void *self, const char *picture, ...);      //  Receive a binary encoded 'picture' message from the socket (or actor).       //  This method is similar to zsock_recv, except the arguments are encoded       //  in a binary format that is compatible with zproto, and is designed to        //  reduce memory allocations. The pattern argument is a string that defines     //  the type of each argument. See zsock_bsend for the supported argument        //  types. All arguments must be pointers; this call sets them to point to       //  values held on a per-socket basis.                                           //  Note that zsock_brecv creates the returned objects, and the caller must      //  destroy them when finished with them. The supplied pointers do not need      //  to be initialized. Returns 0 if successful, or -1 if it failed to read       //  a message.                                                                   CZMQ_EXPORT int         zsock_brecv (void *self, const char *picture, ...);      //  Set socket to use unbounded pipes (HWM=0); use this in cases when you are     //  totally certain the message volume can fit in memory. This method works       //  across all versions of ZeroMQ. Takes a polymorphic socket reference.          CZMQ_EXPORT void         zsock_set_unbounded (void *self);      //  Send a signal over a socket. A signal is a short message carrying a        //  success/failure code (by convention, 0 means OK). Signals are encoded      //  to be distinguishable from ""normal"" messages. Accepts a zsock_t or a       //  zactor_t argument, and returns 0 if successful, -1 if the signal could     //  not be sent. Takes a polymorphic socket reference.                         CZMQ_EXPORT int         zsock_signal (void *self, byte status);      //  Wait on a signal. Use this to coordinate between threads, over pipe       //  pairs. Blocks until the signal is received. Returns -1 on error, 0 or     //  greater on success. Accepts a zsock_t or a zactor_t as argument.          //  Takes a polymorphic socket reference.                                     CZMQ_EXPORT int         zsock_wait (void *self);      //  If there is a partial message still waiting on the socket, remove and         //  discard it. This is useful when reading partial messages, to get specific     //  message types.                                                                CZMQ_EXPORT void         zsock_flush (void *self);      //  Probe the supplied object, and report if it looks like a zsock_t.     //  Takes a polymorphic socket reference.                                 CZMQ_EXPORT bool         zsock_is (void *self);      //  Probe the supplied reference. If it looks like a zsock_t instance, return     //  the underlying libzmq socket handle; else if it looks like a file             //  descriptor, return NULL; else if it looks like a libzmq socket handle,        //  return the supplied value. Takes a polymorphic socket reference.              CZMQ_EXPORT void *         zsock_resolve (void *self);      //  Get socket option `tos`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_tos (void *self);      //  Set socket option `tos`.     CZMQ_EXPORT void         zsock_set_tos (void *self, int tos);      //  Set socket option `router_handover`.     CZMQ_EXPORT void         zsock_set_router_handover (void *self, int router_handover);      //  Set socket option `router_mandatory`.     CZMQ_EXPORT void         zsock_set_router_mandatory (void *self, int router_mandatory);      //  Set socket option `probe_router`.     CZMQ_EXPORT void         zsock_set_probe_router (void *self, int probe_router);      //  Set socket option `req_relaxed`.     CZMQ_EXPORT void         zsock_set_req_relaxed (void *self, int req_relaxed);      //  Set socket option `req_correlate`.     CZMQ_EXPORT void         zsock_set_req_correlate (void *self, int req_correlate);      //  Set socket option `conflate`.     CZMQ_EXPORT void         zsock_set_conflate (void *self, int conflate);      //  Get socket option `zap_domain`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zsock_zap_domain (void *self);      //  Set socket option `zap_domain`.     CZMQ_EXPORT void         zsock_set_zap_domain (void *self, const char *zap_domain);      //  Get socket option `mechanism`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_mechanism (void *self);      //  Get socket option `plain_server`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_plain_server (void *self);      //  Set socket option `plain_server`.     CZMQ_EXPORT void         zsock_set_plain_server (void *self, int plain_server);      //  Get socket option `plain_username`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zsock_plain_username (void *self);      //  Set socket option `plain_username`.     CZMQ_EXPORT void         zsock_set_plain_username (void *self, const char *plain_username);      //  Get socket option `plain_password`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zsock_plain_password (void *self);      //  Set socket option `plain_password`.     CZMQ_EXPORT void         zsock_set_plain_password (void *self, const char *plain_password);      //  Get socket option `curve_server`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_curve_server (void *self);      //  Set socket option `curve_server`.     CZMQ_EXPORT void         zsock_set_curve_server (void *self, int curve_server);      //  Get socket option `curve_publickey`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zsock_curve_publickey (void *self);      //  Set socket option `curve_publickey`.     CZMQ_EXPORT void         zsock_set_curve_publickey (void *self, const char *curve_publickey);      //  Set socket option `curve_publickey` from 32-octet binary     CZMQ_EXPORT void         zsock_set_curve_publickey_bin (void *self, const byte *curve_publickey);      //  Get socket option `curve_secretkey`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zsock_curve_secretkey (void *self);      //  Set socket option `curve_secretkey`.     CZMQ_EXPORT void         zsock_set_curve_secretkey (void *self, const char *curve_secretkey);      //  Set socket option `curve_secretkey` from 32-octet binary     CZMQ_EXPORT void         zsock_set_curve_secretkey_bin (void *self, const byte *curve_secretkey);      //  Get socket option `curve_serverkey`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zsock_curve_serverkey (void *self);      //  Set socket option `curve_serverkey`.     CZMQ_EXPORT void         zsock_set_curve_serverkey (void *self, const char *curve_serverkey);      //  Set socket option `curve_serverkey` from 32-octet binary     CZMQ_EXPORT void         zsock_set_curve_serverkey_bin (void *self, const byte *curve_serverkey);      //  Get socket option `gssapi_server`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_gssapi_server (void *self);      //  Set socket option `gssapi_server`.     CZMQ_EXPORT void         zsock_set_gssapi_server (void *self, int gssapi_server);      //  Get socket option `gssapi_plaintext`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_gssapi_plaintext (void *self);      //  Set socket option `gssapi_plaintext`.     CZMQ_EXPORT void         zsock_set_gssapi_plaintext (void *self, int gssapi_plaintext);      //  Get socket option `gssapi_principal`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zsock_gssapi_principal (void *self);      //  Set socket option `gssapi_principal`.     CZMQ_EXPORT void         zsock_set_gssapi_principal (void *self, const char *gssapi_principal);      //  Get socket option `gssapi_service_principal`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zsock_gssapi_service_principal (void *self);      //  Set socket option `gssapi_service_principal`.     CZMQ_EXPORT void         zsock_set_gssapi_service_principal (void *self, const char *gssapi_service_principal);      //  Get socket option `ipv6`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_ipv6 (void *self);      //  Set socket option `ipv6`.     CZMQ_EXPORT void         zsock_set_ipv6 (void *self, int ipv6);      //  Get socket option `immediate`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_immediate (void *self);      //  Set socket option `immediate`.     CZMQ_EXPORT void         zsock_set_immediate (void *self, int immediate);      //  Set socket option `router_raw`.     CZMQ_EXPORT void         zsock_set_router_raw (void *self, int router_raw);      //  Get socket option `ipv4only`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_ipv4only (void *self);      //  Set socket option `ipv4only`.     CZMQ_EXPORT void         zsock_set_ipv4only (void *self, int ipv4only);      //  Set socket option `delay_attach_on_connect`.     CZMQ_EXPORT void         zsock_set_delay_attach_on_connect (void *self, int delay_attach_on_connect);      //  Get socket option `type`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_type (void *self);      //  Get socket option `sndhwm`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_sndhwm (void *self);      //  Set socket option `sndhwm`.     CZMQ_EXPORT void         zsock_set_sndhwm (void *self, int sndhwm);      //  Get socket option `rcvhwm`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_rcvhwm (void *self);      //  Set socket option `rcvhwm`.     CZMQ_EXPORT void         zsock_set_rcvhwm (void *self, int rcvhwm);      //  Get socket option `affinity`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_affinity (void *self);      //  Set socket option `affinity`.     CZMQ_EXPORT void         zsock_set_affinity (void *self, int affinity);      //  Set socket option `subscribe`.     CZMQ_EXPORT void         zsock_set_subscribe (void *self, const char *subscribe);      //  Set socket option `unsubscribe`.     CZMQ_EXPORT void         zsock_set_unsubscribe (void *self, const char *unsubscribe);      //  Get socket option `identity`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zsock_identity (void *self);      //  Set socket option `identity`.     CZMQ_EXPORT void         zsock_set_identity (void *self, const char *identity);      //  Get socket option `rate`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_rate (void *self);      //  Set socket option `rate`.     CZMQ_EXPORT void         zsock_set_rate (void *self, int rate);      //  Get socket option `recovery_ivl`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_recovery_ivl (void *self);      //  Set socket option `recovery_ivl`.     CZMQ_EXPORT void         zsock_set_recovery_ivl (void *self, int recovery_ivl);      //  Get socket option `sndbuf`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_sndbuf (void *self);      //  Set socket option `sndbuf`.     CZMQ_EXPORT void         zsock_set_sndbuf (void *self, int sndbuf);      //  Get socket option `rcvbuf`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_rcvbuf (void *self);      //  Set socket option `rcvbuf`.     CZMQ_EXPORT void         zsock_set_rcvbuf (void *self, int rcvbuf);      //  Get socket option `linger`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_linger (void *self);      //  Set socket option `linger`.     CZMQ_EXPORT void         zsock_set_linger (void *self, int linger);      //  Get socket option `reconnect_ivl`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_reconnect_ivl (void *self);      //  Set socket option `reconnect_ivl`.     CZMQ_EXPORT void         zsock_set_reconnect_ivl (void *self, int reconnect_ivl);      //  Get socket option `reconnect_ivl_max`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_reconnect_ivl_max (void *self);      //  Set socket option `reconnect_ivl_max`.     CZMQ_EXPORT void         zsock_set_reconnect_ivl_max (void *self, int reconnect_ivl_max);      //  Get socket option `backlog`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_backlog (void *self);      //  Set socket option `backlog`.     CZMQ_EXPORT void         zsock_set_backlog (void *self, int backlog);      //  Get socket option `maxmsgsize`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_maxmsgsize (void *self);      //  Set socket option `maxmsgsize`.     CZMQ_EXPORT void         zsock_set_maxmsgsize (void *self, int maxmsgsize);      //  Get socket option `multicast_hops`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_multicast_hops (void *self);      //  Set socket option `multicast_hops`.     CZMQ_EXPORT void         zsock_set_multicast_hops (void *self, int multicast_hops);      //  Get socket option `rcvtimeo`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_rcvtimeo (void *self);      //  Set socket option `rcvtimeo`.     CZMQ_EXPORT void         zsock_set_rcvtimeo (void *self, int rcvtimeo);      //  Get socket option `sndtimeo`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_sndtimeo (void *self);      //  Set socket option `sndtimeo`.     CZMQ_EXPORT void         zsock_set_sndtimeo (void *self, int sndtimeo);      //  Set socket option `xpub_verbose`.     CZMQ_EXPORT void         zsock_set_xpub_verbose (void *self, int xpub_verbose);      //  Get socket option `tcp_keepalive`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_tcp_keepalive (void *self);      //  Set socket option `tcp_keepalive`.     CZMQ_EXPORT void         zsock_set_tcp_keepalive (void *self, int tcp_keepalive);      //  Get socket option `tcp_keepalive_idle`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_tcp_keepalive_idle (void *self);      //  Set socket option `tcp_keepalive_idle`.     CZMQ_EXPORT void         zsock_set_tcp_keepalive_idle (void *self, int tcp_keepalive_idle);      //  Get socket option `tcp_keepalive_cnt`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_tcp_keepalive_cnt (void *self);      //  Set socket option `tcp_keepalive_cnt`.     CZMQ_EXPORT void         zsock_set_tcp_keepalive_cnt (void *self, int tcp_keepalive_cnt);      //  Get socket option `tcp_keepalive_intvl`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_tcp_keepalive_intvl (void *self);      //  Set socket option `tcp_keepalive_intvl`.     CZMQ_EXPORT void         zsock_set_tcp_keepalive_intvl (void *self, int tcp_keepalive_intvl);      //  Get socket option `tcp_accept_filter`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zsock_tcp_accept_filter (void *self);      //  Set socket option `tcp_accept_filter`.     CZMQ_EXPORT void         zsock_set_tcp_accept_filter (void *self, const char *tcp_accept_filter);      //  Get socket option `rcvmore`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_rcvmore (void *self);      //  Get socket option `fd`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT SOCKET         zsock_fd (void *self);      //  Get socket option `events`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_events (void *self);      //  Get socket option `last_endpoint`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zsock_last_endpoint (void *self);      //  Self test of this class.     CZMQ_EXPORT void         zsock_test (bool verbose);      #ifdef CZMQ_BUILD_DRAFT_API     //  *** Draft method, for development use, may change without warning ***     //  Create a SERVER socket. Default action is bind.     CZMQ_EXPORT zsock_t *         zsock_new_server (const char *endpoint);      //  *** Draft method, for development use, may change without warning ***     //  Create a CLIENT socket. Default action is connect.     CZMQ_EXPORT zsock_t *         zsock_new_client (const char *endpoint);      //  *** Draft method, for development use, may change without warning ***     //  Create a RADIO socket. Default action is bind.     CZMQ_EXPORT zsock_t *         zsock_new_radio (const char *endpoint);      //  *** Draft method, for development use, may change without warning ***     //  Create a DISH socket. Default action is connect.     CZMQ_EXPORT zsock_t *         zsock_new_dish (const char *endpoint);      //  *** Draft method, for development use, may change without warning ***     //  Create a GATHER socket. Default action is bind.     CZMQ_EXPORT zsock_t *         zsock_new_gather (const char *endpoint);      //  *** Draft method, for development use, may change without warning ***     //  Create a SCATTER socket. Default action is connect.     CZMQ_EXPORT zsock_t *         zsock_new_scatter (const char *endpoint);      //  *** Draft method, for development use, may change without warning ***     //  Return socket routing ID if any. This returns 0 if the socket is not     //  of type ZMQ_SERVER or if no request was already received on it.          CZMQ_EXPORT uint32_t         zsock_routing_id (zsock_t *self);      //  *** Draft method, for development use, may change without warning ***     //  Set routing ID on socket. The socket MUST be of type ZMQ_SERVER.             //  This will be used when sending messages on the socket via the zsock API.     CZMQ_EXPORT void         zsock_set_routing_id (zsock_t *self, uint32_t routing_id);      //  *** Draft method, for development use, may change without warning ***     //  Join a group for the RADIO-DISH pattern. Call only on ZMQ_DISH.     //  Returns 0 if OK, -1 if failed.                                      CZMQ_EXPORT int         zsock_join (void *self, const char *group);      //  *** Draft method, for development use, may change without warning ***     //  Leave a group for the RADIO-DISH pattern. Call only on ZMQ_DISH.     //  Returns 0 if OK, -1 if failed.                                       CZMQ_EXPORT int         zsock_leave (void *self, const char *group);      //  *** Draft method, for development use, may change without warning ***     //  Get socket option `heartbeat_ivl`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_heartbeat_ivl (void *self);      //  *** Draft method, for development use, may change without warning ***     //  Set socket option `heartbeat_ivl`.     CZMQ_EXPORT void         zsock_set_heartbeat_ivl (void *self, int heartbeat_ivl);      //  *** Draft method, for development use, may change without warning ***     //  Get socket option `heartbeat_ttl`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_heartbeat_ttl (void *self);      //  *** Draft method, for development use, may change without warning ***     //  Set socket option `heartbeat_ttl`.     CZMQ_EXPORT void         zsock_set_heartbeat_ttl (void *self, int heartbeat_ttl);      //  *** Draft method, for development use, may change without warning ***     //  Get socket option `heartbeat_timeout`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_heartbeat_timeout (void *self);      //  *** Draft method, for development use, may change without warning ***     //  Set socket option `heartbeat_timeout`.     CZMQ_EXPORT void         zsock_set_heartbeat_timeout (void *self, int heartbeat_timeout);      //  *** Draft method, for development use, may change without warning ***     //  Get socket option `use_fd`.     //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT int         zsock_use_fd (void *self);      //  *** Draft method, for development use, may change without warning ***     //  Set socket option `use_fd`.     CZMQ_EXPORT void         zsock_set_use_fd (void *self, int use_fd);      #endif // CZMQ_BUILD_DRAFT_API This is the class self test code:     zsock_t *writer = zsock_new_push (""@tcp://127.0.0.1:5560"");     assert (writer);     assert (zsock_resolve (writer) != writer);     assert (streq (zsock_type_str (writer), ""PUSH""));      int rc;     #if (ZMQ_VERSION >= ZMQ_MAKE_VERSION (3, 2, 0))     //  Check unbind     rc = zsock_unbind (writer, ""tcp://127.0.0.1:%d"", 5560);     assert (rc == 0);      //  In some cases and especially when running under Valgrind, doing     //  a bind immediately after an unbind causes an EADDRINUSE error.     //  Even a short sleep allows the OS to release the port for reuse.     zclock_sleep (100);      //  Bind again     rc = zsock_bind (writer, ""tcp://127.0.0.1:%d"", 5560);     assert (rc == 5560);     assert (streq (zsock_endpoint (writer), ""tcp://127.0.0.1:5560""));     #endif      zsock_t *reader = zsock_new_pull ("">tcp://127.0.0.1:5560"");     assert (reader);     assert (zsock_resolve (reader) != reader);     assert (streq (zsock_type_str (reader), ""PULL""));      //  Basic Hello, World     zstr_send (writer, ""Hello, World"");     zmsg_t *msg = zmsg_recv (reader);     assert (msg);     char *string = zmsg_popstr (msg);     assert (streq (string, ""Hello, World""));     free (string);     zmsg_destroy (&msg);      //  Test resolve libzmq socket     #if (ZMQ_VERSION >= ZMQ_MAKE_VERSION (3, 2, 0))     void *zmq_ctx = zmq_ctx_new ();     #else     void *zmq_ctx = zmq_ctx_new (1);     #endif     assert (zmq_ctx);     void *zmq_sock = zmq_socket (zmq_ctx, ZMQ_PUB);     assert (zmq_sock);     assert (zsock_resolve (zmq_sock) == zmq_sock);     zmq_close (zmq_sock);     zmq_ctx_term (zmq_ctx);      //  Test resolve zsock     zsock_t *resolve = zsock_new_pub(""@tcp://127.0.0.1:5561"");     assert (resolve);     assert (zsock_resolve (resolve) == resolve->handle);     zsock_destroy (&resolve);      //  Test resolve FD     SOCKET fd = zsock_fd (reader);     assert (zsock_resolve ((void *) &fd) == NULL);      //  Test binding to ephemeral ports, sequential and random     int port = zsock_bind (writer, ""tcp://127.0.0.1:*"");     assert (port >= DYNAMIC_FIRST && port <= DYNAMIC_LAST);     port = zsock_bind (writer, ""tcp://127.0.0.1:*[50000-]"");     assert (port >= 50000 && port <= DYNAMIC_LAST);     port = zsock_bind (writer, ""tcp://127.0.0.1:*[-50001]"");     assert (port >= DYNAMIC_FIRST && port <= 50001);     port = zsock_bind (writer, ""tcp://127.0.0.1:*[60000-60050]"");     assert (port >= 60000 && port <= 60050);      port = zsock_bind (writer, ""tcp://127.0.0.1:!"");     assert (port >= DYNAMIC_FIRST && port <= DYNAMIC_LAST);     port = zsock_bind (writer, ""tcp://127.0.0.1:![50000-]"");     assert (port >= 50000 && port <= DYNAMIC_LAST);     port = zsock_bind (writer, ""tcp://127.0.0.1:![-50001]"");     assert (port >= DYNAMIC_FIRST && port <= 50001);     port = zsock_bind (writer, ""tcp://127.0.0.1:![60000-60050]"");     assert (port >= 60000 && port <= 60050);      //  Test zsock_attach method     zsock_t *server = zsock_new (ZMQ_DEALER);     assert (server);     rc = zsock_attach (server, ""@inproc://myendpoint,tcp://127.0.0.1:5556,inproc://others"", true);     assert (rc == 0);     rc = zsock_attach (server, """", false);     assert (rc == 0);     rc = zsock_attach (server, NULL, true);     assert (rc == 0);     rc = zsock_attach (server, "">a,@b, c,, "", false);     assert (rc == -1);     zsock_destroy (&server);      //  Test zsock_endpoint method     rc = zsock_bind (writer, ""inproc://test.%s"", ""writer"");     assert (rc == 0);     assert (streq (zsock_endpoint (writer), ""inproc://test.writer""));      //  Test error state when connecting to an invalid socket type     //  ('txp://' instead of 'tcp://', typo intentional)     rc = zsock_connect (reader, ""txp://127.0.0.1:5560"");     assert (rc == -1);      //  Test signal/wait methods     rc = zsock_signal (writer, 123);     assert (rc == 0);     rc = zsock_wait (reader);     assert (rc == 123);      //  Test zsock_send/recv pictures     uint8_t  number1 = 123;     uint16_t number2 = 123 * 123;     uint32_t number4 = 123 * 123 * 123;     uint64_t number4_MAX = UINT32_MAX;     uint64_t number8 = 123 * 123 * 123 * 123;     uint64_t number8_MAX = UINT64_MAX;      zchunk_t *chunk = zchunk_new (""HELLO"", 5);     assert (chunk);     zframe_t *frame = zframe_new (""WORLD"", 5);     assert (frame);     zhashx_t *hash = zhashx_new ();     assert (hash);     zuuid_t *uuid = zuuid_new ();     assert (uuid);     zhashx_autofree (hash);     zhashx_insert (hash, ""1"", ""value A"");     zhashx_insert (hash, ""2"", ""value B"");     char *original = ""pointer"";      //  Test zsock_recv into each supported type     zsock_send (writer, ""i124488zsbcfUhp"",                 -12345, number1, number2, number4, number4_MAX,                 number8, number8_MAX,                 ""This is a string"", ""ABCDE"", 5,                 chunk, frame, uuid, hash, original);     char *uuid_str = strdup (zuuid_str (uuid));     zchunk_destroy (&chunk);     zframe_destroy (&frame);     zuuid_destroy (&uuid);     zhashx_destroy (&hash);      int integer;     byte *data;     size_t size;     char *pointer;     number8_MAX = number8 = number4 = number2 = number1 = 0;     rc = zsock_recv (reader, ""i124488zsbcfUhp"",                      &integer, &number1, &number2, &number4, &number4_MAX,                      &number8, &number8_MAX, &string, &data, &size, &chunk,                      &frame, &uuid, &hash, &pointer);     assert (rc == 0);     assert (integer == -12345);     assert (number1 == 123);     assert (number2 == 123 * 123);     assert (number4 == 123 * 123 * 123);     assert (number4_MAX == UINT32_MAX);     assert (number8 == 123 * 123 * 123 * 123);     assert (number8_MAX == UINT64_MAX);     assert (streq (string, ""This is a string""));     assert (memcmp (data, ""ABCDE"", 5) == 0);     assert (size == 5);     assert (memcmp (zchunk_data (chunk), ""HELLO"", 5) == 0);     assert (zchunk_size (chunk) == 5);     assert (streq (uuid_str, zuuid_str (uuid)));     assert (memcmp (zframe_data (frame), ""WORLD"", 5) == 0);     assert (zframe_size (frame) == 5);     char *value = (char *) zhashx_lookup (hash, ""1"");     assert (streq (value, ""value A""));     value = (char *) zhashx_lookup (hash, ""2"");     assert (streq (value, ""value B""));     assert (original == pointer);     free (string);     free (data);     free (uuid_str);     zframe_destroy (&frame);     zchunk_destroy (&chunk);     zhashx_destroy (&hash);     zuuid_destroy (&uuid);      //  Test zsock_recv of short message; this lets us return a failure     //  with a status code and then nothing else; the receiver will get     //  the status code and NULL/zero for all other values     zsock_send (writer, ""i"", -1);     zsock_recv (reader, ""izsbcfp"",         &integer, &string, &data, &size, &chunk, &frame, &pointer);     assert (integer == -1);     assert (string == NULL);     assert (data == NULL);     assert (size == 0);     assert (chunk == NULL);     assert (frame == NULL);     assert (pointer == NULL);      msg = zmsg_new ();     zmsg_addstr (msg, ""frame 1"");     zmsg_addstr (msg, ""frame 2"");     zsock_send (writer, ""szm"", ""header"", msg);     zmsg_destroy (&msg);      zsock_recv (reader, ""szm"", &string, &msg);      assert (streq (""header"", string));     assert (zmsg_size (msg) == 2);     assert (zframe_streq (zmsg_first (msg), ""frame 1""));     assert (zframe_streq (zmsg_next (msg), ""frame 2""));     zstr_free (&string);     zmsg_destroy (&msg);      //  Test zsock_recv with null arguments     chunk = zchunk_new (""HELLO"", 5);     assert (chunk);     frame = zframe_new (""WORLD"", 5);     assert (frame);     zsock_send (writer, ""izsbcfp"",                 -12345, ""This is a string"", ""ABCDE"", 5, chunk, frame, original);     zframe_destroy (&frame);     zchunk_destroy (&chunk);     zsock_recv (reader, ""izsbcfp"", &integer, NULL, NULL, NULL, &chunk, NULL, NULL);     assert (integer == -12345);     assert (memcmp (zchunk_data (chunk), ""HELLO"", 5) == 0);     assert (zchunk_size (chunk) == 5);     zchunk_destroy (&chunk);      //  Test zsock_bsend/brecv pictures with binary encoding     frame = zframe_new (""Hello"", 5);     chunk = zchunk_new (""World"", 5);      msg = zmsg_new ();     zmsg_addstr (msg, ""Hello"");     zmsg_addstr (msg, ""World"");      zsock_bsend (writer, ""1248sSpcfm"",                  number1, number2, number4, number8,                  ""Hello, World"",                  ""Goodbye cruel World!"",                  original,                  chunk, frame, msg);     zchunk_destroy (&chunk);     zframe_destroy (&frame);     zmsg_destroy (&msg);      number8 = number4 = number2 = number1 = 0;     char *longstr;     zsock_brecv (reader, ""1248sSpcfm"",                  &number1, &number2, &number4, &number8,                  &string, &longstr,                  &pointer,                  &chunk, &frame, &msg);     assert (number1 == 123);     assert (number2 == 123 * 123);     assert (number4 == 123 * 123 * 123);     assert (number8 == 123 * 123 * 123 * 123);     assert (streq (string, ""Hello, World""));     assert (streq (longstr, ""Goodbye cruel World!""));     assert (pointer == original);     zstr_free (&longstr);     zchunk_destroy (&chunk);     zframe_destroy (&frame);     zmsg_destroy (&msg);      #ifdef ZMQ_SERVER      //  Test zsock_bsend/brecv pictures with binary encoding on SERVER and CLIENT sockets     server = zsock_new_server (""tcp://127.0.0.1:5561"");     assert (server);     zsock_t* client = zsock_new_client (""tcp://127.0.0.1:5561"");     assert (client);      //  From client to server     chunk = zchunk_new (""World"", 5);     zsock_bsend (client, ""1248sSpc"",                  number1, number2, number4, number8,                  ""Hello, World"",                  ""Goodbye cruel World!"",                  original,                  chunk);     zchunk_destroy (&chunk);      number8 = number4 = number2 = number1 = 0;     zsock_brecv (server, ""1248sSpc"",                  &number1, &number2, &number4, &number8,                  &string, &longstr,                  &pointer,                  &chunk);     assert (number1 == 123);     assert (number2 == 123 * 123);     assert (number4 == 123 * 123 * 123);     assert (number8 == 123 * 123 * 123 * 123);     assert (streq (string, ""Hello, World""));     assert (streq (longstr, ""Goodbye cruel World!""));     assert (pointer == original);     assert (zsock_routing_id (server));     zstr_free (&longstr);     zchunk_destroy (&chunk);      //  From server to client     chunk = zchunk_new (""World"", 5);     zsock_bsend (server, ""1248sSpc"",                  number1, number2, number4, number8,                  ""Hello, World"",                  ""Goodbye cruel World!"",                  original,                  chunk);     zchunk_destroy (&chunk);      number8 = number4 = number2 = number1 = 0;     zsock_brecv (client, ""1248sSpc"",                  &number1, &number2, &number4, &number8,                  &string, &longstr,                  &pointer,                  &chunk);     assert (number1 == 123);     assert (number2 == 123 * 123);     assert (number4 == 123 * 123 * 123);     assert (number8 == 123 * 123 * 123 * 123);     assert (streq (string, ""Hello, World""));     assert (streq (longstr, ""Goodbye cruel World!""));     assert (pointer == original);     assert (zsock_routing_id (client) == 0);     zstr_free (&longstr);     zchunk_destroy (&chunk);      zsock_destroy (&client);     zsock_destroy (&server);      #endif      #ifdef ZMQ_SCATTER      zsock_t* gather = zsock_new_gather (""inproc://test-gather-scatter"");     assert (gather);     zsock_t* scatter = zsock_new_scatter (""inproc://test-gather-scatter"");     assert (scatter);      rc = zstr_send (scatter, ""HELLO"");     assert (rc == 0);      char* message;     message = zstr_recv (gather);     assert (streq(message, ""HELLO""));     zstr_free (&message);          zsock_destroy (&gather);     zsock_destroy (&scatter);      #endif      //  Check that we can send a zproto format message     zsock_bsend (writer, ""1111sS4"", 0xAA, 0xA0, 0x02, 0x01, ""key"", ""value"", 1234);     zgossip_msg_t *gossip = zgossip_msg_new ();     zgossip_msg_recv (gossip, reader);     assert (zgossip_msg_id (gossip) == ZGOSSIP_MSG_PUBLISH);     zgossip_msg_destroy (&gossip);      zsock_destroy (&reader);     zsock_destroy (&writer);  zstr - sending and receiving strings The zstr class provides utility functions for sending and receiving C strings across ØMQ sockets. It sends strings without a terminating null, and appends a null byte on received strings. This class is for simple message sending.    Memory                       Wire    +-------------+---+          +---+-------------+  Send | S t r i n g | 0 | ----> | 6 | S t r i n g | +-------------+---+ +---+-------------+    Wire                         Heap    +---+-------------+          +-------------+---+  Recv | 6 | S t r i n g | ----> | S t r i n g | 0 | +---+-------------+ +-------------+---+ This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     //  This class has draft methods, which may change over time. They are not     //  in stable releases, by default. Use --enable-drafts to enable.     //  Receive C string from socket. Caller must free returned string using     //  zstr_free(). Returns NULL if the context is being terminated or the      //  process was interrupted.                                                 //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zstr_recv (void *source);      //  Receive a series of strings (until NULL) from multipart data.         //  Each string is allocated and filled with string data; if there        //  are not enough frames, unallocated strings are set to NULL.           //  Returns -1 if the message could not be read, else returns the         //  number of strings filled, zero or more. Free each returned string     //  using zstr_free(). If not enough strings are provided, remaining      //  multipart frames in the message are dropped.                          CZMQ_EXPORT int         zstr_recvx (void *source, char **string_p, ...);      //  Send a C string to a socket, as a frame. The string is sent without      //  trailing null byte; to read this you can use zstr_recv, or a similar     //  method that adds a null terminator on the received string. String        //  may be NULL, which is sent as """".                                        CZMQ_EXPORT int         zstr_send (void *dest, const char *string);      //  Send a C string to a socket, as zstr_send(), with a MORE flag, so that     //  you can send further strings in the same multi-part message.               CZMQ_EXPORT int         zstr_sendm (void *dest, const char *string);      //  Send a formatted string to a socket. Note that you should NOT use     //  user-supplied strings in the format (they may contain '%' which       //  will create security holes).                                          CZMQ_EXPORT int         zstr_sendf (void *dest, const char *format, ...);      //  Send a formatted string to a socket, as for zstr_sendf(), with a           //  MORE flag, so that you can send further strings in the same multi-part     //  message.                                                                   CZMQ_EXPORT int         zstr_sendfm (void *dest, const char *format, ...);      //  Send a series of strings (until NULL) as multipart data        //  Returns 0 if the strings could be sent OK, or -1 on error.     CZMQ_EXPORT int         zstr_sendx (void *dest, const char *string, ...);      //  Free a provided string, and nullify the parent pointer. Safe to call on     //  a null pointer.                                                             CZMQ_EXPORT void         zstr_free (char **string_p);      //  Self test of this class.     CZMQ_EXPORT void         zstr_test (bool verbose);      #ifdef CZMQ_BUILD_DRAFT_API     //  *** Draft method, for development use, may change without warning ***     //  Accepts a void pointer and returns a fresh character string. If source     //  is null, returns an empty string.                                          //  Caller owns return value and must destroy it when done.     CZMQ_EXPORT char *         zstr_str (void *source);      #endif // CZMQ_BUILD_DRAFT_API This is the class self test code:     //  Create two PAIR sockets and connect over inproc     zsock_t *output = zsock_new_pair (""@inproc://zstr.test"");     assert (output);     zsock_t *input = zsock_new_pair ("">inproc://zstr.test"");     assert (input);      //  Send ten strings, five strings with MORE flag and then END     int string_nbr;     for (string_nbr = 0; string_nbr < 10; string_nbr++)         zstr_sendf (output, ""this is string %d"", string_nbr);     zstr_sendx (output, ""This"", ""is"", ""almost"", ""the"", ""very"", ""END"", NULL);      //  Read and count until we receive END     string_nbr = 0;     for (string_nbr = 0;; string_nbr++) {         char *string = zstr_recv (input);         assert (string);         if (streq (string, ""END"")) {             zstr_free (&string);             break;         }         zstr_free (&string);     }     assert (string_nbr == 15);      zsock_destroy (&input);     zsock_destroy (&output);      #if defined (ZMQ_SERVER)     //  Test SERVER/CLIENT over zstr     zsock_t *server = zsock_new_server (""inproc://zstr-test-routing"");     zsock_t *client = zsock_new_client (""inproc://zstr-test-routing"");;     assert (server);     assert (client);      //  Try normal ping-pong to check reply routing ID     int rc = zstr_send (client, ""Hello"");     assert (rc == 0);     char *request = zstr_recv (server);     assert (streq (request, ""Hello""));     assert (zsock_routing_id (server));     free (request);      rc = zstr_send (server, ""World"");     assert (rc == 0);     char *reply = zstr_recv (client);     assert (streq (reply, ""World""));     free (reply);      rc = zstr_sendf (server, ""%s"", ""World"");     assert (rc == 0);     reply = zstr_recv (client);     assert (streq (reply, ""World""));     free (reply);      //  Try ping-pong using sendx and recx     rc = zstr_sendx (client, ""Hello"", NULL);     assert (rc == 0);     rc = zstr_recvx (server, &request, NULL);     assert (rc >= 0);     assert (streq (request, ""Hello""));     free (request);      rc = zstr_sendx (server, ""World"", NULL);     assert (rc == 0);     rc = zstr_recvx (client, &reply, NULL);     assert (rc >= 0);     assert (streq (reply, ""World""));     free (reply);      //  Client and server disallow multipart     rc = zstr_sendm (client, ""Hello"");     assert (rc == -1);     rc = zstr_sendm (server, ""World"");     assert (rc == -1);      zsock_destroy (&client);     zsock_destroy (&server);     #endif zsys - system-level methods The zsys class provides a portable wrapper for system calls. We collect them here to reduce the number of weird #ifdefs in other classes. As far as possible, the bulk of CZMQ classes are fully portable. Please add @discuss section in ../src/zsys.c. This is the class interface:     #define UDP_FRAME_MAX   255         //  Max size of UDP frame      //  Callback for interrupt signal handler     typedef void (zsys_handler_fn) (int signal_value);      //  Initialize CZMQ zsys layer; this happens automatically when you create     //  a socket or an actor; however this call lets you force initialization     //  earlier, so e.g. logging is properly set-up before you start working.     //  Not threadsafe, so call only from main thread. Safe to call multiple     //  times. Returns global CZMQ context.     CZMQ_EXPORT void *         zsys_init (void);      //  Optionally shut down the CZMQ zsys layer; this normally happens automatically     //  when the process exits; however this call lets you force a shutdown     //  earlier, avoiding any potential problems with atexit() ordering, especially     //  with Windows dlls.     CZMQ_EXPORT void         zsys_shutdown (void);      //  Get a new ZMQ socket, automagically creating a ZMQ context if this is     //  the first time. Caller is responsible for destroying the ZMQ socket     //  before process exits, to avoid a ZMQ deadlock. Note: you should not use     //  this method in CZMQ apps, use zsock_new() instead.     //  *** This is for CZMQ internal use only and may change arbitrarily ***     CZMQ_EXPORT void *         zsys_socket (int type, const char *filename, size_t line_nbr);      //  Destroy/close a ZMQ socket. You should call this for every socket you     //  create using zsys_socket().     //  *** This is for CZMQ internal use only and may change arbitrarily ***     CZMQ_EXPORT int         zsys_close (void *handle, const char *filename, size_t line_nbr);      //  Return ZMQ socket name for socket type     //  *** This is for CZMQ internal use only and may change arbitrarily ***     CZMQ_EXPORT char *         zsys_sockname (int socktype);      //  Create a pipe, which consists of two PAIR sockets connected over inproc.     //  The pipe is configured to use the zsys_pipehwm setting. Returns the     //  frontend socket successful, NULL if failed.     CZMQ_EXPORT zsock_t *         zsys_create_pipe (zsock_t **backend_p);      //  Set interrupt handler; this saves the default handlers so that a     //  zsys_handler_reset () can restore them. If you call this multiple times     //  then the last handler will take affect. If handler_fn is NULL, disables     //  default SIGINT/SIGTERM handling in CZMQ.     CZMQ_EXPORT void         zsys_handler_set (zsys_handler_fn *handler_fn);      //  Reset interrupt handler, call this at exit if needed     CZMQ_EXPORT void         zsys_handler_reset (void);      //  Set default interrupt handler, so Ctrl-C or SIGTERM will set     //  zsys_interrupted. Idempotent; safe to call multiple times.     //  *** This is for CZMQ internal use only and may change arbitrarily ***     CZMQ_EXPORT void         zsys_catch_interrupts (void);      //  Return 1 if file exists, else zero     CZMQ_EXPORT bool         zsys_file_exists (const char *filename);      //  Return size of file, or -1 if not found     CZMQ_EXPORT ssize_t         zsys_file_size (const char *filename);      //  Return file modification time. Returns 0 if the file does not exist.     CZMQ_EXPORT time_t         zsys_file_modified (const char *filename);      //  Return file mode; provides at least support for the POSIX S_ISREG(m)     //  and S_ISDIR(m) macros and the S_IRUSR and S_IWUSR bits, on all boxes.     //  Returns a mode_t cast to int, or -1 in case of error.     CZMQ_EXPORT int         zsys_file_mode (const char *filename);      //  Delete file. Does not complain if the file is absent     CZMQ_EXPORT int         zsys_file_delete (const char *filename);      //  Check if file is 'stable'     CZMQ_EXPORT bool         zsys_file_stable (const char *filename);      //  Create a file path if it doesn't exist. The file path is treated as a      //  printf format.     CZMQ_EXPORT int         zsys_dir_create (const char *pathname, ...);      //  Remove a file path if empty; the pathname is treated as printf format.     CZMQ_EXPORT int         zsys_dir_delete (const char *pathname, ...);      //  Move to a specified working directory. Returns 0 if OK, -1 if this failed.     CZMQ_EXPORT int         zsys_dir_change (const char *pathname);      //  Set private file creation mode; all files created from here will be     //  readable/writable by the owner only.     CZMQ_EXPORT void         zsys_file_mode_private (void);      //  Reset default file creation mode; all files created from here will use     //  process file mode defaults.     CZMQ_EXPORT void         zsys_file_mode_default (void);      //  Return the CZMQ version for run-time API detection; returns version     //  number into provided fields, providing reference isn't null in each case.     CZMQ_EXPORT void         zsys_version (int *major, int *minor, int *patch);      //  Format a string using printf formatting, returning a freshly allocated     //  buffer. If there was insufficient memory, returns NULL. Free the returned     //  string using zstr_free().     CZMQ_EXPORT char *         zsys_sprintf (const char *format, ...);      //  Format a string with a va_list argument, returning a freshly allocated     //  buffer. If there was insufficient memory, returns NULL. Free the returned     //  string using zstr_free().     CZMQ_EXPORT char *         zsys_vprintf (const char *format, va_list argptr);      //  Create UDP beacon socket; if the routable option is true, uses     //  multicast (not yet implemented), else uses broadcast. This method     //  and related ones might _eventually_ be moved to a zudp class.     //  *** This is for CZMQ internal use only and may change arbitrarily ***     CZMQ_EXPORT SOCKET         zsys_udp_new (bool routable);      //  Close a UDP socket     //  *** This is for CZMQ internal use only and may change arbitrarily ***     CZMQ_EXPORT int         zsys_udp_close (SOCKET handle);      //  Send zframe to UDP socket, return -1 if sending failed due to     //  interface having disappeared (happens easily with WiFi)     //  *** This is for CZMQ internal use only and may change arbitrarily ***     CZMQ_EXPORT int         zsys_udp_send (SOCKET udpsock, zframe_t *frame, inaddr_t *address, int addrlen);      //  Receive zframe from UDP socket, and set address of peer that sent it     //  The peername must be a char [INET_ADDRSTRLEN] array.     //  *** This is for CZMQ internal use only and may change arbitrarily ***     CZMQ_EXPORT zframe_t *         zsys_udp_recv (SOCKET udpsock, char *peername, int peerlen);      //  Handle an I/O error on some socket operation; will report and die on     //  fatal errors, and continue silently on ""try again"" errors.     //  *** This is for CZMQ internal use only and may change arbitrarily ***     CZMQ_EXPORT void         zsys_socket_error (const char *reason);      //  Return current host name, for use in public tcp:// endpoints. Caller gets     //  a freshly allocated string, should free it using zstr_free(). If the host     //  name is not resolvable, returns NULL.     CZMQ_EXPORT char *         zsys_hostname (void);      //  Move the current process into the background. The precise effect depends     //  on the operating system. On POSIX boxes, moves to a specified working     //  directory (if specified), closes all file handles, reopens stdin, stdout,     //  and stderr to the null device, and sets the process to ignore SIGHUP. On     //  Windows, does nothing. Returns 0 if OK, -1 if there was an error.     CZMQ_EXPORT int         zsys_daemonize (const char *workdir);      //  Drop the process ID into the lockfile, with exclusive lock, and switch     //  the process to the specified group and/or user. Any of the arguments     //  may be null, indicating a no-op. Returns 0 on success, -1 on failure.     //  Note if you combine this with zsys_daemonize, run after, not before     //  that method, or the lockfile will hold the wrong process ID.     CZMQ_EXPORT int         zsys_run_as (const char *lockfile, const char *group, const char *user);      //  Returns true if the underlying libzmq supports CURVE security.     //  Uses a heuristic probe according to the version of libzmq being used.     CZMQ_EXPORT bool         zsys_has_curve (void);      //  Configure the number of I/O threads that ZeroMQ will use. A good     //  rule of thumb is one thread per gigabit of traffic in or out. The     //  default is 1, sufficient for most applications. If the environment     //  variable ZSYS_IO_THREADS is defined, that provides the default.     //  Note that this method is valid only before any socket is created.     CZMQ_EXPORT void         zsys_set_io_threads (size_t io_threads);      //  Configure the number of sockets that ZeroMQ will allow. The default     //  is 1024. The actual limit depends on the system, and you can query it     //  by using zsys_socket_limit (). A value of zero means ""maximum"".     //  Note that this method is valid only before any socket is created.     CZMQ_EXPORT void         zsys_set_max_sockets (size_t max_sockets);      //  Return maximum number of ZeroMQ sockets that the system will support.     CZMQ_EXPORT size_t         zsys_socket_limit (void);      //  Configure the default linger timeout in msecs for new zsock instances.     //  You can also set this separately on each zsock_t instance. The default     //  linger time is zero, i.e. any pending messages will be dropped. If the     //  environment variable ZSYS_LINGER is defined, that provides the default.     //  Note that process exit will typically be delayed by the linger time.     CZMQ_EXPORT void         zsys_set_linger (size_t linger);      //  Configure the default outgoing pipe limit (HWM) for new zsock instances.     //  You can also set this separately on each zsock_t instance. The default     //  HWM is 1,000, on all versions of ZeroMQ. If the environment variable     //  ZSYS_SNDHWM is defined, that provides the default. Note that a value of     //  zero means no limit, i.e. infinite memory consumption.     CZMQ_EXPORT void         zsys_set_sndhwm (size_t sndhwm);      //  Configure the default incoming pipe limit (HWM) for new zsock instances.     //  You can also set this separately on each zsock_t instance. The default     //  HWM is 1,000, on all versions of ZeroMQ. If the environment variable     //  ZSYS_RCVHWM is defined, that provides the default. Note that a value of     //  zero means no limit, i.e. infinite memory consumption.     CZMQ_EXPORT void         zsys_set_rcvhwm (size_t rcvhwm);      //  Configure the default HWM for zactor internal pipes; this is set on both     //  ends of the pipe, for outgoing messages only (sndhwm). The default HWM is     //  1,000, on all versions of ZeroMQ. If the environment var ZSYS_ACTORHWM is     //  defined, that provides the default. Note that a value of zero means no     //  limit, i.e. infinite memory consumption.     CZMQ_EXPORT void         zsys_set_pipehwm (size_t pipehwm);      //  Return the HWM for zactor internal pipes.     CZMQ_EXPORT size_t         zsys_pipehwm (void);      //  Configure use of IPv6 for new zsock instances. By default sockets accept     //  and make only IPv4 connections. When you enable IPv6, sockets will accept     //  and connect to both IPv4 and IPv6 peers. You can override the setting on     //  each zsock_t instance. The default is IPv4 only (ipv6 set to 0). If the     //  environment variable ZSYS_IPV6 is defined (as 1 or 0), this provides the     //  default. Note: has no effect on ZMQ v2.     CZMQ_EXPORT void         zsys_set_ipv6 (int ipv6);      //  Return use of IPv6 for zsock instances.     CZMQ_EXPORT int         zsys_ipv6 (void);      //  Set network interface name to use for broadcasts, particularly zbeacon.     //  This lets the interface be configured for test environments where required.     //  For example, on Mac OS X, zbeacon cannot bind to 255.255.255.255 which is     //  the default when there is no specified interface. If the environment     //  variable ZSYS_INTERFACE is set, use that as the default interface name.     //  Setting the interface to ""*"" means ""use all available interfaces"".     CZMQ_EXPORT void         zsys_set_interface (const char *value);      //  Return network interface to use for broadcasts, or """" if none was set.     CZMQ_EXPORT const char *         zsys_interface (void);      //  Set IPv6 address to use zbeacon socket, particularly for receiving zbeacon.     //  This needs to be set IPv6 is enabled as IPv6 can have multiple addresses     //  on a given interface. If the environment variable ZSYS_IPV6_ADDRESS is set,     //  use that as the default IPv6 address.     CZMQ_EXPORT void         zsys_set_ipv6_address (const char *value);      //  Return IPv6 address to use for zbeacon reception, or """" if none was set.     CZMQ_EXPORT const char *         zsys_ipv6_address (void);      //  Set IPv6 milticast address to use for sending zbeacon messages. This needs     //  to be set if IPv6 is enabled. If the environment variable     //  ZSYS_IPV6_MCAST_ADDRESS is set, use that as the default IPv6 multicast     //  address.     CZMQ_EXPORT void         zsys_set_ipv6_mcast_address (const char *value);      //  Return IPv6 multicast address to use for sending zbeacon, or """" if none was     //  set.     CZMQ_EXPORT const char *         zsys_ipv6_mcast_address (void);      //  Configure the automatic use of pre-allocated FDs when creating new sockets.     //  If 0 (default), nothing will happen. Else, when a new socket is bound, the     //  system API will be used to check if an existing pre-allocated FD with a     //  matching port (if TCP) or path (if IPC) exists, and if it does it will be     //  set via the ZMQ_USE_FD socket option so that the library will use it     //  instead of creating a new socket.     CZMQ_EXPORT void         zsys_set_auto_use_fd (int auto_use_fd);      //  Return use of automatic pre-allocated FDs for zsock instances.     CZMQ_EXPORT int         zsys_auto_use_fd (void);      //  Set log identity, which is a string that prefixes all log messages sent     //  by this process. The log identity defaults to the environment variable     //  ZSYS_LOGIDENT, if that is set.     CZMQ_EXPORT void         zsys_set_logident (const char *value);      //  Set stream to receive log traffic. By default, log traffic is sent to     //  stdout. If you set the stream to NULL, no stream will receive the log     //  traffic (it may still be sent to the system facility).     CZMQ_EXPORT void         zsys_set_logstream (FILE *stream);      //  Sends log output to a PUB socket bound to the specified endpoint. To     //  collect such log output, create a SUB socket, subscribe to the traffic     //  you care about, and connect to the endpoint. Log traffic is sent as a     //  single string frame, in the same format as when sent to stdout. The     //  log system supports a single sender; multiple calls to this method will     //  bind the same sender to multiple endpoints. To disable the sender, call     //  this method with a null argument.     CZMQ_EXPORT void         zsys_set_logsender (const char *endpoint);      //  Enable or disable logging to the system facility (syslog on POSIX boxes,     //  event log on Windows). By default this is disabled.     CZMQ_EXPORT void         zsys_set_logsystem (bool logsystem);      //  Log error condition - highest priority     CZMQ_EXPORT void         zsys_error (const char *format, ...);      //  Log warning condition - high priority     CZMQ_EXPORT void         zsys_warning (const char *format, ...);      //  Log normal, but significant, condition - normal priority     CZMQ_EXPORT void         zsys_notice (const char *format, ...);      //  Log informational message - low priority     CZMQ_EXPORT void         zsys_info (const char *format, ...);      //  Log debug-level message - lowest priority     CZMQ_EXPORT void         zsys_debug (const char *format, ...);      //  Self test of this class     CZMQ_EXPORT void         zsys_test (bool verbose);      //  Global signal indicator, TRUE when user presses Ctrl-C or the process     //  gets a SIGTERM signal.     CZMQ_EXPORT extern volatile int zsys_interrupted;     //  Deprecated name for this variable     CZMQ_EXPORT extern volatile int zctx_interrupted; This is the class self test code:     zsys_catch_interrupts ();      //  Check capabilities without using the return value     int rc = zsys_has_curve ();      if (verbose) {         char *hostname = zsys_hostname ();         zsys_info (""host name is %s"", hostname);         free (hostname);         zsys_info (""system limit is %zu ZeroMQ sockets"", zsys_socket_limit ());     }     zsys_set_linger (0);     zsys_set_sndhwm (1000);     zsys_set_rcvhwm (1000);     zsys_set_pipehwm (2500);     assert (zsys_pipehwm () == 2500);     zsys_set_ipv6 (0);      //  Test pipe creation     zsock_t *pipe_back;     zsock_t *pipe_front = zsys_create_pipe (&pipe_back);     zstr_send (pipe_front, ""Hello"");     char *string = zstr_recv (pipe_back);     assert (streq (string, ""Hello""));     free (string);     zsock_destroy (&pipe_back);     zsock_destroy (&pipe_front);      //  Test file manipulation     rc = zsys_file_delete (""nosuchfile"");     assert (rc == -1);      bool rc_bool = zsys_file_exists (""nosuchfile"");     assert (rc_bool != true);      rc = (int) zsys_file_size (""nosuchfile"");     assert (rc == -1);      time_t when = zsys_file_modified (""."");     assert (when > 0);      int mode = zsys_file_mode (""."");     assert (S_ISDIR (mode));     assert (mode & S_IRUSR);     assert (mode & S_IWUSR);      zsys_file_mode_private ();     rc = zsys_dir_create (""%s/%s"", ""."", "".testsys/subdir"");     assert (rc == 0);     when = zsys_file_modified (""./.testsys/subdir"");     assert (when > 0);     assert (!zsys_file_stable (""./.testsys/subdir""));     rc = zsys_dir_delete (""%s/%s"", ""."", "".testsys/subdir"");     assert (rc == 0);     rc = zsys_dir_delete (""%s/%s"", ""."", "".testsys"");     assert (rc == 0);     zsys_file_mode_default ();     assert (zsys_dir_change (""."") == 0);      int major, minor, patch;     zsys_version (&major, &minor, &patch);     assert (major == CZMQ_VERSION_MAJOR);     assert (minor == CZMQ_VERSION_MINOR);     assert (patch == CZMQ_VERSION_PATCH);      string = zsys_sprintf (""%s %02x"", ""Hello"", 16);     assert (streq (string, ""Hello 10""));     free (string);      char *str64 = ""ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz1234567890,."";     int num10 = 1234567890;     string = zsys_sprintf (""%s%s%s%s%d"", str64, str64, str64, str64, num10);     assert (strlen (string) == (4 * 64 + 10));     free (string);      //  Test logging system     zsys_set_logident (""czmq_selftest"");     zsys_set_logsender (""inproc://logging"");     void *logger = zsys_socket (ZMQ_SUB, NULL, 0);     assert (logger);     rc = zmq_connect (logger, ""inproc://logging"");     assert (rc == 0);     rc = zmq_setsockopt (logger, ZMQ_SUBSCRIBE, """", 0);     assert (rc == 0);      if (verbose) {         zsys_error (""This is an %s message"", ""error"");         zsys_warning (""This is a %s message"", ""warning"");         zsys_notice (""This is a %s message"", ""notice"");         zsys_info (""This is a %s message"", ""info"");         zsys_debug (""This is a %s message"", ""debug"");         zsys_set_logident (""hello, world"");         zsys_info (""This is a %s message"", ""info"");         zsys_debug (""This is a %s message"", ""debug"");          //  Check that logsender functionality is working         char *received = zstr_recv (logger);         assert (received);         zstr_free (&received);     }     zsys_close (logger, NULL, 0); ztimerset - timer set ztimerset - timer set Please add @discuss section in ../src/ztimerset.c. This is the class interface:     //  This is a draft class, and may change without notice. It is disabled in     //  stable builds by default. If you use this in applications, please ask     //  for it to be pushed to stable state. Use --enable-drafts to enable.     #ifdef CZMQ_BUILD_DRAFT_API     // Callback function for timer event.     typedef void (ztimerset_fn) (         int timer_id, void *arg);      //  *** Draft method, for development use, may change without warning ***     //  Create new timer set.     CZMQ_EXPORT ztimerset_t *         ztimerset_new (void);      //  *** Draft method, for development use, may change without warning ***     //  Destroy a timer set     CZMQ_EXPORT void         ztimerset_destroy (ztimerset_t **self_p);      //  *** Draft method, for development use, may change without warning ***     //  Add a timer to the set. Returns timer id if OK, -1 on failure.     CZMQ_EXPORT int         ztimerset_add (ztimerset_t *self, size_t interval, ztimerset_fn handler, void *arg);      //  *** Draft method, for development use, may change without warning ***     //  Cancel a timer. Returns 0 if OK, -1 on failure.     CZMQ_EXPORT int         ztimerset_cancel (ztimerset_t *self, int timer_id);      //  *** Draft method, for development use, may change without warning ***     //  Set timer interval. Returns 0 if OK, -1 on failure.                                         //  This method is slow, canceling the timer and adding a new one yield better performance.     CZMQ_EXPORT int         ztimerset_set_interval (ztimerset_t *self, int timer_id, size_t interval);      //  *** Draft method, for development use, may change without warning ***     //  Reset timer to start interval counting from current time. Returns 0 if OK, -1 on failure.     //  This method is slow, canceling the timer and adding a new one yield better performance.       CZMQ_EXPORT int         ztimerset_reset (ztimerset_t *self, int timer_id);      //  *** Draft method, for development use, may change without warning ***     //  Return the time until the next interval.                             //  Should be used as timeout parameter for the zpoller wait method.     //  The timeout is in msec.                                              CZMQ_EXPORT int         ztimerset_timeout (ztimerset_t *self);      //  *** Draft method, for development use, may change without warning ***     //  Invoke callback function of all timers which their interval has elapsed.     //  Should be call after zpoller wait method.                                    //  Returns 0 if OK, -1 on failure.                                              CZMQ_EXPORT int         ztimerset_execute (ztimerset_t *self);      //  *** Draft method, for development use, may change without warning ***     //  Self test of this class.     CZMQ_EXPORT void         ztimerset_test (bool verbose);      #endif // CZMQ_BUILD_DRAFT_API This is the class self test code:     //  Simple create/destroy test     ztimerset_t *self = ztimerset_new ();     assert (self);      //  Adding timer     bool timer_invoked = false;     int timer_id = ztimerset_add (self, 100, handler, &timer_invoked);     assert (timer_id != -1);     int rc = ztimerset_execute (self);     assert (rc == 0);     assert (!timer_invoked);     int timeout = ztimerset_timeout (self);     assert (timeout > 0);     zclock_sleep (timeout);     rc = ztimerset_execute (self);     assert (rc == 0);     assert (timer_invoked);      //  Cancel timer     timeout = ztimerset_timeout (self);     assert (timeout > 0);     rc = ztimerset_cancel (self, timer_id);     assert (rc == 0);     timeout = ztimerset_timeout (self);     assert(timeout == -1);      //  Reset a timer     timer_id = ztimerset_add (self, 100, handler, &timer_invoked);     assert (timer_id != -1);     timeout = ztimerset_timeout (self);     assert (timeout > 0);     zclock_sleep (timeout / 2);     timeout = ztimerset_timeout (self);     rc = ztimerset_reset(self, timer_id);     assert (rc == 0);     int timeout2 = ztimerset_timeout (self);     assert (timeout2 > timeout);     rc = ztimerset_cancel (self, timer_id);     assert (rc == 0);      //  Set interval     timer_id = ztimerset_add (self, 100, handler, &timer_invoked);     assert (timer_id != -1);     timeout = ztimerset_timeout (self);     rc = ztimerset_set_interval(self, timer_id, 200);     timeout2 = ztimerset_timeout (self);     assert (timeout2 > timeout);      ztimerset_destroy (&self); ztrie - simple trie for tokenizable strings This is a variant of a trie or prefix tree where all the descendants of a node have a common prefix of the string associated with that node. This implementation is specialized for strings that can be tokenized by a delimiter like a URL, URI or URN. Routes in the tree can be matched by regular expressions and by using capturing groups parts of a matched route can be easily obtained. Note that the performance for pure string based matching is okay but on short strings zhash and zhashx are 3-4 times faster. This is the class interface:     //  This is a draft class, and may change without notice. It is disabled in     //  stable builds by default. If you use this in applications, please ask     //  for it to be pushed to stable state. Use --enable-drafts to enable.     #ifdef CZMQ_BUILD_DRAFT_API     // Callback function for ztrie_node to destroy node data.     typedef void (ztrie_destroy_data_fn) (         void **data);      //  *** Draft method, for development use, may change without warning ***     //  Creates a new ztrie.     CZMQ_EXPORT ztrie_t *         ztrie_new (char delimiter);      //  *** Draft method, for development use, may change without warning ***     //  Destroy the ztrie.     CZMQ_EXPORT void         ztrie_destroy (ztrie_t **self_p);      //  *** Draft method, for development use, may change without warning ***     //  Inserts a new route into the tree and attaches the data. Returns -1          //  if the route already exists, otherwise 0. This method takes ownership of     //  the provided data if a destroy_data_fn is provided.                          CZMQ_EXPORT int         ztrie_insert_route (ztrie_t *self, const char *path, void *data, ztrie_destroy_data_fn destroy_data_fn);      //  *** Draft method, for development use, may change without warning ***     //  Removes a route from the trie and destroys its data. Returns -1 if the     //  route does not exists, otherwise 0.                                        //  the start of the list call zlist_first (). Advances the cursor.            CZMQ_EXPORT int         ztrie_remove_route (ztrie_t *self, const char *path);      //  *** Draft method, for development use, may change without warning ***     //  Returns true if the path matches a route in the tree, otherwise false.     CZMQ_EXPORT bool         ztrie_matches (ztrie_t *self, const char *path);      //  *** Draft method, for development use, may change without warning ***     //  Returns the data of a matched route from last ztrie_matches. If the path     //  did not match, returns NULL. Do not delete the data as it's owned by         //  ztrie.                                                                       CZMQ_EXPORT void *         ztrie_hit_data (ztrie_t *self);      //  *** Draft method, for development use, may change without warning ***     //  Returns the count of parameters that a matched route has.     CZMQ_EXPORT size_t         ztrie_hit_parameter_count (ztrie_t *self);      //  *** Draft method, for development use, may change without warning ***     //  Returns the parameters of a matched route with named regexes from last        //  ztrie_matches. If the path did not match or the route did not contain any     //  named regexes, returns NULL.                                                  CZMQ_EXPORT zhashx_t *         ztrie_hit_parameters (ztrie_t *self);      //  *** Draft method, for development use, may change without warning ***     //  Returns the asterisk matched part of a route, if there has been no match     //  or no asterisk match, returns NULL.                                          CZMQ_EXPORT const char *         ztrie_hit_asterisk_match (ztrie_t *self);      //  *** Draft method, for development use, may change without warning ***     //  Print the trie     CZMQ_EXPORT void         ztrie_print (ztrie_t *self);      //  *** Draft method, for development use, may change without warning ***     //  Self test of this class.     CZMQ_EXPORT void         ztrie_test (bool verbose);      #endif // CZMQ_BUILD_DRAFT_API This is the class self test code:     //  Create a new trie for matching strings that can be tokenized by a slash     //  (e.g. URLs minus the protocol, address and port).     ztrie_t *self = ztrie_new ('/');     assert (self);      int ret = 0;      //  Let's start by inserting a couple of routes into the trie.     //  This one is for the route '/foo/bar' the slash at the beginning of the     //  route is important because everything before the first delimiter will be     //  discarded. A slash at the end of a route is optional though. The data     //  associated with this node is passed without destroy function which means     //  it must be destroyed by the caller.     int foo_bar_data = 10;     ret = ztrie_insert_route (self, ""/foo/bar"", &foo_bar_data, NULL);     assert (ret == 0);      //  Now suppose we like to match all routes with two tokens that start with     //  '/foo/' but aren't '/foo/bar'. This is possible by using regular     //  expressions which are enclosed in an opening and closing curly bracket.     //  Tokens that contain regular  expressions are always match after string     //  based tokens.     //  Note: There is no order in which regular expressions are sorted thus     //  if you enter multiple expressions for a route you will have to make     //  sure they don't have overlapping results. For example '/foo/{[^/]+}'     //  and '/foo/{\d+} having could turn out badly.     int foo_other_data = 100;     ret = ztrie_insert_route (self, ""/foo/{[^/]+}"", &foo_other_data, NULL);     assert (ret == 0);      //  Regular expression are only matched against tokens of the same level.     //  This allows us to append to are route with a regular expression as if     //  it were a string.     ret = ztrie_insert_route (self, ""/foo/{[^/]+}/gulp"", NULL, NULL);     assert (ret == 0);      //  Routes are identified by their endpoint, which is the last token of the route.     //  It is possible to insert routes for a node that already exists but isn't an     //  endpoint yet. The delimiter at the end of a route is optional and has no effect.     ret = ztrie_insert_route (self, ""/foo/"", NULL, NULL);     assert (ret == 0);      //  If you try to insert a route which already exists the method will return -1.     ret = ztrie_insert_route (self, ""/foo"", NULL, NULL);     assert (ret == -1);      //  It is not allowed to insert routes with empty tokens.     ret = ztrie_insert_route (self, ""//foo"", NULL, NULL);     assert (ret == -1);      //  Everything before the first delimiter is ignored so 'foo/bar/baz' is equivalent     //  to '/bar/baz'.     ret = ztrie_insert_route (self, ""foo/bar/baz"", NULL, NULL);     assert (ret == 0);     ret = ztrie_insert_route (self, ""/bar/baz"", NULL, NULL);     assert (ret == -1);      //  Of course you are allowed to remove routes, in case there is data associated with a     //  route and a destroy data function has been supplied that data will be destroyed.     ret = ztrie_remove_route (self, ""/foo"");     assert (ret == 0);      //  Removing a non existent route will  as well return -1.     ret = ztrie_remove_route (self, ""/foo"");     assert (ret == -1);      //  Removing a route with a regular expression must exactly match the entered one.     ret = ztrie_remove_route (self, ""/foo/{[^/]+}"");     assert (ret == 0);      //  Next we like to match a path by regular expressions and also extract matched     //  parts of a route. This can be done by naming the regular expression. The name of a     //  regular expression is entered at the beginning of the curly brackets and separated     //  by a colon from the regular expression. The first one in this examples is named     //  'name' and names the expression '[^/]'. If there is no capturing group defined in     //  the expression the whole matched string will be associated with this parameter. In     //  case you don't like the get the whole matched string use a capturing group, like     //  it has been done for the 'id' parameter. This is nice but you can even match as     //  many parameter for a token as you like. Therefore simply put the parameter names     //  separated by colons in front of the regular expression and make sure to add a     //  capturing group for each parameter. The first parameter will be associated with     //  the first capturing and so on.     char *data = (char *) malloc (80);     sprintf (data, ""%s"", ""Hello World!"");     ret = ztrie_insert_route (self, ""/baz/{name:[^/]+}/{id:--(\\d+)}/{street:nr:(\\a+)(\\d+)}"", data, NULL);     assert (ret == 0);      //  There is a lot you can do with regular expression but matching routes     //  of arbitrary length wont work. Therefore we make use of the asterisk     //  operator. Just place it at the end of your route, e.g. '/config/bar/*'.     ret = ztrie_insert_route (self, ""/config/bar/*"", NULL, NULL);     assert (ret == 0);      //  Appending to an asterisk as you would to with a regular expression     //  isn't valid.     ret = ztrie_insert_route (self, ""/config/bar/*/bar"", NULL, NULL);     assert (ret == -1);      //  The asterisk operator will only work as a leaf in the tree. If you     //  enter an asterisk in the middle of your route it will simply be     //  interpreted as a string.     ret = ztrie_insert_route (self, ""/test/*/bar"", NULL, NULL);     assert (ret == 0);      //  If a parent has an asterisk as child it is not allowed to have     //  other siblings.     ret = ztrie_insert_route (self, ""/config/bar/foo/glup"", NULL, NULL);     assert (ret != 0);      //  Test matches     bool hasMatch = false;      //  The route '/bar/foo' will fail to match as this route has never been inserted.     hasMatch = ztrie_matches (self, ""/bar/foo"");     assert (!hasMatch);      //  The route '/foo/bar' will match and we can obtain the data associated with it.     hasMatch = ztrie_matches (self, ""/foo/bar"");     assert (hasMatch);     int foo_bar_hit_data = *((int *) ztrie_hit_data (self));     assert (foo_bar_data == foo_bar_hit_data);      //  This route is part of another but is no endpoint itself thus the matches will fail.     hasMatch = ztrie_matches (self, ""/baz/blub"");     assert (!hasMatch);      //  This route will match our named regular expressions route. Thus we can extract data     //  from the route by their names.     hasMatch = ztrie_matches (self, ""/baz/blub/--11/abc23"");     assert (hasMatch);     char *match_data = (char *) ztrie_hit_data (self);     assert (streq (""Hello World!"", match_data));     zhashx_t *parameters = ztrie_hit_parameters (self);     assert (zhashx_size (parameters) == 4);     assert (streq (""blub"", (char *) zhashx_lookup (parameters, ""name"")));     assert (streq (""11"", (char *) zhashx_lookup (parameters, ""id"")));     assert (streq (""abc"", (char *) zhashx_lookup (parameters, ""street"")));     assert (streq (""23"", (char *) zhashx_lookup (parameters, ""nr"")));     zhashx_destroy (&parameters);      //  This will match our asterisk route '/config/bar/*'. As the result we     //  can obtain the asterisk matched part of the route.     hasMatch = ztrie_matches (self, ""/config/bar/foo/bar"");     assert (hasMatch);     assert (streq (ztrie_hit_asterisk_match (self), ""foo/bar""));      zstr_free (&data);     ztrie_destroy (&self); zuuid - UUID support class The zuuid class generates UUIDs and provides methods for working with them. If you build CZMQ with libuuid, on Unix/Linux, it will use that library. On Windows it will use UuidCreate(). Otherwise it will use a random number generator to produce convincing imitations of UUIDs. Please add @discuss section in ../src/zuuid.c. This is the class interface:     //  This is a stable class, and may not change except for emergencies. It     //  is provided in stable builds.     //  Create a new UUID object.     CZMQ_EXPORT zuuid_t *         zuuid_new (void);      //  Create UUID object from supplied ZUUID_LEN-octet value.     CZMQ_EXPORT zuuid_t *         zuuid_new_from (const byte *source);      //  Destroy a specified UUID object.     CZMQ_EXPORT void         zuuid_destroy (zuuid_t **self_p);      //  Set UUID to new supplied ZUUID_LEN-octet value.     CZMQ_EXPORT void         zuuid_set (zuuid_t *self, const byte *source);      //  Set UUID to new supplied string value skipping '-' and '{' '}'     //  optional delimiters. Return 0 if OK, else returns -1.              CZMQ_EXPORT int         zuuid_set_str (zuuid_t *self, const char *source);      //  Return UUID binary data.     CZMQ_EXPORT const byte *         zuuid_data (zuuid_t *self);      //  Return UUID binary size     CZMQ_EXPORT size_t         zuuid_size (zuuid_t *self);      //  Returns UUID as string     CZMQ_EXPORT const char *         zuuid_str (zuuid_t *self);      //  Return UUID in the canonical string format: 8-4-4-4-12, in lower     //  case. Caller does not modify or free returned value. See             //  http://en.wikipedia.org/wiki/Universally_unique_identifier           CZMQ_EXPORT const char *         zuuid_str_canonical (zuuid_t *self);      //  Store UUID blob in target array     CZMQ_EXPORT void         zuuid_export (zuuid_t *self, byte *target);      //  Check if UUID is same as supplied value     CZMQ_EXPORT bool         zuuid_eq (zuuid_t *self, const byte *compare);      //  Check if UUID is different from supplied value     CZMQ_EXPORT bool         zuuid_neq (zuuid_t *self, const byte *compare);      //  Make copy of UUID object; if uuid is null, or memory was exhausted,     //  returns null.                                                           CZMQ_EXPORT zuuid_t *         zuuid_dup (zuuid_t *self);      //  Self test of this class.     CZMQ_EXPORT void         zuuid_test (bool verbose);  This is the class self test code:     //  Simple create/destroy test     assert (ZUUID_LEN == 16);     assert (ZUUID_STR_LEN == 32);      zuuid_t *uuid = zuuid_new ();     assert (uuid);     assert (zuuid_size (uuid) == ZUUID_LEN);     assert (strlen (zuuid_str (uuid)) == ZUUID_STR_LEN);     zuuid_t *copy = zuuid_dup (uuid);     assert (streq (zuuid_str (uuid), zuuid_str (copy)));      //  Check set/set_str/export methods     const char *myuuid = ""8CB3E9A9649B4BEF8DE225E9C2CEBB38"";     const char *myuuid2 = ""8CB3E9A9-649B-4BEF-8DE2-25E9C2CEBB38"";     const char *myuuid3 = ""{8CB3E9A9-649B-4BEF-8DE2-25E9C2CEBB38}"";     const char *myuuid4 = ""8CB3E9A9649B4BEF8DE225E9C2CEBB3838"";     int rc = zuuid_set_str (uuid, myuuid);     assert (rc == 0);     assert (streq (zuuid_str (uuid), myuuid));     rc = zuuid_set_str (uuid, myuuid2);     assert (rc == 0);     assert (streq (zuuid_str (uuid), myuuid));     rc = zuuid_set_str (uuid, myuuid3);     assert (rc == 0);     assert (streq (zuuid_str (uuid), myuuid));     rc = zuuid_set_str (uuid, myuuid4);     assert (rc == -1);     byte copy_uuid [ZUUID_LEN];     zuuid_export (uuid, copy_uuid);     zuuid_set (uuid, copy_uuid);     assert (streq (zuuid_str (uuid), myuuid));      //  Check the canonical string format     assert (streq (zuuid_str_canonical (uuid),                    ""8cb3e9a9-649b-4bef-8de2-25e9c2cebb38""));      zuuid_destroy (&uuid);     zuuid_destroy (&copy); API v2 Summary This is the deprecated API provided by CZMQ v2.x, in alphabetical order. zauth_v2 - authentication for ZeroMQ servers (deprecated) A zauth object takes over authentication for all incoming connections in its context. This class is deprecated in CZMQ v3; it works together with zctx, zsocket, and other deprecated V2 classes. New applications should use the V3 zauth interface, based on zactor, together with the zsock class for sockets. This is the class interface:     #ifndef CURVE_ALLOW_ANY     #   define CURVE_ALLOW_ANY ""*""     #endif      //  Constructor     //  Install authentication for the specified context. Returns a new zauth     //  object that you can use to configure authentication. Note that until you     //  add policies, all incoming NULL connections are allowed (classic ZeroMQ     //  behaviour), and all PLAIN and CURVE connections are denied. If there was     //  an error during initialization, returns NULL.     CZMQ_EXPORT zauth_t *         zauth_new (zctx_t *ctx);      //  Destructor     CZMQ_EXPORT void         zauth_destroy (zauth_t **self_p);      //  Allow (whitelist) a single IP address. For NULL, all clients from this     //  address will be accepted. For PLAIN and CURVE, they will be allowed to     //  continue with authentication. You can call this method multiple times      //  to whitelist multiple IP addresses. If you whitelist a single address,     //  any non-whitelisted addresses are treated as blacklisted.     CZMQ_EXPORT void         zauth_allow (zauth_t *self, const char *address);      //  Deny (blacklist) a single IP address. For all security mechanisms, this     //  rejects the connection without any further authentication. Use either a     //  whitelist, or a blacklist, not not both. If you define both a whitelist      //  and a blacklist, only the whitelist takes effect.     CZMQ_EXPORT void         zauth_deny (zauth_t *self, const char *address);      //  Configure PLAIN authentication for a given domain. PLAIN authentication     //  uses a plain-text password file. To cover all domains, use ""*"". You can     //  modify the password file at any time; it is reloaded automatically.     CZMQ_EXPORT void         zauth_configure_plain (zauth_t *self, const char *domain, const char *filename);      //  Configure CURVE authentication for a given domain. CURVE authentication     //  uses a directory that holds all public client certificates, i.e. their     //  public keys. The certificates must be in zcert_save () format. To cover     //  all domains, use ""*"". You can add and remove certificates in that     //  directory at any time. To allow all client keys without checking, specify     //  CURVE_ALLOW_ANY for the location.     CZMQ_EXPORT void         zauth_configure_curve (zauth_t *self, const char *domain, const char *location);      //  Configure GSSAPI authentication for a given domain. GSSAPI authentication     //  uses an underlying mechanism (usually Kerberos) to establish a secure     //  context and perform mutual authentication. To cover all domains, use ""*"".     CZMQ_EXPORT void         zauth_configure_gssapi (zauth_t *self, char *domain);      //  Enable verbose tracing of commands and activity     CZMQ_EXPORT void         zauth_set_verbose (zauth_t *self, bool verbose);      //  Selftest     CZMQ_EXPORT void         zauth_v2_test (bool verbose); This is the class self test code:     //  Create temporary directory for test files     #   define TESTDIR "".test_zauth""     zsys_dir_create (TESTDIR);      //  Install the authenticator     zctx_t *ctx = zctx_new ();     assert (ctx);     zauth_t *auth = zauth_new (ctx);     assert (auth);     zauth_set_verbose (auth, verbose);      //  A default NULL connection should always success, and not     //  go through our authentication infrastructure at all.     void *server = zsocket_new (ctx, ZMQ_PUSH);     assert (server);     void *client = zsocket_new (ctx, ZMQ_PULL);     assert (client);     bool success = s_can_connect (ctx, &server, &client);     assert (success);      //  When we set a domain on the server, we switch on authentication     //  for NULL sockets, but with no policies, the client connection     //  will be allowed.     zsocket_set_zap_domain (server, ""global"");     success = s_can_connect (ctx, &server, &client);     assert (success);      //  Blacklist 127.0.0.1, connection should fail     zsocket_set_zap_domain (server, ""global"");     zauth_deny (auth, ""127.0.0.1"");     success = s_can_connect (ctx, &server, &client);     assert (!success);      //  Whitelist our address, which overrides the blacklist     zsocket_set_zap_domain (server, ""global"");     zauth_allow (auth, ""127.0.0.1"");     success = s_can_connect (ctx, &server, &client);     assert (success);      //  Try PLAIN authentication     zsocket_set_plain_server (server, 1);     zsocket_set_plain_username (client, ""admin"");     zsocket_set_plain_password (client, ""Password"");     success = s_can_connect (ctx, &server, &client);     assert (!success);      FILE *password = fopen (TESTDIR ""/password-file"", ""w"");     assert (password);     fprintf (password, ""admin=Password\n"");     fclose (password);     zsocket_set_plain_server (server, 1);     zsocket_set_plain_username (client, ""admin"");     zsocket_set_plain_password (client, ""Password"");     zauth_configure_plain (auth, ""*"", TESTDIR ""/password-file"");     success = s_can_connect (ctx, &server, &client);     assert (success);      zsocket_set_plain_server (server, 1);     zsocket_set_plain_username (client, ""admin"");     zsocket_set_plain_password (client, ""Bogus"");     success = s_can_connect (ctx, &server, &client);     assert (!success);      if (zsys_has_curve ()) {         //  Try CURVE authentication         //  We'll create two new certificates and save the client public         //  certificate on disk; in a real case we'd transfer this securely         //  from the client machine to the server machine.         zcert_t *server_cert = zcert_new ();         assert (server_cert);         zcert_t *client_cert = zcert_new ();         assert (client_cert);         const char *server_key = zcert_public_txt (server_cert);          //  Test without setting-up any authentication         zcert_apply (server_cert, server);         zcert_apply (client_cert, client);         zsocket_set_curve_server (server, 1);         zsocket_set_curve_serverkey (client, server_key);         success = s_can_connect (ctx, &server, &client);         assert (!success);          //  Test CURVE_ALLOW_ANY         zcert_apply (server_cert, server);         zcert_apply (client_cert, client);         zsocket_set_curve_server (server, 1);         zsocket_set_curve_serverkey (client, server_key);         zauth_configure_curve (auth, ""*"", CURVE_ALLOW_ANY);         success = s_can_connect (ctx, &server, &client);         assert (success);          //  Test full client authentication using certificates         zcert_apply (server_cert, server);         zcert_apply (client_cert, client);         zsocket_set_curve_server (server, 1);         zsocket_set_curve_serverkey (client, server_key);         zcert_save_public (client_cert, TESTDIR ""/mycert.txt"");         zauth_configure_curve (auth, ""*"", TESTDIR);         success = s_can_connect (ctx, &server, &client);         assert (success);          zcert_destroy (&server_cert);         zcert_destroy (&client_cert);     }     //  Remove the authenticator and check a normal connection works     zauth_destroy (&auth);     success = s_can_connect (ctx, &server, &client);     assert (success);      zctx_destroy (&ctx);      //  Delete all test files     zdir_t *dir = zdir_new (TESTDIR, NULL);     assert (dir);     zdir_remove (dir, true);     zdir_destroy (&dir); zctx - working with ØMQ contexts (deprecated) The zctx class wraps ØMQ contexts. It manages open sockets in the context and automatically closes these before terminating the context. It provides a simple way to set the linger timeout on sockets, and configure contexts for number of I/O threads. Sets-up signal (interrupt) handling for the process. The zctx class has these main features: Tracks all open sockets and automatically closes them before calling zmq_term(). This avoids an infinite wait on open sockets. Automatically configures sockets with a ZMQ_LINGER timeout you can define, and which defaults to zero. The default behavior of zctx is therefore like ØMQ/2.0, immediate termination with loss of any pending messages. You can set any linger timeout you like by calling the zctx_set_linger() method. Moves the iothreads configuration to a separate method, so that default usage is 1 I/O thread. Lets you configure this value. Sets up signal (SIGINT and SIGTERM) handling so that blocking calls such as zmq_recv() and zmq_poll() will return when the user presses Ctrl-C. NOTE: this class is deprecated in favor of zsock, which does not expose contexts in the API at all. All zsock instances use the same global context. This is the class interface:     //  Create new context, returns context object, replaces zmq_init     CZMQ_EXPORT zctx_t *         zctx_new (void);      //  Destroy context and all sockets in it, replaces zmq_term     CZMQ_EXPORT void         zctx_destroy (zctx_t **self_p);      //  Create new shadow context, returns context object     CZMQ_EXPORT zctx_t *         zctx_shadow (zctx_t *self);     //  Raise default I/O threads from 1, for crazy heavy applications     //  The rule of thumb is one I/O thread per gigabyte of traffic in     //  or out. Call this method before creating any sockets on the context,     //  or calling zctx_shadow, or the setting will have no effect.     CZMQ_EXPORT void         zctx_set_iothreads (zctx_t *self, int iothreads);      //  Set msecs to flush sockets when closing them, see the ZMQ_LINGER     //  man page section for more details. By default, set to zero, so     //  any in-transit messages are discarded when you destroy a socket or     //  a context.     CZMQ_EXPORT void         zctx_set_linger (zctx_t *self, int linger);      //  Set initial high-water mark for inter-thread pipe sockets. Note that     //  this setting is separate from the default for normal sockets. You      //  should change the default for pipe sockets *with care*. Too low values     //  will cause blocked threads, and an infinite setting can cause memory     //  exhaustion. The default, no matter the underlying ZeroMQ version, is     //  1,000.     CZMQ_EXPORT void         zctx_set_pipehwm (zctx_t *self, int pipehwm);      //  Set initial send HWM for all new normal sockets created in context.     //  You can set this per-socket after the socket is created.     //  The default, no matter the underlying ZeroMQ version, is 1,000.     CZMQ_EXPORT void         zctx_set_sndhwm (zctx_t *self, int sndhwm);      //  Set initial receive HWM for all new normal sockets created in context.     //  You can set this per-socket after the socket is created.     //  The default, no matter the underlying ZeroMQ version, is 1,000.     CZMQ_EXPORT void         zctx_set_rcvhwm (zctx_t *self, int rcvhwm);      //  Return low-level ØMQ context object, will be NULL before first socket     //  is created. Use with care.     CZMQ_EXPORT void *         zctx_underlying (zctx_t *self);      //  Self test of this class     CZMQ_EXPORT void         zctx_test (bool verbose); This is the class self test code:     //  Create and destroy a context without using it     zctx_t *ctx = zctx_new ();     assert (ctx);     zctx_destroy (&ctx);     assert (ctx == NULL);      //  Create a context with many busy sockets, destroy it     ctx = zctx_new ();     assert (ctx);     zctx_set_iothreads (ctx, 1);     zctx_set_linger (ctx, 5);       //  5 msecs     void *s1 = zctx__socket_new (ctx, ZMQ_PAIR);     assert (s1);     void *s2 = zctx__socket_new (ctx, ZMQ_XREQ);     assert (s2);     void *s3 = zctx__socket_new (ctx, ZMQ_REQ);     assert (s3);     void *s4 = zctx__socket_new (ctx, ZMQ_REP);     assert (s4);     void *s5 = zctx__socket_new (ctx, ZMQ_PUB);     assert (s5);     void *s6 = zctx__socket_new (ctx, ZMQ_SUB);     assert (s6);     int rc = zsocket_connect (s1, ""tcp://127.0.0.1:5555"");     assert (rc == 0);     rc = zsocket_connect (s2, ""tcp://127.0.0.1:5555"");     assert (rc == 0);     rc = zsocket_connect (s3, ""tcp://127.0.0.1:5555"");     assert (rc == 0);     rc = zsocket_connect (s4, ""tcp://127.0.0.1:5555"");     assert (rc == 0);     rc = zsocket_connect (s5, ""tcp://127.0.0.1:5555"");     assert (rc == 0);     rc = zsocket_connect (s6, ""tcp://127.0.0.1:5555"");     assert (rc == 0);     assert (zctx_underlying (ctx));     zctx_destroy (&ctx); zmonitor_v2 - socket event monitor (deprecated) The zmonitor class provides an API for obtaining socket events such as connected, listen, disconnected, etc. Socket events are only available for sockets connecting or bound to ipc:// and tcp:// endpoints. This class wraps the ZMQ socket monitor API, see zmq_socket_monitor for details. Currently this class requires libzmq v4.0 or later and is empty on older versions of libzmq. This class is deprecated in CZMQ v3; it works together with zctx, zsocket, and other deprecated V2 classes. New applications should use the V3 zmonitor interface, based on zactor, together with the zsock class for sockets. This is the class interface:     //  This code needs backporting to work with ZMQ v3.2     #if (ZMQ_VERSION_MAJOR == 4)      //  Create a new socket monitor     CZMQ_EXPORT zmonitor_t *         zmonitor_new (zctx_t *ctx, void *socket, int events);      //  Destroy a socket monitor     CZMQ_EXPORT void         zmonitor_destroy (zmonitor_t **self_p);      //  Receive a status message from the monitor; if no message arrives within     //  500 msec, or the call was interrupted, returns NULL.     CZMQ_EXPORT zmsg_t *         zmonitor_recv (zmonitor_t *self);      //  Get the ZeroMQ socket, for polling      CZMQ_EXPORT void *         zmonitor_socket (zmonitor_t *self);      //  Enable verbose tracing of commands and activity     CZMQ_EXPORT void         zmonitor_set_verbose (zmonitor_t *self, bool verbose);     #endif          //  ZeroMQ 4.0 or later      // Self test of this class     CZMQ_EXPORT void         zmonitor_v2_test (bool verbose); This is the class self test code:     zctx_t *ctx = zctx_new ();     assert (ctx);     bool result;      void *sink = zsocket_new (ctx, ZMQ_PULL);     assert (sink);     zmonitor_t *sinkmon = zmonitor_new (ctx,                                         sink, ZMQ_EVENT_LISTENING | ZMQ_EVENT_ACCEPTED);     assert (sinkmon);     zmonitor_set_verbose (sinkmon, verbose);      //  Check sink is now listening     int port_nbr = zsocket_bind (sink, ""tcp://127.0.0.1:*"");     assert (port_nbr != -1);     result = s_check_event (sinkmon, ZMQ_EVENT_LISTENING);     assert (result);      void *source = zsocket_new (ctx, ZMQ_PUSH);     assert (source);     zmonitor_t *sourcemon = zmonitor_new (ctx,                                           source, ZMQ_EVENT_CONNECTED | ZMQ_EVENT_DISCONNECTED);     assert (sourcemon);     zmonitor_set_verbose (sourcemon, verbose);     zsocket_connect (source, ""tcp://127.0.0.1:%d"", port_nbr);      //  Check source connected to sink     result = s_check_event (sourcemon, ZMQ_EVENT_CONNECTED);     assert (result);      //  Check sink accepted connection     result = s_check_event (sinkmon, ZMQ_EVENT_ACCEPTED);     assert (result);      zmonitor_destroy (&sinkmon);     zmonitor_destroy (&sourcemon);     zctx_destroy (&ctx); zmutex - working with mutexes (deprecated) The zmutex class provides a portable wrapper for mutexes. Please do not use this class to do multi-threading. It is for the rare case where you absolutely need thread-safe global state. This should happen in system code only. DO NOT USE THIS TO SHARE SOCKETS BETWEEN THREADS, OR DARK THINGS WILL HAPPEN TO YOUR CODE. Please add @discuss section in ../src/zmutex.c. This is the class interface:     //  This is a deprecated class, and will be removed over time. It is     //  provided in stable builds to support old applications. You should     //  stop using this class, and migrate any code that is still using it.      //  Create a new mutex container     CZMQ_EXPORT zmutex_t *         zmutex_new (void);      //  Destroy a mutex container     CZMQ_EXPORT void         zmutex_destroy (zmutex_t **self_p);      //  Lock mutex     CZMQ_EXPORT void         zmutex_lock (zmutex_t *self);      //  Unlock mutex     CZMQ_EXPORT void         zmutex_unlock (zmutex_t *self);      //  Try to lock mutex     CZMQ_EXPORT int         zmutex_try_lock (zmutex_t *self);      //  Self test of this class.     CZMQ_EXPORT void         zmutex_test (bool verbose); This is the class self test code:     zmutex_t *mutex = zmutex_new ();     assert (mutex);     zmutex_lock (mutex);     zmutex_unlock (mutex);     zmutex_destroy (&mutex); zproxy_v2 - run a steerable proxy in the background (deprecated) The zproxy class provides an equivalent to the ZMQ steerable proxy, on all versions of ZeroMQ. This class is deprecated in CZMQ v3; it works together with zctx, zsocket, and other deprecated V2 classes. New applications should use the V3 zproxy interface, based on zactor, together with the zsock class for sockets. This is the class interface:     //  Constructor     //  Create a new zproxy object. You must create the frontend and backend     //  sockets, configure them, and connect or bind them, before you pass them     //  to the constructor. Do NOT use the sockets again, after passing them to     //  this method.     CZMQ_EXPORT zproxy_t *         zproxy_new (zctx_t *ctx, void *frontend, void *backend);      //  Destructor     //  Destroy a zproxy object; note this first stops the proxy.     CZMQ_EXPORT void         zproxy_destroy (zproxy_t **self_p);      //  Copy all proxied messages to specified endpoint; if this is NULL, any     //  in-progress capturing will be stopped. You must already have bound the     //  endpoint to a PULL socket.     CZMQ_EXPORT void         zproxy_capture (zproxy_t *self, const char *endpoint);      //  Pauses a zproxy object; a paused proxy will cease processing messages,     //  causing them to be queued up and potentially hit the high-water mark on     //  the frontend socket, causing messages to be dropped, or writing     //  applications to block.     CZMQ_EXPORT void         zproxy_pause (zproxy_t *self);      //  Resume a zproxy object     CZMQ_EXPORT void         zproxy_resume (zproxy_t *self);      // Self test of this class     CZMQ_EXPORT void         zproxy_v2_test (bool verbose); This is the class self test code:     zctx_t *ctx = zctx_new ();     assert (ctx);     void *frontend = zsocket_new (ctx, ZMQ_PULL);     assert (frontend);     int rc = zsocket_bind (frontend, ""inproc://frontend"");     assert (rc == 0);     void *backend = zsocket_new (ctx, ZMQ_PUSH);     assert (backend);     rc = zsocket_bind (backend, ""inproc://backend"");     assert (rc == 0);     zproxy_t *proxy = zproxy_new (ctx, frontend, backend);     assert (proxy);      //  Connect application sockets to proxy     void *faucet = zsocket_new (ctx, ZMQ_PUSH);     assert (faucet);     rc = zsocket_connect (faucet, ""inproc://frontend"");     assert (rc == 0);     void *sink = zsocket_new (ctx, ZMQ_PULL);     assert (sink);     rc = zsocket_connect (sink, ""inproc://backend"");     assert (rc == 0);      //  Send some messages and check they arrived     zstr_send (faucet, ""Hello"");     char *string = zstr_recv (sink);     assert (streq (string, ""Hello""));     zstr_free (&string);      //  Check pause/resume functionality     zproxy_pause (proxy);     zstr_send (faucet, ""World"");      zproxy_resume (proxy);     string = zstr_recv (sink);     assert (streq (string, ""World""));     zstr_free (&string);      //  Create capture socket, must be a PULL socket     void *capture = zsocket_new (ctx, ZMQ_PULL);     assert (capture);     rc = zsocket_bind (capture, ""inproc://capture"");     assert (rc == 0);      //  Switch on capturing, check that it works     zproxy_capture (proxy, ""inproc://capture"");     zstr_send (faucet, ""Hello"");      string = zstr_recv (sink);     assert (streq (string, ""Hello""));     zstr_free (&string);      string = zstr_recv (capture);     assert (streq (string, ""Hello""));     zstr_free (&string);     zproxy_destroy (&proxy);     zctx_destroy (&ctx);  zsocket - working with ØMQ sockets (deprecated) The zsocket class provides helper functions for ØMQ sockets. It doesn't wrap the ØMQ socket type, to avoid breaking all libzmq socket-related calls. Please add @discuss section in ../src/zsocket.c. This is the class interface:     //  This port range is defined by IANA for dynamic or private ports     //  We use this when choosing a port for dynamic binding.     #define ZSOCKET_DYNFROM     0xc000     #define ZSOCKET_DYNTO       0xffff      //  Callback function for zero-copy methods     typedef void (zsocket_free_fn) (void *data, void *arg);      //  Create a new socket within our CZMQ context, replaces zmq_socket.     //  Use this to get automatic management of the socket at shutdown.     //  Note: SUB sockets do not automatically subscribe to everything; you     //  must set filters explicitly.     CZMQ_EXPORT void *         zsocket_new (zctx_t *self, int type);      //  Destroy a socket within our CZMQ context, replaces zmq_close.     CZMQ_EXPORT void         zsocket_destroy (zctx_t *ctx, void *self);      //  Bind a socket to a formatted endpoint. If the port is specified as     //  '*', binds to any free port from ZSOCKET_DYNFROM to ZSOCKET_DYNTO     //  and returns the actual port number used. Otherwise asserts that the     //  bind succeeded with the specified port number. Always returns the     //  port number if successful.     CZMQ_EXPORT int         zsocket_bind (void *self, const char *format, ...);      //  Unbind a socket from a formatted endpoint.     //  Returns 0 if OK, -1 if the endpoint was invalid or the function     //  isn't supported.     CZMQ_EXPORT int         zsocket_unbind (void *self, const char *format, ...);      //  Connect a socket to a formatted endpoint     //  Returns 0 if OK, -1 if the endpoint was invalid.     CZMQ_EXPORT int         zsocket_connect (void *self, const char *format, ...);      //  Disconnect a socket from a formatted endpoint     //  Returns 0 if OK, -1 if the endpoint was invalid or the function     //  isn't supported.     CZMQ_EXPORT int         zsocket_disconnect (void *self, const char *format, ...);      //  Poll for input events on the socket. Returns TRUE if there is input     //  ready on the socket, else FALSE.     CZMQ_EXPORT bool         zsocket_poll (void *self, int msecs);      //  Returns socket type as printable constant string     CZMQ_EXPORT const char *         zsocket_type_str (void *self);      //  Send data over a socket as a single message frame.     //  Accepts these flags: ZFRAME_MORE and ZFRAME_DONTWAIT.     //  Returns -1 on error, 0 on success     CZMQ_EXPORT int         zsocket_sendmem (void *self, const void *data, size_t size, int flags);      //  Send a signal over a socket. A signal is a zero-byte message.     //  Signals are used primarily between threads, over pipe sockets.     //  Returns -1 if there was an error sending the signal.     CZMQ_EXPORT int         zsocket_signal (void *self);      //  Wait on a signal. Use this to coordinate between threads, over     //  pipe pairs. Returns -1 on error, 0 on success.     CZMQ_EXPORT int         zsocket_wait (void *self);      //  Self test of this class     CZMQ_EXPORT void         zsocket_test (bool verbose); This is the class self test code:     zctx_t *ctx = zctx_new ();     assert (ctx);      //  Create a detached thread, let it run     char *interf = ""127.0.0.1"";     char *domain = ""localhost"";     int service = 5560;      void *writer = zsocket_new (ctx, ZMQ_PUSH);     assert (writer);     void *reader = zsocket_new (ctx, ZMQ_PULL);     assert (reader);     assert (streq (zsocket_type_str (writer), ""PUSH""));     assert (streq (zsocket_type_str (reader), ""PULL""));     int rc = zsocket_bind (writer, ""tcp://%s:%d"", interf, service);     assert (rc == service);      #if (ZMQ_VERSION >= ZMQ_MAKE_VERSION (3, 2, 0))     //  Check unbind     rc = zsocket_unbind (writer, ""tcp://%s:%d"", interf, service);     assert (rc == 0);      //  In some cases and especially when running under Valgrind, doing     //  a bind immediately after an unbind causes an EADDRINUSE error.     //  Even a short sleep allows the OS to release the port for reuse.     zclock_sleep (100);      //  Bind again     rc = zsocket_bind (writer, ""tcp://%s:%d"", interf, service);     assert (rc == service);     #endif      rc = zsocket_connect (reader, ""tcp://%s:%d"", domain, service);     assert (rc == 0);     zstr_send (writer, ""HELLO"");     char *message = zstr_recv (reader);     assert (message);     assert (streq (message, ""HELLO""));     free (message);      //  Test binding to ports     int port = zsocket_bind (writer, ""tcp://%s:*"", interf);     assert (port >= ZSOCKET_DYNFROM && port <= ZSOCKET_DYNTO);      assert (zsocket_poll (writer, 100) == false);      //  Test error state when connecting to an invalid socket type     //  ('txp://' instead of 'tcp://', typo intentional)     rc = zsocket_connect (reader, ""txp://%s:%d"", domain, service);     assert (rc == -1);      //  Test sending frames to socket     rc = zsocket_sendmem (writer, ""ABC"", 3, ZFRAME_MORE);     assert (rc == 0);     rc = zsocket_sendmem (writer, ""DEFG"", 4, 0);     assert (rc == 0);      zframe_t *frame = zframe_recv (reader);     assert (frame);     assert (zframe_streq (frame, ""ABC""));     assert (zframe_more (frame));     zframe_destroy (&frame);      frame = zframe_recv (reader);     assert (frame);     assert (zframe_streq (frame, ""DEFG""));     assert (!zframe_more (frame));     zframe_destroy (&frame);      rc = zsocket_signal (writer);     assert (rc == 0);     rc = zsocket_wait (reader);     assert (rc == 0);      zsocket_destroy (ctx, reader);     zsocket_destroy (ctx, writer);     zctx_destroy (&ctx); zsockopt - get/set ØMQ socket options (deprecated) The zsockopt class provides access to the ØMQ getsockopt/setsockopt API. This class is generated, using the GSL code generator. See the sockopts XML file, which provides the metadata, and the zsockopt.gsl template, which does the work. This is the class interface:     #if (ZMQ_VERSION_MAJOR == 4)     //  Get socket options     CZMQ_EXPORT int zsocket_heartbeat_ivl (void *zocket);     CZMQ_EXPORT int zsocket_heartbeat_ttl (void *zocket);     CZMQ_EXPORT int zsocket_heartbeat_timeout (void *zocket);     CZMQ_EXPORT int zsocket_use_fd (void *zocket);     CZMQ_EXPORT int zsocket_tos (void *zocket);     CZMQ_EXPORT char * zsocket_zap_domain (void *zocket);     CZMQ_EXPORT int zsocket_mechanism (void *zocket);     CZMQ_EXPORT int zsocket_plain_server (void *zocket);     CZMQ_EXPORT char * zsocket_plain_username (void *zocket);     CZMQ_EXPORT char * zsocket_plain_password (void *zocket);     CZMQ_EXPORT int zsocket_curve_server (void *zocket);     CZMQ_EXPORT char * zsocket_curve_publickey (void *zocket);     CZMQ_EXPORT char * zsocket_curve_secretkey (void *zocket);     CZMQ_EXPORT char * zsocket_curve_serverkey (void *zocket);     CZMQ_EXPORT int zsocket_gssapi_server (void *zocket);     CZMQ_EXPORT int zsocket_gssapi_plaintext (void *zocket);     CZMQ_EXPORT char * zsocket_gssapi_principal (void *zocket);     CZMQ_EXPORT char * zsocket_gssapi_service_principal (void *zocket);     CZMQ_EXPORT int zsocket_ipv6 (void *zocket);     CZMQ_EXPORT int zsocket_immediate (void *zocket);     CZMQ_EXPORT int zsocket_ipv4only (void *zocket);     CZMQ_EXPORT int zsocket_type (void *zocket);     CZMQ_EXPORT int zsocket_sndhwm (void *zocket);     CZMQ_EXPORT int zsocket_rcvhwm (void *zocket);     CZMQ_EXPORT int zsocket_affinity (void *zocket);     CZMQ_EXPORT char * zsocket_identity (void *zocket);     CZMQ_EXPORT int zsocket_rate (void *zocket);     CZMQ_EXPORT int zsocket_recovery_ivl (void *zocket);     CZMQ_EXPORT int zsocket_sndbuf (void *zocket);     CZMQ_EXPORT int zsocket_rcvbuf (void *zocket);     CZMQ_EXPORT int zsocket_linger (void *zocket);     CZMQ_EXPORT int zsocket_reconnect_ivl (void *zocket);     CZMQ_EXPORT int zsocket_reconnect_ivl_max (void *zocket);     CZMQ_EXPORT int zsocket_backlog (void *zocket);     CZMQ_EXPORT int zsocket_maxmsgsize (void *zocket);     CZMQ_EXPORT int zsocket_multicast_hops (void *zocket);     CZMQ_EXPORT int zsocket_rcvtimeo (void *zocket);     CZMQ_EXPORT int zsocket_sndtimeo (void *zocket);     CZMQ_EXPORT int zsocket_tcp_keepalive (void *zocket);     CZMQ_EXPORT int zsocket_tcp_keepalive_idle (void *zocket);     CZMQ_EXPORT int zsocket_tcp_keepalive_cnt (void *zocket);     CZMQ_EXPORT int zsocket_tcp_keepalive_intvl (void *zocket);     CZMQ_EXPORT char * zsocket_tcp_accept_filter (void *zocket);     CZMQ_EXPORT int zsocket_rcvmore (void *zocket);     CZMQ_EXPORT SOCKET zsocket_fd (void *zocket);     CZMQ_EXPORT int zsocket_events (void *zocket);     CZMQ_EXPORT char * zsocket_last_endpoint (void *zocket);      //  Set socket options     CZMQ_EXPORT void zsocket_set_heartbeat_ivl (void *zocket, int heartbeat_ivl);     CZMQ_EXPORT void zsocket_set_heartbeat_ttl (void *zocket, int heartbeat_ttl);     CZMQ_EXPORT void zsocket_set_heartbeat_timeout (void *zocket, int heartbeat_timeout);     CZMQ_EXPORT void zsocket_set_use_fd (void *zocket, int use_fd);     CZMQ_EXPORT void zsocket_set_tos (void *zocket, int tos);     CZMQ_EXPORT void zsocket_set_router_handover (void *zocket, int router_handover);     CZMQ_EXPORT void zsocket_set_router_mandatory (void *zocket, int router_mandatory);     CZMQ_EXPORT void zsocket_set_probe_router (void *zocket, int probe_router);     CZMQ_EXPORT void zsocket_set_req_relaxed (void *zocket, int req_relaxed);     CZMQ_EXPORT void zsocket_set_req_correlate (void *zocket, int req_correlate);     CZMQ_EXPORT void zsocket_set_conflate (void *zocket, int conflate);     CZMQ_EXPORT void zsocket_set_zap_domain (void *zocket, const char * zap_domain);     CZMQ_EXPORT void zsocket_set_plain_server (void *zocket, int plain_server);     CZMQ_EXPORT void zsocket_set_plain_username (void *zocket, const char * plain_username);     CZMQ_EXPORT void zsocket_set_plain_password (void *zocket, const char * plain_password);     CZMQ_EXPORT void zsocket_set_curve_server (void *zocket, int curve_server);     CZMQ_EXPORT void zsocket_set_curve_publickey (void *zocket, const char * curve_publickey);     CZMQ_EXPORT void zsocket_set_curve_publickey_bin (void *zocket, const byte *curve_publickey);     CZMQ_EXPORT void zsocket_set_curve_secretkey (void *zocket, const char * curve_secretkey);     CZMQ_EXPORT void zsocket_set_curve_secretkey_bin (void *zocket, const byte *curve_secretkey);     CZMQ_EXPORT void zsocket_set_curve_serverkey (void *zocket, const char * curve_serverkey);     CZMQ_EXPORT void zsocket_set_curve_serverkey_bin (void *zocket, const byte *curve_serverkey);     CZMQ_EXPORT void zsocket_set_gssapi_server (void *zocket, int gssapi_server);     CZMQ_EXPORT void zsocket_set_gssapi_plaintext (void *zocket, int gssapi_plaintext);     CZMQ_EXPORT void zsocket_set_gssapi_principal (void *zocket, const char * gssapi_principal);     CZMQ_EXPORT void zsocket_set_gssapi_service_principal (void *zocket, const char * gssapi_service_principal);     CZMQ_EXPORT void zsocket_set_ipv6 (void *zocket, int ipv6);     CZMQ_EXPORT void zsocket_set_immediate (void *zocket, int immediate);     CZMQ_EXPORT void zsocket_set_router_raw (void *zocket, int router_raw);     CZMQ_EXPORT void zsocket_set_ipv4only (void *zocket, int ipv4only);     CZMQ_EXPORT void zsocket_set_delay_attach_on_connect (void *zocket, int delay_attach_on_connect);     CZMQ_EXPORT void zsocket_set_sndhwm (void *zocket, int sndhwm);     CZMQ_EXPORT void zsocket_set_rcvhwm (void *zocket, int rcvhwm);     CZMQ_EXPORT void zsocket_set_affinity (void *zocket, int affinity);     CZMQ_EXPORT void zsocket_set_subscribe (void *zocket, const char * subscribe);     CZMQ_EXPORT void zsocket_set_unsubscribe (void *zocket, const char * unsubscribe);     CZMQ_EXPORT void zsocket_set_identity (void *zocket, const char * identity);     CZMQ_EXPORT void zsocket_set_rate (void *zocket, int rate);     CZMQ_EXPORT void zsocket_set_recovery_ivl (void *zocket, int recovery_ivl);     CZMQ_EXPORT void zsocket_set_sndbuf (void *zocket, int sndbuf);     CZMQ_EXPORT void zsocket_set_rcvbuf (void *zocket, int rcvbuf);     CZMQ_EXPORT void zsocket_set_linger (void *zocket, int linger);     CZMQ_EXPORT void zsocket_set_reconnect_ivl (void *zocket, int reconnect_ivl);     CZMQ_EXPORT void zsocket_set_reconnect_ivl_max (void *zocket, int reconnect_ivl_max);     CZMQ_EXPORT void zsocket_set_backlog (void *zocket, int backlog);     CZMQ_EXPORT void zsocket_set_maxmsgsize (void *zocket, int maxmsgsize);     CZMQ_EXPORT void zsocket_set_multicast_hops (void *zocket, int multicast_hops);     CZMQ_EXPORT void zsocket_set_rcvtimeo (void *zocket, int rcvtimeo);     CZMQ_EXPORT void zsocket_set_sndtimeo (void *zocket, int sndtimeo);     CZMQ_EXPORT void zsocket_set_xpub_verbose (void *zocket, int xpub_verbose);     CZMQ_EXPORT void zsocket_set_tcp_keepalive (void *zocket, int tcp_keepalive);     CZMQ_EXPORT void zsocket_set_tcp_keepalive_idle (void *zocket, int tcp_keepalive_idle);     CZMQ_EXPORT void zsocket_set_tcp_keepalive_cnt (void *zocket, int tcp_keepalive_cnt);     CZMQ_EXPORT void zsocket_set_tcp_keepalive_intvl (void *zocket, int tcp_keepalive_intvl);     CZMQ_EXPORT void zsocket_set_tcp_accept_filter (void *zocket, const char * tcp_accept_filter);     #endif      #if (ZMQ_VERSION_MAJOR == 3)     //  Get socket options     CZMQ_EXPORT int zsocket_ipv4only (void *zocket);     CZMQ_EXPORT int zsocket_type (void *zocket);     CZMQ_EXPORT int zsocket_sndhwm (void *zocket);     CZMQ_EXPORT int zsocket_rcvhwm (void *zocket);     CZMQ_EXPORT int zsocket_affinity (void *zocket);     CZMQ_EXPORT char * zsocket_identity (void *zocket);     CZMQ_EXPORT int zsocket_rate (void *zocket);     CZMQ_EXPORT int zsocket_recovery_ivl (void *zocket);     CZMQ_EXPORT int zsocket_sndbuf (void *zocket);     CZMQ_EXPORT int zsocket_rcvbuf (void *zocket);     CZMQ_EXPORT int zsocket_linger (void *zocket);     CZMQ_EXPORT int zsocket_reconnect_ivl (void *zocket);     CZMQ_EXPORT int zsocket_reconnect_ivl_max (void *zocket);     CZMQ_EXPORT int zsocket_backlog (void *zocket);     CZMQ_EXPORT int zsocket_maxmsgsize (void *zocket);     CZMQ_EXPORT int zsocket_multicast_hops (void *zocket);     CZMQ_EXPORT int zsocket_rcvtimeo (void *zocket);     CZMQ_EXPORT int zsocket_sndtimeo (void *zocket);     CZMQ_EXPORT int zsocket_tcp_keepalive (void *zocket);     CZMQ_EXPORT int zsocket_tcp_keepalive_idle (void *zocket);     CZMQ_EXPORT int zsocket_tcp_keepalive_cnt (void *zocket);     CZMQ_EXPORT int zsocket_tcp_keepalive_intvl (void *zocket);     CZMQ_EXPORT char * zsocket_tcp_accept_filter (void *zocket);     CZMQ_EXPORT int zsocket_rcvmore (void *zocket);     CZMQ_EXPORT SOCKET zsocket_fd (void *zocket);     CZMQ_EXPORT int zsocket_events (void *zocket);     CZMQ_EXPORT char * zsocket_last_endpoint (void *zocket);      //  Set socket options     CZMQ_EXPORT void zsocket_set_router_raw (void *zocket, int router_raw);     CZMQ_EXPORT void zsocket_set_ipv4only (void *zocket, int ipv4only);     CZMQ_EXPORT void zsocket_set_delay_attach_on_connect (void *zocket, int delay_attach_on_connect);     CZMQ_EXPORT void zsocket_set_sndhwm (void *zocket, int sndhwm);     CZMQ_EXPORT void zsocket_set_rcvhwm (void *zocket, int rcvhwm);     CZMQ_EXPORT void zsocket_set_affinity (void *zocket, int affinity);     CZMQ_EXPORT void zsocket_set_subscribe (void *zocket, const char * subscribe);     CZMQ_EXPORT void zsocket_set_unsubscribe (void *zocket, const char * unsubscribe);     CZMQ_EXPORT void zsocket_set_identity (void *zocket, const char * identity);     CZMQ_EXPORT void zsocket_set_rate (void *zocket, int rate);     CZMQ_EXPORT void zsocket_set_recovery_ivl (void *zocket, int recovery_ivl);     CZMQ_EXPORT void zsocket_set_sndbuf (void *zocket, int sndbuf);     CZMQ_EXPORT void zsocket_set_rcvbuf (void *zocket, int rcvbuf);     CZMQ_EXPORT void zsocket_set_linger (void *zocket, int linger);     CZMQ_EXPORT void zsocket_set_reconnect_ivl (void *zocket, int reconnect_ivl);     CZMQ_EXPORT void zsocket_set_reconnect_ivl_max (void *zocket, int reconnect_ivl_max);     CZMQ_EXPORT void zsocket_set_backlog (void *zocket, int backlog);     CZMQ_EXPORT void zsocket_set_maxmsgsize (void *zocket, int maxmsgsize);     CZMQ_EXPORT void zsocket_set_multicast_hops (void *zocket, int multicast_hops);     CZMQ_EXPORT void zsocket_set_rcvtimeo (void *zocket, int rcvtimeo);     CZMQ_EXPORT void zsocket_set_sndtimeo (void *zocket, int sndtimeo);     CZMQ_EXPORT void zsocket_set_xpub_verbose (void *zocket, int xpub_verbose);     CZMQ_EXPORT void zsocket_set_tcp_keepalive (void *zocket, int tcp_keepalive);     CZMQ_EXPORT void zsocket_set_tcp_keepalive_idle (void *zocket, int tcp_keepalive_idle);     CZMQ_EXPORT void zsocket_set_tcp_keepalive_cnt (void *zocket, int tcp_keepalive_cnt);     CZMQ_EXPORT void zsocket_set_tcp_keepalive_intvl (void *zocket, int tcp_keepalive_intvl);     CZMQ_EXPORT void zsocket_set_tcp_accept_filter (void *zocket, const char * tcp_accept_filter);     #endif      #if (ZMQ_VERSION_MAJOR == 2)     //  Get socket options     CZMQ_EXPORT int zsocket_hwm (void *zocket);     CZMQ_EXPORT int zsocket_swap (void *zocket);     CZMQ_EXPORT int zsocket_affinity (void *zocket);     CZMQ_EXPORT char * zsocket_identity (void *zocket);     CZMQ_EXPORT int zsocket_rate (void *zocket);     CZMQ_EXPORT int zsocket_recovery_ivl (void *zocket);     CZMQ_EXPORT int zsocket_recovery_ivl_msec (void *zocket);     CZMQ_EXPORT int zsocket_mcast_loop (void *zocket);     #   if (ZMQ_VERSION_MINOR == 2)     CZMQ_EXPORT int zsocket_rcvtimeo (void *zocket);     #   endif     #   if (ZMQ_VERSION_MINOR == 2)     CZMQ_EXPORT int zsocket_sndtimeo (void *zocket);     #   endif     CZMQ_EXPORT int zsocket_sndbuf (void *zocket);     CZMQ_EXPORT int zsocket_rcvbuf (void *zocket);     CZMQ_EXPORT int zsocket_linger (void *zocket);     CZMQ_EXPORT int zsocket_reconnect_ivl (void *zocket);     CZMQ_EXPORT int zsocket_reconnect_ivl_max (void *zocket);     CZMQ_EXPORT int zsocket_backlog (void *zocket);     CZMQ_EXPORT int zsocket_type (void *zocket);     CZMQ_EXPORT int zsocket_rcvmore (void *zocket);     CZMQ_EXPORT SOCKET zsocket_fd (void *zocket);     CZMQ_EXPORT int zsocket_events (void *zocket);      //  Set socket options     CZMQ_EXPORT void zsocket_set_hwm (void *zocket, int hwm);     CZMQ_EXPORT void zsocket_set_swap (void *zocket, int swap);     CZMQ_EXPORT void zsocket_set_affinity (void *zocket, int affinity);     CZMQ_EXPORT void zsocket_set_identity (void *zocket, const char * identity);     CZMQ_EXPORT void zsocket_set_rate (void *zocket, int rate);     CZMQ_EXPORT void zsocket_set_recovery_ivl (void *zocket, int recovery_ivl);     CZMQ_EXPORT void zsocket_set_recovery_ivl_msec (void *zocket, int recovery_ivl_msec);     CZMQ_EXPORT void zsocket_set_mcast_loop (void *zocket, int mcast_loop);     #   if (ZMQ_VERSION_MINOR == 2)     CZMQ_EXPORT void zsocket_set_rcvtimeo (void *zocket, int rcvtimeo);     #   endif     #   if (ZMQ_VERSION_MINOR == 2)     CZMQ_EXPORT void zsocket_set_sndtimeo (void *zocket, int sndtimeo);     #   endif     CZMQ_EXPORT void zsocket_set_sndbuf (void *zocket, int sndbuf);     CZMQ_EXPORT void zsocket_set_rcvbuf (void *zocket, int rcvbuf);     CZMQ_EXPORT void zsocket_set_linger (void *zocket, int linger);     CZMQ_EXPORT void zsocket_set_reconnect_ivl (void *zocket, int reconnect_ivl);     CZMQ_EXPORT void zsocket_set_reconnect_ivl_max (void *zocket, int reconnect_ivl_max);     CZMQ_EXPORT void zsocket_set_backlog (void *zocket, int backlog);     CZMQ_EXPORT void zsocket_set_subscribe (void *zocket, const char * subscribe);     CZMQ_EXPORT void zsocket_set_unsubscribe (void *zocket, const char * unsubscribe);     #endif      //  Self test of this class     CZMQ_EXPORT void zsockopt_test (bool verbose); This is the class self test code:     zctx_t *ctx = zctx_new ();     assert (ctx);     void *zocket;     #if (ZMQ_VERSION_MAJOR == 4)     #     if defined (ZMQ_HEARTBEAT_IVL)     zocket = zsocket_new (ctx, ZMQ_DEALER);     assert (zocket);     zsocket_set_heartbeat_ivl (zocket, 2000);     assert (zsocket_heartbeat_ivl (zocket) == 2000);     zsocket_heartbeat_ivl (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_HEARTBEAT_TTL)     zocket = zsocket_new (ctx, ZMQ_DEALER);     assert (zocket);     zsocket_set_heartbeat_ttl (zocket, 4000);     assert (zsocket_heartbeat_ttl (zocket) == 4000);     zsocket_heartbeat_ttl (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_HEARTBEAT_TIMEOUT)     zocket = zsocket_new (ctx, ZMQ_DEALER);     assert (zocket);     zsocket_set_heartbeat_timeout (zocket, 6000);     assert (zsocket_heartbeat_timeout (zocket) == 6000);     zsocket_heartbeat_timeout (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_USE_FD)     zocket = zsocket_new (ctx, ZMQ_REQ);     assert (zocket);     zsocket_set_use_fd (zocket, 3);     assert (zsocket_use_fd (zocket) == 3);     zsocket_use_fd (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_TOS)     zocket = zsocket_new (ctx, ZMQ_DEALER);     assert (zocket);     zsocket_set_tos (zocket, 1);     assert (zsocket_tos (zocket) == 1);     zsocket_tos (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_ROUTER_HANDOVER)     zocket = zsocket_new (ctx, ZMQ_ROUTER);     assert (zocket);     zsocket_set_router_handover (zocket, 1);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_ROUTER_MANDATORY)     zocket = zsocket_new (ctx, ZMQ_ROUTER);     assert (zocket);     zsocket_set_router_mandatory (zocket, 1);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_PROBE_ROUTER)     zocket = zsocket_new (ctx, ZMQ_DEALER);     assert (zocket);     zsocket_set_probe_router (zocket, 1);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_REQ_RELAXED)     zocket = zsocket_new (ctx, ZMQ_REQ);     assert (zocket);     zsocket_set_req_relaxed (zocket, 1);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_REQ_CORRELATE)     zocket = zsocket_new (ctx, ZMQ_REQ);     assert (zocket);     zsocket_set_req_correlate (zocket, 1);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_CONFLATE)     zocket = zsocket_new (ctx, ZMQ_PUSH);     assert (zocket);     zsocket_set_conflate (zocket, 1);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_ZAP_DOMAIN)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_zap_domain (zocket, ""test"");     char *zap_domain = zsocket_zap_domain (zocket);     assert (zap_domain);     free (zap_domain);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_MECHANISM)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_mechanism (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_PLAIN_SERVER)     zocket = zsocket_new (ctx, ZMQ_PUB);     assert (zocket);     zsocket_set_plain_server (zocket, 1);     assert (zsocket_plain_server (zocket) == 1);     zsocket_plain_server (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_PLAIN_USERNAME)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_plain_username (zocket, ""test"");     char *plain_username = zsocket_plain_username (zocket);     assert (plain_username);     free (plain_username);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_PLAIN_PASSWORD)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_plain_password (zocket, ""test"");     char *plain_password = zsocket_plain_password (zocket);     assert (plain_password);     free (plain_password);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_IPV6)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_ipv6 (zocket, 1);     assert (zsocket_ipv6 (zocket) == 1);     zsocket_ipv6 (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_IMMEDIATE)     zocket = zsocket_new (ctx, ZMQ_DEALER);     assert (zocket);     zsocket_set_immediate (zocket, 1);     assert (zsocket_immediate (zocket) == 1);     zsocket_immediate (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_ROUTER_RAW)     zocket = zsocket_new (ctx, ZMQ_ROUTER);     assert (zocket);     zsocket_set_router_raw (zocket, 1);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_IPV4ONLY)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_ipv4only (zocket, 1);     assert (zsocket_ipv4only (zocket) == 1);     zsocket_ipv4only (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_DELAY_ATTACH_ON_CONNECT)     zocket = zsocket_new (ctx, ZMQ_PUB);     assert (zocket);     zsocket_set_delay_attach_on_connect (zocket, 1);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_TYPE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_type (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_SNDHWM)     zocket = zsocket_new (ctx, ZMQ_PUB);     assert (zocket);     zsocket_set_sndhwm (zocket, 1);     assert (zsocket_sndhwm (zocket) == 1);     zsocket_sndhwm (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RCVHWM)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_rcvhwm (zocket, 1);     assert (zsocket_rcvhwm (zocket) == 1);     zsocket_rcvhwm (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_AFFINITY)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_affinity (zocket, 1);     assert (zsocket_affinity (zocket) == 1);     zsocket_affinity (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_SUBSCRIBE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_subscribe (zocket, ""test"");     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_UNSUBSCRIBE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_unsubscribe (zocket, ""test"");     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_IDENTITY)     zocket = zsocket_new (ctx, ZMQ_DEALER);     assert (zocket);     zsocket_set_identity (zocket, ""test"");     char *identity = zsocket_identity (zocket);     assert (identity);     free (identity);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RATE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_rate (zocket, 1);     assert (zsocket_rate (zocket) == 1);     zsocket_rate (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RECOVERY_IVL)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_recovery_ivl (zocket, 1);     assert (zsocket_recovery_ivl (zocket) == 1);     zsocket_recovery_ivl (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_SNDBUF)     zocket = zsocket_new (ctx, ZMQ_PUB);     assert (zocket);     zsocket_set_sndbuf (zocket, 1);     assert (zsocket_sndbuf (zocket) == 1);     zsocket_sndbuf (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RCVBUF)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_rcvbuf (zocket, 1);     assert (zsocket_rcvbuf (zocket) == 1);     zsocket_rcvbuf (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_LINGER)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_linger (zocket, 1);     assert (zsocket_linger (zocket) == 1);     zsocket_linger (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RECONNECT_IVL)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_reconnect_ivl (zocket, 1);     assert (zsocket_reconnect_ivl (zocket) == 1);     zsocket_reconnect_ivl (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RECONNECT_IVL_MAX)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_reconnect_ivl_max (zocket, 1);     assert (zsocket_reconnect_ivl_max (zocket) == 1);     zsocket_reconnect_ivl_max (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_BACKLOG)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_backlog (zocket, 1);     assert (zsocket_backlog (zocket) == 1);     zsocket_backlog (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_MAXMSGSIZE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_maxmsgsize (zocket, 1);     assert (zsocket_maxmsgsize (zocket) == 1);     zsocket_maxmsgsize (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_MULTICAST_HOPS)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_multicast_hops (zocket, 1);     assert (zsocket_multicast_hops (zocket) == 1);     zsocket_multicast_hops (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RCVTIMEO)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_rcvtimeo (zocket, 1);     assert (zsocket_rcvtimeo (zocket) == 1);     zsocket_rcvtimeo (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_SNDTIMEO)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_sndtimeo (zocket, 1);     assert (zsocket_sndtimeo (zocket) == 1);     zsocket_sndtimeo (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_XPUB_VERBOSE)     zocket = zsocket_new (ctx, ZMQ_XPUB);     assert (zocket);     zsocket_set_xpub_verbose (zocket, 1);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_TCP_KEEPALIVE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_tcp_keepalive (zocket, 1);     assert (zsocket_tcp_keepalive (zocket) == 1);     zsocket_tcp_keepalive (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_TCP_KEEPALIVE_IDLE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_tcp_keepalive_idle (zocket, 1);     assert (zsocket_tcp_keepalive_idle (zocket) == 1);     zsocket_tcp_keepalive_idle (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_TCP_KEEPALIVE_CNT)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_tcp_keepalive_cnt (zocket, 1);     assert (zsocket_tcp_keepalive_cnt (zocket) == 1);     zsocket_tcp_keepalive_cnt (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_TCP_KEEPALIVE_INTVL)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_tcp_keepalive_intvl (zocket, 1);     assert (zsocket_tcp_keepalive_intvl (zocket) == 1);     zsocket_tcp_keepalive_intvl (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_TCP_ACCEPT_FILTER)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_tcp_accept_filter (zocket, ""127.0.0.1"");     char *tcp_accept_filter = zsocket_tcp_accept_filter (zocket);     assert (tcp_accept_filter);     free (tcp_accept_filter);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RCVMORE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_rcvmore (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_FD)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_fd (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_EVENTS)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_events (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_LAST_ENDPOINT)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     char *last_endpoint = zsocket_last_endpoint (zocket);     assert (last_endpoint);     free (last_endpoint);     zsocket_destroy (ctx, zocket);     #     endif     #endif      #if (ZMQ_VERSION_MAJOR == 3)     #     if defined (ZMQ_ROUTER_RAW)     zocket = zsocket_new (ctx, ZMQ_ROUTER);     assert (zocket);     zsocket_set_router_raw (zocket, 1);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_IPV4ONLY)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_ipv4only (zocket, 1);     assert (zsocket_ipv4only (zocket) == 1);     zsocket_ipv4only (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_DELAY_ATTACH_ON_CONNECT)     zocket = zsocket_new (ctx, ZMQ_PUB);     assert (zocket);     zsocket_set_delay_attach_on_connect (zocket, 1);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_TYPE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_type (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_SNDHWM)     zocket = zsocket_new (ctx, ZMQ_PUB);     assert (zocket);     zsocket_set_sndhwm (zocket, 1);     assert (zsocket_sndhwm (zocket) == 1);     zsocket_sndhwm (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RCVHWM)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_rcvhwm (zocket, 1);     assert (zsocket_rcvhwm (zocket) == 1);     zsocket_rcvhwm (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_AFFINITY)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_affinity (zocket, 1);     assert (zsocket_affinity (zocket) == 1);     zsocket_affinity (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_SUBSCRIBE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_subscribe (zocket, ""test"");     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_UNSUBSCRIBE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_unsubscribe (zocket, ""test"");     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_IDENTITY)     zocket = zsocket_new (ctx, ZMQ_DEALER);     assert (zocket);     zsocket_set_identity (zocket, ""test"");     char *identity = zsocket_identity (zocket);     assert (identity);     free (identity);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RATE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_rate (zocket, 1);     assert (zsocket_rate (zocket) == 1);     zsocket_rate (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RECOVERY_IVL)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_recovery_ivl (zocket, 1);     assert (zsocket_recovery_ivl (zocket) == 1);     zsocket_recovery_ivl (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_SNDBUF)     zocket = zsocket_new (ctx, ZMQ_PUB);     assert (zocket);     zsocket_set_sndbuf (zocket, 1);     assert (zsocket_sndbuf (zocket) == 1);     zsocket_sndbuf (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RCVBUF)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_rcvbuf (zocket, 1);     assert (zsocket_rcvbuf (zocket) == 1);     zsocket_rcvbuf (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_LINGER)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_linger (zocket, 1);     assert (zsocket_linger (zocket) == 1);     zsocket_linger (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RECONNECT_IVL)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_reconnect_ivl (zocket, 1);     assert (zsocket_reconnect_ivl (zocket) == 1);     zsocket_reconnect_ivl (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RECONNECT_IVL_MAX)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_reconnect_ivl_max (zocket, 1);     assert (zsocket_reconnect_ivl_max (zocket) == 1);     zsocket_reconnect_ivl_max (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_BACKLOG)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_backlog (zocket, 1);     assert (zsocket_backlog (zocket) == 1);     zsocket_backlog (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_MAXMSGSIZE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_maxmsgsize (zocket, 1);     assert (zsocket_maxmsgsize (zocket) == 1);     zsocket_maxmsgsize (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_MULTICAST_HOPS)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_multicast_hops (zocket, 1);     assert (zsocket_multicast_hops (zocket) == 1);     zsocket_multicast_hops (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RCVTIMEO)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_rcvtimeo (zocket, 1);     assert (zsocket_rcvtimeo (zocket) == 1);     zsocket_rcvtimeo (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_SNDTIMEO)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_sndtimeo (zocket, 1);     assert (zsocket_sndtimeo (zocket) == 1);     zsocket_sndtimeo (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_XPUB_VERBOSE)     zocket = zsocket_new (ctx, ZMQ_XPUB);     assert (zocket);     zsocket_set_xpub_verbose (zocket, 1);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_TCP_KEEPALIVE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_tcp_keepalive (zocket, 1);     assert (zsocket_tcp_keepalive (zocket) == 1);     zsocket_tcp_keepalive (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_TCP_KEEPALIVE_IDLE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_tcp_keepalive_idle (zocket, 1);     assert (zsocket_tcp_keepalive_idle (zocket) == 1);     zsocket_tcp_keepalive_idle (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_TCP_KEEPALIVE_CNT)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_tcp_keepalive_cnt (zocket, 1);     assert (zsocket_tcp_keepalive_cnt (zocket) == 1);     zsocket_tcp_keepalive_cnt (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_TCP_KEEPALIVE_INTVL)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_tcp_keepalive_intvl (zocket, 1);     assert (zsocket_tcp_keepalive_intvl (zocket) == 1);     zsocket_tcp_keepalive_intvl (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_TCP_ACCEPT_FILTER)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_tcp_accept_filter (zocket, ""127.0.0.1"");     char *tcp_accept_filter = zsocket_tcp_accept_filter (zocket);     assert (tcp_accept_filter);     free (tcp_accept_filter);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RCVMORE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_rcvmore (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_FD)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_fd (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_EVENTS)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_events (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_LAST_ENDPOINT)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     char *last_endpoint = zsocket_last_endpoint (zocket);     assert (last_endpoint);     free (last_endpoint);     zsocket_destroy (ctx, zocket);     #     endif     #endif      #if (ZMQ_VERSION_MAJOR == 2)     #     if defined (ZMQ_HWM)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_hwm (zocket, 1);     assert (zsocket_hwm (zocket) == 1);     zsocket_hwm (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_SWAP)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_swap (zocket, 1);     assert (zsocket_swap (zocket) == 1);     zsocket_swap (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_AFFINITY)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_affinity (zocket, 1);     assert (zsocket_affinity (zocket) == 1);     zsocket_affinity (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_IDENTITY)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_identity (zocket, ""test"");     char *identity = zsocket_identity (zocket);     assert (identity);     free (identity);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RATE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_rate (zocket, 1);     assert (zsocket_rate (zocket) == 1);     zsocket_rate (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RECOVERY_IVL)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_recovery_ivl (zocket, 1);     assert (zsocket_recovery_ivl (zocket) == 1);     zsocket_recovery_ivl (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RECOVERY_IVL_MSEC)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_recovery_ivl_msec (zocket, 1);     assert (zsocket_recovery_ivl_msec (zocket) == 1);     zsocket_recovery_ivl_msec (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_MCAST_LOOP)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_mcast_loop (zocket, 1);     assert (zsocket_mcast_loop (zocket) == 1);     zsocket_mcast_loop (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #   if (ZMQ_VERSION_MINOR == 2)     #     if defined (ZMQ_RCVTIMEO)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_rcvtimeo (zocket, 1);     assert (zsocket_rcvtimeo (zocket) == 1);     zsocket_rcvtimeo (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #   endif     #   if (ZMQ_VERSION_MINOR == 2)     #     if defined (ZMQ_SNDTIMEO)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_sndtimeo (zocket, 1);     assert (zsocket_sndtimeo (zocket) == 1);     zsocket_sndtimeo (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #   endif     #     if defined (ZMQ_SNDBUF)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_sndbuf (zocket, 1);     assert (zsocket_sndbuf (zocket) == 1);     zsocket_sndbuf (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RCVBUF)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_rcvbuf (zocket, 1);     assert (zsocket_rcvbuf (zocket) == 1);     zsocket_rcvbuf (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_LINGER)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_linger (zocket, 1);     assert (zsocket_linger (zocket) == 1);     zsocket_linger (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RECONNECT_IVL)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_reconnect_ivl (zocket, 1);     assert (zsocket_reconnect_ivl (zocket) == 1);     zsocket_reconnect_ivl (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RECONNECT_IVL_MAX)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_reconnect_ivl_max (zocket, 1);     assert (zsocket_reconnect_ivl_max (zocket) == 1);     zsocket_reconnect_ivl_max (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_BACKLOG)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_backlog (zocket, 1);     assert (zsocket_backlog (zocket) == 1);     zsocket_backlog (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_SUBSCRIBE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_subscribe (zocket, ""test"");     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_UNSUBSCRIBE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_set_unsubscribe (zocket, ""test"");     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_TYPE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_type (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_RCVMORE)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_rcvmore (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_FD)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_fd (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #     if defined (ZMQ_EVENTS)     zocket = zsocket_new (ctx, ZMQ_SUB);     assert (zocket);     zsocket_events (zocket);     zsocket_destroy (ctx, zocket);     #     endif     #endif      zctx_destroy (&ctx); zthread - working with system threads (deprecated) The zthread class wraps OS thread creation. It creates detached threads that look like normal OS threads, or attached threads that share the caller's ØMQ context, and get an inproc pipe to talk back to the parent thread. Detached threads create their own ØMQ contexts as needed. NOTE: this class is deprecated in favor of zactor. We have several use cases for multiple threads. One is to simulate many processes, so we can test ØMQ designs and flows more easily. Another is to create APIs that can send and receive ØMQ messages in the background. zthread solves these two use cases separately, using the zthread_new and zthead_fork methods respectively. These methods wrap the native system calls needed to start threads, so your code can remain fully portable. Detached threads follow the POSIX pthreads API; they accept a void * argument and return a void * result (always NULL in our case). Attached thread receive a void * argument, a zctx_t context, and a pipe socket. The pipe socket is a PAIR socket that is connected back to the caller. When you call zthread_fork, it returns you a PAIR socket that is the other end of this pipe. Thus attached threads can talk back to their parent threads over the pipe. We use this very heavily when making so-called ""asynchronous"" APIs, which you can see in the Guide examples like 'clone'. To recap some rules about threading: do not share sockets between threads or your code will crash. You can migrate a socket from one thread to a child thread, if you stop using it in the parent thread immediately after creating the child thread. If you want to connect sockets over inproc:// they must share the same ØMQ context, i.e. be attached threads. You should always use zthread_fork to create an attached thread; it is not sufficient to pass a zctx_t structure to a detached thread (this will crash). If you want to communicate over ipc:// or tcp:// you may be sharing the same context, or use separate contexts. Thus, every detached thread usually starts by creating its own zctx_t instance. This is the class interface:     //  Detached threads follow POSIX pthreads API     typedef void *(zthread_detached_fn) (void *args);      //  Attached threads get context and pipe from parent     typedef void (zthread_attached_fn) (void *args, zctx_t *ctx, void *pipe);      //  Create a detached thread. A detached thread operates autonomously     //  and is used to simulate a separate process. It gets no ctx, and no     //  pipe.     CZMQ_EXPORT int         zthread_new (zthread_detached_fn *thread_fn, void *args);      //  Create an attached thread. An attached thread gets a ctx and a PAIR     //  pipe back to its parent. It must monitor its pipe, and exit if the     //  pipe becomes unreadable. Do not destroy the ctx, the thread does this     //  automatically when it ends.     CZMQ_EXPORT void *         zthread_fork (zctx_t *ctx, zthread_attached_fn *thread_fn, void *args);      //  Self test of this class     CZMQ_EXPORT void         zthread_test (bool verbose); This is the class self test code:     static void *     s_test_detached (void *args)     {     //  Create a socket to check it'll be automatically deleted     zctx_t *ctx = zctx_new ();     assert (ctx);      void *push = zsocket_new (ctx, ZMQ_PUSH);     assert (push);     zctx_destroy (&ctx);     return NULL;     }      static void     s_test_attached (void *args, zctx_t *ctx, void *pipe)     {     //  Create a socket to check it'll be automatically deleted     zsocket_new (ctx, ZMQ_PUSH);     assert (ctx);     //  Wait for our parent to ping us, and pong back     char *ping = zstr_recv (pipe);     assert (ping);     zstr_free (&ping);     zstr_send (pipe, ""pong"");     }      zctx_t *ctx = zctx_new ();     assert (ctx);     int rc = 0;      //  Create a detached thread, let it run     rc = zthread_new (s_test_detached, NULL);     assert (rc == 0);     zclock_sleep (100);      //  Create an attached thread, check it's safely alive     void *pipe = zthread_fork (ctx, s_test_attached, NULL);     assert (pipe);     zstr_send (pipe, ""ping"");     char *pong = zstr_recv (pipe);     assert (pong);     assert (streq (pong, ""pong""));     zstr_free (&pong);      //  Everything should be cleanly closed now     zctx_destroy (&ctx); Error Handling The CZMQ policy is to reduce the error flow to 0/-1 where possible. libzmq still does a lot of errno setting. CZMQ does not do that, as it creates a fuzzy API. Things either work as expected, or they fail, and the application's best strategy is usually to assert on non-zero return codes. Some older libraries still return plethora of error codes, to indicate different types of failure. This ironically makes both library and application more likely to be buggy. The reason is simply that it needs more code on both sides of the API, and the more code, the more bugs. The use of black/white error handling fits the CLASS style for APIs where each call is explicit and without side effects of any kind, and where damage is either impossible, or fatal. The one exception is running out of resources (memory, sockets). In that case, there are two strategies that work, for different types of app. One is to assert, to force better sizing of the machine and/or limits such as max connections. Two is to degrade carefully, e.g. refuse new connections, however that is considerably harder to do correctly and probably unrealistic for most developers. Some CZMQ methods used to actually assert, e.g. in zsocket_bind, if the action failed, instead of returning -1. That was just closer to the majority case where the action MUST work, or nothing can continue. However there's a small slice of cases where failure means something positive, and for these cases, such calls return -1 on failure. 99% of calling code simply asserts the return value is not -1. There are a few cases where the return value is overloaded to return -1, 0, or other values. These are somewhat confusing special cases and we aim to eliminate them over time. The overall goal with this strategy is robustness, and absolute minimal and predictable expression in the code. You can see that it works: the CZMQ code is generally very simple and clear, with a few exceptions of places where people have used their old C style (we fix these over time). CZMQ Actors The v2 API had a zthread class that let you create ""attached threads"" connected to their parent by an inproc:// PIPE socket. In v3 this has been simplified and better wrapped as the zactor class. CZMQ actors are in effect threads with a socket interface. A zactor_t instance works like a socket, and the CZMQ classes that deal with sockets (like zmsg and zpoller) all accept zactor_t references as well as zsock_t and libzmq void * socket handles. To write an actor, use this template. Note that your actor is a single function ""void myname (zsock_t *pipe, void *args)"" function: /*  =========================================================================     someclass - some description      Copyright (c) the Contributors as noted in the AUTHORS file.     This file is part of CZMQ, the high-level C binding for ØMQ:     http://czmq.zeromq.org.      This Source Code Form is subject to the terms of the Mozilla Public     License, v. 2.0. If a copy of the MPL was not distributed with this     file, You can obtain one at http://mozilla.org/MPL/2.0/.     ========================================================================= */  /* @header     Please take e.g. include/zmonitor.h as basis for your public API.     And delete this text, and write your own, when you create an actor :-) @discuss  @end */  #include ""../include/czmq.h""  //  -------------------------------------------------------------------------- //  The self_t structure holds the state for one actor instance  typedef struct {     zsock_t *pipe;              //  Actor command pipe     zpoller_t *poller;          //  Socket poller     //  ... you'll be adding other stuff here     bool terminated;            //  Did caller ask us to quit?     bool verbose;               //  Verbose logging enabled? } self_t;  static self_t * s_self_new (zsock_t *pipe) {     self_t *self = (self_t *) zmalloc (sizeof (self_t));     self->pipe = pipe;     //  ... initialize your own state including any other     //  sockets, which you can add to the poller:     self->poller = zpoller_new (self->pipe, NULL);     return self; }  static void s_self_destroy (self_t **self_p) {     assert (self_p);     if (*self_p) {         self_t *self = *self_p;         zpoller_destroy (&self->poller);         //  ... destroy your own state here         free (self);         *self_p = NULL;     } }   //  -------------------------------------------------------------------------- //  Handle a command from calling application  static int s_self_handle_pipe (self_t *self) {     //  Get the whole message off the pipe in one go     zmsg_t *request = zmsg_recv (self->pipe);     if (!request)         return -1;                  //  Interrupted      char *command = zmsg_popstr (request);     if (self->verbose)         zsys_info (""zxxx: API command=%s"", command);     if (streq (command, ""VERBOSE""))         self->verbose = true;     else     //  An example of a command that the caller would wait for     //  via a signal, so that the two threads synchronize     if (streq (command, ""WAIT""))         zsock_signal (self->pipe, 0);     else     if (streq (command, ""$TERM""))         self->terminated = true;     else {         zsys_error (""zxxx: - invalid command: %s"", command);         assert (false);     }     zstr_free (&command);     zmsg_destroy (&request);     return 0; }   //  -------------------------------------------------------------------------- //  zxxx() implements the zxxx actor interface  void zxxx (zsock_t *pipe, void *args) {     self_t *self = s_self_new (pipe);     //  Signal successful initialization     zsock_signal (pipe, 0);      while (!self->terminated) {         zsock_t *which = (zsock_t *) zpoller_wait (self->poller, -1);         if (which == self->pipe)             s_self_handle_pipe (self);         else         if (zpoller_terminated (self->poller))             break;          //  Interrupted     }     s_self_destroy (&self); }   //  -------------------------------------------------------------------------- //  Selftest  void zxxx_test (bool verbose) {     printf ("" * zxxx: "");     if (verbose)         printf (""\n"");      //  @selftest     zactor_t *xxx = zactor_new (zxxx, NULL);     assert (xxx);     if (verbose)         zstr_sendx (xxx, ""VERBOSE"", NULL);      zactor_destroy (&xxx);     //  @end     printf (""OK\n""); }  The selftest code shows how to create, talk to, and destroy an actor. Under the Hood Adding a New Class If you define a new CZMQ class myclass you need to: Write the zmyclass.c and zmyclass.h source files, in src and include respectively. Add#include <zmyclass.h> to include/czmq.h. Add the myclass header and test call to src/czmq_selftest.c. Add a reference documentation to 'doc/zmyclass.txt'. Add myclass to 'model/projects.xml` and read model/README.txt. Add a section to README.txt. Documentation Man pages are generated from the class header and source files via the doc/mkman tool, and similar functionality in the gitdown tool (http://github.com/imatix/gitdown). The header file for a class must wrap its interface as follows (example is from include/zclock.h): //  @interface //  Sleep for a number of milliseconds void     zclock_sleep (int msecs);  //  Return current system clock as milliseconds int64_t     zclock_time (void);  //  Self test of this class int     zclock_test (Bool verbose); //  @end  The source file for a class must provide documentation as follows: /* @header ...short explanation of class... @discuss ...longer discussion of how it works... @end */  The source file for a class then provides the self test example as follows: //  @selftest int64_t start = zclock_time (); zclock_sleep (10); assert ((zclock_time () - start) >= 10); //  @end  The template for man pages is in doc/mkman. Development CZMQ is developed through a test-driven process that guarantees no memory violations or leaks in the code: Modify a class or method. Update the test method for that class. Run the 'selftest' script, which uses the Valgrind memcheck tool. Repeat until perfect. Porting CZMQ When you try CZMQ on an OS that it's not been used on (ever, or for a while), you will hit code that does not compile. In some cases the patches are trivial, in other cases (usually when porting to Windows), the work needed to build equivalent functionality may be non-trivial. In any case, the benefit is that once ported, the functionality is available to all applications. Before attempting to patch code for portability, please read the czmq_prelude.h header file. There are several typical types of changes you may need to make to get functionality working on a specific operating system: Defining typedefs which are missing on that specific compiler: do this in czmq_prelude.h. Defining macros that rename exotic library functions to more conventional names: do this in czmq_prelude.h. Reimplementing specific methods to use a non-standard API: this is typically needed on Windows. Do this in the relevant class, using #ifdefs to properly differentiate code for different platforms. Hints to Contributors CZMQ is a nice, neat library, and you may not immediately appreciate why. Read the CLASS style guide please, and write your code to make it indistinguishable from the rest of the code in the library. That is the only real criteria for good style: it's invisible. Don't include system headers in source files. The right place for these is czmq_prelude.h. If you need to check against configured libraries and/or headers, include platform.h in the source before including czmq.h. Do read your code after you write it and ask, ""Can I make this simpler?"" We do use a nice minimalist and yet readable style. Learn it, adopt it, use it. Before opening a pull request read our contribution guidelines. Thanks! Code Generation We generate the zsockopt class using GSL, using a code generator script in scripts/sockopts.gsl. We also generate the project files. This Document This document is originally at README.txt and is built using gitdown. This documentation was generated from czmq/README.txt using Gitdown Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/zeromq/czmq"	"A high-level binding for ZeroMQ."	"true"
"Networking and Internet"	"GNU adns"	"https://gnu.org/software/adns/"	"An advanced, easy-to-use, asynch-capable DNS client library and utilities. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"adns - advanced, alternative, asynchronous resolver GNU adns Advanced, easy to use, asynchronous-capable DNS client library and utilities. adns is a resolver library for C (and C++) programs, and a collection of useful DNS resolver utilities. C library In contrast with the standard interfaces, gethostbyname et al and libresolv, it has the following features: It is reasonably easy to use for simple programs which just want to translate names to addresses, look up MX records, etc. It can be used in an asynchronous, non-blocking, manner. Many queries can be handled simultaneously. Responses are decoded automatically into a natural representation for a C program - there is no need to deal with DNS packet and RRDATA formats. Sanity checking (eg, name syntax checking, reverse/forward correspondence, CNAME pointing to CNAME) is performed automatically by default. Time-to-live, CNAME and other similar information is returned in an easy-to-use form, without getting in the way. There is no global state in the library; resolver state is an opaque data structure which the client creates explicitly. A program can have several instances of the resolver. Errors are reported to the application in a way that distinguishes the various causes of failure properly. adns understands conventional resolv.conf, but this can overridden by environment variables. Flexibility. For example, the application can tell adns to: ignore environment variables (for setuid programs), disable hostname syntax sanity checks to return arbitrary data, override or ignore resolv.conf in favour of supplied configuration, etc. Believed to be correct ! For example, will correctly back off to TCP in case of long replies or queries, or to other nameservers if several are available. It has sensible handling of bad responses etc. DNS utility programs adns also comes with a number of utility programs for use from the command line and in scripts: adnslogres is a much faster version of Apache's logresolv program. adnsresfilter is a filter which copies its input to its output, replacing IP addresses by the corresponding names, without unduly delaying the output. For example, you can usefully pipe the output of netstat -n, tcpdump -ln, and the like, into it. adnshost is a general-purpose DNS lookup utility which can be used easily in from the command line and from shell scripts to do simple lookups. In a more advanced mode it can be used as a general-purpose DNS helper program for scripting languages which can invoke and communicate with subprocesses. See the adnshost usage message for a summary of its capabilities. Documentation I'm afraid there is no manual yet. However, competent C programmers should be able to use the library based on the commented adns.h header file, and the usage messages for the programs should be sufficient. Feedback I'd be pleased if you would let me know if you're using my library in your project, and what you think of it. Bug reports should be reported to the GNU Debbugs. Send an email to submit@debbugs.gnu.org and at the top of your email, in a paragraph of its own, write the single line  Package: adns  Your bug report will be published via to the adns-discuss list. Feedback and discussion takes place on the adns-discuss list. You can mail me privately at ijackson@chiark.greenend.org.uk. Mailinglists I have set up mailinglists adns-announce and adns-discuss. The announcements list is moderated and will contain only announcements of important bugs, new versions, etc. There are archives and subscription web pages, or you can subscribe by sending mail containing the word `subscribe' to adns-announce-REQUEST@chiark.greenend.org.uk or adns-discuss-REQUEST@chiark.greenend.org.uk. Documentation adns.h API header file with documentation comments usage message for adnshost Download and source code The current release as a gzipped tarfile. Previous versions and other files (including OpenPGP signatures). master git (version control) repository browser. adns is also available from the GNU Project FTP servers and their mirrors. Installation note adns requires a real nameserver like BIND running on the same system or a nearby one, which must be willing to provide `recursive service'. I.e., adns is a `stub resolver'. adns requires that your real nameserver is on the same machine, or connected via a secure network, so that an attacker cannot fake the replies to adns's queries. References and related projects Python bindings by Andy Dustman. liboop event loop library has a built-in binding for adns. port to MS Visual Studio 6 C++ by Jarle Aase. Copyright and licensing adns is Copyright 1997-2000,2003,2006,2014 Ian Jackson, Copyright 2014 Mark Wooding, Copyright 1999-2000,2003,2006 Tony Finch, and Copyright (C) 1991 Massachusetts Institute of Technology. adns is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 3 of the License, or (at your option) any later version. This program and documentation is distributed in the hope that it will be useful, but without any warranty; without even the implied warranty of merchantability or fitness for a particular purpose. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with adns, or one should be available above; if not, write to the Free Software Foundation or email ijackson@chiark.greenend.org.uk. Ian Jackson / ijackson@chiark.greenend.org.uk. GNU home page; chiark home page; site or mirror home page This web page is Copyright (C)1996-2005,2014 Ian Jackson. See the Copyright/acknowledgements."	"null"	"null"	"An advanced, easy-to-use, asynch-capable DNS client library and utilities. or later."	"true"
"Networking and Internet"	"GNU SASL"	"https://gnu.org/software/gsasl/"	"An implementation of the Simple Authentication and Security Layer and a few common SASL mechanism. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"GNU SASL Library - Libgsasl - GNU Project - Free Software Foundation Skip to main text Set language English [en] The  9th HACKERS MEETING  will be held in Rennes (France) from August 18 to 20. JOIN THE FSF Free Software Supporter GNU Operating System Sponsored by the Free Software Foundation About GNU Philosophy Licenses Education = Software = Documentation Help GNU GNU SASL Library - Libgsasl Introduction GNU SASL is an implementation of the Simple Authentication and Security Layer framework and a few common SASL mechanisms. SASL is used by network servers (e.g., IMAP, SMTP) to request authentication from clients, and in clients to authenticate against servers. GNU SASL consists of a library (`libgsasl'), a command line utility (`gsasl') to access the library from the shell, and a manual. The library includes support for the framework (with authentication functions and application data privacy and integrity functions) and at least partial support for the CRAM-MD5, EXTERNAL, GSSAPI, ANONYMOUS, PLAIN, SECURID, DIGEST-MD5, SCRAM-SHA-1, SCRAM-SHA-1-PLUS, LOGIN, and NTLM mechanisms. The library is portable because it does not do network communication by itself, but rather leaves it up to the calling application. The library is flexible with regards to the authorization infrastructure used, as it utilizes callbacks into the application to decide whether an user is authorized or not. GNU SASL is written in pure ANSI C89 to be portable to embedded and otherwise limited platforms. The entire library, with full support for ANONYMOUS, EXTERNAL, PLAIN, LOGIN and CRAM-MD5, and the front-end that supports client and server mode, and the IMAP and SMTP protocols, fits in under 80kb on an Intel x86 platform, without any modifications to the code. (This figure was accurate as of version 1.1.) GNU SASL is developed for the GNU/Linux system, but runs on over 20 platforms including most major Unix platforms and Windows, and many kind of devices including iPAQ handhelds and S/390 mainframes. The core GNU SASL library, and most mechanisms, are licensed under the GNU Lesser General Public version 2.1 (or later). It is distributed separately, as the ""libgsasl"" package. The GNU SASL command line application, self test suite and more are licensed under the GNU General Public License version 3 (or later). The ""gsasl"" package distribution includes the library part as well, so you do not need to install two packages. Some of the goals with this project are: Clean room implementation. This means the copyright and license conditions are clear. Internationalization. It handles non-ASCII username and passwords by using SASLprep. User visible strings used in the library (error messages) can be translated into the users' language. Thread safe library. This library uses no global state and multiple concurrent SASL sessions are possibly (e.g. in a multithreaded server). Portable. It should work on all Unix like operating systems, including Windows. The library itself should be portable to any C89 system, not even POSIX is required. Table of Contents Introduction Documentation and Status Support News Downloading Development Dependencies Bugs Documentation and Status Refer to the GNU SASL Manual web page for links to the manual in all formats; however, quick links to the most popular formats: Online HTML manual PDF manual API reference in HTML See also the various standard texts: RFC 4422, the core SASL specification RFC 2831, the DIGEST-MD5 mechanism RFC 4505, the ANONYMOUS mechanism RFC 4616, the PLAIN mechanism RFC 4752, the Kerberos V5 GSSAPI mechanism RFC 5801, the GS2 mechanism (GS2-KRB5) RFC 5802, the SCRAM mechanism RFC 6595, the SAML20 mechanism RFC 6616, the OPENID20 mechanism Currently the ANONYMOUS, EXTERNAL, CRAM-MD5, DIGEST-MD5, GS2-KRB5, GSS-API, PLAIN, LOGIN, SCRAM-SHA-1, SCRAM-SHA-1-PLUS, and SECURID mechanisms are implemented and work both in client and server mode. The NTLM mechanism is implemented in client mode only. The library has been used in production for several years and should be considered mature. GNU SASL has been ported to Windows and there are some resources around this effort: Installing under Windows Kerberos on Windows Pre-built Windows binaries Free software projects using GNU SASL include: GNU Emacs, in the Gnus MUA. GNU Mailutils. GNU Anubis. MSMTP. MPOP. VMIME. Vortex Library, a BEEP stack. Jabberd2, a XMPP server. Let us know about more free software projects that use GNU SASL! Support A mailing list where GNU SASL users may help each other exists, and you can reach it by sending e-mail to help-gsasl@gnu.org. Archives of the mailing list discussions, and an interface to manage subscriptions, is available through the World Wide Web at http://lists.gnu.org/mailman/listinfo/help-gsasl. If you are interested in paid support of GNU SASL, or sponsor the development, please contact me. If you provide paid services for GNU SASL, and would like to be mentioned here, also contact me. If you find GNU SASL useful, please consider making a donation. No amount is too small! News Note that new releases are only mentioned here if they introduce a major feature or is significant in some other way. Read the help-gsasl mailing list if you seek more frequent announcements. Information on what is new in the library itself is found in the NEWS and lib/NEWS file (live version). 2010-12-14: New stable release 1.6.0 with SCRAM-SHA-1(-PLUS) and GS2-KRB5 support. 2010-11-14: SCRAM-SHA-1-PLUS is supported in experimental 1.5.3 release. 2010-03-31: GS2-KRB5 is supported in the experimental 1.5.0 release. 2009-11-07: SCRAM-SHA-1 is now intended for stable use with the version 1.4 release. 2009-10-08: As of version 1.3 the library experimentally supports SCRAM-SHA-1. 2008-08-19: The library can be built as a native Windows Visual Studio project. 2008-01-12: Instructions for building GNU SASL under uClinux have been published. 2007-10-08: Git repository moved to Savannah, you can browse it. 2007-07-09: The command line, self tests, examples etc of GNU SASL are now licensed under the GPL version 3. The library remains licensed under the LGPL version 2.1. 2007-06-01: GNU SASL is now developed in git instead of cvs. 2007-04-20: Version 0.2.16, released today, will likely be the last release on the 0.2.x. branch, next we'll focus on implementing GS2. 2006-06-14: Newly released version 0.2.13 works well under Windows. 2004-11-07: A new major release, version 0.2.0, has been released. 2004-04-16: The license for the core library, and most common mechanisms, is being changed to LGPL. A release candidate of 0.0.15 with this change is available. 2004-01-01: Savannah had problems last month, and still isn't operating fully. CVS has been moved to a private machine, a read-only mirror of it will hopefully be available via Savannah in the future. 2003-10-11 Version 0.0.8 includes API for SASLprep/trace string preparation, improved portability, and more. 2003-06-02 The GSSAPI mechanism now supports GSS and Heimdal, besides MIT Kerberos. 2003-03-17 Debian includes libgsasl, thanks to Ryan M. Golbeck. 2003-02-02 The KERBEROS_V5 document is updated with examples from our library used in GNU Mailutil's imap4d server. 2003-01-30 Implementation of our KERBEROS_V5 mechanism proposal started, using Shishi. 2002-12-16 gnu.org web pages opened and development moved to savannah. 2002-12-13 Version 0.0.4 renames the package from ""libgsasl"" to GNU SASL and the license is changed to the GPL. 2002-12-09 Official GNU project. 2002-10-07 Initial release of version 0.0.0. Downloading The releases are distributed from ftp://ftp.gnu.org/gnu/gsasl/. All official releases are signed with an OpenPGP key with fingerprint 0xB565716F. Unofficial Windows binaries are provided by Francis Brosnan Blazquez at Sourceforge's Vortex project. Development There is a Savannah GNU SASL project page. You can check out the sources by using git as follows:  $ git clone git://git.savannah.gnu.org/gsasl.git  The online git interface is available. Notifications of each commit is sent to gsasl-commit@gnu.org. If you have trouble using git, you may download a daily snapshot. The snapshots are prepared similar to regular releases, i.e., you simply build them using ./configure && make. Build logs from building the package, where you can also contribute a build system for your own platform, are available from the GNU SASL autobuild page. See the file README-alpha on how to bootstrap and build the package from version controlled sources. For every release, we publish cyclomatic code complexity charts for the package. There is also self-test code coverage charts available. Dependencies You need at least a shell, a C compiler and a Make tool to build GNU SASL. GNU SASL will enable certain features if you have the following optional external libraries installed: Non-ASCII support (e.g., username and passwords): GNU Libidn. NTLM mechanism: libntlm 0.3.1 or later. GSSAPI mechanism: GNU GSS, MIT Kerberos, Heimdal. Bugs Report all problems to bug-gsasl@gnu.org, but please read the manual on how to report bugs first. GNU home page FSF home page GNU Art GNU's Who? Free Software Directory Hardware Site map “Our mission is to preserve, protect and promote the freedom to use, study, copy, modify, and redistribute computer software, and to defend the rights of Free Software users.” The Free Software Foundation is the principal organizational sponsor of the GNU Operating System. Support GNU and the FSF by buying manuals and gear, joining the FSF as an associate member, or making a donation, either directly to the FSF or via Flattr. back to top Please send general FSF & GNU inquiries to <gnu@gnu.org>. There are also other ways to contact the FSF. Broken links and other corrections or suggestions can be sent to <help-gsasl@gnu.org>. Please see the Translations README for information on coordinating and submitting translations of this article. Copyright © 2002-2008 Simon Josefsson Copyright © 2016 Free Software foundation, Inc. This page is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License. Copyright Infringement Notification Updated: $Date: 2016/05/25 20:58:28 $"	"null"	"null"	"An implementation of the Simple Authentication and Security Layer and a few common SASL mechanism. or later."	"true"
"Networking and Internet"	"gumbo-parser"	"https://github.com/google/gumbo-parser"	"An HTML5 parsing library in C99.."	"null"	"null"	"null"	"Apache2.0"	"http://directory.fsf.org/wiki/License:Apache2.0"	"null"	"null"	"3759"	"320"	"489"	"GitHub - google/gumbo-parser: An HTML5 parsing library in pure C99 Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 320 Star 3,759 Fork 489 google/gumbo-parser Code Issues 30 Pull requests 4 Pulse Graphs An HTML5 parsing library in pure C99 403 commits 4 branches 7 releases Fetching contributors HTML 87.1% C 10.1% C++ 1.2% Ragel in Ruby Host 1.1% Python 0.5% Makefile 0.0% HTML C C++ Ragel in Ruby Host Python Makefile Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master v0.10.2 v0.11.0 v1.0.0 Nothing to show v0.10.1 v0.10.0 v0.9.4 v0.9.3 v0.9.2 v0.9.1 v0.9.0 Nothing to show New pull request Latest commit aa91b27 Jun 28, 2016 nostrademons committed on GitHub Merge pull request #367 from mominul/patch-1 … Markdownify CHANGELOG.md Permalink Failed to load latest commit information. benchmarks Add baidu benchmark which has been left out of the git repository all… Feb 18, 2015 examples Recognize templates in serialize and prettyprint Feb 17, 2015 python/gumbo Update gen_tags.py to exempt generated files from clang-format, and r… Apr 30, 2015 src Fix error mesage use of return value form vnsprintf Dec 3, 2015 testdata @ e633ddf Move html5lib-tests submodule ref up to include the ruby fix. Feb 18, 2015 tests Added a test for fragments with multiple nodes. May 7, 2015 third_party Integrate gumbo_parser with gtest. Sep 14, 2013 visualc Update strings.h Dec 26, 2014 .clang-format Reformat the source code with clang-format, and add a config file for… Apr 30, 2015 .gitignore Add .dylib files to gitignore. Apr 30, 2015 .gitmodules Pull the html5lib tests in as a submodule (for real; before they were… Sep 22, 2014 .travis.yml Add a line to the TravisCI config to make sure one of the example pro… Feb 18, 2015 CHANGES.md Markdownify CHANGELOG.md Jun 24, 2016 CONTRIBUTING.md Update to CONTRIBUTING file with code hygiene guidelines. Apr 30, 2015 COPYING Initial commit. Aug 9, 2013 DEBUGGING.md Additional debugging instructions. Feb 17, 2015 Doxyfile Update version number and changelist for 0.9.2 release. Sep 21, 2014 Makefile.am tags: Use a gperf-based hash table Mar 2, 2015 README.md Merge master, bringing in some tag utilities that weren't yet on v0.1… Apr 30, 2015 THANKS Update THANKS file with additional contributors. Apr 30, 2015 appveyor.yml Add AppVeyor configuration. Apr 30, 2015 autogen.sh Test for both glibtoolize and libtoolize on Mac; the downloaded versi… Mar 22, 2015 configure.ac Bump version number. Because the version-number commit for v0.9.4 cam… Apr 30, 2015 genperf.py tags: Use a gperf-based hash table Mar 2, 2015 gentags.py Update gen_tags.py to exempt generated files from clang-format, and r… Apr 30, 2015 gtest.gyp Integrate gumbo_parser with gtest. Sep 14, 2013 gumbo.pc.in Initial commit. Aug 9, 2013 gumbo_parser.gyp Add proper cflags for building via gyp Aug 19, 2014 setup.py Bump version number. Because the version-number commit for v0.9.4 cam… May 1, 2015 README.md Gumbo - A pure-C HTML5 parser. Gumbo is an implementation of the HTML5 parsing algorithm implemented as a pure C99 library with no outside dependencies. It's designed to serve as a building block for other tools and libraries such as linters, validators, templating languages, and refactoring and analysis tools. Goals & features: Fully conformant with the HTML5 spec. Robust and resilient to bad input. Simple API that can be easily wrapped by other languages. Support for source locations and pointers back to the original text. Support for fragment parsing. Relatively lightweight, with no outside dependencies. Passes all html5lib tests, including the template tag. Tested on over 2.5 billion pages from Google's index. Non-goals: Execution speed. Gumbo gains some of this by virtue of being written in C, but it is not an important consideration for the intended use-case, and was not a major design factor. Support for encodings other than UTF-8. For the most part, client code can convert the input stream to UTF-8 text using another library before processing. Mutability. Gumbo is intentionally designed to turn an HTML document into a parse tree, and free that parse tree all at once. It's not designed to persistently store nodes or subtrees outside of the parse tree, or to perform arbitrary DOM mutations within your program. If you need this functionality, we recommend translating the Gumbo parse tree into a mutable DOM representation more suited for the particular needs of your program before operating on it. C89 support. Most major compilers support C99 by now; the major exception (Microsoft Visual Studio) should be able to compile this in C++ mode with relatively few changes. (Bug reports welcome.) Security. Gumbo was initially designed for a product that worked with trusted input files only. We're working to harden this and make sure that it behaves as expected even on malicious input, but for now, Gumbo should only be run on trusted input or within a sandbox. Gumbo underwent a number of security fixes and passed Google's security review as of version 0.9.1. Wishlist (aka ""We couldn't get these into the original release, but are hoping to add them soon""): Full-featured error reporting. Additional performance improvements. DOM wrapper library/libraries (possibly within other language bindings) Query libraries, to extract information from parse trees using CSS or XPATH. Installation To build and install the library, issue the standard UNIX incantation from the root of the distribution: $ ./autogen.sh $ ./configure $ make $ sudo make install Gumbo comes with full pkg-config support, so you can use the pkg-config to print the flags needed to link your program against it: $ pkg-config --cflags gumbo         # print compiler flags $ pkg-config --libs gumbo           # print linker flags $ pkg-config --cflags --libs gumbo  # print both For example: $ gcc my_program.c `pkg-config --cflags --libs gumbo` See the pkg-config man page for more info. There are a number of sample programs in the examples/ directory. They're built automatically by 'make', but can also be made individually with make <programname> (eg. make clean_text). To run the unit tests, you'll need to have googletest downloaded and unzipped. The googletest maintainers recommend against using make install; instead, symlink the root googletest directory to 'gtest' inside gumbo's root directory, and then make check: $ unzip gtest-1.6.0.zip $ cd gumbo-* $ ln -s ../gtest-1.6.0 gtest $ make check Gumbo's make check has code to automatically configure & build gtest and then link in the library. Debian and Fedora users can install libgtest with: $ apt-get install libgtest-dev  # Debian/Ubuntu $ yum install gtest-devel       # CentOS/Fedora Note for Ubuntu users: libgtest-dev package only install source files. You have to make libraries yourself using cmake: $ sudo apt-get install cmake $ cd /usr/src/gtest $ sudo cmake CMakeLists.txt $ sudo make $ sudo cp *.a /usr/lib  The configure script will detect the presence of the library and use that instead. Note that you need to have super user privileges to execute these commands. On most distros, you can prefix the commands above with sudo to execute them as the super user. Debian installs usually don't have sudo installed (Ubuntu however does.) Switch users first with su -, then run apt-get. Basic Usage Within your program, you need to include ""gumbo.h"" and then issue a call to gumbo_parse: #include ""gumbo.h""  int main() {   GumboOutput* output = gumbo_parse(""<h1>Hello, World!</h1>"");   // Do stuff with output->root   gumbo_destroy_output(&kGumboDefaultOptions, output); } See the API documentation and sample programs for more details. A note on API/ABI compatibility We'll make a best effort to preserve API compatibility between releases. The initial release is a 0.9 (beta) release to solicit comments from early adopters, but if no major problems are found with the API, a 1.0 release will follow shortly, and the API of that should be considered stable. If changes are necessary, we follow semantic versioning. We make no such guarantees about the ABI, and it's very likely that subsequent versions may require a recompile of client code. For this reason, we recommend NOT using Gumbo data structures throughout a program, and instead limiting them to a translation layer that picks out whatever data is needed from the parse tree and then converts that to persistent data structures more appropriate for the application. The API is structured to encourage this use, with a single delete function for the whole parse tree, and is not designed with mutation in mind. Python usage To install the python bindings, make sure that the C library is installed first, and then sudo python setup.py install from the root of the distro. This installs a 'gumbo' module; pydoc gumbo should tell you about it. Recommended best-practice for Python usage is to use one of the adapters to an existing API (personally, I prefer BeautifulSoup) and write your program in terms of those. The raw CTypes bindings should be considered building blocks for higher-level libraries and rarely referenced directly. External Bindings and other wrappers The following language bindings or other tools/wrappers are maintained by various contributors in other repositories: C++: gumbo-query by lazytiger Ruby: ruby-gumbo by Nicolas Martyanoff nokogumbo by Sam Ruby Node.js: node-gumbo-parser by Karl Westin D: gumbo-d by Christopher Bertels Lua: lua-gumbo by Craig Barnes Objective-C: ObjectiveGumbo by Programming Thomas OCGumbo by TracyYih C#: GumboBindings by Vladimir Zotov PHP: GumboPHP by Paul Preece Perl: HTML::Gumbo by Ruslan Zakirov Julia: Gumbo.jl by James Porter C/Libxml: gumbo-libxml by Jonathan Tang Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/google/gumbo-parser"	"An HTML5 parsing library in C99.."	"true"
"Networking and Internet"	"http-parser"	"https://github.com/nodejs/http-parser"	"An HTTP request/response parser.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"2736"	"256"	"746"	"GitHub - nodejs/http-parser: http request/response parser for c Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 256 Star 2,736 Fork 746 nodejs/http-parser Code Issues 22 Pull requests 18 Pulse Graphs http request/response parser for c 393 commits 5 branches 18 releases 68 contributors C 96.5% Makefile 2.2% Python 1.3% C Makefile Python Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags event_stream master v0.6 v0.10 version0.2 Nothing to show v2.7.0 v2.6.2 v2.6.1 v2.6.0 v2.5.0 v2.5 v2.4.2 v2.4.1 v2.4 v2.3 v2.2.1 v2.2 v2.1 v2.0 v1.0 v0.3 v0.2 v0.1 Nothing to show New pull request Latest commit b2cc8e4 Apr 22, 2016 guoxiao committed with indutny test: remove ‘nread’, which is not used … PR-URL: #300 Reviewed-By: Fedor Indutny <fedor@indutny.com> Permalink Failed to load latest commit information. contrib src: introduce `http_parser_url_init` Oct 27, 2015 .gitignore header: treat Wine like MinGW Jul 22, 2015 .mailmap Bump version to 2.4.0 Jan 14, 2015 .travis.yml send travis irc notifications to #node-ci Nov 3, 2014 AUTHORS src: support LINK/UNLINK (RFC 2068, draft-snell-link-method) Oct 26, 2015 LICENSE-MIT It was pointed out we're missing attribution to NGINX May 15, 2011 Makefile Bump version to 2.6.0 Apr 19, 2016 README.md readme: improve format, fix code syntax May 31, 2016 bench.c bench: add chunked bytes Dec 5, 2014 http_parser.c src: put `assert()` after var declarations Apr 25, 2016 http_parser.gyp build: add default build flags to gyp script Oct 14, 2012 http_parser.h Bump version to 2.6.0 Apr 19, 2016 test.c test: remove ‘nread’, which is not used Jun 22, 2016 README.md HTTP Parser This is a parser for HTTP messages written in C. It parses both requests and responses. The parser is designed to be used in performance HTTP applications. It does not make any syscalls nor allocations, it does not buffer data, it can be interrupted at anytime. Depending on your architecture, it only requires about 40 bytes of data per message stream (in a web server that is per connection). Features: No dependencies Handles persistent streams (keep-alive). Decodes chunked encoding. Upgrade support Defends against buffer overflow attacks. The parser extracts the following information from HTTP messages: Header fields and values Content-Length Request method Response status code Transfer-Encoding HTTP version Request URL Message body Usage One http_parser object is used per TCP connection. Initialize the struct using http_parser_init() and set the callbacks. That might look something like this for a request parser: http_parser_settings settings; settings.on_url = my_url_callback; settings.on_header_field = my_header_field_callback; /* ... */  http_parser *parser = malloc(sizeof(http_parser)); http_parser_init(parser, HTTP_REQUEST); parser->data = my_socket; When data is received on the socket execute the parser and check for errors. size_t len = 80*1024, nparsed; char buf[len]; ssize_t recved;  recved = recv(fd, buf, len, 0);  if (recved < 0) {   /* Handle error. */ }  /* Start up / continue the parser.  * Note we pass recved==0 to signal that EOF has been received.  */ nparsed = http_parser_execute(parser, &settings, buf, recved);  if (parser->upgrade) {   /* handle new protocol */ } else if (nparsed != recved) {   /* Handle error. Usually just close the connection. */ } HTTP needs to know where the end of the stream is. For example, sometimes servers send responses without Content-Length and expect the client to consume input (for the body) until EOF. To tell http_parser about EOF, give 0 as the fourth parameter to http_parser_execute(). Callbacks and errors can still be encountered during an EOF, so one must still be prepared to receive them. Scalar valued message information such as status_code, method, and the HTTP version are stored in the parser structure. This data is only temporally stored in http_parser and gets reset on each new message. If this information is needed later, copy it out of the structure during the headers_complete callback. The parser decodes the transfer-encoding for both requests and responses transparently. That is, a chunked encoding is decoded before being sent to the on_body callback. The Special Problem of Upgrade HTTP supports upgrading the connection to a different protocol. An increasingly common example of this is the WebSocket protocol which sends a request like     GET /demo HTTP/1.1     Upgrade: WebSocket     Connection: Upgrade     Host: example.com     Origin: http://example.com     WebSocket-Protocol: sample  followed by non-HTTP data. (See RFC6455 for more information the WebSocket protocol.) To support this, the parser will treat this as a normal HTTP message without a body, issuing both on_headers_complete and on_message_complete callbacks. However http_parser_execute() will stop parsing at the end of the headers and return. The user is expected to check if parser->upgrade has been set to 1 after http_parser_execute() returns. Non-HTTP data begins at the buffer supplied offset by the return value of http_parser_execute(). Callbacks During the http_parser_execute() call, the callbacks set in http_parser_settings will be executed. The parser maintains state and never looks behind, so buffering the data is not necessary. If you need to save certain data for later usage, you can do that from the callbacks. There are two types of callbacks: notification typedef int (*http_cb) (http_parser*); Callbacks: on_message_begin, on_headers_complete, on_message_complete. data typedef int (*http_data_cb) (http_parser*, const char *at, size_t length); Callbacks: (requests only) on_url, (common) on_header_field, on_header_value, on_body; Callbacks must return 0 on success. Returning a non-zero value indicates error to the parser, making it exit immediately. For cases where it is necessary to pass local information to/from a callback, the http_parser object's data field can be used. An example of such a case is when using threads to handle a socket connection, parse a request, and then give a response over that socket. By instantiation of a thread-local struct containing relevant data (e.g. accepted socket, allocated memory for callbacks to write into, etc), a parser's callbacks are able to communicate data between the scope of the thread and the scope of the callback in a threadsafe manner. This allows http-parser to be used in multi-threaded contexts. Example:  typedef struct {   socket_t sock;   void* buffer;   int buf_len;  } custom_data_t;   int my_url_callback(http_parser* parser, const char *at, size_t length) {   /* access to thread local custom_data_t struct.   Use this access save parsed data for later use into thread local   buffer, or communicate over socket   */   parser->data;   ...   return 0; }  ...  void http_parser_thread(socket_t sock) {  int nparsed = 0;  /* allocate memory for user data */  custom_data_t *my_data = malloc(sizeof(custom_data_t));   /* some information for use by callbacks.  * achieves thread -> callback information flow */  my_data->sock = sock;   /* instantiate a thread-local parser */  http_parser *parser = malloc(sizeof(http_parser));  http_parser_init(parser, HTTP_REQUEST); /* initialise parser */  /* this custom data reference is accessible through the reference to the  parser supplied to callback functions */  parser->data = my_data;   http_parser_settings settings; /* set up callbacks */  settings.on_url = my_url_callback;   /* execute parser */  nparsed = http_parser_execute(parser, &settings, buf, recved);   ...  /* parsed information copied from callback.  can now perform action on data copied into thread-local memory from callbacks.  achieves callback -> thread information flow */  my_data->buffer;  ... }  In case you parse HTTP message in chunks (i.e. read() request line from socket, parse, read half headers, parse, etc) your data callbacks may be called more than once. Http-parser guarantees that data pointer is only valid for the lifetime of callback. You can also read() into a heap allocated buffer to avoid copying memory around if this fits your application. Reading headers may be a tricky task if you read/parse headers partially. Basically, you need to remember whether last header callback was field or value and apply the following logic: (on_header_field and on_header_value shortened to on_h_*)  ------------------------ ------------ -------------------------------------------- | State (prev. callback) | Callback   | Description/action                         |  ------------------------ ------------ -------------------------------------------- | nothing (first call)   | on_h_field | Allocate new buffer and copy callback data | |                        |            | into it                                    |  ------------------------ ------------ -------------------------------------------- | value                  | on_h_field | New header started.                        | |                        |            | Copy current name,value buffers to headers | |                        |            | list and allocate new buffer for new name  |  ------------------------ ------------ -------------------------------------------- | field                  | on_h_field | Previous name continues. Reallocate name   | |                        |            | buffer and append callback data to it      |  ------------------------ ------------ -------------------------------------------- | field                  | on_h_value | Value for current header started. Allocate | |                        |            | new buffer and copy callback data to it    |  ------------------------ ------------ -------------------------------------------- | value                  | on_h_value | Value continues. Reallocate value buffer   | |                        |            | and append callback data to it             |  ------------------------ ------------ --------------------------------------------  Parsing URLs A simplistic zero-copy URL parser is provided as http_parser_parse_url(). Users of this library may wish to use it to parse URLs constructed from consecutive on_url callbacks. See examples of reading in headers: partial example in C from http-parser tests in C from Node library in Javascript Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/nodejs/http-parser"	"An HTTP request/response parser.."	"true"
"Networking and Internet"	"ldns"	"http://www.nlnetlabs.nl/projects/ldns/index.html"	"A library to simplify DNS programming.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"null"	"null"	"null"	"nlnetlabs.nl :: ldns :: ldns NLnetLabs Home News About Mission Staff Student Alumni Employment Projects NSD Ldns Unbound OpenDNSSEC DNSSEC Dnssec-Trigger DNSSEC Workshop Credns Net::DNS BGP Simulation Drill Student Projects Older Projects Publications Publications Presentations DNSSEC Howto Support Downloads Bug reports NSD support Blog ldns The goal of ldns is to simplify DNS programming, it supports recent RFCs like the DNSSEC documents, and allows developers to easily create software conforming to current RFCs, and experimental software for current Internet Drafts. A secondary benefit of using ldns is speed; ldns is written in C it should be a lot faster than Perl. The first major tool to use ldns is Drill, from which part of the library was derived. From version 1.0.0 on, drill is be included in the ldns release and will not be distributed separately anymore. Its version number will follow that of ldns. The library also includes some other examples and tools to show how it can be used. ldns depends on OpenSSL for its crypto functions. It can be compiled without OpenSSL, but of course you'll lose the ability to perform any cryptographic functions. Feature list IP4 and IP6 support, TSIG support, DNSSEC support; signing and verification, small size, online documentation as well as manual pages. If you want to send us patches please use the code from git (develop). Download The latest release is 1.6.17, dating Jan 10, 2014 Download (checksum sha1: 4218897b3c002aadfc7280b3f40cda829e05c9a4) The changelog for this version can be found at http://git.nlnetlabs.nl/ldns/tree/Changelog?id=release-1.6.17 Compiling After downloading, you can compile the library by doing:  ./configure && (g)make  You need GNU make to compile it. If you compile from the repository, you also need the gnu autotools (autoreconf and libtool). Creating documentation The (html) documentation is created with doxygen. The manual pages are created with a perl program. While sitting in the source directory a simple gmake doc should create everything. Drill ldns includes the Drill tool. Drill is a tool ala dig from BIND. It was designed with DNSSEC in mind and should be a useful debugging/query tool for DNSSEC. A lot of DNS debugging is done with dig, but as dig is made with the same libraries as BIND8/9 (the most used DNS server out there), what are you actually debugging/testing? Drill has nothing in common with either NSD nor BIND. During the development process we are actually uncovering obscure bugs in NSD and BIND (and in drill itself). Example programs A few example programs are included in the source of ldns. They are not compiled by default. You need to explicitly build them with: cd examples && ./configure && (g)make ldns-chaos - Prints some information about the nameserver. ldns-key2ds - Creates a DS record from a DNSKEY record ldns-keyfetcher - Fetches DNSSEC public keys for zones ldns-keygen - Generate private/pubkey key pair for DNSSEC. ldns-mx - Explained in the tutorial. Prints the mx records for a domain. ldns-read-zone - Reads a zone file and prints it with 1 RR per line. ldns-signzone - Signs a zone file according to DNSSECbis. ldns-version - Prints the version of the library. ldns-update - UPDATE examples. ldns-walk - 'Walks' a DNSSEC zone ldns-zsplit - Splits a zone file in smaller parts ldns-zcat - Concatenates zone file parts split with ldns-zsplit ldns-compare-zones - See the differences between zones (added/removed names, added/removed rrs for names) Also see their manual pages. (in the examples/ dir) Support We have a mailing list where ldns related discussion are held. These discussions can range from implementation issues to generic DNS/DNSSEC issues. You can find the mailing list information page here. Links Doxygen Documentation Tutorials GIT Repository Mailing List Bugs   Wed Jun 29 2016 © Stichting NLnet Labs Science Park 400, 1098 XH Amsterdam, The Netherlands labs@nlnetlabs.nl, subsidised by NLnet and SIDN."	"null"	"null"	"A library to simplify DNS programming.."	"true"
"Networking and Internet"	"libcurl"	"https://curl.haxx.se/libcurl/"	"A client-side URL transfer library, supporting a wide range of formats."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"libcurl - the multiprotocol file transfer library libcurl index ABI API Bindings Competitors Examples Features Mailing List Related Libs Using libcurl Tutorial Testimonials cURL / libcurl overview libcurl - the multiprotocol file transfer library libcurl is a free and easy-to-use client-side URL transfer library, supporting DICT, FILE, FTP, FTPS, Gopher, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, POP3, POP3S, RTMP, RTSP, SCP, SFTP, SMTP, SMTPS, Telnet and TFTP. libcurl supports SSL certificates, HTTP POST, HTTP PUT, FTP uploading, HTTP form based upload, proxies, cookies, user+password authentication (Basic, Digest, NTLM, Negotiate, Kerberos), file transfer resume, http proxy tunneling and more! libcurl is highly portable, it builds and works identically on numerous platforms, including Solaris, NetBSD, FreeBSD, OpenBSD, Darwin, HPUX, IRIX, AIX, Tru64, Linux, UnixWare, HURD, Windows, Amiga, OS/2, BeOs, Mac OS X, Ultrix, QNX, OpenVMS, RISC OS, Novell NetWare, DOS and more... libcurl is free, thread-safe, IPv6 compatible, feature rich, well supported, fast, thoroughly documented and is already used by many known, big and successful companies and numerous applications. Download Go to the regular curl download page and get the latest curl package, or one of the specific libcurl packages listed. API You use libcurl with the provided C API or one of the over 40 available bindings. The cURL team works hard to keep the API and ABI stable. Howto Check out our using libcurl page for general hints and advice, the free HTTP client library comparison. or read the comparisons against libwww and WinInet. libcurl is most probably the most portable, most powerful and most often used C-based multi-platform file transfer library on this planet - be it open source or commercial."	"null"	"null"	"A client-side URL transfer library, supporting a wide range of formats."	"true"
"Networking and Internet"	"curl license"	"https://curl.haxx.se/docs/copyright.html"	"A client-side URL transfer library, supporting a wide range of formats."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"cURL - copyright Docs Overview Companies Copyright License Mixing Sponsors Thanks The Name cURL / Docs / Who and Why / Copyright Copyright - License Related: The curl name license mix FAQ Curl and libcurl are true Open Source/Free Software and meet all definitions as such. It means that you are free to modify and redistribute all contents of the curl distributed archives. You may also freely use curl and libcurl in your commercial projects. Curl and libcurl are licensed under a MIT/X derivate license, see below. There are other computer-related projects using the name curl as well. For details, check out our position on the curl name issue. The curl license COPYRIGHT AND PERMISSION NOTICE Copyright (c) 1996 - 2016, Daniel Stenberg, daniel@haxx.se, and many contributors, see the THANKS file. All rights reserved. Permission to use, copy, modify, and distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF THIRD PARTY RIGHTS. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Except as contained in this notice, the name of a copyright holder shall not be used in advertising or otherwise to promote the sale, use or other dealings in this Software without prior written authorization of the copyright holder."	"null"	"null"	"A client-side URL transfer library, supporting a wide range of formats."	"true"
"Networking and Internet"	"LibEtPan"	"https://github.com/dinhviethoa/libetpan"	"A mail library providing an efficient network for IMAP, SMTP, POP and NNTP.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"396"	"30"	"168"	"GitHub - dinhviethoa/libetpan: Mail Framework for C Language Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 30 Star 396 Fork 168 dinhviethoa/libetpan Code Issues 18 Pull requests 0 Pulse Graphs Mail Framework for C Language http://www.etpan.org 626 commits 3 branches 10 releases 44 contributors C 95.6% Makefile 2.1% Objective-C 1.0% M4 0.6% Shell 0.5% C++ 0.2% C Makefile Objective-C M4 Shell C++ Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags dvh-chacham15-master master qqmail-envelope Nothing to show 1.7.2 1.7 1.6 1.5 1.4.1 1.4 1.3.pre2 1.3.pre1 1.2 1.2.pre1 Nothing to show New pull request Latest commit 4c36ec1 Jul 13, 2016 dinhviethoa Fixed crash with IDLE Permalink Failed to load latest commit information. build-android android build version 4 May 6, 2016 build-mac Fixed config build for Mac/iOS Mar 26, 2016 build-windows fix windows config May 6, 2016 doc import from CVS Jul 19, 2011 include import from CVS Jul 19, 2011 m4 import from CVS Jul 19, 2011 src Fixed crash with IDLE Jul 13, 2016 tests fix 64 bits time_t issues May 16, 2016 travis Automatically choose SDK on Travis Sep 15, 2015 .gitignore add compile script to .gitignore Mar 9, 2016 .travis.yml Use Xcode7 on Travis Sep 15, 2015 AUTHORS import from CVS Jul 19, 2011 COPYRIGHT import from CVS Jul 19, 2011 ChangeLog import from CVS Jul 19, 2011 Makefile.am import from CVS Jul 19, 2011 NEWS import from CVS Jul 19, 2011 README.md add flag --with-poll for configure May 8, 2016 autogen.sh fixed warning Feb 28, 2013 configure.ac Fixed so name again May 25, 2016 libetpan-config.h.in The inline keyword is not part of C in visual studio but is part of C… Mar 20, 2015 libetpan-config.in import from CVS Jul 19, 2011 rules.mk import from CVS Jul 19, 2011 README.md LibEtPan The purpose of this mail library is to provide a portable, efficient framework for different kinds of mail access: IMAP, SMTP, POP and NNTP. It provides an API for C language. Features IMAP SMTP POP NNTP RFC822/MIME message builder RFC822/MIME message parser Maildir mbox MH Build instructions Unix You need to install autoconf, automake and libtool. They can be installed using brew. $ ./autogen.sh $ make  You can use flag --with-poll for using poll() instead of select() for checking connection status How to link with it $ gcc -c -o sample.o sample.c `libetpan-config --cflags` $ gcc -o sample sample.o `libetpan-config --libs`  Mac / iOS Download Xcode Open build-mac/libetpan.xcodeproj Choose the correct target ""static libetpan"" for Mac or ""libetpan ios"" for iOS. Build Setup a Mac project Add libetpan.xcodeproj as sub-project Link with libetpan.a Setup an iOS project Add libetpan.xcodeproj as sub-project Link with libetpan-ios.a Set ""Other Linker Flags"": -lsasl2 Build on Windows See README and Visual Studio Solution in build-windows folder More information See http://etpan.org/libetpan.html for more information and examples. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/dinhviethoa/libetpan"	"A mail library providing an efficient network for IMAP, SMTP, POP and NNTP.."	"true"
"Networking and Internet"	"libev"	"http://software.schmorp.de/pkg/libev.html"	"Yet another event loop.."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"null"	"null"	"null"	"libev Schmorpforge Software Repository libev The free as in beer, liberal, code & content retro-style graphical MMORPG :) libev A full-featured and high-performance (see benchmark) event loop that is loosely modelled after libevent, but without its limitations and bugs. It is used in GNU Virtual Private Ethernet, rxvt-unicode, auditd, the Deliantra MORPG Server and Client, and many other programs. Blurb Features include child/pid watchers, periodic timers based on wallclock (absolute) time (in addition to timers using relative timeouts), as well as epoll/kqueue/event ports/inotify/eventfd/signalfd support, fast timer management, time jump detection and correction, and ease-of-use. It can be used as a libevent replacement using its emulation API or directly embedded into your programs without the need for complex configuration support. A full-featured and well-documented perl interface is also available. A mailing list for discussion and support is now available. Resources CVS Browsable CVS module 'libev' CVS Anonymous CVS:  cvs -z3 -d :pserver:anonymous@cvs.schmorp.de/schmorpforge co libev FILE File Releases LIST Mailing List 'libev' IRC Server irc.schmorp.de, channel #schmorpforge, user schmorp (say hi and wait a few minutes or hours) Additional Documents FILE README POD ev.pod Contact for this page: Marc Lehmann <schmorpforge@schmorp.de>."	"null"	"null"	"Yet another event loop.."	"true"
"Networking and Internet"	"libevent"	"http://libevent.org/"	"An event loop replacement for network servers.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"1622"	"227"	"1119"	"GitHub - libevent/libevent: A public libevent repository.  The official repository is at https://github.com/libevent/libevent Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 227 Star 1,622 Fork 1,119 libevent/libevent forked from nmathewson/Libevent Code Issues 48 Pull requests 25 Wiki Pulse Graphs A public libevent repository. The official repository is at https://github.com/libevent/libevent http://libevent.org 3,658 commits 6 branches 45 releases 83 contributors C 88.5% CMake 3.4% Python 2.3% Groff 1.8% C++ 1.7% M4 1.5% Other 0.8% C CMake Python Groff C++ M4 Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags 2.0.23-stable-rc 20-issue306-fix 21_http_extended_methodcmp master patches-1.4 patches-2.0 Nothing to show release-2.1.5-beta release-2.0.22-stable release-2.0.21-stable release-2.0.20-stable release-2.0.19-stable release-2.0.18-stable release-2.0.17-stable release-2.0.16-stable release-2.0.15-stable release-2.0.14-stable release-2.0.13-stable release-2.0.12-stable release-2.0.11-stable release-2.0.10-stable release-2.0.9-rc release-2.0.8-rc release-2.0.7-rc release-2.0.6-rc release-2.0.5-beta release-2.0.3-alpha release-2.0.2-alpha@1379 release-1.4.15-stable release-1.4.14b-stable release-1.4.14-stable release-1.4.13-stable release-1.4.12-stable release-1.4.11-stable release-1.4.10-stable release-1.4.9-stable release-1.4.8-stable release-1.4.7-stable release-1.4.6 release-1.4.5-stable release-1.4.4-stable release-1.4.3-stable release-1.4.2-rc release-1.4.1-beta release-1.4.0-beta release-1.3e release-1.3d release-1.3c release-1.3b release-1.3a release-1.2 release-1.1b Nothing to show New pull request #379 Compare This branch is even with nmathewson:master. Latest commit df6f99e Jul 8, 2016 mark-chromium committed with azat Check for Mac OS X 10.4 kqueue bug properly … EV_ERROR is a bit in struct kevent::flags. Other bits may be set too.  Actually we have osx builds on travis-ci, but it uses osx 10.9.5, and we don't have warnings there, since I guess that there is no OR'ing with previous flag in case of error, while in 10.12 there is OR.  Fixes: #377 Fixes: #376 Link: https://crbug.com/626534 Link: https://travis-ci.org/libevent/libevent/jobs/141033429 Permalink Failed to load latest commit information. WIN32-Code Increment version to 2.1.5-beta Jan 5, 2015 cmake cmake: fix adding of compiler flags, and now it will Mar 10, 2016 compat/sys Fix all identifiers with names beginning with underscore. Feb 29, 2012 include [#372] check for errno.h Jun 28, 2016 m4 Merge remote-tracking branch 'origin/patches-2.0' Feb 14, 2012 sample Fix memory leak in signal-test.c Jun 29, 2016 test test/buffer: cover evbuffer_expand() for overflow Jun 26, 2016 .gitignore Update gitignore file to ignore cscope gen'ed files Jun 22, 2016 .travis.yml travis-ci/osx: relink gcc/g++ instead of clang May 10, 2016 CMakeLists.txt [#372] check for errno.h Jun 28, 2016 ChangeLog Update changelog Jan 5, 2015 ChangeLog-1.4 Try to finalize changelog situation for 2.1.1-alpha Apr 3, 2012 ChangeLog-2.0 Update ChangeLog-2.0 Nov 18, 2012 Doxyfile Fix doxygen to use new macro conventions Feb 29, 2012 LICENSE Implement fast/precise monotonic clocks on Windows Apr 26, 2012 Makefile.am automake: define serial-tests only if automake have this option May 11, 2016 Makefile.nmake Revert ""The Windows socket type is defined as SOCKET."" Dec 20, 2015 README.md Update README.md Dec 23, 2015 appveyor.yml Use autotools for appveyor until cmake is fixed. May 12, 2015 arc4random.c Merge remote-tracking branch 'origin/patches-2.0' Aug 19, 2013 autogen.sh Prefer autoreconf -ivf to manual autogen.sh Sep 3, 2010 buffer.c buffer: don't mix code and declarations Jul 7, 2016 buffer_iocp.c Have all visible internal function names end with an underscore. Feb 29, 2012 bufferevent-internal.h be_sock: cancel in-progress dns requests Mar 23, 2016 bufferevent.c be: introduce bufferevent_generic_adj_existing_timeouts_() Nov 6, 2015 bufferevent_async.c be async: avoid double close() Nov 21, 2014 bufferevent_filter.c be_filter: avoid data stuck under active watermarks Jun 19, 2016 bufferevent_openssl.c be_openssl: clear all pending errors before SSL_*() calls May 2, 2016 bufferevent_pair.c Fix bufferevent_pair to properly set BEV_EVENT_{READING,WRITING} on f… Jun 17, 2016 bufferevent_ratelim.c Pass and return const for bufferevent_get_token_bucket_cfg Jul 11, 2013 bufferevent_sock.c be_sock: cancel in-progress dns requests Mar 23, 2016 changelist-internal.h Implemented EV_CLOSED event for epoll backend (EPOLLRDHUP). Jan 17, 2014 configure.ac [#372] check for errno.h Jun 28, 2016 defer-internal.h fix the return value of event_deferred_cb_schedule_ Mar 24, 2015 devpoll.c Have all visible internal function names end with an underscore. Feb 29, 2012 epoll.c epoll: introduce PRINT_CHANGES() macro to avoid copy-pasting Nov 18, 2015 epoll_sub.c Merge remote-tracking branch 'origin/patches-2.0' Jan 22, 2014 epolltable-internal.h Split epoll lookup table into a separate header file Jan 21, 2014 evbuffer-internal.h Fix CVE-2014-6272 in Libevent 2.1 Jan 5, 2015 evconfig-private.h.cmake Generate a dummy evconfig-private.h so things build properly. Dec 13, 2013 evconfig-private.h.in Clean up lingering _identifiers. Feb 29, 2012 evdns.3 improved nroff mdoc for the man page Oct 15, 2006 evdns.c evdns: fix searching empty hostnames Mar 25, 2016 event-config.h.cmake [#372] check for errno.h Jun 28, 2016 event-internal.h Add a prototype for event_disable_debug_mode() Sep 10, 2015 event.3 Don't use BSD u_* types. Aug 25, 2015 event.c event_reinit: make signals works after fork() without evsig_add() Dec 27, 2015 event_iocp.c Merge remote-tracking branch 'origin/patches-2.0' Nov 1, 2013 event_rpcgen.py Merge remote-tracking branch 'origin/patches-2.0' Oct 26, 2012 event_tagging.c Include <sys/ioctl.h>, <sys/resource.h> and <sys/wait.h> optionally. Sep 10, 2015 evmap-internal.h Have all visible internal function names end with an underscore. Feb 29, 2012 evmap.c Implemented EV_CLOSED event for epoll backend (EPOLLRDHUP). Jan 18, 2014 evport.c Have all visible internal function names end with an underscore. Feb 29, 2012 evrpc-internal.h Add an include to evrpc-internal to fix openbsd compilation warning Mar 12, 2014 evrpc.c Fix even more coverity warnings. Jan 8, 2014 evsignal-internal.h Add a new libevent_global_shutdown() to free all globals before exiting. Mar 22, 2012 evthread-internal.h Fix ""function declaration isn’t a prototype"" Feb 16, 2015 evthread.c evthread: fix evthread_setup_global_lock_() for debug-lock with a rea… Oct 4, 2015 evthread_pthread.c Clean up lingering _identifiers. Feb 29, 2012 evthread_win32.c Merge remote-tracking branch 'origin/patches-2.0' Dec 4, 2012 evutil.c evdns: export cancel via callbacks in util (like async lib core/extra… Mar 23, 2016 evutil_rand.c Merge remote-tracking branch 'origin/patches-2.0' Sep 19, 2013 evutil_time.c Implement new/free for struct evutil_monotonic_timer and export monot… Dec 4, 2014 ht-internal.h ht-internal: don't reset hth_table_length explicitly in name_##HT_CLEAR Jan 8, 2015 http-internal.h http: fix EVHTTP_CON_READ_ON_WRITE_ERROR when it doesn't supported by OS Mar 11, 2016 http.c [Issue #313] set method to ASCII ""NULL"" if evhttp_method() returns NULL Jun 24, 2016 iocp-internal.h Have all visible internal function names end with an underscore. Feb 29, 2012 ipv6-internal.h Convert include-guard macro convention to avoid reserved identifiers Feb 29, 2012 kqueue-internal.h Replace pipe-based notification with EVFILT_USER where possible Apr 11, 2012 kqueue.c Check for Mac OS X 10.4 kqueue bug properly Jul 12, 2016 libevent.pc.in Change use of AC_CHECK_LIB to AC_SEARCH_LIBS. Jul 10, 2009 libevent_core.pc.in libevent_core and libevent_extra also deserve a pkgconfig file Apr 20, 2016 libevent_extra.pc.in libevent_core and libevent_extra also deserve a pkgconfig file Apr 20, 2016 libevent_openssl.pc.in Use correct openssl libs and includes in pkgconfig file Nov 16, 2012 libevent_pthreads.pc.in Add pkgconfig files for libevent_{openssl,pthreads} Aug 10, 2010 listener.c listener: unlock lev on error in listener_read_cb() Apr 1, 2016 log-internal.h Actually use the log facility for reporting evdns problems. May 29, 2013 log.c Actually use the log facility for reporting evdns problems. May 29, 2013 make-event-config.sed Generate event-config.h with a single sed script Apr 27, 2012 make_epoll_table.py Implemented EV_CLOSED event for epoll backend (EPOLLRDHUP). Jan 18, 2014 minheap-internal.h Remove an unreachable return statement in minheap-internal.h Aug 1, 2013 mm-internal.h Convert include-guard macro convention to avoid reserved identifiers Feb 29, 2012 poll.c Split out time-related prototypes into time-internal.h Apr 20, 2012 ratelim-internal.h Have all visible internal function names end with an underscore. Feb 29, 2012 select.c Tweak the new evutil_weakrand_() code Apr 9, 2012 signal.c Merge remote-tracking branch 'github/20_win64_compilation' into 21_wi… Nov 2, 2012 strlcpy-internal.h Fix all identifiers with names beginning with underscore. Feb 29, 2012 strlcpy.c Fix all identifiers with names beginning with underscore. Feb 29, 2012 time-internal.h Implement new/free for struct evutil_monotonic_timer and export monot… Dec 4, 2014 util-internal.h evdns: export cancel via callbacks in util (like async lib core/extra… Mar 23, 2016 whatsnew-2.0.txt ""buffer"" spelling Feb 7, 2013 whatsnew-2.1.txt Add new APIs to whatsnew-2.1 Mar 16, 2014 win32select.c Don't use BSD u_* types. Aug 25, 2015 README.md 0. BUILDING AND INSTALLATION (Briefly) Autoconf  $ ./configure  $ make  $ make verify   # (optional)  $ sudo make install  Cmake (General) The following Libevent specific Cmake variables ar as follows (the values being the default). # Installation directory for executables EVENT_INSTALL_BIN_DIR:PATH=bin  # Installation directory for CMake files EVENT_INSTALL_CMAKE_DIR:PATH=lib/cmake/libevent  ## Installation directory for header files EVENT_INSTALL_INCLUDE_DIR:PATH=include  ## Installation directory for libraries EVENT_INSTALL_LIB_DIR:PATH=lib  ## Define if libevent should be built with shared libraries instead of archives EVENT__BUILD_SHARED_LIBRARIES:BOOL=OFF  # Enable running gcov to get a test coverage report (only works with # GCC/CLang). Make sure to enable -DCMAKE_BUILD_TYPE=Debug as well. EVENT__COVERAGE:BOOL=OFF  # Defines if libevent should build without the benchmark exectuables EVENT__DISABLE_BENCHMARK:BOOL=OFF  # Define if libevent should build without support for a debug mode EVENT__DISABLE_DEBUG_MODE:BOOL=OFF  # Define if libevent should not allow replacing the mm functions EVENT__DISABLE_MM_REPLACEMENT:BOOL=OFF  # Define if libevent should build without support for OpenSSL encrpytion EVENT__DISABLE_OPENSSL:BOOL=ON  # Disable the regress tests EVENT__DISABLE_REGRESS:BOOL=OFF  # Disable sample files EVENT__DISABLE_SAMPLES:BOOL=OFF  # If tests should be compiled or not EVENT__DISABLE_TESTS:BOOL=OFF  # Define if libevent should not be compiled with thread support EVENT__DISABLE_THREAD_SUPPORT:BOOL=OFF  # Enables verbose debugging EVENT__ENABLE_VERBOSE_DEBUG:BOOL=OFF  # When crosscompiling forces running a test program that verifies that Kqueue # works with pipes. Note that this requires you to manually run the test program # on the the cross compilation target to verify that it works. See cmake # documentation for try_run for more details EVENT__FORCE_KQUEUE_CHECK:BOOL=OFF  # set EVENT_STAGE_VERSION EVENT__STAGE_VERSION:STRING=beta  More variables can be found by running cmake -LAH <sourcedir_path> CMake (Windows) Install CMake: http://www.cmake.org  $ md build && cd build  $ cmake -G ""Visual Studio 10"" ..   # Or whatever generator you want to use cmake --help for a list.  $ start libevent.sln  CMake (Unix)  $ mkdir build && cd build  $ cmake ..     # Default to Unix Makefiles.  $ make  $ make verify  # (optional)  1. BUILDING AND INSTALLATION (In Depth) Autoconf To build libevent, type  $ ./configure && make  (If you got libevent from the git repository, you will first need to run the included ""autogen.sh"" script in order to generate the configure script.) You can run the regression tests by running  $ make verify  Install as root via  $ make install  Before reporting any problems, please run the regression tests. To enable the low-level tracing build the library as:  $ CFLAGS=-DUSE_DEBUG ./configure [...]  Standard configure flags should work. In particular, see: --disable-shared Only build static libraries --prefix Install all files relative to this directory. The configure script also supports the following flags: --enable-gcc-warnings Enable extra compiler checking with GCC. --disable-malloc-replacement Don't let applications replace our memory management functions --disable-openssl Disable support for OpenSSL encryption. --disable-thread-support Don't support multithreaded environments. CMake (Windows) (Note that autoconf is currently the most mature and supported build enviroment for libevent; the cmake instructions here are new and experimental, though they should be solid. We hope that cmake will still be supported in future versions of Libevent, and will try to make sure that happens.) First of all install http://www.cmake.org. To build libevent using Microsoft Visual studio open the ""Visual Studio Command prompt"" and type: $ cd <libevent source dir> $ mkdir build && cd build $ cmake -G ""Visual Studio 10"" ..   # Or whatever generator you want to use cmake --help for a list. $ start libevent.sln  In the above, the "".."" refers to the dir containing the Libevent source code. You can build multiple versions (with different compile time settings) from the same source tree by creating other build directories. It is highly recommended to build ""out of source"" when using CMake instead of ""in source"" like the normal behaviour of autoconf for this reason. The ""NMake Makefiles"" CMake generator can be used to build entirely via the command line. To get a list of settings available for the project you can type: $ cmake -LH ..  GUI CMake also provides a GUI that lets you specify the source directory and output (binary) directory that the build should be placed in. OpenSSL support To build Libevent with OpenSSL support you will need to have OpenSSL binaries available when building, these can be found here: http://www.openssl.org/related/binaries.html 2. USEFUL LINKS: For the latest released version of Libevent, see the official website at http://libevent.org/ . There's a pretty good work-in-progress manual up at http://www.wangafu.net/~nickm/libevent-book/ . For the latest development versions of Libevent, access our Git repository via $ git clone https://github.com/libevent/libevent.git  You can browse the git repository online at: https://github.com/libevent/Libevent To report bugs, issues, or ask for new features: Patches: https://github.com/libevent/libevent/pulls OK, those are not really patches You fork, modify, and hit the ""Create Pull Request"" button. You can still submit normal git patchs via the mailing list. Bugs, Features [RFC], and Issus: https://github.com/libevent/libevent/issues Or you can do it via the mailing list. There's also a libevent-users mailing list for talking about Libevent use and development: http://archives.seul.org/libevent/users/ 3. ACKNOWLEDGMENTS The following people have helped with suggestions, ideas, code or fixing bugs: Samy Al Bahra Antony Antony Jacob Appelbaum Arno Bakker Weston Andros Adamson William Ahern Ivan Andropov Sergey Avseyev Avi Bab Joachim Bauch Andrey Belobrov Gilad Benjamini Stas Bekman Denis Bilenko Julien Blache Kevin Bowling Tomash Brechko Kelly Brock Ralph Castain Adrian Chadd Lawnstein Chan Shuo Chen Ka-Hing Cheung Andrew Cox Paul Croome George Danchev Andrew Danforth Ed Day Christopher Davis Mike Davis Frank Denis Antony Dovgal Mihai Draghicioiu Alexander Drozdov Mark Ellzey Shie Erlich Leonid Evdokimov Juan Pablo Fernandez Christophe Fillot Mike Frysinger Remi Gacogne Artem Germanov Alexander von Gernler Diego Giagio Artur Grabowski Diwaker Gupta Kuldeep Gupta Sebastian Hahn Dave Hart Greg Hazel Nicholas Heath Michael Herf Sebastian Hahn Savg He Mark Heily Maxime Henrion Michael Herf Greg Hewgill Andrew Hochhaus Aaron Hopkins Tani Hosokawa Jamie Iles Xiuqiang Jiang Claudio Jeker Evan Jones Marcin Juszkiewicz George Kadianakis Makoto Kato Phua Keat Azat Khuzhin Alexander Klauer Kevin Ko Brian Koehmstedt Marko Kreen Ondřej Kuzník Valery Kyholodov Ross Lagerwall Scott Lamb Christopher Layne Adam Langley Graham Leggett Volker Lendecke Philip Lewis Zhou Li David Libenzi Yan Lin Moshe Litvin Simon Liu Mitchell Livingston Hagne Mahre Lubomir Marinov Abilio Marques Nicolas Martyanoff Abel Mathew Nick Mathewson James Mansion Nicholas Marriott Andrey Matveev Caitlin Mercer Dagobert Michelsen Andrea Montefusco Mansour Moufid Mina Naguib Felix Nawothnig Trond Norbye Linus Nordberg Richard Nyberg Jon Oberheide John Ohl Phil Oleson Alexey Ozeritsky Dave Pacheco Derrick Pallas Tassilo von Parseval Catalin Patulea Patrick Pelletier Simon Perreault Dan Petro Pierre Phaneuf Amarin Phaosawasdi Ryan Phillips Dimitre Piskyulev Pavel Plesov Jon Poland Roman Puls Nate R Robert Ransom Balint Reczey Bert JW Regeer Nate Rosenblum Peter Rosin Maseeb Abdul Qadir Wang Qin Alex S Gyepi Sam Hanna Schroeter Ralf Schmitt Mike Smellie Steve Snyder Nir Soffer Dug Song Dongsheng Song Hannes Sowa Joakim Soderberg Joseph Spadavecchia Kevin Springborn Harlan Stenn Andrew Sweeney Ferenc Szalai Brodie Thiesfield Jason Toffaletti Brian Utterback Gisle Vanem Bas Verhoeven Constantine Verutin Colin Watt Zack Weinberg Jardel Weyrich Jay R. Wren Zack Weinberg Mobai Zhang Alejo Alex Taral propanbutan masksqwe mmadia yangacer If we have forgotten your name, please contact us. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/libevent/libevent"	"An event loop replacement for network servers.."	"true"
"Networking and Internet"	"libgss"	"https://gnu.org/software/gss/"	"Generic Security Service. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"GNU Generic Security Service - Libgss - GNU Project - Free Software Foundation Skip to main text Set language English [en] The  9th HACKERS MEETING  will be held in Rennes (France) from August 18 to 20. JOIN THE FSF Free Software Supporter GNU Operating System Sponsored by the Free Software Foundation About GNU Philosophy Licenses Education = Software = Documentation Help GNU GNU Generic Security Service - Libgss Introduction This page contain information about Generic Security Service (GSS), a free implementation of RFC 2743/2744. If you do not know what GSS is, I suggest to read the following resources. GSSAPIv2u1 specification (RFC 2743) GSSAPIv2u1 C bindings (RFC 2744) Sun's GSS-API Programming Guide GSS itself is licensed under GPLv3+, and the manual is licensed under GFDLv1.3+. Table of Contents Introduction Status News Support Downloading Development Documentation and Status Refer to the GSS Manual web page for links to the manual in all formats; however, quick links to the most popular formats: Online HTML manual PDF manual API reference in HTML GSS has received some real-world testing and should be considered beta quality. The source code framework is in place, an outline of the documentation is ready, and there are some simple self tests. The Kerberos 5 mechanism (RFC 1964 and RFC 4121) supports mutual authentication, channel bindings and the standard DES cipher. The non-standard 3DES cipher is also implemented, but unfortunately there are no specifications for AES. GNU SASL can use GSS to connect to GNU Mailutils and Cyrus IMAP servers that use the GSS implementations from MIT Kerberos or Heimdal. GNU MailUtils can also use GSS to serve GSSAPI clients. A SSH client and server with GSS authentication is provided by LSH with some patches. GSS is developed for the GNU/Linux system, but runs on over 20 platforms including most major Unix platforms and Windows, and many kind of devices including iPAQ handhelds and S/390 mainframes. GSS uses GNU Shishi to implement the Kerberos V5 mechanism. Projects using GSS include: GNU SASL. GNU Mailutils. Curl. Fetchmail. News 2011-11-25: Version 1.0.2 released 2010-05-20: Version 1.0.1 released 2010-03-30: Version 1.0.0 takes GNU GSS out of alpha testing. 2010-03-15: Version 0.1.3 adds support for Kerberos V5 channel bindings, paving the road for GS2-KRB5 support in GNU SASL. 2007-06-29: Version 0.0.22 released under the GPLv3. 2004-01-22: New releases are no longer announced here. Instead, read help-gss or check the release directory from time to time. By the way, GSS 0.0.10 was just released. 2004-01-15: Version 0.0.9 released, several new features, API documentation using GTK-DOC. 2004-01-11: Version 0.0.8 released, various bug fixes and major documentation revamp. 2004-01-01: Savannah had problems last month, and still isn't operating fully. CVS has been moved to a private machine, a read-only mirror of it will hopefully be available via Savannah in the future. 2003-11-26: Version 0.0.7 released, fixes a problem prohibiting 3DES gss_wrap from working. 2003-09-22: Version 0.0.6 released, accompanies Shishi 0.0.7. 2003-09-16: GSSLib can be used by OpenSSH in client mode to support Kerberos 5 via Shishi, see my page for the OpenSSH GSSLib patch. 2003-08-31: Version 0.0.5 released, accompanies Shishi 0.0.4. 2003-08-10: Version 0.0.4 released, contains Kerberos 5 improvements and accompanies Shishi 0.0.1. 2003-06-30: Added a page with information about SSH authentication using this library. 2003-06-28: Version 0.0.2 contains limited server mode support. GNU Mailutils can use GSS for its native GSSAPI authentication in server mode (with this patch), which then interoperate with (at least) the GNU SASL command line client using GSS. 2003-06-02: Initial release. Support A mailing list where GSS users may help each other exists, and you can reach it by sending e-mail to help-gss@gnu.org. Archives of the mailing list discussions, and an interface to manage subscriptions, is available through the World Wide Web at http://lists.gnu.org/mailman/listinfo/help-gss. If you are interested in paid support of GSS, or sponsor the development, please contact me. If you provide paid services for GSS, and would like to be mentioned here, also contact me. If you find GSS useful, please consider making a donation. No amount is too small! Downloading The releases are distributed from ftp://ftp.gnu.org/gnu/gss/. All official releases are signed with an OpenPGP key with fingerprint B565716F or with fingerprint 54265e8c. Development There is a Savannah GSS project page. You can check out the sources by using git as follows:  git clone git://git.savannah.gnu.org/gss.git  The online git interface is available. See the file README-alpha on how to bootstrap and build the package from version controlled sources. For every release, we publish cyclomatic code complexity charts for the package. There is also self-test code coverage charts available. GNU home page FSF home page GNU Art GNU's Who? Free Software Directory Hardware Site map “Our mission is to preserve, protect and promote the freedom to use, study, copy, modify, and redistribute computer software, and to defend the rights of Free Software users.” The Free Software Foundation is the principal organizational sponsor of the GNU Operating System. Support GNU and the FSF by buying manuals and gear, joining the FSF as an associate member, or making a donation, either directly to the FSF or via Flattr. back to top Please send general FSF & GNU inquiries to <gnu@gnu.org>. There are also other ways to contact the FSF. Broken links and other corrections or suggestions can be sent to <help-gss@gnu.org>. Please see the Translations README for information on coordinating and submitting translations of this article. Copyright © 2002-2008 Simon Josefsson Copyright © 2016 Free Software Foundation, Inc. This page is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License. Copyright Infringement Notification Updated: $Date: 2016/05/25 21:06:02 $"	"null"	"null"	"Generic Security Service. or later."	"true"
"Networking and Internet"	"libhttpd"	"http://www.hughes.com.au/products/libhttpd/"	"A library to add basic web server capabilities to an application or embedded device. only."	"null"	"null"	"null"	"GNU GPL2"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"LibHTTPD : Embedded web server library. Introduction LibHTTPD can be used to add basic web server capabilities to an application or embedded device. The library handles both static and dynamically generated content, has very low overheads, and provides many features to simplify the creation of web based application interfaces. Current Version The current release is LibHTTPD 1.4 released on 2 Feb 2005. Download it here. Read the release notes / history here. License Available under our Dual License scheme (GPL for Open Source users and a Developer license for commercial applications). The Developer license is a royalty free license allowing you to incorporate web server functionality in your product for a low, fixed price. Developer licenses are available from our online store for US$995. Support The complete LibHTTPD manual is available online as a PDF document. Support is available in the LibHTTPD mailing list web server library, embedded web server, embedded http implementation httpd libhttpd Copyright © 2001-2006, Hughes Technologies Pty Ltd. All Rights Reserved. Last updated 04 Sep 2006. Comments to webmaster@Hughes.com.au. Offsite Backups provided by Next Internet"	"null"	"null"	"A library to add basic web server capabilities to an application or embedded device. only."	"true"
"Networking and Internet"	"libidn"	"https://gnu.org/software/libidn/"	"An implementation of the Stringprep, Punycode and IDNA specifications. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"GNU IDN Library - Libidn - GNU Project - Free Software Foundation Skip to main text Set language English [en] The  9th HACKERS MEETING  will be held in Rennes (France) from August 18 to 20. JOIN THE FSF Free Software Supporter GNU Operating System Sponsored by the Free Software Foundation About GNU Philosophy Licenses Education = Software = Documentation Help GNU GNU IDN Library - Libidn Introduction GNU Libidn is a fully documented implementation of the Stringprep, Punycode and IDNA specifications. Libidn's purpose is to encode and decode internationalized domain names. The native C, C# and Java libraries are available under the GNU Lesser General Public License version 2.1 or later. The library contains a generic Stringprep implementation. Profiles for Nameprep, iSCSI, SASL, XMPP and Kerberos V5 are included. Punycode and ASCII Compatible Encoding (ACE) via IDNA are supported. A mechanism to define Top-Level Domain (TLD) specific validation tables, and to compare strings against those tables, is included. Default tables for some TLDs are also included. The Stringprep API consists of two main functions, one for converting data from the system's native representation into UTF-8, and one function to perform the Stringprep processing. Adding a new Stringprep profile for your application within the API is straightforward. The Punycode API consists of one encoding function and one decoding function. The IDNA API consists of the ToASCII and ToUnicode functions, as well as an high-level interface for converting entire domain names to and from the ACE encoded form. The TLD API consists of one set of functions to extract the TLD name from a domain string, one set of functions to locate the proper TLD table to use based on the TLD name, and core functions to validate a string against a TLD table, and some utility wrappers to perform all the steps in one call. The library is used by, e.g., GNU SASL and Shishi to process user names and passwords. Libidn can be built into GNU Libc to enable a new system-wide getaddrinfo flag for IDN processing. Libidn is developed for the GNU/Linux system, but runs on over 20 Unix platforms (including Solaris, IRIX, AIX, and Tru64) and Windows. The library is written in C and (parts of) the API is also accessible from C++, Emacs Lisp, Python and Java. A native Java and C# port is included. Also included is a command line tool, several self tests, code examples, and more, all licensed under the GNU General Public License version 3.0 or later. Table of Contents Introduction News Try it Documentation Downloading Support Development Bugs Related implementations How to use it? Libidn2 News Note that new releases are only mentioned here if they introduce a major feature or is significant in some other way. Read the help-libidn mailing list if you seek more frequent announcements. 2012-01-10: An infloop bug was fixed for the pr29 functions. The library has been relicensed to dual-GPLv2+|LGPLv3+. See the Libidn 1.24 announcement. 2011-05-04: Quality Assurance improvements: we publish clang-analyzer reports for the library. 2011-04-20: An IDNA2008 implementation is announced called libidn2. 2008-10-07: Quality Assurance improvements: we publish cyclomatic code Complexity charts and self-test code coverage charts. 2007-07-31: Version 1.0 is released, to indicate that Libidn is now considered stable. It has been used in production for several years with only minor issues found. 2007-05-31: Libidn is now developed in git instead of cvs, there is a public savannah git repository. 2006-06-07: Translation of error messages are working, and the library has been ported to Windows using MinGW. 2005-12-03: Version 0.6.0 include a native C# port, contributed by Alexander Gnauck. 2004-11-08: GNU/Linux distribution Fedora Core 3 includes Libidn version 0.5.6. 2004-10-02: Version 0.5.6 include functions (e.g., idna_strerror) to translate from return codes to human readable text strings. 2004-06-26: Version 0.5.0 include a module to detect ""problem sequences"" for normalization as discussed in PR-29. 2004-06-01: Version 0.4.8 include a native Java port, thanks to Oliver Hitz. 2004-04-30: People interested in the specifications behind libidn may be interested in a proposed change to NFKC by the Unicode Consortium. I have posted a message to the IDN WG mailing list asking for opinions on this, but apparently the list moderator is ignoring it. 2004-03-27: Recently a patch to GNU Libc has been incorporated, extending the getaddrinfo API based on my writeup. The API is being standardized. 2004-02-28: A NetBSD package exists. 2004-02-28: Version 0.4.0 includes an experimental API for (parts of) the TLD functionality described in draft-hoffman-idn-reg. 2004-01-30: A Perl module Net::LibIDN that provide Perl bindings for Libidn is available, thanks to Thomas Jacob. The page also include a patch that add TLD specific awareness to Libidn. 2004-01-06: A FreeBSD ports package is available, thanks to Kirill Ponomarew. 2004-01-01: Savannah had problems last month, and still isn't operating fully. CVS has been moved to a private machine, a read-only mirror of it will hopefully be available via Savannah in the future. 2003-10-29: A project with the goal of providing PHP bindings of the Libidn API has been started by Turbo Fredriksson. 2003-10-11: Precompiled binaries for Mandrake 9.2 available built as part of glibc, and as a RPM package, thanks to Oden Eriksson. 2003-10-02: Version 0.3.1 fixes all problems discovered during IDNConnect. 2003-06-26: Precompiled binaries for Cygwin available from http://anfaenger.de/cygwin/libidn/, thanks to Gerrit P. Haase. 2003-02-26: Version 0.1.11 includes a command line tool and a Emacs Lisp interface. 2003-02-21: Debian includes libidn, thanks to Ryan M. Golbeck. 2003-02-12: Version 0.1.7 uses official IDNA ACE prefix 'xn--'. 2003-01-28: Version 0.1.5 can be built as an add-on to GNU Libc, available are detailed instructions and example code demonstrating the new getaddrinfo() API. 2003-01-08: Added a simple patch demonstrating support for IDN in the GNU InetUtils ping utility. 2003-01-05: Version 0.1.0 released with Punycode and IDNA. 2003-01-03: Libidn is an official GNU project. 2002-12-26: Moved project to savannah. Initiated renaming of library from ""libstringprep"" to ""libidn"" as the next release will implement Punycode and IDNA too. 2002-12-13: Version 0.0.8 is ported to 20+ platforms, including Microsoft Windows. 2002-11-07: Version 0.0.2 is now used by GNU SASL. 2002-11-05: Initial release of version 0.0.0. Information on what is new in the library itself is found in the NEWS file (live version). Try it A web interface to libidn is available online. Try libidn before you buy it. A simple IDN web server is also available. Documentation Refer to the Libidn Manual web page for links to the manual in all formats; however, quick links to the most popular formats: Online HTML manual PDF manual C/C++ API reference manual in HTML Java API manual in HTML You may also be interested in a preliminary document with Nameprep and IDNA test vectors. See also the various standard texts: IDNA specification Punycode specification Stringprep specification Standard profiles Stringprep profile for IDN: ""Nameprep"" Stringprep profile for iSCSI: ""iSCSI"" Stringprep profile for XMPP: ""Nodeprep"" and ""Resourceprep"" Stringprep profile for user names and passwords: ""SASLprep"" Stringprep profile for SASL ANONYMOUS tokens: ""trace"" Expired profiles Stringprep profile for X.500 Stringprep profile for Kerberos TLD specification IANA Registry for Stringprep Profiles Downloading Libidn can be found on http://ftp.gnu.org/gnu/libidn/ [via HTTP] and ftp://ftp.gnu.org/gnu/libidn/ [via FTP]. It can also be found on one of our FTP mirrors; please use a mirror if possible. All official releases are signed with an OpenPGP key with fingerprint 0xB565716F. Support A mailing list where users of Libidn may help each other exists, and you can reach it by sending e-mail to help-libidn@gnu.org. Archives of the mailing list discussions, and an interface to manage subscriptions, is available through the World Wide Web at http://lists.gnu.org/mailman/listinfo/help-libidn. If you are interested in paid support for Libidn, or sponsor the development, please contact me. If you provide paid services for Libidn, and would like to be mentioned here, also contact me. If you find Libidn useful, please consider making a donation. No amount is too small! Development There is a Savannah Libidn project page. You can check out the sources by using git as follows:  $ git clone git://git.savannah.gnu.org/libidn.git  The online git interface is available. Notifications of each commit is sent to libidn-commit@gnu.org. If you have trouble using git, you may download a daily snapshot. The snapshots are prepared similar to regular releases, i.e., you simply build them using ./configure && make. Build logs from building the package, where you can also contribute a build system for your own platform, are available from the Libidn autobuild page. For every release, we publish cyclomatic code complexity charts for the package. There is also self-test code coverage charts available. Finally, clang-analyzer output is also available. Bugs Report all problems to bug-libidn@gnu.org, but please read the manual on how to report bugs first. Related implementations The following is a list of links to other free IDN, or otherwise related, implementations. The list is not conclusive, suggestions appreciated. JPNIC idnkit Python IDNA IBM ICU Projects using GNU Libidn include: GNU Emacs, in the Gnus news reader. GNU Libc GNU Shishi GNU SASL jabberd Mutt mail reader. Elinks web browser Gloox, a Jabber/XMPP library KDE, for all domain name lookups Net::LibIDN, perl bindings LibIDN Ruby bindings cURL PHP IDNA Extension CocoaPods podspec for Libidn Projects using libidn2 include: mget Let us know about more projects that use GNU Libidn! How to use it? Read data from user, convert it to UTF-8 and then pass it to stringprep(). Example code below (it is included in the distribution as example.c). To simplify compiling, use libtool and pkg-config. More information and more examples are included in the manual. See also the other example*.c files in the source distribution on how to use other features of the library (punycode, IDNA).  #include <stdio.h> #include <stdlib.h> #include <string.h>  /*  * Compiling using libtool and pkg-config is recommended:  *  * $ libtool cc -o example example.c `pkg-config --cflags --libs libidn`  * $ ./example  * Input string encoded as `ISO-8859-1': ª  * Before locale2utf8 (length 2): aa 0a  * Before stringprep (length 3): c2 aa 0a  * After stringprep (length 2): 61 0a  * $  *  */  int main(int argc, char *argv[]) {   char buf[BUFSIZ];   char *p;   int rc, i;    printf(""Input string encoded as `%s': "", 	 stringprep_locale_charset ());   fflush(stdout);   fgets(buf, BUFSIZ, stdin);    printf(""Before locale2utf8 (length %d): "", strlen(buf));   for (i=0; i < strlen(buf); i++)     printf(""%02x "", buf[i] & 0xFF);   printf(""\n"");    p = stringprep_locale_to_utf8 (buf);   if (p)     {       strcpy(buf, p);       free(p);     }   else     printf(""Could not convert string to UTF-8, continuing anyway...\n"");    printf(""Before stringprep (length %d): "", strlen(buf));   for (i=0; i < strlen(buf); i++)     printf(""%02x "", buf[i] & 0xFF);   printf(""\n"");    rc = stringprep(buf, BUFSIZ, 0, stringprep_nameprep);   if (rc != STRINGPREP_OK)     printf(""Stringprep failed with rc %d...\n"", rc);   else     {       printf(""After stringprep (length %d): "", strlen(buf));       for (i=0; i < strlen(buf); i++)         printf(""%02x "", buf[i] & 0xFF);       printf(""\n"");     }    return 0; }  Libidn2 Libidn2 is an implementation of the IDNA2008 specifications (RFC 5890, RFC 5891, RFC 5892, RFC 5893). Libidn2 is a standalone library, without any dependency on Libidn. Libidn2 is believed to be a complete IDNA2008 implementation, but has yet to be as extensively used as the original Libidn library. Libidn2 uses GNU libunistring for Unicode processing and GNU libiconv for character set conversion. Libidn2 can be downloaded from http://alpha.gnu.org/gnu/libidn/ [via HTTP] and ftp://alpha.gnu.org/gnu/libidn/ [via FTP]. It can also be found on one of our FTP mirrors; please use a mirror if possible. The following documentation of libidn2 exists: Libidn2 HTML Manual, generated by Texinfo Libidn2 PDF Manual, generated by Texinfo API Manual, generated by GTK-DOC You may browse the source code git repository. For Quality Assurance, we publish code coverage report and clang static analyzer output. Initial development of Libidn2 has been sponsored by DENIC. GNU home page FSF home page GNU Art GNU's Who? Free Software Directory Hardware Site map “Our mission is to preserve, protect and promote the freedom to use, study, copy, modify, and redistribute computer software, and to defend the rights of Free Software users.” The Free Software Foundation is the principal organizational sponsor of the GNU Operating System. Support GNU and the FSF by buying manuals and gear, joining the FSF as an associate member, or making a donation, either directly to the FSF or via Flattr. back to top Please send general FSF & GNU inquiries to <gnu@gnu.org>. There are also other ways to contact the FSF. Broken links and other corrections or suggestions can be sent to <bug-libidn@gnu.org>. Please see the Translations README for information on coordinating and submitting translations of this article. Copyright © 2002-2011 Free Software Foundation, Inc. This page is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License. Copyright Infringement Notification Updated: $Date: 2016/05/25 21:11:30 $"	"null"	"null"	"An implementation of the Stringprep, Punycode and IDNA specifications. or later."	"true"
"Networking and Internet"	"libmicrohttpd"	"https://gnu.org/software/libmicrohttpd/"	"A small C library that makes it easy to run an HTTP server as part of another application. or later."	"null"	"null"	"null"	"GNU LGPL2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"null"	"null"	"null"	"Libmicrohttpd - GNU Project - Free Software Foundation Skip to main text Set language English [en] The  9th HACKERS MEETING  will be held in Rennes (France) from August 18 to 20. JOIN THE FSF Free Software Supporter GNU Operating System Sponsored by the Free Software Foundation About GNU Philosophy Licenses Education = Software = Documentation Help GNU GNU Libmicrohttpd GNU libmicrohttpd is a small C library that is supposed to make it easy to run an HTTP server as part of another application. GNU GNU Libmicrohttpd is free software and part of the GNU project. Key features that distinguish GNU Libmicrohttpd from other projects are: C library: fast and small API is simple, expressive and fully reentrant Implementation is HTTP 1.1 compliant HTTP server can listen on multiple ports Four different threading models (select, poll, pthread, thread pool) Supported platforms include GNU/Linux, FreeBSD, OpenBSD, NetBSD, Android, OS X, W32, Symbian and z/OS Support for IPv6 Support for SHOUTcast Support for incremental processing of POST data (optional) Support for basic and digest authentication (optional) Support for SSL3 and TLS (requires libgcrypt and libgnutls, optional) Binary is only about 32k (without TLS/SSL support and other optional features) GNU Libmicrohttpd was started because the author needed an easy way to add a concurrent HTTP server to other projects. Existing alternatives were either non-free, not reentrant, standalone, of terrible code quality or a combination thereof. Do not use GNU Libmicrohttpd if you are looking for a standalone HTTP server, there are many other projects out there that provide that kind of functionality already. However, if you want to be able to serve simple WWW pages from within your C or C++ application, check it out. GNU libmicrohttpd is a GNU package. Our official GNU website can be found at http://www.gnu.org/software/libmicrohttpd/. Downloading Libmicrohttpd Source Code Libmicrohttpd can be found on the main GNU ftp server: http://ftp.gnu.org/gnu/libmicrohttpd/ (via HTTP) and ftp://ftp.gnu.org/gnu/libmicrohttpd/ (via FTP). It can also be found on the GNU mirrors; please use a mirror if possible. Debian .deb package The debian package can be downloaded from the official debian archive. The respective packages for libmicrohttpd are libmicrohttpd and for development libmicrohttpd-dev. Backports for Debian Stable are also available. Tar Package The latest version can be found on GNU mirrors. If the mirror does not work, you should be able to find them on the main FTP server at ftp://ftp.gnu.org/gnu/libmicrohttpd/. Latest release is libmicrohttpd-latest.tar.gz. Windows Latest Windows binary is libmicrohttpd-latest-w32-bin.zip. Documentation In addition to the brief documentation on this webpage, we have various other forms of documentation available: microhttpd.h This include file documents most of the API in detail. Manual A manual for Libmicrohttpd is available online, as is documentation for most GNU software. You may also find more information about Libmicrohttpd by running info libmicrohttpd or man libmicrohttpd, or by looking at /usr/share/doc/libmicrohttpd/, /usr/local/doc/libmicrohttpd/, or similar directories on your system. Tutorial The GNU Libmicrohttpd tutorial is available as one document in pdf and html formats. Compatibility API compatibility report comparing most recent GNU libmicrohttpd versions Mailing lists Libmicrohttpd uses the libmicrohttpd mailinglist to discuss all aspects of Libmicrohttpd, including support, development and enhancement requests, as well as bug reports. Announcements about Libmicrohttpd and most other GNU software are made on info-gnu (archive). If you only want to get notifications about Libmicrohttpd, we suggest you subscribe to the project at freshmeat. Security reports that should not be made immediately public can be sent directly to the maintainer. If there is no response to an urgent issue, you can escalate to the general security mailing list for advice. Getting involved Development of Libmicrohttpd, and GNU in general, is a volunteer effort, and you can contribute. For information, please read How to help GNU. If you'd like to get involved, it's a good idea to join the discussion mailing list (see above). Development Known bugs and open feature requests are tracked in our bugtracker. You need to sign up for a reporter account. Please make sure you report bugs under libmicrohttpd and not under any of the other projects. Subversion access You can access the current development version of libmicrohttpd using $ svn checkout https://gnunet.org/svn/libmicrohttpd Our website is kept at $ svn checkout https://gnunet.org/svn/libmicrohttpd-docs Maintainers Libmicrohttpd is currently being co-maintained by Christian Grothoff and Evgeny Grin (Karlson2k). Quick Introduction Dependencies GNU Libmicrohttpd can be used without any dependencies; however, for SSL/TLS support we require libgcrypt and libgnutls. Furthermore, the testcases use libcurl. Some extended testcases also use zzuf and socat (to simulate clients that violate the HTTP protocols). You can compile and use GNU Libmicrohttpd without installing libgcrypt, libgnutls, libcurl, zzuf or socat. A minimal example Before including the microhttpd.h header, you may need to include the headers of your operating system that define the size_t, fd_set, socklen_t and struct sockaddr data types and define MHD_PLATFORM_H. Otherwise, the microhttpd.h header will attempt to include the appropriate headers automatically, which may fail for more exotic platforms. The following is a minimal example for GNU/Linux (included in the distribution):  #include <microhttpd.h> #include <stdlib.h> #include <string.h> #include <stdio.h>  #define PAGE ""<html><head><title>libmicrohttpd demo</title>""\              ""</head><body>libmicrohttpd demo</body></html>""  static int ahc_echo(void * cls, 		    struct MHD_Connection * connection, 		    const char * url, 		    const char * method,                     const char * version, 		    const char * upload_data, 		    size_t * upload_data_size,                     void ** ptr) {   static int dummy;   const char * page = cls;   struct MHD_Response * response;   int ret;    if (0 != strcmp(method, ""GET""))     return MHD_NO; /* unexpected method */   if (&dummy != *ptr)     {       /* The first time only the headers are valid,          do not respond in the first round... */       *ptr = &dummy;       return MHD_YES;     }   if (0 != *upload_data_size)     return MHD_NO; /* upload data in a GET!? */   *ptr = NULL; /* clear context pointer */   response = MHD_create_response_from_buffer (strlen(page),                                               (void*) page,   					      MHD_RESPMEM_PERSISTENT);   ret = MHD_queue_response(connection, 			   MHD_HTTP_OK, 			   response);   MHD_destroy_response(response);   return ret; }  int main(int argc, 	 char ** argv) {   struct MHD_Daemon * d;   if (argc != 2) {     printf(""%s PORT\n"", 	   argv[0]);     return 1;   }   d = MHD_start_daemon(MHD_USE_THREAD_PER_CONNECTION, 		       atoi(argv[1]), 		       NULL, 		       NULL, 		       &ahc_echo, 		       PAGE, 		       MHD_OPTION_END);   if (d == NULL)     return 1;   (void) getc ();   MHD_stop_daemon(d);   return 0; }  Threading models The example above uses the simplest threading model, MHD_USE_THREAD_PER_CONNECTION. In this model, MHD starts one thread to listen on the port for new connections and then spawns a new thread to handle each connection. This model is great if the HTTP server has hardly any state that is shared between connections (no synchronization issues!) and may need to perform blocking operations (such as extensive IO or running of code) to handle an individual connection. The second threading model, MHD_USE_SELECT_INTERNALLY, uses only a single thread to handle listening on the port and processing of requests. This model is preferable if spawning a thread for each connection would be costly. If the HTTP server is able to quickly produce responses without much computational overhead for each connection, this model can be a great choice. Note that MHD will still start a single thread for itself -- this way, the main program can continue with its operations after calling MHD_daemon_start. Naturally, if the HTTP server needs to interact with shared state in the main application, synchronization will be required. If such synchronization in code providing a response results in blocking, all HTTP server operations on all connections will stall. This mode is a bad choice if response data (for responses generated using the MHD_create_response_from_callback function) cannot always be provided instantly. The reason is that the code generating responses should not block (since that would block all other connections) and on the other hand, if response data is not available immediately, MHD will start to busy wait on it. Use the first model if you want to block on providing response data in the callback, or the last model if you want to use a more event-driven model with one big select loop. The third model combines a thread pool with the MHD_USE_SELECT_INTERNALLY mode, which can benefit implementations that require scalability. As said before, by default this mode only uses a single thread. When combined with the thread pool option, it is possible to handle multiple connections with multiple threads. The number of threads is specified using the MHD_OPTION_THREAD_POOL_SIZE; any value greater than one for this option will activate the use of the thread pool. In contrast to the MHD_USE_THREAD_PER_CONNECTION mode (where each thread handles one and only one connection), threads in the pool can handle a large number of concurrent connections. Using MHD_USE_SELECT_INTERNALLY in combination with a thread pool is typically the most scalable (but also hardest to debug) mode of operation for MHD. The fourth threading model (used when no specific flag is given), uses no threads. Instead, the main application must (periodically) request file descriptor sets from MHD, perform a select call and then call MHD_run. MHD_run will then process HTTP requests as usual and return. MHD_run is guaranteed to not block; however, access handlers and response processing callbacks that it invokes may block. This mode is useful if a single-threaded implementation is desired and in particular if the main application already uses a select loop for its processing. If the application is not ready to provide a response, it can just return zero for the number of bytes read and use its file descriptors in the external select loop to wake up and continue once the data is ready -- MHD will unlist the socket from the write set if the application failed to provide response data (this only happens in this mode). The testcases provided include examples for using each of the threading modes. Generating responses MHD provides various functions to create struct MHD_Response objects. A response consists of a set of HTTP headers and a (possibly empty) body. The three main ways to create a response are either by specifying a given (fixed-size) body (MHD_create_response_from_data), by providing a function of type MHD_ContentReaderCallback which provides portions of the response as needed or by providing an open file descriptor (MHD_create_response_from_fd). The first response construction is great for small and in particular static webpages that fit into memory. The second response type should be used for response objects where the size is initially not known or where the response maybe too large to fit into memory. Finally, using a file descriptor can be used on Linux systems to use the highly efficient sendfile call for the file transfer. A response is used by calling MHD_queue_response which sends the response back to the client on the specified connection. Once created, a response object can be used any number of times. Internally, each response uses a reference counter. The response is freed once the reference counter reaches zero. The HTTP server should call MHD_destroy_response when a response object is no longer needed, that is, the server will not call MHD_queue_response again using this response object. Note that this does not mean that the response will be immediately destroyed -- destruction may be delayed until sending of the response is complete on all connections that have the response in the queue. Queueing responses Clients should never create a ""100 CONTINUE"" response. MHD handles ""100 CONTINUE"" internally and only allows clients to queue a single response per connection. Furthermore, clients must not queue a response before the request has been fully received (except in the case of rejecting PUT or POST operations in HTTP 1.1). If a client attempts to queue multiple responses or attempts to queue a response early, MHD_queue_response will fail (and return MHD_NO). The callback function for the respective URL will be called at least twice. The first call happens after the server has received the headers. The client should use the last void** argument to store internal context for the session. The first call to the callback function is mostly for this type of initialization and for internal access checks. At least, the callback function should ""remember"" that the first call with just the headers has happened. Queueing a response during the first call (for a given connection) should only be used for errors -- if the client queues a response during this first call, a 100 CONTINUE response will be suppressed, the request body will not be read and the connection will be closed after sending the response. After the first call, the callback function will be called with upload data. Until *upload_data_size is zero, the callback may not queue a response, any such attempt will fail. The callback function should update *upload_data_size to indicate how many bytes were processed. Depending on available buffer space, incremental processing of the upload maybe required. Once all of the upload data has been processed, MHD will call the callback a second time with *upload_data_size being zero. At this point, the callback should queue a ""normal"" response. If queueing a response is not possible, the callback may either block or simply not queue a response depending on the threading model that is used. If the callback does not queue a response at this point, MHD will either (eventually) timeout the connection or keep calling it. Parsing of POST requests MHD includes a set of three functions for parsing and processing data received in POST requests. The functions allow incremental parsing and processing of POST data. Only a tiny fraction of the overall POST data needs to fit into memory. As a result, applications using MHD can support POST requests of arbitrary size. POST data is processed by providing MHD with a callback function that is called on portions of the received values. The POST parser itself is invoked repeatedly whenever more input bytes become available. MHD supports both uri- and multipart/form-encoded POST data. Memory Management The application can determine the size of buffers that MHD should use for handling of HTTP requests and parsing of POST data. This way, MHD users can trade-off processing time and memory utilization. Applications can limit the overall number of connections MHD will accept, as well as the total amount of memory used per connection. MHD will gracefully handle all out-of-memory situations (by closing the connection and cleaning up any remaining state). Related projects irdis-libmicrohttpd (binding of GNU libmicrohttpd to the Irdis C backend) Projects that use libmicrohttpd If you write an application that uses libmicrohttpd, please let us know so that we can add you to the list! GNUnet (P2P network) Retroshare (P2P network) P4P Portal Gnome Music Player Client CallHome Open Lighting Architecture systemd (journal gatewayd) System monitor for X Kiwix, Offline multimedia reader XBMC, entertainment hub Fawkes, robotics software OpenVAS (Greenbone Security Assistant) Syndicate, distributed storage service Flat8 (Web application engine) OCR system OpenZWave control panel (home automation) Techne, physical simulator and renderer Cables communication project Disk Nukem (disk wiping utility) Psensor (Temperature Monitor) DSLR Camera Control libhttpserver (C++ library for creating an embedded Rest HTTP server) QuickShare (share a directory via HTTP) OpenSIPs (HTTP transport layer via httpd module) volkszaehler (smart meter) Drawpile (collaborative drawing) Sauvegarde (continuous backup) bfgminer (ASIC/FPGA miner) FIWARE Orion (Publish/Subscribe Context Broker) PerfWatcher (performance monitoring) Alternatives If you are aware of a competing library that might be a better fit for some developers, please let us know so that we can add it to the list! Pion Network Library (C++) libhttpd (C) libsoup (C) neon (C) libWWW (C) EHS (C++) Medusa (Python) mihl (C) libebb (C) tntnet (C++) libonion (C) Mongoose (C) Mimosa (C++) libevhtp (C) libasyncd (C) goahead (C) appweb (C) Licensing Libmicrohttpd is free software; you can redistribute it and/or modify it under the GNU LGPL v2.1 or at your option any later version. If you disable HTTPS/SSL support, you can also choose the second license, the eCos License. If you have questions about licensing, please contact the maintainer. GNU home page FSF home page GNU Art GNU's Who? Free Software Directory Hardware Site map “Our mission is to preserve, protect and promote the freedom to use, study, copy, modify, and redistribute computer software, and to defend the rights of Free Software users.” The Free Software Foundation is the principal organizational sponsor of the GNU Operating System. Support GNU and the FSF by buying manuals and gear, joining the FSF as an associate member, or making a donation, either directly to the FSF or via Flattr. back to top Please send general FSF & GNU inquiries to <gnu@gnu.org>. There are also other ways to contact the FSF. Broken links and other corrections or suggestions can be sent to <libmicrohttpd@gnu.org>. Please see the Translations README for information on coordinating and submitting translations of this article. Copyright © 2012-2015 Free Software Foundation, Inc. This page is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License. Copyright Infringement Notification Updated: $Date: 2016/06/12 00:45:52 $"	"null"	"null"	"A small C library that makes it easy to run an HTTP server as part of another application. or later."	"true"
"Networking and Internet"	"libsoup"	"https://wiki.gnome.org/action/show/Projects/libsoup?action=show&redirect=LibSoup"	"A GNOME HTTP client/server library. Uses GObject. only."	"null"	"null"	"null"	"GNU LGPL2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"null"	"null"	"null"	"Projects/libsoup - GNOME Wiki! Projects/libsoup Home RecentChanges Schedule Login GNOME.org Redirected from page ""LibSoup"" Clear message libsoup About libsoup is an HTTP client/server library for GNOME. It uses GObjects and the glib main loop, to integrate well with GNOME applications, and also has a synchronous API, for use in threaded applications. Features include: Both asynchronous (GMainLoop and callback-based) and synchronous APIs Automatically caches connections SSL Support using GnuTLS Proxy support, including authentication and SSL tunneling Client support for Digest, NTLM, and Basic authentication Server support for Digest and Basic authentication Client and server support for XML-RPC See the libsoup client-side HOWTO and libsoup server-side HOWTO for an introduction to using the client and server APIs. Download You can check out the current development snapshot using:  git clone git://git.gnome.org/libsoup Links Releases Browse git repository Reference manual and tutorial (Development Version) libsoup-list@gnome.org libsoup product at bugzilla.gnome.org Projects/libsoup (last edited 2013-11-22 15:51:50 by DanWinship)     Search: Copyright © 2005 - 2015 The GNOME Project. Hosted by Red Hat."	"null"	"null"	"A GNOME HTTP client/server library. Uses GObject. only."	"true"
"Networking and Internet"	"lwan"	"https://github.com/lpereira/lwan"	"An experimental, scalable, high-performance HTTP server. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"3644"	"284"	"448"	"GitHub - lpereira/lwan: Experimental, scalable, high performance HTTP server Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 284 Star 3,644 Fork 448 lpereira/lwan Code Issues 32 Pull requests 2 Wiki Pulse Graphs Experimental, scalable, high performance HTTP server https://lwan.ws 1,516 commits 2 branches 0 releases Fetching contributors C 96.5% CMake 2.6% Other 0.9% C CMake Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master website Nothing to show Nothing to show New pull request Latest commit 2f01bd0 Jul 12, 2016 lpereira Duplicate names in module registry … The module registry hash table was storing pointer to a memory region within the stack of a call frame that would be long gone whenever the hash table would be freed or consulted. Permalink Failed to load latest commit information. common Duplicate names in module registry Jul 12, 2016 freegeoip Also include_directories(${SQLITE_INCLUDE_DIRS}) Jun 24, 2016 lwan Implement --config command line option Jul 1, 2016 techempower Also include_directories(${SQLITE_INCLUDE_DIRS}) Jun 24, 2016 testrunner Build on Mac OSX May 26, 2016 tools Work around cross-compilation issues with mimegen Jun 23, 2016 wwwroot Remove unused itworks.png file Nov 19, 2013 .gitignore Finally add .gitignore file. Mar 22, 2014 CMakeLists.txt Use #include_next instead of having a missing.h header Jul 10, 2016 COPYING Add COPYING file (GPLv2). Oct 13, 2014 README.md Add FreeBSD and OS X buildbot badges Jul 10, 2016 lwan.conf Generate a `testrunner` binary only to run the unit tests. Feb 20, 2016 lwan.pc.cmake Add Description field to lwan.pc Jun 6, 2016 test.lua Allow setting headers from Lua Sep 7, 2015 testrunner.conf Allow obtaining the request body/content-type Apr 9, 2016 README.md Lwan Web Server Lwan is a high-performance & scalable web server for glibc/Linux platforms. In development for almost 4 years, Lwan was until now a personal research effort that focused mostly on building a solid infrastructure for a lightweight and speedy web server: Low memory footprint (~500KiB for 10k idle connections) Minimal memory allocations & copies Minimal system calls Hand-crafted HTTP request parser Files are served using the most efficient way according to their size No copies between kernel and userland for files larger than 16KiB Smaller files are sent using vectored I/O of memory-mapped buffers Header overhead is considered before compressing small files Mostly wait-free multi-threaded design Diminute code base with roughly 7200 lines of C code It is now transitioning into a fully working, capable HTTP server. It is not, however, as feature-packed as other popular web servers. But it is free software, so scratching your own itches and making Lwan hum the way you want it to is possible. Features include: Mustache templating engine Used for directory listing & error messages Available for user-built handlers Easy to use API to create web applications or extend the web server Supports rebimboca da parafuseta Test suite written in Python tests the server as a black box No-nonsense configuration file syntax Supports a subset of HTTP/1.0 and HTTP/1.1 systemd socket activation IPv6 ready The web site has more details, including a FAQ about the name of the project and security concerns. Performance It can achieve good performance, yielding about 320000 requests/second on a Core i7 laptop for requests without disk access, and without pipelining. When disk I/O is required, for files up to 16KiB, it yields about 290000 requests/second; for larger files, this drops to 185000 requests/second, which isn't too shabby either. These results, of course, with keep-alive connections, and with weighttp running on the same machine (and thus using resources that could be used for the webserver itself). Without keep-alive, these numbers drop around 6-fold. Portability Although it uses epoll and the Linux variant of sendfile(), it is fairly portable to other event-based pollers, like kqueue. Porting for FreeBSD and OS X is a work in progress. It works on FreeBSD, but the module registry can't find any module and/or handlers (so it's essentially only serves 404 pages at the moment). Help to fix this is appreciated. Building Before installing Lwan, ensure all dependencies are installed. All of them are common dependencies found in any GNU/Linux distribution; package names will be different, but it shouldn't be difficult to search using whatever package management tool that's used by your distribution. Required dependencies CMake, at least version 2.8 ZLib Optional dependencies The build system will look for these libraries and enable/link if available. SQLite 3 Lua 5.1 or LuaJIT 2.0 Client libraries for either MySQL or MariaDB TCMalloc jemalloc Valgrind To run test suite, Python (2.6+) with Requests module is required Common operating system package names Minimum to build ArchLinux: pacman -S cmake zlib FreeBSD: pkg install cmake pkgconf Ubuntu 14+: apt-get update && apt-get install git cmake zlib1g-dev pkg-config Build all examples ArchLinux: pacman -S cmake zlib sqlite luajit libmariadbclient gperftools valgrind FreeBSD: pkg install cmake pkgconf sqlite3 lua51 Ubuntu 14+: apt-get update && apt-get install git cmake zlib1g-dev pkg-config lua5.1-dev libsqlite3-dev libmysqlclient-dev Build commands Clone the repository ~$ git clone git://github.com/lpereira/lwan ~$ cd lwan  Create the build directory ~/lwan$ mkdir build ~/lwan$ cd build  Select build type Selecting a release version (no debugging symbols, messages, enable some optimizations, etc): ~/lwan/build$ cmake .. -DCMAKE_BUILD_TYPE=Release  If you'd like to enable optimiations but still use a debugger, use this instead: ~/lwan/build$ cmake .. -DCMAKE_BUILD_TYPE=RelWithDebInfo  To disable optimizations and build a more debugging-friendly version: ~/lwan/build$ cmake .. -DCMAKE_BUILD_TYPE=Debug  Build Lwan ~/lwan/build$ make  This will generate a few binaries: lwan/lwan: The main Lwan executable. May be executed with --help for guidance. testrunner/testrunner: Contains code to execute the test suite. freegeoip/freegeoip: FreeGeoIP sample implementation. Requires SQLite. techempower/techempower: Code for the Techempower Web Framework benchmark. Requires SQLite and MySQL libraries. common/mimegen: Builds the extension-MIME type table. Used during build process. Remarks It is important to build outside of the tree; in-tree builds are not supported. Passing -DCMAKE_BUILD_TYPE=Release will enable some compiler optimizations (such as LTO) and tune the code for current architecture. Please use this version when benchmarking, as the default is the Debug build, which not only logs all requests to the standard output, but does so while holding a mutex. The default build (i.e. not passing -DCMAKE_BUILD_TYPE=Release) will build a version suitable for debugging purposes. This version can be used under Valgrind, is built with Undefined Behavior Sanitizer, and includes debugging messages that are stripped in the release version. Debugging messages are printed for each and every request. Running Set up the server by editing the provided lwan.conf; the format is very simple and should be self-explanatory. Configuration files are loaded from the current directory. If no changes are made to this file, running Lwan will serve static files located in the ./wwwroot directory. Lwan will listen on port 8080 on all interfaces. Lwan will detect the number of CPUs, will increase the maximum number of open file descriptors and generally try its best to autodetect reasonable settings for the environment it's running on. Optionally, the lwan binary can be used for one-shot static file serving without any configuration file. Run it with --help for help on that. IRC Channel There is an IRC channel (#lwan) on Freenode. A standard IRC client can be used. A web IRC gateway is also available. Lwan in the wild Here's a non-definitive list of third-party stuff that uses Lwan and have been seen in the wild. Help build this list! An experimental version of Node.js using Lwan as its HTTP server is maintained by @raadad. The beginnings of a C++11 web framework based on Lwan written by @vileda. A more complete C++14 web framework by @matt-42 offers Lwan as one of its backends. A word ladder sample program by @sjnam. Demo. A Shodan search listing some brave souls that expose Lwan to the public internet. Some other distribution channels were made available as well: A Dockerfile is maintained by @jaxgeller, and is available from the Docker registry. A buildpack for Heroku is maintained by @bherrera, and is available from its repo. Lwan is also available as a package in Biicode. User packages for Arch Linux and Ubuntu. Lwan has been also used as a benchmark: Raphael Javaux's master thesis cites Lwan in chapter 5 (""Performance Analysis""). Lwan is used as a benchmark by the PyParallel author. Kong uses Lwan as the backend API in its benchmark. TechEmpower Framework benchmarks feature Lwan since round 10. Not really third-party, but alas: The author's blog. The project's webpage. Build status Platform Release Debug Static Analysis Tests Linux Report history FreeBSD OS X Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/lpereira/lwan"	"An experimental, scalable, high-performance HTTP server. only."	"true"
"Networking and Internet"	"mongoose"	"https://github.com/cesanta/mongoose"	"Embedded web server for C. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"2844"	"327"	"916"	"GitHub - cesanta/mongoose: Mongoose Embedded Web Server Library  - Mongoose is more than an embedded webserver. It is a multi-protocol embedded networking library with functions including TCP, HTTP client and server, WebSocket, JSON-RPC client and server and much more. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 327 Star 2,844 Fork 916 cesanta/mongoose Code Issues 36 Pull requests 11 Pulse Graphs Mongoose Embedded Web Server Library - Mongoose is more than an embedded webserver. It is a multi-protocol embedded networking library with functions including TCP, HTTP client and server, WebSocket, JSON-RPC client and server and much more. https://www.cesanta.com 2,177 commits 1 branch 23 releases 75 contributors C 99.9% Makefile 0.1% C Makefile Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show 6.5 6.4 6.3 6.2 6.1 6.0 5.6 5.5_20140120 5.5 5.4 5.3 5.2 5.1 5.0 4.1 4.0 3.8 3.7 3.6 3.5 3.4 3.3 3.2 Nothing to show New pull request Latest commit 256aa02 Jul 15, 2016 rojer committed with cesantabot Fix compilation for non-MGIOT projects … That don't have CONSOLE_UART defined  PUBLISHED_FROM=7930bb639baf81cff8ce53c6f81e9739668aae08 Permalink Failed to load latest commit information. docs Fix SSL stuff Jul 14, 2016 examples Fix led toggline in CC3200 sensor demo Jul 13, 2016 jni !): Fix for compile error in Android. Jul 6, 2016 CONTRIBUTING.md Add contribution files Feb 15, 2016 LICENSE Add LICENSE file to F&C, update dates Feb 13, 2016 README.md Ditch JSON-RPC from mongoose Jul 1, 2016 mongoose.c Fix compilation for non-MGIOT projects Jul 15, 2016 mongoose.h Fix SSL stuff Jul 14, 2016 README.md Mongoose - Embedded Web Server / Embedded Networking Library Mongoose is ideal for embedded environments. It has been designed for connecting devices and bringing them online. On the market since 2004, used by vast number of open source and commercial products - it even runs on space stations! Mongoose makes embedded network programming fast, robust, and easy. If you're looking for a pre-compiled Windows or Mac binary, Download pre-compiled Mongoose web server binary Alternatively, Download Mongoose Source Code here Check our latest releases Read User Guide and API reference Study mongoose example code If you are looking for a complete solution with firmware and cloud components, check out Mongoose IoT Platform. Support Support Forum - Ask your technical questions here Chat - Visit www.cesanta.com for our live chat Commercial one-to-one support - Available to all commercial license holders Features Cross-platform: works on Linux/UNIX, MacOS, QNX, eCos, Windows, Android, iPhone, FreeRTOS (TI CC3200, ESP8266), etc Single-threaded, asynchronous, non-blocking core with simple event-based API Native support for PicoTCP embedded TCP/IP stack, LWIP embedded TCP/IP stack Builtin protocols: plain TCP, plain UDP, SSL/TLS (over TCP, one-way or two-way) HTTP client, HTTP server WebSocket client, WebSocket server MQTT client, MQTT broker CoAP client, CoAP server DNS client, DNS server, async DNS resolver Tiny static and run-time footprint Source code is both ISO C and ISO C++ compliant Very easy to integrate: just copy mongoose.c and mongoose.h files to your build tree Licensing Mongoose is released under commercial and GNU GPL v.2 open source licenses. Commercial Projects: Once your project becomes commercialised GPLv2 licensing dictates that you need to either open your source fully or purchase a commercial license. Cesanta offer full, royalty-free commercial licenses without any GPL restrictions. If your needs require a custom license, we’d be happy to work on a solution with you. Contact us for pricing. Prototyping: While your project is still in prototyping stage and not for sale, you can use Mongoose’s open source code without license restrictions. Dashboard Example Mongoose is often used to implement device dashboards and real-time data exchange over Websocket. Here is a dashboard example that illustrates the functionality: Developing a new product? Contact us today to discuss how Mongoose can help Contributions To submit contributions, sign Cesanta CLA and send GitHub pull request. You retain the copyright on your contributions. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/cesanta/mongoose"	"Embedded web server for C. only."	"true"
"Networking and Internet"	"nanomsg"	"https://github.com/nanomsg/nanomsg"	"A C-based implementation of ZeroMQ.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"2926"	"351"	"464"	"GitHub - nanomsg/nanomsg: nanomsg library Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 351 Star 2,926 Fork 464 nanomsg/nanomsg Code Issues 37 Pull requests 10 Pulse Graphs nanomsg library 1,531 commits 7 branches 12 releases 77 contributors C 87.6% C++ 10.5% CMake 1.9% C C++ CMake Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags gh-pages master sync tcpmux travis ws ws2 Nothing to show 1.0.0 1.0.0-rc2 1.0.0-rc1 0.9-beta 0.8-beta 0.7-beta 0.6-beta 0.5-beta 0.4-beta 0.3-beta 0.2-alpha 0.1-alpha Nothing to show New pull request Latest commit 7e12a20 Jun 25, 2016 gdamore fixes #770 Please correct the typo in the BUILD section Permalink Failed to load latest commit information. demo fixes #759 Add some demo programs Jun 6, 2016 doc fixes #386 loop prevention code missing Jun 3, 2016 perf fixes #732 performance tests should set max receive size option (fix … May 30, 2016 rfc fixes #604 in-band message type incorrect in sp-ipc-mapping-01.txt Apr 12, 2016 src fixes #768 NN_MAXTTL missed in nn_symbol Jun 25, 2016 tests fixes #763 tcp_shutdown windows races Jun 9, 2016 tools fixes compiler warnings about code paths that could dereference a NUL… May 11, 2016 .appveyor.yml fixes #698 AppVeyor cannot run -j4 May 11, 2016 .gitignore fixes #749 gitignore lists stuff from autotools Jun 3, 2016 .travis.yml fixes #716 No longer need travis deploy. (forgot make dist) May 15, 2016 .version fixes #765 Release 1.0.0 Jun 10, 2016 AUTHORS fixes #734 Update AUTHORS May 26, 2016 CMakeLists.txt fixes #771 reqttl test fail on osx Jun 21, 2016 COPYING Copyright transfer from 250bpm s.r.o. to Martin Sustrik Nov 12, 2014 README fixes #770 Please correct the typo in the BUILD section Jun 25, 2016 README.md fixed README Jan 9, 2013 RELEASING fixes #728 Source archives missing .version == Unknown version May 25, 2016 configure fixes #761 ./configure syntax error with dash Jun 7, 2016 README.md Welcome to nanomsg The nanomsg library is a simple high-performance implementation of several ""scalability protocols"". These scalability protocols are light-weight messaging protocols which can be used to solve a number of very common messaging patterns, such as request/reply, publish/subscribe, surveyor/respondent, and so forth. These protocols can run over a variety of transports such as TCP, UNIX sockets, and even WebSocket. For more information check the website. Prerequisites Windows. Windows Vista or newer (Windows XP and 2003 are NOT supported) Microsoft Visual Studio 2010 (including C++) or newer, or mingw-w64 (Specifically mingw and older Microsoft compilers are *NOT supported) CMake 2.8.7 or newer, available in $PATH as cmake POSIX (Linux, MacOS X, UNIX) ANSI C compiler supporting C89 POSIX pthreads (should be present on all modern POSIX systems) BSD sockets support for both TCP and UNIX domain sockets CMake (http://cmake.org) 2.8.7 or newer, available in $PATH as cmake Documentation (optional) asciidoctor (http://asciidoctor.org/) available as asciidoctor If not present, docs are not formatted, but left in readable ASCII Also available on-line at http://nanomsg.org/documentation Build it with CMake Go to the root directory of the local source repository. To perform an out-of-source build, run: mkdir build cd build cmake .. (You can add -DCMAKE_INSTALL_PREFIX=/usr/local or some other directory.) cmake --build . ctest -C Debug . cmake --build . --target install NB: This may have to be done as a privileged user. (Linux only). ldconfig (As a privileged or root user.) Resources Website: http://nanomsg.org Source code: https://github.com/nanomsg/nanomsg Documentation: http://nanomsg.org/documentation.html Bug tracker: https://github.com/nanomsg/nanomsg/issues Mailing list: nanomsg@freelists.org Gitter Chat: https://gitter.im/nanomsg/nanomsg IRC chatroom: #nanomsg at irc.freenode.net/8001 Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/nanomsg/nanomsg"	"A C-based implementation of ZeroMQ.."	"true"
"Networking and Internet"	"onion"	"https://github.com/davidmoreno/onion"	"HTTP server library, designed to be easy to use.."	"null"	"null"	"null"	"Apache2.0"	"http://directory.fsf.org/wiki/License:Apache2.0"	"null"	"null"	"1058"	"72"	"127"	"GitHub - davidmoreno/onion: C library to create simple HTTP servers and Web Applications. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 72 Star 1,058 Fork 127 davidmoreno/onion Code Issues 18 Pull requests 0 Wiki Pulse Graphs C library to create simple HTTP servers and Web Applications. http://www.coralbits.com/libonion/ 1,085 commits 13 branches 11 releases 23 contributors C 74.2% C++ 19.8% CMake 3.6% Scilab 1.2% Other 1.2% C C++ CMake Scilab Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags bstarynk-master darwin docs fixtimeouts freebsd manpages master nomalloc onion-0-8 parser-ng python stable timerpoller Nothing to show v0.8 v0.7 v0.5 v0.4 v0.3 v0.2 0.7 0.5 0.4 0.3 0.2 Nothing to show New pull request Latest commit 5026256 Jun 23, 2016 davidmoreno Fix #186. Do not declare variable at for statement. Permalink Failed to load latest commit information. debian Updated debian package version to 0.8. May 4, 2016 examples add closing button to websocket example Jun 10, 2016 gentoo Add Redis support to the gentoo ebuild. Dec 31, 2015 manpages Wording fixes. Apr 24, 2016 src indent with tabs rather than spaces Jun 22, 2016 tests Fix #186. Do not declare variable at for statement. Jun 23, 2016 toolchain refreshed gentoo ebuild, cosmetics in bin, lib, include install dirs Feb 5, 2014 tools Fix a memory leak found in otemplate. Mar 15, 2016 .gitignore Updated gitignore Apr 16, 2016 .travis.yml removing dist:trusty from travis.yml Jun 15, 2016 AGPL.txt License changed for the library to LGPL. Examples and tests remain AGPL. Jul 4, 2011 APACHE2.txt Updated license on the library source code to Apache2 + GPLv2+. Examp… Feb 9, 2014 CMakeLists.txt Added -D_ISOC99_SOURCE to allow use of clock_gettime on older browsers. May 28, 2016 CPackConfig.cmake Fixed build, changed README.rst to README.md at cpack. Dec 27, 2014 Doxyfile Added doxygen groups for documentation. Only document C bindings. Apr 29, 2016 GPLv2.txt Update C++ bindings, adding easy way to compose urls, just using the … Feb 19, 2014 LICENSE.txt Fixed where documentation says its only GPLv2, as it is GPLv2+. May 15, 2014 README.md Removed analytics from README. May 4, 2016 git-version-gen Git version gen looks for all tags, not just annotated May 4, 2016 README.md Onion http server library Travis status Coverity status Onion is a C library to create simple HTTP servers and Web Applications. master the development branch. Current stable branch is onion-0-8. Introduction The use case is an existing application, or a new one, that needs some HTTP interconnection with the world. It uses the library to add some handlers for specific URLs and generate and serve the dynamic data as needed. It also has security goals (SSL support) so that you just concentrate on what you want to serve, and serve it. Its not a web server per se, as it is not an executable. If you want to compare to a web server, a web server would use a module or plugin to add some functionality. With libonion you have the functionality and add the webserver as a plugin. There is a wiki available at https://github.com/davidmoreno/onion/wiki, with useful information on how to get started using Onion and it's internal workings. API documentation is at http://coralbits.com/static/onion/. There is a mailing list at https://groups.google.com/a/coralbits.com/forum/?fromgroups=#!forum/onion-dev Collaborate! You can, and are encouraged, to branch at github, download and tweak onion to use it in your projects. The library is dual licensed under the Apache2 license and GPLv2+, so you can make almost anything with it, use it in your commercial and free software programs, and modify it to your needs. Please join the mailing list at https://groups.google.com/a/coralbits.com/group/onion-dev/topics, to ask your questions and comment on your success using onion. There is also a blog to keep everybody informed about news on onion at http://blog.coralbits.com/. Download There are third party packages available: RPM based: http://software.opensuse.org/download.html?project=home%3Admoreno&package=onion Raspberry pi: http://packages.aisoy.com/debian/pool/unstable/libo/libonion/ Arch Linux: https://aur.archlinux.org/packages/libonion-git/ If you know of any other packaged version, please send me a note. As always they may be outdated, if you want the latest and greatest, do a manual compile and install. Thanks to Ruediger Meier for helping for so long with the RPM packages. Compile and Install Manual compile and install:      $ git clone git@github.com:davidmoreno/onion.git      $ cd onion      $ mkdir build      $ cd build      $ cmake ..      $ make      $ sudo make install To compile with debugging enabled, use     $ cmake -DCMAKE_BUILD_TYPE=Debug .. To run with some debug messages, set the ONION_DEBUG and/or ONION_DEBUG0 environment variable containing some source file names, e.g.     $ export ONION_DEBUG0='request.c url.c' Dependencies Required: C compiler cmake make This compilers and minimum versions are known to work: Linux: GCC 4.4 clang 3.0 For the C++ bindings a C++11 compiler is needed: Linux: GCC 4.8 clang 3.7 Optional; Onion will compile but some functionality will not be available: gnutls and gcrypt (SSL support) pthreads (threading support) libxml2 (WebDAV support) libpam (HTTP Basic Auth support using PAM) C++ compiler Systemd (support for listening on systemd sockets) sqlite3 (sqlite3 session backend) hiredis (Redis session backend) Optional for examples: cairo libpng2 boehm gc libjpeg Semantic versioning. Starting with Onion 0.8.0, we use semantic versioning, making the following promises: Version format is [MAJOR].[MINOR].[PATCH]. Only make API and ABI changes at major versions. Can add functionalities at minor releases. Only remove API functions at major versions. No changes in semantics never. Minor versions are always ABI back-compatible. This means that if you compiled with a previous minor version and same major version, it will still compile and work. Only add API functions at minor versions. Only fix patches a patch revisions. Patch revisions are is a non sequential number, so after 0.8.0 is not 0.8.1, but maybe 0.8.23. It will always increase. Check onion/version.h for more information on version control. SSL Support If at compile time the build script finds the gnutls libraries, SSL support will be compiled in. It can be deactivated anyway at ./CMakeLists.txt. To use it you have to set the certificates, and you can check if its on, checking the flag O_SSL_ACTIVATED. If support is not compiled in, then the library will not use SSL, but for the user of the library the interface is the same; it will only change that when trying to set the certificates it will fail. Anwyay for clients its just to use the interface and they dont care at all if suport is in or not. No more than being able to use SSL. This is not mandatory because there may be moments when the program's users do not want to support SSL for whatever reasons, for example speed. Threads support Currently there are two threading modes. It can be set so the server is created as threaded (O_THREADED), and it will create a new thread per connection. There is no data protection as on the listen phase there should not be any change to onion structures. Nevertheless if new handlers are created they must set their own threading support as neccesary. It can be deactivated at CMakeLists.txt. If no pthreads lib is found on the system, it is not compiled in. Also when thread support is on, onion server can be set to work on another (non-main) thread. This is independant from O_THREADED operation; it can have one thread with your normal application and another thread that listens and processes web-requests. Its set with the O_DETACH_LISTEN flag. This is very useful when adding an extra web server to your application so it can be added without changes to the flow of your application, but you will need to thread protect your data if you access to it from the web server. Finally there is a pool mode. Users can set a default number of threads (onion_set_max_threads), and using epoll the data is given to the threads. This is the highest performant method, with up to 30k web-requests served on a Intel(R) Core(TM)2 Duo CPU T6500 @2.10GHz. Customizing low-level allocation and threads Sometimes it may be needed to customize memory allocation and/or threads operation. This could be useful when using an alternative malloc, or if you wanted to use Hans Boehm's conservative garbage collector from http://www.hboehm.info/gc/ e.g. if you use GNU guile. Then you need to define your own memory routines and pass them to onion_low_initialize_memory_allocation before any other calls to onion. Likewise, to customize threads operations, call onion_low_initialize_threads. See comments in header file low.h. A program using Onion and Boehm's GC should first define a memory failure routine which should never return:     /* the memory failure routine should never return! */     static void memory_failure(const char*msg) {       perror(msg);       exit(EXIT_FAILURE);     }; Then, your program (using both onion and Boehm's GC) should initialize both memory routines and threads, like:     onion_low_initialize_memory_allocation       (GC_malloc,  GC_malloc_atomic,  GC_calloc,        GC_realloc, GC_strdup, GC_free,        memory_failure);     onion_low_initialize_threads       (GC_pthread_create, GC_pthread_join,        GC_pthread_cancel, GC_pthread_detach,        GC_pthread_exit, GC_pthread_sigmask); You might need to define your GC_calloc using GC_malloc and memset if your version of Boehm's GC don't provide it. After these low-level initialization you can use Onion as usual. You could also want to call just onion_low_initialize_threads if you wanted to name threads created by the onion library (using pthread_setname_np on Linux) and/or change their priority (using pthread_setschedprio), etc. ARM Support It can be cross compiled for ARM directly from cmake. Just do:     $ mkdir arm     $ cd arm     $ cmake .. -DCMAKE_TOOLCHAIN_FILE=../toolchain/arm.txt     $ make It needs the current system opack and otemplate to compile some examples, so if you want to use the examples on your instalation, compile and install libonion for the current system first. Tested on ubuntu 10.10, with gcc-4.5-arm-linux-gnueabi and g++-4.5-arm-linux-gnueabi installed. Templating support Starting on 0.3.0 development onion has templating support via otemplate. It is a template system similar to django templates (http://docs.djangoproject.com/en/dev/topics/templates/). Check more information on how to use them at tools/otemplate/README.rst. I18N There is I18N support. Check wiki for details or fileserver_otemplate example. Systemd Systemd is integrated. If want to use it, just pass the flag O_SYSTEMD to the onion_new(). Oterm has example socket and service files for oterm support. FreeBSD/Darwin Since september 2013 there is support for FreeBSD using libev or libevent. This work is not as tested as the Linux version, but if some compilation error arises, please send the bug report and we will fix it ASAP. OSX/Darwin support is also available on the darwin branch. Once this work stabilizes it will be merged back to master. Environment variables You can set the following environment variables -e.g. with the export builtin of bash- to modify runtime behaviour of onion: ONION_LOG noinfo -- Disables all info output to the console, to achieve faster results nocolor -- Disable color use by the log nodebug -- Do not show debug lines syslog -- Log to syslog. Can be changed programatically too, with the onion_log global function. ONION_DEBUG0 -- Set the filename of a c source file, and DEBUG0 log messages are written. This is normally very verbose. ONION_SENDFILE -- Set to 0 do disable sendfile. Under some file systems it does not work. Until a detection code is in place, it can be disabled with this. Binary compatibility breaks We try hard to keep binary compatibility, but sometimes its hard. Here is a list of ABI breaks: 0.4.0 Onion object private flags have moved. If on your code you rely on them, must recompile. If dont rely on them, everything should keep working. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/davidmoreno/onion"	"HTTP server library, designed to be easy to use.."	"true"
"Networking and Internet"	"oSip"	"https://gnu.org/software/osip/"	"A SIP implementation in C without additional dependencies. or later."	"null"	"null"	"null"	"GNU LGPLv2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"null"	"null"	"null"	"The GNU oSIP library - GNU Project - Free Software Foundation (FSF) The GNU oSIP library [ English ] Table of Contents Introduction to the GNU oSIP library antisip services Related software oSIP capabilities Download area Documentation SIP related links Mailing Lists Authors Introduction to the GNU oSIP library oSIP is an LGPL implementation of SIP. It's stable, portable, flexible and compliant! -may be more-! It is used mostly with eXosip2 stack (GPL) which provides simpler API for User-Agent implementation. SIP stands for the Session Initiation Protocol and is described by the rfc3261 (wich deprecates rfc2543). This library aims to provide multimedia and telecom software developers an easy and powerful interface to initiate and control SIP based sessions in their applications. SIP is a open standard replacement from IETF for H323. antisip services antisip is my own company. It was started in january 2005 to provide services around SIP and freesoftware. We offer support, training, bug fixes, help and software. Please, come and visit us! Related software eXosip, GPL. This is a library based on oSIP. It contains a high layer easier to use for implementing SIP End point. linphone, GPL. linphone is a SIP webphone with support for several different codecs including speex. osip/eXosip has been tested at several SIPit and compliance with most vendors has been verified. oSIP capabilities The GNU oSIP library is written in C and get no dependencies except the standard C library. oSIP is thread safe and will generally be used in a multi-threaded application. Nevertheless, this is optional. oSIP is little in size and code and thus could be use to implement IP soft-phone as well as embedded SIP software. oSIP is not limited to endpoint agents, and can also be used to implement ""SIP proxy"". oSIP does not intend to provide a high layer API for controlling ""SIP Session"" at this step. Instead, it currently provides an API for the SIP message parser, SDP message parser, and library to handle ""SIP transactions"" as defined by the SIP document. Downloading area oSIP CVS is located on savannah: http://savannah.gnu.org/projects/osip/ oSIP can be found on http://ftp.gnu.org/gnu/osip/ or one of the mirrors. If the above links does not work, new versions of osip can be found there Documentation The documentation is produced with DOXYGEN. It contains various ""How-to"" in the module page which you will find usefull if you are using osip for the first time. There is also some general notes on the main page that describes history and available features of the GNU oSIP stack. in html format. Old documentation is still available in ps and pdf format: in pdf format. in ps format. The above documentation is not regularly updated, you may get a newer API documentation at http://www.antisip.com/doc/ The new one can be rebuilt with the DoxyGen tools. SIP related links Latest SIP RFC: http://www.ietf.org/rfc/rfc3261.txt Reliability of Provisional Responses in the Session Initiation Protocol (SIP: http://www.ietf.org/rfc/rfc3262.txt Session Initiation Protocol (SIP): Locating SIP Servers http://www.ietf.org/rfc/rfc3263.txt An Offer/Answer Model with the Session Description Protocol (SDP) http://www.ietf.org/rfc/rfc3264.txt Session Initiation Protocol (SIP)-Specific Event Notification http://www.ietf.org/rfc/rfc3265.txt SIP forum: http://www.sipforum.com IETF's SIP page: http://www.ietf.org/html.charters/sip-charter.html SIP Working group Supplemental Home Page: http://www.softarmor.com/sipwg/ SIP rfc (deprecated): http://www.ietf.org/rfc/rfc2543.txt Mailing Lists On 21th Of May 2012, official mailing list has been moved to osip-dev@gnu.org. The old osip@atosc.org mailing list has been down for almost one year and I wasn't able maintain it alive. New Mailing list archive: http://lists.gnu.org/archive/html/osip-dev/ Old Mailing list archive: http://www.atosc.org/pipermail/osip/ You can subscribe to the mailing list with by sending a mail to <osip-dev-request@gnu.org> with the subject set to ""subscribe"". Messages can be posted directly to the mailing list to <osip-dev@gnu.org>. Authors Aymeric MOIZARD <amoizard_at_gmail.com> Antisip (me again) [ English ] Return to GNU's home page. Please send FSF & GNU inquiries & questions to gnu@gnu.org. There are also other ways to contact the FSF. Please send comments on these web pages to webmasters@gnu.org, send other questions to gnu@gnu.org. Copyright © 2012 Aymeric MOIZARD. Verbatim copying and distribution of this entire article is permitted in any medium, provided this notice is preserved. Updated: $Date: 2012/05/21 07:48:36 $ $Author: aymeric $"	"null"	"null"	"A SIP implementation in C without additional dependencies. or later."	"true"
"Networking and Internet"	"pig"	"https://github.com/rafael-santiago/pig"	"A Linux packet crafting tool.."	"null"	"null"	"null"	"GPL2"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"241"	"17"	"16"	"GitHub - rafael-santiago/pig: A Linux packet crafting tool Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 17 Star 241 Fork 16 rafael-santiago/pig Code Issues 0 Pull requests 0 Pulse Graphs A Linux packet crafting tool 137 commits 4 branches 0 releases Fetching contributors C 100.0% C Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master v0.0.1 v0.0.2 v0.0.3 Nothing to show Nothing to show New pull request Latest commit 665f46a May 1, 2016 rafael-santiago Typo Permalink Failed to load latest commit information. doc Typo May 1, 2016 etc Updating the main README.md Mar 17, 2016 pigsty Adding a pigsty based on ARP spoofing Mar 17, 2016 src Implementing the --targets dependecy check for ARP signatures Mar 18, 2016 .gitmodules Replacing libcute for libcutest Jun 2, 2015 COPYING Issue#1: Adding to the repo the GPL copy Jul 19, 2015 README.md Updating the main README.md Mar 17, 2016 RELNOTES.md Typo May 1, 2016 README.md Pig Pig (which can be understood as Packet intruder generator) is a Linux packet crafting tool. You can use Pig to test your IDS/IPS among other stuffs. Pig brings a bunch of well-known attack signatures ready to be used and you can expand this collection with more specific things according your requirements. Until now it is possible to create IPv4 signatures with transport layer based on TCP, UDP and ICMP. You can also create signatures based on ARP protocol. How to clone this repo? It is pretty simple: git clone https://github.com/rafael-santiago/pig pig cd pig git submodule update --init  How to build it? You need to use the Hefesto to build pig. After following the steps to put Hefesto working on your system. Move to the pig subdirectory named as src and run the following command: hefesto After this command you should find the pig binary under the path src/bin. The pigsty files Pigsty files are plain text files where you can define a set of packet signatures. There is a specific syntax to be followed. Look out an example of a pigsty file: [ signature   =      ""Hello"",   ip.version  =            4,   ip.ihl      =            5,   ip.tos      =            0,   ip.src      = 192.30.70.10,   ip.dst      =  192.30.70.3,   ip.protocol =           17,   udp.dst     =         1008,   udp.src     =        32000,   udp.payload =    ""Hello!!"" ]  Basically, all signature data must goes between square brackets: [ ... ]. Inside this area the piece of information is supplied by the scheme field = data. If you have some experience with Computer Networks is sure that the majority of fields listed on Table 1 have strong meaning for you. You must use these fields to create your further signatures. Table 1: The pig signature fields. Field Stands for Protocol Data type Sample definition signature The signature name - string signature = ""Udp flood"" ip.version IP version IP number ip.version = 4 ip.ihl Internet Header Len IP number ip.ihl = 5 ip.tos Type of service IP number ip.tos = 0 ip.tlen Total Length IP number ip.tlen = 20 ip.id Packet ID IP number ip.id = 0xbeef ip.flags IP Flags IP number ip.flags = 4 ip.offset Fragment offset IP number ip.offset = 0 ip.ttl Time to live IP number ip.ttl = 64 ip.protocol Protocol IP number ip.protocol = 6 ip.checksum Checksum IP number ip.checksum = 0 ip.src Source address IP ip address ip.src = 192.30.70.3 ip.dst Dest. address IP ip address ip.dst = 192.30.70.3 ip.payload IP raw payload IP string ip.payload = ""\x01\x02"" tcp.src Source port TCP number tcp.src = 80 tcp.dst Dest. port TCP number tcp.dst = 21 tcp.seqno Sequence number TCP number tcp.seqno = 10202 tcp.ackno Acknowledge number TCP number tcp.ackno = 10200 tcp.size TCP Length TCP number tcp.size = 4 tcp.reserv TCP reserv. field TCP number tcp.reserv = 0 tcp.urg TCP urg. flag TCP bit tcp.urg = 0 tcp.ack TCP ack. flag TCP bit tcp.ack = 1 tcp.psh TCP psh. flag TCP bit tcp.psh = 0 tcp.rst TCP psh. flag TCP bit tcp.rst = 0 tcp.syn TCP syn. flag TCP bit tcp.syn = 0 tcp.fin TCP fin. flag TCP bit tcp.fin = 0 tcp.wsize TCP window size TCP number tcp.wsize = 0 tcp.checksum Checksum TCP number tcp.checksum = 0 tcp.urgp Urgent pointer TCP number tcp.urgp = 0 tcp.payload Payload TCP string tcp.payload = ""\x01abc"" udp.src Source port UDP number udp.src = 53 udp.dst Dest. port UDP number udp.dst = 7 udp.size UDP Length UDP number udp.size = 8 udp.checksum Checksum UDP number udp.checksum = 0 udp.payload Payload UDP number udp.payload = ""boo!"" icmp.type ICMP type ICMP number icmp.type = 0 icmp.code ICMP code ICMP number icmp.code = 0 icmp.checksum Checksum ICMP number icmp.checksum = 0 icmp.payload Payload ICMP string icmp.payload = ""ping!"" arp.hwtype ARP hardware type ARP number arp.hwtype = 0x1 arp.ptype ARP protocol type ARP number arp.ptype = 0x0800 arp.hwlen ARP hardware length ARP number arp.hwlen = 6 arp.opcode ARP operation code ARP number arp.opcode = 2 arp.hwsrc ARP src hw address ARP string arp.hwsrc = ""de:ad:be:ef:0:0"" arp.psrc ARP src proto addr ARP ip address arp.psrc = 192.30.70.3 arp.hwdst ARP dst hw address ARP string arp.hwdst = ""de:ad:be:ef:0:0"" arp.pdst ARP dst proto addr ARP ip address arp.pdst = 192.30.70.3 When creating a signature you do not need specify all data. If you specify only the most relevant packet parts the remaining parts will be filled up with default values. The checksums are always recalculated. Tip: take a look in subdirectory pigsty. You will find lots of signature files and you will see that is pretty simple define new ones. Specifying IP addresses geographically Yes, this is possible. In order to use this feature you just need to specify the values listed on Table 2 in ip adddress typed fields. Table 2: IPs by geographic area. Value to use Stands for north-american-ip IP addresses from North America south-american-ip IP addresses from South America asian-ip IP addresses from Asia european-ip IP addresses from Europe Specifying my own addresses You should in any ip address typed field use user-defined-ip as value. Note that you need to use the command line option --targets in this case. See section ""Using pig"" for more information. Contribute sending more packet signatures If you create pigsty files that you judge be relevant beyond your own environment open a pull request in order to include these useful files here. Thank you in advance! Using pig The Pig usage is very straightforward being necessary to supply four basic options which are: --signatures, --gateway, --net-mask, --lo-iface. Do you want to know more about each option, huh?... So let's go: The option --signatures receives a list of file paths to pigsty files. The option --gateway is where you specify your gateway address. Be aware that pig generates or at least try to generate the ethernet frames too. Due to it the gateway address is rather important in order to right composition of the layer-1 data. The option --net-mask for routing issues must receive your network mask. The option --lo-iface is the place where you should inform the name of the local network interface you will use to ""drain out"" the generated packets. The option --no-gateway indicates that any packet will send outside the network. Supposing that we want to generate DDos based traffic: pig --signatures=pigsty/ddos.pigsty --gateway=10.0.2.2 --net-mask=255.255.255.0 --lo-iface=eth0  Now we want to messing around with everything: pig --signatures=pigsty/ddos.pigsty,pigsty/attackresponses.pigsty,pigsty/badtraffic.pigsty,pigsty/backdoors.pigsty --gateway=10.0.2.2 --net-mask=255.255.255.0 --lo-iface=eth0  Extra options Defining timeouts between the signature sendings For it use the option --timeout=<millisecs> Echo suppressing Use the --no-echo option. Defining targets Use the --targets option. You can specify a list based on exact IPs, IP masks and CIDRs. Look this: pig --signatures=pigsty/local-mess.pigsty --targets=192.30.70.3,192.30.70.*,192.30.70.0/9 --gateway=10.0.2.2 --net-mask=255.255.255.0 --lo-iface=eth0  Not using the gateway This is useful when the loaded signatures will not send data outside the current network. In order to flag it you need to use the option --no-gateway. When the --no-gateway option is used you do not need to specify the gateway's address because the packets will not flow outside the current segment. As result to inform the network mask becomes irrelevant too. For instance: pig --signatures=pigsty/local_traffic.pigsty --no-gateway --lo-iface=eth2  In the sample above the ethernet frame will not be a pig's responsibility anymore. For this reason pig will not complain about the lack of --gateway and --net-mask option. The --no-gateway option is rather handy in cases that you need to generate ARP traffic. Take a look in this another document explaining how to perform ARP spoofing with pig. Sending only one signature and going back Maybe you need to send only one signature and so return to the caller in order to check what happened after. This kind of requirement is common when you use this application as support for system tests or unit tests. So, if you need to do this you should try to use the option --single-test: pig --signature=pigsty/syn-scan.pigsty --targets=127.0.0.1 --single-test --gateway=10.0.2.2 --net-mask=255.255.255.0 --lo-iface=eth0  After run this command pig will select only one signature from the file syn-scan.pigsty and try to send it and then exit. If some error has occurred during the process pig will exit with exit-code equals to 1 otherwise pig will exit with exit-code equals to 0. Testing from scratch Save the following data as ""oink.pigsty"": [ signature   =           ""oink"",   ip.version  =                4,   ip.ihl      =                5,   ip.tos      =                0,   ip.src      =        127.0.0.1,   ip.dst      =  user-defined-ip,   ip.protocol =               17,   udp.dst     =             1008,   udp.src     =            32000,   udp.payload =        ""Oink!!\n"" ]  On another tty run the netcat in UDP mode listen for connections on port 1008: nc -u -l -p 1008  Now run pig using this pigsty file and informing as target the loopback: pig --signatures=oink.pigsty --targets=127.0.0.1 --gateway=10.0.2.2 --net-mask=255.255.255.0 --lo-iface=eth0  The netcat should start receive several oinks and... yes, congrats!! pig is up and running on your system! ;) Try to sniff your Network to get more information about these UDP packets that are flowing around your interfaces... Have fun! Santiago. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/rafael-santiago/pig"	"A Linux packet crafting tool.."	"true"
"Networking and Internet"	"s2n"	"https://github.com/awslabs/s2n"	"A C99 implementation of the TLS/SSL protocols, designed to be simple, fast and with security as a priority.."	"null"	"null"	"null"	"Apache2.0"	"http://directory.fsf.org/wiki/License:Apache2.0"	"null"	"null"	"2312"	"154"	"201"	"GitHub - awslabs/s2n: s2n : an implementation of the TLS/SSL protocols Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 154 Star 2,312 Fork 201 awslabs/s2n Code Issues 33 Pull requests 7 Pulse Graphs s2n : an implementation of the TLS/SSL protocols 658 commits 1 branch 0 releases 36 contributors C 96.2% Makefile 1.9% Python 1.4% Shell 0.5% C Makefile Python Shell Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Latest commit ed94d7c Jul 13, 2016 raycoll committed on GitHub Merge pull request #241 from colmmacc/master … Add support for session caching Permalink Failed to load latest commit information. .travis Merge pull request #238 from colmmacc/master Jun 20, 2016 api Add TTL to the store callback Jul 12, 2016 bin Update function signature Jul 12, 2016 crypto Merge pull request #260 from alexw91/addGuards Jul 7, 2016 docs Use TTL value Jul 12, 2016 error Add HKDF tests and fix style Jul 6, 2016 lib Support builds with existing libcrypto May 17, 2016 libcrypto-build Add full instructions for building OpenSSL locally Feb 27, 2015 libcrypto-root Add libcrypto README back Mar 12, 2015 stuffer Add support for session caching Jun 27, 2016 tests Merge pull request #241 from colmmacc/master Jul 13, 2016 tls Merge pull request #241 from colmmacc/master Jul 13, 2016 utils Adds Prediction Resistance to the DRBG and RDRAND if supported Jul 1, 2016 .gitignore Add .gitignore for generated files Jul 5, 2015 .travis.yml Use parallel make jobs for Travis unit tests Jun 17, 2016 LICENSE Adding license headers to a few files and adding a LICENSE and NOTICE… Feb 4, 2015 Makefile Add a basic handshake integration test Jun 9, 2016 NOTICE Adding license headers to a few files and adding a LICENSE and NOTICE… Feb 4, 2015 README.md Fix Build Status link in readme Jul 6, 2016 s2n.mk Support builds with existing libcrypto May 17, 2016 README.md s2n is a C99 implementation of the TLS/SSL protocols that is designed to be simple, small, fast, and with security as a priority. It is released and licensed under the Apache Software License 2.0. Using s2n The s2n I/O APIs are designed to be intuitive to developers familiar with the widely-used POSIX I/O APIs, and s2n supports blocking, non-blocking, and full-duplex I/O. Additionally there are no locks or mutexes within s2n. /* Create a server mode connection handle */ struct s2n_connection *conn = s2n_connection_new(S2N_SERVER); if (conn == NULL) {     ... error ... }  /* Associate a connection with a file descriptor */ if (s2n_connection_set_fd(conn, fd) < 0) {     ... error ... }  /* Negotiate the TLS handshake */ s2n_blocked_status blocked; if (s2n_negotiate(conn, &blocked) < 0) {     ... error ... }  /* Write data to the connection */ int bytes_written; bytes_written = s2n_send(conn, ""Hello World"", sizeof(""Hello World""), &blocked); For details on building the s2n library and how to use s2n in an application you are developing, see the API Reference. s2n features s2n implements SSLv3, TLS1.0, TLS1.1, and TLS1.2. For encryption, s2n supports 128-bit and 256-bit AES, in the CBC and GCM modes, 3DES, and RC4. For forward secrecy, s2n supports both DHE and ECDHE. s2n also supports the Server Name Indicator (SNI), Application-Layer Protocol Negotiation (ALPN) and the Online Certificate Status Protocol (OCSP) TLS extensions. SSLv3, RC4, and DHE are each disabled by default for security reasons. As it can be difficult to keep track of which encryption algorithms and protocols are best to use, s2n features a simple API to use the latest ""default"" set of preferences. If you prefer to remain on a specific version for backwards compatibility, that is also supported. /* Use the latest s2n ""default"" set of ciphersuite and protocol preferences */ s2n_config_set_cipher_preferences(config, ""default"");  /* Use a specific set of preferences, update when you're ready */ s2n_config_set_cipher_preferences(config, ""20150306"") s2n safety mechanisms Internally s2n takes a systematic approach to data protection and includes several mechanisms designed to improve safety. Small and auditable code base Ignoring tests, blank lines and comments, s2n is about 6,000 lines of code. s2n's code is also structured and written with a focus on reviewability. All s2n code is subject to code review, and we plan to complete security evaluations of s2n on an annual basis. To date there have been two external code-level reviews of s2n, including one by a commercial security vendor. s2n has also been shared with some trusted members of the broader cryptography, security, and Open Source communities. Any issues discovered are always recorded in the s2n issue tracker. Static analysis, fuzz-testing and penetration testing In addition to code reviews, s2n is subject to regular static analysis, fuzz-testing, and penetration testing. Several penetration tests have occurred, including two by commercial vendors. Unit tests and end-to-end testing s2n includes positive and negative unit tests and end-to-end test cases. Erase on read s2n encrypts or erases plaintext data as quickly as possible. For example, decrypted data buffers are erased as they are read by the application. Built-in memory protection s2n uses operating system features to protect data from being swapped to disk or appearing in core dumps. Minimalist feature adoption s2n avoids implementing rarely used options and extensions, as well as features with a history of triggering protocol-level vulnerabilities. For example there is no support for session renegotiation or DTLS. Compartmentalized random number generation The security of TLS and its associated encryption algorithms depends upon secure random number generation. s2n provides every thread with two separate random number generators. One for ""public"" randomly generated data that may appear in the clear, and one for ""private"" data that should remain secret. This approach lessens the risk of potential predictability weaknesses in random number generation algorithms from leaking information across contexts. Modularized encryption s2n has been structured so that different encryption libraries may be used. Today s2n supports OpenSSL, LibreSSL, BoringSSL, and the Apple Common Crypto framework to perform the underlying cryptographic operations. Timing blinding s2n includes structured support for blinding time-based side-channels that may leak sensitive data. For example, if s2n fails to parse a TLS record or handshake message, s2n will add a randomized delay of between 10 and 30 seconds, granular to nanoseconds, before responding. This raises the complexity of real-world timing side-channel attacks by a factor of at least tens of trillions. Table based state-machines s2n uses simple tables to drive the TLS/SSL state machines, making it difficult for invalid out-of-order states to arise. C safety s2n is written in C, but makes light use of standard C library functions and wraps all memory handling, string handling, and serialization in systematic boundary-enforcing checks. Security issue notifications If you discover a potential security issue in s2n we ask that you notify AWS Security via our vulnerability reporting page. Please do not create a public github issue. If you package or distribute s2n, or use s2n as part of a large multi-user service, you may be eligible for pre-notification of future s2n releases. Please contact s2n-pre-notification@amazon.com. Contributing to s2n If you are interested in contributing to s2n, please see our development guide. Language Bindings for s2n See our language bindings list for language bindings for s2n that we're aware of. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/awslabs/s2n"	"A C99 implementation of the TLS/SSL protocols, designed to be simple, fast and with security as a priority.."	"true"
"Networking and Internet"	"socket99"	"https://github.com/silentbicycle/socket99"	"A C99 wrapper for the BSD sockets API.."	"null"	"null"	"null"	"ISC"	"http://directory.fsf.org/wiki/License:ISC"	"null"	"null"	"72"	"4"	"6"	"GitHub - silentbicycle/socket99: Wrapper library for the BSD sockets API with a nicer C99 interface Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 4 Star 72 Fork 6 silentbicycle/socket99 Code Issues 1 Pull requests 0 Pulse Graphs Wrapper library for the BSD sockets API with a nicer C99 interface 22 commits 2 branches 2 releases 3 contributors C 94.1% Makefile 3.4% Shell 2.5% C Makefile Shell Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags develop master Nothing to show v0.2.0 v0.1.0 Nothing to show New pull request Latest commit 1491960 Oct 20, 2015 silentbicycle Mention ISC license in README. … Closes #11. Permalink Failed to load latest commit information. .gitignore README.md and .gitignore Jul 25, 2014 Makefile Add install, uninstall targets to Makefile Dec 14, 2014 README.md Mention ISC license in README. Oct 20, 2015 socket99.c Add initial support for setsockopt options in socket config. Dec 14, 2014 socket99.h Bump version to v0.2.0. Jan 2, 2015 test_all Drop sleep during tests from 1 sec to 0.1 sec Dec 14, 2014 test_socket99.c Add initial support for setsockopt options in socket config. Dec 15, 2014 README.md A wrapper library for the BSD sockets API. Why? This library trades the series of getaddrinfo, socket, connect, bind, listen, etc. functions and their convoluted, casted arguments for just one function that takes two structs (configuration and output). By creatively using C99's ""designated initializers"", the configuration struct works rather like a configuration key/value hash; the output struct contains either the socket file descriptor or error information. The sheer generality of the BSD sockets API also makes it rather unwieldy. While the sockets API can be used for a lot of esoteric things, there's no reason common use cases such as opening a TCP socket to a given host and port should take dozens of lines of code. License socket99 is released under the ISC license. Requirements This depends on C99 and a POSIX environment. You've got one of those lying around somewhere, right? Basic Usage Look at the fields in struct socket99_config listen in socket99.h, call socket99_open with a pointer to a configuration struct using the C99 designated initializer syntax. Only a few of the fields will be used, such as: socket99_config cfg = {     .host = ""127.0.0.1"",     .port = 8080,     .server = true,     .nonblocking = true, };  for a non-blocking TCP server that listens to 127.0.0.1. This function will return a bool for whether the socket was successfully created, and the result struct argument will be modified to contain a status code and either a file descriptor (on success) or error information on failure: socket99_result res;   // result output in this struct bool ok = socket99_open(&cfg, &res);  The configuration and result structs are no longer needed after the result struct's file descriptor has been saved / errors are handled, so both structs can be stack-allocated. For more usage examples, look at test_socket99.c. Running the tests To run the tests: $ make test  Note that the tests create a couple short-lived sockets on port 8080, and if that port is already in use, the tests will fail. (This may be configurable in a future release; it should probably check an environment variable but default to 8080.) Supported Use Cases Client and server TCP, UDP, and Unix domain sockets (either stream and datagram) Blocking and nonblocking IPV4, IPv6, and ""don't care"" setsockopt(2) options Future Development Capturing other common use cases for sockets would be good. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/silentbicycle/socket99"	"A C99 wrapper for the BSD sockets API.."	"true"
"Networking and Internet"	"Tox"	"https://github.com/irungentoo/toxcore"	"A communication platform, designed to be a Skype-killer. only."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"7967"	"674"	"989"	"GitHub - irungentoo/toxcore: The future of online communications. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 674 Star 7,967 Fork 989 irungentoo/toxcore Code Issues 86 Pull requests 10 Pulse Graphs The future of online communications. https://tox.chat/ 3,758 commits 2 branches 1 release 168 contributors C 90.3% C++ 5.0% M4 2.6% PHP 1.0% Python 0.5% Shell 0.5% Makefile 0.1% C C++ M4 PHP Python Shell Makefile Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master new Nothing to show api_old_version Nothing to show New pull request Latest commit 532629d Mar 19, 2016 irungentoo Merge branch 'network-test-magic' of https://github.com/roman-yepishe… … …v/toxcore Permalink Failed to load latest commit information. auto_tests Move argument comments to the end of line Feb 27, 2016 build Fix include paths Jan 1, 2016 dist-build Removed unnecessary parameters Aug 25, 2014 docs changed friends list to friend list Oct 23, 2015 m4 Build system now automatically enables epoll support in TCP server Jul 17, 2014 other Merge branch 'make-dist' of https://github.com/roman-yepishev/toxcore Mar 13, 2016 super_donators Added my pixfile! Dec 12, 2015 testing fix: compare sensitive data with sodium_memcmp Jan 27, 2016 toxav added the dropped ; Feb 13, 2016 toxcore Merge branch 'network-test-magic' of https://github.com/roman-yepishe… Mar 19, 2016 toxdns Astyle. Nov 3, 2015 toxencryptsave Add missing files so that archive for make dist is complete Feb 26, 2016 .gitignore Add spec file for rpm generation Mar 4, 2015 .travis.yml Added check of whether tox.h or toxav.h were edited directly Mar 7, 2016 COPYING Removed the unused autotools files Oct 5, 2015 DONATORS If we receive a packet from a node we are searching for, ping it. Dec 8, 2015 INSTALL.md updated git repo urls Oct 23, 2015 Makefile.am Fixed make dist. Jun 24, 2015 README.md Merge branch 'fix-broken-link' of https://github.com/duthils/toxcore Nov 19, 2015 autogen.sh Fix file modes Oct 14, 2015 configure.ac Fixes. Jan 30, 2016 libtoxav.pc.in Build system fixes. Dec 18, 2014 libtoxcore.pc.in Build system fixes. Dec 18, 2014 tox.spec.in Add spec file for rpm generation Mar 3, 2015 README.md With the rise of government surveillance programs, Tox, a FOSS initiative, aims to be an easy to use, all-in-one communication platform that ensures full privacy and secure message delivery. Website | Wiki | Blog | FAQ | Binaries/Downloads | Clients | Compiling IRC Channels: #tox@freenode, #tox-dev@freenode The Complex Stuff: UDP vs. TCP Tox must use UDP simply because hole punching with TCP is not as reliable. However, Tox does use TCP relays as a fallback if it encounters a firewall that prevents UDP hole punching. Connecting & Communicating Every peer is represented as a byte string (the public key [Tox ID] of the peer). By using torrent-style DHT, peers can find the IP of other peers by using their Tox ID. Once the IP is obtained, peers can initiate a secure connection with each other. Once the connection is made, peers can exchange messages, send files, start video chats, etc. using encrypted communications. Current build status: Q&A: What are your goals with Tox? We want Tox to be as simple as possible while remaining as secure as possible. Why are you doing this? There are already a bunch of free Skype alternatives. The goal of this project is to create a configuration-free P2P Skype replacement. “Configuration-free” means that the user will simply have to open the program and will be capable of adding people and communicating with them without having to set up an account. There are many so-called Skype replacements, but all of them are either hard to configure for the normal user or suffer from being way too centralized. TODO: TODO Documentation: Compiling DHT Protocol Crypto Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/irungentoo/toxcore"	"A communication platform, designed to be a Skype-killer. only."	"true"
"Networking and Internet"	"twitc"	"https://github.com/sinemetu1/twitc"	"A mini C library for interacting with the Twitter OAuth API.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"18"	"2"	"2"	"GitHub - sinemetu1/twitc: A mini C library for interacting with the Twitter OAuth api. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 2 Star 18 Fork 2 sinemetu1/twitc Code Issues 0 Pull requests 0 Pulse Graphs A mini C library for interacting with the Twitter OAuth api. 19 commits 1 branch 2 releases Fetching contributors C 98.7% Shell 1.3% C Shell Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show v0.0.2 v0.0.1 Nothing to show New pull request Latest commit 9eac9b7 Jan 23, 2015 sinemetu1 Update README.md Permalink Failed to load latest commit information. src .gitignore maint - adding tests that mock curl calls, separating integration tests, Jan 2, 2015 .travis.yml maint - adding coveralls support Jan 2, 2015 AUTHORS COPYING ChangeLog INSTALL adding initial codebase Dec 25, 2014 LICENSE Initial commit Dec 25, 2014 Makefile.am maint - adding coveralls support Jan 2, 2015 NEWS README.md Update README.md Jan 23, 2015 autogen.sh configure.ac install_deps.sh README.md twitc A mini C library for interacting with the Twitter OAuth api. Installation: # if deps need to be installed: ./install_deps.sh /usr/local  # building twitc ./autogen.sh ./configure make make install  NOTE: There are environment variables that can be set for consumer token, consumer secret, app token, and app secret. See twitc.h and the usage section below. Dependencies: liboauth json-c Usage: See main.c for an example. Environment variables include: export TWITC_KEY=""Consumer Key (API Key)"" export TWITC_SECRET=""Consumer Secret (API Secret)"" export TWITC_ACCESS_TOKEN=""Access Token"" export TWITC_ACCESS_SECRET=""Access Token Secret""  To generate these values go to https://apps.twitter.com/. Tests: Local tests can be run with make check. If you have the environment variables above setup correctly then you can run make integration to test actual integration with Twitter's API. Bugs: Please file bugs in Github issues. License: MIT Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/sinemetu1/twitc"	"A mini C library for interacting with the Twitter OAuth API.."	"true"
"Web Frameworks"	"balde"	"https://github.com/balde/balde"	"A microframework for C based on GLib. only."	"null"	"null"	"null"	"GNU LGPLv2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"656"	"27"	"36"	"GitHub - balde/balde: A microframework for C based on GLib and bad intentions. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 27 Star 656 Fork 36 balde/balde Code Issues 9 Pull requests 2 Wiki Pulse Graphs A microframework for C based on GLib and bad intentions. https://balde.rgm.io/ 559 commits 8 branches 3 releases 3 contributors C 90.5% Makefile 4.7% Shell 3.1% M4 1.1% HTML 0.6% CSS 0.0% C Makefile Shell M4 HTML CSS Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags 0.1.x-maintenance feature/ax_valgrind_check feature/generic-value feature/info feature/sphinx-doc feature/template-for feature/themes master Nothing to show v0.1.2 v0.1.1 v0.1 Nothing to show New pull request Latest commit e3fb5b3 May 21, 2016 rafaelmartins silent more warnings Permalink Failed to load latest commit information. .ci sessions: reimplement session serialization. removed json-glib dep Sep 23, 2015 artwork build: removed splitted Makefile.am files Sep 4, 2014 build-aux valgrind: use glib suppressions from cockpit project May 20, 2016 doc Fix typo on docs Oct 22, 2015 examples doc: readded examples Feb 18, 2015 m4 re-added m4 folder Jan 28, 2014 src silent a few more warnings. May 21, 2016 tests silent a few more warnings. May 21, 2016 .gitignore valgrind: use glib suppressions from cockpit project May 20, 2016 COPYING rename LICENSE to COPYING Jan 2, 2014 Dockerfile Add a simple Dockerfile to aid development Oct 30, 2015 Doxyfile.in build: fix docs infra and website url May 21, 2016 Makefile.am silent more warnings May 21, 2016 README.md build: fix docs infra and website url May 20, 2016 autogen.sh build: upgrade to newer automake Aug 30, 2014 balde.pc.in started implementing sessions support. basic serialization done Jun 21, 2014 configure.ac build: fix docs infra and website url May 20, 2016 README.md balde This is balde, a microframework for C based on GLib and bad intentions. It is designed to be fast, simple, and memory efficient. Most of its architecture is based on other microframeworks, like Flask, and it can run on any web server that supports CGI and/or FastCGI. balde is free software, released under the LGPL2 license. For more information, take a look at: https://balde.rgm.io/ Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/balde/balde"	"A microframework for C based on GLib. only."	"true"
"Numerical"	"apophenia"	"https://github.com/b-k/apophenia"	"A library for statistical and scientific computing. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"92"	"12"	"13"	"GitHub - b-k/apophenia: A C library for statistical and scientific computing Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 12 Star 92 Fork 13 b-k/apophenia Code Issues 2 Pull requests 1 Wiki Pulse Graphs A C library for statistical and scientific computing http://apophenia.info 387 commits 5 branches 6 releases Fetching contributors C 96.9% M4 2.4% Other 0.7% C M4 Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags gh-pages master old_from_sf pkg v1 Nothing to show v1.0 v0.999e 0.999 0.999c 0.999b 0.999a Nothing to show New pull request Latest commit 5352ff1 Apr 25, 2016 Ben Doc update for Homebrew Permalink Failed to load latest commit information. cmd Update histogram plotting Mar 17, 2016 docs Doc update for Homebrew Apr 25, 2016 eg Help faithful.c find its data set. Mar 1, 2016 install Hash names in the apop_name struct Feb 24, 2016 model Fix bug when <predict> is not used Nov 25, 2015 tests Revamp mixture models Feb 18, 2016 transform Update constrained model scale iff parameters change Mar 8, 2016 ChangeLog By popular demand, rename apop_model_stack to apop_model_cross Oct 24, 2014 README V1.0 Nov 25, 2015 apop.m4.h Update constrained model scale iff parameters change Mar 8, 2016 apop_arms.c Have OLS estimation store error variance, for use by likelihood Nov 12, 2015 apop_asst.m4.c Fix warnings from clang Jul 6, 2015 apop_bootstrap.m4.c Deprecate the <Bootstrapped statistics> page, as promised Dec 8, 2015 apop_conversions.m4.c Add libgen header, for POSIX compliance. Mar 8, 2016 apop_data.m4.c Tweaks turned up in testing Jul 1, 2015 apop_db.m4.c apop_opts.db_name_column is now a pointer-to-char, not char[300] Jun 30, 2015 apop_db_mysql.c apop_opts.db_name_column is now a pointer-to-char, not char[300] Jun 30, 2015 apop_db_sqlite.c apop_opts.db_name_column is now a pointer-to-char, not char[300] Jun 30, 2015 apop_fexact.c apop_vector_correlation handles weights Jun 11, 2015 apop_hist.m4.c Weights are a vector. Nov 25, 2015 apop_internal.h Update apop_internal.h Apr 11, 2015 apop_linear_algebra.m4.c Revise narrative documentation Jun 29, 2015 apop_linear_constraint.m4.c Move testing discussion from brief intro to longer outline Jun 23, 2015 apop_mapply.m4.c Revise narrative documentation Jun 29, 2015 apop_mcmc.m4.c Apply J Benoit's patch for MCMC Aug 30, 2015 apop_missing_data.m4.c Update more docmentation Jun 10, 2015 apop_mle.m4.c Revamp mixture models Feb 18, 2016 apop_model.m4.c rm apop_ml_imputation Jul 3, 2015 apop_name.m4.c Hash names in the apop_name struct Feb 24, 2016 apop_output.m4.c Revert ""Tweak printing of column headers"" Jul 1, 2015 apop_rake.m4.c Tweaks turned up in testing Jul 1, 2015 apop_regression.m4.c Handle addition of elements to copied-in factor lists Jul 1, 2015 apop_settings.c apop_vector_correlation handles weights Jun 11, 2015 apop_sort.m4.c Address Issue #30 Feb 29, 2016 apop_stats.m4.c Revamp KL divergence and its test Feb 10, 2016 apop_tests.m4.c Fix bug in apop_test for checking distribtion type Jun 30, 2015 apop_update.m4.c Revise uses of apop_rng_get_thread Jun 16, 2015 apop_vtables.c Start fixing doxygen groups May 10, 2015 asprintf.c logit fixes; asprintf check Jan 7, 2013 configure V1.0 Nov 25, 2015 README Apophenia is an open statistical library for working with data sets and statistical or simulation models. It provides functions on the same level as those of the typical stats package (such as OLS, probit, or singular value decomposition) but gives the user more flexibility to be creative in model-building. Being in C, it is often an order of magnitude faster when searching for optima or running MCMC chains. The core functions are written in C, but experience has shown them to be easy to bind to Python/Julia/Perl/Ruby/&c.  http://apophenia.info/gentle.html provides an overview of the basics of using the library. If you want to know more about the package, see the web site, http://apophenia.info, or have a look at the textbook from Princeton University Press that coevolved with Apophenia, downloadable from http://modelingwithdata.org .   The quick summary for installation:  ∙ The library depends on the GNU Scientific Library and SQLite3. If you are using a system with a package manager of some sort, there is certainly a package for them. Be sure to include both the main package and the lib-, -dev, or -devel package. Sample package manager calls:      sudo apt-get install make gcc libgsl0-dev libsqlite3-dev  or      sudo yum install make gcc gsl-devel libsqlite3x-devel or      sudo pacman -S make gcc gsl sqlite   ∙ The prebuilt package, that has only basic prerequisites (no Autotools or m4) can be downloaded from another Git branch:      #Download the zip file, via wget or your preferred downloading method:     wget https://github.com/b-k/Apophenia/archive/pkg.zip      #unzip and build     unzip pkg.zip     cd Apophenia-pkg     ./configure     make     sudo make install  Or check out the branch via git:      git clone https://github.com/b-k/Apophenia.git     cd Apophenia     git checkout pkg     ./configure     make     sudo make install  ∙ This master branch of the git repository requires Autotools, so it can build the package. Try (apt-get || yum install) autoconf automake libtool. If you have Autotools installed, then from this branch you can run:      ./configure     cd apophenia-1.0     make      sudo make install  ∙ Find detailed setup instructions and some troubleshooting notes at http://apophenia.info/setup.html .   Thanks for your interest. I do hope that Apophenia helps you learn more from your data.  --BK  PS: Lawyers, please note that a file named COPYING in the install/ directory describes how this package is licensed under GPLv2.  Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/b-k/apophenia"	"A library for statistical and scientific computing. only."	"true"
"Numerical"	"ATLAS"	"http://math-atlas.sourceforge.net/"	"Automatically Tuned Linear Algebra Software.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"null"	"null"	"null"	"Automatically Tuned Linear Algebra Software (ATLAS) Automatically Tuned Linear Algebra Software (ATLAS) [Home] [Docs] [FAQ] [Errata] [Software] [Install] [Support] [Lists] [Developer home] [Timings] [SourceForge Summary Page] The ATLAS (Automatically Tuned Linear Algebra Software) project is an ongoing research effort focusing on applying empirical techniques in order to provide portable performance. At present, it provides C and Fortran77 interfaces to a portably efficient BLAS implementation, as well as a few routines from LAPACK. If you download the software, it is critically important that you check the ATLAS errata file. This file lists all known errors in ATLAS, and all known system problems (eg., compiler errors, etc), and any fixes and workarounds. See the faq for support help. The newest ATLAS papers can be found here. [Home] [Docs] [FAQ] [Errata] [Software] [Install] [Support] [Lists] [Developer home] [Timings]"	"null"	"null"	"Automatically Tuned Linear Algebra Software.."	"true"
"Numerical"	"BLAS"	"http://www.netlib.org/blas/"	"Basic Linear Algebra Subprograms; a set of routines that provide vector and matrix operations."	"null"	"null"	"null"	"BLAS license"	"http://www.netlib.org/blas/#_licensing"	"null"	"null"	"null"	"null"	"null"	"BLAS (Basic Linear Algebra Subprograms) BLAS (Basic Linear Algebra Subprograms) Menu JavaScript must be enabled in your browser to display the table of contents. Questions/comments? lapack@cs.utk.edu Contact us get the lastest news BLAS(Legacy Website) FAQ Presentation: The BLAS (Basic Linear Algebra Subprograms) are routines that provide standard building blocks for performing basic vector and matrix operations. The Level 1 BLAS perform scalar, vector and vector-vector operations, the Level 2 BLAS perform matrix-vector operations, and the Level 3 BLAS perform matrix-matrix operations. Because the BLAS are efficient, portable, and widely available, they are commonly used in the development of high quality linear algebra software, LAPACK for example. Acknowledgments: This material is based upon work supported by the National Science Foundation under Grant No. ASC-9313958 and DOE Grant No. DE-FG03-94ER25219. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation (NSF) or the Department of Energy (DOE). History Discover the great history behind BLAS. On April 2004 an oral history interview was conducted as part of the SIAM project on the history of software for scientific computing and numerical analysis. This interview is being conducted with Professor Jack Dongarra in his office at the University of Tennessee. The interviewer is Thomas Haigh. Download Interview Enjoy! Software: Licensing: The reference BLAS is a freely-available software package. It is available from netlib via anonymous ftp and the World Wide Web. Thus, it can be included in commercial software packages (and has been). We only ask that proper credit be given to the authors. Like all software, it is copyrighted. It is not trademarked, but we do ask the following: If you modify the source for these routines we ask that you change the name of the routine and comment the changes made to the original. We will gladly answer any questions regarding the software. If a modification is done, however, it is the responsibility of the person who modified the routine to provide support. REFERENCE BLAS Version 3.6.0 Download blas-3.6.0.tgz Updated November 2015 Quick Reference Guide CBLAS Download cblas.tgz Header file: cblas.h Level 3 BLAS tuned for single processors with caches Downlaod ssgemmbased.tgz Written by Kagstrom B., Ling P., and Van Loan C. High Performance GEMM-Based Level-3 BLAS Webpage - Fortran (High Performance Computing II, 1991, North-Holland) Extended precision Level 2 BLAS routines Download ecblas2.f BLAS for windows The reference BLAS is included inside the LAPACK package. Please refer tools built under Windows using Cmake the cross-platform, open-source build system. The new build system was developed in collaboration with Kitware Inc. A dedicated website (http://icl.cs.utk.edu/lapack-for-windows/lapack/) is available for Windows users. You will find information about your configuration need. You will be able to download BLAS pre-built libraries. SVN Access The LAPACK SVN repository is open for read-only for our users to be able to get the latest bug fixed. The latest version of BLAS is included in LAPACK package. svn co https://icl.cs.utk.edu/svn/lapack-dev/lapack/trunk/ The netlib family and its cousins Basic Linear Algebra Subprograms (BLAS) LAPACK PLASMA MAGMA CLAPACK (no longer maintained) EISPACK (no longer maintained) Support If you have any issue (install, performance), just post your questions on the the LAPACK User Forum. You can also send us an email at lapack@cs.utk.edu Documentation Checkout the BLAS Wikipedia page BLAS Technical Forum The BLAS Technical Forum standard is a specification of a set of kernel routines for linear algebra, historically called the Basic Linear Algebra Subprograms. http://www.netlib.org/blas/blast-forum/ Optimized BLAS Library Machine-specific optimized BLAS libraries are available for a variety of computer architectures. These optimized BLAS libraries are provided by the computer vendor or by an independent software vendor (ISV) . For further details, please see our FAQs. Alternatively, the user can download ATLAS to automatically generate an optimized BLAS library for his architecture. Some prebuilt optimized BLAS libraries are also available from the ATLAS site. If all else fails, the user can download a Fortran77 reference implementation of the BLAS from netlib. However, keep in mind that this is a reference implementation and is not optimized. BLAS vendor library List Last updated: July 20, 2005 BLAS Routines LEVEL 1 SINGLE SROTG - setup Givens rotation SROTMG - setup modified Givens rotation SROT - apply Givens rotation SROTM - apply modified Givens rotation SSWAP - swap x and y SSCAL - x = a*x SCOPY - copy x into y SAXPY - y = a*x + y SDOT - dot product SDSDOT - dot product with extended precision accumulation SNRM2 - Euclidean norm SCNRM2- Euclidean norm SASUM - sum of absolute values ISAMAX - index of max abs value DOUBLE DROTG - setup Givens rotation DROTMG - setup modified Givens rotation DROT - apply Givens rotation DROTM - apply modified Givens rotation DSWAP - swap x and y DSCAL - x = a*x DCOPY - copy x into y DAXPY - y = a*x + y DDOT - dot product DSDOT - dot product with extended precision accumulation DNRM2 - Euclidean norm DZNRM2 - Euclidean norm DASUM - sum of absolute values IDAMAX - index of max abs value COMPLEX CROTG - setup Givens rotation CSROT - apply Givens rotation CSWAP - swap x and y CSCAL - x = a*x CSSCAL - x = a*x CCOPY - copy x into y CAXPY - y = a*x + y CDOTU - dot product CDOTC - dot product, conjugating the first vector SCASUM - sum of absolute values ICAMAX - index of max abs value DOUBLE COMLPEX ZROTG - setup Givens rotation ZDROTF - apply Givens rotation ZSWAP - swap x and y ZSCAL - x = a*x ZDSCAL - x = a*x ZCOPY - copy x into y ZAXPY - y = a*x + y ZDOTU - dot product ZDOTC - dot product, conjugating the first vector DZASUM - sum of absolute values IZAMAX - index of max abs value LEVEL 2 Single SGEMV - matrix vector multiply SGBMV - banded matrix vector multiply SSYMV - symmetric matrix vector multiply SSBMV - symmetric banded matrix vector multiply SSPMV - symmetric packed matrix vector multiply STRMV - triangular matrix vector multiply STBMV - triangular banded matrix vector multiply STPMV - triangular packed matrix vector multiply STRSV - solving triangular matrix problems STBSV - solving triangular banded matrix problems STPSV - solving triangular packed matrix problems SGER - performs the rank 1 operation A := alpha*x*y' + A SSYR - performs the symmetric rank 1 operation A := alpha*x*x' + A SSPR - symmetric packed rank 1 operation A := alpha*x*x' + A SSYR2 - performs the symmetric rank 2 operation, A := alpha*x*y' + alpha*y*x' + A SSPR2 - performs the symmetric packed rank 2 operation, A := alpha*x*y' + alpha*y*x' + A Double DGEMV - matrix vector multiply DGBMV - banded matrix vector multiply DSYMV - symmetric matrix vector multiply DSBMV - symmetric banded matrix vector multiply DSPMV - symmetric packed matrix vector multiply DTRMV - triangular matrix vector multiply DTBMV - triangular banded matrix vector multiply DTPMV - triangular packed matrix vector multiply DTRSV - solving triangular matrix problems DTBSV - solving triangular banded matrix problems DTPSV - solving triangular packed matrix problems DGER - performs the rank 1 operation A := alpha*x*y' + A DSYR - performs the symmetric rank 1 operation A := alpha*x*x' + A DSPR - symmetric packed rank 1 operation A := alpha*x*x' + A DSYR2 - performs the symmetric rank 2 operation, A := alpha*x*y' + alpha*y*x' + A DSPR2 - performs the symmetric packed rank 2 operation, A := alpha*x*y' + alpha*y*x' + A Complex CGEMV - matrix vector multiply CGBMV - banded matrix vector multiply CHEMV - hermitian matrix vector multiply CHBMV - hermitian banded matrix vector multiply CHPMV - hermitian packed matrix vector multiply CTRMV - triangular matrix vector multiply CTBMV - triangular banded matrix vector multiply CTPMV - triangular packed matrix vector multiply CTRSV - solving triangular matrix problems CTBSV - solving triangular banded matrix problems CTPSV - solving triangular packed matrix problems CGERU - performs the rank 1 operation A := alpha*x*y' + A CGERC - performs the rank 1 operation A := alpha*x*conjg( y' ) + A CHER - hermitian rank 1 operation A := alpha*x*conjg(x') + A CHPR - hermitian packed rank 1 operation A := alpha*x*conjg( x' ) + A CHER2 - hermitian rank 2 operation CHPR2 - hermitian packed rank 2 operation Double Complex ZGEMV - matrix vector multiply ZGBMV - banded matrix vector multiply ZHEMV - hermitian matrix vector multiply ZHBMV - hermitian banded matrix vector multiply ZHPMV - hermitian packed matrix vector multiply ZTRMV - triangular matrix vector multiply ZTBMV - triangular banded matrix vector multiply ZTPMV - triangular packed matrix vector multiply ZTRSV - solving triangular matrix problems ZTBSV - solving triangular banded matrix problems ZTPSV - solving triangular packed matrix problems ZGERU - performs the rank 1 operation A := alpha*x*y' + A ZGERC - performs the rank 1 operation A := alpha*x*conjg( y' ) + A ZHER - hermitian rank 1 operation A := alpha*x*conjg(x') + A ZHPR - hermitian packed rank 1 operation A := alpha*x*conjg( x' ) + A ZHER2 - hermitian rank 2 operation ZHPR2 - hermitian packed rank 2 operation LEVEL 3 Single SGEMM - matrix matrix multiply SSYMM - symmetric matrix matrix multiply SSYRK - symmetric rank-k update to a matrix SSYR2K - symmetric rank-2k update to a matrix STRMM - triangular matrix matrix multiply STRSM - solving triangular matrix with multiple right hand sides Double DGEMM - matrix matrix multiply DSYMM - symmetric matrix matrix multiply DSYRK - symmetric rank-k update to a matrix DSYR2K - symmetric rank-2k update to a matrix DTRMM - triangular matrix matrix multiply DTRSM - solving triangular matrix with multiple right hand sides Complex CGEMM - matrix matrix multiply CSYMM - symmetric matrix matrix multiply CHEMM - hermitian matrix matrix multiply CSYRK - symmetric rank-k update to a matrix CHERK - hermitian rank-k update to a matrix CSYR2K - symmetric rank-2k update to a matrix CHER2K - hermitian rank-2k update to a matrix CTRMM - triangular matrix matrix multiply CTRSM - solving triangular matrix with multiple right hand sides Double Complex ZGEMM - matrix matrix multiply ZSYMM - symmetric matrix matrix multiply ZHEMM - hermitian matrix matrix multiply ZSYRK - symmetric rank-k update to a matrix ZHERK - hermitian rank-k update to a matrix ZSYR2K - symmetric rank-2k update to a matrix ZHER2K - hermitian rank-2k update to a matrix ZTRMM - triangular matrix matrix multiply ZTRSM - solving triangular matrix with multiple right hand sides Extended precision Level 2 BLAS routines SUBROUTINE ECGEMV ( TRANS, M, N, ALPHA, A, LDA, X, INCX, BETA, Y, INCY ) SUBROUTINE ECGBMV ( TRANS, M, N, KL, KU, ALPHA, A, LDA, X, INCX, BETA, Y, INCY ) SUBROUTINE ECHEMV ( UPLO, N, ALPHA, A, LDA, X, INCX,BETA, Y, INCY ) SUBROUTINE ECHBMV ( UPLO, N, K, ALPHA, A, LDA, X, INCX,BETA, Y, INCY ) SUBROUTINE ECHPMV ( UPLO, N, ALPHA, AP, X, INCX, BETA, Y, INCY ) SUBROUTINE ECTRMV ( UPLO, TRANS, DIAG, N, A, LDA, X, INCX ) SUBROUTINE ECTBMV ( UPLO, TRANS, DIAG, N, K, A, LDA, X, INCX ) SUBROUTINE ECTPMV ( UPLO, TRANS, DIAG, N, AP, X, INCX ) SUBROUTINE ECTRSV ( UPLO, TRANS, DIAG, N, A, LDA, X, INCX ) SUBROUTINE ECTBSV ( UPLO, TRANS, DIAG, N, K, A, LDA, X, INCX ) SUBROUTINE ECTPSV ( UPLO, TRANS, DIAG, N, AP, X, INCX ) SUBROUTINE ECGERU ( M, N, ALPHA, X, INCX, Y, INCY, A, LDA ) SUBROUTINE ECGERC ( M, N, ALPHA, X, INCX, Y, INCY, A, LDA ) SUBROUTINE ECHER ( UPLO, N, ALPHA, X, INCX, A, LDA ) SUBROUTINE ECHPR ( UPLO, N, ALPHA, X, INCX, AP ) SUBROUTINE ECHER2 ( UPLO, N, ALPHA, X, INCX, Y, INCY, A, LDA ) SUBROUTINE ECHPR2 ( UPLO, N, ALPHA, X, INCX, Y, INCY, AP ) Last updated 2015-11-15 14:40:53 PST"	"null"	"null"	"Basic Linear Algebra Subprograms; a set of routines that provide vector and matrix operations."	"true"
"Numerical"	"Cuba"	"http://www.feynarts.de/cuba/"	"A library for multidimensional numerical integration. only."	"null"	"null"	"null"	"GNU LGPLv3"	"http://www.gnu.org/licenses/lgpl.html"	"null"	"null"	"null"	"null"	"null"	"The Cuba library Cuba - a library for multidimensional numerical integration The Cuba library offers a choice of four independent routines for multidimensional numerical integration: Vegas, Suave, Divonne, and Cuhre. They work by very different methods, summarized in the following table: Routine Basic integration method Algorithm type Variance reduction Vegas Sobol quasi-random sample or Mersenne Twister pseudo-random sample or Ranlux pseudo-random sample Monte Carlo Monte Carlo Monte Carlo importance sampling Suave Sobol quasi-random sample or Mersenne Twister pseudo-random sample or Ranlux pseudo-random sample Monte Carlo Monte Carlo Monte Carlo globally adaptive subdivision     + importance sampling Divonne Korobov quasi-random sample or Sobol quasi-random sample or Mersenne Twister pseudo-random sample or Ranlux pseudo-random sample or cubature rules Monte Carlo Monte Carlo Monte Carlo Monte Carlo deterministic stratified sampling,     aided by methods from     numerical optimization Cuhre cubature rules deterministic globally adaptive subdivision All four have a C/C++, Fortran, and Mathematica interface and can integrate vector integrands. Their invocation is very similar, so it is easy to substitute one method by another for cross-checking. For further safeguarding, the output is supplemented by a chi-square probability which quantifies the reliability of the error estimate. The source code compiles with gcc, the GNU C compiler. The C functions can be called from Fortran directly, so there is no need for adapter code. Similarly, linking Fortran code with the library is straightforward and requires no extra tools. In Fortran and C/C++ the Cuba library can (and usually does) automatically parallelize the sampling of the integrand. Cuba has been published in Comput. Phys. Commun. 168 (2005) 78 [hep-ph/0404043]. The parallel features are described in arXiv:1408.6373. Here is a talk on Cuba given at ACAT 05 [proceedings]. Here is a somewhat more theoretical talk on numerical integration in general, given at CAPP 05. Maple uses Cuba. Reduce uses Cuba. The R2Cuba package makes Cuba available in R. Download: Cuba-4.2.tar.gz [737 kB, MD5: a3eb0751d4872a3f86401694bc5bedae] (current version 4.2) last update: 25 Sep 15 - Fixed bug in Suave.tm (oversight of 'nmin' argument). Cuba-4.1.tar.gz [742 kB, MD5: 04ef4116a2f4f9c1bb121e67310bd12c] (old version 4.1) last update: 28 Nov 14 Cuba-4.0.tar.gz [582 kB, MD5: dd931da596933a835d2fd635e2a58a60] (old version 4.0) last update: 25 Nov 14 Cuba-3.3.tar.gz [427 kB, MD5: c1fec56eec0f76096e865fd062c7f0ec] (old version 3.3) last update: 5 Jun 14 Cuba-3.2.tar.gz [428 kB, MD5: dd51a9f29e8e9195a0f0ec290cdf8d8e] (old version 3.2) last update: 6 Dec 13 Cuba-3.1.tar.gz [420 kB, MD5: 2329509c639cf84bae2ca2387f6d971b] (old version 3.1) last update: 6 Jun 13 Cuba-3.0.tar.gz [414 kB, MD5: 9a5be73f9836bc360aab29c4ee6c61cd] (old version 3.0) last update: 6 Jun 13 Cuba-2.1.tar.gz [311 kB, MD5: 59a4d61e58c26c449d7cd08823f1cc14] (old version 2.1) last update: 21 Jun 11 Cuba-2.0.tar.gz [310 kB, MD5: 1fa8e7d6ead666bd583a2030fdda5d21] (old version 2.0) last update: 20 Jul 10 Cuba-1.7.tar.gz [309 kB, MD5: a6538d9cae3c5903c71d8ca280c325ce] (old version 1.7) last update: 12 Feb 10 Cuba-1.6.tar.gz [344 kB, MD5: 7233a1ce1fea887d5af0fdb7df60c69c] (old version 1.6) last update: 22 Jul 09 Cuba-1.5.tar.gz [314 kB, MD5: ec78578e8cdd6cc0bb436590cbfab7a8] (old version 1.5) last update: 3 Mar 09 Cuba-1.4.tar.gz [341 kB, MD5: 0b6ae96e338b60eb80c09eaf84e6f757] (old version 1.4) last update: 4 Apr 08 Cuba-1.3.tar.gz [321 kB, MD5: b280838061f9aae377c0eba680f7ab2c] (old version 1.3) last update: 30 Nov 07, Cuba-1.2.tar.gz [315 kB, MD5: 16ecd91b55a4eb59bf600a481af4849c] (old version 1.2) last update: 5 Jan 06, Cuba-1.1.tar.gz [255 kB, MD5: 6945423a0b95c324d2b1ca38648ff7ab] (old version 1.1) last update: 27 Jan 05 Cuba-1.0.tar.gz [260 kB, MD5: f28682f58196ee8012016f5b463ba240] (old version 1.0) last update: 23 Dec 04 Windows users: Cuba 3 and up uses fork(2) to parallelize the execution threads. This POSIX function is not part of the Windows API, however, and is furthermore used in an essential way such that it cannot be worked around simply with CreateProcess etc. The only feasible emulation seems to be available through Cygwin. Ready-made MathLink executables (Version 4.2, statically linked as far as possible): Linux x86-64: Vegas-Linux.gz [915 kB, MD5: 9190dac006d253375860dcef7347cb18] Suave-Linux.gz [928 kB, MD5: 8497d66b4419a3004b6fe0139956a1f1] Divonne-Linux.gz [962 kB, MD5: a2f87ec42082c76899cc341e7ed29abd] Cuhre-Linux.gz [914 kB, MD5: d64d5422c7c2b60836e140e42461a3d1] Mac OS X: Vegas-Mac.gz [1.09 MB, MD5: c4d357407a6c1b993474279b97e0973f] Suave-Mac.gz [1.1 MB, MD5: 95f9275b9c07dcf12c9820d5dc21cf7e] Divonne-Mac.gz [1.15 MB, MD5: c43c4d193a8c9735dfcd38ba5d91d57c] Cuhre-Mac.gz [1.09 MB, MD5: 96b3a07c68aa664a6fdd549d976a6b7a] Windows (Cygwin): Vegas.exe-Windows.gz [18 kB, MD5: 249137e588b1b117c21aabb9e6ababcd] Suave.exe-Windows.gz [22 kB, MD5: fd131503e15307ff893bd088b96fa88b] Divonne.exe-Windows.gz [67 kB, MD5: dffba6a84c3aec7337c1d3fb39e59877] Cuhre.exe-Windows.gz [20 kB, MD5: 7c416df13ac56e7ce2e65c3228708c8c] For the computationally challenged: after downloading the files you need to gunzip them, make them executable (chmod 755 file) and possibly rename them (.exe extension required by Windows). Vegas is the simplest of the four. It uses importance sampling for variance reduction, but is only in some cases competitive in terms of the number of samples needed to reach a prescribed accuracy. Nevertheless, it has a few improvements over the original algorithm and comes in handy for cross-checking the results of other methods. Suave is a new algorithm which combines the advantages of two popular methods: importance sampling as done by Vegas and subregion sampling in a manner similar to Miser. By dividing into subregions, Suave manages to a certain extent to get around Vegas' difficulty to adapt its weight function to structures not aligned with the coordinate axes. Divonne is a further development of the CERNLIB routine D151. Divonne works by stratified sampling, where the partitioning of the integration region is aided by methods from numerical optimization. A number of improvements have been added to this algorithm, the most significant being the possibility to supply knowledge about the integrand. Narrow peaks in particular are difficult to find without sampling very many points, especially in high dimensions. Often the exact or approximate location of such peaks is known from analytic considerations, however, and with such hints the desired accuracy can be reached with far fewer points. Cuhre employs a cubature rule for subregion estimation in a globally adaptive subdivision scheme. It is hence a deterministic, not a Monte Carlo method. In each iteration, the subregion with the largest error is halved along the axis where the integrand has the largest fourth difference. Cuhre is quite powerful in moderate dimensions, and is usually the only viable method to obtain high precision, say relative accuracies much below 1e-3. Upward of 75% of all questions regarding Cuba have to do with how to choose bounds different from the unit hypercube in Fortran, C, and C++. The solution is not to choose bounds but to scale the integrand. For the mathematically challenged, the explicit transformation is (in one dimension) ∫ab dx f[x] → ∫01 dy f[a + (b - a) y] (b - a), where the final (b - a) is the one-dimensional version of the Jacobian. This generalizes straightforwardly to more than one dimension. For constant integration bounds, this transformation might be implemented in Fortran as          integer function ScaledIntegrand(ndim, x, ncomp, result)         implicit none         integer ndim, ncomp         double precision x(ndim), result(ncomp)          integer maxdim         parameter (maxdim = 16)          integer Integrand         external Integrand          double precision upper(maxdim)         common /ubound/ upper          double precision lower(maxdim)         common /lbound/ lower          integer dim, comp         double precision range, jacobian, scaledx(maxdim)          jacobian = 1         do dim = 1, ndim           range = upper(dim) - lower(dim)           jacobian = jacobian*range           scaledx(dim) = lower(dim) + x(dim)*range         enddo          ScaledIntegrand = Integrand(ndim, scaledx, ncomp, result)          do comp = 1, ncomp           result(comp) = result(comp)*jacobian         enddo         end  This site and the programs offered here are not commercial. Cuba is an open-source package and free of charge. If you want to use Cuba in a commercial application, make sure you understand the GNU Lesser General Public License under which Cuba is distributed. Cuba is being developed at the Max Planck Institute for Physics in Munich. Last update: 29 Mar 16 Thomas Hahn"	"null"	"null"	"A library for multidimensional numerical integration. only."	"true"
"Numerical"	"FFTW"	"http://www.fftw.org/"	"The Fastest Fourier Transform in the West; a highly-optimized fast Fourier transform routine. or later."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"643"	"97"	"197"	"GitHub - FFTW/fftw3: This is the official repository for the FFTW Fourier transform library, version 3.x Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 97 Star 643 Fork 197 FFTW/fftw3 Code Issues 16 Pull requests 3 Wiki Pulse Graphs This is the official repository for the FFTW Fourier transform library, version 3.x 2,984 commits 2 branches 11 releases 8 contributors C 73.6% OCaml 13.6% C++ 4.7% Makefile 3.3% M4 3.2% Perl 0.9% Shell 0.7% C OCaml C++ Makefile M4 Perl Shell Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags experimental-simd master Nothing to show fftw-3.3.4 fftw-3.3.3 fftw-3.3.2 fftw-3.3.1 fftw-3.3 fftw-3.2.1 fftw-3.2 fftw-3.1.1 fftw-3.1 fftw-3.0.1 fftw-3.0 Nothing to show New pull request Latest commit 2ed010c Jun 5, 2016 matteo-frigo Clean up some int<->size_t confusion Permalink Failed to load latest commit information. api Clean up some int<->size_t confusion Jun 5, 2016 dft Cast Police Jun 4, 2016 doc Clarify ambiguous/wrong documentation of halfcomplex output format. Mar 13, 2016 genfft Cleanup Jan 20, 2016 kernel Integral Type Police Jun 4, 2016 libbench2 Integral Type Police Jun 5, 2016 m4 Added Power8 VSX SIMD support Mar 28, 2015 mpi Integral Type Police Jun 5, 2016 rdft Integral Type Police Jun 5, 2016 reodft copyright year update Mar 4, 2014 simd-support Clean up some int<->size_t confusion Jun 5, 2016 simd git rm *~ Jun 28, 2014 support In maintainer mode, detect whether 'indent' is available and is GNU i… Apr 13, 2015 tests Integral Type Police Jun 5, 2016 threads rm hooks api's, add fftw_make_planner_thread_safe() api May 25, 2015 tools fix #29 Jan 30, 2015 .gitignore Make 128/256 bit generic simd separate options Apr 8, 2015 AUTHORS fix typo Sep 20, 2013 CONVENTIONS added K Mar 1, 2003 COPYING Store GPLv2 in darcs because automake installs GPLv3 these days. Nov 5, 2008 COPYRIGHT copyright year update Mar 4, 2014 Makefile.am Turn AVX-128 into AMD-specific AVX-128-FMA May 26, 2015 NEWS Added Power8 VSX SIMD support Mar 28, 2015 README Clarify how to bootstrap fftw from the git repository Sep 8, 2015 README.md add README.md for github's convenience Mar 17, 2013 TODO Add TODO's May 25, 2015 bootstrap.sh Use ocamlbuild for building genfft May 8, 2011 commercialize.sh note that these scripts are not meant for normal users Mar 17, 2013 configure.ac Enable SSE2 automatically with AVX,AVX2, or AVX512. May 26, 2015 fftw.pc.in make -lm a private library in fftw.pc.in Dec 4, 2012 mkdist.sh note that these scripts are not meant for normal users Mar 17, 2013 README.md This is the official git repository for the FFTW library for computing Fourier transforms (version 3.x). Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/FFTW/fftw3"	"The Fastest Fourier Transform in the West; a highly-optimized fast Fourier transform routine. or later."	"true"
"Numerical"	"FLINT"	"http://flintlib.org/"	"Fast Library for Number Theory; a library supporting arithmetic with numbers, polynomials, power series and matrices, among others. or later."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"null"	"null"	"null"	"FLINT: Fast Library for Number Theory FLINT: Fast Library for Number Theory Overview | News | Features | Benchmarks | Downloads | Development | Authors and credits | Links and references Overview FLINT is a C library for doing number theory, maintained by William Hart. FLINT was licensed GPL v2+ up to and including version 2.5. Our current development version (and subsequent releases) are licensed LGPL v2.1+ after the contributors agreed to change the license in April 2016. FLINT supports arithmetic with numbers, polynomials, power series and matrices over many base rings, including: Multiprecision integers and rationals Integers modulo n p-adic numbers Finite fields (prime and non-prime order) Real and complex numbers (via the Arb extension library) Support is also currently being developed for algebraic number fields (via the Antic extension library). Operations that can be performed include conversions, arithmetic, computing GCDs, factoring, solving linear systems, and evaluating special functions. In addition, FLINT provides various low-level routines for fast arithmetic. FLINT is extensively documented and tested. Benchmark: Time to compute a p-adic logarithm to precision 17n with FLINT, versus Magma. FLINT is written in ANSI C and runs on many platforms (including Linux, Mac OS X and Windows on common hardware configurations), but is currently mostly optimised for x86 and x86-64 CPUs. It is designed to be threadsafe. FLINT depends on the MPIR/GMP and MPFR libraries. FLINT has been used for large scale computations in number theory research (for example: A Trillion Triangles), and is also suited as a general-purpose backend for computer algebra systems. Sage uses FLINT as the default package for polynomial arithmetic over Z, Q and Z/nZ for small n, and work is currently underway to use FLINT in Singular and Macaulay2. Last updated: 2016-04-28 14:09:18 GMT Contact: William Hart, flint-devel mailing list. This site is hosted at arithmeticon.sagemath.org thanks to William Stein and the University of Washington."	"null"	"null"	"Fast Library for Number Theory; a library supporting arithmetic with numbers, polynomials, power series and matrices, among others. or later."	"true"
"Numerical"	"GLPK"	"https://gnu.org/software/glpk/"	"GNU Linear Programming Kit; a package designed for solving large-scale linear programming, mixed integer programming and other related problems. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"GLPK - GNU Project - Free Software Foundation (FSF) GLPK (GNU Linear Programming Kit) Introduction | Downloading | Documentation | Mailing Lists/Newsgroups | Request an Enhancement | Report a Bug | Maintainer Introduction to GLPK The GLPK (GNU Linear Programming Kit) package is intended for solving large-scale linear programming (LP), mixed integer programming (MIP), and other related problems. It is a set of routines written in ANSI C and organized in the form of a callable library. GLPK supports the GNU MathProg modeling language, which is a subset of the AMPL language. The GLPK package includes the following main components: primal and dual simplex methods primal-dual interior-point method branch-and-cut method translator for GNU MathProg application program interface (API) stand-alone LP/MIP solver Downloading GLPK The GLPK distribution tarball can be found on http://ftp.gnu.org/gnu/glpk/ [via http] and ftp://ftp.gnu.org/gnu/glpk/ [via FTP]. It can also be found on one of our FTP mirrors; please use a mirror if possible. To make sure that the GLPK distribution tarball you have downloaded is intact you need to download the corresponding .sig file and run a command like this: gpg --verify glpk-4.32.tar.gz.sig If that command fails because you do not have the required public key, run the following command to import it: gpg --keyserver keys.gnupg.net --recv-keys 5981E818 and then re-run the previous command. Documentation The GLPK documentation consists of the Reference Manual and the description of the GNU MathProg modeling language. Both these documents are included in the distribution (in LaTeX, DVI, and PostScript formats). Mailing Lists/Newsgroups GLPK has two mailing lists: help-glpk@gnu.org and bug-glpk@gnu.org. The main discussion list is help-glpk@gnu.org, and is used to discuss all aspects of GLPK, including development and porting. There is a separate list used for reporting bugs, bug-glpk@gnu.org. For details on submitting a bug report, please see the section Report a Bug below. Announcements about GLPK and most other GNU Software are made on info-gnu@gnu.org. To subscribe to these or any GNU mailing lists, please send an empty mail with a Subject: header line of just ""subscribe"" to the relevant -request list. For example, to subscribe yourself to the main GLPK discussion list, you would send mail to help-glpk-request@gnu.org with no body and a Subject: header line of just ""subscribe"". Another way to subscribe is to use the mailing list interface; see Help-glpk and Bug-glpk. Currently there are no newsgroups dedicated to GLPK. Request an Enhancement If you would like any new feature to be included in future versions of GLPK, please send a request to help-glpk@gnu.org. Please remember that development of GLPK is a volunteer effort, and you can also contribute to its development. For information about contributing to the GNU Project, please read How to help GNU. Report a Bug If you think you have found a bug in GLPK, then please send as complete a report as possible to bug-glpk@gnu.org. Maintainer GLPK is currently being maintained by mao@gnu.org, mao@mai2.rcnet.ru. Please send FSF & GNU inquiries to gnu@gnu.org. There are also other ways to contact the FSF. The GLPK package is part of the GNU project, released under the aegis of GNU. Copyright © 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012 Andrew Makhorin, Department for Applied Informatics, Moscow Aviation Institute, Moscow, Russia. All rights reserved. Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA. Verbatim copying and distribution of this entire article are permitted worldwide, without royalty, in any medium, provided this notice, and the copyright notice, are preserved. Updated: $Date: 2012/06/23 11:35:42 $"	"null"	"null"	"GNU Linear Programming Kit; a package designed for solving large-scale linear programming, mixed integer programming and other related problems. or later."	"true"
"Numerical"	"GMP"	"https://gmplib.org/"	"GNU Multple Precision Arithmetic Library; a library for arbitrary-precision arithmetic. Dual-licensed only and only."	"null"	"null"	"null"	"GNU LGPLv3"	"http://www.gnu.org/licenses/lgpl.html"	"null"	"null"	"null"	"null"	"null"	"The GNU MP Bignum Library GMP «Arithmetic without limitations» The GNU Multiple Precision Arithmetic Library Last modified: 2016-07-03 Documentation: 6.1.1 HTML | 6.1.1 PDF Download: gmp-6.1.1.tar.lz | Release notes   NEW 2016-06-20 Development: Developers' corner GMPbench: Results | Download benchmark sources Fun: Compute billions of digits of π using GMP! Security: GMP server security policy Page contents: What is GMP? Function categories Download Reporting bugs Mailing lists Current release status Future releases This site does not use cookies I agree!  What is GMP? GMP is a free library for arbitrary precision arithmetic, operating on signed integers, rational numbers, and floating-point numbers. There is no practical limit to the precision except the ones implied by the available memory in the machine GMP runs on. GMP has a rich set of functions, and the functions have a regular interface. The main target applications for GMP are cryptography applications and research, Internet security applications, algebra systems, computational algebra research, etc. GMP is carefully designed to be as fast as possible, both for small operands and for huge operands. The speed is achieved by using fullwords as the basic arithmetic type, by using fast algorithms, with highly optimised assembly code for the most common inner loops for a lot of CPUs, and by a general emphasis on speed. The first GMP release was made in 1991. It is continually developed and maintained, with a new release about once a year. Since version 6, GMP is distributed under the dual licenses, GNU LGPL v3 and GNU GPL v2. These licenses make the library free to use, share, and improve, and allow you to pass on the result. The GNU licenses give freedoms, but also set firm restrictions on the use with non-free programs. GMP is part of the GNU project. For more information about the GNU project, please see the official GNU web site. GMP's main target platforms are Unix-type systems, such as GNU/Linux, Solaris, HP-UX, Mac OS X/Darwin, BSD, AIX, etc. It also is known to work on Windows in both 32-bit and 64-bit mode. GMP is brought to you by a team listed in the manual. GMP is carefully developed and maintained, both technically and legally. We of course inspect and test contributed code carefully, but equally importantly we make sure we have the legal right to distribute the contributions, meaning users can safely use GMP. To achieve this, we will ask contributors to sign paperwork where they allow us to distribute their work. GMP function categories There are several categories of functions in GMP: High-level signed integer arithmetic functions (mpz). There are about 150 arithmetic and logic functions in this category. High-level rational arithmetic functions (mpq). This category consists of about 35 functions, but all signed integer arithmetic functions can be used too, by applying them to the numerator and denominator separately. High-level floating-point arithmetic functions (mpf). This is the GMP function category to use if the C type `double' doesn't give enough precision for an application. There are about 70 functions in this category. New projects should strongly consider using the much more complete GMP extension library mpfr instead of mpf. C++ class based interface to all of the above. (The C functions and types can of course be used directly from C++ too.) Low-level positive-integer, hard-to-use, very low overhead functions are found in the mpn category. No memory management is performed; the caller must ensure enough space is available for the results. The set of functions is not always regular, nor is the calling interface. These functions accept input arguments in the form of pairs consisting of a pointer to the least significant word, and an integral size telling how many limbs (= words) there are in that argument. The functions in the other categories call mpn for almost all their calculations. Of these functions about 60 are public. Download the latest release of GMP GMP 6.1.1 lz, 1936768 bytes xz, 1943164 bytes bz2, 2384919 bytes Main site, gmplib.org gmp-6.1.1.tar.lz gmp-6.1.1.tar.xz gmp-6.1.1.tar.bz2 USA, ftp.gnu.org gmp-6.1.1.tar.lz gmp-6.1.1.tar.xz gmp-6.1.1.tar.bz2 To try to verify that the file you have downloaded has not been tampered with, you can check that the GnuPG signature matches the contents of the file. Use your GnuPG software or a key server directly to get the key that was used for creating the signature. Starting from the repackaging of gmp-5.1.0 as gmp-5.1.0a.tar.* the following key is used to sign GMP releases: Key ID: 0x28C67298 Key type: 2560 bit RSA Fingerprint: 343C 2FF0 FBEE 5EC2 EDBE F399 F359 9FF8 28C6 7298 GnuPG signatures: gmp-6.1.1.tar.lz.sig   gmp-6.1.1.tar.xz.sig   gmp-6.1.1.tar.bz2.sig Instead of using a release, you may also get the latest code from the GMP repositories. This will require some more work compared to using a release. Reporting bugs in GMP Please first see the manual on how to report bugs. The proper address for bug reports is gmp-bugs at gmplib.org. Most problems with GMP these days are due to problems not in GMP, but with the compiler used for compiling the GMP sources. This is a major concern to the GMP project, since an incorrect computation is an incorrect computation, whether caused by a GMP bug or a compiler bug. We fight this by making the GMP testsuite have great coverage, so that it should catch every possible miscompilation. GMP mailing lists List Subscribe URL Archive URL Purpose gmp-bugs gmplib.org/mailman/listinfo/gmp-bugs gmplib.org/list-archives/gmp-bugs/ Bug reports (not questions!). See manual. gmp-announce gmplib.org/mailman/listinfo/gmp-announce gmplib.org/list-archives/gmp-announce/ Announcements from the developers (very little traffic) gmp-discuss gmplib.org/mailman/listinfo/gmp-discuss gmplib.org/list-archives/gmp-discuss/ Questions, Help, Discussions gmp-devel gmplib.org/mailman/listinfo/gmp-devel gmplib.org/list-archives/gmp-devel/ Technical discussions between developers gmp-commit gmplib.org/mailman/listinfo/gmp-commit gmplib.org/list-archives/gmp-commit/ Commit messages Note that we perform spam and virus filtering of these lists. The lists have been 100% spam-free during the last years. You cannot subscribe an AOL address to any GMP mailing list, since AOL blocks our mail server until we register with them as a ""bulk mailer"", something we will certainly never do. We're blocking all mail from PR China, since 99% of the spam arriving to the GMP moderators emanates from PR China. If you are affected but have a legitimate reason to send mail to the GMP project, e.g., if you work at a university or corporation with an interest in GMP, please let us know; we will open access for you. Status of the current release The current stable release is 6.1.1, released 2016-06-18. Issues with GMP 6.1.1: [No issues found yet.] Issues with GMP 6.1.0: An assembly file which is used for Intel Broadwell and Intel Skylake (except crippled Pentiums and Celerons without BMI2) will not work correctly for Windoze. Patch. Issues with GMP 6.0.0: [No issues found yet.] Issues with GMP 5.1.3: The documentation of mpn_set_str is incorrect and incomplete wrt allocation requirements. Patch. Issues with GMP 5.1.2: The functions mpn_sbpi1_div_qr_sec and mpn_sbpi1_div_r_sec compute incorrect results for some operands. With uniformly distributed random operands, the error is very hard to trigger, and for the intended use of these functions, operands can be expected to appear as such random operands from these functions' perspective. Patch. The internal function mpn_divrem_2 on Itanium clobbers two callee-saves registers. This can lead to miscomputations or crashes in the callers. Patch. See also issues for subsequent releases above. Issues with GMP 5.1.1: Windows only: A 64-bit build for AMD Bulldozer and Piledriver chips, or a fat 64-bit build running on these chips, will not work correctly. Patch. The function mpz_powm_ui computes garbage if the base argument is over 15000 decimal or the mod argument is at least 7500 decimal digits. No other GMP powm function is affected. Patch. See also issues for subsequent releases above. Issues with GMP 5.1.0: The mini-gmp.c file, which implements a subset of mpn and mpz, was not properly tested and contained a number of bugs. Please do not use the 5.1.0 version of mini-gmp.c. Note that these bugs do not affect GMP itself. The included top-level Makefile.in has an automake-generated distcheck target which creates a world-writable directory. This target is not used in the GMP release process, but it is a potential security problem affecting users who invoke this make target. This problem (and no other) is corrected in the gmp-5.1.0a.tar.* set of files. See also issues for subsequent releases above. For patches to older GMP versions, please see the Info on older GMP releases. Future releases Please see the GMPng page for information on what we're working on. Please send comments about this page to gmp-discuss at gmplib.org Copyright 2000–2016 Free Software Foundation Verbatim copying and distribution of this entire article is permitted in any medium, provided this notice is preserved."	"null"	"null"	"GNU Multple Precision Arithmetic Library; a library for arbitrary-precision arithmetic. Dual-licensed only and only."	"true"
"Numerical"	"GNU MPC"	"http://www.multiprecision.org/index.php?prog=mpc&page=home"	"A library for complex number arithmetic. or later."	"null"	"null"	"null"	"GNU LGPL3"	"http://www.gnu.org/licenses/lgpl.html"	"null"	"null"	"null"	"null"	"null"	"MPC multiprecision.org GNU MPC MPFRCX CM PARI-GNUMP Introduction Download Documentation Platforms Packages Applications Publications Development Workshops Introduction Gnu Mpc is a C library for the arithmetic of complex numbers with arbitrarily high precision and correct rounding of the result. It extends the principles of the IEEE-754 standard for fixed precision real floating point numbers to complex numbers, providing well-defined semantics for every operation. At the same time, speed of operation at high precision is a major design goal. The library is built upon and follows the same principles as Gnu Mpfr. It is written by Andreas Enge, Mickaël Gastineau, Philippe Théveny and Paul Zimmermann and is distributed under the Gnu Lesser General Public License, either version 3 of the licence, or (at your option) any later version (LGPLv3+). The Gnu Mpc library has been registered in France by the Agence pour la Protection des Programmes on 2003-02-05 under the number IDDN FR 001 060029 000 R P 2003 000 10000. News Version 1.0.3, ""Fagus silvatica"", released in February 2015, comes with the following bug fixes: Fixed mpc_pow #18257: Switched to libtool 2.4.5 The third Mpfr/Mpc developer meeting has been held in Nancy from January 20 to 22, 2014. Olds Last changed on 2015-02-16 by Andreas Enge"	"null"	"null"	"A library for complex number arithmetic. or later."	"true"
"Numerical"	"GNU MPFR"	"http://mpfr.loria.fr/index.html"	"A library for arbitrary-precision floating-point arithmetic. or later (most recent versions), or later (until version 2.4.x)."	"null"	"null"	"null"	"GNU LGPL2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"null"	"null"	"null"	"The GNU MPFR Library The GNU MPFR Library [MPFR links] [introduction] [interfaces] [software using MPFR] [related free software] [links] MPFR Links Internal links: Latest release: download – documentation – bugs – changes. Gforge: information to use the anonymous access to the Subversion repository. Sample: to start with the MPFR library. FAQ: frequently asked questions. Credit: involved projects and developers. History: links to all MPFR versions and past events. Algorithms: documents describing algorithms used in MPFR. MPFR in the world: publications citing MPFR and various links about MPFR. How to contribute to MPFR. External links on MPFR: Try MPFR online, thanks to Tomonori Kouya. Mailing-list for announces (moderated). Mailing-list for users and developers (Gmane mirror). Introduction The MPFR library is a C library for multiple-precision floating-point computations with correct rounding. MPFR has continuously been supported by the INRIA and the current main authors come from the Caramba and AriC project-teams at Loria (Nancy, France) and LIP (Lyon, France) respectively; see more on the credit page. MPFR is based on the GMP multiple-precision library. The main goal of MPFR is to provide a library for multiple-precision floating-point computation which is both efficient and has a well-defined semantics. It copies the good ideas from the ANSI/IEEE-754 standard for double-precision floating-point arithmetic (53-bit significand). MPFR is free. It is distributed under the GNU Lesser General Public License (GNU Lesser GPL), version 3 or later (2.1 or later for MPFR versions until 2.4.x). The library has been registered in France by the Agence de Protection des Programmes under the number IDDN FR 001 120020 00 R P 2000 000 10800, on 15 March 2000. This license guarantees your freedom to share and change MPFR, to make sure MPFR is free for all its users. Unlike the ordinary General Public License, the Lesser GPL enables developers of non-free programs to use MPFR in their programs. If you have written a new function for MPFR or improved an existing one, please share your work! Interfaces for MPFR and Extensions The following C++ interfaces for MPFR, very different in their design (and in particular, in the strategies for intermediate precisions, so that they can yield different results), are available: MPFRCPP, written by Alexey V. Beshenov. This interface uses a modern C++ design with using of classes, templates and function objects. Another MPFR C++ wrapper, written by Pavel Holoborodko. The precision of the temporary results in an expression is chosen as the maximum precision of its arguments, and the final result is rounded to the precision of the target variable. The mpfr::real class, written by Christian Schneider. It consists of a template class with precision and rounding mode passed as template arguments. Hence, effectively a new type will be created for each precision and rounding that is used. All the operators available for fundamental floating point types as well as type conversions from and to other types, and the set of mathematical functions known from math.h/cmath are implemented. This should allow for an easy substitution of, e.g., a double with the wrapper class in most cases. MPFR++, developed in the AriC project. Warning! The version currently available (2004-02-27) is not up-to-date, is not compatible with the latest releases of MPFR and has several bugs. News from 2007-05-02: Changes have been done on this interface since, but they are not published yet. The gmpfrxx C++ interface for both GMP and MPFR, written by Jon Wilkening. Boost also includes an interface for MPFR, as part of its Multiprecision library. The multiple-precision arithmetic is very useful for interval arithmetic. Get a multiple-precision interval arithmetic library MPFI, based on MPFR. This library MPFI is developed by Nathalie Revol from the AriC project and Fabrice Rouillier. MPFI implements a subset of the mathematical functions provided by MPFR. Read more explanations on Nathalie Revol's software page. The GNU MPC library, a library for multiple-precision complex arithmetic with correct rounding, based on the MPFR and GMP libraries. The Perl interface Math::MPFR. The Python interface bigfloat (documentation), written by Mark Dickinson. The Python bindings for GMP, MPFR and MPC (gmpy2). A LISP interface, written by Richard Fateman. This package also contains a FFT implementation. The functional programming language Ursala includes an MPFR interface. Haskell interfaces: hmpfr written by Aleš Bizjak and haskell-mpfr. Ruby bindings for GMP and MPFR. Eiffel interface to MPFR. The RandomLib MPFR interface (C++ classes). R interface to MPFR. Ada bindings to GMP and MPFR, written by Vincent Diemunsch (announce in the MPFR mailing-list). The Racket language includes an MPFR interface. Java bindings to MPFR. Software Using MPFR The KDE calculator Abakus by Michael Pyne (supporting arbitrary precision thanks to MPFR as of version 0.90). The ALGLIB.NET project implements multiple-precision linear algebra using MPFR. The APRON library, dedicated to the static analysis of the numerical variables of a program by Abstract Interpretation. The ARAnyM virtual machine as of version 0.9.12, for the FPU emulation. Arb, a C library for arbitrary-precision floating-point ball arithmetic, developed by Fredrik Johansson. The numerical analysis library BNCpack can be compiled with MPFR. CGAL (Computational Geometry Algorithms Library). DateTime-Astro (functions for astronomical calendars). Eigen, a C++ template library for linear algebra, via Pavel Holoborodko's MPFR C++ wrapper. FLINT (Fast Library for Number Theory). MPFR is also used by the Fluctuat tool developed and used internally at the CEA (France). FractalNow, a fractal generator. Gappa, a tool intended to help verifying and formally proving properties on numerical programs, by Guillaume Melquiond. GCC: first in GFortran, then in the middle-end phase as of GCC 4.3, to resolve math functions with constant arguments. More information. Genius Math Tool and the GEL language, by Jiri Lebl. Giac/Xcas, a free computer algebra system, by Bernard Parisse. GNOME Calculator, as of version 3.15.4. GNU Awk, as of version 4.1.0 (for optional arbitrary-precision arithmetic). Herbie, a tool for improving the accuracy of floating-point expressions. The iRRAM - Exact Arithmetic in C++ implementation from Norbert Müller (University of Trier, Germany). The Julia language implementation (source). The ledger accounting system. The C++ continued fractions toolkit libcff (no longer maintained), by Johan Vervloet. The libieeep1788 library, a C++ implementation of the preliminary IEEE P1788 standard for interval arithmetic. Macaulay 2, a software system devoted to supporting research in algebraic geometry and commutative algebra (as of version 1.1). The Magma computational algebra system. The Maple computer algebra system via the RS library, since version 11 (reference). Mathemagix, a free computer algebra system, in the numerix package. MCAS/libivl (computational algebra and plot system / interval computations library), by Mateusz Paprocki. MPACK (multiple precision arithmetic BLAS and LAPACK), by Nakata Maho, supports MPFR as of version 0.6.5 (2010-05-21). The MPFRCX library for the arithmetic of univariate polynomials over arbitrary precision real (MPFR) or complex (MPC) numbers, without control on the rounding. The mpfs library, an experiment in stochastic lazy floating-point arithmetic, from Keith Briggs. MPFUN2015, an arbitrary precision package by David H. Bailey; the MPFUN-MPFR version is based on MPFR. Multiprecision Computing Toolbox for MATLAB. NARS2000, an experimental APL interpreter, has datatypes for multiple-precision floating-point numbers via MPFR. The GNU Octave interval package. Protea, a software devoted to protein-coding sequences identification, by Arnaud Fontaine and Hélène Touzet. The Rasqal RDF Query Library optionally uses MPFR for accurate xsd:decimal implementation. ReactOS Calc uses MPFR when multiple-precision support is enabled. MPFR is one of the components of SAGE. Soft84, a calculator for Android devices. Sollya, a tool environment for safe floating-point code development, written by Christoph Lauter and Sylvain Chevillard (in the old Arénaire project). SXEmacs can be compiled with MPFR support (as of version 22.1.3). SweeD, a tool that implements a composite likelihood ratio test for detecting selective sweeps. TIDES: a Taylor Integrator for Differential Equations, to integrate numerically Ordinary Differential Equations in arbitrary precision. TRIP, a general computer algebra system dedicated to celestial mechanics. The Wcalc calculator by Kyle Wheeler (supporting arbitrary precision thanks to MPFR as of version 2.0). ZKCM, a C++ library for multi-precision complex-number matrix calculations. Other Related Free Software MAPM, a portable arbitrary precision math library in C, by Michael C. Ring. CoStLy, a Complex interval Standard functions Library developed by Markus Neher (Karlsruhe). The XSC-Languages, FI_LIB, FILIB++ and intpak software developed at University of Wuppertal (Germany). The CORE library: a library for robust numerical and geometric computation. The CLN C++ library (GPL). The Quad-Double package by David Bailey, Yozo Hida and Sherry Li. The numerical difference utility from Nelson Beebe, similar to diff but for numerical files. The mpmath Python library for arbitrary-precision floating-point arithmetic. The Constructive Reals Calculator from Hans Boehm. The xrc - exact reals in C from Keith Briggs. The precise computation software from Oliver Aberth. The RR class from NTL, which implements a smooth extension of IEEE floating point to arbitrary precision and guarantees a platform-independent behaviour. A continued-fraction package based on GMP, by François Balsalobre. SCSLib, a fast and lightweight multiple-precision library supporting the four arithmetic operations, developed in the old Arénaire project; the precision (210 bits by default) is fixed at compile time. CRlibm, a correctly rounded elementary function library. Sun's libmcr, a correctly rounded library of basic double-precision transcendental elementary functions. The PreciseFloating (floating-point arithmetic library) project in Java, by Daniel Aioanei: directed rounding, rational arithmetic and arbitrary precision arithmetic based on regular continued fraction expansions. The decNumber package by Mike Cowlishaw (IBM): arbitrary-precision decimal arithmetic. The Intel® Decimal Floating-Point Math Library for the IEEE 754-2008 Standard (download). The calc calculator by Landon Curt Noll. This calculator implements a rational arithmetic, with a fallback to some kind of multiple-precision fixed-point arithmetic (integer multiplied by a configurable epsilon). The Qalculate calculator by Niklas Knutsson, based on CLN. The MathCW mathematical function library (supporting binary and decimal floating-point arithmetic) by Nelson H. F. Beebe. Libraries for extended precision on GPU: gnuprec. The mpdecimal package for correctly rounded arbitrary-precision decimal floating-point arithmetic, by Stefan Krah. CAMPARY: multiple precision arithmetic routines for GPUs (based on floating-point expansions), written in CUDA C. Related References and Links The C standard: the N1256 draft (C99 with TC3) and the C99 rationale (especially Section 7.12 and Annex F). New in C99. The N1570 draft (last C1x draft of C11). LIA stuff. These standards are freely available. The General Decimal Arithmetic pages from Mike Cowlishaw. The Digital Library of Mathematical Functions project, whose aim is to develop an electronic version of the Handbook of Mathematical Functions from Abramowitz and Stegun. The Computer Arithmetic & Numerical Techniques (CANT) research group at University of Antwerp, Belgium. The Table Maker's Dilemma page from the AriC (formerly Arénaire) project at ENS-Lyon, France. Mathematical constants and computation by Xavier Gourdon and Pascal Sebah. The 754R standard revision group. The CerPAN ANR project. The EVA-Flo ANR project. LOCOMAT (the Loria Collection of Mathematical Tables)."	"null"	"null"	"A library for arbitrary-precision floating-point arithmetic. or later (most recent versions), or later (until version 2.4.x)."	"true"
"Numerical"	"GNU MPRIA"	"https://gnu.org/software/mpria/"	"A portable mathematics library for multi-precision rational interval arithmetic. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"GNU MPRIA - GNU Project - Free Software Foundation Skip to main text Set language English [en] The  9th HACKERS MEETING  will be held in Rennes (France) from August 18 to 20. JOIN THE FSF Free Software Supporter GNU Operating System Sponsored by the Free Software Foundation About GNU Philosophy Licenses Education = Software = Documentation Help GNU GNU MPRIA Introduction GNU MPRIA is intended to be a portable mathematical library written in C for Multi-Precision Rational Interval Arithmetic computations. It is free software under the GNU General Public License. The basic principle of rational interval arithmetic consists in enclosing every number by a rational interval containing it: each number is stored as its lower and upper endpoints and these bounds are rational numbers; their absolute difference measures the precision. The purpose is on the right hand to obtain guaranteed results, thanks to interval computation, and on the left hand to compute accurate results, thanks to arbitrary precision arithmetic. The arithmetic operations are extended for interval operands in such a way that the exact result of the operation belongs to the computed rational interval. The GNU MPRIA library is built upon the GMP library for operating on rational numbers; see https://gmplib.org/. The GNU MPRIA library was inspired by the Multi-Precision Floating-point Interval arithmetic library (MPFI) available at http://mpfi.gforge.inria.fr/. The MPFI library is based on the MPFR library for operating on floating-point numbers (see http://www.mpfr.org/), itself built upon GMP. The corresponding software page written by Nathalie Revol gives a more detailed introduction to interval arithmetic, a succinct bibliography on the subject and some related links. Downloading GNU MPRIA MPRIA can be found on the main GNU ftp server: http://ftp.gnu.org/gnu/mpria/ (via HTTP) and ftp://ftp.gnu.org/gnu/mpria/ (via FTP). It can also be found on the GNU mirrors; please use a mirror if possible. Documentation Documentation for MPRIA is available online, as is documentation for most GNU software. You may also find more information about MPRIA by running info mpria, or by looking at /usr/share/doc/mpria/, /usr/local/doc/mpria/, or similar directories on your system. Mailing lists The discussion list for GNU MPRIA is bug-mpria, and it is used to discuss all aspects of GNU MPRIA, including support questions, development and enhancement requests, bug reports, suggestions and patches. Announcements about MPRIA and most other GNU software are made on info-gnu (archive). Getting involved Development of MPRIA, and GNU in general, is a volunteer effort, and you can contribute. For information, please read How to help GNU. If you'd like to get involved, it's a good idea to join the discussion mailing list (see above). Test releases Trying the latest test release (when available) is always appreciated. Test releases of MPRIA can be found at http://alpha.gnu.org/gnu/mpria/ (via HTTP) and ftp://alpha.gnu.org/gnu/mpria/ (via FTP). Development For development sources, issue trackers, and other information, please see the MPRIA project page at savannah.gnu.org. Maintainer MPRIA is currently being maintained by Jérôme Benoit. Please use the mailing lists for contact. Licensing GNU MPRIA is Copyright © 2014-2016 Jérôme Benoit GNU MPRIA is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 3 of the License, or (at your option) any later version. GNU home page FSF home page GNU Art GNU's Who? Free Software Directory Hardware Site map “Our mission is to preserve, protect and promote the freedom to use, study, copy, modify, and redistribute computer software, and to defend the rights of Free Software users.” The Free Software Foundation is the principal organizational sponsor of the GNU Operating System. Support GNU and the FSF by buying manuals and gear, joining the FSF as an associate member, or making a donation, either directly to the FSF or via Flattr. back to top Please send general FSF & GNU inquiries to <gnu@gnu.org>. There are also other ways to contact the FSF. Broken links and other corrections or suggestions can be sent to <bug-mpria@gnu.org>. Please see the Translations README for information on coordinating and submitting translations of this article. This web page is Copyright © 2014-2016 Free Software Foundation, Inc. This page is licensed under a Creative Commons Attribution-NoDerivs 3.0 United States License. Copyright Infringement Notification Last updated January 31, 2016 at 18:12:54 UTC"	"null"	"null"	"A portable mathematics library for multi-precision rational interval arithmetic. or later."	"true"
"Numerical"	"GSL"	"http://www.gnu.org/software/gsl/"	"The GNU Scientific Library; a sophisticated numerical library. only."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"GSL - GNU Scientific Library - GNU Project - Free Software Foundation Skip to main text Set language English [en] The  9th HACKERS MEETING  will be held in Rennes (France) from August 18 to 20. JOIN THE FSF Free Software Supporter GNU Operating System Sponsored by the Free Software Foundation About GNU Philosophy Licenses Education = Software = Documentation Help GNU GSL - GNU Scientific Library Introduction The GNU Scientific Library (GSL) is a numerical library for C and C++ programmers. It is free software under the GNU General Public License. The library provides a wide range of mathematical routines such as random number generators, special functions and least-squares fitting. There are over 1000 functions in total with an extensive test suite. The complete range of subject areas covered by the library includes, Complex Numbers Roots of Polynomials Special Functions Vectors and Matrices Permutations Sorting BLAS Support Linear Algebra Eigensystems Fast Fourier Transforms Quadrature Random Numbers Quasi-Random Sequences Random Distributions Statistics Histograms N-Tuples Monte Carlo Integration Simulated Annealing Differential Equations Interpolation Numerical Differentiation Chebyshev Approximation Series Acceleration Discrete Hankel Transforms Root-Finding Minimization Least-Squares Fitting Physical Constants IEEE Floating-Point Discrete Wavelet Transforms Basis splines Running Statistics Sparse Matrices and Linear Algebra Unlike the licenses of proprietary numerical libraries the license of GSL does not restrict scientific cooperation. It allows you to share your programs freely with others. Downloading GSL The current stable version is GSL-2.1. It was released on 11 November 2015. Details of recent changes can be found in the NEWS file. GSL can be found in the gsl subdirectory on your nearest GNU mirror http://ftpmirror.gnu.org/gsl/. Main GNU ftp site: ftp://ftp.gnu.org/gnu/gsl/ For other ways to obtain GSL, please read How to get GNU Software Installation instructions can be found in the included README and INSTALL files. Precompiled binary packages are included in most GNU/Linux distributions. A compiled version of GSL is available as part of Cygwin on Windows (but we recommend using GSL on a free operating system, such as GNU/Linux). Verifying GSL Signature To verify the signature of the GSL tarball, please download both the gsl-X.Y.tar.gz and gsl-X.Y.tar.gz.sig files. The key used to sign the official releases can be found here. The signature can be verified with the following steps:  gpg --import gsl_key.txt gpg --verify gsl-X.Y.tar.gz.sig  Documentation GSL includes a 500 page reference manual in Texinfo format. You can print the manual in postscript or read it on your system using the shell command info gsl-ref (if the library is installed). The GSL Reference Manual is available online, GSL Reference Manual - HTML GSL Reference Manual - PDF GSL Reference Manual - Gzipped Postscript The manual has been published as a printed book (under the GNU Free Documentation License), the latest edition is GNU Scientific Library Reference Manual - Third Edition (January 2009), M. Galassi et al, ISBN 0954612078 (paperback) RRP $39.95. See www.network-theory.co.uk for ordering information. A Japanese translation is also available online (may not be the most recent version). GSL Reference Manual - Japanese Translation (by Daisuke Tominaga, AIST Computational Biology Research Center) A Portuguese translation is also available online. GSL Reference Manual - Portuguese Translation (by Jorge Barros de Abreu) Supported Platforms GSL is developed on the following platform, GNU/Linux with gcc It has been reported to compile on the following other platforms, SunOS 4.1.3 & Solaris 2.x (Sparc) Alpha GNU/Linux, gcc HP-UX 9/10/11, PA-RISC, gcc/cc IRIX 6.5, gcc m68k NeXTSTEP, gcc Compaq Alpha Tru64 Unix, gcc FreeBSD, OpenBSD & NetBSD, gcc Cygwin Apple Darwin 5.4 Hitachi SR8000 Super Technical Server, cc We require that GSL should build on any UNIX-like system with an ANSI C compiler, so if doesn't, that's a bug and we would love a patch! The complete library should also pass ""make check"". If you have found a bug, please report it to bug-gsl@gnu.org. Previously submitted bug reports can be found in the bug-gsl mailing list archives and the GSL bug database. Mailing Lists Follow the links to the individual mailing lists below to subscribe or view the list archives: Bug-gsl <bug-gsl@gnu.org> mailing list -- bug reports for the GNU Scientific Library should be sent here Help-gsl <help-gsl@gnu.org> users mailing list -- for questions about installation, how GSL works and how it is used, or general questions concerning GSL. Info-gsl <info-gsl@gnu.org> mailing list -- announcements of new releases are made here. You can also follow announcements via the Savannah GSL RSS feed. Motivation Here are some of the main benefits of using a free scientific library under the GNU General Public License, allows easier collaboration, library is freely available to everyone. software using the library can be released publicly as source-code. you can adapt the source code to your needs. respects your privacy - does not impose any conditions on ""in-house"" use. you can contribute back improvements to the user community. Special Features The library uses an object-oriented design. Different algorithms can be plugged-in easily or changed at run-time without recompiling the program. It is intended for ordinary scientific users. Anyone who knows some C programming will be able to start using the library straight-away. The interface was designed to be simple to link into very high-level languages, such as GNU Guile or Python The library is thread-safe. Where possible the routines have been based on reliable public-domain Fortran packages such as FFTPACK and QUADPACK, which the developers of GSL have reimplemented in C with modern coding conventions. The library is easy to compile and does not have any dependencies on other packages. Licensing GSL is distributed under the terms of the GNU General Public License (GPL). The reasons why the GNU Project uses the GPL are described in the following articles: Copyleft: Pragmatic Idealism by Richard Stallman Why you should not use the Lesser GPL for your next library by Richard Stallman Additional information for researchers is available in the following article: Releasing Free Software if you work at a University by Richard Stallman Some answers to common questions about the license: If I write an application which uses GSL, am I forced to distribute that application? No. The license gives you the option to distribute your application if you want to. You do not have to exercise this option in the license. If I wanted to distribute an application which uses GSL, what license would I need to use? The GNU General Public License (GPL). The bottom line for commercial users: GSL can be used internally (""in-house"") without restriction, but only redistributed in other software that is under the GNU GPL. More Information If you would like to refer to the GNU Scientific Library in a journal article, the recommended way is to cite the reference manual, e.g. M. Galassi et al, GNU Scientific Library Reference Manual (3rd Ed.), ISBN 0954612078. If you want to give a url, use ""http://www.gnu.org/software/gsl/"". Related Packages GSL requires a BLAS library for vector and matrix operations. The default CBLAS library supplied with GSL can be replaced by the tuned ATLAS library for better performance, ATLAS - a portable self-optimising BLAS library with CBLAS interface ATLAS is free software and its license is compatible with the GNU GPL. Other packages that are useful for scientific computing are: GLPK - GNU Linear Programming Kit FFTW - Large-scale Fast Fourier Transforms NLopt - nonlinear optimization with unconstrained, bound-constrained, and general nonlinear inequality constraints All these packages are free software (GNU GPL/LGPL). Development GSL development is hosted on Savannah.gnu.org at http://savannah.gnu.org/projects/gsl The repository is available via 'git' with  git clone git://git.savannah.gnu.org/gsl.git  Note: if you use git, you will need automake, autoconf, libtool, GNU m4, GNU make, and GNU Texinfo (makeinfo). To begin the build process from a checkout, start with: ./autogen.sh which will prepare the package for compilation. You can then use ./configure --enable-maintainer-mode and make in the usual way. Commit notifications are available through the git repository news feed. In addition to the GSL Reference Manual, anyone wanting to work on the library should read the GSL design document, GSL Design Document - HTML GSL is a mature library with a stable API. The main emphasis is on ensuring the stability of the existing functions, tidying up and fixing any bugs that are reported, and adding new, useful algorithms which have been well tested and documented. Potential contributors are encouraged to gain familiarity with the library by investigating and fixing known problems in the BUGS database. The project is always looking to introduce new capabilities and expand or improve existing functionality. To maintain stability, any new functionality is encouraged as packages, built on top of GSL and maintained independently by their authors, as in other free software projects. The design of GSL permits extensions to be used alongside the existing library easily by simple linking. Once a new extension is proven useful and stable, it can be incorporated into the main GSL repository. Discussions about the development of the library take place on the gsl-discuss@sourceware.org mailing list. Any comments from experts in numerical analysis are welcome. You can subscribe to gsl-discuss here. GSL is part of the GNU Project and so follows the GNU Coding Standards. Extensions/Applications The following third-party packages provide extensions to GSL. If you want to add a feature to GSL we recommend that you make it an extension first. We will list it here so that people can try it out. Extensions can be incorporated after they have been tested in real use (see ""How to help"" for more information). quasimontecarlo - quasi-Monte Carlo integration routines (David Zaslavsky) ISVD - Incremental Singular Value Decomposition (Attila Axt) Marray and Tensor - extensions for multidimensional arrays and tensors (Jordi Burguet Castell) ndlinear - simpler interface for N-dimensional least squares fits (Patrick Alken) Annealing - reworking of simulating annealing with new API (alpha - Marco Maggi) jacobi-0.9 - Jacobi polynomials and operations related to Gauss-jacobi quadrature (integration, derivatives and interpolation) (Paulo Jabardo) Ziggurat Gaussian - faster gaussian generator using Ziggurat method (Jochen Voss) -- now incorporated in GSL 1.8 wigner.c - alternative Wigner coefficient calculations (large j) (J. Underwood) adaptint.c - adaptive multidimensional integration, similar to cubpack (Steven G. Johnson) jsqrng - higher dimensional quasi-random sequences (J. Scott) qrngextra - extended dimensionality QRNGs (Philipp Baecker) CQP - solves convex quadratic problems (Ewgenij Hübner) Bundle - powerful bundle minimisation algorithm (needs CQP) (Ewgenij Hübner - upgraded to v1.2, Oct 2006) Geczy - additional minimisation algorithms (Peter Geczy) Quartic - quartic polynomial solver (Andrew Steiner) Fresnel - sine and cosine fresnel integrals (Aleksey Dmitriev) SimplexImproved - alternative simplex minimiser (Ivo Alxneit) TAMUANOVA - the TAMU ANOVA package, provides single and two factor ANOVA. OOL - the ""Open Optimization Library"", provides GSL-compatible constrained optimization methods (under development). rngextra-0.2 - additional random number generators (Brian Gough, example package) Other packages: Dieharder - extensive random number test suite for GSL based on Marsaglia's Diehard tests and the NIST Statistical Test Suite (Robert G. Brown) VFGEN - generates C source code for GSL ODE systems from a user-supplied specification of a vector field (Warren Weckesser) Some applications using GSL that we know of: GSL Shell (Lua) - interface to GSL routines using the Lua scripting language. NEMO -N-body stellar dynamics toolbox, a unix-like toolset of libraries and programs, also has tools to operate on ascii tables and other types of data LUSH - Lisp Universal Shell, an object-oriented programming language with full interfaces to GSL, LAPACK, and BLAS. NumExp - interactive graphical exploration of numerical functions and algorithms (uses Gtk) LabPlot - software for data analysis and visualisation Qumax - a Quantum Monte Carlo Software for Atoms, Molecules and Solids ORSA - Orbit Reconstruction, Simulation and Analysis. QtiPlot - scientific plotting and data analysis application Rlabplus - libraries for Rlab, a high-level language for numerics Blahut - computes information theoretic rate-distortion and channel capacity Wrappers for Other Languages (not necessarily complete): JavaCPP - Java wrappers for GSL Math::GSL - Perl interface to GSL VALA - VALA bindings for GSL GSLL - Common Lisp interface to GSL FGSL - Fortran interface to GSL (under development) PyGSL - Python Bindings for GSL PyrexGsl - Pyrex interface to GSL (Pyrex is a version of Python which allows mixing of Python and C datatypes) ctypesGsl - Python ctypes-style interface to GSL (under development) Ruby/GSL - Ruby Bindings for GSL PDL::GSL - Perl Data Language interface to GSL Random Numbers (included in the main PDL distribution) R gsl - package, bindings for GSL special functions in GNU R S-lang/GSL - bindings for GSL and S-Lang Zoom - C++ wrappers for GSL special functions OCAML GSL - bindings for the OCAML functional language O2scl - a numerical C++ class library which is compatible with GSL datatypes (A.Steiner) Textbooks: ""Numerische Physik"" by Harald Wiedemann (ISBN 3-540-40774-X, Published by Springer (2004), 297 pages, in German) A textbook on numerical physics, covering classical mechanics, electrodynamics, optics, statistical physics and quantum mechanics. The example programs in the book use the GNU Scientific Library and are free software (the source code is included on a CDROM with the book). Further information about this book is available from the publisher at Springer.de. Project Background The project was conceived in 1996 by Dr M. Galassi and Dr J. Theiler of Los Alamos National Laboratory. They were joined by other physicists who also felt that the licenses of existing libraries were hindering scientific cooperation. Most of the library has been written by a relatively small number of people with backgrounds in computational physics in order to provide a consistent and reasonably-designed framework. Overall development of the library and the design and implementation of the major modules was carried out by Dr G. Jungman and Dr B. Gough. Modules were also written by Dr J. Davies, R. Priedhorsky, Dr M. Booth, and Dr F. Rossi, along with many useful contributions from others in the user community. Debian packages for the library are maintained by Dr D. Eddelbuettel. Release History gsl-2.1 was released in November 2015. gsl-2.0 was released in October 2015. gsl-1.16 was released in July 2013. gsl-1.15 was released in May 2011. gsl-1.14 was released in March 2010. gsl-1.13 was released in September 2009. gsl-1.12 was released in December 2008. gsl-1.11 was released in March 2008. gsl-1.10 was released in September 2007. gsl-1.9 was released in February 2007. gsl-1.8 was released in April 2006. gsl-1.7 was released in September 2005. gsl-1.6 was released in December 2004. gsl-1.5 was released in June 2004. gsl-1.4 was released in August 2003. gsl-1.3 was released in December 2002. gsl-1.2 was released in July 2002. gsl-1.1.1 was released in March 2002. gsl-1.1 was released in February 2002. gsl-1.0 was released in November 2001. gsl-0.9.4 was released in October 2001 (fifth beta-test release). gsl-0.9.3 was released in September 2001 (fourth beta-test release). gsl-0.9.2 was released in September 2001 (third beta-test release). gsl-0.9.1 was released in August 2001 (second beta-test release). gsl-0.9 was released in July 2001 (first beta-test release). gsl-0.8 was released in May 2001. gsl-0.7 was released in October 2000. gsl-0.6 was released in June 2000. gsl-0.5 was released in December 1999. gsl-0.4.1 was released in February 1999. gsl-0.4 was released in August 1998. gsl-0.3f was released in May 1998. gsl-0.3b was released in February 1998. gsl-0.2 was released in October 1996. gsl-0.1 was released in sometime in 1996. gsl-0.0 was released in sometime in 1996. The gsl project was started in May 1996 (earliest recorded changelog entry). GNU home page FSF home page GNU Art GNU's Who? Free Software Directory Hardware Site map “Our mission is to preserve, protect and promote the freedom to use, study, copy, modify, and redistribute computer software, and to defend the rights of Free Software users.” The Free Software Foundation is the principal organizational sponsor of the GNU Operating System. Support GNU and the FSF by buying manuals and gear, joining the FSF as an associate member, or making a donation, either directly to the FSF or via Flattr. back to top Please send general FSF & GNU inquiries to <gnu@gnu.org>. There are also other ways to contact the FSF. Broken links and other corrections or suggestions can be sent to <bug-gsl@gnu.org>. Please see the Translations README for information on coordinating and submitting translations of this article. Copyright © 2009 Free Software Foundation, Inc. This page is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License. Copyright Infringement Notification Updated: $Date: 2016/05/16 20:59:26 $"	"null"	"null"	"The GNU Scientific Library; a sophisticated numerical library. only."	"true"
"Numerical"	"KISS FFT"	"https://sourceforge.net/projects/kissfft/"	"A very simple fast Fourier transform library.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"null"	"null"	"null"	"Kiss FFT download | SourceForge.net SourceForge Browse Enterprise Blog Deals Help Create Log In or Join Solution Centers Go Parallel Resources Newsletters Cloud Storage Providers Business VoIP Providers Call Center Providers Home Browse Audio & Video Sound/Audio Analysis Kiss FFT Kiss FFT Brought to you by: mborg Summary Files Reviews Support Wiki Mercurial ▾ Code Kissfft-blank Tickets ▾ Feature Requests Bugs Support Requests Patches News Discussion Donate ★ 5.0 Stars (15) 333 Downloads (This Week) Last Update: 2013-06-20 Download kiss_fft130.zip Browse All Files Description A Fast Fourier Transform based up on the principle, ""Keep It Simple, Stupid."" Kiss FFT is a very small, reasonably efficient, mixed radix FFT library that can use either fixed or floating point data types. Kiss FFT Web Site Categories Analysis, Mathematics License BSD License KEEP ME UPDATED By clicking on ""Follow"" below, you are agreeing to the Terms of Use and the Privacy Policy. Get notifications on updates for this project. Get newsletters with site news, white paper/events resources, and sponsored content from our partners. Invalid email address. Please try again. Sent to None. Follow You seem to have CSS turned off. Please don't fill out this field. You seem to have CSS turned off. Please don't fill out this field. User Ratings 5.0 out of 5 stars ★★★★★ ★★★★ ★★★ ★★ ★ 15 0 0 0 0 ease 1 of 5 2 of 5 3 of 5 4 of 5 5 of 5 5 / 5 features 1 of 5 2 of 5 3 of 5 4 of 5 5 of 5 5 / 5 design 1 of 5 2 of 5 3 of 5 4 of 5 5 of 5 5 / 5 support 1 of 5 2 of 5 3 of 5 4 of 5 5 of 5 4 / 5 Write a Review User Reviews Filter All All ★★★★★ ★★★★ ★★★ ★★ ★ pepper-jack 1 of 5 2 of 5 3 of 5 4 of 5 5 of 5 The best........ EVER!!!!!!!!!, and all other libraries suck compared to this one Posted 06/09/2016 kdidkovsky 1 of 5 2 of 5 3 of 5 4 of 5 5 of 5 A great library - very simple to use, with the most convenient license and very good performance. The only additional thing I'd wish is more detailed documentation. Posted 01/31/2014 capn_fish 1 of 5 2 of 5 3 of 5 4 of 5 5 of 5 Exactly as advertised- small, simple to use, supports floating- and fixed-point versions, and even comes with notes on what you can easily mess with to reduce the code size. Posted 10/28/2013 charlifiiiii 1 of 5 2 of 5 3 of 5 4 of 5 5 of 5 great, efficient lib. Thanks ! Note: Including a very simple ""gettingstarted.c"" could be a plus, to help users to understand in 1 minute how to do a basic floating point fft. Regards Posted 08/22/2013 ckorda 1 of 5 2 of 5 3 of 5 4 of 5 5 of 5 I use Kiss FFT for real-time audio spectrum analysis, and it's excellent. It's easy to understand and integrate, it supports both floats and doubles, it compiles clean in .NET 2008 (32-bit and 64-bit), it's plenty fast enough for most needs, and it's incredibly small. Posted 04/06/2013 Read more reviews Additional Project Details Languages English Intended Audience Developers Programming Language C Registered 2003-05-18 Recommended Projects AVR FFT LCD Exocortex.DSP fftw++ Deals Top Searches c# fft fft fast fourier transform audio fft c++ fft fourier fft avr fft c# fftw short-time fourier transform Report inappropriate content Thanks for helping keep SourceForge clean. Screenshot instructions: Windows Mac Red Hat Linux   Ubuntu Click URL instructions: Right-click on ad, choose ""Copy Link"", then paste here → (This may not be possible with some types of ads) More information about our ad policies X You seem to have CSS turned off. Please don't fill out this field. You seem to have CSS turned off. Please don't fill out this field. Briefly describe the problem (required): Upload screenshot of ad (required): Select a file, or drag & drop file here. ✔ ✘ Please provide the ad click URL, if possible: SourceForge About Site Status @sfnet_ops Find and Develop Software Create a Project Software Directory Top Downloaded Projects Community Blog @sourceforge Resources Help Site Documentation Support Request © 2016 Slashdot Media. All Rights Reserved. Terms Privacy Opt Out Choices Advertise Get latest updates about Open Source Projects, Conferences and News. Sign up for the SourceForge newsletter: I agree to receive quotes, newsletters and other information from sourceforge.net and its partners regarding IT services and products. I understand that I can withdraw my consent at any time. Please refer to our Privacy Policy or Contact Us for more details You seem to have CSS turned off. Please don't fill out this field. You seem to have CSS turned off. Please don't fill out this field. No, thanks Screenshots can attract more users to your project. Features can attract more users to your project."	"null"	"null"	"A very simple fast Fourier transform library.."	"true"
"Numerical"	"LAPACKE"	"http://www.netlib.org/lapack/lapacke.html"	"A C interface to.."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"The LAPACKE C Interface to LAPACK The LAPACKE C Interface to LAPACK Table of Contents JavaScript must be enabled in your browser to display the table of contents. Introduction This document describes a two-level C interface to LAPACK, consisting of a high-level interface and a middle-level interface. The high-level interface handles all workspace memory allocation internally, while the middle-level interface requires the user to provide workspace arrays as in the original FORTRAN interface. Both interfaces provide support for both column-major and row-major matrices. The prototypes for both interfaces, associated macros and type definitions are contained in the header file lapacke.h. Naming Schemes The naming scheme for the high-level interface is to take the FORTRAN LAPACK routine name, make it lower case, and add the prefix LAPACKE_. For example, the LAPACK subroutine DGETRF becomes LAPACKE_dgetrf. The naming scheme for the middle-level interface is to take the FORTRAN LAPACK routine name, make it lower case, then add the prefix LAPACKE_ and the suffix _work. For example, the LAPACK subroutine DGETRF becomes LAPACKE_dgetrf_work. Complex Types Complex data types are defined by the macros lapack_complex_float and lapack_complex_double, which represent single precision and double precision complex data types respectively. It is assumed throughout that the real and imaginary components are stored contiguously in memory, with the real component first. The lapack_complex_float and lapack_complex_double macros can be either C99 _Complex types, a C struct defined type, C++ STL complex types, or a custom complex type. See lapacke.h for more details. Array Arguments Arrays are passed as pointers, not as a pointer to pointers. All the LAPACKE routines that take one or more 2D arrays as a pointer receive a single extra parameter of type int. This argument must be equal to either LAPACK_ROW_MAJOR or LAPACK_COL_MAJOR which are defined in lapacke.h, specifying whether the arrays are stored in row-major or column-major order. If a routine has multiple array inputs, they must all use the same ordering. Note that using row-major ordering may require more memory and time than column-major ordering, because the routine must transpose the row-major order to the column-major order required by the underlying LAPACK routine. Each 2D array argument in a FORTRAN LAPACK routine has an additional argument that specifies its leading dimension. For row-major 2D arrays, elements within a row are assumed to be contiguous and elements from one row to the next are assumed to be a leading dimension apart. For column-major 2D arrays, elements within a column are assumed to be contiguous and elements from one column to the next are assumed to be a leading dimension apart. Aliasing of Arguments Unless specified otherwise, only input arguments (that is, scalars passed by values and arrays specified with the const qualifier) may be legally aliased on a call to C interface to LAPACK. INFO Parameters The LAPACKE interface functions set their lapack_int return value to the value of the INFO parameter, which contains information such as error and exit conditions. This differs from LAPACK routines, which return this information as a FORTRAN integer parameter. In LAPACKE, INFO is used exactly as it is in LAPACK. If INFO returns the row or column number of a matrix using 1-based indexing in FORTRAN, the value is not adjusted for zero-based indexing. NaN Checking The high-level interface includes an optional, on by default, NaN check on all matrix inputs before calling any LAPACK routine. This option affects all routines. If the inputs contain any NaNs, the input parameter corresponding matrix will be flagged with an INFO parameter error. For example, if the fifth parameter is found to contain a NaN, the function will return with the value -5. The NaN check, as well as other parameters, can be disabled by defining LAPACK_DISABLE_NAN_CHECK macro in lapacke.h. The middle-level interface does not contain the NaN check. Integers Variables with the FORTRAN type integer are converted to lapack_int in LAPACKE. This conforms with modifiable integer type size, especially given ILP64 programming model: re-defining lapack_int as long int (8 bytes) will be enough to support this model, as lapack_int is defined as int (4 bytes) by default, supporting LP64 programming model. Logicals FORTRAN logicals are converted to lapack_logical, which is defined as lapack_int. Memory Management All memory management is handled by the functions LAPACKE_malloc and LAPACKE_free. This allows users to easily use their own memory manager instead of the default by modifying their definitions in lapacke.h. This interface should be thread-safe to the extent that these memory management routines and the underlying LAPACK routines are thread-safe. New Error Codes Since the high level interface does not use work arrays, error notification is needed in the event of a user running out of memory. If a work array cannot be allocated, LAPACK_WORK_MEMORY_ERROR is returned by the function; if there was insufficient memory to complete a transposition, LAPACK_TRANSPOSE_MEMORY_ERROR is returned. Function List This section list the currently available LAPACK subroutines that are available in the LAPACKE C interface. The LAPACK base names are given below; the corresponding LAPACKE function name is LAPACKE_xbase or LAPACKE_xbase_work where x is the type: s or d for single or double precision real, c or z for single or double precision complex, with base representing the base name. Function prototypes are given in the file lapacke.h. See the LAPACK documentation for detailed information about the routines and their parameters. Real Functions The following LAPACK subroutine base names are supported for single precision (s) and double precision (d+), in both the high-level and middle-level interfaces: bdsdc bdsqr disna gbbrd gbcon gbequ gbequb gbrfs gbrfsx gbsv gbsvx gbsvxx gbtrf gbtrs gebak gebal gebrd gecon geequ geequb gees geesx geev geevx gehrd gejsv gelqf gels gelsd gelss gelsy geqlf geqp3 geqpf geqrf geqrfp gerfs gerfsx gerqf gesdd gesv gesvd gesvj gesvx gesvxx getrf getri getrs ggbak ggbal gges ggesx ggev ggevx ggglm gghrd gglse ggqrf ggrqf ggsvd ggsvp gtcon gtrfs gtsv gtsvx gttrf gttrs hgeqz hsein hseqr opgtr opmtr orgbr orghr orglq orgql orgqr orgrq orgtr ormbr ormhr ormlq ormql ormqr ormrq ormrz ormtr pbcon pbequ pbrfs pbstf pbsv pbsvx pbtrf pbtrs pftrf pftri pftrs pocon poequ poequb porfs porfsx posv posvx posvxx potrf potri potrs ppcon ppequ pprfs ppsv ppsvx pptrf pptri pptrs pstrf ptcon pteqr ptrfs ptsv ptsvx pttrf pttrs sbev sbevd sbevx sbgst sbgv sbgvd sbgvx sbtrd sfrk spcon spev spevd spevx spgst spgv spgvd spgvx sprfs spsv spsvx sptrd sptrf sptri sptrs stebz stedc stegr stein stemr steqr sterf stev stevd stevr stevx sycon syequb syev syevd syevr syevx sygst sygv sygvd sygvx syrfs syrfsx sysv sysvx sysvxx sytrd sytrf sytri sytrs tbcon tbrfs tbtrs tfsm tftri tfttp tfttr tgevc tgexc tgsen tgsja tgsna tgsyl tpcon tprfs tptri tptrs tpttf tpttr trcon trevc trexc trrfs trsen trsna trsyl trtri trtrs trttf trttp tzrzf Complex Functions The following LAPACK subroutine base names are supported for complex single precision (c) and complex double precision (z), in both the high-level and middle-level interfaces: bdsqr gbbrd gbcon gbequ gbequb gbrfs gbrfsx gbsv gbsvx gbsvxx gbtrf gbtrs gebak gebal gebrd gecon geequ geequb gees geesx geev geevx gehrd gelqf gels gelsd gelss gelsy geqlf geqp3 geqpf geqrf geqrfp gerfs gerfsx gerqf gesdd gesv gesvd gesvx gesvxx getrf getri getrs ggbak ggbal gges ggesx ggev ggevx ggglm gghrd gglse ggqrf ggrqf ggsvd ggsvp gtcon gtrfs gtsv gtsvx gttrf gttrs hbev hbevd hbevx hbgst hbgv hbgvd hbgvx hbtrd hecon heequb heev heevd heevr heevx hegst hegv hegvd hegvx herfs herfsx hesv hesvx hesvxx hetrd hetrf hetri hetrs hfrk hgeqz hpcon hpev hpevd hpevx hpgst hpgv hpgvd hpgvx hprfs hpsv hpsvx hptrd hptrf hptri hptrs hsein hseqr pbcon pbequ pbrfs pbstf pbsv pbsvx pbtrf pbtrs pftrf pftri pftrs pocon poequ poequb porfs porfsx posv posvx posvxx potrf potri potrs ppcon ppequ pprfs ppsv ppsvx pptrf pptri pptrs pstrf ptcon pteqr ptrfs ptsv ptsvx pttrf pttrs spcon sprfs spsv spsvx sptrf sptri sptrs stedc stegr stein stemr steqr sycon syequb syrfs syrfsx sysv sysvx sysvxx sytrf sytri sytrs tbcon tbrfs tbtrs tfsm tftri tfttp tfttr tgevc tgexc tgsen tgsja tgsna tgsyl tpcon tprfs tptri tptrs tpttf tpttr trcon trevc trexc trrfs trsen trsna trsyl trtri trtrs trttf trttp tzrzf ungbr unghr unglq ungql ungqr ungrq ungtr unmbr unmhr unmlq unmql unmqr unmrq unmrz unmtr upgtr upmtr Mixed Precision Functions The following LAPACK subroutine base names are supported only for double precision (d) and complex double precision (z): sgesv sposv Examples This section contains examples of calling LAPACKE functions from a C program. Calling DGEQRF Suppose you wish to call the function DGEQRF, which computes the QR factorization of a double precision real rectangular matrix in LAPACK, and you wish to have the LAPACKE interface handle the necessary work space memory allocation for you. The base name for this function is geqrf, which is included in the list of real functions above. The LAPACKE function name is then constructed by prepending LAPACK_ followed by d to the base name: LAPACKE_dgeqrf. We will assume that our matrix is stored in column-major order in the m-by-n array a, which has a leading dimension of lda. The variable declarations should be as follows: The LAPACKE function call is then: Calling CUNGQR Suppose you wish to call the function CUNGQR, which generates Q from the results of a QR factorization of a single precision complex rectangular matrix, and you wish to provide the required workspace. The base name for this function is ungqr, which is included in the list of complex functions above. The LAPACKE function name is then constructed by prepending LAPACK_ followed by c to the base name, with the suffix _work to indicate that the user will supply the work space: LAPACKE_cungqr_work. We will assume again that our matrix is stored in column-major order in the m-by-n array a, which has a leading dimension of lda. From the LAPACK documentation, the work space array work must have a length of at least n; the length of work is given in lwork. The variable declarations should be as follows: The LAPACKE function call is then: Calling DGELS In this example, we wish solve the least squares problem min_x || B - Ax || for two right-hand sides using the LAPACK routine DGELS. For input we will use the 5-by-3 matrix     ( 1  1  1 )     ( 2  3  4 ) A = ( 3  5  2 )     ( 4  2  5 )     ( 5  4  3 ) and the 5-by-2 matrix     ( -10 -3 )     (  12 14 ) B = (  14 12 )     (  16 16 )     (  18 16 ) We will first store the input matrix as a static C two-dimensional array, which is stored in row-major order, and let LAPACKE handle the work space array allocation. The LAPACK base name for this function is gels, and we will use double precision (d), so the LAPACKE function name is LAPACKE_dgels. thus lda=3 and ldb=2. The output for each right hand side is stored in b as consecutive vectors of length 3. The correct answer for this problem is the 3-by-2 matrix ( 2 1 ) ( 1 1 ) ( 1 2 ) A complete C program for this example is given below. Note that when the arrays are passed to the LAPACK routine, they must be dereferenced, since LAPACK is expecting arrays of type double *, not double **. Alternatively, we can use column-major ordering for the matrices in this example, as shown below. Here, the matrices are stored as static one-dimensional C arrays. These arrays have a leading dimension that is equal to the number of rows. Calling CGEQRF and the CBLAS In this example, we will call the LAPACK routine CGEQRF to compute the QR factorization of a matrix. We then call CUNGQR to construct the Q matrix and then use the CBLAS routine CGEMM to compute QH Q - I to check that Q is Hermitian. The error ||QH Q - I|| is printed at the end of the program. In the first version, given below, we let LAPACKE handle the memory allocation for the workspace internally. The second version, shown below, uses the workspace query facility for both CGEQRF and CUNGQR to obtain the optimal size for the parameter lwork, which we use to allocate our own workspace in the array work. Last updated 2016-04-28 20:18:03 PDT"	"null"	"null"	"A C interface to.."	"true"
"Numerical"	"LAPACK"	"http://www.netlib.org/lapack/"	"A C interface to.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"null"	"null"	"null"	"LAPACK — Linear Algebra PACKage LAPACK — Linear Algebra PACKage Menu JavaScript must be enabled in your browser to display the table of contents. Version 3.6.1 Browse the LAPACK User Forum Contact the LAPACK team Get the latest LAPACK News # access LAPACK is a software package provided by Univ. of Tennessee; Univ. of California, Berkeley; Univ. of Colorado Denver; and NAG Ltd.. Presentation LAPACK is written in Fortran 90 and provides routines for solving systems of simultaneous linear equations, least-squares solutions of linear systems of equations, eigenvalue problems, and singular value problems. The associated matrix factorizations (LU, Cholesky, QR, SVD, Schur, generalized Schur) are also provided, as are related computations such as reordering of the Schur factorizations and estimating condition numbers. Dense and banded matrices are handled, but not general sparse matrices. In all areas, similar functionality is provided for real and complex matrices, in both single and double precision. The original goal of the LAPACK project was to make the widely used EISPACK and LINPACK libraries run efficiently on shared-memory vector and parallel processors. On these machines, LINPACK and EISPACK are inefficient because their memory access patterns disregard the multi-layered memory hierarchies of the machines, thereby spending too much time moving data instead of doing useful floating-point operations. LAPACK addresses this problem by reorganizing the algorithms to use block matrix operations, such as matrix multiplication, in the innermost loops. These block operations can be optimized for each architecture to account for the memory hierarchy, and so provide a transportable way to achieve high efficiency on diverse modern machines. We use the term ""transportable"" instead of ""portable"" because, for fastest possible performance, LAPACK requires that highly optimized block matrix operations be already implemented on each machine. LAPACK routines are written so that as much as possible of the computation is performed by calls to the Basic Linear Algebra Subprograms (BLAS). LAPACK is designed at the outset to exploit the Level 3 BLAS — a set of specifications for Fortran subprograms that do various types of matrix multiplication and the solution of triangular systems with multiple right-hand sides. Because of the coarse granularity of the Level 3 BLAS operations, their use promotes high efficiency on many high-performance computers, particularly if specially coded implementations are provided by the manufacturer. Highly efficient machine-specific implementations of the BLAS are available for many modern high-performance computers. For details of known vendor- or ISV-provided BLAS, consult the BLAS FAQ. Alternatively, the user can download ATLAS to automatically generate an optimized BLAS library for the architecture. A Fortran 77 reference implementation of the BLAS is available from netlib; however, its use is discouraged as it will not perform as well as a specifically tuned implementation. Acknowledgments: Since 2010, this material is based upon work supported by the National Science Foundation under Grant No. NSF-OCI-1032861. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation (NSF). Until 2006, this material was based upon work supported by the National Science Foundation under Grant No. ASC-9313958, NSF-0444486 and DOE Grant No. DE-FG03-94ER25219. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation (NSF) or the Department of Energy (DOE). The LAPACK project is also sponsored in part by MathWorks and Intel since many years. Software Licensing LAPACK is a freely-available software package. It is available from netlib via anonymous ftp and the World Wide Web at http://www.netlib.org/lapack . Thus, it can be included in commercial software packages (and has been). We only ask that proper credit be given to the authors. The license used for the software is the modified BSD license, see: LICENSE Like all software, it is copyrighted. It is not trademarked, but we do ask the following: If you modify the source for these routines we ask that you change the name of the routine and comment the changes made to the original. We will gladly answer any questions regarding the software. If a modification is done, however, it is the responsibility of the person who modified the routine to provide support. LAPACK, version 3.6.1 Download: lapack-3.6.1.tgz LAPACK 3.6.1 Release Notes Updated: June 18, 2016 LAPACK Errata (Current known bugs) Standard C language APIs for LAPACK collaboration LAPACK and INTEL Math Kernel Library Team LAPACK C INTERFACE is now included in the LAPACK package (in the lapacke directory) LAPACKE User Guide Updated: November 16, 2013 header files: lapacke.h, lapacke_config.h, lapacke_mangling.h, lapacke_utils.h LAPACK for Windows LAPACK is built under Windows using Cmake the cross-platform, open-source build system. The new build system was developed in collaboration with Kitware Inc. A dedicated website (http://icl.cs.utk.edu/lapack-for-windows/lapack) is available for Windows users. You will find information about your configuration need. You will be able to download BLAS, LAPACK, LAPACKE pre-built libraries. You will learn how you can directly run LAPACKE from VS Studio (just C code, no Fortran!!!). LAPACK now offers Windows users the ability to code in C using Microsoft Visual Studio and link to LAPACK Fortran libraries without the need of a vendor-supplied Fortran compiler add-on. To get more information, please refer to lawn 270. You will get step by steps procedures Easy Windows Build. SVN Access The LAPACK SVN repository is open for read-only for our users to be able to get the latest bug fixed. svn co https://icl.cs.utk.edu/svn/lapack-dev/lapack/trunk Support Browse the LAPACK/ScaLAPACK User Forum Contact the LAPACK team Archives of LAPACK mailing list Do not forget to check the current LAPACK errata to check current bug status. Contributors LAPACK is a community-wide effort.LAPACK relies on many contributors, and we would like to acknowledge their outstanding work. Here is the list of LAPACK contributors since 1992. If you are wishing to contribute, please have a look at the LAPACK Program Style. This document has been written to facilitate contributions to LAPACK by documenting their design and implementation guidelines. LAPACK Project Software Grant and Corporate Contributor License Agreement (“Agreement”) [Download] Contributions are always welcome and can be sent to the LAPACK team. Documentation Release Notes The LAPACK Release Notes contain the history of the modifications made to the LAPACK library between each new version. Improvements and Bugs LAPACK is a currently active project, we are striving to bring new improvements and new algorithms on a regular basis. Here is the list of the improvement since LAPACK 3.0. Please contribute to our wishlist if you feel some functionality or algorithms are missing by emailing the LAPACK team. Current LAPACK errata Here is the list of the bugs (corrected, confirmed and to be confirmed) since LAPACK 3.0. FAQ Consult LAPACK Frequently Asked Questions. Please contribute to our FAQ if you feel some questions are missing by emailing the LAPACK team. The LAPACK User Forum is also a good source to find answers. Browse, Download LAPACK routines with on-line documentation browser Explore LAPACK code Here you will be able to browse through the many LAPACK functions, and also download individual routine plus its dependency. To access a routine, either use the search functionality or go through the different modules. Users' Guide HTML version of the LAPACK Users' Guide, Third Edition LAPACK Quick Reference Guide to the Driver Routines (VERSION 3.0) HTML version of ""Quick Installation Guide for LAPACK"" LAPACK Working Note 81: Quick Installation Guide for LAPACK on Unix Systems (25 pages) (VERSION 3.0) HTML version of ""LAPACK Installation Guide"" LAPACK Working Note 41: LAPACK Installation Guide (VERSION 3.0) Manpages gzip tar file of the manual pages for LAPACK Please follow the instructions of the README to install the LAPACK manpages on your machine. The LAPACK team would like to thank Sylvestre Ledru for helping us maintaing those manpages and Albert from the Doxygen team. LAWNS: LAPACK Working Notes LAWNS Release History Version 1.0 : February 29, 1992 Revised, Version 1.0a: June 30, 1992 Revised, Version 1.0b: October 31, 1992 Revised, Version 1.1: March 31, 1993 Version 2.0: September 30, 1994 Version 3.0: June 30, 1999 Update, Version 3.0: October 31, 1999 Update, Version 3.0: May 31, 2000 Version 3.1.0: November 12, 2006 Version 3.1.1: February 26, 2007 Version 3.2: November 18, 2008 Version 3.2.1: April 17, 2009 Version 3.2.2: June 30, 2010 Version 3.3.0: November 14, 2010 Version 3.3.1: April 18, 2011 Version 3.4.0: November 11, 2011 Version 3.4.1: April 20, 2012 Version 3.4.2: September 25, 2012 Version 3.5.0: November 19, 2013 Version 3.6.0: November 15, 2015 *Version 3.6.1: June 18, 2016* Previous Release LAPACK, version 3.6.1 Download: lapack-3.6.1.tgz LAPACK 3.6.1 Release Notes Updated: June 18, 2016 LAPACK, version 3.6.0 Download: lapack-3.6.0.tgz LAPACK 3.6.0 Release Notes Updated: November 15, 2015 LAPACK, version 3.5.0 Download: lapack-3.5.0.tgz LAPACK 3.5.0 Release Notes Updated: November 19, 2013 LAPACK, version 3.4.2 Download: lapack-3.4.2.tgz LAPACK 3.4.2 Release Notes Updated: September 25, 2012 LAPACK, version 3.4.1 Download: lapack-3.4.1.tgz LAPACK 3.4.1 Release Notes Updated: April 20, 2012 LAPACK, version 3.4.0 Download: lapack-3.4.0.tgz LAPACK 3.4.0 Release Notes Updated: November 11, 2011 LAPACK, version 3.3.1 Download: lapack-3.3.1.tgz LAPACK 3.3.1 Release Notes Updated: April 18, 2011 LAPACK version 3.3.0 Download: lapack-3.3.0.tgz LAPACK 3.3.0 Release Notes Updated: November 14, 2010 LAPACK version 3.2.2 Download: lapack-3.2.2.tgz LAPACK 3.2.2 Release Notes Updated: June 30, 2010 LAPACK version 3.2.1 Download: lapack-3.2.1.tgz LAPACK 3.2.1 Release Notes Updated: April 17, 2009 LAPACK version 3.2 with CMAKE package Download: lapack-3.2.1-CMAKE.tgz Download: lapack-3.2.1-CMAKE.zip LAPACK 3.2.2 Release Notes Updated: January 26, 2010 LAPACK version 3.2 Download: lapack-3.2.tgz LAPACK 3.2 Release Notes Updated: November 18, 2008 LAPACK version 3.1.1 with manpages and html Download: lapack-3.1.1.tgz LAPACK 3.1.1 Release Notes Updated: February 26, 2007 LAPACK version 3.1.1 Download: lapack-lite-3.1.1.tgz LAPACK 3.1.1 Release Notes Updated: February 26, 2007 LAPACK version 3.1 Download: lapack-lite-3.1.0.tgz LAPACK 3.1 Release Notes Updated: November 12, 2006 LAPACK version 3.0 + UPDATES Download: lapack-3.0.tgz Updated: May 31, 2000 LAPACK UPDATES for version 3.0 Download: update.tgz Instructions: cd LAPACK; gunzip -c update.tgz | tar xvf - Updated: May 31, 2000 Vendors LAPACK library Please report to our FAQ to know the list of the current vendors implementations. Related Projects CLAPACK CLAPACK is an f2c’ed conversion of LAPACK CLAPACK website ScaLAPACK ScaLAPACK is a distributed-memory implementation of LAPACK ScaLAPACK website PLASMA The Parallel Linear Algebra for Scalable Multi-core Architectures (PLASMA) project aims to address the critical and highly disruptive situation that is facing the Linear Algebra and High Performance Computing community due to the introduction of multi-core architectures. PLASMA’s ultimate goal is to create software frameworks that enable programmers to simplify the process of developing applications that can achieve both high performance and portability across a range of new architectures. The development of programming models that enforce asynchronous, out of order scheduling of operations is the concept used as the basis for the definition of a scalable yet highly efficient software framework for Computational Linear Algebra applications. PLASMA website MAGMA The MAGMA (Matrix Algebra on GPU and Multicore Architectures) project aims to develop a dense linear algebra library similar to LAPACK but for heterogeneous/hybrid architectures, starting with current ""Multicore+GPU"" systems. The MAGMA research is based on the idea that, to address the complex challenges of the emerging hybrid environments, optimal software solutions will themselves have to hybridize, combining the strengths of different algorithms within a single framework. Building on this idea, we aim to design linear algebra algorithms and frameworks for hybrid manycore and GPUs systems that can enable applications to fully exploit the power that each of the hybrid components offers. MAGMA website Related older Projects Fortran95 interface to LAPACK LAPACK 95 by Jerzy Waśniewski Fortran-to-Java LAPACK JLAPACK C++ implementation of LAPACK LAPACK extensions for high performance linear algebra computations. This version includes support for solving linear systems using LU, Cholesky, and QR matrix factorizations. lapack++ by Roldan Pozo essl Subdirectory containing CCI (Call Conversion Interface) for LAPACK/ESSL. See lawn82 for more information. Last updated 2016-06-18 13:39:07 PDT"	"null"	"null"	"A C interface to.."	"true"
"Numerical"	"PARI/GP"	"http://pari.math.u-bordeaux.fr/"	"A computer algebra system for number theory; includes a compiler to C. or later."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"null"	"null"	"null"	"PARI/GP Development Headquarters Main   Download   Packages   GP in your browser   Timeline   Search Support   FAQ   Documentation   Tutorials   Ateliers PARI/GP   Mailing Lists GP scripts library   Contributed scripts Development   Bugs   Latest Changes   Version Control   Coding Guidelines   PariDroid   Funding Tests & benchmarks   Buildlogs   Coverage report   Benchmarks Miscellaneous   WWW Stats   Logo   Fun!   Links PARI/GP home PARI/GP Calcul formel, théorie algébriques des nombres, courbes elliptiques, fonctions transcendantes GPLv2+ PARI/GP is a widely used computer algebra system designed for fast computations in number theory (factorizations, algebraic number theory, elliptic curves...), but also contains a large number of other useful functions to compute with mathematical entities such as matrices, polynomials, power series, algebraic numbers etc., and a lot of transcendental functions. PARI is also available as a C library to allow for faster computations. Originally developed by Henri Cohen and his co-workers (Université Bordeaux I, France), PARI is now under the GPL and maintained by Karim Belabas with the help of many volunteer contributors. PARI is a C library, allowing fast computations. gp is an easy-to-use interactive shell giving access to the PARI functions. GP is the name of gp's scripting language. gp2c, the GP-to-C compiler, combines the best of both worlds by compiling GP scripts to the C language and transparently loading the resulting functions into gp. (gp2c-compiled scripts will typically run 3 or 4 times faster.) gp2c currently only understands a subset of the GP language. News: Run PARI/GP in your browser! The workshop Atelier PARI/GP 2017 will take place (Jan 9th-13th 2017) at Institut Camille Jordan (Lyon). PARI/GP Development Last Modified: 2016-03-22 20:34:27 Copyleft © 2003-2016 the PARI group."	"null"	"null"	"A computer algebra system for number theory; includes a compiler to C. or later."	"true"
"Parallel Programming"	"PETSc"	"http://www.mcs.anl.gov/petsc/"	"A suite of data structures and routines for scalable parallel solution of scientific applications modelled by partial differential equations.."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"null"	"null"	"null"	"PETSc: Home Page PETSc Portable, Extensible Toolkit for Scientific Computation Home Download Features Documentation Manual pages and Users Manual Citing PETSc Tutorials Installation SAWs Changes BugReporting CodeManagement FAQ License Applications/Publications Miscellaneous External Software Developers Site Toggle Search News: PETSc User Meeting, June 28-30, 2016 The current version of PETSc is 3.7; released April 25, 2016. PETSc, pronounced PET-see (the S is silent), is a suite of data structures and routines for the scalable (parallel) solution of scientific applications modeled by partial differential equations. It supports MPI, and GPUs through CUDA or OpenCL, as well as hybrid MPI-GPU parallelism. Scientific applications that use PETSc Features of the PETSc libraries (and a recent podcast) Linear system solvers accessible from PETSc Related packages that use PETSc MOOSE - Multiphysics Object-Oriented Simulation Environment finite element framework, built on top of libMesh and PETSc SLEPc - Scalable Library for Eigenvalue Problems COOLFluiD - CFD, plasma and multi-physics simulation package Fluidity - a finite element/volume fluids code OpenFVM - finite volume based CFD solver OOFEM - object oriented finite element library libMesh - adaptive finite element library FEniCS - sophisticated Python based finite element simulation package Firedrake - sophisticated Python based finite element simulation package DEAL.II - sophisticated C++ based finite element simulation package PHAML - The Parallel Hierarchical Adaptive MultiLevel Project Chaste - Cancer, Heart and Soft Tissue Environment PyClaw - A massively parallel, high order accurate, hyperbolic PDE solver PetIGA - A framework for high performance Isogeometric Analysis Python Bindings petsc4py from Lisandro Dalcin at CIMEC Elefant from the SML group at NICTA Java Bindings jpetsctao from Hannes Sommer Packages that PETSc can optionally use PETSc is developed as open-source, requests and contributions are welcome. Who are we? Questions and Bug Reports Applications FAQ Tutorials Mailing Lists Citing PETSc Acknowledgements Funding"	"null"	"null"	"A suite of data structures and routines for scalable parallel solution of scientific applications modelled by partial differential equations.."	"true"
"Parallel Programming"	"SLEPc"	"http://slepc.upv.es/"	"A software library for the solution of large, sparse eigenvalue problems on parallel computers. only."	"null"	"null"	"null"	"GNU LGPL3"	"http://www.gnu.org/licenses/lgpl.html"	"null"	"null"	"null"	"null"	"null"	"SLEPc - Scalable Library for Eigenvalue Problem Computations This is the home page of SLEPc, the Scalable Library for Eigenvalue Problem Computations. SLEPc is a software library for the solution of large scale sparse eigenvalue problems on parallel computers. It is an extension of PETSc and can be used for linear eigenvalue problems in either standard or generalized form, with real or complex arithmetic. It can also be used for computing a partial SVD of a large, sparse, rectangular matrix, and to solve nonlinear eigenvalue problems (polynomial or general). Additionally, SLEPc provides solvers for the computation of the action of a matrix function on a vector. The current version of SLEPc is 3.7, released in May, 2016. SLEPc is based on the PETSc data structures and it employs the MPI standard for message-passing communication. It is being developed by researchers from Universitat Politècnica de València (Spain). For a summary of its functionality, download the SLEPc 1-page flyer:   Latest News and Forthcoming Events subscribe May 27, 2016 New patch release: slepc-3.7.1 contains miscellaneous fixes, mainly related to the MFNKRYLOV and PEPJD solvers. May 16, 2016 SLEPc 3.7 has been released. The distribution file is available at the download page. A list of changes in this release is available. Mar 29, 2016 New patch release: slepc-3.6.3 contains miscellaneous fixes. Mar 21, 2016 A new SLEPc technical report STR-11 has been added in the documentation section. The report describes the contour integral solvers in SLEPc. Mar 21, 2016 SLEPc developers will be attending the forthcoming PETSc User Meeting 2016 in Vienna on June 28-30, 2016. Nov 3, 2015 New patch release: slepc-3.6.2 contains various fixes, related to the EPSLOBPCG and NEPINTERPOL solvers, among other issues."	"null"	"null"	"A software library for the solution of large, sparse eigenvalue problems on parallel computers. only."	"true"
"Numerical"	"Yeppp!"	"http://www.yeppp.info/"	"Very fast, SIMD-optimized mathematical library.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"null"	"null"	"null"	"Yeppp! - Main Yeppp! Home Benchmarks Documentation C/C++ FORTRAN Java C# Examples C/C++ FORTRAN Java C# Downloads Publications Sponsors Contact HPC for everyone! Yeppp! is a high-performance SIMD-optimized mathematical library for x86, ARM, and MIPS processors on Windows, Android, Mac OS X, and GNU/Linux systems. Yeppp! officially supports the C, C++, C#, Java, and FORTRAN programming languages. Ok, I want it now! Hmm… I'm not sure 7 reasons to use Yeppp! Reason 1: Yeppp! is fast! Yeppp! provides extremely fast vector mathematical functions, such as log, exp, and cos. On Haswell, Intel's latest microarchitecture, Yeppp! spends on average 5 cycles per element to compute log or less than 3 cycles per element to compute exp. BTW, floating-point addition on Haswell takes 3 cycles, and multiplication — 5. Can Java be faster than FORTRAN? Yeppp! (if you use Yeppp!) Yeppp! enables high-level managed languages in getting better performance than the best optimizing C and FORTRAN compilers. Yeppp! can accelerate computations from the top-end processors inside compute clusters to low-power processors in mobiles phones, tablets, and single-board computers like Raspberry Pi. Reason 2: Yeppp! makes a better use of your CPU Instead of processing elements one-by-one, Yeppp! uses special SIMD instructions, which compute several elements in just one instruction. Yeppp! uses software pipelining, a technique which rearranges instructions to better fit processor pipeline, to utilize your processors' ability to execute multiple instructions per cycle. Yeppp! provides compute kernels in multiple versions optimized for different processors and instruction sets with the same interface. The optimal implementation is automatically detected during initialization. Reason 3: Yeppp! improves battery life and reduces cloud computing cost With Yeppp! processor can finish computations faster and switch to low-power idle state. With Yeppp! real-time applications can use fewer processor cores and still maintain comfortable FPS. As operating system can switch the idle cores to deep sleep state, the Yeppp!-powered applications will enjoy better battery life. Due to better utilization of CPU resources, applications which use Yeppp! spend less CPU time, and need fewer cloud computing instances. Reason 4: ""It just works"" with popular programming languages Yeppp! provides pure C interface headers which can be natively used with C (C89 and later), C++, and Objective-C languages. Getting started with C/C++ and Yeppp! » Yeppp! comes with interface definitions for FORTRAN. It allow to use Yeppp! with gfortran, Intel Fortran Compiler, and other FORTRAN compilers which support the standard ISO_C_BINDING module. Getting started with FORTRAN and Yeppp! » Yeppp! can be used from .Net languages, such as C#, F#, and VB.Net. Official binaries are provided for .Net 2.0 (compatible with newer .Net versions and Mono framework). Getting started with C# and Yeppp! » Yeppp! supports Java via official JNI bindings. These bindings also can be used with other JVM languages, such as Scala and Jython. Getting started with Java and Yeppp! » Reason 5: Yeppp! supports a wide range of hardware Yeppp! can detect more than 60 x86 and x86-64 instruction extensions. Yeppp! has compute kernels are optimized for SSE (up to 4.2), AVX, AVX2, FMA (both FMA3 and FMA4), XOP, and supports Xeon Phi co-processor. Yeppp! is equally well optimized for Intel and AMD processors. Yeppp! detects all publicly announced ARM instruction sets, including ARMv6, ARMv7, VFPv3, VFPv4, NEON, NEONv2, half-precision extensions, and hardware division extension. Some extensions can be detected even if Linux kernel is not aware of them. Yeppp! compute kernels are optimized for ARM Vector Floating-Point (VFP) and NEON instruction sets. On MIPS Yeppp! recognizes most instruction extensions, including MIPS R2, DSP and DSPv2, paired-single instructions, and MXU (Ingenic Media Extension). Reason 6: Yeppp! is available on multiple platforms Yeppp! supports x86 (32-bit) and x86-64 (64-bit) versions of Windows, starting with Windows XP. Yeppp! can be used on Android 1.5 and later. We provide binaries for ARM (both ARMEABI and ARMEABIv7a), x86, and MIPS, so you can use Yeppp! on nearly all Android devices. And due to Java bindings you can use Yeppp! on Android without writing any C/C++ code! Yeppp! runs well on Intel-based Apple computers with Mac OS X 10.5 or later. You are free to use either 32-bit or 64-bit version or the library. Yeppp! works on Linux-based systems with 2.6 or later kernels. Yeppp! does not depend on any system libraries (including libc), and is binary compatible with most Linux distributions. x86 (Pentium and later), x86-64, armel (ARMv5T and later), armhf (ARMv7-A and later), and k1om (Xeon Phi) architectures are supported on Linux. Reason 7: Yeppp! is reliable and documented Yeppp! was tested on a high number of software and hardware installations ranging from nodes of Cray XE6 supercomputer to Raspberry Pi microcomputer to ensure that the processor features are always correctly detected. This includes over 2000 mobile devices which installed Yeppp! CPUID utility from Android Play Store. Yeppp! uses unit tests for all optimized compute kernels to make sure that they produce the same results as the reference non-optimized implementations. Yeppp! provides extensive documentation for C/C++, C#, FORTRAN, and Java programmers auto-generated with Doxygen. The documentation includes examples of using Yeppp! with each of these programming languages. Browse documentation » Bonus reason: Yeppp! is free and open-source software Yeppp! is licensed under the New (3-clause) BSD license, an OSI-approved permissive license. Yeppp! repository is hosted on BitBucket and contributors are welcome. Browse repository » Download now! » Follow @YepppLibrary © Georgia Institute of Technology 2013–2014 This website is licensed under a Creative Commons Attribution-NoDerivs 3.0 United States License. © Georgia Institute of Technology 2013–2014 This website is licensed under a Creative Commons Attribution-NoDerivs 3.0 United States License. © Georgia Institute of Technology 2013–2014"	"null"	"null"	"Very fast, SIMD-optimized mathematical library.."	"true"
"Parallel Programming"	"cchan"	"http://repo.hu/projects/cchan/"	"A small library for channel constructs for inter-thread communication. Public domain."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"cchan cchan This is a small library that implements a ""channel"" construct for inter-thread communication in C programs. Each channel is a FIFO of fixed-length messages. The FIFO will grow to make space for unread messages; the write operation will never block. Multiple threads can write into one channel at once. Multiple threads can read from one channel at once - but each message is received only once. If there are multiple parallel readers, a random reader will get each message. There are two versions of the cchan library (with the same API): one for pthread, and one for SDL. License Copyright (C) 2010 Máté Nagy <mnagy@port70.net> This code is in the public domain. Downloads You can download the current version of cchan from the Subversion repository:  $ svn co svn://repo.hu/cchan  There may be some packaged releases as well. API #include ""cchan_pthread.h"" (or) #include ""cchan_sdl.h"" cchan_t * cchan_new(int valuesize); /* This call creates a new channel.  * valuesize specifies the message size that the channel will use.  */ void cchan_free(cchan_t *chan); /* Destroys the given channel.  * This call is not thread-safe.  */ void cchan_send(cchan_t *chan, void *value); /* Writes the given message to the channel.  * The message is copied from the given pointer - as many bytes as specified  * in the parameter of cchan_new.  */ int cchan_recv(cchan_t *chan, void *output); /* Tries to receive a message from a channel.  * This call doesn't block.  * If no message is available, it returns 0.  * If a message is available, it is taken from the FIFO and copied to *output;  * the call returns nonzero.  */ void cchan_wait(cchan_t *chan, void *output); /* Receives a message from a channel.  * This call blocks indefinitely until a message is available.  * The message is copied to *output.  */ int cchan_waittime(cchan_t *chan, void *output, int ms); /* This call waits up to ms milliseconds for a message to arrive on the channel.  * If a message arrives, it is copied to *output and the call returns nonzero.  * If no message arrives, the call returns zero after at least ms milliseconds  * have elapsed.  */"	"null"	"null"	"A small library for channel constructs for inter-thread communication. Public domain."	"true"
"Parallel Programming"	"ck"	"https://github.com/concurrencykit/ck"	"Concurrency primitives, safe memory reclamation mechanisms and non-blocking data structures.."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"965"	"81"	"126"	"GitHub - concurrencykit/ck: Concurrency primitives, safe memory reclamation mechanisms and non-blocking (including lock-free) data structures designed to aid in the research, design and implementation of high performance concurrent systems. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 81 Star 965 Fork 126 concurrencykit/ck Code Issues 11 Pull requests 1 Pulse Graphs Concurrency primitives, safe memory reclamation mechanisms and non-blocking (including lock-free) data structures designed to aid in the research, design and implementation of high performance concurrent systems. http://concurrencykit.org/ 1,463 commits 1 branch 35 releases Fetching contributors C 90.4% C++ 5.8% Makefile 3.5% Objective-C 0.3% C C++ Makefile Objective-C Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show 0.5.1 0.5.0 0.4.5 0.4.4 0.4.3 0.4.2 0.4.1 0.4 0.3.5 0.3.4 0.3.3 0.3.2 0.3.1 0.3 0.2.20 0.2.19 0.2.18 0.2.17 0.2.16 0.2.15 0.2.14 0.2.13 0.2.12 0.2.11 0.2.10 0.2.9 0.2.8 0.2.7 0.2.6 0.2.5 0.2.4 0.2.3 0.2.2 0.2.1 0.2 Nothing to show New pull request Fetching latest commit… Cannot retrieve the latest commit at this time. Permalink Failed to load latest commit information. build build/ck.pc.in: fix expansion of PC_CFLAGS Aug 10, 2015 doc doc: ck_epoch_poll now only takes one argument. Jun 3, 2016 include Update ck_ring.h Jul 14, 2016 regressions Ht: regressions: validate serial: check that our hash function was ac… Mar 10, 2016 src ck_ht_hash(): actually use user-provided hash function Mar 10, 2016 tools Initial import. Feb 20, 2011 .gitignore [git] Additional .gitignore entries. Dec 30, 2015 LICENSE update Aug 1, 2014 Makefile.in add --with(out)?-pic configure options Apr 21, 2014 README README: Remove trailing whitespace. Jun 10, 2012 configure build: Fix clang detection to require major >= 3. Jul 15, 2016 README   ____                                                        _  ___ _  / ___|___  _ __   ___ _   _ _ __ _ __ ___ _ __   ___ _   _  | |/ (_) |_ | |   / _ \| '_ \ / __| | | | '__| '__/ _ \ '_ \ / __| | | | | ' /| | __| | |__| (_) | | | | (__| |_| | |  | | |  __/ | | | (__| |_| | | . \| | |_  \____\___/|_| |_|\___|\__,_|_|  |_|  \___|_| |_|\___|\__, | |_|\_\_|\__|                                                       |___/  Step 1. 	./configure 	For additional options try ./configure --help  Step 2. 	In order to compile regressions (requires POSIX threads) use         ""make regressions"". In order to compile libck use ""make all"" or ""make"".  Step 3. 	In order to install use ""make install"" 	To uninstall use ""make uninstall"".  See http://concurrencykit.org/ for more information.   Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/concurrencykit/ck"	"Concurrency primitives, safe memory reclamation mechanisms and non-blocking data structures.."	"true"
"Parallel Programming"	"mill"	"http://libmill.org/"	"Go-style concurrency in C.."	"null"	"null"	"null"	"X11"	"https://directory.fsf.org/wiki/License:X11"	"null"	"null"	"null"	"null"	"null"	"libmill Go-style concurrency in C Home Download Tutorial Documentation Development Community Libmill is a library that introduces Go-style concurrency to C. It can execute up to 20 million coroutines and 50 million context switches per second.      Go C go foo(arg1, arg2, arg3) go(foo(arg1, arg2, arg3)); ch := make(chan int) chan ch = chmake(int, 0); ch := make(chan int, 1000) chan ch = chmake(int, 1000); ch <- 42 chs(ch, int, 42); i := <- ch int i = chr(ch, int); close(ch) chdone(ch, int, 0); <garbage collector> chclose(ch); select { case ch <- 42: foo() case i := <- ch: bar(i) default: baz() } choose { out(ch, int, 42): foo(); in(ch, int, i): bar(i); otherwise: baz(); end }   Libmill is licensed under MIT/X11 license."	"null"	"null"	"Go-style concurrency in C.."	"true"
"Parallel Programming"	"MPICH"	"http://www.mpich.org/"	"Another implementation of MPI.."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"MPICH | High-Performance Portable MPI MPICH High-Performance Portable MPI Skip to content Home About MPICH Overview News and Events Collaborators MPI Forum Downloads Releases Release Timeline Pending Tickets Source Changes Documentation Guides Manpages Publications MPICH Wiki Hydra Usage Developer Docs Contributor Docs Support FAQs Mailing Lists Report a Bug ABI Compatibility Initiative MPICH is a high performance and widely portable implementation of the Message Passing Interface (MPI) standard. MPICH and its derivatives form the most widely used implementations of MPI in the world. They are used exclusively on nine of the top 10 supercomputers (June 2015 ranking), including the world’s fastest supercomputer: Tianhe-2. News & Events MPICH Birds-of-a-Feather @ SC15 Thanks to all who attended and gave presentations at this years MPICH Birds-of-a-Feather session at Supercomputing in Austin, TX. It ... Read More >> Learn about MPICH The documentation page provides documents for installing MPICH, how to get started with MPI, and how to run MPI applications. It also includes tutorials, publications and other documents for developers. Read More >> Support The support page provides help for MPICH users and developers. There are links to frequently asked questions, support mailing lists and a trac system to report new bugs. Read More >> Comments are closed. About Support News Documentation Downloads Publications Collaborators FAQ RSS Feed"	"null"	"null"	"Another implementation of MPI.."	"true"
"Parallel Programming"	"MPICH licence"	"http://git.mpich.org/mpich.git/blob_plain/6aab201f58d71fc97f2c044d250389ba86ac1e3c:/COPYRIGHT"	"Another implementation of MPI.."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"COPYRIGHT The following is a notice of limited availability of the code, and disclaimer which must be included in the prologue of the code and in all source listings of the code. Copyright Notice + 2002 University of Chicago Permission is hereby granted to use, reproduce, prepare derivative works, and to redistribute to others. This software was authored by: Mathematics and Computer Science Division Argonne National Laboratory, Argonne IL 60439 (and) Department of Computer Science University of Illinois at Urbana-Champaign GOVERNMENT LICENSE Portions of this material resulted from work developed under a U.S. Government Contract and are subject to the following license: the Government is granted for itself and others acting on its behalf a paid-up, nonexclusive, irrevocable worldwide license in this computer software to reproduce, prepare derivative works, and perform publicly and display publicly. DISCLAIMER This computer code material was prepared, in part, as an account of work sponsored by an agency of the United States Government. Neither the United States, nor the University of Chicago, nor any of their employees, makes any warranty express or implied, or assumes any legal liability or responsibility for the accuracy, completeness, or usefulness of any information, apparatus, product, or process disclosed, or represents that its use would not infringe privately owned rights."	"null"	"null"	"Another implementation of MPI.."	"true"
"Parallel Programming"	"OpenMP"	"http://openmp.org/wp/about-openmp/"	"A set of C pragmas designed to allow for easy parallelization of code. Standard (licensing not applicable)."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"OpenMP.org   » About the OpenMP ARB and OpenMP.org   The OpenMP® API specification for parallel programming About the OpenMP ARB and OpenMP.org Mission The OpenMP ARB mission is to standardize directive-based multi-language high-level parallelism that is performant, productive and portable. Jointly defined by a group of major computer hardware and software vendors and major parallel computing user facilities, the OpenMP API is a portable, scalable model that gives shared-memory parallel programmers a simple and flexible interface for developing parallel applications on platforms ranging from embedded systems and accelerator devices to multicore systems and shared-memory systems. The OpenMP ARB owns the OpenMP brand, oversees the OpenMP specification and produces and approves new versions of the specification. The OpenMP Architecture Review Board The OpenMP ARB (or just “ARB”) is the non-profit corporation that owns the OpenMP brand, oversees the OpenMP specification and produces and approves new versions of the specification. The ARB helps to organize and fund conferences, workshops, and other related events, and promotes OpenMP. The ARB is composed of permanent and auxiliary members. Permanent members are vendors who have a long-term interest in creating products for OpenMP. Auxiliary members are normally organizations with an interest in the standard but that do not create or sell OpenMP products. Contact the ARB at the e-mail address info AT openmp.org to submit questions about membership, business issues, and the like. All other questions about the OpenMP API should be directed through the User Forums. The ARB, like most non-profit corporations, has corporate officers (CEO, CFO, and Secretary) and a Board of Directors. The officers are responsible for the day-to-day business of the corporation. The Board of Directors is responsible for setting long-term corporate direction and approving large or unusual expenditures; it acts as an oversight and governance body for the corporation. Read the OpenMP Welcome Guide for more information about OpenMP membership and history. Members Permanent Members of the ARB: AMD (Greg Stoner) ARM (Chris Adeniyi-Jones) Cray (Luiz DeRose) Fujitsu (Eiji Yamanaka) HP (Sujoy Saraswati) IBM (Kelvin Li) Intel (Xinmin Tian) Micron (Kirby Collins) NEC (Kazuhiro Kusano) NVIDIA (Jeff Larkin) Oracle Corporation (Nawal Copty) Red Hat (Matt Newsome) Texas Instruments (Eric Stotzer) Auxiliary Members of the ARB: Argonne National Laboratory (Kalyan Kumaran) ASC/Lawrence Livermore National Laboratory (Bronis R. de Supinski) Barcelona Supercomputing Center (Xavier Martorell) Bristol University (Simon McIntosh-Smith) cOMPunity (Barbara Chapman/Yonghong Yan) Edinburgh Parallel Computing Centre (EPCC) (Mark Bull) INRIA (Olivier Aumage) Los Alamos National Laboratory (David Montoya) Lawrence Berkeley National Laboratory (Alice Koniges/Helen He) NASA (Henry Jin) Oak Ridge National Laboratory (Oscar Hernandez) RWTH Aachen University (Dieter an Mey) Sandia National Laboratory (Stephen Olivier) Texas Advanced Computing Center (Kent Milfeld) University of Houston (Barbara Chapman/Deepak Eachempati) Directors Sanjiv Shah, Intel –– Chair (through 2015) is the director of the Performance, Analysis and Threading Lab in the software group at Intel. Sanjiv specializes in parallel computing and his lab produces tools and libraries for parallel software, performance and correctness analysis. Sanjiv has been extensively involved with the OpenMP specifications from the beginning and implemented the first Fortran and C/C++ compilers supporting OpenMP (and precursors of OpenMP). He is a former CEO of the OpenMP Architecture Review Board and continues to serve on its Board of Directors. Josh Simons, VMware, Inc. (through 2017) With over 20 years of experience in High Performance Computing, Josh currently leads an effort to bring the full value of virtualization to HPC. Previously, he was a Distinguished Engineer at Sun Microsystems with broad responsibilities for HPC direction and strategy. He joined Sun in 1996 from Thinking Machines Corporation, a pioneering company in the area of Massively Parallel Processors (MPPs), where he held a variety of technical positions. Josh has worked on developer tools for distributed parallel computing, including language and compiler design, scalable parallel debugger design and development, and MPI. He has also worked in the areas of 3D graphics, image processing, and realtime device control. Josh has an undergraduate degree in Engineering from Harvard College and a Masters in Computer Science from Harvard University. He has served as a member of the Board of Directors since 2002. Andy Fritsch, Texas Instruments (through 2015) is the Manager of Foundational Tools for Texas Instruments. In his role, Andy manages development of tools for TI’s processors across many product areas including DSPs, microcontrollers and automotive. His responsibilities include compilers, hardware debug probes/platforms, simulators, tools product management and applications support.  Previously, he was a silicon development program manager with responsibility for architecture, specification, design, test and verification, packaging, qualification and software platforms for TI’s C6000 DSPs. Andy started his career at TI developing real time geophysical applications and RTOS’s.  He has also held roles in applications engineering management, partner relationship management and in software and hardware development.  Andy has a BS in Applied Mathematics from the University of Tulsa. Partha Tirumalai, Oracle (through 2017) is a Senior Principal Engineer and Technical Advisor in the Systems Group of Oracle Corporation. His interests are in processor architecture, optimizing and parallelizing compilers, application performance, and high performance computing systems. He has authored numerous papers and has received a number of patents in these areas. Prior to joining Oracle, he was a Distinguished Engineer at Sun Microsystems, and earlier worked as a Senior Research Scientist at Hewlett-Packard Laboratories. Partha holds a B. Tech degree in Electrical Engineering from I.I.T., Madras, and M.S. and Ph.D. degrees in Computer Science from Northwestern University. Dieter an Mey (through 2016) leads the high performance computing team of RWTH Aachen University’s Center for Computing and Communication in Germany. He studied Mathematics and Computer Science in Aachen and by now has a 30+ year track record in HPC with a focus on user support and services. Starting with vectorization and message passing, he and his group are actively participating in the OpenMP community since the first OpenMP specification was released. He is co-author of numerous publications on OpenMP programming and productivity. Officers CEO: Dr. Michael Klemm obtained an M.Sc. in Computer Science in 2003 and received a Doctor of Engineering degree (Dr.-Ing.) from the Friedrich-Alexander-University Erlangen-Nuremberg, Germany, in 2008. Michael Klemm works in the Developer Relations Division at Intel in Germany and his areas of interest include compiler construction, design of programming languages, parallel programming, and performance analysis and tuning. Michael Klemm joined the OpenMP organization in 2009. CFO: Dave Poulsen, Intel Dave Poulsen received a Ph.D. degree in Electrical and Computer Engineering from the University of Illinois in 1994. He then joined Kuck and Associates, Inc. (KAI) where he worked on parallelizing compilers, as well as KAI’s OpenMP compiler and threading correctness/performance tools. With KAI’s acquisition by Intel in 2000, he worked on integrating OpenMP and KAI’s threading tools technologies into Intel’s software product line-up. After a brief stint working on Intel’s MPI library product, Dave became the project lead for Intel’s new Threading Building Blocks (TBB) product. Dave is currently the engineering manager of the Threading Runtimes team in the Performance, Analysis and Threading Lab at Intel, which develops their OpenMP runtime libraries as well as TBB. Prior to working on his Ph.D., Dave worked for IBM in upstate New York, where he was a processor designer for 3090-class mainframe CPUs. And, he’s very neat and well organized, and knows how to balance a checkbook, which is why he is CFO. Secretary: Christian Terboven, RWTH Aachen University Marketing Coordinator: Matthijs van Waveren is the Fujitsu representative to the OpenMP ARB and to the SPEC High-Performance Group. He has contributed to the development of several SPEC benchmarks and of a number of OpenMP features. He is member of the Board of SPEC, and has received several SPECtacular awards. He holds a PhD from the University of Amsterdam. Chair of the Language Committee: Bronis R. de Supinski is the principal investigator and leader of the Exascale Computing Technlogies (ExaCT) project and the co-leader of the Advanced Simulation and Computing (ASC) program’s Application Development Environment and Performance Team (ADEPT) at Lawrence Livermore National Laboratory (LLNL). He is also an Adjunct Associate Professor in the Department of Computer Science and Engineering at Texas A&M University. Bronis earned his Ph.D. in Computer Science from the University of Virginia in 1998 and he joined LLNL’s Center for Applied Scientific Computing (CASC) in July 1998. Currently, his projects include scalable debugging methods, investigations into mechanisms and tools to improve memory performance, applications of data mining techniques to tools for large-scale systems, resiliency techniques, a variety of optimization techniques and tools for MPI and several issues with OpenMP, including its memory model and tool support. He pursues the last set of topics as the Chair of the OpenMP Language Committee. Throughout his career, Bronis has won several awards, including the prestigious Gordon Bell Prize in 2005 and 2006. Webmaster: Richard Friedman is a freelance technical writer/editor and web designer, and lives in Oakland, CA. For 3 decades he was a Fortran and systems programmer on the IBM 650, IBM 7094, CDC 6600/7600, Cray 1, Cyber 205, before becoming a full-time technical writer at Sun Microsystems, specializing in compilers and high performance computing. Visit his website at rchrd.com. Last updated on July 14, 2015     Get »OpenMP specs Use »OpenMP Compilers Learn »Using OpenMP -- the book »Using OpenMP -- the examples »Using OpenMP -- the forum »Wikipedia »OpenMP Tutorial »More Resources Discuss »User Forum Ask the experts and get answers to questions about OpenMP Recent News Bristol University Joins the OpenMP Effort Call for Papers - OpenMPCon 2016 Latest OpenMP News GCC 6.1 Released - Supports OpenMP 4.5 OpenMPCon 2016 Developers Conference – Call for Papers Subscribe to the News Feed »OpenMP Specifications »About the OpenMP ARB »Frequently Asked Questions »Compilers »Resources »Who's Using OpenMP? »Press Releases »Videos »Discussion Forums Events »Public OpenMP Calendar Input Register Alert the OpenMP.org webmaster about new products, events, or updates and we'll post it here. »webmaster@openmp.org Follow @OpenMP_ARB Search OpenMP.org Archives June 2016 May 2016 April 2016 March 2016 February 2016 December 2015 November 2015 October 2015 September 2015 August 2015 July 2015 May 2015 April 2015 February 2015 January 2015 December 2014 November 2014 October 2014 June 2014 April 2014 March 2014 February 2014 January 2014 December 2013 November 2013 September 2013 July 2013 May 2013 April 2013 March 2013 February 2013 January 2013 December 2012 November 2012 October 2012 September 2012 July 2012 June 2012 May 2012 April 2012 March 2012 February 2012 January 2012 November 2011 October 2011 September 2011 July 2011 May 2011 February 2011 October 2010 July 2010 May 2010 June 2009 April 2009 March 2009 February 2009 January 2009 November 2008 October 2008 September 2008 August 2008 July 2008 June 2008 May 2008 April 2008 Copyright © 1998-2015. OpenMP and the OpenMP logo are registered trademarks of the OpenMP Architecture Review Board in the United States and other countries. All rights reserved. »Trademarks and Logo Usage »Privacy Policy"	"null"	"null"	"A set of C pragmas designed to allow for easy parallelization of code. Standard (licensing not applicable)."	"true"
"Parallel Programming"	"OpenMPI"	"https://github.com/open-mpi/ompi"	"A message passing interface implementation.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"186"	"64"	"151"	"GitHub - open-mpi/ompi: Open MPI main development repository Skip to content Personal Open source Business Explore Start building Sign in Pricing Blog Support Search GitHub This repository Watch 64 Star 186 Fork 151 open-mpi/ompi Code Issues 261 Pull requests 31 Wiki Pulse Graphs Open MPI main development repository 25,392 commits 1 branch 1 release 89 contributors C 81.9% Groff 4.0% Shell 3.6% FORTRAN 3.5% Makefile 2.2% M4 1.4% Other 3.4% C Groff Shell FORTRAN Makefile M4 Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show dev Nothing to show New pull request Latest commit 06930a0 Jul 14, 2016 jladd-mlnx committed on GitHub Merge pull request #1840 from artpol84/yalla_perf_fix … pml/yalla: fix yalla performance regression Permalink Failed to load latest commit information. config Correct ""configure --help"" output and amend the default setting if user Jul 13, 2016 contrib openmpi.spec: don't export FFLAGS Jul 12, 2016 examples examples: update ompi_info bindings checks Feb 28, 2016 ompi Merge pull request #1840 from artpol84/yalla_perf_fix Jul 14, 2016 opal Fix singletons - do not include the PMIx tool URI in the environment … Jul 13, 2016 orte Merge pull request #1872 from rhc54/topic/continuous Jul 13, 2016 oshmem oshmem: replace header files in include/mpp with symlinks Jul 14, 2016 test test: fixup hostname max length usage Apr 25, 2016 .gitignore Add support for PMIx tool connections and queries. Initially only sup… Jun 29, 2016 .mailmap Added an entry in .mailmap to correct email address. Jun 17, 2016 .travis.yml travis: fix a typo and create bogus directories to avoid compiler war… May 26, 2016 AUTHORS arm64: add timer support Jun 23, 2016 Doxyfile Fix the broken Doxyfile so people can generate what little code base … Apr 13, 2006 HACKING HACKING: update language about developer builds Mar 17, 2016 INSTALL INSTALL: whitespace cleanup Apr 27, 2015 LICENSE Update license copyright year for Intel Apr 6, 2016 Makefile.am Makefile.am: only check for common symbols on dev builds Apr 20, 2016 Makefile.ompi-rules Incorporate @jsquyres suggestions about OMPI_V_GEN & echo'ing another… May 17, 2016 NEWS NEWS: improve bullet about MPI_THREAD_MULTIPLE May 2, 2016 README README: fix spelling of ""schizo"" framework name Apr 25, 2016 README.JAVA.txt README.JAVA.txt: trivial whitespace cleanup Aug 15, 2014 VERSION configury: clean up .so version numbers Dec 18, 2015 autogen.pl autogen: patch config/ltmain.sh in order to make NAG compiler pass th… Jun 6, 2016 configure.ac opal/memory: disable __malloc_initialize_hook if poisoned Jun 15, 2016 README Copyright (c) 2004-2007 The Trustees of Indiana University and Indiana                         University Research and Technology                         Corporation.  All rights reserved. Copyright (c) 2004-2015 The University of Tennessee and The University                         of Tennessee Research Foundation.  All rights                         reserved. Copyright (c) 2004-2008 High Performance Computing Center Stuttgart,                         University of Stuttgart.  All rights reserved. Copyright (c) 2004-2007 The Regents of the University of California.                         All rights reserved. Copyright (c) 2006-2016 Cisco Systems, Inc.  All rights reserved. Copyright (c) 2006-2011 Mellanox Technologies. All rights reserved. Copyright (c) 2006-2012 Oracle and/or its affiliates.  All rights reserved. Copyright (c) 2007      Myricom, Inc.  All rights reserved. Copyright (c) 2008      IBM Corporation.  All rights reserved. Copyright (c) 2010      Oak Ridge National Labs.  All rights reserved. Copyright (c) 2011      University of Houston. All rights reserved. Copyright (c) 2013-2015 Intel, Inc. All rights reserved Copyright (c) 2015      NVIDIA Corporation.  All rights reserved. $COPYRIGHT$  Additional copyrights may follow  $HEADER$  ===========================================================================  When submitting questions and problems, be sure to include as much extra information as possible.  This web page details all the information that we request in order to provide assistance:       http://www.open-mpi.org/community/help/  The best way to report bugs, send comments, or ask questions is to sign up on the user's and/or developer's mailing list (for user-level and developer-level questions; when in doubt, send to the user's list):          users@open-mpi.org         devel@open-mpi.org  Because of spam, only subscribers are allowed to post to these lists (ensure that you subscribe with and post from exactly the same e-mail address -- joe@example.com is considered different than joe@mycomputer.example.com!).  Visit these pages to subscribe to the lists:       http://www.open-mpi.org/mailman/listinfo.cgi/users      http://www.open-mpi.org/mailman/listinfo.cgi/devel  Thanks for your time.  ===========================================================================  Much, much more information is also available in the Open MPI FAQ:      http://www.open-mpi.org/faq/  ===========================================================================  The following abbreviated list of release notes applies to this code base as of this writing (April 2015):  General notes -------------  - Open MPI now includes two public software layers: MPI and OpenSHMEM.   Throughout this document, references to Open MPI implicitly include   both of these layers. When distinction between these two layers is   necessary, we will reference them as the ""MPI"" and ""OSHMEM"" layers   respectively.  - OpenSHMEM is a collaborative effort between academia, industry, and   the U.S. Government to create a specification for a standardized API   for parallel programming in the Partitioned Global Address Space   (PGAS).  For more information about the OpenSHMEM project, including   access to the current OpenSHMEM specification, please visit:       http://openshmem.org/    This OpenSHMEM implementation is provided on an experimental basis;   it has been lightly tested and will only work in Linux environments.   Although this implementation attempts to be portable to multiple   different environments and networks, it is still new and will likely   experience growing pains typical of any new software package.   End-user feedback is greatly appreciated.    This implementation will currently most likely provide optimal   performance on Mellanox hardware and software stacks.  Overall   performance is expected to improve as other network vendors and/or   institutions contribute platform specific optimizations.    See below for details on how to enable the OpenSHMEM implementation.  - Open MPI includes support for a wide variety of supplemental   hardware and software package.  When configuring Open MPI, you may   need to supply additional flags to the ""configure"" script in order   to tell Open MPI where the header files, libraries, and any other   required files are located.  As such, running ""configure"" by itself   may not include support for all the devices (etc.) that you expect,   especially if their support headers / libraries are installed in   non-standard locations.  Network interconnects are an easy example   to discuss -- Libfabric and OpenFabrics networks, for example, both   have supplemental headers and libraries that must be found before   Open MPI can build support for them.  You must specify where these   files are with the appropriate options to configure.  See the   listing of configure command-line switches, below, for more details.  - The majority of Open MPI's documentation is here in this file, the   included man pages, and on the web site FAQ   (http://www.open-mpi.org/).  - Note that Open MPI documentation uses the word ""component""   frequently; the word ""plugin"" is probably more familiar to most   users.  As such, end users can probably completely substitute the   word ""plugin"" wherever you see ""component"" in our documentation.   For what it's worth, we use the word ""component"" for historical   reasons, mainly because it is part of our acronyms and internal API   function calls.  - The run-time systems that are currently supported are:   - rsh / ssh   - LoadLeveler   - PBS Pro, Torque   - Platform LSF (v7.0.2 and later)   - SLURM   - Cray XE, XC, and XK   - Oracle Grid Engine (OGE) 6.1, 6.2 and open source Grid Engine  - Systems that have been tested are:   - Linux (various flavors/distros), 32 bit, with gcc   - Linux (various flavors/distros), 64 bit (x86), with gcc, Absoft,     Intel, and Portland (*)   - OS X (10.6, 10.7, 10.8, 10.9, 10.10), 32 and 64 bit (x86_64), with     XCode and Absoft compilers (*)    (*) Be sure to read the Compiler Notes, below.  - Other systems have been lightly (but not fully tested):   - Cygwin 32 & 64 bit with gcc   - ARMv4, ARMv5, ARMv6, ARMv7, ARMv8   - Other 64 bit platforms (e.g., Linux on PPC64)   - Oracle Solaris 10 and 11, 32 and 64 bit (SPARC, i386, x86_64),     with Oracle Solaris Studio 12.2, 12.3, and 12.4  Compiler Notes --------------  - Open MPI requires a C99-capable compiler to build.  - Mixing compilers from different vendors when building Open MPI   (e.g., using the C/C++ compiler from one vendor and the Fortran   compiler from a different vendor) has been successfully employed by   some Open MPI users (discussed on the Open MPI user's mailing list),   but such configurations are not tested and not documented.  For   example, such configurations may require additional compiler /   linker flags to make Open MPI build properly.  - In general, the latest versions of compilers of a given vendor's   series have the least bugs.  We have seen cases where Vendor XYZ's   compiler version A.B fails to compile Open MPI, but version A.C   (where C>B) works just fine.  If you run into a compile failure, you   might want to double check that you have the latest bug fixes and   patches for your compiler.  - Users have reported issues with older versions of the Fortran PGI   compiler suite when using Open MPI's (non-default) --enable-debug   configure option.  Per the above advice of using the most recent   version of a compiler series, the Open MPI team recommends using the   latest version of the PGI suite, and/or not using the --enable-debug   configure option.  If it helps, here's what we have found with some   (not comprehensive) testing of various versions of the PGI compiler   suite:      pgi-8 : NO known good version with --enable-debug     pgi-9 : 9.0-4 known GOOD     pgi-10: 10.0-0 known GOOD     pgi-11: NO known good version with --enable-debug     pgi-12: 12.10 known BAD due to C99 compliance issues, and 12.8             and 12.9 both known BAD with --enable-debug     pgi-13: 13.10 known GOOD  - Similarly, there is a known Fortran PGI compiler issue with long   source directory path names that was resolved in 9.0-4 (9.0-3 is   known to be broken in this regard).  - IBM's xlf compilers: NO known good version that can build/link   the MPI f08 bindings or build/link the OSHMEM Fortran bindings.  - On NetBSD-6 (at least AMD64 and i386), and possibly on OpenBSD,   libtool misidentifies properties of f95/g95, leading to obscure   compile-time failures if used to build Open MPI.  You can work   around this issue by ensuring that libtool will not use f95/g95   (e.g., by specifying FC=<some_other_compiler>, or otherwise ensuring   a different Fortran compiler will be found earlier in the path than   f95/g95), or by disabling the Fortran MPI bindings with   --disable-mpi-fortran.  - Absoft 11.5.2 plus a service pack from September 2012 (which Absoft   says is available upon request), or a version later than 11.5.2   (e.g., 11.5.3), is required to compile the new Fortran mpi_f08   module.  - Open MPI does not support the Sparc v8 CPU target.  However,   as of Solaris Studio 12.1,  and later compilers, one should not   specify -xarch=v8plus or -xarch=v9.  The use of the options   -m32 and -m64 for producing 32 and 64 bit targets, respectively,   are now preferred by the Solaris Studio compilers.  GCC may   require either ""-m32"" or ""-mcpu=v9 -m32"", depending on GCC version.  - It has been noticed that if one uses CXX=sunCC, in which sunCC   is a link in the Solaris Studio compiler release, that the OMPI   build system has issue with sunCC and does not build libmpi_cxx.so.   Therefore  the make install fails.  So we suggest that one should   use CXX=CC, which works, instead of CXX=sunCC.  - If one tries to build OMPI on Ubuntu with Solaris Studio using the C++   compiler and the -m32 option, you might see a warning:      CC: Warning: failed to detect system linker version, falling back to     custom linker usage    And the build will fail.  One can overcome this error by either   setting LD_LIBRARY_PATH to the location of the 32 bit libraries (most   likely /lib32), or giving LDFLAGS=""-L/lib32 -R/lib32"" to the configure   command.  Officially, Solaris Studio is not supported on Ubuntu Linux   distributions, so additional problems might be incurred.  - Open MPI does not support the gccfss compiler (GCC For SPARC   Systems; a now-defunct compiler project from Sun).  - At least some versions of the Intel 8.1 compiler seg fault while   compiling certain Open MPI source code files.  As such, it is not   supported.  - The Intel 9.0 v20051201 compiler on IA64 platforms seems to have a   problem with optimizing the ptmalloc2 memory manager component (the   generated code will segv).  As such, the ptmalloc2 component will   automatically disable itself if it detects that it is on this   platform/compiler combination.  The only effect that this should   have is that the MCA parameter mpi_leave_pinned will be inoperative.  - It has been reported that the Intel 9.1 and 10.0 compilers fail to   compile Open MPI on IA64 platforms.  As of 12 Sep 2012, there is   very little (if any) testing performed on IA64 platforms (with any   compiler).  Support is ""best effort"" for these platforms, but it is   doubtful that any effort will be expended to fix the Intel 9.1 /   10.0 compiler issuers on this platform.  - Early versions of the Intel 12.1 Linux compiler suite on x86_64 seem   to have a bug that prevents Open MPI from working.  Symptoms   including immediate segv of the wrapper compilers (e.g., mpicc) and   MPI applications.  As of 1 Feb 2012, if you upgrade to the latest   version of the Intel 12.1 Linux compiler suite, the problem will go   away.  - Early versions of the Portland Group 6.0 compiler have problems   creating the C++ MPI bindings as a shared library (e.g., v6.0-1).   Tests with later versions show that this has been fixed (e.g.,   v6.0-5).  - The Portland Group compilers prior to version 7.0 require the   ""-Msignextend"" compiler flag to extend the sign bit when converting   from a shorter to longer integer.  This is is different than other   compilers (such as GNU).  When compiling Open MPI with the Portland   compiler suite, the following flags should be passed to Open MPI's   configure script:    shell$ ./configure CFLAGS=-Msignextend CXXFLAGS=-Msignextend \          --with-wrapper-cflags=-Msignextend \          --with-wrapper-cxxflags=-Msignextend ...    This will both compile Open MPI with the proper compile flags and   also automatically add ""-Msignextend"" when the C and C++ MPI wrapper   compilers are used to compile user MPI applications.  - Using the MPI C++ bindings with older versions of the Pathscale   compiler on some platforms is an old issue that seems to be a   problem when Pathscale uses a back-end GCC 3.x compiler. Here's a   proposed solution from the Pathscale support team (from July 2010):        The proposed work-around is to install gcc-4.x on the system and       use the pathCC -gnu4 option. Newer versions of the compiler (4.x       and beyond) should have this fixed, but we'll have to test to       confirm it's actually fixed and working correctly.    We don't anticipate that this will be much of a problem for Open MPI   users these days (our informal testing shows that not many users are   still using GCC 3.x).  Contact Pathscale support if you continue to   have problems with Open MPI's C++ bindings.  - Using the Absoft compiler to build the MPI Fortran bindings on Suse   9.3 is known to fail due to a Libtool compatibility issue.  - MPI Fortran API support has been completely overhauled since the   Open MPI v1.5/v1.6 series.    ********************************************************************   ********************************************************************   *** There is now only a single Fortran MPI wrapper compiler and a   *** single Fortran OSHMEM wrapper compiler: mpifort and oshfort,   *** respectively.  mpif77 and mpif90 still exist, but they are   *** symbolic links to mpifort.   ********************************************************************   *** Similarly, Open MPI's configure script only recognizes the FC   *** and FCFLAGS environment variables (to specify the Fortran   *** compiler and compiler flags, respectively).  The F77 and FFLAGS   *** environment variables are IGNORED.   ********************************************************************   ********************************************************************    As a direct result, it is STRONGLY recommended that you specify a   Fortran compiler that uses file suffixes to determine Fortran code   layout (e.g., free form vs. fixed).  For example, with some versions   of the IBM XLF compiler, it is preferable to use FC=xlf instead of   FC=xlf90, because xlf will automatically determine the difference   between free form and fixed Fortran source code.    However, many Fortran compilers allow specifying additional   command-line arguments to indicate which Fortran dialect to use.   For example, if FC=xlf90, you may need to use ""mpifort --qfixed ...""   to compile fixed format Fortran source files.    You can use either ompi_info or oshmem_info to see with which Fortran   compiler Open MPI was configured and compiled.    There are up to three sets of Fortran MPI bindings that may be   provided depending on your Fortran compiler):    - mpif.h: This is the first MPI Fortran interface that was defined     in MPI-1.  It is a file that is included in Fortran source code.     Open MPI's mpif.h does not declare any MPI subroutines; they are     all implicit.    - mpi module: The mpi module file was added in MPI-2.  It provides     strong compile-time parameter type checking for MPI subroutines.    - mpi_f08 module: The mpi_f08 module was added in MPI-3.  It     provides many advantages over the mpif.h file and mpi module.  For     example, MPI handles have distinct types (vs. all being integers).     See the MPI-3 document for more details.      *** The mpi_f08 module is STRONGLY is recommended for all new MPI         Fortran subroutines and applications.  Note that the mpi_f08         module can be used in conjunction with the other two Fortran         MPI bindings in the same application (only one binding can be         used per subroutine/function, however).  Full interoperability         between mpif.h/mpi module and mpi_f08 module MPI handle types         is provided, allowing mpi_f08 to be used in new subroutines in         legacy MPI applications.    Per the OSHMEM specification, there is only one Fortran OSHMEM binding   provided:    - shmem.fh: All Fortran OpenSHMEM programs **should** include 'shmem.fh',     and Fortran OSHMEM programs that use constants defined by OpenSHMEM     **MUST** include 'shmem.fh'.    The following notes apply to the above-listed Fortran bindings:    - All Fortran compilers support the mpif.h/shmem.fh-based bindings,     with one exception: the MPI_SIZEOF interfaces will only be present     when Open MPI is built with a Fortran compiler that support the     INTERFACE keyword and ISO_FORTRAN_ENV.  Most notably, this     excludes the GNU Fortran compiler suite before version 4.9.    - The level of support provided by the mpi module is based on your     Fortran compiler.      If Open MPI is built with a non-GNU Fortran compiler, or if Open     MPI is built with the GNU Fortran compiler >= v4.9, all MPI     subroutines will be prototyped in the mpi module.  All calls to     MPI subroutines will therefore have their parameter types checked     at compile time.      If Open MPI is built with an old gfortran (i.e., < v4.9), a     limited ""mpi"" module will be built.  Due to the limitations of     these compilers, and per guidance from the MPI-3 specification,     all MPI subroutines with ""choice"" buffers are specifically *not*     included in the ""mpi"" module, and their parameters will not be     checked at compile time.  Specifically, all MPI subroutines with     no ""choice"" buffers are prototyped and will receive strong     parameter type checking at run-time (e.g., MPI_INIT,     MPI_COMM_RANK, etc.).      Similar to the mpif.h interface, MPI_SIZEOF is only supported on     Fortran compilers that support INTERFACE and ISO_FORTRAN_ENV.    - The mpi_f08 module is new and has been tested with the Intel     Fortran compiler and gfortran >= 4.9.  Other modern Fortran     compilers may also work (but are, as yet, only lightly tested).     It is expected that this support will mature over time.      Many older Fortran compilers do not provide enough modern Fortran     features to support the mpi_f08 module.  For example, gfortran <     v4.9 does provide enough support for the mpi_f08 module.    You can examine the output of the following command to see all   the Fortran features that are/are not enabled in your Open MPI   installation:    shell$ ompi_info | grep -i fort   General Run-Time Support Notes ------------------------------  - The Open MPI installation must be in your PATH on all nodes (and   potentially LD_LIBRARY_PATH (or DYLD_LIBRARY_PATH), if libmpi/libshmem   is a shared library), unless using the --prefix or   --enable-mpirun-prefix-by-default functionality (see below).  - Open MPI's run-time behavior can be customized via MCA (""MPI   Component Architecture"") parameters (see below for more information   on how to get/set MCA parameter values).  Some MCA parameters can be   set in a way that renders Open MPI inoperable (see notes about MCA   parameters later in this file).  In particular, some parameters have   required options that must be included.    - If specified, the ""btl"" parameter must include the ""self""     component, or Open MPI will not be able to deliver messages to the     same rank as the sender.  For example: ""mpirun --mca btl tcp,self     ...""   - If specified, the ""btl_tcp_if_exclude"" paramater must include the     loopback device (""lo"" on many Linux platforms), or Open MPI will     not be able to route MPI messages using the TCP BTL.  For example:     ""mpirun --mca btl_tcp_if_exclude lo,eth1 ...""  - Running on nodes with different endian and/or different datatype   sizes within a single parallel job is supported in this release.   However, Open MPI does not resize data when datatypes differ in size   (for example, sending a 4 byte MPI_DOUBLE and receiving an 8 byte   MPI_DOUBLE will fail).   MPI Functionality and Features ------------------------------  - Rank reordering support is available using the TreeMatch library. It   is activated for the graph and dist_graph topologies.  - All MPI-3 functionality is supported.  - When using MPI deprecated functions, some compilers will emit   warnings.  For example:    shell$ cat deprecated_example.c   #include <mpi.h>   void foo(void) {       MPI_Datatype type;       MPI_Type_struct(1, NULL, NULL, NULL, &type);   }   shell$ mpicc -c deprecated_example.c   deprecated_example.c: In function 'foo':   deprecated_example.c:4: warning: 'MPI_Type_struct' is deprecated (declared at /opt/openmpi/include/mpi.h:1522)   shell$  - MPI_THREAD_MULTIPLE support is included, but is only lightly tested.   It likely does not work for thread-intensive applications.  Note   that *only* the MPI point-to-point communication functions for the   BTL's listed here are considered thread safe.  Other support   functions (e.g., MPI attributes) have not been certified as safe   when simultaneously used by multiple threads.   - tcp   - sm   - self    Note that Open MPI's thread support is in a fairly early stage; the   above devices may *work*, but the latency is likely to be fairly   high.  Specifically, efforts so far have concentrated on   *correctness*, not *performance* (yet).    YMMV.  - MPI_REAL16 and MPI_COMPLEX32 are only supported on platforms where a   portable C datatype can be found that matches the Fortran type   REAL*16, both in size and bit representation.  - The ""libompitrace"" library is bundled in Open MPI and is installed   by default (it can be disabled via the --disable-libompitrace   flag).  This library provides a simplistic tracing of select MPI   function calls via the MPI profiling interface.  Linking it in to   your appliation via (e.g., via -lompitrace) will automatically   output to stderr when some MPI functions are invoked:    shell$ cd examples/   shell$ mpicc hello_c.c -o hello_c -lompitrace   shell$ mpirun -np 1 hello_c   MPI_INIT: argc 1   Hello, world, I am 0 of 1   MPI_BARRIER[0]: comm MPI_COMM_WORLD   MPI_FINALIZE[0]   shell$    Keep in mind that the output from the trace library is going to   stderr, so it may output in a slightly different order than the   stdout from your application.    This library is being offered as a ""proof of concept"" / convenience   from Open MPI.  If there is interest, it is trivially easy to extend   it to printf for other MPI functions.  Patches and/or suggestions   would be greatfully appreciated on the Open MPI developer's list.  OSHMEM Functionality and Features ------------------------------  - All OpenSHMEM-1.0 functionality is supported.   MPI Collectives -----------  - The ""hierarch"" coll component (i.e., an implementation of MPI   collective operations) attempts to discover network layers of   latency in order to segregate individual ""local"" and ""global""   operations as part of the overall collective operation.  In this   way, network traffic can be reduced -- or possibly even minimized   (similar to MagPIe).  The current ""hierarch"" component only   separates MPI processes into on- and off-node groups.    Hierarch has had sufficient correctness testing, but has not   received much performance tuning.  As such, hierarch is not   activated by default -- it must be enabled manually by setting its   priority level to 100:      mpirun --mca coll_hierarch_priority 100 ...    We would appreciate feedback from the user community about how well   hierarch works for your applications.  - The ""fca"" coll component: the Mellanox Fabric Collective Accelerator   (FCA) is a solution for offloading collective operations from the   MPI process onto Mellanox QDR InfiniBand switch CPUs and HCAs.  - The ""ML"" coll component is an implementation of MPI collective   operations that takes advantage of communication hierarchies in   modern systems. A ML collective operation is implemented by   combining multiple independently progressing collective primitives   implemented over different communication hierarchies, hence a ML   collective operation is also referred to as a hierarchical   collective operation. The number of collective primitives that are   included in a ML collective operation is a function of   subgroups(hierarchies).  Typically, MPI processes in a single   communication hierarchy such as CPU socket, node, or subnet are   grouped together into a single subgroup (hierarchy). The number of   subgroups are configurable at runtime, and each different collective   operation could be configured to have a different of number of   subgroups.    The component frameworks and components used by/required for a   ""ML"" collective operation.    Frameworks:   * ""sbgp"" - Provides functionality for grouping processes into              subgroups   * ""bcol"" - Provides collective primitives optimized for a particular              communication hierarchy    Components:   * sbgp components - Provides grouping functionality over a CPU                       socket (""basesocket""), shared memory                       (""basesmuma""), Mellanox's ConnectX HCA                       (""ibnet""), and other interconnects supported by                       PML (""p2p"")   * BCOL components - Provides optimized collective primitives for                       shared memory (""basesmuma""), Mellanox's ConnectX                       HCA (""iboffload""), and other interconnects                       supported by PML (""ptpcoll"")  - The ""cuda"" coll component provides CUDA-aware support for the   reduction type collectives with GPU buffers. This component is only   compiled into the library when the library has been configured with   CUDA-aware support.  It intercepts calls to the reduction   collectives, copies the data to staging buffers if GPU buffers, then   calls underlying collectives to do the work.  OSHMEM Collectives -----------  - The ""fca"" scoll component: the Mellanox Fabric Collective Accelerator   (FCA) is a solution for offloading collective operations from the   MPI process onto Mellanox QDR InfiniBand switch CPUs and HCAs.  - The ""basic"" scoll component: Reference implementation of all OSHMEM   collective operations.   Network Support ---------------  - There are three main MPI network models available: ""ob1"", ""cm"", and   ""yalla"". ""ob1"" uses BTL (""Byte Transfer Layer"") components for each   supported network.  ""cm"" uses MTL (""Matching Tranport Layer"")   components for each supported network.  ""yalla"" uses the Mellanox   MXM transport.    - ""ob1"" supports a variety of networks that can be used in     combination with each other (per OS constraints; e.g., there are     reports that the GM and OpenFabrics kernel drivers do not operate     well together):      - OpenFabrics: InfiniBand, iWARP, and RoCE     - Loopback (send-to-self)     - Shared memory     - TCP     - Intel Phi SCIF     - SMCUDA     - Cisco usNIC     - uGNI (Cray Gemini, Aries)     - vader (XPMEM, Linux CMA, Linux KNEM, and general shared memory)    - ""cm"" supports a smaller number of networks (and they cannot be     used together), but may provide better overall MPI performance:      - QLogic InfiniPath / Intel True Scale PSM     - Intel Omni-Path PSM2     - Mellanox MXM     - Portals4     - OpenFabrics Interfaces (""libfabric"" tag matching)      Open MPI will, by default, choose to use ""cm"" when one of the     above transports can be used.  Otherwise, ""ob1"" will be used and     the corresponding BTLs will be selected. Users can force the use     of ob1 or cm if desired by setting the ""pml"" MCA parameter at     run-time:        shell$ mpirun --mca pml ob1 ...       or       shell$ mpirun --mca pml cm ...  - Similarly, there are two OSHMEM network models available: ""yoda"",   and ""ikrit"". ""yoda"" also uses the BTL components for many supported   network. ""ikrit"" interfaces directly with Mellanox MXM.    - ""yoda"" supports a variety of networks that can be used:      - OpenFabrics: InfiniBand, iWARP, and RoCE     - Loopback (send-to-self)     - Shared memory     - TCP    - ""ikrit"" only supports Mellanox MXM.  - MXM is the Mellanox Messaging Accelerator library utilizing a full   range of IB transports to provide the following messaging services   to the upper level MPI/OSHMEM libraries:    - Usage of all available IB transports   - Native RDMA support   - Progress thread   - Shared memory communication   - Hardware-assisted reliability  - The usnic BTL is support for Cisco's usNIC device (""userspace NIC"")   on Cisco UCS servers with the Virtualized Interface Card (VIC).   Although the usNIC is accessed via the OpenFabrics Libfabric API   stack, this BTL is specific to the Cisco usNIC device.  - uGNI is a Cray library for communicating over the Gemini and Aries   interconnects.  - The OpenFabrics Enterprise Distribution (OFED) software package v1.0   will not work properly with Open MPI v1.2 (and later) due to how its   Mellanox InfiniBand plugin driver is created.  The problem is fixed   OFED v1.1 (and later).  - Better memory management support is available for OFED-based   transports using the ""ummunotify"" Linux kernel module.  OFED memory   managers are necessary for better bandwidth when re-using the same   buffers for large messages (e.g., benchmarks and some applications).    Unfortunately, the ummunotify module was not accepted by the Linux   kernel community (and is still not distributed by OFED).  But it   still remains the best memory management solution for MPI   applications that used the OFED network transports.  If Open MPI is   able to find the <linux/ummunotify.h> header file, it will build   support for ummunotify and include it by default.  If MPI processes   then find the ummunotify kernel module loaded and active, then their   memory managers (which have been shown to be problematic in some   cases) will be disabled and ummunotify will be used.  Otherwise, the   same memory managers from prior versions of Open MPI will be used.   The ummunotify Linux kernel module can be downloaded from:      http://lwn.net/Articles/343351/  - The use of fork() with OpenFabrics-based networks (i.e., the openib   BTL) is only partially supported, and only on Linux kernels >=   v2.6.15 with libibverbs v1.1 or later (first released as part of   OFED v1.2), per restrictions imposed by the OFED network stack.  - Linux ""knem"" support is used when the ""vader"" or ""sm"" (shared   memory) BTLs are compiled with knem support (see the --with-knem   configure option) and the knem Linux module is loaded in the running   kernel.  If the knem Linux kernel module is not loaded, the knem   support is (by default) silently deactivated during Open MPI jobs.    See http://runtime.bordeaux.inria.fr/knem/ for details on Knem.  - Linux Cross-Memory Attach (CMA) or XPMEM is used by the vader   shared-memory BTL when the CMA/XPMEM libraries are installedm,   respectively.  Linux CMA and XPMEM are similar (but different)   mechanisms for Open MPI to utilize single-copy semantics for shared   memory.  Open MPI Extensions -------------------  - An MPI ""extensions"" framework has been added (but is not enabled by   default).  See the ""Open MPI API Extensions"" section below for more   information on compiling and using MPI extensions.  - The following extensions are included in this version of Open MPI:    - affinity: Provides the OMPI_Affinity_str() routine on retrieving     a string that contains what resources a process is bound to.  See     its man page for more details.   - cr: Provides routines to access to checkpoint restart routines.     See ompi/mpiext/cr/mpiext_cr_c.h for a listing of availble     functions.   - cuda: When the library is compiled with CUDA-aware support, it provides     two things.  First, a macro MPIX_CUDA_AWARE_SUPPORT. Secondly, the     function MPIX_Query_cuda_support that can be used to query for support.   - example: A non-functional extension; its only purpose is to     provide an example for how to create other extensions.  ===========================================================================  Building Open MPI -----------------  Open MPI uses a traditional configure script paired with ""make"" to build.  Typical installs can be of the pattern:  --------------------------------------------------------------------------- shell$ ./configure [...options...] shell$ make all install ---------------------------------------------------------------------------  There are many available configure options (see ""./configure --help"" for a full list); a summary of the more commonly used ones is included below.  Note that for many of Open MPI's --with-<foo> options, Open MPI will, by default, search for header files and/or libraries for <foo>.  If the relevant files are found, Open MPI will built support for <foo>; if they are not found, Open MPI will skip building support for <foo>. However, if you specify --with-<foo> on the configure command line and Open MPI is unable to find relevant support for <foo>, configure will assume that it was unable to provide a feature that was specifically requested and will abort so that a human can resolve out the issue.  INSTALLATION OPTIONS  --prefix=<directory>   Install Open MPI into the base directory named <directory>.  Hence,   Open MPI will place its executables in <directory>/bin, its header   files in <directory>/include, its libraries in <directory>/lib, etc.  --disable-shared   By default, libmpi and libshmem are built as a shared library, and   all components are built as dynamic shared objects (DSOs). This   switch disables this default; it is really only useful when used with   --enable-static.  Specifically, this option does *not* imply   --enable-static; enabling static libraries and disabling shared   libraries are two independent options.  --enable-static   Build libmpi and libshmem as static libraries, and statically link in all   components.  Note that this option does *not* imply   --disable-shared; enabling static libraries and disabling shared   libraries are two independent options.    Be sure to read the description of --without-memory-manager, below;   it may have some effect on --enable-static.  --disable-wrapper-rpath   By default, the wrapper compilers (e.g., mpicc) will enable ""rpath""   support in generated executables on systems that support it.  That   is, they will include a file reference to the location of Open MPI's   libraries in the application executable itself.  This means that   the user does not have to set LD_LIBRARY_PATH to find Open MPI's   libraries (e.g., if they are installed in a location that the   run-time linker does not search by default).    On systems that utilize the GNU ld linker, recent enough versions   will actually utilize ""runpath"" functionality, not ""rpath"".  There   is an important difference between the two:    ""rpath"": the location of the Open MPI libraries is hard-coded into       the MPI/OSHMEM application and cannot be overridden at run-time.   ""runpath"": the location of the Open MPI libraries is hard-coded into       the MPI/OSHMEM application, but can be overridden at run-time by       setting the LD_LIBRARY_PATH environment variable.    For example, consider that you install Open MPI vA.B.0 and   compile/link your MPI/OSHMEM application against it.  Later, you install   Open MPI vA.B.1 to a different installation prefix (e.g.,   /opt/openmpi/A.B.1 vs. /opt/openmpi/A.B.0), and you leave the old   installation intact.    In the rpath case, your MPI application will always use the   libraries from your A.B.0 installation.  In the runpath case, you   can set the LD_LIBRARY_PATH environment variable to point to the   A.B.1 installation, and then your MPI application will use those   libraries.    Note that in both cases, however, if you remove the original A.B.0   installation and set LD_LIBRARY_PATH to point to the A.B.1   installation, your application will use the A.B.1 libraries.    This rpath/runpath behavior can be disabled via   --disable-wrapper-rpath.  --enable-dlopen   Build all of Open MPI's components as standalone Dynamic Shared   Objects (DSO's) that are loaded at run-time (this is the default).   The opposite of this option, --disable-dlopen, causes two things:    1. All of Open MPI's components will be built as part of Open MPI's      normal libraries (e.g., libmpi).   2. Open MPI will not attempt to open any DSO's at run-time.    Note that this option does *not* imply that OMPI's libraries will be   built as static objects (e.g., libmpi.a).  It only specifies the   location of OMPI's components: standalone DSOs or folded into the   Open MPI libraries.  You can control whether Open MPI's libraries   are build as static or dynamic via --enable|disable-static and   --enable|disable-shared.  --with-platform=FILE   Load configure options for the build from FILE.  Options on the   command line that are not in FILE are also used.  Options on the   command line and in FILE are replaced by what is in FILE.  NETWORKING SUPPORT / OPTIONS  --with-fca=<directory>   Specify the directory where the Mellanox FCA library and   header files are located.    FCA is the support library for Mellanox QDR switches and HCAs.  --with-hcoll=<directory>   Specify the directory where the Mellanox hcoll library and header   files are located.  This option is generally only necessary if the   hcoll headers and libraries are not in default compiler/linker   search paths.    hcoll is the support library for MPI collective operation offload on   Mellanox ConnectX-3 HCAs (and later).  --with-knem=<directory>   Specify the directory where the knem libraries and header files are   located.  This option is generally only necessary if the knem headers   and libraries are not in default compiler/linker search paths.    knem is a Linux kernel module that allows direct process-to-process   memory copies (optionally using hardware offload), potentially   increasing bandwidth for large messages sent between messages on the   same server.  See http://runtime.bordeaux.inria.fr/knem/ for   details.  --with-libfabric=<directory>   Specify the directory where the OpenFabrics Interfaces libfabric   library and header files are located.  This option is generally only   necessary if the libfabric headers and libraries are not in default   compiler/linker search paths.    Libfabric is the support library for OpenFabrics Interfaces-based   network adapters, such as Cisco usNIC, Intel True Scale PSM, etc.  --with-libfabric-libdir=<directory>   Look in directory for the libfabric libraries.  By default, Open MPI   will look in <libfabric directory>/lib and <libfabric   directory>/lib64, which covers most cases.  This option is only   needed for special configurations.  --with-mxm=<directory>   Specify the directory where the Mellanox MXM library and header   files are located.  This option is generally only necessary if the   MXM headers and libraries are not in default compiler/linker search   paths.    MXM is the support library for Mellanox Network adapters.  --with-mxm-libdir=<directory>   Look in directory for the MXM libraries.  By default, Open MPI will   look in <mxm directory>/lib and <mxm directory>/lib64, which covers   most cases.  This option is only needed for special configurations.  --with-portals4=<directory>   Specify the directory where the Portals4 libraries and header files   are located.  This option is generally only necessary if the Portals4   headers and libraries are not in default compiler/linker search   paths.    Portals is a low-level network API for high-performance networking   on high-performance computing systems developed by Sandia National   Laboratories, Intel Corporation, and the University of New Mexico.   The Portals 4 Reference Implementation is a complete implementation   of Portals 4, with transport over InfiniBand verbs and UDP.  --with-portals4-libdir=<directory>   Location of libraries to link with for Portals4 support.  --with-portals4-max-md-size=SIZE --with-portals4-max-va-size=SIZE   Set configuration values for Portals 4  --with-psm=<directory>   Specify the directory where the QLogic InfiniPath / Intel True Scale   PSM library and header files are located.  This option is generally   only necessary if the PSM headers and libraries are not in default   compiler/linker search paths.    PSM is the support library for QLogic InfiniPath and Intel TrueScale   network adapters.  --with-psm-libdir=<directory>   Look in directory for the PSM libraries.  By default, Open MPI will   look in <psm directory>/lib and <psm directory>/lib64, which covers   most cases.  This option is only needed for special configurations.  --with-psm2=<directory>   Specify the directory where the Intel Omni-Path PSM2 library and   header files are located.  This option is generally only necessary   if the PSM2 headers and libraries are not in default compiler/linker   search paths.    PSM2 is the support library for Intel Omni-Path network adapters.  --with-psm2-libdir=<directory>   Look in directory for the PSM2 libraries.  By default, Open MPI will   look in <psm2 directory>/lib and <psm2 directory>/lib64, which   covers most cases.  This option is only needed for special   configurations.  --with-scif=<dir>   Look in directory for Intel SCIF support libraries  --with-verbs=<directory>   Specify the directory where the verbs (also know as OpenFabrics, and   previously known as OpenIB) libraries and header files are located.   This option is generally only necessary if the verbs headers and   libraries are not in default compiler/linker search paths.    ""OpenFabrics"" refers to operating system bypass networks, such as   InfiniBand, usNIC, iWARP, and RoCE (aka ""IBoIP"").  --with-verbs-libdir=<directory>   Look in directory for the verbs libraries.  By default, Open MPI   will look in <verbs_directory>/lib and <verbs_ directory>/lib64,   which covers most cases.  This option is only needed for special   configurations.  --with-verbs-usnic   This option will activate support in Open MPI for disabling a   dire-sounding warning message from libibverbs that Cisco usNIC   devices are not supported (because Cisco usNIC devices are supported   through libfabric, not libibverbs).  This libibverbs warning can   also be suppressed by installing the ""no op"" libusnic_verbs plugin   for libibverbs (see https://github.com/cisco/libusnic_verbs, or   download binaries from cisco.com).  This option is disabled by   default because it causes libopen-pal.so to depend on libibverbs.so,   which is undesirable to many downstream packagers.  --with-usnic   Abort configure if Cisco usNIC support cannot be built.  RUN-TIME SYSTEM SUPPORT  --enable-mpirun-prefix-by-default   This option forces the ""mpirun"" command to always behave as if   ""--prefix $prefix"" was present on the command line (where $prefix is   the value given to the --prefix option to configure).  This prevents   most rsh/ssh-based users from needing to modify their shell startup   files to set the PATH and/or LD_LIBRARY_PATH for Open MPI on remote   nodes.  Note, however, that such users may still desire to set PATH   -- perhaps even in their shell startup files -- so that executables   such as mpicc and mpirun can be found without needing to type long   path names.  --enable-orterun-prefix-by-default is a synonym for   this option.  --enable-sensors   Enable internal sensors (default: disabled).  --enable-orte-static-ports    Enable orte static ports for tcp oob (default: enabled).  --with-alps   Force the building of for the Cray Alps run-time environment.  If   Alps support cannot be found, configure will abort.  --with-loadleveler   Force the building of LoadLeveler scheduler support.  If LoadLeveler   support cannot be found, configure will abort.  --with-lsf=<directory>   Specify the directory where the LSF libraries and header files are   located.  This option is generally only necessary if the LSF headers   and libraries are not in default compiler/linker search paths.    LSF is a resource manager system, frequently used as a batch   scheduler in HPC systems.    NOTE: If you are using LSF version 7.0.5, you will need to add         ""LIBS=-ldl"" to the configure command line.  For example:              ./configure LIBS=-ldl --with-lsf ...          This workaround should *only* be needed for LSF 7.0.5.  --with-lsf-libdir=<directory>   Look in directory for the LSF libraries.  By default, Open MPI will   look in <lsf directory>/lib and <lsf directory>/lib64, which covers   most cases.  This option is only needed for special configurations.  --with-pmi   Build PMI support (by default on non-Cray XE/XC systems, it is not   built).  On Cray XE/XC systems, the location of pmi is detected   automatically as part of the configure process.  For non-Cray   systems, if the pmi2.h header is found in addition to pmi.h, then   support for PMI2 will be built.  --with-slurm   Force the building of SLURM scheduler support.  --with-sge   Specify to build support for the Oracle Grid Engine (OGE) resource   manager and/or the Open Grid Engine.  OGE support is disabled by   default; this option must be specified to build OMPI's OGE support.    The Oracle Grid Engine (OGE) and open Grid Engine packages are   resource manager systems, frequently used as a batch scheduler in   HPC systems.  --with-tm=<directory>   Specify the directory where the TM libraries and header files are   located.  This option is generally only necessary if the TM headers   and libraries are not in default compiler/linker search paths.    TM is the support library for the Torque and PBS Pro resource   manager systems, both of which are frequently used as a batch   scheduler in HPC systems.  MISCELLANEOUS SUPPORT LIBRARIES  --with-blcr=<directory>   Specify the directory where the Berkeley Labs Checkpoint / Restart   (BLCR) libraries and header files are located.  This option is   generally only necessary if the BLCR headers and libraries are not   in default compiler/linker search paths.    This option is only meaningful if the --with-ft option is also used   to active Open MPI's fault tolerance behavior.  --with-blcr-libdir=<directory>   Look in directory for the BLCR libraries.  By default, Open MPI will   look in <blcr directory>/lib and <blcr directory>/lib64, which   covers most cases.  This option is only needed for special   configurations.  --with-dmtcp=<directory>   Specify the directory where the Distributed MultiThreaded   Checkpointing (DMTCP) libraries and header files are located.  This   option is generally only necessary if the DMTCP headers and   libraries are not in default compiler/linker search paths.    This option is only meaningful if the --with-ft option is also used   to active Open MPI's fault tolerance behavior.  --with-dmtcp-libdir=<directory>   Look in directory for the DMTCP libraries.  By default, Open MPI   will look in <dmtcp directory>/lib and <dmtcp directory>/lib64,   which covers most cases.  This option is only needed for special   configurations.  --with-libevent(=value)   This option specifies where to find the libevent support headers and   library.  The following VALUEs are permitted:      internal:    Use Open MPI's internal copy of libevent.     external:    Use an external libevent installation (rely on default                  compiler and linker paths to find it)     <no value>:  Same as ""internal"".     <directory>: Specify the location of a specific libevent                  installation to use    By default (or if --with-libevent is specified with no VALUE), Open   MPI will build and use the copy of libeveny that it has in its   source tree.  However, if the VALUE is ""external"", Open MPI will   look for the relevant libevent header file and library in default   compiler / linker locations.  Or, VALUE can be a directory tree   where the libevent header file and library can be found.  This   option allows operating systems to include Open MPI and use their   default libevent installation instead of Open MPI's bundled libevent.    libevent is a support library that provides event-based processing,   timers, and signal handlers.  Open MPI requires libevent to build;   passing --without-libevent will cause configure to abort.  --with-libevent-libdir=<directory>   Look in directory for the libevent libraries.  This option is only   usable when building Open MPI against an external libevent   installation.  Just like other --with-FOO-libdir configure options,   this option is only needed for special configurations.  --with-hwloc(=value)   Build hwloc support (default: enabled).  This option specifies where   to find the hwloc support headers and library.  The following values   are permitted:      internal:    Use Open MPI's internal copy of hwloc.     external:    Use an external hwloc installation (rely on default                  compiler and linker paths to find it)     <no value>:  Same as ""internal"".     <directory>: Specify the location of a specific hwloc                  installation to use    By default (or if --with-hwloc is specified with no VALUE), Open MPI   will build and use the copy of hwloc that it has in its source tree.   However, if the VALUE is ""external"", Open MPI will look for the   relevant hwloc header files and library in default compiler / linker   locations.  Or, VALUE can be a directory tree where the hwloc header   file and library can be found.  This option allows operating systems   to include Open MPI and use their default hwloc installation instead   of Open MPI's bundled hwloc.    hwloc is a support library that provides processor and memory   affinity information for NUMA platforms.  --with-hwloc-libdir=<directory>   Look in directory for the hwloc libraries.  This option is only   usable when building Open MPI against an external hwloc   installation.  Just like other --with-FOO-libdir configure options,   this option is only needed for special configurations.  --disable-hwloc-pci   Disable building hwloc's PCI device-sensing capabilities.  On some   platforms (e.g., SusE 10 SP1, x86-64), the libpci support library is   broken.  Open MPI's configure script should usually detect when   libpci is not usable due to such brokenness and turn off PCI   support, but there may be cases when configure mistakenly enables   PCI support in the presence of a broken libpci.  These cases may   result in ""make"" failing with warnings about relocation symbols in   libpci.  The --disable-hwloc-pci switch can be used to force Open   MPI to not build hwloc's PCI device-sensing capabilities in these   cases.    Similarly, if Open MPI incorrectly decides that libpci is broken,   you can force Open MPI to build hwloc's PCI device-sensing   capabilities by using --enable-hwloc-pci.    hwloc can discover PCI devices and locality, which can be useful for   Open MPI in assigning message passing resources to MPI processes.  --with-libltdl=<directory>   Specify the directory where the GNU Libtool libltdl libraries and   header files are located.  This option is generally only necessary   if the libltdl headers and libraries are not in default   compiler/linker search paths.    Note that this option is ignored if --disable-dlopen is specified.  --disable-libompitrace   Disable building the simple ""libompitrace"" library (see note above   about libompitrace)  --with-valgrind(=<directory>)   Directory where the valgrind software is installed.  If Open MPI   finds Valgrind's header files, it will include additional support   for Valgrind's memory-checking debugger.    Specifically, it will eliminate a lot of false positives from   running Valgrind on MPI applications.  There is a minor performance   penalty for enabling this option.  MPI FUNCTIONALITY  --with-mpi-param-check(=value)   Whether or not to check MPI function parameters for errors at   runtime.  The following values are permitted:      always:  MPI function parameters are always checked for errors     never:   MPI function parameters are never checked for errors     runtime: Whether MPI function parameters are checked depends on              the value of the MCA parameter mpi_param_check (default:              yes).     yes:     Synonym for ""always"" (same as --with-mpi-param-check).     no:      Synonym for ""none"" (same as --without-mpi-param-check).    If --with-mpi-param is not specified, ""runtime"" is the default.  --enable-mpi-thread-multiple   Allows the MPI thread level MPI_THREAD_MULTIPLE.   This is currently disabled by default. Enabling   this feature will automatically --enable-opal-multi-threads.  --enable-opal-multi-threads   Enables thread lock support in the OPAL and ORTE layers. Does   not enable MPI_THREAD_MULTIPLE - see above option for that feature.   This is currently disabled by default.  --enable-mpi-cxx   Enable building the C++ MPI bindings (default: disabled).    The MPI C++ bindings were deprecated in MPI-2.2, and removed from   the MPI standard in MPI-3.0.  --enable-mpi-java   Enable building of an EXPERIMENTAL Java MPI interface (disabled by   default).  You may also need to specify --with-jdk-dir,   --with-jdk-bindir, and/or --with-jdk-headers.  See README.JAVA.txt   for details.    Note that this Java interface is INCOMPLETE (meaning: it does not   support all MPI functionality) and LIKELY TO CHANGE.  The Open MPI   developers would very much like to hear your feedback about this   interface.  See README.JAVA.txt for more details.  --enable-mpi-fortran(=value)   By default, Open MPI will attempt to build all 3 Fortran bindings:   mpif.h, the ""mpi"" module, and the ""mpi_f08"" module.  The following   values are permitted:      all:        Synonym for ""yes"".     yes:        Attempt to build all 3 Fortran bindings; skip                 any binding that cannot be built (same as                 --enable-mpi-fortran).     mpifh:      Build mpif.h support.     usempi:     Build mpif.h and ""mpi"" module support.     usempif08:  Build mpif.h, ""mpi"" module, and ""mpi_f08""                 module support.     none:       Synonym for ""no"".     no:         Do not build any MPI Fortran support (same as                 --disable-mpi-fortran).  This is mutually exclusive                 with building the OSHMEM Fortran interface.  --enable-mpi-ext(=<list>)   Enable Open MPI's non-portable API extensions.  If no <list> is   specified, all of the extensions are enabled.    See ""Open MPI API Extensions"", below, for more details.  --with-io-romio-flags=flags   Pass flags to the ROMIO distribution configuration script.  This   option is usually only necessary to pass   parallel-filesystem-specific preprocessor/compiler/linker flags back   to the ROMIO system.  --enable-sparse-groups   Enable the usage of sparse groups. This would save memory   significantly especially if you are creating large   communicators. (Disabled by default)  OSHMEM FUNCTIONALITY  --disable-oshmem   Disable building the OpenSHMEM implementation (by default, it is   enabled).  --disable-oshmem-fortran   Disable building only the Fortran OSHMEM bindings. Please see   the ""Compiler Notes"" section herein which contains further   details on known issues with various Fortran compilers.  MISCELLANEOUS FUNCTIONALITY  --without-memory-manager   Disable building Open MPI's memory manager.  Open MPI's memory   manager is usually built on Linux based platforms, and is generally   only used for optimizations with some OpenFabrics-based networks (it   is not *necessary* for OpenFabrics networks, but some performance   loss may be observed without it).    However, it may be necessary to disable the memory manager in order   to build Open MPI statically.  --with-ft=TYPE   Specify the type of fault tolerance to enable.  Options: LAM   (LAM/MPI-like), cr (Checkpoint/Restart).  Fault tolerance support is   disabled unless this option is specified.  --enable-peruse   Enable the PERUSE MPI data analysis interface.  --enable-heterogeneous   Enable support for running on heterogeneous clusters (e.g., machines   with different endian representations).  Heterogeneous support is   disabled by default because it imposes a minor performance penalty.    *** THIS FUNCTIONALITY IS CURRENTLY BROKEN - DO NOT USE ***  --with-wrapper-cflags=<cflags> --with-wrapper-cxxflags=<cxxflags> --with-wrapper-fflags=<fflags> --with-wrapper-fcflags=<fcflags> --with-wrapper-ldflags=<ldflags> --with-wrapper-libs=<libs>   Add the specified flags to the default flags that used are in Open   MPI's ""wrapper"" compilers (e.g., mpicc -- see below for more   information about Open MPI's wrapper compilers).  By default, Open   MPI's wrapper compilers use the same compilers used to build Open   MPI and specify a minimum set of additional flags that are necessary   to compile/link MPI applications.  These configure options give   system administrators the ability to embed additional flags in   OMPI's wrapper compilers (which is a local policy decision).  The   meanings of the different flags are:    <cflags>:   Flags passed by the mpicc wrapper to the C compiler   <cxxflags>: Flags passed by the mpic++ wrapper to the C++ compiler   <fcflags>:  Flags passed by the mpifort wrapper to the Fortran compiler   <ldflags>:  Flags passed by all the wrappers to the linker   <libs>:     Flags passed by all the wrappers to the linker    There are other ways to configure Open MPI's wrapper compiler   behavior; see the Open MPI FAQ for more information.  There are many other options available -- see ""./configure --help"".  Changing the compilers that Open MPI uses to build itself uses the standard Autoconf mechanism of setting special environment variables either before invoking configure or on the configure command line. The following environment variables are recognized by configure:  CC          - C compiler to use CFLAGS      - Compile flags to pass to the C compiler CPPFLAGS    - Preprocessor flags to pass to the C compiler  CXX         - C++ compiler to use CXXFLAGS    - Compile flags to pass to the C++ compiler CXXCPPFLAGS - Preprocessor flags to pass to the C++ compiler  FC          - Fortran compiler to use FCFLAGS     - Compile flags to pass to the Fortran compiler  LDFLAGS     - Linker flags to pass to all compilers LIBS        - Libraries to pass to all compilers (it is rarely               necessary for users to need to specify additional LIBS)  PKG_CONFIG  - Path to the pkg-config utility  For example:    shell$ ./configure CC=mycc CXX=myc++ FC=myfortran ...  *** NOTE: We generally suggest using the above command line form for     setting different compilers (vs. setting environment variables and     then invoking ""./configure"").  The above form will save all     variables and values in the config.log file, which makes     post-mortem analysis easier if problems occur.  Note that if you intend to compile Open MPI with a ""make"" other than the default one in your PATH, then you must either set the $MAKE environment variable before invoking Open MPI's configure script, or pass ""MAKE=your_make_prog"" to configure.  For example:    shell$ ./configure MAKE=/path/to/my/make ...  This could be the case, for instance, if you have a shell alias for ""make"", or you always type ""gmake"" out of habit.  Failure to tell configure which non-default ""make"" you will use to compile Open MPI can result in undefined behavior (meaning: don't do that).  Note that you may also want to ensure that the value of LD_LIBRARY_PATH is set appropriately (or not at all) for your build (or whatever environment variable is relevant for your operating system).  For example, some users have been tripped up by setting to use a non-default Fortran compiler via FC, but then failing to set LD_LIBRARY_PATH to include the directory containing that non-default Fortran compiler's support libraries.  This causes Open MPI's configure script to fail when it tries to compile / link / run simple Fortran programs.  It is required that the compilers specified be compile and link compatible, meaning that object files created by one compiler must be able to be linked with object files from the other compilers and produce correctly functioning executables.  Open MPI supports all the ""make"" targets that are provided by GNU Automake, such as:  all       - build the entire Open MPI package install   - install Open MPI uninstall - remove all traces of Open MPI from the $prefix clean     - clean out the build tree  Once Open MPI has been built and installed, it is safe to run ""make clean"" and/or remove the entire build tree.  VPATH and parallel builds are fully supported.  Generally speaking, the only thing that users need to do to use Open MPI is ensure that <prefix>/bin is in their PATH and <prefix>/lib is in their LD_LIBRARY_PATH.  Users may need to ensure to set the PATH and LD_LIBRARY_PATH in their shell setup files (e.g., .bashrc, .cshrc) so that non-interactive rsh/ssh-based logins will be able to find the Open MPI executables.  ===========================================================================  Open MPI Version Numbers and Binary Compatibility -------------------------------------------------  Open MPI has two sets of version numbers that are likely of interest to end users / system administrator:    * Software version number   * Shared library version numbers  Both are predicated on Open MPI's definition of ""backwards compatibility.""  NOTE: The version numbering conventions were changed with the release       of v1.10.0.  Most notably, Open MPI no longer uses an ""odd/even""       release schedule to indicate feature development vs. stable       releases.  See the README in releases prior to v1.10.0 for more       information (e.g.,       https://github.com/open-mpi/ompi-release/blob/v1.8/README#L1392-L1475).  Backwards Compatibility -----------------------  Open MPI version vY is backwards compatible with Open MPI version vX (where Y>X) if users can:    * Users can compile a correct MPI / OSHMEM program with vX   * Run it with the same CLI options and MCA parameters using vX or vY   * The job executes correctly  Note that this definition encompasses several things:    * Application Binary Interface (ABI)   * MPI / OSHMEM run time system   * mpirun / oshrun command line options   * MCA parameter names / values / meanings  However, this definition only applies when the same version of Open MPI is used with all instances of the runtime and MPI / OSHMEM processes in a single MPI job.  If the versions are not exactly the same everywhere, Open MPI is not guaranteed to work properly in any scenario.  Software Version Number -----------------------  Official Open MPI releases use the common ""A.B.C"" version identifier format.  Each of the three numbers has a specific meaning:    * Major: The major number is the first integer in the version string     Changes in the major number typically indicate a significant     change in the code base and/or end-user functionality, and also     indicate a break from backwards compatibility.  Specifically: Open     MPI releases with different major version numbers are not     backwards compatibile with each other.      CAVEAT: This rule does not extend to versions prior to v1.10.0.             Specifically: v1.10.x is not guaranteed to be backwards             compatible with other v1.x releases.    * Minor: The minor number is the second integer in the version     string.  Changes in the minor number indicate a user-observable     change in the code base and/or end-user functionality.  Backwards     compatibility will still be preserved with prior releases that     have the same major version number (e.g., v2.5.3 is backwards     compatible with v2.3.1).    * Release: The release number is the third integer in the version     string.  Changes in the release number typically indicate a bug     fix in the code base and/or end-user functionality.  For example,     if there is a release that only contains bug fixes and no other     user-observable changes or new features, only the third integer     will be increased (e.g., from v4.3.0 to v4.3.1).  The ""A.B.C"" version number may optionally be followed by a Quantifier:    * Quantifier: Open MPI version numbers sometimes have an arbitrary     string affixed to the end of the version number. Common strings     include:      o aX: Indicates an alpha release. X is an integer indicating the       number of the alpha release (e.g., v1.10.3a5 indicates the 5th       alpha release of version 1.10.3).     o bX: Indicates a beta release. X is an integer indicating the       number of the beta release (e.g., v1.10.3b3 indicates the 3rd       beta release of version 1.10.3).     o rcX: Indicates a release candidate. X is an integer indicating       the number of the release candidate (e.g., v1.10.3rc4 indicates       the 4th release candidate of version 1.10.3).  Nightly development snapshot tarballs use a different version number scheme; they contain three distinct values:     * The most recent Git tag name on the branch from which the tarball      was created.    * An integer indicating how many Git commits have occurred since      that Git tag.    * The Git hash of the tip of the branch.  For example, a snapshot tarball filename of ""openmpi-v1.8.2-57-gb9f1fd9.tar.bz2"" indicates that this tarball was created from the v1.8 branch, 57 Git commits after the ""v1.8.2"" tag, specifically at Git hash gb9f1fd9.  Open MPI's Git master branch contains a single ""dev"" tag.  For example, ""openmpi-dev-8-gf21c349.tar.bz2"" represents a snapshot tarball created from the master branch, 8 Git commits after the ""dev"" tag, specifically at Git hash gf21c349.  The exact value of the ""number of Git commits past a tag"" integer is fairly meaningless; its sole purpose is to provide an easy, human-recognizable ordering for snapshot tarballs.  Shared Library Version Number -----------------------------  The GNU Libtool official documentation details how the versioning scheme works.  The quick version is that the shared library versions are a triple of integers: (current,revision,age), or ""c:r:a"".  This triple is not related to the Open MPI software version number.  There are six simple rules for updating the values (taken almost verbatim from the Libtool docs):   1. Start with version information of ""0:0:0"" for each shared library.   2. Update the version information only immediately before a public     release of your software. More frequent updates are unnecessary,     and only guarantee that the current interface number gets larger     faster.   3. If the library source code has changed at all since the last     update, then increment revision (""c:r:a"" becomes ""c:r+1:a"").   4. If any interfaces have been added, removed, or changed since the     last update, increment current, and set revision to 0.   5. If any interfaces have been added since the last public release,     then increment age.   6. If any interfaces have been removed since the last public release,     then set age to 0.  Here's how we apply those rules specifically to Open MPI:   1. The above rules do not apply to MCA components (a.k.a. ""plugins"");     MCA component .so versions stay unspecified.   2. The above rules apply exactly as written to the following     libraries starting with Open MPI version v1.5 (prior to v1.5,     libopen-pal and libopen-rte were still at 0:0:0 for reasons     discussed in bug ticket #2092     https://svn.open-mpi.org/trac/ompi/ticket/2092):      * libopen-rte     * libopen-pal     * libmca_common_*   3. The following libraries use a slightly modified version of the     above rules: rules 4, 5, and 6 only apply to the official MPI and     OpenSHMEM interfaces (functions, global variables).  The rationale     for this decision is that the vast majority of our users only care     about the official/public MPI/OSHMEM interfaces; we therefore want     the .so version number to reflect only changes to the official     MPI/OSHMEM APIs.  Put simply: non-MPI/OSHMEM API / internal     changes to the MPI-application-facing libraries are irrelevant to     pure MPI/OSHMEM applications.      * libmpi     * libmpi_mpifh     * libmpi_usempi_tkr     * libmpi_usempi_ignore_tkr     * libmpi_usempif08     * libmpi_cxx     * libmpi_java     * liboshmem  ===========================================================================  Checking Your Open MPI Installation -----------------------------------  The ""ompi_info"" command can be used to check the status of your Open MPI installation (located in <prefix>/bin/ompi_info).  Running it with no arguments provides a summary of information about your Open MPI installation.  Note that the ompi_info command is extremely helpful in determining which components are installed as well as listing all the run-time settable parameters that are available in each component (as well as their default values).  The following options may be helpful:  --all       Show a *lot* of information about your Open MPI             installation. --parsable  Display all the information in an easily             grep/cut/awk/sed-able format. --param <framework> <component>             A <framework> of ""all"" and a <component> of ""all"" will             show all parameters to all components.  Otherwise, the             parameters of all the components in a specific framework,             or just the parameters of a specific component can be             displayed by using an appropriate <framework> and/or             <component> name. --level <level>             By default, ompi_info only shows ""Level 1"" MCA parameters             -- parameters that can affect whether MPI processes can             run successfully or not (e.g., determining which network             interfaces to use).  The --level option will display all             MCA parameters from level 1 to <level> (the max <level>             value is 9).  Use ""ompi_info --param <framework>             <component> --level 9"" to see *all* MCA parameters for a             given component.  See ""The Modular Component Architecture             (MCA)"" section, below, for a fuller explanation.  Changing the values of these parameters is explained in the ""The Modular Component Architecture (MCA)"" section, below.  When verifying a new Open MPI installation, we recommend running six tests:  1. Use ""mpirun"" to launch a non-MPI program (e.g., hostname or uptime)    across multiple nodes.  2. Use ""mpirun"" to launch a trivial MPI program that does no MPI    communication (e.g., the hello_c program in the examples/ directory    in the Open MPI distribution).  3. Use ""mpirun"" to launch a trivial MPI program that sends and    receives a few MPI messages (e.g., the ring_c program in the    examples/ directory in the Open MPI distribution).  4. Use ""oshrun"" to launch a non-OSHMEM program across multiple nodes.  5. Use ""oshrun"" to launch a trivial MPI program that does no OSHMEM    communication (e.g., hello_shmem.c program in the examples/ directory    in the Open MPI distribution.)  6. Use ""oshrun"" to launch a trivial OSHMEM program that puts and gets    a few messages. (e.g., the ring_shmem.c in the examples/ directory    in the Open MPI distribution.)  If you can run all six of these tests successfully, that is a good indication that Open MPI built and installed properly.  ===========================================================================  Open MPI API Extensions -----------------------  Open MPI contains a framework for extending the MPI API that is available to applications.  Each extension is usually a standalone set of functionality that is distinct from other extensions (similar to how Open MPI's plugins are usually unrelated to each other).  These extensions provide new functions and/or constants that are available to MPI applications.  WARNING: These extensions are neither standard nor portable to other MPI implementations!  Compiling the extensions ------------------------  Open MPI extensions are all enabled by default; they can be disabled via the --disable-mpi-ext command line switch.  Since extensions are meant to be used by advanced users only, this file does not document which extensions are available or what they do.  Look in the ompi/mpiext/ directory to see the extensions; each subdirectory of that directory contains an extension.  Each has a README file that describes what it does.  Using the extensions --------------------  To reinforce the fact that these extensions are non-standard, you must include a separate header file after <mpi.h> to obtain the function prototypes, constant declarations, etc.  For example:  ----- #include <mpi.h> #if defined(OPEN_MPI) && OPEN_MPI #include <mpi-ext.h> #endif  int main() {     MPI_Init(NULL, NULL);  #if defined(OPEN_MPI) && OPEN_MPI     {         char ompi_bound[OMPI_AFFINITY_STRING_MAX];         char current_binding[OMPI_AFFINITY_STRING_MAX];         char exists[OMPI_AFFINITY_STRING_MAX];         OMPI_Affinity_str(OMPI_AFFINITY_LAYOUT_FMT, ompi_bound,                           current_bindings, exists);     } #endif     MPI_Finalize();     return 0; } -----  Notice that the Open MPI-specific code is surrounded by the #if statement to ensure that it is only ever compiled by Open MPI.  The Open MPI wrapper compilers (mpicc and friends) should automatically insert all relevant compiler and linker flags necessary to use the extensions.  No special flags or steps should be necessary compared to ""normal"" MPI applications.  ===========================================================================  Compiling Open MPI Applications -------------------------------  Open MPI provides ""wrapper"" compilers that should be used for compiling MPI and OSHMEM applications:  C:          mpicc, oshcc C++:        mpiCC, oshCC (or mpic++ if your filesystem is case-insensitive) Fortran:    mpifort, oshfort  For example:    shell$ mpicc hello_world_mpi.c -o hello_world_mpi -g   shell$  For OSHMEM applications:    shell$ oshcc hello_shmem.c -o hello_shmem -g   shell$  All the wrapper compilers do is add a variety of compiler and linker flags to the command line and then invoke a back-end compiler.  To be specific: the wrapper compilers do not parse source code at all; they are solely command-line manipulators, and have nothing to do with the actual compilation or linking of programs.  The end result is an MPI executable that is properly linked to all the relevant libraries.  Customizing the behavior of the wrapper compilers is possible (e.g., changing the compiler [not recommended] or specifying additional compiler/linker flags); see the Open MPI FAQ for more information.  Alternatively, Open MPI also installs pkg-config(1) configuration files under $libdir/pkgconfig.  If pkg-config is configured to find these files, then compiling / linking Open MPI programs can be performed like this:    shell$ gcc hello_world_mpi.c -o hello_world_mpi -g \               `pkg-config ompi-c --cflags --libs`   shell$  Open MPI supplies multiple pkg-config(1) configuration files; one for each different wrapper compiler (language):  ------------------------------------------------------------------------ ompi       Synonym for ""ompi-c""; Open MPI applications using the C            MPI bindings ompi-c     Open MPI applications using the C MPI bindings ompi-cxx   Open MPI applications using the C or C++ MPI bindings ompi-fort  Open MPI applications using the Fortran MPI bindings ------------------------------------------------------------------------  The following pkg-config(1) configuration files *may* be installed, depending on which command line options were specified to Open MPI's configure script.  They are not necessary for MPI applications, but may be used by applications that use Open MPI's lower layer support libraries.  orte:       Open MPI Run-Time Environment applicaions opal:       Open Portable Access Layer applications  ===========================================================================  Running Open MPI Applications -----------------------------  Open MPI supports both mpirun and mpiexec (they are exactly equivalent) to launch MPI applications.  For example:    shell$ mpirun -np 2 hello_world_mpi   or   shell$ mpiexec -np 1 hello_world_mpi : -np 1 hello_world_mpi  are equivalent.  Some of mpiexec's switches (such as -host and -arch) are not yet functional, although they will not error if you try to use them.  The rsh launcher (which defaults to using ssh) accepts a -hostfile parameter (the option ""-machinefile"" is equivalent); you can specify a -hostfile parameter indicating an standard mpirun-style hostfile (one hostname per line):    shell$ mpirun -hostfile my_hostfile -np 2 hello_world_mpi  If you intend to run more than one process on a node, the hostfile can use the ""slots"" attribute.  If ""slots"" is not specified, a count of 1 is assumed.  For example, using the following hostfile:  --------------------------------------------------------------------------- node1.example.com node2.example.com node3.example.com slots=2 node4.example.com slots=4 ---------------------------------------------------------------------------    shell$ mpirun -hostfile my_hostfile -np 8 hello_world_mpi  will launch MPI_COMM_WORLD rank 0 on node1, rank 1 on node2, ranks 2 and 3 on node3, and ranks 4 through 7 on node4.  Other starters, such as the resource manager / batch scheduling environments, do not require hostfiles (and will ignore the hostfile if it is supplied).  They will also launch as many processes as slots have been allocated by the scheduler if no ""-np"" argument has been provided.  For example, running a SLURM job with 8 processors:    shell$ salloc -n 8 mpirun a.out  The above command will reserve 8 processors and run 1 copy of mpirun, which will, in turn, launch 8 copies of a.out in a single MPI_COMM_WORLD on the processors that were allocated by SLURM.  Note that the values of component parameters can be changed on the mpirun / mpiexec command line.  This is explained in the section below, ""The Modular Component Architecture (MCA)"".  Open MPI supports oshrun to launch OSHMEM applications. For example:     shell$ oshrun -np 2 hello_world_oshmem  OSHMEM applications may also be launched directly by resource managers such as SLURM. For example, when OMPI is configured --with-pmi and --with-slurm one may launch OSHMEM applications via srun:     shell$ srun -N 2 hello_world_oshmem   ===========================================================================  The Modular Component Architecture (MCA)  The MCA is the backbone of Open MPI -- most services and functionality are implemented through MCA components.  Here is a list of all the component frameworks in Open MPI:  ---------------------------------------------------------------------------  MPI component frameworks: -------------------------  bcol      - Base collective operations bml       - BTL management layer coll      - MPI collective algorithms crcp      - Checkpoint/restart coordination protocol fbtl      - file byte transfer layer: abstraction for individual             read/write operations for OMPIO fcoll     - collective read and write operations for MPI I/O fs        - file system functions for MPI I/O io        - MPI I/O mtl       - Matching transport layer, used for MPI point-to-point             messages on some types of networks op        - Back end computations for intrinsic MPI_Op operators osc       - MPI one-sided communications pml       - MPI point-to-point management layer rte       - Run-time environment operations sbgp      - Collective operation sub-group sharedfp  - shared file pointer operations for MPI I/O topo      - MPI topology routines vprotocol - Protocols for the ""v"" PML  OSHMEM component frameworks: -------------------------  atomic    - OSHMEM atomic operations memheap   - OSHMEM memory allocators that support the             PGAS memory model scoll     - OSHMEM collective operations spml      - OSHMEM ""pml-like"" layer: supports one-sided,             point-to-point operations sshmem    - OSHMEM shared memory backing facility   Back-end run-time environment (RTE) component frameworks: ---------------------------------------------------------  dfs       - Distributed file system errmgr    - RTE error manager ess       - RTE environment-specfic services filem     - Remote file management grpcomm   - RTE group communications iof       - I/O forwarding notifier  - System-level notification support odls      - OpenRTE daemon local launch subsystem oob       - Out of band messaging plm       - Process lifecycle management ras       - Resource allocation system rmaps     - Resource mapping system rml       - RTE message layer routed    - Routing table for the RML rtc       - Run-time control framework schizo    - OpenRTE personality framework snapc     - Snapshot coordination sstore    - Distributed scalable storage state     - RTE state machine  Miscellaneous frameworks: -------------------------  allocator   - Memory allocator backtrace   - Debugging call stack backtrace support btl         - point-to-point Byte Transfer Layer compress    - Compression algorithms crs         - Checkpoint and restart service dl          - Dynamic loading library interface event       - Event library (libevent) versioning support hwloc       - Hardware locality (hwloc) versioning support if          - OS IP interface support installdirs - Installation directory relocation services memchecker  - Run-time memory checking memcpy      - Memopy copy support memory      - Memory management hooks mpool       - Memory pooling patcher     - Symbol patcher hooks pmix        - Process management interface (exascale) pstat       - Process status rcache      - Memory registration cache reachable   - Network reachability computations sec         - Security framework shmem       - Shared memory support (NOT related to OSHMEM) timer       - High-resolution timers  ---------------------------------------------------------------------------  Each framework typically has one or more components that are used at run-time.  For example, the btl framework is used by the MPI layer to send bytes across different types underlying networks.  The tcp btl, for example, sends messages across TCP-based networks; the openib btl sends messages across OpenFabrics-based networks.  Each component typically has some tunable parameters that can be changed at run-time.  Use the ompi_info command to check a component to see what its tunable parameters are.  For example:    shell$ ompi_info --param btl tcp  shows a some of parameters (and default values) for the tcp btl component.  Note that ompi_info only shows a small number a component's MCA parameters by default.  Each MCA parameter has a ""level"" value from 1 to 9, corresponding to the MPI-3 MPI_T tool interface levels.  In Open MPI, we have interpreted these nine levels as three groups of three:   1. End user / basic  2. End user / detailed  3. End user / all   4. Application tuner / basic  5. Application tuner / detailed  6. Application tuner / all   7. MPI/OSHMEM developer / basic  8. MPI/OSHMEM developer / detailed  9. MPI/OSHMEM developer / all  Here's how the three sub-groups are defined:   1. End user: Generally, these are parameters that are required for     correctness, meaning that someone may need to set these just to     get their MPI/OSHMEM application to run correctly.  2. Application tuner: Generally, these are parameters that can be     used to tweak MPI application performance.  3. MPI/OSHMEM developer: Parameters that either don't fit in the     other two, or are specifically intended for debugging /     development of Open MPI itself.  Each sub-group is broken down into three classifications:   1. Basic: For parameters that everyone in this category will want to     see.  2. Detailed: Parameters that are useful, but you probably won't need     to change them often.  3. All: All other parameters -- probably including some fairly     esoteric parameters.  To see *all* available parameters for a given component, specify that ompi_info should use level 9:    shell$ ompi_info --param btl tcp --level 9  These values can be overridden at run-time in several ways.  At run-time, the following locations are examined (in order) for new values of parameters:  1. <prefix>/etc/openmpi-mca-params.conf     This file is intended to set any system-wide default MCA parameter    values -- it will apply, by default, to all users who use this Open    MPI installation.  The default file that is installed contains many    comments explaining its format.  2. $HOME/.openmpi/mca-params.conf     If this file exists, it should be in the same format as    <prefix>/etc/openmpi-mca-params.conf.  It is intended to provide    per-user default parameter values.  3. environment variables of the form OMPI_MCA_<name> set equal to a    <value>     Where <name> is the name of the parameter.  For example, set the    variable named OMPI_MCA_btl_tcp_frag_size to the value 65536    (Bourne-style shells):     shell$ OMPI_MCA_btl_tcp_frag_size=65536    shell$ export OMPI_MCA_btl_tcp_frag_size  4. the mpirun/oshrun command line: --mca <name> <value>     Where <name> is the name of the parameter.  For example:     shell$ mpirun --mca btl_tcp_frag_size 65536 -np 2 hello_world_mpi  These locations are checked in order.  For example, a parameter value passed on the mpirun command line will override an environment variable; an environment variable will override the system-wide defaults.  Each component typically activates itself when relavant.  For example, the MX component will detect that MX devices are present and will automatically be used for MPI communications.  The SLURM component will automatically detect when running inside a SLURM job and activate itself.  And so on.  Components can be manually activated or deactivated if necessary, of course.  The most common components that are manually activated, deactivated, or tuned are the ""BTL"" components -- components that are used for MPI point-to-point communications on many types common networks.  For example, to *only* activate the TCP and ""self"" (process loopback) components are used for MPI communications, specify them in a comma-delimited list to the ""btl"" MCA parameter:     shell$ mpirun --mca btl tcp,self hello_world_mpi  To add shared memory support, add ""sm"" into the command-delimited list (list order does not matter):     shell$ mpirun --mca btl tcp,sm,self hello_world_mpi  To specifically deactivate a specific component, the comma-delimited list can be prepended with a ""^"" to negate it:     shell$ mpirun --mca btl ^tcp hello_mpi_world  The above command will use any other BTL component other than the tcp component.  ===========================================================================  Common Questions ----------------  Many common questions about building and using Open MPI are answered on the FAQ:      http://www.open-mpi.org/faq/  ===========================================================================  Got more questions? -------------------  Found a bug?  Got a question?  Want to make a suggestion?  Want to contribute to Open MPI?  Please let us know!  When submitting questions and problems, be sure to include as much extra information as possible.  This web page details all the information that we request in order to provide assistance:       http://www.open-mpi.org/community/help/  User-level questions and comments should generally be sent to the user's mailing list (users@open-mpi.org).  Because of spam, only subscribers are allowed to post to this list (ensure that you subscribe with and post from *exactly* the same e-mail address -- joe@example.com is considered different than joe@mycomputer.example.com!).  Visit this page to subscribe to the user's list:       http://www.open-mpi.org/mailman/listinfo.cgi/users  Developer-level bug reports, questions, and comments should generally be sent to the developer's mailing list (devel@open-mpi.org).  Please do not post the same question to both lists.  As with the user's list, only subscribers are allowed to post to the developer's list.  Visit the following web page to subscribe:       http://www.open-mpi.org/mailman/listinfo.cgi/devel  Make today an Open MPI day!  Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/open-mpi/ompi"	"A message passing interface implementation.."	"true"
"Parallel Programming"	"pth"	"https://gnu.org/software/pth/"	"A portable implementation for non-preemptive priority-based scheduling for multiple threads of execution. or later."	"null"	"null"	"null"	"pthreads"	"https://en.wikipedia.org/wiki/POSIX_Threads"	"null"	"null"	"null"	"null"	"null"	"GNU Pth - The GNU Portable Threads GNU Pth - The GNU Portable Threads Copyright © 1999-2006 Ralf S. Engelschall <rse@gnu.org> Release Version:   GNU Pth 2.0.7   (08-Jun-2006)    ChangeLog Abstract Pth is a very portable POSIX/ANSI-C based library for Unix platforms which provides non-preemptive priority-based scheduling for multiple threads of execution (aka ``multithreading'') inside event-driven applications. All threads run in the same address space of the server application, but each thread has it's own individual program-counter, run-time stack, signal mask and errno variable. The thread scheduling itself is done in a cooperative way, i.e., the threads are managed by a priority- and event-based non-preemptive scheduler. The intention is that this way one can achieve better portability and run-time performance than with preemptive scheduling. The event facility allows threads to wait until various types of events occur, including pending I/O on filedescriptors, asynchronous signals, elapsed timers, pending I/O on message ports, thread and process termination, and even customized callback functions. Additionally Pth provides an optional emulation API for POSIX.1c threads (""Pthreads"") which can be used for backward compatibility to existing multithreaded applications. Notice: GNU pth and OSSP pth are exactly the same. OSSP pth just became an official part of the GNU project some time ago. That's why its primary name is now GNU pth, although it is still developed by the OSSP project only. The companion OSSP locations are: http://www.ossp.org/pkg/lib/pth/ and ftp://ftp.ossp.org/pkg/lib/pth/. Documentation GNU Pth is documented by a manual which describes the functionality and API of the library in detail. This document is available in HTML, DVI, Postscript and POD format. Additionally there is a draft of the forthcoming paper Portable Multithreading (Postscript) from the author. Finally the Brave GNU World column contains a short introduction to GNU Pth in its Issue No. 7. Distribution The distribution of the latest GNU Pth release version can be found on ftp://ftp.ossp.org/pkg/lib/pth/ and ftp://ftp.gnu.org/gnu/pth/ (or one of the mirrors). Alpha versions can be found on ftp://alpha.gnu.org/gnu/pth/. For more details about the latest changes have a look at the change logfile ChangeLog. Bug Reports and Support If you think you have found a bug in GNU Pth, then you should send a report as complete as possible to <bug-pth@gnu.org>. And if you can, please try to fix the problem and include a patch made with ""diff -u3"" in your report. Additionally there is a mailing list <pth-users@gnu.org> which you can join for support and discussions. Send a mail with ``subscribe pth-users'' in the body to <pth-users-request@gnu.org> Old messages of the mailing list are archived at http://www.mail-archive.com/pth-users@gnu.org/. Further Reading For more details on available multithreading software, we have collected a list of multithreading libraries. Use this to find Pth related projects and packages. Please send FSF & GNU inquiries & questions to gnu@gnu.org. There are also other ways to contact the FSF. Please send comments on these web pages to webmasters@gnu.org, send other questions to gnu@gnu.org. Verbatim copying and distribution of this entire article is permitted in any medium, provided this notice is preserved. Copyright © 1999-2006 Ralf S. Engelschall <rse@gnu.org> Last Modified: 2006-06-08 20:20:09 Return to GNU's home page."	"null"	"null"	"A portable implementation for non-preemptive priority-based scheduling for multiple threads of execution. or later."	"true"
"Parallel Programming"	"TinyCThread"	"https://tinycthread.github.io/"	"A portable, small implementation of the C11 threads API.."	"null"	"null"	"null"	"zlib"	"http://directory.fsf.org/wiki/License:Zlib"	"null"	"null"	"198"	"29"	"35"	"GitHub - tinycthread/tinycthread: Small, portable implementation of the C11 threads API Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 29 Star 198 Fork 35 tinycthread/tinycthread Code Issues 5 Pull requests 2 Pulse Graphs Small, portable implementation of the C11 threads API https://tinycthread.github.io/ 66 commits 3 branches 1 release 10 contributors C 87.4% Shell 6.0% Makefile 4.4% CMake 2.2% C Shell Makefile CMake Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master staging wip/mingw Nothing to show v1.1 Nothing to show New pull request Latest commit 018100a Jun 9, 2016 nemequ cmake: use CMAKE_THREAD_LIBS_INIT instead of Threads::Threads … Threads::Threads didn't exist until cmake 3.1; with this patch we can use at least 2.8.4. Permalink Failed to load latest commit information. doc Bumped to version 1.1 Sep 8, 2012 source Define _XPG6 (for Solaris) Jun 9, 2016 test travis: build on OS X Oct 15, 2015 .gitignore Add small CMakeLists.txt Jun 8, 2016 .travis.sh travis: build on OS X Oct 16, 2015 .travis.yml travis: build on OS X Oct 16, 2015 CMakeLists.txt cmake: use CMAKE_THREAD_LIBS_INIT instead of Threads::Threads Jun 9, 2016 README.txt cmake: focus on in-tree use, but still allow installing a stacic library Jun 8, 2016 mkbuild.sh Bumped to version 1.1 Sep 7, 2012 README.txt TinyCThread v1.2 ================  https://tinycthread.github.io   About -----  TinyCThread is a minimalist, portable, threading library for C, intended to make it easy to create multi threaded C applications.  The library is closesly modeled after the C11 standard, but only a subset is implemented at the moment.  See the documentation in the doc/html directory for more information.   Using TinyCThread -----------------  To use TinyCThread in your own project, just add tinycthread.c and tinycthread.h to your project. In your own code, do:  #include <tinycthread.h>  TinyCThread also includes CMake support, so if your project uses CMake you can just `add_subdirectory(tinycthread)`. Then simply add the tinycthread target (using `target_link_libraries`) where necessary and CMake will take care of everything else, including adding the correct include directory and CTest integration.   Building the test programs --------------------------  From the test folder, issue one of the following commands:  Linux, Mac OS X, OpenSolaris etc:   make   (you may need to use gmake on some systems)  Windows/MinGW:   mingw32-make  Windows/MS Visual Studio:   nmake /f Makefile.msvc   History -------  v1.2 - Unreleased   - Updated API to better match the final specification (e.g. removed mtx_try)   - Improved Windows support, including TSS destructors   - Added once support   - Improved unit testing   - Added CMake support   - Assorted bug fixes  v1.1 - 2012.9.8   - First release.   - Updated API to better match the final specification (e.g. removed xtime).   - Some functionality still missing (mtx_timedlock, TSS destructors under     Windows, ...).  v1.0 - Never released   - Development version based on C11 specification draft.    License -------  Copyright (c) 2012 Marcus Geelnard               2013-2016 Evan Nemerson  This software is provided 'as-is', without any express or implied warranty. In no event will the authors be held liable for any damages arising from the use of this software.  Permission is granted to anyone to use this software for any purpose, including commercial applications, and to alter it and redistribute it freely, subject to the following restrictions:      1. The origin of this software must not be misrepresented; you must not     claim that you wrote the original software. If you use this software     in a product, an acknowledgment in the product documentation would be     appreciated but is not required.      2. Altered source versions must be plainly marked as such, and must not be     misrepresented as being the original software.      3. This notice may not be removed or altered from any source     distribution.  Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/tinycthread/tinycthread"	"A portable, small implementation of the C11 threads API.."	"true"
"Regex"	"PCRE"	"http://www.pcre.org/"	"An implementation of regexes identical to that of Perl 5.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"null"	"null"	"null"	"PCRE - Perl Compatible Regular Expressions PCRE - Perl Compatible Regular Expressions The PCRE library is a set of functions that implement regular expression pattern matching using the same syntax and semantics as Perl 5. PCRE has its own native API, as well as a set of wrapper functions that correspond to the POSIX regular expression API. The PCRE library is free, even for building proprietary software. PCRE was originally written for the Exim MTA, but is now used by many high-profile open source projects, including Apache, PHP, KDE, Postfix, Analog, and Nmap. PCRE has also found its way into some well known commercial products, like Apple Safari. Some other interesting projects using PCRE include Chicken, Ferite, Onyx, Hypermail, Leafnode, Askemos, Wenlin, and 8th. Versions There are two major versions of the PCRE library. The newest version, PCRE2, was released in 2015 and is at version 10.21. The original, very widely deployed PCRE library, originally released in 1997, is at version 8.39, and the API and feature set are stable—future releases will be for bugfixes only. All new future features will be to PCRE2, not the original PCRE 8.x series. Download You can download the current releases of the PCRE and PCRE2 libraries from their official home via anonymous FTP: ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/ You can also download via HTTPS from the mirror at SourceForge: https://sourceforge.net/projects/pcre/files/ You can check out the PCRE2 source code via Subversion (or browse PCRE2 source code on-line): svn co svn://vcs.exim.org/pcre2/code/trunk pcre Or, to check out the older PCRE source code can via Subversion (or browse older PCRE source code on-line): svn co svn://vcs.exim.org/pcre/code/trunk pcre Contributed Ports A precompiled Windows port of PCRE, which may be a few versions behind, is available courtesy the GnuWin32 project. http://gnuwin32.sourceforge.net/packages/pcre.htm If you just need the command-line PCRE or PCRE2 tools on Windows, more up to date precompiled binary versions are available here: http://www.rexegg.com/pcregrep-pcretest.html A PCRE port for z/OS, a mainframe operating system which uses EBCDIC as its default character encoding, can be found here: http://www.cbttape.org/ (File 882) Documentation You can read PCRE2 HTML documentation, or the text version of the PCRE2 man pages. For Perl 5 regular expression syntax, read the Perl regular expressions man page. The distribution itself also contains a README and the BSD LICENCE. If you are upgrading, read the NEWS and ChangeLog files. You can also browse the older PCRE HTML documentation, text version of the older PCRE man pages, and the original README or and the original ChangeLog files. Details on PCRE, and, in particular, comparisons to Perl's regular expression semantics, can also be found in the community authored Wikipedia entry on PCRE. You can find a curated summary of changes with each PCRE release, copies of documentation from older releases, and other useful information from the third party authored RexEgg PCRE Documentation and Change Log page. Contact To report a problem with the PCRE library, or to make a feature request, please file a bug in the PCRE bug repository. You may want to browse currently open PCRE bugs first. Please don't use the SourceForge bug tracking system, as it is not normally monitored. There is a mailing list for active PCRE developers at pcre-dev@exim.org, and you can browse the mailing list archives on-line. The PCRE library was written by Philip Hazel: E-mail local part:  ph10 E-mail domain:  cam.ac.uk Please note that neither this website nor the SourceForge download repositories are maintained by Philip. Please report website or SourceForge PCRE project problems to webmaster@pcre.org. Last modified - webmaster@pcre.org"	"null"	"null"	"An implementation of regexes identical to that of Perl 5.."	"true"
"Regex"	"SLRE"	"https://github.com/cesanta/slre"	"Super Light Regular Expression library; a very small implementation of a subset of Perl regex syntax. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"283"	"39"	"61"	"GitHub - cesanta/slre: Super Light Regexp engine for C/C++ Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 39 Star 283 Fork 61 cesanta/slre Code Issues 9 Pull requests 0 Pulse Graphs Super Light Regexp engine for C/C++ 80 commits 1 branch 3 releases Fetching contributors C 100.0% C Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show 1.3 1.2 1.1 Nothing to show New pull request Latest commit 1ac661a Jun 20, 2016 rojer committed with cesantabot Mass-fix header guards … PUBLISHED_FROM=7e5fc4da88069a6193d911660f522b43ed1a5d40 Permalink Failed to load latest commit information. docs SLRE docs - README references real docs Jun 7, 2016 LICENSE URL fixed Feb 11, 2014 README.md Simplify Contributions section in readmes Jun 10, 2016 slre.c Bit test fix in match_set() Jul 17, 2015 slre.h Mass-fix header guards Jun 20, 2016 unit_test.c Update unit_test.c Mar 10, 2016 README.md SLRE: Super Light Regular Expression library Documentation and API reference are at docs.cesanta.com/slre Contributions To submit contributions, sign Cesanta CLA and send GitHub pull request. You retain the copyright on your contributions. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/cesanta/slre"	"Super Light Regular Expression library; a very small implementation of a subset of Perl regex syntax. only."	"true"
"Regex"	"TRE"	"https://github.com/laurikari/tre/"	"A POSIX-compliant, feature-full regex library.."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"276"	"28"	"48"	"GitHub - laurikari/tre: The approximate regex matching library and agrep command line tool. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 28 Star 276 Fork 48 laurikari/tre Code Issues 32 Pull requests 6 Pulse Graphs The approximate regex matching library and agrep command line tool. 124 commits 1 branch 0 releases 4 contributors C 97.5% Shell 2.0% Python 0.5% C Shell Python Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Latest commit 556ef09 Aug 13, 2015 laurikari Merge pull request #34 from mvkorpel/trivial-typo-patch … Trivial typo fix Permalink Failed to load latest commit information. doc Updates for 0.8.0. Sep 20, 2009 include/tre TRE public headers moved to include/tre to follow Linux header location. May 26, 2013 lib Trivial typo fix Aug 13, 2015 m4 Removed guessing of best optimizing CFLAGS. Jul 22, 2006 po Updates for 0.8.0. Sep 20, 2009 python Fix: Copy tre-config.h from include/tre for Windows compile. Dec 6, 2013 src Added tre_ prefix to all functions. Sep 19, 2009 tests Added tre_ prefix to all functions. Sep 19, 2009 utils Remove dependency to Darcs. Feb 26, 2013 vcbuild TRE public headers moved to include/tre to follow Linux header location. May 26, 2013 win32 Fix: Copy tre-config.h from include/tre for Windows compile. Dec 6, 2013 .gitignore + ignore file for VS output Mar 3, 2013 AUTHORS Import from TRE 0.7.2 CVS tree. Mar 28, 2005 ChangeLog.old ChangeLog is now generated by darcs. Apr 2, 2006 LICENSE Changed the license from LGPL to a BSD-style license. May 22, 2009 Makefile.am Include the new Visual Studio project files in packages. Oct 2, 2009 NEWS Updates for 0.8.0. Sep 20, 2009 README Changed the license from LGPL to a BSD-style license. May 22, 2009 README.darcs Updated for 0.7.6. May 23, 2009 THANKS Updates for 0.8.0. Sep 20, 2009 TODO Import from TRE 0.7.2 CVS tree. Mar 28, 2005 configure.ac Updates for 0.8.0. Sep 20, 2009 tre.pc.in Import from TRE 0.7.2 CVS tree. Mar 28, 2005 tre.spec.in Fixed %doc usage. Jul 22, 2006 README Introduction     TRE is a lightweight, robust, and efficient POSIX compliant regexp    matching library with some exciting features such as approximate    (fuzzy) matching.     The matching algorithm used in TRE uses linear worst-case time in    the length of the text being searched, and quadratic worst-case    time in the length of the used regular expression. In other words,    the time complexity of the algorithm is O(M^2N), where M is the    length of the regular expression and N is the length of the    text. The used space is also quadratic on the length of the regex,    but does not depend on the searched string. This quadratic    behaviour occurs only on pathological cases which are probably very    rare in practice.  Features     TRE is not just yet another regexp matcher. TRE has some features    which are not there in most free POSIX compatible    implementations. Most of these features are not present in non-free    implementations either, for that matter.  Approximate matching     Approximate pattern matching allows matches to be approximate, that    is, allows the matches to be close to the searched pattern under    some measure of closeness. TRE uses the edit-distance measure (also    known as the Levenshtein distance) where characters can be    inserted, deleted, or substituted in the searched text in order to    get an exact match. Each insertion, deletion, or substitution adds    the distance, or cost, of the match. TRE can report the matches    which have a cost lower than some given threshold value. TRE can    also be used to search for matches with the lowest cost.     TRE includes a version of the agrep (approximate grep) command line    tool for approximate regexp matching in the style of grep. Unlike    other agrep implementations (like the one by Sun Wu and Udi Manber    from University of Arizona available here) TRE agrep allows full    regexps of any length, any number of errors, and non-uniform costs    for insertion, deletion and substitution.  Strict standard conformance     POSIX defines the behaviour of regexp functions precisely. TRE    attempts to conform to these specifications as strictly as    possible. TRE always returns the correct matches for subpatterns,    for example. Very few other implementations do this correctly. In    fact, the only other implementations besides TRE that I am aware of    (free or not) that get it right are Rx by Tom Lord, Regex++ by John    Maddock, and the AT&T ast regex by Glenn Fowler and Doug McIlroy.     The standard TRE tries to conform to is the IEEE Std 1003.1-2001,    or Open Group Base Specifications Issue 6, commonly referred to as    ""POSIX"".  It can be found online here. The relevant parts are the    base specifications on regular expressions (and the rationale) and    the description of the regcomp() API.     For an excellent survey on POSIX regexp matchers, see the testregex    pages by Glenn Fowler of AT&T Labs Research.  Predictable matching speed     Because of the matching algorithm used in TRE, the maximum time    consumed by any regexec() call is always directly proportional to    the length of the searched string. There is one exception: if back    references are used, the matching may take time that grows    exponentially with the length of the string. This is because    matching back references is an NP complete problem, and almost    certainly requires exponential time to match in the worst case.  Predictable and modest memory consumption     A regexec() call never allocates memory from the heap. TRE    allocates all the memory it needs during a regcomp() call, and some    temporary working space from the stack frame for the duration of    the regexec() call. The amount of temporary space needed is    constant during matching and does not depend on the searched    string. For regexps of reasonable size TRE needs less than 50K of    dynamically allocated memory during the regcomp() call, less than    20K for the compiled pattern buffer, and less than two kilobytes of    temporary working space from the stack frame during a regexec()    call. There is no time/memory tradeoff. TRE is also small in code    size; statically linking with TRE increases the executable size    less than 30K (gcc-3.2, x86, GNU/Linux).  Wide character and multibyte character set support     TRE supports multibyte character sets. This makes it possible to    use regexps seamlessly with, for example, Japanese locales. TRE    also provides a wide character API.  Binary pattern and data support     TRE provides APIs which allow binary zero characters both in    regexps and searched strings. The standard API cannot be easily    used to, for example, search for printable words from binary data    (although it is possible with some hacking). Searching for patterns    which contain binary zeroes embedded is not possible at all with    the standard API.  Completely thread safe     TRE is completely thread safe. All the exported functions are    re-entrant, and a single compiled regexp object can be used    simultaneously in multiple contexts; e.g. in main() and a signal    handler, or in many threads of a multithreaded application.  Portable     TRE is portable across multiple platforms. Here's a table of    platforms and compilers that have been successfully used to compile    and run TRE:        Platform(s)                       | Compiler(s)       ----------------------------------+------------       AIX 4.3.2 - 5.3.0                 | GCC, C for AIX compiler version 5       Compaq Tru64 UNIX V5.1A/B         | Compaq C V6.4-014 - V6.5-011       Cygwin 1.3 - 1.5                  | GCC       Digital UNIX V4.0                 | DEC C V5.9-005       FreeBSD 4 and above               | GCC       GNU/Linux systems on x86, x86_64, | GCC       ppc64, s390			|       HP-UX 10.20- 11.00                | GCC, HP C Compiler       IRIX 6.5                          | GCC, MIPSpro Compilers 7.3.1.3m       Max OS X				|       NetBSD 1.5 and above              | GCC, egcs       OpenBSD 3.3 and above             | GCC       Solaris 2.7-10 sparc/x86          | GCC, Sun Workshop 6 compilers       Windows 98 - XP                   | Microsoft Visual C++ 6.0     TRE 0.7.5 should compile without changes on all of the above    platforms.  Tell me if you are using TRE on a platform that is not    listed above, and I'll add it to the list. Also let me know if TRE    does not work on a listed platform.     Depending on the platform, you may need to install libutf8 to get    wide character and multibyte character set support.   Free     TRE is released under a license which is essentially the same as    the ""2 clause"" BSD-style license used in NetBSD.  See the file    LICENSE for details.  Roadmap     There are currently two features, both related to collating    elements, missing from 100% POSIX compliance. These are:       * Support for collating elements (e.g. [[.<X>.]], where <X> is a        collating element). It is not possible to support        multi-character collating elements portably, since POSIX does        not define a way to determine whether a character sequence is a        multi-character collating element or not.       * Support for equivalence classes, for example [[=<X>=]], where        <X> is a collating element. An equivalence class matches any        character which has the same primary collation weight as        <X>. Again, POSIX provides no portable mechanism for        determining the primary collation weight of a collating        element.     Note that other portable regexp implementations don't support    collating elements either. The single exception is Regex++, which    comes with its own database for collating elements for different    locales. Support for collating elements and equivalence classes has    not been widely requested and is not very high on the TODO list at    the moment.     These are other features I'm planning to implement real soon now:       * All the missing GNU extensions enabled in GNU regex, such as        [[:<:]] and [[:>:]]       * A REG_SHORTEST regexec() flag for returning the shortest match        instead of the longest match.       * Perl-compatible syntax              [:^class:]                Matches anything but the characters in class. Note that                [^[:class:]] works already, this would be just a                convenience shorthand.              \A                Match only at beginning of string              \Z                Match only at end of string, or before newline at the end              \z                Match only at end of string              \l                Lowercase next char (think vi)              \u                Uppercase next char (think vi)              \L                Lowercase till \E (think vi)              \U                Uppercase till \E (think vi)              (?=pattern)                Zero-width positive look-ahead assertions.              (?!pattern)                Zero-width negative look-ahead assertions.              (?<=pattern)                Zero-width positive look-behind assertions.              (?<!pattern)                Zero-width negative look-behind assertions.     Documentation especially for the nonstandard features of TRE, such    as approximate matching, is a work in progress (with ""progress""    loosely defined...)     Mailing lists     tre-general@lists.laurikari.net       This list is for any discussion on the TRE software, including       reporting bugs, feature requests, requests for help, and other       things.     tre-announce@lists.laurikari.net       Subscribe to this list to get announcements of new releases of       TRE.  Alternatively, you can subscribe to the freshmeat.net       project and get similar announcements that way, if you prefer.  Ville Laurikari    <vl@iki.fi>  Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/laurikari/tre/"	"A POSIX-compliant, feature-full regex library.."	"true"
"Serialization"	"c-capnproto"	"https://github.com/jmckaskill/c-capnproto"	"An implementation of the Cap'n Proto serialization protocol.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"53"	"16"	"24"	"GitHub - jmckaskill/c-capnproto: C library/compiler for the Cap'n Proto serialization/RPC protocol Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 16 Star 53 Fork 24 jmckaskill/c-capnproto Code Issues 5 Pull requests 3 Pulse Graphs C library/compiler for the Cap'n Proto serialization/RPC protocol 49 commits 2 branches 0 releases Fetching contributors C++ 62.8% C 37.2% C++ C Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master win32 Nothing to show Nothing to show New pull request Fetching latest commit… Cannot retrieve the latest commit at this time. Permalink Failed to load latest commit information. compiler .gitignore LICENSE Makefile capn-list.inc capn-malloc.c capn-stream-test.cpp capn-stream.c capn-test.cpp capn.c capn.h gtest-all-test.cpp Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/jmckaskill/c-capnproto"	"An implementation of the Cap'n Proto serialization protocol.."	"true"
"Serialization"	"cmp"	"https://github.com/camgunz/cmp"	"An implementation of the serialization protocol.."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"111"	"22"	"44"	"GitHub - camgunz/cmp: An implementation of the MessagePack serialization format in C / msgpack.org[C] Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 22 Star 111 Fork 44 camgunz/cmp Code Issues 3 Pull requests 0 Pulse Graphs An implementation of the MessagePack serialization format in C / msgpack.org[C] http://msgpack.org 73 commits 1 branch 11 releases 9 contributors C 99.6% Shell 0.4% C Shell Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show v10 v9 v8 v7 v6 v5 v4 v3 v2 v1 1 Nothing to show New pull request Latest commit daec9e0 Jan 7, 2016 camgunz Add email to coc Permalink Failed to load latest commit information. examples Put example2.c under the MIT license explicitly Jun 18, 2015 test Add cmp_read/write_decimal Jun 22, 2015 .gitignore Update gitignore Apr 29, 2014 CODE_OF_CONDUCT.md Add email to coc Jan 7, 2016 LICENSE Fill out the read API, fix a ton of bugs Apr 28, 2014 README.md Add functions providing compat with MessagePack v4 Jun 22, 2015 TODO.md Add a second example for documentation purposes May 3, 2014 VERSION.md Added a better API for reading integers May 4, 2014 cmp.c Add cmp_read/write_decimal Jun 22, 2015 cmp.h Add cmp_read/write_decimal Jun 22, 2015 README.md cmp CMP is a C implementation of the MessagePack serialization format. It currently implements version 5 of the MessagePack Spec. CMP's goal is to be lightweight and straightforward, forcing nothing on the programmer. License While I'm a big believer in the GPL, I license CMP under the MIT license. Example Usage The following examples use a file as the backend, and are modeled after the examples included with the msgpack-c project. #include <stdbool.h> #include <stdint.h> #include <stdio.h> #include <stdlib.h>  #include ""cmp.h""  static bool read_bytes(void *data, size_t sz, FILE *fh) {     return fread(data, sizeof(uint8_t), sz, fh) == (sz * sizeof(uint8_t)); }  static bool file_reader(cmp_ctx_t *ctx, void *data, size_t limit) {     return read_bytes(data, limit, (FILE *)ctx->buf); }  static size_t file_writer(cmp_ctx_t *ctx, const void *data, size_t count) {     return fwrite(data, sizeof(uint8_t), count, (FILE *)ctx->buf); }  void error_and_exit(const char *msg) {     fprintf(stderr, ""%s\n\n"", msg);     exit(EXIT_FAILURE); }  int main(void) {     FILE *fh = NULL;     cmp_ctx_t cmp;     uint32_t array_size = 0;     uint32_t str_size = 0;     char hello[6] = {0, 0, 0, 0, 0, 0};     char message_pack[12] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};      fh = fopen(""cmp_data.dat"", ""w+b"");      if (fh == NULL)         error_and_exit(""Error opening data.dat"");      cmp_init(&cmp, fh, file_reader, file_writer);      if (!cmp_write_array(&cmp, 2))         error_and_exit(cmp_strerror(&cmp));      if (!cmp_write_str(&cmp, ""Hello"", 5))         error_and_exit(cmp_strerror(&cmp));      if (!cmp_write_str(&cmp, ""MessagePack"", 11))         error_and_exit(cmp_strerror(&cmp));      rewind(fh);      if (!cmp_read_array(&cmp, &array_size))         error_and_exit(cmp_strerror(&cmp));      /* You can read the str byte size and then read str bytes... */      if (!cmp_read_str_size(&cmp, &str_size))         error_and_exit(cmp_strerror(&cmp));      if (str_size > (sizeof(hello) - 1))         error_and_exit(""Packed 'hello' length too long\n"");      if (!read_bytes(hello, str_size, fh))         error_and_exit(cmp_strerror(&cmp));      /*      * ...or you can set the maximum number of bytes to read and do it all in      * one call      */      str_size = sizeof(message_pack);     if (!cmp_read_str(&cmp, message_pack, &str_size))         error_and_exit(cmp_strerror(&cmp));      printf(""Array Length: %zu.\n"", array_size);     printf(""[\""%s\"", \""%s\""]\n"", hello, message_pack);      fclose(fh);      return EXIT_SUCCESS; } Advanced Usage See the examples folder. Fast, Lightweight, Flexible, and Robust CMP uses no internal buffers; conversions, encoding and decoding are done on the fly. CMP's source and header file together are ~3,300 LOC. CMP makes no heap allocations. CMP uses standardized types rather than declaring its own, and it depends only on stdbool.h, stdint.h and string.h. It has no link-time dependencies, not even the C Standard Library. CMP is written using C89 (ANSI C), aside, of course, from its use of fixed-width integer types and bool. On the other hand, CMP's test suite depends upon the C Standard Library and requires C99. CMP only requires the programmer supply a read function and a write function. In this way, the programmer can use CMP on memory, files, sockets, etc. CMP is portable. It uses fixed-width integer types, and checks the endianness of the machine at runtime before swapping bytes (MessagePack is big-endian). CMP provides a fairly comprehensive error reporting mechanism modeled after errno and strerror. CMP is threadsafe; while contexts cannot be shared between threads, each thread may use its own context freely. CMP is tested using the MessagePack test suite as well as a large set of custom test cases. Its small test program is compiled with clang using -Wall -Werror -Wextra ... along with several other flags, and generates no compilation errors. CMP's source is written as readably as possible, using explicit, descriptive variable names and a consistent, clear style. CMP's source is written to be as secure as possible. Its testing suite checks for invalid values, and data is always treated as suspect before it passes validation. CMP's API is designed to be clear, convenient and unsurprising. Strings are null-terminated, binary data is not, error codes are clear, and so on. CMP provides optional backwards compatibility for use with other MessagePack implementations that only implement version 4 of the spec. Building There is no build system for CMP. The programmer can drop cmp.c and cmp.h in their source tree and modify as necessary. No special compiler settings are required to build it, and it generates no compilation errors in either clang or gcc. Backwards Compatibility Version 4 of the MessagePack spec has no BIN type, and provides no STR8 marker. In order to remain backwards compatible with version 4 of MessagePack, do the following: Avoid these functions: cmp_write_bin cmp_write_bin_marker cmp_write_str8_marker cmp_write_str8 cmp_write_bin8_marker cmp_write_bin8 cmp_write_bin16_marker cmp_write_bin16 cmp_write_bin32_marker cmp_write_bin32 Use these functions in lieu of their v5 counterparts: cmp_write_str_marker_v4 instead of cmp_write_str_marker cmp_write_str_v4 instead of cmp_write_str cmp_write_object_v4 instead of cmp_write_object Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/camgunz/cmp"	"An implementation of the serialization protocol.."	"true"
"Serialization"	"MessagePack"	"http://msgpack.org/"	"Another implementation of the serialization protocol.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"null"	"null"	"null"	"MessagePack · GitHub Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This organization MessagePack http://msgpack.org/ Repositories People 28 Filters Sources Forks HTML 29 14 website http://msgpack.org/ Updated Jul 14, 2016 Go 73 13 msgpack-go Updated Jul 13, 2016 C++ 770 325 msgpack-c MessagePack implementation for C and C++ / msgpack.org[C/C++] Updated Jul 12, 2016 C# 356 82 msgpack-cli MessagePack implementation for Common Language Infrastructure / msgpack.org[C#] Updated Jul 10, 2016 Java 612 174 msgpack-java MessagePack serializer implementation for Java / msgpack.org[Java] Updated Jul 9, 2016 C 423 72 msgpack-ruby MessagePack implementation for Ruby / msgpack.org[Ruby] Updated Jul 8, 2016 PHP 392 86 msgpack-php msgpack.org[PHP] Updated Jul 4, 2016 Haskell 81 57 msgpack-haskell Haskell implementation of MessagePack / msgpack.org[Haskell] Updated Jun 29, 2016 D 85 24 msgpack-d MessagePack for D / msgpack.org[D] Updated Jun 17, 2016 Perl 38 7 msgpack-perl MessagePack serializer implementation for Perl / msgpack.org[Perl] Updated Jun 15, 2016 Python 610 100 msgpack-python MessagePack serializer implementation for Python msgpack.org[Python] Updated Jun 13, 2016 Smalltalk 11 0 msgpack-smalltalk MessagePack serialization library for various Smalltalk dialects / msgpack.org[Smalltalk] Updated Jun 4, 2016 OCaml 22 9 msgpack-ocaml MwssagePack implementation for OCaml / msgpack.org[OCaml] Updated May 23, 2016 JavaScript 168 43 msgpack-node MessagePack implementation for Node.js Updated May 20, 2016 Erlang 154 54 msgpack-erlang MessagePack (de)serializer implementation for Erlang / msgpack.org[Erlang] Updated May 19, 2016 C 271 44 msgpack-objectivec MessagePack serializer implementation for Objective-C / msgpack.org[Objective-C] Updated Feb 24, 2016 2,997 276 msgpack MessagePack is an extremely efficient object serialization library. It's like JSON, but very fast and small. Updated Dec 22, 2015 Scala 68 21 msgpack-scala MessagePack serializer implementation for Scala / msgpack.org[Scala] Updated Aug 28, 2015 JavaScript 393 58 msgpack-javascript MessagePack serializer implementation for JavaScript / msgpack.org[JavaScript] Updated Aug 23, 2015 Scala 6 1 pickling-msgpack Msgpack support for Scala pickling object serialization framework. Updated Feb 18, 2014 Previous 1 2 Next 28 People Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/msgpack/"	"Another implementation of the serialization protocol.."	"true"
"Serialization"	"libavro"	"http://avro.apache.org/docs/current/api/c/index.html#_introduction_to_avro_c"	"A C implementation of the Avro data serialization system.."	"null"	"null"	"null"	"Apache2.0"	"http://directory.fsf.org/wiki/License:Apache2.0"	"null"	"null"	"null"	"null"	"null"	"Avro C Avro C Table of Contents JavaScript must be enabled in your browser to display the table of contents. The current version of Avro is 1.8.1. The current version of libavro is 23:0:0. This document was created 2016-05-15. 1. Introduction to Avro Avro is a data serialization system. Avro provides: Rich data structures. A compact, fast, binary data format. A container file, to store persistent data. Remote procedure call (RPC). This document will focus on the C implementation of Avro. To learn more about Avro in general, visit the Avro website. 2. Introduction to Avro C     ___                      ______    /   |_   ___________     / ____/   / /| | | / / ___/ __ \   / /  / ___ | |/ / /  / /_/ /  / /___ /_/  |_|___/_/   \____/   \____/ A C program is like a fast dance on a newly waxed dance floor by people carrying razors. (walra%moacs11 @ nl.net) 94/03/18 — Waldi Ravens The C implementation has been tested on MacOSX and Linux but, over time, the number of support OSes should grow. Please let us know if you’re using Avro C on other systems. Avro depends on the Jansson JSON parser, version 2.3 or higher. On many operating systems this library is available through your package manager (for example, apt-get install libjansson-dev on Ubuntu/Debian, and brew install jansson on Mac OS). If not, please download and install it from source. The C implementation supports: binary encoding/decoding of all primitive and complex data types storage to an Avro Object Container File schema resolution, promotion and projection validating and non-validating mode for writing Avro data The C implementation is lacking: RPC To learn about the API, take a look at the examples and reference files later in this document. We’re always looking for contributions so, if you’re a C hacker, please feel free to submit patches to the project. 3. Error reporting Most functions in the Avro C library return a single int status code. Following the POSIX errno.h convention, a status code of 0 indicates success. Non-zero codes indiciate an error condition. Some functions return a pointer value instead of an int status code; for these functions, a NULL pointer indicates an error. You can retrieve a string description of the most recent error using the avro_strerror function: avro_schema_t  schema = avro_schema_string(); if (schema == NULL) {     fprintf(stderr, ""Error was %s\n"", avro_strerror()); } 4. Avro values Starting with version 1.6.0, the Avro C library has a new API for handling Avro data. To help distinguish between the two APIs, we refer to the old one as the legacy or datum API, and the new one as the value API. (These names come from the names of the C types used to represent Avro data in the corresponding API — avro_datum_t and avro_value_t.) The legacy API is still present, but it’s deprecated — you shouldn’t use the avro_datum_t type or the avro_datum_* functions in new code. One main benefit of the new value API is that you can treat any existing C type as an Avro value; you just have to provide a custom implementation of the value interface. In addition, we provide a generic value implementation; “generic”, in this sense, meaning that this single implementation works for instances of any Avro schema type. Finally, we also provide a wrapper implementation for the deprecated avro_datum_t type, which lets you gradually transition to the new value API. 4.1. Avro value interface You interact with Avro values using the value interface, which defines methods for setting and retrieving the contents of an Avro value. An individual value is represented by an instance of the avro_value_t type. This section provides an overview of the methods that you can call on an avro_value_t instance. There are quite a few methods in the value interface, but not all of them make sense for all Avro schema types. For instance, you won’t be able to call avro_value_set_boolean on an Avro array value. If you try to call an inappropriate method, we’ll return an EINVAL error code. Note that the functions in this section apply to all Avro values, regardless of which value implementation is used under the covers. This section doesn’t describe how to create value instances, since those constructors will be specific to a particular value implementation. 4.1.1. Common methods There are a handful of methods that can be used with any value, regardless of which Avro schema it’s an instance of: #include <stdint.h> #include <avro.h>  avro_type_t avro_value_get_type(const avro_value_t *value); avro_schema_t avro_value_get_schema(const avro_value_t *value);  int avro_value_equal(const avro_value_t *v1, const avro_value_t *v2); int avro_value_equal_fast(const avro_value_t *v1, const avro_value_t *v2);  int avro_value_copy(avro_value_t *dest, const avro_value_t *src); int avro_value_copy_fast(avro_value_t *dest, const avro_value_t *src);  uint32_t avro_value_hash(avro_value_t *value);  int avro_value_reset(avro_value_t *value); The get_type and get_schema methods can be used to get information about what kind of Avro value a given avro_value_t instance represents. (For get_schema, you borrow the value’s reference to the schema; if you need to save it and ensure that it outlives the value, you need to call avro_schema_incref on it.) The equal and equal_fast methods compare two values for equality. The two values do not have to have the same value implementations, but they do have to be instances of the same schema. (Not equivalent schemas; the same schema.) The equal method checks that the schemas match; the equal_fast method assumes that they do. The copy and copy_fast methods copy the contents of one Avro value into another. (Where possible, this is done without copying the actual content of a bytes, string, or fixed value, using the avro_wrapped_buffer_t functions described in the next section.) Like equal, the two values must have the same schema; copy checks this, while copy_fast assumes it. The hash method returns a hash value for the given Avro value. This can be used to construct hash tables that use Avro values as keys. The function works correctly even with maps; it produces a hash that doesn’t depend on the ordering of the elements of the map. Hash values are only meaningful for comparing values of exactly the same schema. Hash values are not guaranteed to be consistent across different platforms, or different versions of the Avro library. That means that it’s really only safe to use these hash values internally within the context of a single execution of a single application. The reset method “clears out” an +avro_value_t instance, making sure that it’s ready to accept the contents of a new value. For scalars, this is usually a no-op, since the new value will just overwrite the old one. For arrays and maps, this removes any existing elements from the container, so that we can append the elements of the new value. For records and unions, this just recursively resets the fields or current branch. 4.1.2. Scalar values The simplest case is handling instances of the scalar Avro schema types. In Avro, the scalars are all of the primitive schema types, as well as enum and fixed — i.e., anything that can’t contain another Avro value. Note that we use standard C99 types to represent the primitive contents of an Avro scalar. To retrieve the contents of an Avro scalar, you can use one of the getter methods: #include <stdint.h> #include <stdlib.h> #include <avro.h>  int avro_value_get_boolean(const avro_value_t *value, int *dest); int avro_value_get_bytes(const avro_value_t *value,                          const void **dest, size_t *size); int avro_value_get_double(const avro_value_t *value, double *dest); int avro_value_get_float(const avro_value_t *value, float *dest); int avro_value_get_int(const avro_value_t *value, int32_t *dest); int avro_value_get_long(const avro_value_t *value, int64_t *dest); int avro_value_get_null(const avro_value_t *value); int avro_value_get_string(const avro_value_t *value,                           const char **dest, size_t *size); int avro_value_get_enum(const avro_value_t *value, int *dest); int avro_value_get_fixed(const avro_value_t *value,                          const void **dest, size_t *size); For the most part, these should be self-explanatory. For bytes, string, and fixed values, the pointer to the underlying content is const — you aren’t allowed to modify the contents directly. We guarantee that the content of a string will be NUL-terminated, so you can use it as a C string as you’d expect. The size returned for a string object will include the NUL terminator; it will be one more than you’d get from calling strlen on the content. Also, for bytes, string, and fixed, the dest and size parameters are optional; if you only want to determine the length of a bytes value, you can use: avro_value_t  *value = /* from somewhere */; size_t  size; avro_value_get_bytes(value, NULL, &size); To set the contents of an Avro scalar, you can use one of the setter methods: #include <stdint.h> #include <stdlib.h> #include <avro.h>  int avro_value_set_boolean(avro_value_t *value, int src); int avro_value_set_bytes(avro_value_t *value,                          void *buf, size_t size); int avro_value_set_double(avro_value_t *value, double src); int avro_value_set_float(avro_value_t *value, float src); int avro_value_set_int(avro_value_t *value, int32_t src); int avro_value_set_long(avro_value_t *value, int64_t src); int avro_value_set_null(avro_value_t *value); int avro_value_set_string(avro_value_t *value, const char *src); int avro_value_set_string_len(avro_value_t *value,                               const char *src, size_t size); int avro_value_set_enum(avro_value_t *value, int src); int avro_value_set_fixed(avro_value_t *value,                          void *buf, size_t size); These are also straightforward. For bytes, string, and fixed values, the set methods will make a copy of the underlying data. For string values, the content must be NUL-terminated. You can use set_string_len if you already know the length of the string content; the length you pass in should include the NUL terminator. If you call set_string, then we’ll use strlen to calculate the length. For fixed values, the size must match what’s expected by the value’s underlying fixed schema; if the sizes don’t match, you’ll get an error code. If you don’t want to copy the contents of a bytes, string, or fixed value, you can use the giver and grabber functions: #include <stdint.h> #include <stdlib.h> #include <avro.h>  typedef void (*avro_buf_free_t)(void *ptr, size_t sz, void *user_data);  int avro_value_give_bytes(avro_value_t *value, avro_wrapped_buffer_t *src); int avro_value_give_string_len(avro_value_t *value, avro_wrapped_buffer_t *src); int avro_value_give_fixed(avro_value_t *value, avro_wrapped_buffer_t *src);  int avro_value_grab_bytes(const avro_value_t *value, avro_wrapped_buffer_t *dest); int avro_value_grab_string(const avro_value_t *value, avro_wrapped_buffer_t *dest); int avro_value_grab_fixed(const avro_value_t *value, avro_wrapped_buffer_t *dest);  typedef struct avro_wrapped_buffer {     const void  *buf;     size_t  size;     void (*free)(avro_wrapped_buffer_t *self);     int (*copy)(avro_wrapped_buffer_t *dest,                 const avro_wrapped_buffer_t *src,                 size_t offset, size_t length);     int (*slice)(avro_wrapped_buffer_t *self,                  size_t offset, size_t length); } avro_wrapped_buffer_t;  void avro_wrapped_buffer_free(avro_wrapped_buffer_t *buf);  int avro_wrapped_buffer_copy(avro_wrapped_buffer_t *dest,                          const avro_wrapped_buffer_t *src,                          size_t offset, size_t length);  int avro_wrapped_buffer_slice(avro_wrapped_buffer_t *self,                           size_t offset, size_t length); The give functions give control of an existing buffer to the value. (You should not try to free the src wrapped buffer after calling this method.) The grab function fills in a wrapped buffer with a pointer to the contents of an Avro value. (You should free the dest wrapped buffer when you’re done with it.) The avro_wrapped_buffer_t struct encapsulates the location and size of the existing buffer. It also includes several methods. The free method will be called when the content of the buffer is no longer needed. The slice method will be called when the wrapped buffer needs to be updated to point at a subset of what it pointed at before. (This doesn’t create a new wrapped buffer; it updates an existing one.) The copy method will be called if the content needs to be copied. Note that if you’re wrapping a buffer with nice reference counting features, you don’t need to perform an actual copy; you just need to ensure that the free function can be called on both the original and the copy, and not have things blow up. The “generic” value implementation takes advantage of this feature; if you pass in a wrapped buffer with a give method, and then retrieve it later with a grab method, then we’ll use the wrapped buffer’s copy method to fill in the dest parameter. If your wrapped buffer implements a slice method that updates reference counts instead of actually copying, then you’ve got nice zero-copy access to the contents of an Avro value. 4.1.3. Compound values The following sections describe the getter and setter methods for handling compound Avro values. All of the compound values are responsible for the storage of their children; this means that there isn’t a method, for instance, that lets you add an existing avro_value_t to an array. Instead, there’s a method that creates a new, empty avro_value_t of the appropriate type, adds it to the array, and returns it for you to fill in as needed. You also shouldn’t try to free the child elements that are created this way; the container value is responsible for their life cycle. The child element is guaranteed to be valid for as long as the container value is. You’ll usually define an avro_value_t in the stack, and let it fall out of scope when you’re done with it: avro_value_t  *array = /* from somewhere else */;  {     avro_value_t  child;     avro_value_get_by_index(array, 0, &child, NULL);     /* do something interesting with the array element */ } 4.1.4. Arrays There are three methods that can be used with array values: #include <stdlib.h> #include <avro.h>  int avro_value_get_size(const avro_value_t *array, size_t *size); int avro_value_get_by_index(const avro_value_t *array, size_t index,                             avro_value_t *element, const char **unused); int avro_value_append(avro_value_t *array, avro_value_t *element,                       size_t *new_index); The get_size method returns the number of elements currently in the array. The get_by_index method fills in element to point at the array element with the given index. (You should use NULL for the unused parameter; it’s ignored for array values.) The append method creates a new value, appends it to the array, and returns it in element. If new_index is given, then it will be filled in with the index of the new element. 4.1.5. Maps There are four methods that can be used with map values: #include <stdlib.h> #include <avro.h>  int avro_value_get_size(const avro_value_t *map, size_t *size); int avro_value_get_by_name(const avro_value_t *map, const char *key,                            avro_value_t *element, size_t *index); int avro_value_get_by_index(const avro_value_t *map, size_t index,                             avro_value_t *element, const char **key); int avro_value_add(avro_value_t *map,                    const char *key, avro_value_t *element,                    size_t *index, int *is_new); The get_size method returns the number of elements currently in the map. Map elements can be retrieved either by their key (get_by_name) or by their numeric index (get_by_index). (Numeric indices in a map are based on the order that the elements were added to the map.) In either case, the method takes in an optional output parameter that let you retrieve the index associated with a key, and vice versa. The add method will add a new value to the map, if the given key isn’t already present. If the key is present, then the existing value with be returned. The index parameter, if given, will be filled in the element’s index. The is_new parameter, if given, can be used to determine whether the mapped value is new or not. 4.1.6. Records There are three methods that can be used with record values: #include <stdlib.h> #include <avro.h>  int avro_value_get_size(const avro_value_t *record, size_t *size); int avro_value_get_by_index(const avro_value_t *record, size_t index,                             avro_value_t *element, const char **field_name); int avro_value_get_by_name(const avro_value_t *record, const char *field_name,                            avro_value_t *element, size_t *index); The get_size method returns the number of fields in the record. (You can also get this by querying the value’s schema, but for some implementations, this method can be faster.) The get_by_index and get_by_name functions can be used to retrieve one of the fields in the record, either by its ordinal position within the record, or by the name of the underlying field. Like with maps, the methods take in an additional parameter that let you retrieve the index associated with a field name, and vice versa. When possible, it’s recommended that you access record fields by their numeric index, rather than by their field name. For most implementations, this will be more efficient. 4.1.7. Unions There are three methods that can be used with union values: #include <avro.h>  int avro_value_get_discriminant(const avro_value_t *union_val, int *disc); int avro_value_get_current_branch(const avro_value_t *union_val, avro_value_t *branch); int avro_value_set_branch(avro_value_t *union_val,                           int discriminant, avro_value_t *branch); The get_discriminant and get_current_branch methods return the current state of the union value, without modifying which branch is currently selected. The set_branch method can be used to choose the active branch, filling in the branch value to point at the branch’s value instance. (Most implementations will be smart enough to detect when the desired branch is already selected, so you should always call this method unless you can guarantee that the right branch is already current.) 4.2. Creating value instances Okay, so we’ve described how to interact with a value that you already have a pointer to, but how do you create one in the first place? Each implementation of the value interface must provide its own functions for creating avro_value_t instances for that class. The 10,000-foot view is to: Get an implementation struct for the value implementation that you want to use. (This is represented by an avro_value_iface_t pointer.) Use the implementation’s constructor function to allocate instances of that value implementation. Do whatever you need to the value (using the avro_value_t methods described in the previous section). Free the value instance, if necessary, using the implementation’s destructor function. Free the implementation struct when you’re done creating value instances. These steps use the following functions: #include <avro.h>  avro_value_iface_t *avro_value_iface_incref(avro_value_iface_t *iface); void avro_value_iface_decref(avro_value_iface_t *iface); Note that for most value implementations, it’s fine to reuse a single avro_value_t instance for multiple values, using the avro_value_reset function before filling in the instance for each value. (This helps reduce the number of malloc and free calls that your application will make.) We provide a “generic” value implementation that will work (efficiently) for any Avro schema. For most applications, you won’t need to write your own value implementation; the Avro C library provides an efficient “generic” implementation, which supports the full range of Avro schema types. There’s a good chance that you just want to use this implementation, rather than rolling your own. (The primary reason for rolling your own would be if you want to access the elements of a compound value using C syntax — for instance, translating an Avro record into a C struct.) You can use the following functions to create and work with a generic value implementation for a particular schema: #include <avro.h>  avro_value_iface_t *avro_generic_class_from_schema(avro_schema_t schema); int avro_generic_value_new(const avro_value_iface_t *iface, avro_value_t *dest); void avro_generic_value_free(avro_value_t *self); Combining all of this together, you might have the following snippet of code: avro_schema_t  schema = avro_schema_long(); avro_value_iface_t  *iface = avro_generic_class_from_schema(schema);  avro_value_t  val; avro_generic_value_new(iface, &val);  /* Generate Avro longs from 0-499 */ int  i; for (i = 0; i < 500; i++) {     avro_value_reset(&val);     avro_value_set_long(&val, i);     /* do something with the value */ }  avro_generic_value_free(&val); avro_value_iface_decref(iface); avro_schema_decref(schema); 5. Reference Counting Avro C does reference counting for all schema and data objects. When the number of references drops to zero, the memory is freed. For example, to create and free a string, you would use: avro_datum_t string = avro_string(""This is my string"");  ... avro_datum_decref(string); Things get a little more complicated when you consider more elaborate schema and data structures. For example, let’s say that you create a record with a single string field: avro_datum_t example = avro_record(""Example""); avro_datum_t solo_field = avro_string(""Example field value"");  avro_record_set(example, ""solo"", solo_field);  ... avro_datum_decref(example); In this example, the solo_field datum would not be freed since it has two references: the original reference and a reference inside the Example record. The avro_datum_decref(example) call drops the number of reference to one. If you are finished with the solo_field schema, then you need to avro_schema_decref(solo_field) to completely dereference the solo_field datum and free it. 6. Wrap It and Give It You’ll notice that some datatypes can be ""wrapped"" and ""given"". This allows C programmers the freedom to decide who is responsible for the memory. Let’s take strings for example. To create a string datum, you have three different methods: avro_datum_t avro_string(const char *str); avro_datum_t avro_wrapstring(const char *str); avro_datum_t avro_givestring(const char *str); If you use, avro_string then Avro C will make a copy of your string and free it when the datum is dereferenced. In some cases, especially when dealing with large amounts of data, you want to avoid this memory copy. That’s where avro_wrapstring and avro_givestring can help. If you use, avro_wrapstring then Avro C will do no memory management at all. It will just save a pointer to your data and it’s your responsibility to free the string. Warning When using avro_wrapstring, do not free the string before you dereference the string datum with avro_datum_decref(). Lastly, if you use avro_givestring then Avro C will free the string later when the datum is dereferenced. In a sense, you are ""giving"" responsibility for freeing the string to Avro C. Warning Don’t ""give"" Avro C a string that you haven’t allocated from the heap with e.g. malloc or strdup. For example, don’t do this: avro_datum_t bad_idea = avro_givestring(""This isn't allocated on the heap""); 7. Schema Validation If you want to write a datum, you would use the following function int avro_write_data(avro_writer_t writer,                     avro_schema_t writers_schema, avro_datum_t datum); If you pass in a writers_schema, then you datum will be validated before it is sent to the writer. This check ensures that your data has the correct format. If you are certain your datum is correct, you can pass a NULL value for writers_schema and Avro C will not validate before writing. Note Data written to an Avro File Object Container is always validated. 8. Examples I’m not even supposed to be here today! — Dante Hicks Imagine you’re a free-lance hacker in Leonardo, New Jersey and you’ve been approached by the owner of the local Quick Stop Convenience store. He wants you to create a contact database case he needs to call employees to work on their day off. You might build a simple contact system using Avro C like the following… /*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements. See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to you under the Apache License, Version 2.0  * (the ""License""); you may not use this file except in compliance with  * the License. You may obtain a copy of the License at  *  * http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an ""AS IS"" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  * implied. See the License for the specific language governing  * permissions and limitations under the License.  */  #include <avro.h> #include <stdio.h> #include <stdlib.h>  #ifdef DEFLATE_CODEC #define QUICKSTOP_CODEC  ""deflate"" #else #define QUICKSTOP_CODEC  ""null"" #endif  avro_schema_t person_schema; int64_t id = 0;  /* A simple schema for our tutorial */ const char  PERSON_SCHEMA[] = ""{\""type\"":\""record\"",\  \""name\"":\""Person\"",\  \""fields\"":[\  {\""name\"": \""ID\"", \""type\"": \""long\""},\  {\""name\"": \""First\"", \""type\"": \""string\""},\  {\""name\"": \""Last\"", \""type\"": \""string\""},\  {\""name\"": \""Phone\"", \""type\"": \""string\""},\  {\""name\"": \""Age\"", \""type\"": \""int\""}]}"";  /* Parse schema into a schema data structure */ void init_schema(void) {         if (avro_schema_from_json_literal(PERSON_SCHEMA, &person_schema)) {                 fprintf(stderr, ""Unable to parse person schema\n"");                 exit(EXIT_FAILURE);         } }  /* Create a datum to match the person schema and save it */ void add_person(avro_file_writer_t db, const char *first, const char *last,            const char *phone, int32_t age) {         avro_datum_t person = avro_record(person_schema);          avro_datum_t id_datum = avro_int64(++id);         avro_datum_t first_datum = avro_string(first);         avro_datum_t last_datum = avro_string(last);         avro_datum_t age_datum = avro_int32(age);         avro_datum_t phone_datum = avro_string(phone);          if (avro_record_set(person, ""ID"", id_datum)             || avro_record_set(person, ""First"", first_datum)             || avro_record_set(person, ""Last"", last_datum)             || avro_record_set(person, ""Age"", age_datum)             || avro_record_set(person, ""Phone"", phone_datum)) {                 fprintf(stderr, ""Unable to create Person datum structure\n"");                 exit(EXIT_FAILURE);         }          if (avro_file_writer_append(db, person)) {                 fprintf(stderr,                         ""Unable to write Person datum to memory buffer\nMessage: %s\n"", avro_strerror());                 exit(EXIT_FAILURE);         }          /* Decrement all our references to prevent memory from leaking */         avro_datum_decref(id_datum);         avro_datum_decref(first_datum);         avro_datum_decref(last_datum);         avro_datum_decref(age_datum);         avro_datum_decref(phone_datum);         avro_datum_decref(person);          //fprintf(stdout, ""Successfully added %s, %s id=%""PRId64""\n"", last, first, id); }  int print_person(avro_file_reader_t db, avro_schema_t reader_schema) {         int rval;         avro_datum_t person;          rval = avro_file_reader_read(db, reader_schema, &person);         if (rval == 0) {                 int64_t i64;                 int32_t i32;                 char *p;                 avro_datum_t id_datum, first_datum, last_datum, phone_datum,                     age_datum;                  if (avro_record_get(person, ""ID"", &id_datum) == 0) {                         avro_int64_get(id_datum, &i64);                         fprintf(stdout, ""%""PRId64"" | "", i64);                 }                 if (avro_record_get(person, ""First"", &first_datum) == 0) {                         avro_string_get(first_datum, &p);                         fprintf(stdout, ""%15s | "", p);                 }                 if (avro_record_get(person, ""Last"", &last_datum) == 0) {                         avro_string_get(last_datum, &p);                         fprintf(stdout, ""%15s | "", p);                 }                 if (avro_record_get(person, ""Phone"", &phone_datum) == 0) {                         avro_string_get(phone_datum, &p);                         fprintf(stdout, ""%15s | "", p);                 }                 if (avro_record_get(person, ""Age"", &age_datum) == 0) {                         avro_int32_get(age_datum, &i32);                         fprintf(stdout, ""%d"", i32);                 }                 fprintf(stdout, ""\n"");                  /* We no longer need this memory */                 avro_datum_decref(person);         }         return rval; }  int main(void) {         int rval;         avro_file_reader_t dbreader;         avro_file_writer_t db;         avro_schema_t projection_schema, first_name_schema, phone_schema;         int64_t i;         const char *dbname = ""quickstop.db"";         char number[15] = {0};          /* Initialize the schema structure from JSON */         init_schema();          /* Delete the database if it exists */         remove(dbname);         /* Create a new database */         rval = avro_file_writer_create_with_codec             (dbname, person_schema, &db, QUICKSTOP_CODEC, 0);         if (rval) {                 fprintf(stderr, ""There was an error creating %s\n"", dbname);                 fprintf(stderr, "" error message: %s\n"", avro_strerror());                 exit(EXIT_FAILURE);         }          /* Add lots of people to the database */         for (i = 0; i < 1000; i++)         {                 sprintf(number, ""(%d)"", (int)i);                 add_person(db, ""Dante"", ""Hicks"", number, 32);                 add_person(db, ""Randal"", ""Graves"", ""(555) 123-5678"", 30);                 add_person(db, ""Veronica"", ""Loughran"", ""(555) 123-0987"", 28);                 add_person(db, ""Caitlin"", ""Bree"", ""(555) 123-2323"", 27);                 add_person(db, ""Bob"", ""Silent"", ""(555) 123-6422"", 29);                 add_person(db, ""Jay"", ""???"", number, 26);         }          /* Close the block and open a new one */         avro_file_writer_flush(db);         add_person(db, ""Super"", ""Man"", ""123456"", 31);          avro_file_writer_close(db);          fprintf(stdout, ""\nNow let's read all the records back out\n"");          /* Read all the records and print them */         if (avro_file_reader(dbname, &dbreader)) {                 fprintf(stderr, ""Error opening file: %s\n"", avro_strerror());                 exit(EXIT_FAILURE);         }         for (i = 0; i < id; i++) {                 if (print_person(dbreader, NULL)) {                         fprintf(stderr, ""Error printing person\nMessage: %s\n"", avro_strerror());                         exit(EXIT_FAILURE);                 }         }         avro_file_reader_close(dbreader);          /* You can also use projection, to only decode only the data you are  interested in. This is particularly useful when you have  huge data sets and you'll only interest in particular fields  e.g. your contacts First name and phone number */         projection_schema = avro_schema_record(""Person"", NULL);         first_name_schema = avro_schema_string();         phone_schema = avro_schema_string();         avro_schema_record_field_append(projection_schema, ""First"",                                         first_name_schema);         avro_schema_record_field_append(projection_schema, ""Phone"",                                         phone_schema);          /* Read only the record you're interested in */         fprintf(stdout,                 ""\n\nUse projection to print only the First name and phone numbers\n"");         if (avro_file_reader(dbname, &dbreader)) {                 fprintf(stderr, ""Error opening file: %s\n"", avro_strerror());                 exit(EXIT_FAILURE);         }         for (i = 0; i < id; i++) {                 if (print_person(dbreader, projection_schema)) {                         fprintf(stderr, ""Error printing person: %s\n"",                                 avro_strerror());                         exit(EXIT_FAILURE);                 }         }         avro_file_reader_close(dbreader);         avro_schema_decref(first_name_schema);         avro_schema_decref(phone_schema);         avro_schema_decref(projection_schema);          /* We don't need this schema anymore */         avro_schema_decref(person_schema);         return 0; } When you compile and run this program, you should get the following output Successfully added Hicks, Dante id=1 Successfully added Graves, Randal id=2 Successfully added Loughran, Veronica id=3 Successfully added Bree, Caitlin id=4 Successfully added Silent, Bob id=5 Successfully added ???, Jay id=6  Avro is compact. Here is the data for all 6 people. | 02 0A 44 61 6E 74 65 0A | 48 69 63 6B 73 1C 28 35 |   ..Dante.Hicks.(5 | 35 35 29 20 31 32 33 2D | 34 35 36 37 40 04 0C 52 |   55) 123-4567@..R | 61 6E 64 61 6C 0C 47 72 | 61 76 65 73 1C 28 35 35 |   andal.Graves.(55 | 35 29 20 31 32 33 2D 35 | 36 37 38 3C 06 10 56 65 |   5) 123-5678<..Ve | 72 6F 6E 69 63 61 10 4C | 6F 75 67 68 72 61 6E 1C |   ronica.Loughran. | 28 35 35 35 29 20 31 32 | 33 2D 30 39 38 37 38 08 |   (555) 123-09878. | 0E 43 61 69 74 6C 69 6E | 08 42 72 65 65 1C 28 35 |   .Caitlin.Bree.(5 | 35 35 29 20 31 32 33 2D | 32 33 32 33 36 0A 06 42 |   55) 123-23236..B | 6F 62 0C 53 69 6C 65 6E | 74 1C 28 35 35 35 29 20 |   ob.Silent.(555) | 31 32 33 2D 36 34 32 32 | 3A 0C 06 4A 61 79 06 3F |   123-6422:..Jay.? | 3F 3F 1C 28 35 35 35 29 | 20 31 32 33 2D 39 31 38 |   ??.(555) 123-918 | 32 34 .. .. .. .. .. .. | .. .. .. .. .. .. .. .. |   24..............  Now let's read all the records back out 1 |           Dante |           Hicks |  (555) 123-4567 | 32 2 |          Randal |          Graves |  (555) 123-5678 | 30 3 |        Veronica |        Loughran |  (555) 123-0987 | 28 4 |         Caitlin |            Bree |  (555) 123-2323 | 27 5 |             Bob |          Silent |  (555) 123-6422 | 29 6 |             Jay |             ??? |  (555) 123-9182 | 26   Use projection to print only the First name and phone numbers           Dante |  (555) 123-4567 |          Randal |  (555) 123-5678 |        Veronica |  (555) 123-0987 |         Caitlin |  (555) 123-2323 |             Bob |  (555) 123-6422 |             Jay |  (555) 123-9182 | The Quick Stop owner was so pleased, he asked you to create a movie database for his RST Video store. 9. Reference files 9.1. avro.h The avro.h header file contains the complete public API for Avro C. The documentation is rather sparse right now but we’ll be adding more information soon. /*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements. See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to you under the Apache License, Version 2.0  * (the ""License""); you may not use this file except in compliance with  * the License. You may obtain a copy of the License at  *  * http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an ""AS IS"" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  * implied. See the License for the specific language governing  * permissions and limitations under the License.  */ #ifndef AVRO_H #define AVRO_H #ifdef __cplusplus extern ""C"" { #define CLOSE_EXTERN } #else #define CLOSE_EXTERN #endif  #include <avro/allocation.h> #include <avro/basics.h> #include <avro/consumer.h> #include <avro/data.h> #include <avro/errors.h> #include <avro/generic.h> #include <avro/io.h> #include <avro/legacy.h> #include <avro/platform.h> #include <avro/resolver.h> #include <avro/schema.h> #include <avro/value.h>  CLOSE_EXTERN #endif 9.2. test_avro_data.c Another good way to learn how to encode/decode data in Avro C is to look at the test_avro_data.c unit test. This simple unit test checks that all the avro types can be encoded/decoded correctly. /*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements. See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to you under the Apache License, Version 2.0  * (the ""License""); you may not use this file except in compliance with  * the License. You may obtain a copy of the License at  *  * http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an ""AS IS"" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  * implied. See the License for the specific language governing  * permissions and limitations under the License.  */  #include ""avro.h"" #include ""avro_private.h"" #include <limits.h> #include <stdlib.h> #include <string.h> #include <time.h>  char buf[4096]; avro_reader_t reader; avro_writer_t writer;  typedef int (*avro_test) (void);  /*  * Use a custom allocator that verifies that the size that we use to  * free an object matches the size that we use to allocate it.  */  static void * test_allocator(void *ud, void *ptr, size_t osize, size_t nsize) {         AVRO_UNUSED(ud);         AVRO_UNUSED(osize);          if (nsize == 0) {                 size_t  *size = ((size_t *) ptr) - 1;                 if (osize != *size) {                         fprintf(stderr,                                 ""Error freeing %p:\n""                                 ""Size passed to avro_free (%"" PRIsz "") ""                                 ""doesn't match size passed to ""                                 ""avro_malloc (%"" PRIsz "")\n"",                                 ptr, osize, *size);                         abort();                         //exit(EXIT_FAILURE);                 }                 free(size);                 return NULL;         } else {                 size_t  real_size = nsize + sizeof(size_t);                 size_t  *old_size = ptr? ((size_t *) ptr)-1: NULL;                 size_t  *size = (size_t *) realloc(old_size, real_size);                 *size = nsize;                 return (size + 1);         } }  void init_rand(void) {         srand(time(NULL)); }  double rand_number(double from, double to) {         double range = to - from;         return from + ((double)rand() / (RAND_MAX + 1.0)) * range; }  int64_t rand_int64(void) {         return (int64_t) rand_number(LONG_MIN, LONG_MAX); }  int32_t rand_int32(void) {         return (int32_t) rand_number(INT_MIN, INT_MAX); }  void write_read_check(avro_schema_t writers_schema, avro_datum_t datum,                  avro_schema_t readers_schema, avro_datum_t expected, char *type) {         avro_datum_t datum_out;         int validate;          for (validate = 0; validate <= 1; validate++) {                  reader = avro_reader_memory(buf, sizeof(buf));                 writer = avro_writer_memory(buf, sizeof(buf));                  if (!expected) {                         expected = datum;                 }                  /* Validating read/write */                 if (avro_write_data                     (writer, validate ? writers_schema : NULL, datum)) {                         fprintf(stderr, ""Unable to write %s validate=%d\n %s\n"",                                 type, validate, avro_strerror());                         exit(EXIT_FAILURE);                 }                 int64_t size =                     avro_size_data(writer, validate ? writers_schema : NULL,                                    datum);                 if (size != avro_writer_tell(writer)) {                         fprintf(stderr,                                 ""Unable to calculate size %s validate=%d ""                                 ""(%""PRId64"" != %""PRId64"")\n %s\n"",                                 type, validate, size, avro_writer_tell(writer),                                 avro_strerror());                         exit(EXIT_FAILURE);                 }                 if (avro_read_data                     (reader, writers_schema, readers_schema, &datum_out)) {                         fprintf(stderr, ""Unable to read %s validate=%d\n %s\n"",                                 type, validate, avro_strerror());                         fprintf(stderr, "" %s\n"", avro_strerror());                         exit(EXIT_FAILURE);                 }                 if (!avro_datum_equal(expected, datum_out)) {                         fprintf(stderr,                                 ""Unable to encode/decode %s validate=%d\n %s\n"",                                 type, validate, avro_strerror());                         exit(EXIT_FAILURE);                 }                  avro_reader_dump(reader, stderr);                 avro_datum_decref(datum_out);                 avro_reader_free(reader);                 avro_writer_free(writer);         } }  static void test_json(avro_datum_t datum, const char *expected) {         char  *json = NULL;         avro_datum_to_json(datum, 1, &json);         if (strcasecmp(json, expected) != 0) {                 fprintf(stderr, ""Unexpected JSON encoding: %s\n"", json);                 exit(EXIT_FAILURE);         }         free(json); }  static int test_string(void) {         unsigned int i;         const char *strings[] = { ""Four score and seven years ago"",                 ""our father brought forth on this continent"",                 ""a new nation"", ""conceived in Liberty"",                 ""and dedicated to the proposition that all men are created equal.""         };         avro_schema_t writer_schema = avro_schema_string();         for (i = 0; i < sizeof(strings) / sizeof(strings[0]); i++) {                 avro_datum_t datum = avro_givestring(strings[i], NULL);                 write_read_check(writer_schema, datum, NULL, NULL, ""string"");                 avro_datum_decref(datum);         }          avro_datum_t  datum = avro_givestring(strings[0], NULL);         test_json(datum, ""\""Four score and seven years ago\"""");         avro_datum_decref(datum);          // The following should bork if we don't copy the string value         // correctly (since we'll try to free a static string).          datum = avro_string(""this should be copied"");         avro_string_set(datum, ""also this"");         avro_datum_decref(datum);          avro_schema_decref(writer_schema);         return 0; }  static int test_bytes(void) {         char bytes[] = { 0xDE, 0xAD, 0xBE, 0xEF };         avro_schema_t writer_schema = avro_schema_bytes();         avro_datum_t datum;         avro_datum_t expected_datum;          datum = avro_givebytes(bytes, sizeof(bytes), NULL);         write_read_check(writer_schema, datum, NULL, NULL, ""bytes"");         test_json(datum, ""\""\\u00de\\u00ad\\u00be\\u00ef\"""");         avro_datum_decref(datum);         avro_schema_decref(writer_schema);          datum = avro_givebytes(NULL, 0, NULL);         avro_givebytes_set(datum, bytes, sizeof(bytes), NULL);         expected_datum = avro_givebytes(bytes, sizeof(bytes), NULL);         if (!avro_datum_equal(datum, expected_datum)) {                 fprintf(stderr,                         ""Expected equal bytes instances.\n"");                 exit(EXIT_FAILURE);         }         avro_datum_decref(datum);         avro_datum_decref(expected_datum);          // The following should bork if we don't copy the bytes value         // correctly (since we'll try to free a static string).          datum = avro_bytes(""original"", 8);         avro_bytes_set(datum, ""alsothis"", 8);         avro_datum_decref(datum);          avro_schema_decref(writer_schema);         return 0; }  static int test_int32(void) {         int i;         avro_schema_t writer_schema = avro_schema_int();         avro_schema_t long_schema = avro_schema_long();         avro_schema_t float_schema = avro_schema_float();         avro_schema_t double_schema = avro_schema_double();         for (i = 0; i < 100; i++) {                 int32_t  value = rand_int32();                 avro_datum_t datum = avro_int32(value);                 avro_datum_t long_datum = avro_int64(value);                 avro_datum_t float_datum = avro_float(value);                 avro_datum_t double_datum = avro_double(value);                 write_read_check(writer_schema, datum, NULL, NULL, ""int"");                 write_read_check(writer_schema, datum,                                  long_schema, long_datum, ""int->long"");                 write_read_check(writer_schema, datum,                                  float_schema, float_datum, ""int->float"");                 write_read_check(writer_schema, datum,                                  double_schema, double_datum, ""int->double"");                 avro_datum_decref(datum);                 avro_datum_decref(long_datum);                 avro_datum_decref(float_datum);                 avro_datum_decref(double_datum);         }          avro_datum_t  datum = avro_int32(10000);         test_json(datum, ""10000"");         avro_datum_decref(datum);          avro_schema_decref(writer_schema);         avro_schema_decref(long_schema);         avro_schema_decref(float_schema);         avro_schema_decref(double_schema);         return 0; }  static int test_int64(void) {         int i;         avro_schema_t writer_schema = avro_schema_long();         avro_schema_t float_schema = avro_schema_float();         avro_schema_t double_schema = avro_schema_double();         for (i = 0; i < 100; i++) {                 int64_t  value = rand_int64();                 avro_datum_t datum = avro_int64(value);                 avro_datum_t float_datum = avro_float(value);                 avro_datum_t double_datum = avro_double(value);                 write_read_check(writer_schema, datum, NULL, NULL, ""long"");                 write_read_check(writer_schema, datum,                                  float_schema, float_datum, ""long->float"");                 write_read_check(writer_schema, datum,                                  double_schema, double_datum, ""long->double"");                 avro_datum_decref(datum);                 avro_datum_decref(float_datum);                 avro_datum_decref(double_datum);         }          avro_datum_t  datum = avro_int64(10000);         test_json(datum, ""10000"");         avro_datum_decref(datum);          avro_schema_decref(writer_schema);         avro_schema_decref(float_schema);         avro_schema_decref(double_schema);         return 0; }  static int test_double(void) {         int i;         avro_schema_t schema = avro_schema_double();         for (i = 0; i < 100; i++) {                 avro_datum_t datum = avro_double(rand_number(-1.0E10, 1.0E10));                 write_read_check(schema, datum, NULL, NULL, ""double"");                 avro_datum_decref(datum);         }          avro_datum_t  datum = avro_double(2000.0);         test_json(datum, ""2000.0"");         avro_datum_decref(datum);          avro_schema_decref(schema);         return 0; }  static int test_float(void) {         int i;         avro_schema_t schema = avro_schema_float();         avro_schema_t double_schema = avro_schema_double();         for (i = 0; i < 100; i++) {                 float  value = rand_number(-1.0E10, 1.0E10);                 avro_datum_t datum = avro_float(value);                 avro_datum_t double_datum = avro_double(value);                 write_read_check(schema, datum, NULL, NULL, ""float"");                 write_read_check(schema, datum,                                  double_schema, double_datum, ""float->double"");                 avro_datum_decref(datum);                 avro_datum_decref(double_datum);         }          avro_datum_t  datum = avro_float(2000.0);         test_json(datum, ""2000.0"");         avro_datum_decref(datum);          avro_schema_decref(schema);         avro_schema_decref(double_schema);         return 0; }  static int test_boolean(void) {         int i;         const char  *expected_json[] = { ""false"", ""true"" };         avro_schema_t schema = avro_schema_boolean();         for (i = 0; i <= 1; i++) {                 avro_datum_t datum = avro_boolean(i);                 write_read_check(schema, datum, NULL, NULL, ""boolean"");                 test_json(datum, expected_json[i]);                 avro_datum_decref(datum);         }         avro_schema_decref(schema);         return 0; }  static int test_null(void) {         avro_schema_t schema = avro_schema_null();         avro_datum_t datum = avro_null();         write_read_check(schema, datum, NULL, NULL, ""null"");         test_json(datum, ""null"");         avro_datum_decref(datum);         return 0; }  static int test_record(void) {         avro_schema_t schema = avro_schema_record(""person"", NULL);         avro_schema_record_field_append(schema, ""name"", avro_schema_string());         avro_schema_record_field_append(schema, ""age"", avro_schema_int());          avro_datum_t datum = avro_record(schema);         avro_datum_t name_datum, age_datum;          name_datum = avro_givestring(""Joseph Campbell"", NULL);         age_datum = avro_int32(83);          avro_record_set(datum, ""name"", name_datum);         avro_record_set(datum, ""age"", age_datum);          write_read_check(schema, datum, NULL, NULL, ""record"");         test_json(datum, ""{\""name\"": \""Joseph Campbell\"", \""age\"": 83}"");          int  rc;         avro_record_set_field_value(rc, datum, int32, ""age"", 104);          int32_t  age = 0;         avro_record_get_field_value(rc, datum, int32, ""age"", &age);         if (age != 104) {                 fprintf(stderr, ""Incorrect age value\n"");                 exit(EXIT_FAILURE);         }          avro_datum_decref(name_datum);         avro_datum_decref(age_datum);         avro_datum_decref(datum);         avro_schema_decref(schema);         return 0; }  static int test_nested_record(void) {         const char  *json =                 ""{""                 "" \""type\"": \""record\"",""                 "" \""name\"": \""list\"",""                 "" \""fields\"": [""                 "" { \""name\"": \""x\"", \""type\"": \""int\"" },""                 "" { \""name\"": \""y\"", \""type\"": \""int\"" },""                 "" { \""name\"": \""next\"", \""type\"": [\""null\"",\""list\""]}""                 "" ]""                 ""}"";          int  rval;          avro_schema_t schema = NULL;         avro_schema_error_t error;         avro_schema_from_json(json, strlen(json), &schema, &error);          avro_datum_t  head = avro_datum_from_schema(schema);         avro_record_set_field_value(rval, head, int32, ""x"", 10);         avro_record_set_field_value(rval, head, int32, ""y"", 10);          avro_datum_t  next = NULL;         avro_datum_t  tail = NULL;          avro_record_get(head, ""next"", &next);         avro_union_set_discriminant(next, 1, &tail);         avro_record_set_field_value(rval, tail, int32, ""x"", 20);         avro_record_set_field_value(rval, tail, int32, ""y"", 20);          avro_record_get(tail, ""next"", &next);         avro_union_set_discriminant(next, 0, NULL);          write_read_check(schema, head, NULL, NULL, ""nested record"");          avro_schema_decref(schema);         avro_datum_decref(head);          return 0; }  static int test_enum(void) {         enum avro_languages {                 AVRO_C,                 AVRO_CPP,                 AVRO_PYTHON,                 AVRO_RUBY,                 AVRO_JAVA         };         avro_schema_t schema = avro_schema_enum(""language"");         avro_datum_t datum = avro_enum(schema, AVRO_C);          avro_schema_enum_symbol_append(schema, ""C"");         avro_schema_enum_symbol_append(schema, ""C++"");         avro_schema_enum_symbol_append(schema, ""Python"");         avro_schema_enum_symbol_append(schema, ""Ruby"");         avro_schema_enum_symbol_append(schema, ""Java"");          if (avro_enum_get(datum) != AVRO_C) {                 fprintf(stderr, ""Unexpected enum value AVRO_C\n"");                 exit(EXIT_FAILURE);         }          if (strcmp(avro_enum_get_name(datum), ""C"") != 0) {                 fprintf(stderr, ""Unexpected enum value name C\n"");                 exit(EXIT_FAILURE);         }          write_read_check(schema, datum, NULL, NULL, ""enum"");         test_json(datum, ""\""C\"""");          avro_enum_set(datum, AVRO_CPP);         if (strcmp(avro_enum_get_name(datum), ""C++"") != 0) {                 fprintf(stderr, ""Unexpected enum value name C++\n"");                 exit(EXIT_FAILURE);         }          write_read_check(schema, datum, NULL, NULL, ""enum"");         test_json(datum, ""\""C++\"""");          avro_enum_set_name(datum, ""Python"");         if (avro_enum_get(datum) != AVRO_PYTHON) {                 fprintf(stderr, ""Unexpected enum value AVRO_PYTHON\n"");                 exit(EXIT_FAILURE);         }          write_read_check(schema, datum, NULL, NULL, ""enum"");         test_json(datum, ""\""Python\"""");          avro_datum_decref(datum);         avro_schema_decref(schema);         return 0; }  static int test_array(void) {         int i, rval;         avro_schema_t schema = avro_schema_array(avro_schema_int());         avro_datum_t datum = avro_array(schema);          for (i = 0; i < 10; i++) {                 avro_datum_t i32_datum = avro_int32(i);                 rval = avro_array_append_datum(datum, i32_datum);                 avro_datum_decref(i32_datum);                 if (rval) {                         exit(EXIT_FAILURE);                 }         }          if (avro_array_size(datum) != 10) {                 fprintf(stderr, ""Unexpected array size"");                 exit(EXIT_FAILURE);         }          write_read_check(schema, datum, NULL, NULL, ""array"");         test_json(datum, ""[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"");         avro_datum_decref(datum);         avro_schema_decref(schema);         return 0; }  static int test_map(void) {         avro_schema_t schema = avro_schema_map(avro_schema_long());         avro_datum_t datum = avro_map(schema);         int64_t i = 0;         char *nums[] =             { ""zero"", ""one"", ""two"", ""three"", ""four"", ""five"", ""six"", NULL };         while (nums[i]) {                 avro_datum_t i_datum = avro_int64(i);                 avro_map_set(datum, nums[i], i_datum);                 avro_datum_decref(i_datum);                 i++;         }          if (avro_array_size(datum) != 7) {                 fprintf(stderr, ""Unexpected map size\n"");                 exit(EXIT_FAILURE);         }          avro_datum_t value;         const char  *key;         avro_map_get_key(datum, 2, &key);         avro_map_get(datum, key, &value);         int64_t  val;         avro_int64_get(value, &val);          if (val != 2) {                 fprintf(stderr, ""Unexpected map value 2\n"");                 exit(EXIT_FAILURE);         }          int  index;         if (avro_map_get_index(datum, ""two"", &index)) {                 fprintf(stderr, ""Can't get index for key \""two\"": %s\n"",                         avro_strerror());                 exit(EXIT_FAILURE);         }         if (index != 2) {                 fprintf(stderr, ""Unexpected index for key \""two\""\n"");                 exit(EXIT_FAILURE);         }         if (!avro_map_get_index(datum, ""foobar"", &index)) {                 fprintf(stderr, ""Unexpected index for key \""foobar\""\n"");                 exit(EXIT_FAILURE);         }          write_read_check(schema, datum, NULL, NULL, ""map"");         test_json(datum,                   ""{\""zero\"": 0, \""one\"": 1, \""two\"": 2, \""three\"": 3, ""                   ""\""four\"": 4, \""five\"": 5, \""six\"": 6}"");         avro_datum_decref(datum);         avro_schema_decref(schema);         return 0; }  static int test_union(void) {         avro_schema_t schema = avro_schema_union();         avro_datum_t union_datum;         avro_datum_t datum;         avro_datum_t union_datum1;         avro_datum_t datum1;          avro_schema_union_append(schema, avro_schema_string());         avro_schema_union_append(schema, avro_schema_int());         avro_schema_union_append(schema, avro_schema_null());          datum = avro_givestring(""Follow your bliss."", NULL);         union_datum = avro_union(schema, 0, datum);          if (avro_union_discriminant(union_datum) != 0) {                 fprintf(stderr, ""Unexpected union discriminant\n"");                 exit(EXIT_FAILURE);         }          if (avro_union_current_branch(union_datum) != datum) {                 fprintf(stderr, ""Unexpected union branch datum\n"");                 exit(EXIT_FAILURE);         }          union_datum1 = avro_datum_from_schema(schema);         avro_union_set_discriminant(union_datum1, 0, &datum1);         avro_givestring_set(datum1, ""Follow your bliss."", NULL);          if (!avro_datum_equal(datum, datum1)) {                 fprintf(stderr, ""Union values should be equal\n"");                 exit(EXIT_FAILURE);         }          write_read_check(schema, union_datum, NULL, NULL, ""union"");         test_json(union_datum, ""{\""string\"": \""Follow your bliss.\""}"");          avro_datum_decref(datum);         avro_union_set_discriminant(union_datum, 2, &datum);         test_json(union_datum, ""null"");          avro_datum_decref(union_datum);         avro_datum_decref(datum);         avro_datum_decref(union_datum1);         avro_schema_decref(schema);         return 0; }  static int test_fixed(void) {         char bytes[] = { 0xD, 0xA, 0xD, 0xA, 0xB, 0xA, 0xB, 0xA };         avro_schema_t schema = avro_schema_fixed(""msg"", sizeof(bytes));         avro_datum_t datum;         avro_datum_t expected_datum;          datum = avro_givefixed(schema, bytes, sizeof(bytes), NULL);         write_read_check(schema, datum, NULL, NULL, ""fixed"");         test_json(datum, ""\""\\r\\n\\r\\n\\u000b\\n\\u000b\\n\"""");         avro_datum_decref(datum);          datum = avro_givefixed(schema, NULL, sizeof(bytes), NULL);         avro_givefixed_set(datum, bytes, sizeof(bytes), NULL);         expected_datum = avro_givefixed(schema, bytes, sizeof(bytes), NULL);         if (!avro_datum_equal(datum, expected_datum)) {                 fprintf(stderr,                         ""Expected equal fixed instances.\n"");                 exit(EXIT_FAILURE);         }         avro_datum_decref(datum);         avro_datum_decref(expected_datum);          // The following should bork if we don't copy the fixed value         // correctly (since we'll try to free a static string).          datum = avro_fixed(schema, ""original"", 8);         avro_fixed_set(datum, ""alsothis"", 8);         avro_datum_decref(datum);          avro_schema_decref(schema);         return 0; }  int main(void) {         avro_set_allocator(test_allocator, NULL);          unsigned int i;         struct avro_tests {                 char *name;                 avro_test func;         } tests[] = {                 {                 ""string"", test_string}, {                 ""bytes"", test_bytes}, {                 ""int"", test_int32}, {                 ""long"", test_int64}, {                 ""float"", test_float}, {                 ""double"", test_double}, {                 ""boolean"", test_boolean}, {                 ""null"", test_null}, {                 ""record"", test_record}, {                 ""nested_record"", test_nested_record}, {                 ""enum"", test_enum}, {                 ""array"", test_array}, {                 ""map"", test_map}, {                 ""fixed"", test_fixed}, {                 ""union"", test_union}         };          init_rand();         for (i = 0; i < sizeof(tests) / sizeof(tests[0]); i++) {                 struct avro_tests *test = tests + i;                 fprintf(stderr, ""**** Running %s tests ****\n"", test->name);                 if (test->func() != 0) {                         return EXIT_FAILURE;                 }         }         return EXIT_SUCCESS; } Last updated 2016-05-15 00:48:18 UTC"	"null"	"null"	"A C implementation of the Avro data serialization system.."	"true"
"Serialization"	"mpack"	"https://github.com/ludocode/mpack"	"Another implementation of the serialization protocol.."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"40"	"5"	"11"	"GitHub - ludocode/mpack: MPack - A C encoder/decoder for the MessagePack serialization format / msgpack.org[C] Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 5 Star 40 Fork 11 ludocode/mpack Code Issues 2 Pull requests 0 Pulse Graphs MPack - A C encoder/decoder for the MessagePack serialization format / msgpack.org[C] 490 commits 5 branches 12 releases Fetching contributors C 97.9% Python 1.4% C++ 0.7% C Python C++ Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: develop Switch branches/tags Branches Tags develop gh-pages master readme-v0.9 tree-stream Nothing to show v0.8.2 v0.8.1 v0.8 v0.7.1 v0.7 v0.6 v0.5.1 v0.5 v0.4 v0.3 v0.2 v0.1 Nothing to show New pull request Latest commit 8c13a0d May 1, 2016 ludocode Fixed skip fill when connected to a socket Permalink Failed to load latest commit information. docs Added type-generic write helpers to feature doc Apr 23, 2016 projects Added MPACK_HAS_CONFIG=1 to Visual Studio project Apr 12, 2016 src Fixed skip fill when connected to a socket May 1, 2016 test Added mpack_writer_flush_message() May 1, 2016 tools Fixed some issues running unit tests on FreeBSD Apr 29, 2016 .editorconfig Updated .editorconfig Jun 26, 2015 .gitignore Cleaned up vgcore files left by Valgrind Apr 10, 2016 .travis.yml Added xcodebuild to Travis Apr 13, 2016 AUTHORS Added missing contributors to AUTHORS file Feb 26, 2016 CHANGELOG.md Implemented v4 compatibility mode for writer Apr 17, 2016 LICENSE Updated copyright notice year Jan 11, 2016 README.md Reverted README changes removing mpack-config.h Apr 12, 2016 SConscript Fixed some issues running unit tests on FreeBSD Apr 30, 2016 SConstruct Fixed some issues running unit tests on FreeBSD Apr 30, 2016 appveyor.yml Added AppVeyor configuration Dec 19, 2015 README.md Introduction MPack is a C implementation of an encoder and decoder for the MessagePack serialization format. It is intended to be: Simple and easy to use Secure against untrusted data Lightweight, suitable for embedded Extensively documented Extremely fast The core of MPack contains a buffered reader and writer, and a tree-style parser that decodes into a tree of dynamically typed nodes. Helper functions can be enabled to read values of expected type, to work with files, to allocate strings automatically, to check UTF-8 encoding, and more. The MPack code is small enough to be embedded directly into your codebase. The easiest way to use it is to download the amalgamation package and insert the source files directly into your project. Copy mpack.h and mpack.c into to your codebase, and copy mpack-config.h.sample as mpack-config.h. You can use the defaults or edit it if you'd like to customize the MPack featureset. Build Status MPack is beta software under development. Branch Travis-CI AppVeyor Coveralls.io master develop The Node Reader API The Node API parses a chunk of MessagePack data into an immutable tree of dynamically-typed nodes. A series of helper functions can be used to extract data of specific types from each node. // parse a file into a node tree mpack_tree_t tree; mpack_tree_init_file(&tree, ""homepage-example.mp"", 0); mpack_node_t root = mpack_tree_root(&tree);  // extract the example data on the msgpack homepage bool compact = mpack_node_bool(mpack_node_map_cstr(root, ""compact"")); int schema = mpack_node_i32(mpack_node_map_cstr(root, ""schema""));  // clean up and check for errors if (mpack_tree_destroy(tree) != mpack_ok) {     fprintf(stderr, ""An error occurred decoding the data!\n"");     return; } Note that no additional error handling is needed in the above code. If the file is missing or corrupt, if map keys are missing or if nodes are not in the expected types, special ""nil"" nodes and false/zero values are returned and the tree is placed in an error state. An error check is only needed before using the data. The above example decodes into allocated pages of nodes. A fixed node pool can be provided to the parser instead in memory-constrained environments. For maximum performance and minimal memory usage, the Expect API can be used to parse data of a predefined schema. The Write API The MPack Write API encodes structured data to MessagePack. // encode to memory buffer char* data; size_t size; mpack_writer_t writer; mpack_writer_init_growable(&writer, &data, &size);  // write the example on the msgpack homepage mpack_start_map(&writer, 2); mpack_write_cstr(&writer, ""compact""); mpack_write_bool(&writer, true); mpack_write_cstr(&writer, ""schema""); mpack_write_uint(&writer, 0); mpack_finish_map(&writer);  // finish writing if (mpack_writer_destroy(&writer) != mpack_ok) {     fprintf(stderr, ""An error occurred encoding the data!\n"");     return; }  // use the data do_something_with_data(data, size); free(data); In the above example, we encode to a growable memory buffer. The writer can instead write to a pre-allocated or stack-allocated buffer, avoiding the need for memory allocation. The writer can also be provided with a flush function (such as a file or socket write function) to call when the buffer is full or when writing is done. If any error occurs, the writer is placed in an error state. The writer will flag an error if too much data is written, if the wrong number of elements are written, if the data could not be flushed, etc. No additional error handling is needed in the above code; any subsequent writes are ignored when the writer is in an error state, so you don't need to check every write for errors. Note in particular that in debug mode, the mpack_finish_map() call above ensures that two key/value pairs were actually written as claimed, something that other MessagePack C/C++ libraries may not do. Comparison With Other Parsers MPack is rich in features while maintaining very high performance and a small code footprint. Here's a short feature table comparing it to other C parsers: MPack (v0.8) msgpack-c (v1.3.0) CMP (v14) No libc requirement ✓ ✓ Growable memory writer ✓ ✓ File I/O helpers ✓ ✓ Tree parser ✓ ✓ Propagating errors ✓ ✓ Compound size tracking ✓ Incremental parser ✓ ✓ Incremental range/match helpers ✓ Tree stream parser ✓ UTF-8 verification ✓ A larger feature comparison table is available here which includes descriptions of the various entries in the table. This benchmarking suite compares the performance of MPack to other implementations of schemaless serialization formats. MPack outperforms all JSON and MessagePack libraries, and in some tests MPack is several times faster than RapidJSON for equivalent data. Why Not Just Use JSON? Conceptually, MessagePack stores data similarly to JSON: they are both composed of simple values such as numbers and strings, stored hierarchically in maps and arrays. So why not just use JSON instead? The main reason is that JSON is designed to be human-readable, so it is not as efficient as a binary serialization format: Compound types such as strings, maps and arrays are delimited, so appropriate storage cannot be allocated upfront. The whole object must be parsed to determine its size. Strings are not stored in their native encoding. Special characters such as quotes and backslashes must be escaped when written and converted back when read. Numbers are particularly inefficient (especially when parsing back floats), making JSON inappropriate as a base format for structured data that contains lots of numbers. Binary data is not supported by JSON at all. Small binary blobs such as icons and thumbnails need to be Base64 encoded or passed out-of-band. The above issues greatly increase the complexity of the decoder. Full-featured JSON decoders are quite large, and minimal decoders tend to leave out such features as string unescaping and float parsing, instead leaving these up to the user or platform. This can lead to hard-to-find platform-specific and locale-specific bugs, as well as a greater potential for security vulnerabilites. This also significantly decreases performance, making JSON unattractive for use in applications such as mobile games. While the space inefficiencies of JSON can be partially mitigated through minification and compression, the performance inefficiencies cannot. More importantly, if you are minifying and compressing the data, then why use a human-readable format in the first place? Running the Unit Tests The MPack build process does not build MPack into a library; it is used to build and run the unit tests. You do not need to build MPack or the unit testing suite to use MPack. On Linux, the test suite uses SCons and requires Valgrind, and can be run in the repository or in the amalgamation package. Run scons to build and run the test suite in full debug configuration. On Windows, there is a Visual Studio solution, and on OS X, there is an Xcode project for building and running the test suite. You can also build and run the test suite in all supported configurations, which is what the continuous integration server will build and run. If you are on 64-bit, you will need support for cross-compiling to 32-bit, and running 32-bit binaries with 64-bit Valgrind. On Ubuntu, you'll need libc6-dbg:i386. On Arch you'll need gcc-multilib or lib32-clang, and valgrind-multilib. Use scons all=1 -j16 (or some appropriate thread count) to build and run all tests. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/ludocode/mpack"	"Another implementation of the serialization protocol.."	"true"
"Serialization"	"protobuf-c"	"https://github.com/protobuf-c/protobuf-c"	"An implementation of Google Protocol Buffer in C.."	"null"	"null"	"null"	"xdr"	"https://en.wikipedia.org/wiki/External_Data_Representation"	"null"	"null"	"500"	"86"	"180"	"GitHub - protobuf-c/protobuf-c: Protocol Buffers implementation in C Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 86 Star 500 Fork 180 protobuf-c/protobuf-c Code Issues 13 Pull requests 0 Wiki Pulse Graphs Protocol Buffers implementation in C 467 commits 3 branches 9 releases 13 contributors C++ 50.4% C 45.6% Protocol Buffer 2.8% Other 1.2% C++ C Protocol Buffer Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags gh-pages master next Nothing to show v1.2.1 v1.2.0 v1.1.1 v1.1.0 v1.0.2 v1.0.1 v1.0.0 v1.0.0-rc2 v1.0.0-rc1 Nothing to show New pull request Latest commit 006d69b Feb 2, 2016 edmonds ChangeLog: 1.2.1 Permalink Failed to load latest commit information. build-cmake Bump version to 1.2.1 Feb 2, 2016 m4 switch to a more automake-ish method of generating the html doxygen d… Jun 3, 2014 protobuf-c Bump version to 1.2.1 Feb 2, 2016 protoc-c Fix union initialization Feb 2, 2016 t t: Add coverage Dec 12, 2015 .commit_docs.sh .commit_docs.sh: initial version of the documentation update script Nov 15, 2014 .gitignore switch to a more automake-ish method of generating the html doxygen d… Jun 3, 2014 .travis.yml .travis.yml: Add sanitizer checks Dec 12, 2015 ChangeLog ChangeLog: 1.2.1 Feb 2, 2016 Doxyfile.in Doxyfile.in: enable MACRO_EXPANSION Jun 3, 2014 DoxygenLayout.xml DoxygenLayout.xml: initial customizations Jun 3, 2014 LICENSE LICENSE: 2016 Jan 29, 2016 Makefile.am skip protoc-c tests on cross-compiling Jan 29, 2016 README.md Update link to Autotools Mythbuster to canonical site Jan 9, 2016 TODO TODO: Remove items that have been completed Feb 14, 2015 autogen.sh new build system Nov 16, 2013 configure.ac Bump version to 1.2.1 Feb 2, 2016 README.md Overview This is protobuf-c, a C implementation of the Google Protocol Buffers data serialization format. It includes libprotobuf-c, a pure C library that implements protobuf encoding and decoding, and protoc-c, a code generator that converts Protocol Buffer .proto files to C descriptor code, based on the original protoc. protobuf-c formerly included an RPC implementation; that code has been split out into the protobuf-c-rpc project. protobuf-c was originally written by Dave Benson and maintained by him through version 0.15 but is now being maintained by a new team. Thanks, Dave! Mailing list protobuf-c's mailing list is hosted on a Google Groups forum. Subscribe by sending an email to protobuf-c+subscribe@googlegroups.com. Building protobuf-c requires a C compiler, a C++ compiler, protobuf, and pkg-config to be installed. ./configure && make && make install  If building from a git checkout, the autotools (autoconf, automake, libtool) must also be installed, and the build system must be generated by running the autogen.sh script. ./autogen.sh && ./configure && make && make install  Documentation See the online Doxygen documentation here or the Wiki for a detailed reference. The Doxygen documentation can be built from the source tree by running: make html  Synopsis Use the protoc-c command to generate .pb-c.c and .pb-c.h output files from your .proto input file. protoc-c --c_out=. example.proto  Include the .pb-c.h file from your C source code. #include ""example.pb-c.h""  Compile your C source code together with the .pb-c.c file. Add the output of the following command to your compile flags. pkg-config --cflags 'libprotobuf-c >= 1.0.0'  Link against the libprotobuf-c support library. Add the output of the following command to your link flags. pkg-config --libs 'libprotobuf-c >= 1.0.0'  If using autotools, the PKG_CHECK_MODULES macro can be used to detect the presence of libprotobuf-c. Add the following line to your configure.ac file: PKG_CHECK_MODULES([PROTOBUF_C], [libprotobuf-c >= 1.0.0])  This will place compiler flags in the PROTOBUF_C_CFLAGS variable and linker flags in the PROTOBUF_C_LDFLAGS variable. Read more information here about the PKG_CHECK_MODULES macro. Versioning protobuf-c follows the Semantic Versioning Specification as of version 1.0.0. Note that as of version of 1.0.0, the header files generated by the protoc-c compiler contain version guards to prevent incompatibilities due to version skew between the .pb-c.h files generated by protoc-c and the public protobuf-c.h include file supplied by the libprotobuf-c support library. While we will try not to make changes to protobuf-c that will require triggering the version guard often, such as releasing a new major version of protobuf-c, this cannot be guaranteed. Thus, it's a good idea to recompile your .pb-c.c and .pb-c.h files from their source .proto files with protoc-c as part of your build system, with proper source file dependency tracking, rather than shipping potentially stale .pb-c.c and .pb-c.h files that may not be compatible with the libprotobuf-c headers installed on the system in project artifacts like repositories and release tarballs. (Note that the output of the protoc-c code generator is not standalone, as the output of some other tools that generate C code is, such as flex and bison.) Major API/ABI changes may occur between major version releases, by definition. It is not recommended to export the symbols in the code generated by protoc-c in a stable library interface, as this will embed the protobuf-c ABI into your library's ABI. Nor is it recommended to install generated .pb-c.h files into a public header file include path as part of a library API, as this will tie clients of your library's API to particular versions of libprotobuf-c. Contributing Please send patches to the protobuf-c mailing list or by opening a GitHub pull request. The most recently released protobuf-c version is kept on the master branch, while the next branch is used for commits targeted at the next release. Please base patches and pull requests against the next branch, not the master branch. Copyright to all contributions are retained by the original author, but must be licensed under the terms of the BSD-2-Clause license. Please add a Signed-off-by header to your commit message (git commit -s) to indicate that you are licensing your contribution under these terms. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/protobuf-c/protobuf-c"	"An implementation of Google Protocol Buffer in C.."	"true"
"Source Code Collections"	"CCAN"	"http://ccodearchive.net/"	"Modelled after Perl's CPAN, this is a big collection of C code that does stuff. The full list is. Various licenses (all free software)."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"ccan Comprehensive C Archive Network Upload Code Download Code About The Idea That nice snippets of C code should be moved out of junkcode directories and exposed to a wider world, where they can become something useful. CCAN is loosely modelled after the successful CPAN project for Perl code development and sharing. Get The Code You can get each module as a tarball (see list), get a tarball of the whole repository with tools, or clone our git repository (git clone git://git.ozlabs.org/~ccan/ccan) or the one on github. Use The Code There are two ways to use it: Put modules into a ccan/ subdirectory into your project. Add a ""config.h"" (like this example, or generate one using the configurator) and compile every .c file in ccan/* (as in this Makefile)). Alternatively, just hack whatever parts you want so it compiles in your project. Add Code We always welcome new code; see how!. Anyone can send code or a git pull request to the friendly mailing list or just upload it using the web form. ""GPLv2 or later"" and supersets thereof (eg. LGPLv2+ or BSD) licenses preferred. Complaints, Ideas and Infrastructure We have a low volume mailing list for discussion of CCAN in general, and you're welcome to join. We also have an IRC channel: #ccan on Freenode. We also have a wiki; feel free to enhance it."	"null"	"null"	"Modelled after Perl's CPAN, this is a big collection of C code that does stuff. The full list is. Various licenses (all free software)."	"true"
"Source Code Collections"	"here"	"http://ccodearchive.net/list.html"	"Modelled after Perl's CPAN, this is a big collection of C code that does stuff. The full list is. Various licenses (all free software)."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"ccan Comprehensive C Archive Network Upload Code Download Code About List of all CCAN modules: Note that two downloads are offered: the first includes with all the other ccan modules this module uses, the second is a standalone download. Or you can just download the tarball of everything including CCAN tools (1975K). Name Summary / Link to details Download a_star A straightforward implementation of the a-star path finding algorithm 11K / 11K aga Abstract Graph Algorithms 51K / 27K agar Re-entrant Abstract Graph Algorithms 275K / 17K alignof ALIGNOF() macro to determine alignment of a type. 5K / 5K altstack run a function with a dedicated stack, and then release the memory 9K / 9K antithread Accelerated Native Technology Implementation of ""threads"" 157K / 57K antithread/alloc memory allocator routines 61K / 22K argcheck macros to check arguments at runtime 47K / 5K array_size routine for safely deriving the size of a visible array. 6K / 5K asearch typesafe binary search (bsearch) 17K / 12K asort typesafe array sort (qsort) 25K / 14K asprintf asprintf wrapper (and if necessary, implementation). 8K / 3K autodata stash pointers in your binary for automatic registration 14K / 5K avl Key-value dictionary based on AVL trees 21K / 8K base64 base64 encoding and decoding (rfc4648). 8K / 8K bdelta Generate and apply binary deltas 13K / 13K bitmap bitmap handling 17K / 13K block_pool An efficient allocator for blocks that don't need to be resized or freed. 47K / 5K breakpoint break if the program is run under gdb. 7K / 4K btree Efficient sorted associative container based on B-trees. 15K / 15K build_assert routines for build-time assertions 5K / 5K bytestring simple bytestring handling 23K / 14K cast routines for safer casting. 15K / 12K ccan_tokenizer A full-text lexer for C source files 381K / 32K cdump routines to parse simple C structures. 269K / 10K charset character set conversion and validation routines 9K / 9K check_type routines for compile time type checking 6K / 5K ciniparser easily parse and manipulate ini style configuration files 12K / 12K compiler macros for common compiler extensions 6K / 6K container_of routine for upcasting 7K / 5K cppmagic Abuse of the C preprocessor 4K / 4K cpuid a CPUID instruction parser for x86/x86_64 CPUs. 13K / 9K crc routines for crc of bytes 22K / 18K crcsync routines to use crc for an rsync-like protocol. 33K / 16K crypto/ripemd160 implementation of RIPEMD 160 bit digest algorithm. 12K / 7K crypto/sha256 implementation of SHA-2 with 256 bit digest. 25K / 21K crypto/shachain compactly-representable chain of 256-bit numbers. 35K / 7K crypto/siphash24 implementation of SipHash-2-4. 10K / 8K daemon_with_notify daemonize a process, can wait for child to signal readiness 5K / 5K daemonize routine to turn a process into a well-behaved daemon. 4K / 4K darray Generic resizable arrays 305K / 305K deque type-preserving resizing circular deque 10K / 10K dgraph simple directed graph module 283K / 12K endian endian conversion macros for simple types 6K / 6K eratosthenes Sieve of Eratosthenes 18K / 11K err err(), errx(), warn() and warnx(), as per BSD's err.h. 8K / 5K failtest unit test helpers for testing malloc and other failures. 82K / 20K foreach macro for simple iteration of arrays 25K / 8K generator generators for C 22K / 13K grab_file file helper routines 46K / 11K hash routines for hashing bytes 18K / 17K heap a simple heap implementation 5K / 5K htable hash table routines 25K / 21K idtree id allocation tree 245K / 11K ilog Integer logarithm. 10K / 7K invbloom implementation of invertible bloom lookup tables. 247K / 6K io simple library for asynchronous io handling. 278K / 27K isaac A fast, high-quality pseudo-random number generator. 24K / 18K iscsi async library for iscsi functionality 32K / 28K jacobson_karels Jacobson/Karels Round Trip Time algorithm 14K / 10K jmap map from indices to values (based on libJudy) 27K / 18K jset set of pointers (based on libJudy) 23K / 13K json Parse and generate JSON (JavaScript Object Notation) 14K / 14K lbalance helpers for loadbalancing parallel tasks 42K / 17K likely macros for annotating likely/unlikely branches in the code 44K / 7K list double linked list routines 20K / 11K lpq Simple, slow priority queue implementation 30K / 12K lqueue Simple, singly-linked-list queue implementation 11K / 4K lstack Simple, singly-linked-list stack implementation 11K / 4K md4 MD4 Message Digest Algorithm (RFC1320). 16K / 10K mem Provide mem*() functions if missing from C library 10K / 8K minmax typesafe minimum and maximum functions 6K / 5K net simple IPv4/IPv6 socket library 11K / 7K nfs nfs client library 47K / 43K noerr routines for cleaning up without blatting errno 5K / 5K ntdb Next Generation Trivial Database 304K / 243K objset unordered set of pointers. 44K / 12K ogg_to_pcm decode ogg vorbis audio files to PCM data using libvorbis 9K / 9K opt simple command line parsing 42K / 26K order Simple, common value comparison functions 14K / 7K permutation Generate permutations 22K / 13K pipecmd code to fork and run a command in a pipe. 7K / 6K pr_log print things with varying levels of importance 20K / 11K ptr_valid test whether a pointer is safe to dereference. 9K / 6K ptrint Encoding integers in pointer values 8K / 5K pushpull simple marshalling/unmarshalling routines 9K / 7K rbtree talloc-aware Red Black Tree 125K / 19K rbuf buffered I/O input primitive. 5K / 5K read_write_all read_all and write_all routines. 11K / 11K rfc822 Parsing of RFC822 emails 290K / 45K rszshm resizable pointer-safe shared memory 11K / 11K short_types shorter names for standard integer types 5K / 5K siphash a keyed hash function 15K / 10K sparse_bsearch search a sorted array with some invalid entries 19K / 11K str string helper routines 9K / 8K str/hex hex-to-string conversions and vice-versa 5K / 5K strgrp group/cluster similar strings. 596K / 11K stringbuilder join lists of strings 6K / 6K stringmap Macros for mapping strings to things 53K / 8K strmap an ordered map of strings to values 27K / 6K strset an ordered set of strings 58K / 10K structeq bitwise comparison of structs. 4K / 4K take routines to mark pointers to be consumed by called functions. 46K / 6K tal compact tree allocator routines (inspired by talloc) 238K / 178K tal/grab_file file helper routines 241K / 11K tal/link link helper for tal 242K / 5K tal/path routines to manipulate paths 256K / 9K tal/stack stack of tal contextes (inspired by talloc_stack) 239K / 3K tal/str string helper routines which use tal 252K / 8K tal/talloc an implementation of the tal interface in terms of talloc. 56K / 10K talloc tree allocator routines 43K / 36K tally running tally of integers 52K / 10K tap Test Anything Protocol 15K / 11K tcon routines for creating typesafe generic containers 9K / 9K time routines for dealing with time 8K / 8K timer efficient implementation of rarely-expiring timers. 75K / 22K tlist typesafe double linked list routines 28K / 8K tlist2 typesafe double linked list routines, alternative form 28K / 7K ttxml tiny XML library for parsing (trusted!) XML documents. 16K / 16K typesafe_cb macros for safe callbacks. 8K / 8K version helper functions for major.minor-style version numbers 3K / 3K wwviaudio realtime playback and mixing of 16 bit signed PCM audio data. 13K / 12K xstring bounded string builder with three valued comparator 9K / 9K Contents of Junkcode: (This is contributed code which was dumped here: these gems may need some polishing.) codedr@gmail.com-grok.tar.bz2 (2K) Browse contents... dongre.avinash@gmail.com-clibutils.tar.bz2 (410K) Browse contents... fork0@users.sf.net-bitmaps.tar.bz2 (2K) Browse contents... fork0@users.sf.net-pathexpand.tar.bz2 (2K) Browse contents... fork0@users.sf.net-timeout.tar.bz2 (3K) Browse contents... guerrilla_thought@gmx.de-bst.tar.bz2 (2K) Browse contents... henryeshbaugh@gmail.com-log.tar.bz2 (4K) Browse contents... iasoule32@gmail.com-polynomial.tar.bz2 (6K) Browse contents... mansourmoufid@gmail.com-endianness.tar.bz2 (1K) Browse contents... swehack@gmail.com-snifstat.tar.bz2 (3K) Browse contents... tinkertim@gmail.com-grawk.tar.bz2 (7K) Browse contents... tterribe@email.unc.edu-nmbrthry.tar.bz2 (10K) Browse contents..."	"null"	"null"	"Modelled after Perl's CPAN, this is a big collection of C code that does stuff. The full list is. Various licenses (all free software)."	"true"
"String Manipulation"	"clib"	"https://github.com/clibs/clib"	"Simple Dynamic Strings; a library for handling C strings in a simpler way, but one that is compatible with normal C string functions. Available via.."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"2135"	"104"	"112"	"GitHub - clibs/clib: C package manager-ish Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 104 Star 2,135 Fork 112 clibs/clib Code Issues 20 Pull requests 2 Wiki Pulse Graphs C package manager-ish 247 commits 1 branch 26 releases 20 contributors C 74.0% Shell 21.1% Makefile 4.9% C Shell Makefile Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show 1.7.0 1.6.0 1.5.0 1.4.2 1.4.1 1.4.0 1.3.0 1.2.4 1.2.3 1.2.2 1.2.1 1.2.0 1.1.7 1.1.6 1.1.5 1.1.4 1.1.3 1.1.2 1.1.1 1.1.0 1.0.1 1.0.0 0.2.0 0.1.0 0.0.3 0.0.2 Nothing to show New pull request Latest commit 8fa0743 Apr 5, 2016 0dayZh committed with jwerle Update .gitignore Permalink Failed to load latest commit information. deps deps,package: update `parson` Jan 17, 2016 src Correct Issue with Saving Libs with '.' in their Names Jan 15, 2016 test test: fix installed `parson` version Jan 17, 2016 .gitignore Update .gitignore Apr 4, 2016 .travis.yml travis: add apt-get update before installing Nov 20, 2014 History.md Release 1.7.0 Jan 17, 2016 LICENSE Add an explicit LICENSE file to get people to stop emailing me Mar 18, 2014 Makefile Makefile: rename `MKDIR_P` to `MKDIRP` Jan 17, 2016 Readme.md Adds blog article Oct 18, 2014 package.json Release 1.7.0 Jan 18, 2016 test.sh test.sh cygwin compatibility May 21, 2015 Readme.md clib(1) Package manager for the C programming language. Installation Expects libcurl to be installed and linkable. With homebrew: $ brew install clib With git: $ git clone https://github.com/clibs/clib.git /tmp/clib $ cd /tmp/clib $ make install Ubuntu: # install libcurl $ sudo apt-get install libcurl4-gnutls-dev -qq # clone $ git clone https://github.com/clibs/clib.git /tmp/clib && cd /tmp/clib # build $ make # put on path $ sudo make install About Basically the lazy-man's copy/paste promoting smaller C utilities, also serving as a nice way to discover these sort of libraries. From my experience C libraries are scattered all over the web and discovery is relatively poor. The footprint of these libraries is usually quite large and unfocused. The goal of clibs is to provide stand-alone ""micro"" C libraries for developers to quickly install without coupling to large frameworks. You should use clib(1) to fetch these files for you and check them into your repository, the end-user and contributors should not require having clib(1) installed. This allows clib(1) to fit into any new or existing C workflow without friction. The wiki listing of packages acts as the ""registry"" and populates the clib-search(1) results. Usage   clib <command> [options]    Options:      -h, --help     Output this message     -v, --version  Output version information    Commands:      install [name...]  Install one or more packages     search [query]     Search for packages     help <cmd>         Display help for cmd  Examples Install a few dependencies to ./deps: $ clib install clibs/ms clibs/commander Install them to ./src instead: $ clib install clibs/ms clibs/commander -o src When installing libraries from the clibs org you can omit the name: $ clib install ms file hash Install some executables: $ clib install visionmedia/mon visionmedia/every visionmedia/watch package.json Example of a package.json explicitly listing the source: {   ""name"": ""term"",   ""version"": ""0.0.1"",   ""repo"": ""clibs/term"",   ""description"": ""Terminal ansi escape goodies"",   ""keywords"": [""terminal"", ""term"", ""tty"", ""ansi"", ""escape"", ""colors"", ""console""],   ""license"": ""MIT"",   ""src"": [""src/term.c"", ""src/term.h""] } Example of a package.json for an executable: {   ""name"": ""mon"",   ""version"": ""1.1.1"",   ""repo"": ""visionmedia/mon"",   ""description"": ""Simple process monitoring"",   ""keywords"": [""process"", ""monitoring"", ""monitor"", ""availability""],   ""license"": ""MIT"",   ""install"": ""make install"" } See explanation of package.json for more details. Contributing If you're interested in being part of this initiative let me know and I'll add you to the clibs organization so you can create repos here and contribute to existing ones. Articles Introducing Clib - introduction to clib The Advent of Clib: the C Package Manager - overview article about clib Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/clibs/clib"	"Simple Dynamic Strings; a library for handling C strings in a simpler way, but one that is compatible with normal C string functions. Available via.."	"true"
"Source Code Collections"	"bunch of libraries of its own"	"https://github.com/clibs/clib/wiki/Packages"	"Something of a package manager for C. Comes with a.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"2135"	"104"	"112"	"Packages · clibs/clib Wiki · GitHub Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 104 Star 2,135 Fork 112 clibs/clib Code Issues 20 Pull requests 2 Wiki Pulse Graphs Packages mikepb edited this page Apr 21, 2016 · 235 revisions Pages 3 Home Explanation of package.json Packages Clone this wiki locally Clone in Desktop List of available packages. This page is mined to populate clib-search(1). String manipulation clibs/buffer - tiny c-string library nami-doc/trim.c - trim a string, in place nami-doc/strlen.c - get a string's length jwerle/strsplit.h - Split a string into a char array by a given delimiter jwerle/chfreq.c - Compute character frequency in a string hkjels/slug.c - Create slug from a given string. stephenmathieson/case.c - string case conversion stephenmathieson/occurrences.c - Count occurrences in a string stephenmathieson/path-join.c - join a path stephenmathieson/path-normalize.c - normalize a path jb55/extname.c - get the extension of a file from a path stephenmathieson/rot13.c - Simple ROT13 stephenmathieson/str-ends-with.c - Check if a string ends with another string stephenmathieson/str-flatten.c - Flatten a char array stephenmathieson/str-replace.c - string replacement stephenmathieson/str-starts-with.c - Check if a string starts with another string stephenmathieson/substr.c - Get a substring of a string stephenmathieson/trim.c - string trim with left and right support dhobsd/vstring - A simple string building API for C chrisdew/sds - Antirez's Simple Dynamic Strings library michaelrhodes/path-basename.c - Find the last portion of a path. Similar to Node’s path.basename method. movesmyers/str-truncate.c - Simple string truncation clibs/wildcardcmp - Simple wildcard string comparison for C littlstar/asprintf.c - asprintf() implementation clibs/strndup - Safe implementation of strndup clibs/strdup - Safe implementation of strdup mattn/wcwidth - Determine columns needed for a wide character TingPing/ustring - Utils for safely handling utf8 strings. movesmyers/char-indices.c - Get an array of indices where a character exists in a string wooorm/stmr.c - Porter Stemmer algorithm gioyik/buffer-libc - Buffer C lib littlstar/trim.cc - C++ std::string trim util wooorm/levenshtein.c - Levenshtein’s string edit distance algorithm Utilities clibs/rgba - rgba color string parser clibs/unlikely - gcc branch prediction macros clibs/commander - expressive argument parser clibs/flag - Go style flag parsing clibs/ms - millisecond parser / formatter util clibs/bytes - byte-length parser / formatter util clibs/term - terminal utilities clibs/inih - INI parser jb55/rotate-bits.h - bitwise rotations jwerle/url.h - Parse URLs in C much like Node's url module. doches/progressbar - A library for displaying command-line progress bars jwerle/progress.h - Progress display lib for c jwerle/repl.h - Create a repl with eval/print/error hooks with given stdin, stdout, and stderr streams jwerle/getch.c - getch() implementation jwerle/usleep.h - usleep implementation using poll() or select() jwerle/libbacon - A C implementation of the Baconian Cipher ! BACON jwerle/libbeaufort - A C implementation of the Beaufort Cipher stephenmathieson/is-email.c - Loosely validate an email address thlorenz/gumbo-parser.c - HTML5 parser thlorenz/log.h - Minimal yet colorful logging lib sciascid/tree - convenient wrapper around BSD sys/tree.h. clehner/chains - Markov chains Constellation/console-colors.c - Write formatted string to console with colors stephenmathieson/expand-braces.c - Simple shell-like brace expansion stephenmathieson/wiki-registry.c - Turn a GitHub wiki page into a package registry xythobuz/serial - POSIX serial port interface with optional flow control support. lukedeo/cmd-parser - A Lightweight, header-only commandline parser clibs/mt19937ar - Mersenne Twister random number generator willemt/config-re - Data structure allows your program to be configured brendanashworth/genpassword.c - Random password generating library clibs/dumpasn1 - Displays contents of ASN.1 encoded data orangeduck/LuaAutoC - Automagically use C Functions and Structs with the Lua API Gioyik/color-sh - Display colors on your terminal Gioyik/c_printf - Color C lib for printf Gioyik/slim_color - Ultra simple C lib to output color nsf/termbox - Powerful but simple library for writing text-based user interfaces noporpoise/sort_r - Portable re-entrant qsort (qsort_r / qsort_s) Data structure yrmt/ArrayList - doubly linked list based on BSD TAILQ clibs/hash - hash library built on zhash clibs/list - simple doubly linked list clibs/red-black-tree - Generic red-black tree library (by Julienne Walker). thlorenz/sync-stream.c - synchronous stream implementation troydhanson/uthash - C macros for hash tables and more willemt/cbuffer - circular buffer willemt/bipbuffer - circular buffer alternative willemt/heap - heap priority queue willemt/pseudolru - pseudo least recently used cache willemt/bag - data structure which only has put and randomised take operations willemt/bitfield - easily get and set bits in a bitfield willemt/array-avl-tree - self balancing tree willemt/linked-list-hashmap - hashmap that uses linked lists for managing collisions willemt/quadratic-probing-hashmap - hashmap that uses quadratic probing (open addressing) for managing collisions rxi/vec - dynamic array jlcordeiro/cmap - map with string keys willemt/skiplist - Dictionary implemented through a skiplist willemt/linked-list-queue - Queue using a linked list willemt/meanqueue - An integer queue that calculates mean in O(1) willemt/chunkybar - Data structure that efficiently represents multi-piece progress bars willemt/farraylist - An arraylist that doesn't shift items so you can have ""holes"" between slots jonathanmarvens/hopscotch - A generic concurrent skip list library. mbucc/cqueue - OpenBSD's queue(3): linked lists and queues. clibs/lmdb - Symas Lightning Memory-Mapped Database (LMDB) willemt/arrayqueue - Queue implemented using an array AjayMT/dict.c - Simple dictionary implemented through a linked list AjayMT/list.c - Simple linked list skeeto/lstack - A lock-free stack using C11's new stdatomic.h features clehner/ll.c - Transparent linked lists kellydunn/libkld - Personal implementations of common datastructures. (List, Vector, Graph, Matrix, Tree, etc) willemt/duraqueue - Queue built to be durable under failure Gioyik/mapc - C lib for mapping neylsongularte/simple-linked-list-c - Linked list implementation Parsing clibs/logfmt - fast logfmt parser. clibs/jsmn - JSON parser. orangeduck/mpc - Parser Combinator Library for C willemt/torrent-reader - Read torrent files mbucc/js0n - Parse JSON. jb55/field-range-parser.c - Parse field ranges (like cut) brendanashworth/http-parser - http request/response parser for c h2non/semver.c - Semver 2.0 parser and render written in ANSI C Encoding/Decoding clibs/rle - Run-length encoding clibs/snappy - Snappy codec littlstar/uri.c - URI Component encoder/decoder mbucc/chtmlescape - HTML escape the characters '<', '>', '&', and '""' littlstar/b64.c - Base64 encode/decode jwerle/libutf8 - A whatwg compliant UTF8 encoding and decoding library willemt/bitstream - Let me write out bits to a stream willemt/fe - Flip the endianess of integers mikepb/endian.h - Portable endian conversion functions for C mattn/locale-string - Convert between locale string and utf-8 string georgy7/zlib - A massively spiffy yet delicately unobtrusive compression library. lemire/simdcomp - A simple C library for compressing lists of integers powturbo/TurboPFor - Fastest Integer Compression + Direct Access w/o decompression Filesystem jwerle/fs.c - File system API much like Node's fs module stephenmathieson/mkdirp.c - mkdir -p stephenmathieson/rimraf.c - rm -rf willemt/file2str - reads a file and returns contents as a string willemt/stubfile - for managing the creation of files where the content of the files will be written to randomly stephenmathieson/tempdir.c - An implementation of Python's tempfile.tempdir algorithm willemt/pidfile - Create a pidfile Hashing jwerle/murmurhash.c - MurmurHash3 general hash bashed lookup function implementation clibs/sha1 - sha1 hash algorithm jb55/sha256.c - sha256 hash algorithm zackehh/siphash-c - SipHash hash algorithm Net aisk/libae - Async event loop library extract from from redis jb55/anet.c - Basic TCP socket stuff made a bit less boring willemt/raft - C implementation of the Raft consensus protocol willemt/tracker-client - Connect to a bittorrent tracker willemt/pwp - A Bittorrent peer wire protocol implementation willemt/yabtorrent - Cross platform Bittorrent library clibs/amp - Abstract Message Protocol C implementation littlstar/request.cc - libcurl-backed HTTP request library for C++ Libraries clibs/uv - Cross-platform asychronous I/O clibs/leveldb - LevelDB is a fast key-value storage library written at Google that provides an ordered mapping from string keys to string values clibs/ck - Concurrency primitives, safe memory reclamation mechanisms and non-blocking data structures designed to aid in the research, design and implementation of high performance concurrent systems. beltex/libsmc - Apple System Management Controller (SMC) API brendanashworth/r3 - high-performance path dispatching library for the web qute/qute - AST generation library clibs/sophia - modern embeddable key-value database tzador/gl-matrix - Matrix and Vector library for High Performance OpenGL apps erf/stb - stb single-file public domain libraries for C/C++ Program flow jlcordeiro/threadpool - A simple thread pool implementation (POSIX) jwerle/async.h - Asynchronous goodies built on libuv stephenmathieson/batch.c - Simple async batch using pthreads clibs/trigger - Simple event handling library. thlorenz/ee.c - EventEmitter modeled after nodejs event emitter stephenmathieson/emitter.c - Tiny event emitter jwerle/throw.h - Create and throw errors easily clibs/coro - Coroutines in C tylertreat/chan - Pure C implementation of Go channels willemt/uv_multiplex - Let's share one TCP socket across multiple threads willemt/bmon - Batch work from multiple threads guillermocalvo/exceptions4c - An exception handling framework for C Serialization willemt/heapless-bencode - Bencode reader that doesn't use the heap willemt/streaming-bencode - Bencode reader that loves working with streams Testing/Quality Assurance orangeduck/ptest - DRY Microtesting for C clibs/debug - Conditional debug logging for C stephenmathieson/debug.c - Conditional debugging for C (again) hij1nx/debug - Conditional debug logging for C++ stephenmathieson/describe.h - Simple BDD testing utility jwerle/libok - Super tiny tap output library thlorenz/tap.c - tap test runner jlcordeiro/minunit - A minimal, header-only, unit testing framework. stephenmathieson/assertion-macros.h - simple assertion macros (assert_equal, assert_str_equal, etc.) silentbicycle/greatest - A C unit testing library in 1 file. No dependencies, no dynamic allocation willemt/cutest - C unit testing jeradesign/MinUnit - JTN002: A minimal unit testing framework for C compiler-dept/speck - A small unit testing framework for C Timing clibs/timestamp - millisecond resolution timestamps clibs/bench.h - get wall and cpu time for benchmarking clibs/timer - timer with microsecond resolution willemt/event-timer - A timer that fires events based off time brendanashworth/bench - easy to use, beautiful-looking benchmarking library opal-instruments/tiny-midi-clock - A small MIDI Beat Clock implementation with millisecond precision. Executables visionmedia/watch - periodically execute commands visionmedia/every - simple crontab alternative visionmedia/mon - simple process monitoring visionmedia/histo - display histograms from static or streaming input jb55/extname - get file extensions from arguments, see jb55/extname.c for library jb55/samp - Sample input given some probability jb55/pidpath - Get the executable path from a pid on OSX sphia/sphia - Command line utility for operations on a sophia database stephenmathieson/tabs-to-spaces - convert tabs to spaces in files stephenmathieson/sophia-repl - REPL for Sophia databases hij1nx/ldb - A c++ repl for leveldb tomerdmnt/levelfs - leveldb FUSE filesystem jonathanmarvens/netmask-tool - Simple netmask utility. lavoiesl/osx-cpu-temp - Outputs current CPU temperature in °C for OSX clibs/entr - A utility for running arbitrary commands when files change stephenmathieson/ghi - less opinionated clib-install for non clib-enabled repos remis-thoughts/shared-lib - A cross=platform tool for generating compiler options when creating shared libraries jwerle/suri - Set and get application URI schemes for OS X wooorm/stmr - Porter Stemmer CLI andik/makeheaders - make headers from .c source files (from http://www.hwaci.com/sw/mkhdr/) wooorm/levenshtein - Levenshtein’s string edit distance algorithm CLI nilsding/cnsc - C No Scope Commits: Angular commits minus scope and stuff OS Specific mattn/ansicolor-w32.c - ANSI color support on windows Plugins clibs/clib-uninstall - plugin for uninstalling executables clibs/clib-validate - validate a package.json Math jb55/bresenham-line.c - Bresenham's line drawing algorithm MauroMombelli/TrigonomeC - Basic implementation of 3d vector and quaternion MauroMombelli/FreeDCM - An implementation of Direct Cosine Matrix, a fast orientation algorithm willemt/minmax - min and max functions AVR opal-instruments/max7219-avr - max7219 LED Driver for AVR devices. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/clibs/clib/wiki/Packages"	"Something of a package manager for C. Comes with a.."	"true"
"Source Code Collections"	"gnulib"	"https://www.gnu.org/software/gnulib/"	"A collection of common GNU code. Various licenses, all free."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Gnulib - GNU Portability Library - GNU Project - Free Software Foundation Skip to main text Set language English [en] The  9th HACKERS MEETING  will be held in Rennes (France) from August 18 to 20. JOIN THE FSF Free Software Supporter GNU Operating System Sponsored by the Free Software Foundation About GNU Philosophy Licenses Education = Software = Documentation Help GNU Gnulib - The GNU Portability Library Introduction to Gnulib GNU software has a well-deserved reputation for running on many different types of systems. While our primary goal is to write software for the GNU system, many users and developers have been introduced to us through the systems that they were already using. Gnulib is a central location for common GNU code, intended to be shared among GNU packages. GCC has libiberty, but this is hard to disentangle from the GCC build tree. Gnulib takes a different approach. Its components are intended to be shared at the source level, rather than being a library that gets built, installed, and linked against. Thus, there is no distribution tarball; the idea is to copy files from Gnulib into your own source tree. Gnulib also includes copies of a few files purely for convenience: the GNU coding standards, the GNU maintainer information, the GPL and other licenses (in Texinfo), assorted configuration scripts, and more. The goal is to provide all the common infrastructure needed by GNU packages. Downloading Gnulib Gnulib does not make releases. It is intended to be used at the source level. You can browse the current gnulib sources on Savannah. To use Gnulib, you can retrieve its source code and its history via anonymous Git, using the following shell command: git clone git://git.savannah.gnu.org/gnulib.git  Developers can also retrieve the source code via non-anonymous Git, for purposes of doing commits; for details, please see Gnulib's top-level README file. After you have the sources, run ./gnulib-tool --help. For help and more info, see the documentation and other resources below. Documentation The manual is still minimal and sketchy (volunteers especially welcome). ./gnulib-tool --help also provides some information, as mentioned above. You can also view the modules comprising gnulib. Mailing lists bug-gnulib@gnu.org is used to discuss most aspects of Gnulib, including development and enhancement requests, as well as bug reports. Getting involved If you think you have found a bug in Gnulib, then please send as complete a report as possible to the mailing list above. If you would like any new feature to be included in future versions of Gnulib, please send a request to the mailing list above. Please remember that development of Gnulib is a volunteer effort, and you can also contribute to its development. For information about contributing to the GNU Project in general, please read How to help GNU. Here are some guidelines for people wishing to contribute to Gnulib: If your .c and .h files define functions that are broken or missing on some other system, we should be able to include it. If your functions remove arbitrary limits from existing functions (either under the same name, or as a slightly different name), we should be able to include it. If your functions define completely new but rarely used functionality, you should probably consider packaging it as a separate library. All Gnulib source code is copylefted by the Free Software Foundation. Assignment forms may be necessary before we can access your source code. Contributors Principal active contributors to Gnulib: Eric Blake, Jim Meyering, Pádraig Brady, Paul Eggert, and Simon Josefsson. Please use the mailing list for contact. GNU home page FSF home page GNU Art GNU's Who? Free Software Directory Hardware Site map “Our mission is to preserve, protect and promote the freedom to use, study, copy, modify, and redistribute computer software, and to defend the rights of Free Software users.” The Free Software Foundation is the principal organizational sponsor of the GNU Operating System. Support GNU and the FSF by buying manuals and gear, joining the FSF as an associate member, or making a donation, either directly to the FSF or via Flattr. back to top Please send general FSF & GNU inquiries to <gnu@gnu.org>. There are also other ways to contact the FSF. Broken links and other corrections or suggestions can be sent to <bug-gnulib@gnu.org>. Please see the Translations README for information on coordinating and submitting translations of this article. Copyright © 2014 Free Software Foundation, Inc. This page is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License. Copyright Infringement Notification Updated: $Date: 2016/04/25 21:18:41 $"	"null"	"null"	"A collection of common GNU code. Various licenses, all free."	"true"
"Source Code Collections"	"libdjb"	"http://www.fefe.de/djb/"	"A collection of libraries doing various things. (Apparently) public domain."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"The libdjb project (Note: This has not been touched since 2000, use instead) Recent changes: implement socket_sendfile and socket_getifidx, work around broken BSD includes. What is it? This project aims to make the excellent libraries from Dan Bernstein available to a wider public by extracting them from his packages and providing a minimal Makefile for each library. So far, I extracted the alloc, buffer, byte, dns, tai, timeoutconn and unix libraries (iopause and timeoutconn are not libraries in djb's software but I made them into libraries for easier use), but since they share some include files (I hardlinked them in the respective directories so you can still use each library completely on its own) and the whole package is below 40k when compressed with bzip2, I chose to distribute them in one package. The package also comes with a few undocumented perl scripts that will hopefully evolve into a system that allows you to incorporate the libraries into your code easily. You can reach me as felix-djb@fefe.de. Licensing terms? The same as the rest of Bernstein's code. See http://cr.yp.to/softwarelaw.html. Actually, Bernstein explicitly declared parts of his work to be public domain, for example the tai code that is included in libdjb (albeit not documented yet). What do the libraries do? alloc.a contains wrappers around memory allocation, stralloc (dynamic strings) buffer.a contains buffered I/O byte.a contains formatting, scanning and other string routines dns.a contains a full blown DNS resolver tai.a contains an abstraction for 64-bit system time timeout.a contains versions of several socket routines with user specified timeout unix.a contains wrappers for socket functions, mkfifo, opendir, wait and an abstraction around errno. sig.a contains wrappers for Unix signal functions. Did you add anything? Yes. See news.html for a list of recent changes. Every directory now also contains a ""make clean"" target. unix also contains IPv6 versions of djb's socket routines, env and iopause. dns also contains support for resolving IPv6 addresses. byte also contains implementations for scan_0x and fmt_xlong, and support for parsing and formatting IPv6 numbers. timeoutconn.o was taken from ucspi-tcp, I added a timeoutconn6.o for IPv6 and called the result timeoutconn.a. Converted K&R prototypes to ANSI Changed uint32 and uint64 checks to allow cross compiling added byte_dup and str_dup functions to create a malloced copy The IPv6 socket routines in unix.a look and feel like the IPv4 routines except that the IPs are now 16 instead of 4 bytes long. The routines will compile and work even if you don't have IPv6 support in your system, so you can write IPv6 code that is 100% backwards compatible to IPv4 without making your code unreadable with tons of #ifdefs and conversion code all over the place. Or, even easier, use my IPv6 patches to ucspi-tcp and completely get rid of transport protocol dependencies in your code! Where can I download it? Just grab djb-0.5.2.tar.bz2. See also a GPL reimplementation efford of libdjb. my diet libc. my IPv6 patches to djbdns my IPv6 patches to ucspi-tcp. These two spawned the project my ncp rewrite using libdjb. This is my first program using libdjb. superscript djblib appears to be a similar project (without IPv6 though)"	"null"	"null"	"A collection of libraries doing various things. (Apparently) public domain."	"true"
"Standard Libraries"	"Bionic"	"https://github.com/android/platform_bionic"	"Google's C standard library, developed for Android.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"262"	"59"	"247"	"GitHub - android/platform_bionic Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 59 Star 262 Fork 247 android/platform_bionic mirrored from https://android.googlesource.com/platform/bionic.git Code Pull requests 1 Wiki Pulse Graphs No description or website provided. 16,990 commits 87 branches 266 releases 114 contributors C 69.8% Assembly 16.5% C++ 12.5% Python 0.8% Makefile 0.3% Shell 0.1% C Assembly C++ Python Makefile Shell Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags brillo-m7-dev brillo-m7-mr-dev brillo-m7-release brillo-m8-dev brillo-m8-release brillo-m9-dev brillo-m9-release brillo-m10-dev brillo-m10-release donut-release donut-release2 eclair-passion-release eclair-release eclair-sholes-release eclair-sholes-release2 froyo-release froyo gingerbread-mr4-release gingerbread-release gingerbread ics-factoryrom-2-release ics-mr0-release ics-mr0 ics-mr1-release ics-mr1 ics-plus-aosp idea133-weekly-release idea133 jb-dev jb-mr0-release jb-mr1-dev-plus-aosp jb-mr1-dev jb-mr1-release jb-mr1.1-cts-dev jb-mr1.1-dev-plus-aosp jb-mr1.1-dev jb-mr1.1-release jb-mr2-cts-dev jb-mr2-dev jb-mr2-release jb-mr2.0-release jb-mr2.0.0-release jb-release kitkat-cts-dev kitkat-cts-release kitkat-dev kitkat-mr1-release kitkat-mr1.1-release kitkat-mr2-release kitkat-mr2.1-release kitkat-mr2.2-release kitkat-release kitkat-wear l-preview lollipop-cts-dev lollipop-cts-release lollipop-dev lollipop-mr1-cts-dev lollipop-mr1-cts-release lollipop-mr1-dev lollipop-mr1-fi-release lollipop-mr1-release lollipop-mr1-wfc-release lollipop-release lollipop-wear-release marshmallow-cts-dev marshmallow-cts-release marshmallow-dev marshmallow-dr-dev marshmallow-dr-dragon-release marshmallow-dr-release marshmallow-dr1.5-dev marshmallow-dr1.5-release marshmallow-dr1.6-release marshmallow-mr1-dev marshmallow-mr1-release marshmallow-mr2-release marshmallow-release master-soong master ndk-r11-release ndk-r12-release studio-1.1-release tools_r20 tools_r21 tools_r22 tools_r22.2 Nothing to show ndk-r12b ndk-r12-beta2 ndk-r12-beta1 ndk-r11 ndk-r11c ndk-r11b android-wear-n-preview-3 android-wear-5.1.1_r1 android-wear-5.1.0_r1 android-wear-5.0.0_r1 android-sdk-support_r11 android-sdk-adt_r20 android-sdk-adt_r16.0.1 android-sdk-4.4.2_r1.0.1 android-sdk-4.4.2_r1 android-sdk-4.0.3_r1 android-sdk-4.0.3-tools_r1 android-n-preview-4 android-n-preview-3 android-n-preview-2 android-n-preview-1 android-m-preview android-m-preview-2 android-m-preview-1 android-l-preview_r2 android-cts-verifier-4.0.3_r1 android-cts-verifier-4.0_r1 android-cts-6.0_r8 android-cts-6.0_r7 android-cts-6.0_r6 android-cts-6.0_r5 android-cts-6.0_r4 android-cts-6.0_r3 android-cts-6.0_r2 android-cts-6.0_r1 android-cts-5.1_r9 android-cts-5.1_r8 android-cts-5.1_r7 android-cts-5.1_r6 android-cts-5.1_r5 android-cts-5.1_r4 android-cts-5.1_r3 android-cts-5.1_r2 android-cts-5.1_r1 android-cts-5.0_r8 android-cts-5.0_r7 android-cts-5.0_r6 android-cts-5.0_r5 android-cts-5.0_r4 android-cts-5.0_r3 android-cts-4.4_r4 android-cts-4.4_r1 android-cts-4.2_r2 android-cts-4.2_r1 android-cts-4.1_r4 android-cts-4.1_r2 android-cts-4.1_r1 android-cts-4.0.3_r2 android-cts-4.0.3_r1 android-cts-4.0_r1 android-cts-2.3_r12 android-cts-2.3_r11 android-cts-2.3_r10 android-cts-2.2_r8 android-6.0.1_r55 android-6.0.1_r54 android-6.0.1_r53 android-6.0.1_r52 android-6.0.1_r51 android-6.0.1_r50 android-6.0.1_r49 android-6.0.1_r48 android-6.0.1_r47 android-6.0.1_r46 android-6.0.1_r45 android-6.0.1_r43 android-6.0.1_r42 android-6.0.1_r41 android-6.0.1_r40 android-6.0.1_r33 android-6.0.1_r32 android-6.0.1_r31 android-6.0.1_r30 android-6.0.1_r28 android-6.0.1_r27 android-6.0.1_r26 android-6.0.1_r25 android-6.0.1_r24 android-6.0.1_r22 android-6.0.1_r21 android-6.0.1_r20 android-6.0.1_r18 android-6.0.1_r17 android-6.0.1_r16 android-6.0.1_r13 android-6.0.1_r12 android-6.0.1_r11 android-6.0.1_r10 android-6.0.1_r9 android-6.0.1_r8 Nothing to show New pull request Fetching latest commit… Cannot retrieve the latest commit at this time. Permalink Failed to load latest commit information. benchmarks Convert bionic benchmarks and tests to Android.bp Jul 14, 2016 build Convert bionic benchmarks and tests to Android.bp Jul 14, 2016 libc Add an alias for _CTYPE_N. Jul 15, 2016 libdl Remove deprecated Android.mk files May 26, 2016 libm Don't expose all BSD extensions. Jun 13, 2016 libstdc++ Remove libstdc++ include files. May 27, 2016 linker Fix typo in the comment Jul 14, 2016 tests Convert bionic benchmarks and tests to Android.bp Jul 14, 2016 tools Fix clean mma in bionic Jul 14, 2016 .clang-format Fix .clang-format ContinuationIndentWidth. Jun 1, 2016 .gitignore Merge memory checking functionality from sandbox Feb 16, 2010 Android.bp Use Android.soong.mk to handle mixed Android.mk and Android.bp dirs May 16, 2016 Android.mk Rename Android.soong.mk to Android.mk Jul 11, 2016 CPPLINT.cfg Add primitive CPPLINT.cfg. Jan 29, 2015 CleanSpec.mk Make jemalloc the default choice. Jul 11, 2014 README.md Update the ""adding a syscall"" docs. May 26, 2016 README.md Working on bionic What are the big pieces of bionic? libc/ --- libc.so, libc.a The C library. Stuff like fopen(3) and kill(2). libm/ --- libm.so, libm.a The math library. Traditionally Unix systems kept stuff like sin(3) and cos(3) in a separate library to save space in the days before shared libraries. libdl/ --- libdl.so The dynamic linker interface library. This is actually just a bunch of stubs that the dynamic linker replaces with pointers to its own implementation at runtime. This is where stuff like dlopen(3) lives. libstdc++/ --- libstdc++.so The C++ ABI support functions. The C++ compiler doesn't know how to implement thread-safe static initialization and the like, so it just calls functions that are supplied by the system. Stuff like __cxa_guard_acquire and __cxa_pure_virtual live here. linker/ --- /system/bin/linker and /system/bin/linker64 The dynamic linker. When you run a dynamically-linked executable, its ELF file has a DT_INTERP entry that says ""use the following program to start me"". On Android, that's either linker or linker64 (depending on whether it's a 32-bit or 64-bit executable). It's responsible for loading the ELF executable into memory and resolving references to symbols (so that when your code tries to jump to fopen(3), say, it lands in the right place). tests/ --- unit tests The tests/ directory contains unit tests. Roughly arranged as one file per publicly-exported header file. benchmarks/ --- benchmarks The benchmarks/ directory contains benchmarks. What's in libc/? libc/   arch-arm/   arch-arm64/   arch-common/   arch-mips/   arch-mips64/   arch-x86/   arch-x86_64/     # Each architecture has its own subdirectory for stuff that isn't shared     # because it's architecture-specific. There will be a .mk file in here that     # drags in all the architecture-specific files.     bionic/       # Every architecture needs a handful of machine-specific assembler files.       # They live here.     include/       machine/         # The majority of header files are actually in libc/include/, but many         # of them pull in a  for things like limits,         # endianness, and how floating point numbers are represented. Those         # headers live here.     string/       # Most architectures have a handful of optional assembler files       # implementing optimized versions of various routines. The        # functions are particular favorites.     syscalls/       # The syscalls directories contain script-generated assembler files.       # See 'Adding system calls' later.    include/     # The public header files on everyone's include path. These are a mixture of     # files written by us and files taken from BSD.    kernel/     # The kernel uapi header files. These are scrubbed copies of the originals     # in external/kernel-headers/. These files must not be edited directly. The     # generate_uapi_headers.sh script should be used to go from a kernel tree to     # external/kernel-headers/ --- this takes care of the architecture-specific     # details. The update_all.py script should be used to regenerate bionic's     # scrubbed headers from external/kernel-headers/.    private/     # These are private header files meant for use within bionic itself.    dns/     # Contains the DNS resolver (originates from NetBSD code).    upstream-freebsd/   upstream-netbsd/   upstream-openbsd/     # These directories contain unmolested upstream source. Any time we can     # just use a BSD implementation of something unmodified, we should.     # The structure under these directories mimics the upstream tree,     # but there's also...     android/       include/         # This is where we keep the hacks necessary to build BSD source         # in our world. The *-compat.h files are automatically included         # using -include, but we also provide equivalents for missing         # header/source files needed by the BSD implementation.    bionic/     # This is the biggest mess. The C++ files are files we own, typically     # because the Linux kernel interface is sufficiently different that we     # can't use any of the BSD implementations. The C files are usually     # legacy mess that needs to be sorted out, either by replacing it with     # current upstream source in one of the upstream directories or by     # switching the file to C++ and cleaning it up.    malloc_debug/     # The code that implements the functionality to enable debugging of     # native allocation problems.    stdio/     # These are legacy files of dubious provenance. We're working to clean     # this mess up, and this directory should disappear.    tools/     # Various tools used to maintain bionic.    tzcode/     # A modified superset of the IANA tzcode. Most of the modifications relate     # to Android's use of a single file (with corresponding index) to contain     # time zone data.   zoneinfo/     # Android-format time zone data.     # See 'Updating tzdata' later.  Adding system calls Adding a system call usually involves: Add entries to SYSCALLS.TXT. See SYSCALLS.TXT itself for documentation on the format. Run the gensyscalls.py script. Add constants (and perhaps types) to the appropriate header file. Note that you should check to see whether the constants are already in kernel uapi header files, in which case you just need to make sure that the appropriate POSIX header file in libc/include/ includes the relevant file or files. Add function declarations to the appropriate header file. Add the function name to the correct section in libc/libc.map.txt and run ./libc/tools/genversion-scripts.py. Add at least basic tests. Even a test that deliberately supplies an invalid argument helps check that we're generating the right symbol and have the right declaration in the header file, and that you correctly updated the maps in step 5. (You can use strace(1) to confirm that the correct system call is being made.) Updating kernel header files As mentioned above, this is currently a two-step process: Use generate_uapi_headers.sh to go from a Linux source tree to appropriate contents for external/kernel-headers/. Run update_all.py to scrub those headers and import them into bionic. Updating tzdata This is fully automated (and these days handled by the libcore team, because they own icu, and that needs to be updated in sync with bionic): Run update-tzdata.py in external/icu/tools/. Verifying changes If you make a change that is likely to have a wide effect on the tree (such as a libc header change), you should run make checkbuild. A regular make will not build the entire tree; just the minimum number of projects that are required for the device. Tests, additional developer tools, and various other modules will not be built. Note that make checkbuild will not be complete either, as make tests covers a few additional modules, but generally speaking make checkbuild is enough. Running the tests The tests are all built from the tests/ directory. Device tests $ mma $ adb remount $ adb sync $ adb shell /data/nativetest/bionic-unit-tests/bionic-unit-tests32 $ adb shell \     /data/nativetest/bionic-unit-tests-static/bionic-unit-tests-static32 # Only for 64-bit targets $ adb shell /data/nativetest64/bionic-unit-tests/bionic-unit-tests64 $ adb shell \     /data/nativetest64/bionic-unit-tests-static/bionic-unit-tests-static64  Host tests The host tests require that you have lunched either an x86 or x86_64 target. $ mma $ mm bionic-unit-tests-run-on-host32 $ mm bionic-unit-tests-run-on-host64  # For 64-bit *targets* only.  Against glibc As a way to check that our tests do in fact test the correct behavior (and not just the behavior we think is correct), it is possible to run the tests against the host's glibc. The executables are already in your path. $ mma $ bionic-unit-tests-glibc32 $ bionic-unit-tests-glibc64  Gathering test coverage For either host or target coverage, you must first: $ export NATIVE_COVERAGE=true Note that the build system is ignorant to this flag being toggled, i.e. if you change this flag, you will have to manually rebuild bionic. Set bionic_coverage=true in libc/Android.mk and libm/Android.mk. Coverage from device tests $ mma $ adb sync $ adb shell \     GCOV_PREFIX=/data/local/tmp/gcov \     GCOV_PREFIX_STRIP=`echo $ANDROID_BUILD_TOP | grep -o / | wc -l` \     /data/nativetest/bionic-unit-tests/bionic-unit-tests32 $ acov  acov will pull all coverage information from the device, push it to the right directories, run lcov, and open the coverage report in your browser. Coverage from host tests First, build and run the host tests as usual (see above). $ croot $ lcov -c -d $ANDROID_PRODUCT_OUT -o coverage.info $ genhtml -o covreport coverage.info # or lcov --list coverage.info  The coverage report is now available at covreport/index.html. Attaching GDB to the tests Bionic's test runner will run each test in its own process by default to prevent tests failures from impacting other tests. This also has the added benefit of running them in parallel, so they are much faster. However, this also makes it difficult to run the tests under GDB. To prevent each test from being forked, run the tests with the flag --no-isolate. 32-bit ABI bugs This probably belongs in the NDK documentation rather than here, but these are the known ABI bugs in the 32-bit ABI: time_t is 32-bit. http://b/5819737. In the 64-bit ABI, time_t is 64-bit. off_t is 32-bit. There is off64_t, and in newer releases there is almost-complete support for _FILE_OFFSET_BITS. Unfortunately our stdio implementation uses 32-bit offsets and -- worse -- function pointers to functions that use 32-bit offsets, so there's no good way to implement the last few pieces http://b/24807045. In the 64-bit ABI, off_t is off64_t. sigset_t is too small on ARM and x86 (but correct on MIPS), so support for real-time signals is broken. http://b/5828899 In the 64-bit ABI, sigset_t is the correct size for every architecture. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/android/platform_bionic"	"Google's C standard library, developed for Android.."	"true"
"Standard Libraries"	"dietlibc"	"http://www.fefe.de/dietlibc/"	"A C standard library designed for the smallest possible binaries. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"null"	"null"	"null"	"diet libc - a libc optimized for small size diet libc - a libc optimized for small size [Other pages for this project: freshmeat, advogato, gnu.org] Person who say it cannot be done should not interrupt person doing it. --Chinese Proverb What is it? The diet libc is a libc that is optimized for small size. It can be used to create small statically linked binaries for Linux on alpha, arm, hppa, ia64, i386, mips, s390, sparc, sparc64, ppc and x86_64. The latest version is always available via anonymous CVS (which is the recommended way to get the sources):  $ cvs -d :pserver:cvs@cvs.fefe.de:/cvs -z9 co dietlibc  There is a mailing list for the diet libc. You can subscribe by sending an empty email to dietlibc-subscribe@fefe.de; it is run by ezmlm. There is an archive of precompiled binaries at foobar.math.fu-berlin.de. Please read the FAQ if you have any questions. The diet libc would not be possible without the many many contributors. To acknowledge their work, I created this scoreboard. Recent News [20130312] dietlibc-0.33 [GPG sig] has been released (no diff this time). Here are the changes. [20090529] dietlibc-0.32 [GPG sig] (diff from 0.31 [GPG sig]) has been released. Here are the changes. [20070824] dietlibc-0.31 [GPG sig] (diff from 0.30 [GPG sig]) has been released. Here are the changes. [20060621] dietlibc-0.30 [GPG sig] (diff from 0.29 [GPG sig]) has been released. Here are the changes. [20050520] dietlibc-0.29 [GPG sig] (diff from 0.28 [GPG sig]) has been released. Here are the changes. [20050131] dietlibc-0.28 [GPG sig] (diff from 0.27 [GPG sig]) has been released. Here are the changes. [20040729] dietlibc-0.27 [GPG sig] (diff from 0.26 [GPG sig]) has been released. Here are the changes. [20040603] dietlibc-0.26 [GPG sig] (diff from 0.25 [GPG sig]) has been released. Here are the changes. [20040327] dietlibc-0.25 [GPG sig] (diff from 0.24 [GPG sig]) has been released. Here are the changes. [20031205] Made a Credits Scoreboard where I give points to everyone helping with the diet libc. [20031121] dietlibc-0.24 [GPG sig] (diff from 0.23 [GPG sig]) has been released. Here are the changes. [20030912] dietlibc-0.23 [GPG sig] (diff from 0.22 [GPG sig]) has been released. Here are the changes. [20030218] dietlibc-0.22 [GPG sig] (diff from 0.21) has been released. Here are the changes. [20021004] dietlibc-0.21 [GPG sig] (diff from 0.20) has been released. Here are the changes. [20020810] dietlibc-0.20 (diff from 0.19) has been released. Here are the changes. [20020805] dietlibc-0.19 (diff from 0.18) has been released. Here are the changes. This release contains security fixes! [20020710] dietlibc-0.18 (diff from 0.17) has been released. Here are the changes. [20020503] dietlibc-0.17 (diff from 0.16) has been released. Here are the changes. [20020322] dietlibc-0.16 (diff from 0.15) has been released. Here are the changes. [20020221] dietlibc-0.15 (diff from 0.14) has been released. Here are the changes. [20020129] dietlibc-0.14 (diff from 0.13) has been released. Here are the changes. [20020112] The diet libc is now hosted at your local ftp.kernel.org mirror, in /pub/linux/libs/dietlibc (please give it a little time to propagate). Thanks, HPA! [20020111] Thomas Ogrisegg unceremoniously sent me a few patches to port the diet libc to HP's PA-RISC architecture! Hooray! [20020109] dietlibc-0.13 (diff from 0.12) has been released. Here are the changes. I also updated the FAQ. [oldnews] Documentation The diet libc does not contain man pages yet. I recommend using the Single Unix Specification or the Linux man pages. Please do read the Frequently Asked Questions (with answers) list if you have any question! Or you can read slides from my talk at Linux Kongress 2001 or at Chemnitzer Linux Tag 4 (and previously Chaos Communication Congress 2001, same contents but in German). Writing Small Software (German version held at Chemnitzer Linux Tag 4). What does dietlibc include? Here is a list of the exported symbols. Licensing terms? The diet libc is covered by the GNU General Public License Version 2. Other licensing terms (e.g. for commercial projects) can be negotiated for substantial contributors or project sponsors. See also DietLinux! A boot floppy based on the diet libc (see also this directory Fabrice Bellard's Tiny C Compiler. You can't compile the diet libc with it. Olaf's patches the libdjb project and the libowfat project ugrep by Jens Lass, a mini grep of 11k! small utils (dd, cat, touch, cp, rm and mv using diet libc, no bloat, no features except the bare minimum ;-}) The ELKS project's libc is very lean, too. shi-sh, a small shell using libowfat and dietlibc (link broken) LZMA utils in C (the regular ones are in C++ and thus do not work with dietlibc) fgetty, a very small getty fget, a very small http/ftp fetcher my ncp rewrite using libdjb. This is my first program using libdjb and it was the testing ground for dietlibc. my embedded utils project, a collection of popular class utilities like mkdir and echo, targeted specifically at diet libc and small size. A small sed for diet libc. The heirloom project aims to port the original Unix userland to modern Unixes. Very cool project, although it only works partially with the diet libc until I finally add wide char routines. uclibc.org hosts another open source project called ""uClibc"" that seems to be quite close to dietlibc. trio. trio aims to be a portable and complete scanf and printf implementation. If the diet libc implementation misses a feature that you need, you might want to look at trio. www.linuxassembly.org is also interested in small programs, but they are limiting themselves to x86. libsys by Rick Hohensee. The PowerPC EMbedded Systems HOWTO and the Linux Assembly HOWTO may both be relevant. The e3 editor is an impressively small editor. It has an x86 assembly version and a C version that works just fine with the diet libc. dnetc linux is a floppy linux using the diet libc. Pauls Boot CD uses the diet libc for linuxrc. sw-ports links many packages with the diet libc. fdlibm, a free math library xyssl, a small ssl library (client-side only, ~100k, APIs not openssl compatible)"	"null"	"null"	"A C standard library designed for the smallest possible binaries. only."	"true"
"Standard Libraries"	"glibc"	"http://www.gnu.org/software/libc/"	"The GNU C Library; an implementation of the C standard library. only."	"null"	"null"	"null"	"GNU LGPL2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"null"	"null"	"null"	"The GNU C Library The GNU C Library (glibc) About glibc Documentation Download Development Bugs Overview Any Unix-like operating system needs a C library: the library which defines the ``system calls'' and other basic facilities such as open, malloc, printf, exit... The GNU C Library is used as the C library in the GNU system and in GNU/Linux systems, as well as many other systems that use Linux as the kernel. Project Goals The GNU C Library is primarily designed to be a portable and high performance C library. It follows all relevant standards including ISO C11 and POSIX.1-2008. It is also internationalized and has one of the most complete internationalization interfaces known. Current Status The current stable version of glibc is 2.23. See the NEWS file in the glibc sources for more information. Latest News 2016-02-19: glibc 2.23 released. 2016-02-16: CVE-2015-7547: glibc getaddrinfo() stack-based buffer overflow -- Fixed on development branch for glibc 2.23 release. 2015-08-14: glibc 2.22 released. 2015-02-06: glibc 2.21 released. 2014-09-07: glibc 2.20 released. 2014-02-08: glibc 2.19 released. 2013-08-12: glibc 2.18 released. History The history of Unix and various standards determine much of the interface of the C library. In general the GNU C Library supports the ISO C and POSIX standards. We also try to support the features of popular Unix variants (including BSD and System V) when those do not conflict with the standards. Different compatibility modes (selectable when you compile an application) allow the peaceful coexistence of compatibility support for different varieties of Unix. People The GNU C Library is currently maintained by a community of developers many of which are listed on the MAINTAINERS page of the project wiki. Many others have contributed in large amounts as documented in the glibc Contributors. Thank you to all who have contributed, either in bug reports, or by answering a question, your help is appreciated. Last modified on 2016-02-22"	"null"	"null"	"The GNU C Library; an implementation of the C standard library. only."	"true"
"Standard Libraries"	"musl"	"http://www.musl-libc.org/"	"A standard C library, compatible with POSIX 2008 and C11. Designed for static linking.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"null"	"null"	"null"	"musl libc musl libc Home Introduction FAQ How to use Support Documentation Download Browse Source Community Wiki Welcome to the home of musl, a new standard library to power a new generation of Linux-based devices. musl is lightweight, fast, simple, free, and strives to be correct in the sense of standards-conformance and safety. See how musl compares to other major libcs."	"null"	"null"	"A standard C library, compatible with POSIX 2008 and C11. Designed for static linking.."	"true"
"String Manipulation"	"bstrlib"	"http://bstring.sourceforge.net/"	"The Better String Library. Dual-licensed under or only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"null"	"null"	"null"	"The Better String Library The Better String Library by Paul Hsieh GIT - src 08/27/2015 GIT - zip 08/27/2015 EXAMPLES 09/28/2006 Documentation bstring.txt Security Statement security.txt Porting Guide porting.txt Frequently Asked Questions Bstrlib FAQ Comparisons Comparison Table Usage Licenses BSD license GPL license Discussion Developer Forum Contact email Paul Hsieh Introduction The Better String Library is an abstraction of a string data type which is superior to the C library char buffer string type, or C++'s std::string. Among the features achieved are: Substantial mitigation of buffer overflow/overrun problems and other failures that result from erroneous usage of the common C string library functions Significantly simplified string manipulation High performance interoperability with other source/libraries which expect '\0' terminated char buffers Improved overall performance of common string operations Functional equivalency with other more modern languages The library is totally stand alone, portable (known to work with gcc/g++, MSVC++, Intel C++, WATCOM C/C++, Turbo C, Borland C++, IBM's native CC compiler on Windows, Linux and Mac OS X), high performance, easy to use and is not part of some other collection of data structures. Even the file I/O functions are totally abstracted (so that other stream-like mechanisms, like sockets, can be used.) Nevertheless, it is adequate as a complete replacement of the C string library for string manipulation in any C program. The library includes a robust C++ wrapper that uses overloaded operators, rich constructors, exceptions, stream I/O and STL to make the CBString struct a natural and powerful string abstraction with more functionality and higher performance than std::string. Bstrlib is stable, well tested and suitable for any software production environment."	"null"	"null"	"The Better String Library. Dual-licensed under or only."	"true"
"String Manipulation"	"ICU"	"http://site.icu-project.org/"	"International Components for Unicode; a library for Unicode support.."	"null"	"null"	"null"	"ICU license"	"http://source.icu-project.org/repos/icu/icu/trunk/license.html"	"null"	"null"	"null"	"null"	"null"	"ICU - International Components for Unicode ICU - International Components for Unicode Search this site Navigation Unicode About ICU · ICU Home · Download ICU Demos & Tools · ICU4C Demos · ICU Collation Demo · ICU4J Demos · Data Customizer Documents · User Guide · ICU FAQ · ICU4J FAQ · Docs & Papers API References Official Release · ICU4C (57.1) · ICU4J (57.1) Latest Development Version · N/A Data & Charts · Conversion Tables · Feature Comparisons · Performance & Size Development · Project Information · Design Docs · Source Repository · Processes · Members-Only Area Bugs & Contacts · Bugs · Feature Requests · Mailing Lists · Feedback Sitemap ICU-TC Home Page News 2016-05-18: The Unicode® Consortium has announced that it will host development of the ICU libraries. The ICU Project Management Committee is now a Unicode Technical Committee, the ICU-TC. ICU will continue to be released under a similar open source license. For more details, see the Unicode announcement. 2016-03-23: ICU 57.1 is now available. For details about new features and other improvements, see ICU 57 download page. Contents 1 News 2 What is ICU? 3 Why Unicode? 4 Why ICU4C? 5 Why ICU4J? 6 ICU4JNI 7 Who Uses ICU? 7.1 Companies and Organizations using ICU 7.2 Apache Projects 7.3 Products from IBM 7.4 Products from Google 7.5 Products from Apple 7.6 Products from Harman/Becker 7.7 Related Projects Schedule 2016-03-23 57 Release (57.1) 2016-07-01 58 Milestone 1 (tag only) 2016-09-15 58 Release Candidate 2016-10-01 58 Release (58.1) What is ICU? ICU is a mature, widely used set of C/C++ and Java libraries providing Unicode and Globalization support for software applications. ICU is widely portable and gives applications the same results on all platforms and between C/C++ and Java software. ICU is released under a nonrestrictive open source license that is suitable for use with both commercial software and with other open source or free software. Here are a few highlights of the services provided by ICU: Code Page Conversion: Convert text data to or from Unicode and nearly any other character set or encoding. ICU's conversion tables are based on charset data collected by IBM over the course of many decades, and is the most complete available anywhere. Collation: Compare strings according to the conventions and standards of a particular language, region or country. ICU's collation is based on the Unicode Collation Algorithm plus locale-specific comparison rules from the Common Locale Data Repository, a comprehensive source for this type of data. Formatting: Format numbers, dates, times and currency amounts according the conventions of a chosen locale. This includes translating month and day names into the selected language, choosing appropriate abbreviations, ordering fields correctly, etc. This data also comes from the Common Locale Data Repository. Time Calculations: Multiple types of calendars are provided beyond the traditional Gregorian calendar. A thorough set of timezone calculation APIs are provided. Unicode Support: ICU closely tracks the Unicode standard, providing easy access to all of the many Unicode character properties, Unicode Normalization, Case Folding and other fundamental operations as specified by the Unicode Standard. Regular Expression: ICU's regular expressions fully support Unicode while providing very competitive performance. Bidi: support for handling text containing a mixture of left to right (English) and right to left (Arabic or Hebrew) data. Text Boundaries: Locate the positions of words, sentences, paragraphs within a range of text, or identify locations that would be suitable for line wrapping when displaying the text. And much more. Refer to the ICU User Guide for details. Why Unicode? Unicode (and the parallel ISO 10646 standard) defines the character set necessary for efficiently processing text in any language and for maintaining text data integrity. In addition to global character coverage, the Unicode standard is unique among character set standards because it also defines data and algorithms for efficient and consistent text processing. This simplifies high-level processing and ensures that all conformant software produces the same results. The widespread adoption of Unicode over the last decade made text data truly portable and formed a cornerstone of the Internet. Unicode overview What is Unicode? Globalized software, based on Unicode, maximizes market reach and minimizes cost. Globalized software is built and installed once and yet handles text for and from users worldwide and accomodates their cultural conventions. It minimizes cost by eliminating per-language builds, installations, and maintenance updates. Why ICU4C? The C and C++ languages and many operating system environments do not provide full support for Unicode and standards-compliant text handling services. Even though some platforms do provide good Unicode text handling services, portable application code can not make use of them. The ICU4C libraries fills in this gap. ICU4C provides an open, flexible, portable foundation for applications to use for their software globalization requirements. ICU4C closely tracks industry standards, including Unicode and CLDR (Common Locale Data Repository). Why ICU4J? Java provides a very strong foundation for global programs, and IBM and the ICU team played a key role in providing globalization technology into Sun's Java. But because of its long release schedule, Java cannot always keep up-to-date with evolving standards. The ICU team continues to extend Java's Unicode and internationalization support, focusing on improving performance, keeping current with the Unicode standard, and providing richer APIs, while remaining as compatible as possible with the original Java text and internationalization API design. See Why Use ICU4J? ICU4JNI New versions of ICU4JNI are no longer being created. If you need the functionality of ICU4JNI, you should consider migrating to ICU4J. Who Uses ICU? The following is a list of products, companies and organizations reported to be using ICU. If you have any feedback on this list (corrections, additions, or details), please contact us (on icu-support). Companies and Organizations using ICU ABAS Software, Adobe, Amazon (Kindle), Amdocs, Apache, Appian, Apple, Argonne National Laboratory, Avaya, BAE Systems Geospatial eXploitation Products, BEA, BluePhoenix Solutions, BMC Software, Boost, BroadJump, Business Objects, caris, CERN, CouchDB, Debian Linux, Dell, Eclipse, eBay, EMC Corporation, ESRI, Firebird RDBMS, Free BSD, Gentoo Linux, Google, GroundWork Open Source, GTK+, Harman/Becker Automotive Systems GmbH, HP, Hyperion, IBM, Inktomi, Innodata Isogen, Informatica, Intel, Interlogics, IONA, IXOS, Jikes, Library of Congress, Mathworks, Microsoft, Mozilla, Netezza, Node.js, OpenOffice, Oracle (Solaris, Java), Lawson Software, Leica Geosystems GIS & Mapping LLC, Mandrake Linux, OCLC, Progress Software, Python, QNX, Rogue Wave, SAP, SIL, SPSS, Software AG, SuSE, Sybase, Symantec, Teradata (NCR), ToolAware, Trend Micro, Virage, webMethods, Wine, WMS Gaming, XyEnterprise, Yahoo!, Vuo, and many others. Apache Projects Harmony, Lucene search library, Solr search engine server, PDFBox library, Tika metadata toolkits, Xalan XSLT, Xerces XML Products from IBM DB2, Lotus, Websphere, Tivoli, Rational, AIX, i/OS, z/OS Ascential Software, Cloudant, Cognos, PSD Print Architecture, COBOL, Host Access Client, InfoPrint Manager, Informix GLS, Language Analysis Systems, Lotus Notes, Lotus Extended Search, Lotus Workplace, WebSphere Message Broker, NUMA-Q, OTI, OmniFind, Pervasive Computing WECMS, Rational Business Developer and Rational Application Developer, SS&S Websphere Banking Solutions, Tivoli Presentation Services, Tivoli Identity Manager, WBI Adapter/ Connect/Modeler and Monitor/ Solution Technology Development/WBI-Financial TePI, Websphere Application Server/ Studio Workload Simulator/Transcoding Publisher, XML Parser. Products from Google Web Search, Google+, Chrome/Chrome OS, Android, Adwords, Google Finance, Google Maps, Blogger, Google Analytics, Google Groups, and others. Products from Apple Mac OS X (OS & applications), iOS (iPhone, iPad, iPod touch), watchOS & tvOS, Safari for Windows & other Windows applications and related support, Apple Mobile Device Support in iTunes for Windows. Products from Harman/Becker The following car brands are using ICU via the Harman/Becker automotive software: Alfa Romeo, Audi, Bentley, BMW, Buick, more... Related Projects There are also some related projects that wrap the existing functionality of ICU. Subpages (1): Why Use ICU4J? Comments Sign in|Recent Site Activity|Report Abuse|Print Page|Powered By Google Sites"	"null"	"null"	"International Components for Unicode; a library for Unicode support.."	"true"
"String Manipulation"	"libunistring"	"https://gnu.org/software/libunistring/"	"A library for manipulating Unicode strings in C. only."	"null"	"null"	"null"	"GNU LGPL3"	"http://www.gnu.org/licenses/lgpl.html"	"null"	"null"	"null"	"null"	"null"	"libunistring - GNU Project - Free Software Foundation (FSF) libunistring Introduction | Get the Software Introduction to libunistring Text files are nowadays usually encoded in Unicode, and may consist of very different scripts – from Latin letters to Chinese Hanzi –, with many kinds of special characters – accents, right-to-left writing marks, hyphens, Roman numbers, and much more. But the POSIX platform APIs for text do not contain adequate functions for dealing with particular properties of many Unicode characters. In fact, the POSIX APIs for text have several assumptions at their base which don't hold for Unicode text. This library provides functions for manipulating Unicode strings and for manipulating C strings according to the Unicode standard. Details This library consists of the following parts: <unistr.h>   elementary string functions <uniconv.h>   conversion from/to legacy encodings <unistdio.h>   formatted output to strings <uniname.h>   character names <unictype.h>   character classification and properties <uniwidth.h>   string width when using nonproportional fonts <uniwbrk.h>   word breaks <unilbrk.h>   line breaking algorithm <uninorm.h>   normalization (composition and decomposition) <unicase.h>   case folding <uniregex.h>   regular expressions (not yet implemented) Who needs libunistring? libunistring is for you if your application involves non-trivial text processing, such as upper/lower case conversions, line breaking, operations on words, or more advanced analysis of text. Text provided by the user can, in general, contain characters of all kinds of scripts. The text processing functions provided by this library handle all scripts and all languages. libunistring is for you if your application already uses the ISO C / POSIX <ctype.h>, <wctype.h> functions and the text it operates on is provided by the user and can be in any language. libunistring is also for you if your application uses Unicode strings as internal in-memory representation. Documentation The online manual is available at www.gnu.org/software/libunistring/manual/libunistring.html Downloading libunistring libunistring can be found on in the subdirectory /pub/gnu/libunistring/ on your favorite GNU mirror. For other ways to obtain libunistring, please read How to get GNU Software. The latest release is http://ftp.gnu.org/gnu/libunistring/libunistring-0.9.6.tar.xz The latest development sources can be obtained through the savannah project. Bug reports Bug reports should be sent to <bug-libunistring-antispam@antispam.gnu.org>. Return to GNU's home page. Please send general FSF & GNU inquiries to <gnu@gnu.org>. There are also other ways to contact the FSF. Please send broken links and other corrections or suggestions to <bug-libunistring-antispam@antispam.gnu.org>. Copyright (C) 1998, 2010 Free Software Foundation, Inc. Verbatim copying and distribution of this entire article is permitted in any medium, provided this notice is preserved. Last updated: $Date: 2016/06/10 03:32:01 $ $Author: ueno $"	"null"	"null"	"A library for manipulating Unicode strings in C. only."	"true"
"String Manipulation"	"libgiconv"	"https://gnu.org/software/libiconv/"	"A text conversion library. only (library), only ( program)."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"libiconv - GNU Project - Free Software Foundation (FSF) libiconv Introduction | Get the Software Introduction to libiconv For historical reasons, international text is often encoded using a language or country dependent character encoding. With the advent of the internet and the frequent exchange of text across countries - even the viewing of a web page from a foreign country is a ""text exchange"" in this context -, conversions between these encodings have become important. They have also become a problem, because many characters which are present in one encoding are absent in many other encodings. To solve this mess, the Unicode encoding has been created. It is a super-encoding of all others and is therefore the default encoding for new text formats like XML. Still, many computers still operate in locale with a traditional (limited) character encoding. Some programs, like mailers and web browsers, must be able to convert between a given text encoding and the user's encoding. Other programs internally store strings in Unicode, to facilitate internal processing, and need to convert between internal string representation (Unicode) and external string representation (a traditional encoding) when they are doing I/O. GNU libiconv is a conversion library for both kinds of applications. Details This library provides an iconv() implementation, for use on systems which don't have one, or whose implementation cannot convert from/to Unicode. It provides support for the encodings: European languages ASCII, ISO-8859-{1,2,3,4,5,7,9,10,13,14,15,16}, KOI8-R, KOI8-U, KOI8-RU, CP{1250,1251,1252,1253,1254,1257}, CP{850,866,1131}, Mac{Roman,CentralEurope,Iceland,Croatian,Romania}, Mac{Cyrillic,Ukraine,Greek,Turkish}, Macintosh Semitic languages ISO-8859-{6,8}, CP{1255,1256}, CP862, Mac{Hebrew,Arabic} Japanese EUC-JP, SHIFT_JIS, CP932, ISO-2022-JP, ISO-2022-JP-2, ISO-2022-JP-1 Chinese EUC-CN, HZ, GBK, CP936, GB18030, EUC-TW, BIG5, CP950, BIG5-HKSCS, BIG5-HKSCS:2004, BIG5-HKSCS:2001, BIG5-HKSCS:1999, ISO-2022-CN, ISO-2022-CN-EXT Korean EUC-KR, CP949, ISO-2022-KR, JOHAB Armenian ARMSCII-8 Georgian Georgian-Academy, Georgian-PS Tajik KOI8-T Kazakh PT154, RK1048 Thai ISO-8859-11, TIS-620, CP874, MacThai Laotian MuleLao-1, CP1133 Vietnamese VISCII, TCVN, CP1258 Platform specifics HP-ROMAN8, NEXTSTEP Full Unicode UTF-8 UCS-2, UCS-2BE, UCS-2LE UCS-4, UCS-4BE, UCS-4LE UTF-16, UTF-16BE, UTF-16LE UTF-32, UTF-32BE, UTF-32LE UTF-7 C99, JAVA Full Unicode, in terms of uint16_t or uint32_t (with machine dependent endianness and alignment) UCS-2-INTERNAL, UCS-4-INTERNAL Locale dependent, in terms of `char' or `wchar_t' (with machine dependent endianness and alignment, and with OS and locale dependent semantics) char, wchar_t The empty encoding name """" is equivalent to ""char"": it denotes the locale dependent character encoding. When configured with the option --enable-extra-encodings, it also provides support for a few extra encodings: European languages CP{437,737,775,852,853,855,857,858,860,861,863,865,869,1125} Semitic languages CP864 Japanese EUC-JISX0213, Shift_JISX0213, ISO-2022-JP-3 Chinese BIG5-2003 (experimental) Turkmen TDS565 Platform specifics ATARIST, RISCOS-LATIN1 It can convert from any of these encodings to any other, through Unicode conversion. It has also some limited support for transliteration, i.e. when a character cannot be represented in the target character set, it can be approximated through one or several similarly looking characters. Transliteration is activated when ""//TRANSLIT"" is appended to the target encoding name. libiconv is for you if your application needs to support multiple character encodings, but that support lacks from your system. Installation As usual for GNU packages: $ ./configure --prefix=/usr/local $ make $ make install  After installing GNU libiconv for the first time, it is recommended to recompile and reinstall GNU gettext, so that it can take advantage of libiconv. On systems other than GNU/Linux, the iconv program will be internationalized only if GNU gettext has been built and installed before GNU libiconv. This means that the first time GNU libiconv is installed, we have a circular dependency between the GNU libiconv and GNU gettext packages, which can be resolved by building and installing either first libiconv, then gettext, then libiconv again, or (on systems supporting shared libraries, excluding AIX) first gettext, then libiconv, then gettext again. Recall that before building a package for the second time, you need to erase the traces of the first build by running ""make distclean"". This library can be built and installed in two variants: The library mode. This works on all systems, and uses a library libiconv.so and a header file <iconv.h>. (Both are installed through ""make install"".) To use it, simply #include <iconv.h> and use the functions. To use it in an autoconfiguring package: If you don't use automake, append m4/iconv.m4 to your aclocal.m4 file. If you do use automake, add m4/iconv.m4 to your m4 macro repository. Add to the link command line of libraries and executables that use the functions the placeholder @LIBICONV@ (or, if using libtool for the link, @LTLIBICONV@). If you use automake, the right place for these additions are the *_LDADD variables. Note that iconv.m4 is also part of the GNU gettext package, which installs it in /usr/local/share/aclocal/iconv.m4. The libc plug/override mode. This works on GNU/Linux, Solaris and OSF/1 systems only. It is a way to get good iconv support without having glibc-2.1. It installs a library preloadable_libiconv.so. This library can be used with LD_PRELOAD, to override the iconv* functions present in the C library. On GNU/Linux and Solaris: $ export LD_PRELOAD=/usr/local/lib/preloadable_libiconv.so On OSF/1: $ export _RLD_LIST=/usr/local/lib/preloadable_libiconv.so:DEFAULT A program's source need not be modified, the program need not even be recompiled. Just set the LD_PRELOAD environment variable, that's it! Copyright The libiconv and libcharset libraries and their header files are under LGPL. The iconv program is under GPL. Downloading libiconv libiconv can be found on in the subdirectory /pub/gnu/libiconv/ on your favorite GNU mirror. For other ways to obtain libiconv, please read How to get GNU Software. The latest release is http://ftp.gnu.org/pub/gnu/libiconv/libiconv-1.14.tar.gz The latest development sources can be obtained through the savannah project. Documentation Below are the links for the online documentation. The iconv program iconv.1.html The library functions iconv_open.3.html iconv.3.html iconv_close.3.html iconvctl.3.html iconv_open_into.3.html Bug reports Bug reports should be sent to <bug-gnu-libiconv-antispam@antispam.gnu.org>. Return to GNU's home page. Please send general FSF & GNU inquiries to <gnu@gnu.org>. There are also other ways to contact the FSF. Please send broken links and other corrections or suggestions to <bug-gnu-libiconv-antispam@antispam.gnu.org>. Copyright (C) 1998, 2010 Free Software Foundation, Inc. Verbatim copying and distribution of this entire article is permitted in any medium, provided this notice is preserved. Last updated: $Date: 2011/08/07 18:23:36 $ $Author: haible $"	"null"	"null"	"A text conversion library. only (library), only ( program)."	"true"
"String Manipulation"	"SDS"	"https://github.com/antirez/sds"	"Simple Dynamic Strings; a library for handling C strings in a simpler way, but one that is compatible with normal C string functions. Available via.."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"1656"	"94"	"169"	"GitHub - antirez/sds: Simple Dynamic Strings library for C Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 94 Star 1,656 Fork 169 antirez/sds Code Issues 15 Pull requests 42 Pulse Graphs Simple Dynamic Strings library for C 45 commits 1 branch 2 releases 6 contributors C 99.6% Makefile 0.4% C Makefile Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show 2.0.0 1.0.0 Nothing to show New pull request Latest commit 3892c0e Jan 9, 2016 antirez Merge pull request #62 from gavinwahl/patch-1 … I think this is supposed to represent a single string Permalink Failed to load latest commit information. .gitignore .gitignore file added. Feb 2, 2014 Changelog SDS version 2.0.0. Jul 25, 2015 LICENSE LICENSE file added. Feb 3, 2014 Makefile .gitignore file added. Feb 2, 2014 README.md I think this is supposed to represent a single string Jan 8, 2016 sds.c Export API to use the allocator SDS is using. Nov 16, 2015 sds.h Export API to use the allocator SDS is using. Nov 16, 2015 sdsalloc.h sdsalloc.h copyright notice updated as well. Jul 25, 2015 testhelp.h Test fixed to work with new sdsrange() API. Feb 2, 2014 README.md Simple Dynamic Strings Notes about verison 2: this is an updated version of SDS in an attempt to finally unify Redis, Disque, Hiredis, and the stand alone SDS versions. This version is NOT* binary compatible with SDS verison 1, but the API is 99% compatible so switching to the new lib should be trivial. Note that this version of SDS may be a slower with certain workloads, but uses less memory compared to V1 since header size is dynamic and depends to the string to alloc. Moreover it includes a few more API functions, notably sdscatfmt which is a faster version of sdscatprintf that can be used for the simpler cases in order to avoid the libc printf family functions performance penalty. How SDS strings work SDS is a string library for C designed to augment the limited libc string handling functionalities by adding heap allocated strings that are: Simpler to use. Binary safe. Computationally more efficient. But yet... Compatible with normal C string functions. This is achieved using an alternative design in which instead of using a C structure to represent a string, we use a binary prefix that is stored before the actual pointer to the string that is returned by SDS to the user. +--------+-------------------------------+-----------+ | Header | Binary safe C alike string... | Null term | +--------+-------------------------------+-----------+          |          `-> Pointer returned to the user.  Because of meta data stored before the actual returned pointer as a prefix, and because of every SDS string implicitly adding a null term at the end of the string regardless of the actual content of the string, SDS strings work well together with C strings and the user is free to use them interchangeably with other std C string functions that access the string in read-only. SDS was a C string I developed in the past for my everyday C programming needs, later it was moved into Redis where it is used extensively and where it was modified in order to be suitable for high performance operations. Now it was extracted from Redis and forked as a stand alone project. Because of its many years life inside Redis, SDS provides both higher level functions for easy strings manipulation in C, but also a set of low level functions that make it possible to write high performance code without paying a penalty for using an higher level string library. Advantages and disadvantages of SDS Normally dynamic string libraries for C are implemented using a structure that defines the string. The structure has a pointer field that is managed by the string function, so it looks like this: struct yourAverageStringLibrary {     char *buf;     size_t len;     ... possibly more fields here ... }; SDS strings as already mentioned don't follow this schema, and are instead a single allocation with a prefix that lives before the address actually returned for the string. There are advantages and disadvantages with this approach over the traditional approach: Disadvantage #1: many functions return the new string as value, since sometimes SDS requires to create a new string with more space, so the most SDS API calls look like this: s = sdscat(s,""Some more data""); As you can see s is used as input for sdscat but is also set to the value returned by the SDS API call, since we are not sure if the call modified the SDS string we passed or allocated a new one. Not remembering to assign back the return value of sdscat or similar functions to the variable holding the SDS string will result in a bug. Disadvantage #2: if an SDS string is shared in different places in your program you have to modify all the references when you modify the string. However most of the times when you need to share SDS strings it is much better to encapsulate them into structures with a reference count otherwise it is too easy to incur into memory leaks. Advantage #1: you can pass SDS strings to functions designed for C functions without accessing a struct member or calling a function, like this: printf(""%s\n"", sds_string); In most other libraries this will be something like: printf(""%s\n"", string->buf); Or: printf(""%s\n"", getStringPointer(string)); Advantage #2: accessing individual chars is straightforward. C is a low level language so this is an important operation in many programs. With SDS strings accessing individual chars is very natural: printf(""%c %c\n"", s[0], s[1]); With other libraries your best chance is to assign string->buf (or call the function to get the string pointer) to a char pointer and work with this. However since the other libraries may reallocate the buffer implicitly every time you call a function that may modify the string you have to get a reference to the buffer again. Advantage #3: single allocation has better cache locality. Usually when you access a string created by a string library using a structure, you have two different allocations for the structure representing the string, and the actual buffer holding the string. Over the time the buffer is reallocated, and it is likely that it ends in a totally different part of memory compared to the structure itself. Since modern programs performances are often dominated by cache misses, SDS may perform better in many workloads. SDS basics The type of SDS strings is just the char pointer char *. However SDS defines an sds type as alias of char * in its header file: you should use the sds type in order to make sure you remember that a given variable in your program holds an SDS string and not a C string, however this is not mandatory. This is the simplest SDS program you can write that does something: sds mystring = sdsnew(""Hello World!""); printf(""%s\n"", mystring); sdsfree(mystring);  output> Hello World! The above small program already shows a few important things about SDS: SDS strings are created, and heap allocated, via the sdsnew() function, or other similar functions that we'll see in a moment. SDS strings can be passed to printf() like any other C string. SDS strings require to be freed with sdsfree(), since they are heap allocated. Creating SDS strings sds sdsnewlen(const void *init, size_t initlen); sds sdsnew(const char *init); sds sdsempty(void); sds sdsdup(const sds s); There are many ways to create SDS strings: The sdsnew function creates an SDS string starting from a C null terminated string. We already saw how it works in the above example. The sdsnewlen function is similar to sdsnew but instead of creating the string assuming that the input string is null terminated, it gets an additional length parameter. This way you can create a string using binary data: char buf[3]; sds mystring;  buf[0] = 'A'; buf[1] = 'B'; buf[2] = 'C'; mystring = sdsnewlen(buf,3); printf(""%s of len %d\n"", mystring, (int) sdslen(mystring));  output> ABC of len 3 Note: sdslen return value is casted to int because it returns a size_t type. You can use the right printf specifier instead of casting. The sdsempty() function creates an empty zero-length string: sds mystring = sdsempty(); printf(""%d\n"", (int) sdslen(mystring));  output> 0 The sdsdup() function duplicates an already existing SDS string: sds s1, s2;  s1 = sdsnew(""Hello""); s2 = sdsdup(s1); printf(""%s %s\n"", s1, s2);  output> Hello Hello Obtaining the string length size_t sdslen(const sds s); In the examples above we already used the sdslen function in order to get the length of the string. This function works like strlen of the libc except that: It runs in constant time since the length is stored in the prefix of SDS strings, so calling sdslen is not expensive even when called with very large strings. The function is binary safe like any other SDS string function, so the length is the true length of the string regardless of the content, there is no problem if the string includes null term characters in the middle. As an example of the binary safeness of SDS strings, we can run the following code: sds s = sdsnewlen(""A\0\0B"",4); printf(""%d\n"", (int) sdslen(s));  output> 4 Note that SDS strings are always null terminated at the end, so even in that case s[4] will be a null term, however printing the string with printf would result in just ""A"" to be printed since libc will treat the SDS string like a normal C string. Destroying strings void sdsfree(sds s); The destroy an SDS string there is just to call sdsfree with the string pointer. Note that even empty strings created with sdsempty need to be destroyed as well otherwise they'll result into a memory leak. The function sdsfree does not perform any operation if instead of an SDS string pointer, NULL is passed, so you don't need to check for NULL explicitly before calling it: if (string) sdsfree(string); /* Not needed. */ sdsfree(string); /* Same effect but simpler. */ Concatenating strings Concatenating strings to other strings is likely the operation you will end using the most with a dynamic C string library. SDS provides different functions to concatenate strings to existing strings. sds sdscatlen(sds s, const void *t, size_t len); sds sdscat(sds s, const char *t); The main string concatenation functions are sdscatlen and sdscat that are identical, the only difference being that sdscat does not have an explicit length argument since it expects a null terminated string. sds s = sdsempty(); s = sdscat(s, ""Hello ""); s = sdscat(s, ""World!""); printf(""%s\n"", s);  output> Hello World! Sometimes you want to cat an SDS string to another SDS string, so you don't need to specify the length, but at the same time the string does not need to be null terminated but can contain any binary data. For this there is a special function: sds sdscatsds(sds s, const sds t); Usage is straightforward: sds s1 = sdsnew(""aaa""); sds s2 = sdsnew(""bbb""); s1 = sdscatsds(s1,s2); sdsfree(s2); printf(""%s\n"", s1);  output> aaabbb Sometimes you don't want to append any special data to the string, but you want to make sure that there are at least a given number of bytes composing the whole string. sds sdsgrowzero(sds s, size_t len); The sdsgrowzero function will do nothing if the current string length is already len bytes, otherwise it will enlarge the string to len just padding it with zero bytes. sds s = sdsnew(""Hello""); s = sdsgrowzero(s,6); s[5] = '!'; /* We are sure this is safe because of sdsgrowzero() */ printf(""%s\n', s);  output> Hello! Formatting strings There is a special string concatenation function that accepts a printf alike format specifier and cats the formatted string to the specified string. sds sdscatprintf(sds s, const char *fmt, ...) { Example: sds s; int a = 10, b = 20; s = sdsnew(""The sum is: ""); s = sdscatprintf(s,""%d+%d = %d"",a,b,a+b); Often you need to create SDS string directly from printf format specifiers. Because sdscatprintf is actually a function that concatenates strings, all you need is to concatenate your string to an empty string: char *name = ""Anna""; int loc = 2500; sds s; s = sdscatprintf(sdsempty(), ""%s wrote %d lines of LISP\n"", name, loc); You can use sdscatprintf in order to convert numbers into SDS strings: int some_integer = 100; sds num = sdscatprintf(sdsempty(),""%d\n"", some_integer); However this is slow and we have a special function to make it efficient. Fast number to string operations Creating an SDS string from an integer may be a common operation in certain kind of programs, and while you may do this with sdscatprintf the performance hit is big, so SDS provides a specialized function. sds sdsfromlonglong(long long value); Use it like this: sds s = sdsfromlonglong(10000); printf(""%d\n"", (int) sdslen(s));  output> 5 Trimming strings and getting ranges String trimming is a common operation where a set of characters are removed from the left and the right of the string. Another useful operation regarding strings is the ability to just take a range out of a larger string. void sdstrim(sds s, const char *cset); void sdsrange(sds s, int start, int end); SDS provides both the operations with the sdstrim and sdsrange functions. However note that both functions work differently than most functions modifying SDS strings since the return value is void: basically those functions always destructively modify the passed SDS string, never allocating a new one, because both trimming and ranges will never need more room: the operations can only remove characters from the original string. Because of this behavior, both functions are fast and don't involve reallocation. This is an example of string trimming where newlines and spaces are removed from an SDS strings: sds s = sdsnew(""         my string\n\n  ""); sdstrim(s,"" \n""); printf(""-%s-\n"",s);  output> -my string- Basically sdstrim takes the SDS string to trim as first argument, and a null terminated set of characters to remove from left and right of the string. The characters are removed as long as they are not interrupted by a character that is not in the list of characters to trim: this is why the space between ""my"" and ""string"" was preserved in the above example. Taking ranges is similar, but instead to take a set of characters, it takes to indexes, representing the start and the end as specified by zero-based indexes inside the string, to obtain the range that will be retained. sds s = sdsnew(""Hello World!""); sdsrange(s,1,4); printf(""-%s-\n"");  output> -ello- Indexes can be negative to specify a position starting from the end of the string, so that -1 means the last character, -2 the penultimate, and so forth: sds s = sdsnew(""Hello World!""); sdsrange(s,6,-1); printf(""-%s-\n""); sdsrange(s,0,-2); printf(""-%s-\n"");  output> -World!- output> -World- sdsrange is very useful when implementing networking servers processing a protocol or sending messages. For example the following code is used implementing the write handler of the Redis Cluster message bus between nodes: void clusterWriteHandler(..., int fd, void *privdata, ...) {     clusterLink *link = (clusterLink*) privdata;     ssize_t nwritten = write(fd, link->sndbuf, sdslen(link->sndbuf));     if (nwritten <= 0) {         /* Error handling... */     }     sdsrange(link->sndbuf,nwritten,-1);     ... more code here ... } Every time the socket of the node we want to send the message to is writable we attempt to write as much bytes as possible, and we use sdsrange in order to remove from the buffer what was already sent. The function to queue new messages to send to some node in the cluster will simply use sdscatlen in order to put more data in the send buffer. Note that the Redis Cluster bus implements a binary protocol, but since SDS is binary safe this is not a problem, so the goal of SDS is not just to provide an high level string API for the C programmer but also dynamically allocated buffers that are easy to manage. String copying The most dangerous and infamus function of the standard C library is probably strcpy, so perhaps it is funny how in the context of better designed dynamic string libraries the concept of copying strings is almost irrelevant. Usually what you do is to create strings with the content you want, or concatenating more content as needed. However SDS features a string copy function that is useful in performance critical code sections, however I guess its practical usefulness is limited as the function never managed to get called in the context of the 50k lines of code composing the Redis code base. sds sdscpylen(sds s, const char *t, size_t len); sds sdscpy(sds s, const char *t); The string copy function of SDS is called sdscpylen and works like that: s = sdsnew(""Hello World!""); s = sdscpylen(s,""Hello Superman!"",15); As you can see the function receives as input the SDS string s, but also returns an SDS string. This is common to many SDS functions that modify the string: this way the returned SDS string may be the original one modified or a newly allocated one (for example if there was not enough room in the old SDS string). The sdscpylen will simply replace what was in the old SDS string with the new data you pass using the pointer and length argument. There is a similar function called sdscpy that does not need a length but expects a null terminated string instead. You may wonder why it makes sense to have a string copy function in the SDS library, since you can simply create a new SDS string from scratch with the new value instead of copying the value in an existing SDS string. The reason is efficiency: sdsnewlen will always allocate a new string while sdscpylen will try to reuse the existing string if there is enough room to old the new content specified by the user, and will allocate a new one only if needed. Quoting strings In order to provide consistent output to the program user, or for debugging purposes, it is often important to turn a string that may contain binary data or special characters into a quoted string. Here for quoted string we mean the common format for String literals in programming source code. However today this format is also part of the well known serialization formats like JSON and CSV, so it definitely escaped the simple goal of representing literals strings in the source code of programs. An example of quoted string literal is the following: ""\x00Hello World\n"" The first byte is a zero byte while the last byte is a newline, so there are two non alphanumerical characters inside the string. SDS uses a concatenation function for this goal, that concatenates to an existing string the quoted string representation of the input string. sds sdscatrepr(sds s, const char *p, size_t len); The scscatrepr (where repr means representation) follows the usualy SDS string function rules accepting a char pointer and a length, so you can use it with SDS strings, normal C strings by using strlen() as len argument, or binary data. The following is an example usage: sds s1 = sdsnew(""abcd""); sds s2 = sdsempty(); s[1] = 1; s[2] = 2; s[3] = '\n'; s2 = sdscatrepr(s2,s1,sdslen(s1)); printf(""%s\n"", s2);  output> ""a\x01\x02\n"" This is the rules sdscatrepr uses for conversion: \ and "" are quoted with a backslash. It quotes special characters '\n', '\r', '\t', '\a' and '\b'. All the other non printable characters not passing the isprint test are quoted in \x.. form, that is: backslash followed by x followed by two digit hex number representing the character byte value. The function always adds initial and final double quotes characters. There is an SDS function that is able to perform the reverse conversion and is documented in the Tokenization section below. Tokenization Tokenization is the process of splitting a larger string into smaller strings. In this specific case, the split is performed specifying another string that acts as separator. For example in the following string there are two substrings that are separated by the |-| separator: foo|-|bar|-|zap  A more common separator that consists of a single character is the comma: foo,bar,zap  In many progrems it is useful to process a line in order to obtain the sub strings it is composed of, so SDS provides a function that returns an array of SDS strings given a string and a separator. sds *sdssplitlen(const char *s, int len, const char *sep, int seplen, int *count); void sdsfreesplitres(sds *tokens, int count); As usually the function can work with both SDS strings or normal C strings. The first two arguments s and len specify the string to tokenize, and the other two arguments sep and seplen the separator to use during the tokenization. The final argument count is a pointer to an integer that will be set to the number of tokens (sub strings) returned. The return value is a heap allocated array of SDS strings. sds *tokens; int count, j;  sds line = sdsnew(""Hello World!""); tokens = sdssplitlen(line,sdslen(line),"" "",1,&count);  for (j = 0; j < count; j++)     printf(""%s\n"", tokens[j]); sdsfreesplitres(tokens,count);  output> Hello output> World! The returned array is heap allocated, and the single elements of the array are normal SDS strings. You can free everything calling sdsfreesplitres as in the example. Alternativey you are free to release the array yourself using the free function and use and/or free the individual SDS strings as usually. A valid approach is to set the array elements you reused in some way to NULL, and use sdsfreesplitres to free all the rest. Command line oriented tokenization Splitting by a separator is a useful operation, but usually it is not enough to perform one of the most common tasks involving some non trivial string manipulation, that is, implementing a Command Line Interface for a program. This is why SDS also provides an additional function that allows you to split arguments provided by the user via the keyboard in an interactive manner, or via a file, network, or any other mean, into tokens. sds *sdssplitargs(const char *line, int *argc); The sdssplitargs function returns an array of SDS strings exactly like sdssplitlen. The function to free the result is also identical, and is sdsfreesplitres. The difference is in the way the tokenization is performed. For example if the input is the following line: call ""Sabrina""    and ""Mark Smith\n""  The function will return the following tokens: ""call"" ""Sabrina"" ""and"" ""Mark Smith\n"" Basically different tokens need to be separated by one or more spaces, and every single token can also be a quoted string in the same format that sdscatrepr is able to emit. String joining There are two functions doing the reverse of tokenization by joining strings into a single one. sds sdsjoin(char **argv, int argc, char *sep, size_t seplen); sds sdsjoinsds(sds *argv, int argc, const char *sep, size_t seplen); The two functions take as input an array of strings of length argc and a separator and its length, and produce as output an SDS string consisting of all the specified strings separated by the specified separator. The difference between sdsjoin and sdsjoinsds is that the former accept C null terminated strings as input while the latter requires all the strings in the array to be SDS strings. However because of this only sdsjoinsds is able to deal with binary data. char *tokens[3] = {""foo"",""bar"",""zap""}; sds s = sdsjoin(tokens,3,""|"",1); printf(""%s\n"", s);  output> foo|bar|zap Error handling All the SDS functions that return an SDS pointer may also return NULL on out of memory, this is basically the only check you need to perform. However many modern C programs handle out of memory simply aborting the program so you may want to do this as well by wrapping malloc and other related memory allocation calls directly. SDS internals and advanced usage At the very beginning of this documentation it was explained how SDS strings are allocated, however the prefix stored before the pointer returned to the user was classified as an header without further details. For an advanced usage it is better to dig more into the internals of SDS and show the structure implementing it: struct sdshdr {     int len;     int free;     char buf[]; }; As you can see, the structure may resemble the one of a conventional string library, however the buf field of the structure is different since it is not a pointer but an array without any length declared, so buf actually points at the first byte just after the free integer. So in order to create an SDS string we just allocate a piece of memory that is as large as the sdshdr structure plus the length of our string, plus an additional byte for the mandatory null term that every SDS string has. The len field of the structure is quite obvious, and is the current length of the SDS string, always computed every time the string is modified via SDS function calls. The free field instead represents the amount of free memory in the current allocation that can be used to store more characters. So the actual SDS layout is this one: +------------+------------------------+-----------+---------------\ | Len | Free | H E L L O W O R L D \n | Null term |  Free space   \ +------------+------------------------+-----------+---------------\              |              `-> Pointer returned to the user.  You may wonder why there is some free space at the end of the string, it looks like a waste. Actually after a new SDS string is created, there is no free space at the end at all: the allocation will be as small as possible to just hold the header, string, and null term. However other access patterns will create extra free space at the end, like in the following program: s = sdsempty(); s = sdscat(s,""foo""); s = sdscat(s,""bar""); s = sdscat(s,""123""); Since SDS tries to be efficient it can't afford to reallocate the string every time new data is appended, since this would be very inefficient, so it uses the preallocation of some free space every time you enlarge the string. The preallocation algorithm used is the following: every time the string is reallocated in order to hold more bytes, the actual allocation size performed is two times the minimum required. So for instance if the string currently is holding 30 bytes, and we concatenate 2 more bytes, instead of allocating 32 bytes in total SDS will allocate 64 bytes. However there is an hard limit to the allocation it can perform ahead, and is defined by SDS_MAX_PREALLOC. SDS will never allocate more than 1MB of additional space (by default, you can change this default). Shrinking strings sds sdsRemoveFreeSpace(sds s); size_t sdsAllocSize(sds s); Sometimes there are class of programs that require to use very little memory. After strings concatenations, trimming, ranges, the string may end having a non trivial amount of additional space at the end. It is possible to resize a string back to its minimal size in order to hold the current content by using the function sdsRemoveFreeSpace. s = sdsRemoveFreeSpace(s); There is also a function that can be used in order to get the size of the total allocation for a given string, and is called sdsAllocSize. sds s = sdsnew(""Ladies and gentlemen""); s = sdscat(s,""... welcome to the C language.""); printf(""%d\n"", (int) sdsAllocSize(s)); s = sdsRemoveFreeSpace(s); printf(""%d\n"", (int) sdsAllocSize(s));  output> 109 output> 59 NOTE: SDS Low level API use cammelCase in order to warn you that you are playing with the fire. Manual modifications of SDS strings void sdsupdatelen(sds s);  Sometimes you may want to hack with an SDS string manually, without using SDS functions. In the following example we implicitly change the length of the string, however we want the logical length to reflect the null terminated C string. The function sdsupdatelen does just that, updating the internal length information for the specified string to the length obtained via strlen. sds s = sdsnew(""foobar""); s[2] = '\0'; printf(""%d\n"", sdslen(s)); sdsupdatelen(s); printf(""%d\n"", sdslen(s));  output> 6 output> 2 Sharing SDS strings If you are writing a program in which it is advantageous to share the same SDS string across different data structures, it is absolutely advised to encapsulate SDS strings into structures that remember the number of references of the string, with functions to increment and decrement the number of references. This approach is a memory management technique called reference counting and in the context of SDS has two advantages: It is less likely that you'll create memory leaks or bugs due to non freeing SDS strings or freeing already freed strings. You'll not need to update every reference to an SDS string when you modify it (since the new SDS string may point to a different memory location). While this is definitely a very common programming technique I'll outline the basic ideas here. You create a structure like that: struct mySharedString {     int refcount;     sds string; } When new strings are created, the structure is allocated and returned with refcount set to 1. The you have two functions to change the reference count of the shared string: incrementStringRefCount will simply increment refcount of 1 in the structure. It will be called every time you add a reference to the string on some new data structure, variable, or whatever. decrementStringRefCount is used when you remove a reference. This function is however special since when the refcount drops to zero, it automatically frees the SDS string, and the mySharedString structure as well. Interactions with heap checkers Because SDS returns pointers into the middle of memory chunks allocated with malloc, heap checkers may have issues, however: The popular Valgrind program will detect SDS strings are possibly lost memory and never as definitely lost, so it is easy to tell if there is a leak or not. I used Valgrind with Redis for years and every real leak was consistently detected as ""definitely lost"". OSX instrumentation tools don't detect SDS strings as leaks but are able to correctly handle pointers pointing to the middle of memory chunks. Zero copy append from syscalls At this point you should have all the tools to dig more inside the SDS library by reading the source code, however there is an interesting pattern you can mount using the low level API exported, that is used inside Redis in order to improve performances of the networking code. Using sdsIncrLen() and sdsMakeRoomFor() it is possible to mount the following schema, to cat bytes coming from the kernel to the end of an sds string without copying into an intermediate buffer: oldlen = sdslen(s); s = sdsMakeRoomFor(s, BUFFER_SIZE); nread = read(fd, s+oldlen, BUFFER_SIZE); ... check for nread <= 0 and handle it ... sdsIncrLen(s, nread); sdsIncrLen is documented inside the source code of sds.c. Embedding SDS into your project This is as simple as copying the following files inside your project: sds.c sds.h sdsalloc.h The source code is small and every C99 compiler should deal with it without issues. Using a different allocator for SDS Internally sds.c uses the allocator defined into sdsalloc.h. This header file just defines macros for malloc, realloc and free, and by default libc malloc(), realloc() and free() are used. Just edit this file in order to change the name of the allocation functions. The program using SDS can call the SDS allocator in order to manipulate SDS pointers (usually not needed but sometimes the program may want to do advanced things) by using the API exported by SDS in order to call the allocator used. This is especially useful when the program linked to SDS is using a different allocator compared to what SDS is using. The API to access the allocator used by SDS is composed of three functions: sds_malloc(), sds_realloc() and sds_free(). Credits and license SDS was created by Salvatore Sanfilippo and is released under the BDS two clause license. See the LICENSE file in this source distribution for more information. Oran Agra improved SDS version 2 by adding dynamic sized headers in order to save memory for small strings and allow strings greater than 4GB. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/antirez/sds"	"Simple Dynamic Strings; a library for handling C strings in a simpler way, but one that is compatible with normal C string functions. Available via.."	"true"
"String Manipulation"	"shoco"	"https://github.com/Ed-von-Schleck/shoco"	"A compressor for small text strings.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"116"	"19"	"20"	"GitHub - Ed-von-Schleck/shoco: shoco is a compressor for small text strings Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 19 Star 116 Fork 20 Ed-von-Schleck/shoco Code Issues 6 Pull requests 5 Pulse Graphs shoco is a compressor for small text strings http://ed-von-schleck.github.io/shoco/ 51 commits 2 branches 0 releases Fetching contributors C 85.2% Python 11.2% JavaScript 1.4% Makefile 1.2% HTML 1.0% C Python JavaScript Makefile HTML Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags gh-pages master Nothing to show Nothing to show New pull request Latest commit 4dee0fc Dec 8, 2015 Ed-von-Schleck Merge pull request #17 from charmander/master … Check for end of string properly when length given Permalink Failed to load latest commit information. models training_data .gitignore More fine-tuning for the text. Apr 17, 2014 LICENSE Makefile README.md generate_compressor_model.py Got shoco to compile without warnings under MSVC2013 Oct 6, 2014 pre.js shoco-bin.c shoco.c shoco.h shoco.html shoco.js shoco_model.h shoco_table.h test_input.c tests.c README.md shoco: a fast compressor for short strings shoco is a C library to compress and decompress short strings. It is very fast and easy to use. The default compression model is optimized for english words, but you can generate your own compression model based on your specific input data. shoco is free software, distributed under the MIT license. Quick Start Copy shoco.c, shoco.h and shoco_model.h from github/shoco over to your project. Include shoco.h and you are ready to use the API! API Here is all of it: size_t shoco_compress(const char * in, size_t len, char * out, size_t bufsize); size_t shoco_decompress(const char * in, size_t len, char * out, size_t bufsize); If the len argument for shoco_compress is 0, the input char is assumed to be null-terminated. If it’s a positive integer, parsing the input will stop after this length, or at a null-char, whatever comes first. shoco_decompress however will need a positive integer for len (most likely you should pass the return value of shoco_compress). The return value is the number of bytes written. If it is less than bufsize, all is well. In case of decompression, a null-terminator is written. If the return value is exactly bufsize, the output is all there, but not null-terminated. It is up to you to decide if that’s an error or not. If the buffer is not large enough for the output, the return value will be bufsize + 1. You might want to allocate a bigger output buffer. The compressed string will never be null-terminated. If you are sure that the input data is plain ASCII, your out buffer for shoco_compress only needs to be as large as the input string. Otherwise, the output buffer may need to be up to 2x as large as the input, if it’s a 1-byte encoding, or even larger for multi-byte or variable-width encodings like UTF-8. For the standard values of shoco, maximum compression is 50%, so the out buffer for shoco_decompress needs to be a maximum of twice the size of the compressed string. How It Works Have you ever tried compressing the string “hello world” with gzip? Let’s do it now: $ echo ""hello world"" | gzip -c | wc -c 32 So the output is actually larger than the input string. And gzip is quite good with short input: xz produces an output size of 68 bytes. Of course, compressing short strings is not what they are made for, because you rarely need to make small strings even smaller – except when you do. That’s why shoco was written. shoco works best if your input is ASCII. In fact, the most remarkable property of shoco is that the compressed size will never exceed the size of your input string, provided it is plain ASCII. What is more: An ASCII string is suitable input for the decompressor (which will return the exact same string, of course). That property comes at a cost, however: If your input string is not entirely (or mostly) ASCII, the output may grow. For some inputs, it can grow quite a lot. That is especially true for multibyte encodings such as UTF-8. Latin-1 and comparable encodings fare better, but will still increase your output size, if you don’t happen to hit a common character. Why is that so? In every language, some characters are used more often than others. English is no exception to this rule. So if one simply makes a list of the, say, sixteen most common characters, four bits would be sufficient to refer to them (as opposed to eight bits – one byte – used by ASCII). But what if the input string includes an uncommon character, that is not in this list? Here’s the trick: We use the first bit of a char to indicate if the following bits refer to a short common character index, or a normal ASCII byte. Since the first bit in plain ASCII is always 0, setting the first bit to 1 says “the next bits represent short indices for common chars”. But what if our character is not ASCII (meaning the first bit of the input char is not 0)? Then we insert a marker that says “copy the next byte over as-is”, and we’re done. That explains the growth for non-ASCII characters: This marker takes up a byte, doubling the effective size of the character. How shoco actually marks these packed representations is a bit more complicated than that (e.g., we also need to specify how many packed characters follow, so a single leading bit won’t be sufficient), but the principle still holds. But shoco is a bit smarter than just to abbreviate characters based on absolute frequency – languages have more regularities than that. Some characters are more likely to be encountered next to others; the canonical example would be q, that’s almost always followed by a u. In english, the, she, he, then are all very common words – and all have a h followed by a e. So if we’d assemble a list of common characters following common characters, we can do with even less bits to represent these successor characters, and still have a good hit rate. That’s the idea of shoco: Provide short representations of characters based on the previous character. This does not allow for optimal compression – by far. But if one carefully aligns the representation packs to byte boundaries, and uses the ASCII-first-bit-trick above to encode the indices, it works well enough. Moreover, it is blazingly fast. You wouldn’t want to use shoco for strings larger than, say, a hundred bytes, because then the overhead of a full-blown compressor like gzip begins to be dwarfed by the advantages of the much more efficient algorithms it uses. If one would want to classify shoco, it would be an entropy encoder, because the length of the representation of a character is determined by the probability of encountering it in a given input string. That’s opposed to dictionary coders that maintain a dictionary of common substrings. An optimal compression for short strings could probably be achieved using an arithmetic coder (also a type of entropy encoder), but most likely one could not achieve the same kind of performance that shoco delivers. How does shoco get the information about character frequencies? They are not pulled out of thin air, but instead generated by analyzing text with a relatively simple script. It counts all bigrams – two successive characters – in the text and orders them by frequency. If wished for, it also tests for best encodings (like: Is it better to spend more bits on the leading character or on the successor character?), and then outputs its findings as a header file for shoco.c to include. That means the statistical model is compiled in; we simply can’t add it to the compressed string without blowing it out of proportions (and defeating the whole purpose of this exercise). This script is shipped with shoco, and the next section is about how you can use it to generate a model that’s optimized for your kind of data. Just remember that, with shoco, you need to control both ends of the chain (compression and decompression), because you can’t decompress data correctly if you’re not sure that the compressor has used the same model. Generating Compression Models Maybe your typical input isn’t english words. Maybe it’s german or french – or whole sentences. Or file system paths. Or URLs. While the standard compression model of shoco should work for all of these, it might be worthwile to train shoco for this specific type of input data. Fortunately, that’s really easy: shoco includes a python script called generate_compression_model.py that takes one or more text files and ouputs a header file ready for shoco to use. Here’s an example that trains shoco with a dictionary (btw., not the best kind of training data, because it’s dominated by uncommon words): $ ./generate_compression_model.py /usr/share/dict/words -o shoco_model.h There are options on how to chunk and strip the input data – for example, if we want to train shoco with the words in a readme file, but without punctuation and whitespace, we could do $ ./generate_compression_model.py --split=whitespace --strip=punctuation README.md Since we haven’t specified an output file, the resulting table file is printed on stdout. This is most likely all you’ll need to generate a good model, but if you are adventurous, you might want to play around with all the options of the script: Type generate_compression_model.py --help to get a friendly help message. We won’t dive into the details here, though – just one word of warning: Generating tables can be slow if your input data is large, and especially so if you use the --optimize-encoding option. Using pypy can significantly speed up the process. Comparisons With Other Compressors smaz There’s another good small string compressor out there: smaz. smaz seems to be dictionary based, while shoco is an entropy encoder. As a result, smaz will often do better than shoco when compressing common english terms. However, shoco typically beats smaz for more obscure input, as long as it’s ASCII. smaz may enlarge your string for uncommon words (like numbers), shoco will never do that for ASCII strings. Performance-wise, shoco is typically faster by at least a factor of 2. As an example, compressing and decompressing all words in /usr/dict/share/words with smaz takes around 0.325s on my computer and compresses on average by 28%, while shoco has a compression average of 33% (with the standard model; an optimized model will be even better) and takes around 0.145s. shoco is especially fast at decompression. shoco can be trained with user data, while smaz’s dictionary is built-in. That said, the maximum compression rate of smaz is hard to reach for shoco, so depending on your input type, you might fare better with smaz (there’s no way around it: You have to measure it yourself). gzip, xz As mentioned, shoco’s compression ratio can’t (and doesn’t want to) compete with gzip et al. for strings larger than a few bytes. But for very small strings, it will always be better than standard compressors. The performance of shoco should always be several times faster than about any standard compression tool. For testing purposes, there’s a binary inlcuded (unsurprisingly called shoco) that compresses and decompresses single files. The following timings were made with this command line tool. The data is /usr/share/dict/words (size: 4,953,680), compressing it as a whole (not a strong point of shoco): compressor compression time decompression time compressed size shoco 0.070s 0.010s 3,393,975 gzip 0.470s 0.048s 1,476,083 xz 3.300s 0.148s 1,229,980 This demonstates quite clearly that shoco’s compression rate sucks, but also that it’s very fast. Javascript Version For showing off, shoco ships with a Javascript version (shoco.js) that’s generated with emscripten. If you change the default compression model, you need to re-generate it by typing make js. You do need to have emscripten installed. The output is asm.js with a small shim to provide a convenient API: compressed = shoco.compress(input_string); output_string = shoco.decompress(compressed); The compressed string is really a Uint8Array, since that resembles a C string more closely. The Javascript version is not as furiously fast as the C version because there’s dynamic (heap) memory allocation involved, but I guess there’s no way around it. shoco.js should be usable as a node.js module. Tools And Other Included Extras Most of them have been mentioned already, but for the sake of completeness – let’s have a quick overview over what you’ll find in the repo: shoco.c, shoco.h, shoco_model.h The heart of the project. If you don’t want to bother with nitty-gritty details, and the compression works for you, it’s all you’ll ever need. models/* As examples, there are more models included. Feel free to use one of them instead of the default model: Just copy it over shoco_model.h and you’re all set. Re-build them with make models. training_data/* Some books from Project Gutenberg used for generating the default model. shoco.js Javascript library, generated by emscripten. Also usable as a node.js module (put it in node_modules and require it). Re-build with make js. shoco.html A example of how to use shoco.js in a website. shoco A testing tool for compressing and decompressing files. Build it with make shoco or just make. Use it like this: $ shoco compress file-to-compress.txt compressed-file.shoco $ shoco decompress compressed-file.shoco decompressed-file.txt It’s not meant for production use, because I can’t image why one would want to use shoco on entire files. test_input Another testing tool for compressing and decompressing every line in the input file. Build it with make test_input. Usage example: $ time ./test_input < /usr/share/dict/words  Number of compressed strings: 479828, average compression ratio: 33%  real   0m0.158s user   0m0.145s sys    0m0.013s Adding the command line switch -v gives line-by-line information about the compression ratios. Makefile It’s not the cleanest or l33test Makefile ever, but it should give you hints for integrating shoco into your project. tests Invoke them with make check. They should pass. Things Still To Do shoco is stable, and it works well – but I’d have only tested it with gcc/clang on x86_64 Linux. Feedback on how it runs on other OSes, compilers and architectures would be highly appreciated! If it fails, it’s a bug (and given the size of the project, it should be easy to fix). Other than that, there’s a few issues that could stand some improvements: There should be more tests, because there’s never enough tests. Ever. Patches are very welcome! Tests should include model generation. As that involves re-compilation, these should probably written as a Makefile, or in bash or Python (maybe using ctypes to call the shoco-functions directly). The Python script for model generation should see some clean-up, as well as documentation. Also it should utilize all cpu cores (presumably via the multiprocess-module). This is a good task for new contributers! Again for model generation: Investigate why pypy isn’t as fast as should be expected (jitviewer might be of help here). Make a real node.js module. The current SSE2 optimization is probably not optimal. Anyone who loves to tinker with these kinds of micro-optimizations is invited to try his or her hand here. Publishing/packaging it as a real library probably doesn’t make much sense, as the model is compiled-in, but maybe we should be making it easier to use shoco as a git submodule (even if it’s just about adding documentation), or finding other ways to avoid the copy&paste installation. Feedback If you use shoco, or like it for whatever reason, I’d really love to hear from you! If wished for, I can provide integration with shoco for your commercial services (at a price, of course), or for your totally awesome free and open source software (for free, if I find the time). Also, a nice way of saying thanks is to support me financially via git tip or flattr. If you find a bug, or have a feature request, file it! If you have a question about usage or internals of shoco, ask it on stackoverflow for good exposure – and write me a mail, so that I don’t miss it. Authors shoco is written by Christian Schramm. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/Ed-von-Schleck/shoco"	"A compressor for small text strings.."	"true"
"String Manipulation"	"smaz"	"https://github.com/antirez/smaz"	"An efficient string compression library.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"461"	"24"	"60"	"GitHub - antirez/smaz: Small strings compression library Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 24 Star 461 Fork 60 antirez/smaz Code Issues 1 Pull requests 4 Pulse Graphs Small strings compression library 7 commits 1 branch 0 releases Fetching contributors C 100.0% C Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Latest commit 2f62584 Feb 24, 2012 antirez Smaz test improved. Permalink Failed to load latest commit information. COPYING README and COPYING added Mar 31, 2009 Makefile first commit Mar 31, 2009 README doc updated Mar 31, 2009 TODO TODO added with feedbacks from progreddit / hackernews Apr 1, 2009 smaz.c first commit Mar 31, 2009 smaz.h first commit Mar 31, 2009 smaz_test.c Smaz test improved. Feb 24, 2012 README SMAZ - compression for very small strings -----------------------------------------  Smaz is a simple compression library suitable for compressing very short strings. General purpose compression libraries will build the state needed for compressing data dynamically, in order to be able to compress every kind of data. This is a very good idea, but not for a specific problem: compressing small strings will not work.  Smaz instead is not good for compressing general purpose data, but can compress text by 40-50% in the average case (works better with English), and is able to perform a bit of compression for HTML and urls as well. The important point is that Smaz is able to compress even strings of two or three bytes!  For example the string ""the"" is compressed into a single byte.  To compare this with other libraries, think that like zlib will usually not be able to compress text shorter than 100 bytes.  COMPRESSION EXAMPLES --------------------  'This is a small string' compressed by 50% 'foobar' compressed by 34% 'the end' compressed by 58% 'not-a-g00d-Exampl333' enlarged by 15% 'Smaz is a simple compression library' compressed by 39% 'Nothing is more difficult, and therefore more precious, than to be able to decide' compressed by 49% 'this is an example of what works very well with smaz' compressed by 49% '1000 numbers 2000 will 10 20 30 compress very little' compressed by 10%  In general, lowercase English will work very well. It will suck with a lot of numbers inside the strings. Other languages are compressed pretty well too, the following is Italian, not very similar to English but still compressible by smaz:  'Nel mezzo del cammin di nostra vita, mi ritrovai in una selva oscura' compressed by 33% 'Mi illumino di immenso' compressed by 37% 'L'autore di questa libreria vive in Sicilia' compressed by 28%  It can compress URLS pretty well:  'http://google.com' compressed by 59% 'http://programming.reddit.com' compressed by 52% 'http://github.com/antirez/smaz/tree/master' compressed by 46%  USAGE -----  The lib consists of just two functions:      int smaz_compress(char *in, int inlen, char *out, int outlen);  Compress the buffer 'in' of length 'inlen' and put the compressed data into 'out' of max length 'outlen' bytes. If the output buffer is too short to hold the whole compressed string, outlen+1 is returned. Otherwise the length of the compressed string (less then or equal to outlen) is returned.      int smaz_decompress(char *in, int inlen, char *out, int outlen);  Decompress the buffer 'in' of length 'inlen' and put the decompressed data into 'out' of max length 'outlen' bytes. If the output buffer is too short to hold the whole decompressed string, outlen+1 is returned. Otherwise the length of the compressed string (less then or equal to outlen) is returned. This function will not automatically put a nul-term at the end of the string if the original compressed string didn't included a nulterm.   CREDITS -------  Small was writte by Salvatore Sanfilippo and is released under the BSD license. Check the COPYING file for more information.  Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/antirez/smaz"	"An efficient string compression library.."	"true"
"Testing"	"CHEAT"	"https://github.com/Tuplanolla/cheat"	"A very simple unit testing framework.."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"122"	"3"	"5"	"GitHub - Tuplanolla/cheat: A convenient unit testing framework for the C programming language Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 3 Star 122 Fork 5 Tuplanolla/cheat forked from Tordek/cheat Code Issues 1 Pull requests 0 Pulse Graphs A convenient unit testing framework for the C programming language http://users.jyu.fi/~sapekiis/cheat/ 264 commits 3 branches 4 releases Fetching contributors C 94.6% Groff 4.3% Other 1.1% C Groff Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags develop master release-1 Nothing to show 1.0.3 1.0.2 1.0.1 1.0.0 Nothing to show New pull request Pull request Compare This branch is 214 commits ahead of Tordek:master. Latest commit 08f04c4 Apr 25, 2015 Tuplanolla Merge branch 'release-1' Permalink Failed to load latest commit information. pictures tests LICENSE README.md cheat.7 cheat.h cheats.h dependencies.dot example.c examples.c gcc-4_7_0-release make.bat makefile makefile.bat makefile.clang makefile.gcc Adjusted the warnings slightly. Jul 31, 2014 makefile.tcc meta.c streams.dot test test.bat windowed.h README.md CHEAT CHEAT stands for C Header Embedded Automated Testing or something like that. It is a convenient unit testing framework for the C programming language. It has no dependencies and requires no installation or configuration. Only a header file and a test case is needed. #include <cheat.h>  CHEAT_TEST(mathematics_still_work,     cheat_assert(2 + 2 == 4);     cheat_assert_not(2 + 2 == 5); )  The following section presents the basic use case; you can skip to section 2 if you are only looking for an overview. 1   Getting Started In this introduction it is assumed that you are running a Linux system with the GNU Core Utilities and the GNU Compiler Collection installed. None of that is necessary, but it makes the introduction easier to follow. Compatibility with other tools and operating systems is addressed in section 4. 1.1   Preparing First you need to download the main header [user@computer:~]$ wget http://github.com/Tuplanolla/cheat/raw/1.0.3/cheat.h  and move it to a suitable location like the global search path [user@computer:~]$ sudo mv -i cheat.h /usr/include  or the working directory of your project. [user@computer:~]$ mv -i cheat.h project  Then you are ready to write tests. 1.2   Writing Tests Tests go into their own source file. [user@computer:~/project]$ cat > tests.c #include <cheat.h>  It is an ordinary file with the exception that it is processed more than once. Therefore you must wrap all top level declarations and definitions with the appropriate preprocessor directives. The reason for that is found in section 2.3. Including the main header is enough to get an empty test suite, but such a thing is not very useful beyond making sure everything is set up right. The next step is to define tests. You can define tests with CHEAT_TEST(name, statements) and their success conditions called assertions with cheat_assert(bool expected). Doing so is demonstrated in the example file. [user@computer:~/project]$ wget http://github.com/Tuplanolla/cheat/raw/1.0.3/example.c [user@computer:~/project]$ mv -i example.c tests.c  The example also shows how you can declare global variables with CHEAT_DECLARE(declarations) and manage them with CHEAT_SET_UP(statements) and CHEAT_TEAR_DOWN(statements), which are executed before and after each test respectively. A detailed explanation of the entire interface is in section 3.2. However it is important to note that the state of all global variables that are mutable (as in modified by any execution path) is undefined when the set up or, in case there is no set up, a test begins. It is time to run your new tests. 1.3   Running Tests Tests compile into an executable [user@computer:~/project]$ gcc -I . -o tests tests.c  that takes care of running the tests and reporting their outcomes. There are two things that need to be taken care of when compiling a test suite. First you have to add the directory of the test suite to the search path, as is done here with -I .. Then you have to make __BASE_FILE__ point to the test suite, by using -D __BASE_FILE__=\""tests.c\"" or such, if the compiler does not. The reason is related to the previous oddity and again found in section 2.3. The resulting executable runs tests in a security harness if possible, so the suite does not crash or hang if one of its tests does. [user@computer:~/project]$ ./tests ..:..??..!.. --- tests.c:81: assertion in 'philosophy_never_worked' failed: 'heap == stack' tests.c:104: assertion in 'important' failed: 'THIS_TEST == IMPORTANT_TEST' --- 8 successful and 2 failed of 12 run FAILURE  The results are reported in five parts. The first part is the progress bar, where a success is a green dot, a failure is a red colon, a crash is a red exclamation mark, a time out is a yellow exclamation mark and an ignored outcome is signaled with a yellow question mark. The second part contains diagnostic messages in a format similar to what many popular C compilers produce. The third and fourth parts, which are omitted here, hold the contents of the captured standard output and error streams. The fifth and last part, which is always shown, briefly summarizes what the outcome of the test suite is. A test suite is considered successful if and only if every single one of its tests completes without failing a single assertion. The outcome is also reflected by the exit code of the process. [user@computer:~/project]$ echo returned $? returned 1  You can change the behavior of the test suite with command line options or force running individual tests by giving their names as arguments. [user@computer:~/project]$ ./tests --list --minimal | xargs ./tests ..:..:.:..!.. --- example.c:81: assertion in 'philosophy_never_worked' failed: 'heap == stack' example.c:104: assertion in 'important' failed: 'THIS_TEST == IMPORTANT_TEST' example.c:112: assertion in 'pointless' failed: '(0 | ~0) == 0' --- 9 successful and 4 failed of 13 run FAILURE  The option syntax is specified in section 3.3. 1.4   Using Extensions There is an extension header in addition to the main header. [user@computer:~/project]$ wget http://github.com/Tuplanolla/cheat/raw/1.0.3/cheats.h  It is supposed to be used as a supplement and expects the main header to be included first. [user@computer:~/project]$ cat > tests.c #include <cheat.h> #include <cheats.h>  It provides specialized assertions like cheat_assert_double(double actual, double expected, double tolerance) and cheat_assert_string(char const* actual, char const* expected) for they require less typing and provide more detailed diagnostic messages. Its features are demonstrated in the additional example file. [user@computer:~/project]$ wget http://github.com/Tuplanolla/cheat/raw/1.0.3/examples.c [user@computer:~/project]$ mv -i examples.c tests.c  You can read more about the extensions in section 3.4. Hopefully you have now gotten started by now. 2   Overview 2.1   License CHEAT is free software and as such licensed under the simplified BSD license with two clauses. The full license can be found in the LICENSE file that resides in the same directory as this file. In short, copies and derivative works are permitted as long as they use the same license. It would be licensed under the GNU GPL, but the authors felt that such a decision would hinder its adoption. 2.2   History The project was started on 2012-08-07 and first released on 2014-08-07. It was originally written by Guillermo ""Tordek"" Freschi for the entertainment and education of everyone in the ISO/IEC 9899 community on Freenode. The prototype was later picked up by Sampsa ""Tuplanolla"" Kiiskinen who grew tired of unit testing frameworks that suck and wondered what happened to the one that did not. It was rewritten, stuffed with new features and finally audited in a small scale. 2.3   Implementation The working principle is best explained by a thought experiment. Imagine a source file including a header file. Then imagine the header file including the source file that included it. Now imagine doing that three times in a row within the same header file. Proceed to imagine redefining all of the identifiers each time. Finally imagine doing all of that with preprocessor directives. What you ended up with is CHEAT. It sounds strange, but it works. 2.4   Correctness Everything in the project is built with extreme care and attention to detail. While the authors are quite confident the project is free of serious bugs, they are mere mortals and not well versed in certified programming. 2.5   Contributing The support for Windows and other more exotic operating systems is not complete. For example stream capturing is currently very limited without POSIX interfaces. Contributions in the forms of feedback and pull requests are all very welcome! 3   Usage 3.1   Files The project contains other useful files in addition to the main header. You can acquire them by cloning the repository [user@computer:~]$ git clone git@github.com:Tuplanolla/cheat.git [user@computer:~]$ cd cheat  or downloading the clone directly. [user@computer:~]$ wget http://github.com/Tuplanolla/cheat/archive/1.0.3.zip [user@computer:~]$ unzip 1.0.3.zip [user@computer:~]$ mv -i cheat-1.0.3 cheat [user@computer:~]$ cd cheat  In addition to the main header there is an extension header and examples of how to use them with various compilers. [user@computer:~/cheat]$ less example.c examples.c [user@computer:~/cheat]$ make -f makefile.gcc  The extensions are introduced in section 3.4. There are also tests for corner cases, [user@computer:~/cheat]$ ls tests [user@computer:~/cheat]$ ./test  supplementary reading material [user@computer:~/cheat]$ man ./cheat.7 [user@computer:~/cheat]$ sudo cp -i cheat.7 /usr/man/man7 [user@computer:~/cheat]$ sudo gzip /usr/man/man7/cheat.7  and things used during development. [user@computer:~/cheat]$ xdot streams.dot [user@computer:~/cheat]$ tcc -run meta.c 4 [user@computer:~/cheat]$ rm -i windowed.h  3.2   Interface Tests can be defined with CHEAT_TEST(name, statements), where name must be a valid identifier and statements a list of statements. The identifier must not conflict with an existing preprocessor directive. For example putc is not a valid identifier, because it is reserved by the standard library and exit and write may not be valid unless CHEAT_NO_WRAP is defined, because procedures that resemble continuations or effects are wrapped by default. The list of statements must not be empty or ambiguous. For example int x, y; may be interpreted as an invalid parameter list if the compiler does not support __VA_ARGS__. Solutions to that are presented in section 5.5. Tests can also be defined with CHEAT_IGNORE(name, statements) and CHEAT_SKIP(name, statements). They work like CHEAT_TEST(name, statements) with the exception that the outcome of the former is ignored and the latter is not executed at all, but only when they are not explicitly requested to be run. That feature is explained in section 3.3. Repeated tests can be defined with CHEAT_REPEAT(name, statements), which is otherwise identical with CHEAT_TEST(name, statements), but the statement list is repeated until a failure or CHEAT_REPETITIONS is reached. Its purpose is to make working with stochastic tests less of a hassle. Manually interrupting tests that have already failed can be achieved by calling cheat_yield(void) in the appropriate place. It must not be used outside test cases or compatible procedures, because it can only alter the control flow of the procedure it is called from. Here compatible procedures mean procedures that have the same type as CHEAT_GET(name) for any valid name. Tests need success conditions called assertions and those can be checked with cheat_assert(bool expected) or its logical complement cheat_assert_not(bool unexpected). The condition is satisfied if expected is true or, in other words, not zero. In addition to tests it is possible to write global declarations by putting them inside CHEAT_DECLARE(declarations), where declarations must be a valid list of top level declarations or definitions. Preprocessor directives do not need it since an #ifndef condition works similarly. Global definitions can also contain assertions and be called from within tests. Running code before and after each test can be done with CHEAT_SET_UP(statements) and CHEAT_TEAR_DOWN(statements), where statements is a list of statements with the same restrictions as before. There can be only one set up and one tear down in a test suite. The names given to tests are not directly used identifiers, but the identifier of a test can be retrieved with CHEAT_GET(name), where name must match the name of the test. Pointers to test procedures have the type cheat_procedure or equivalently void (*)(void). The convenient CHEAT_CALL(name) is equivalent to CHEAT_GET(name)(). The behavior of the test suite is primarly controlled with command line options. However some of the options are compiled into the test suite and their default values can be overridden by defining them before including the main header. The size_t CHEAT_REPETITIONS option controls the amount of repetitions done by CHEAT_REPEAT(name, statements). Its default value is 256. The size_t CHEAT_LIMIT option determines how long string literals in diagnostic messages can be. Its valid values go from 3 to SIZE_MAX - 1 and the default is the maximum length of a string literal required by the standard. The CHEAT_TIME option sets the maximum time after which unresponsive tests are terminated if such a thing is possible. It is always stored in milliseconds, but its type is implementation defined. The default value is two thousand and therefore equal to two seconds. The int CHEAT_OFFSET option changes the range of exit codes used for internal interprocess communication. The only reason it exists is to stop serious crashes that use reserved error numbers from showing up with the wrong outcome. The CHEAT_NO_MAIN option removes the main procedure from the test suite, making it possible to link it with other object files. It is not very useful. The CHEAT_NO_WRAP option prevents wrapping procedures that resemble continuations or effects. Such procedures include exit, printf, fwrite, fflush and perror. It is only useful if the tests rely on the exact way they call standard library and system procedures or their names clash with existing preprocessor directives. Wrapping can be undone with CHEAT_UNWRAP(name) instead of turning it off or repeated with CHEAT_WRAP(name) if it is already turned off. The expansion of commas can be delayed with CHEAT_COMMAS(...) or, in case __VA_ARGS__ is not available, with CHEAT_COMMA or the matching CHEAT_COMMAS_ n (x1, x2, ... ), where n is the amount of commas in the argument list. For example CHEAT_COMMAS(int x, y;), int x CHEAT_COMMA y; and CHEAT_COMMAS_1(int x, y;) all expand to int x, y;. 3.3   Options Test suites obey a basic set of command line options so that they do not need to be recompiled after every change. There are options and names with slightly different semantics. Options begin with a dash. They are parameterless, essentially orderless and case insensitive. Each of them has a long and a short form that work identically. Everything else is considered a name. Since names might start with a dash, there is a special -- option that disables parsing and so turns the arguments that come after it into names. For example the command ./tests -e x --plain -- -ed would treat x and -ed as a names and the rest as options. It is safe to use wrong or conflicting options, because they are checked before anything else is done. The -h for --help option briefly summarizes all of the options. The -v for --version option prints the name of the project and its version. The -l for --list option lists the names of all of the tests. The -s for --safe option enables a security harness that runs tests in isolated processes if fork() or CreateProcess() is supported. The -d for --dangerous option provides an alternative harness that runs everything in the same process, but provides some stability by attempting to recover from fatal signals like SIGFPE and SIGSEGV. It most likely leads to undefined behavior, but luckily undefined behavior is often defined enough behavior. The -u for --unsafe option disables all security measures. The -t for --timed option enables terminating unresponsive processes and the -e for --eternal option disables doing so. The -n for --noisy option enables capturing and displaying the contents of the standard streams and the -q for --quiet option enables them. As an added bonus the -c for --colorful option makes everything colorful if the output terminal has ISO/IEC 6429 escape sequence support, the -m for --minimal option makes those things machine readable and the -x for --xml option does nothing for good measure. The default options depend on the target platform. 3.4   Extensions Specialized assertions can be checked with the matching cheat_assert_ i ( t actual, t expected), where t is its type and i is an identifier built from the type. The CHEAT_NO_MATH option disables floating point extensions that use a few mathematical functions and therefore may require compiling the test suite with -lm to link libm. 3.5   Design Decisions Empty tests and test suites are both have successful outcomes, because every predicate is true for the empty set, so why not choose favorably? 4   Portability 4.1   Standards Compliance CHEAT follows the original language specification, ANSI X3.159-1989 or ISO/IEC 9899:1990, and the first POSIX specification, IEEE Std 1003.1-1988, to the letter. It also takes the newer revisions, both ISO/IEC 9899:1999 and IEEE Std 1003.1-2001, into account whenever possible. The project does not require a POSIX system to work, but it helps, because only the most critical features are universal and just a few of the rest are compatible with Windows. While the project does not rely on a particular compiler, it is easier to use with some of them. Specialized build automation scripts are provided to help hammer out common problems and save you from needless frustration. [user@computer:~/cheat]$ make -f makefile.gcc    computer# make -f makefile.tcc    E:\CHEAT> makefile.bat  You can see screenshots of them in section 6. 4.2   Language Compatibility The project is designed for C, but also works with C++. It abides by ISO/IEC 14882:1998 as far as is reasonable. Hopefully it is not an issue to wade through a million warnings. [user@computer:~/cheat]$ make -e CC=g++ -f makefile.gcc  5   Bugs and Limitations CHEAT is naturally fickle, because it is built with heavy preprocessor abuse. Some problems are impossible to fix, so they are collected into this section. 5.1   Identifiers Identifiers starting with CHEAT_ and cheat_ are reserved for internal use as C does not have namespaces. Extensions reserve identifiers starting with CHEATS_ and cheats_ as well. 5.2   Base File If the compiler does not define __BASE_FILE__, then the test suite will fail to compile. Luckily it can be to set to __FILE__ at the beginning of the test suite #ifndef __BASE_FILE__ #define __BASE_FILE__ __FILE__ #endif  or defined manually. 5.3   Commas Using commas directly inside preprocessor directives like CHEAT_TEST(name, statements) without support for __VA_ARGS__ causes everything that comes after them to be interpreted as extra arguments. The solution is to delay the expansion of the commas as described in section 3.2. 5.4   Expressions The expressions given to cheat_assert(bool expected) and friends should be at most 509 characters long since they are converted into string literals and the limit of their length may be that low. 5.5   Broken Compiler If the compiler works like Microsoft C/C++ (commonly known as cl.exe) and defines both __BASE_FILE__ and __FILE__ wrong, then the test suite will be empty. The definition should be fed to the compiler manually. 5.6   Debugging It is not possible to attach a breakpoint to any of the identifiers that are part of the public interface, because they are all preprocessor directives. Attaching one to CHEAT_GET(name) or cheat_check() should work instead. 5.7   Printing Streams are captured by default, so it is not possible to print things on the screen while the tests are running. However using the CHEAT_NO_WRAP option with the --dangerous option allows bypassing stream capturing. 6   Screenshots Everyone likes pretty pictures. Here is a picture of CHEAT being compiled with the GNU Compiler Collection and run in the Xfce terminal emulator that is provided by a Linux distribution. Here is a picture of CHEAT being compiled with Microsoft C/C++ and run in the command prompt of Windows XP. Here is a picture of CHEAT being compiled with Borland Turbo C and run in the default shell of FreeDOS. 7   Reference 7.1   Main Header CHEAT_TEST(name, statements) defines a test CHEAT_IGNORE(name, statements) defines a test that does not matter CHEAT_SKIP(name, statements) defines a test that is not run CHEAT_REPEAT(name, statements) defines a test that is repeated several times   cheat_yield(void) interrupts a test if it has already failed   cheat_assert(bool expected) checks a success condition cheat_assert_not(bool unexpected) checks the opposite of a success condition   CHEAT_DECLARE(declarations) creates global declarations and definitions   CHEAT_SET_UP(statements) defines what to do before every test CHEAT_TEAR_DOWN(statements) defines what to do after every test   CHEAT_GET(name) returns a test procedure CHEAT_CALL(name) calls a test procedure   size_t CHEAT_REPETITIONS controls the amount of repetitions size_t CHEAT_LIMIT determines the maximum length of string literals CHEAT_TIME sets the time after which unresponsive tests are terminated int CHEAT_OFFSET changes the range of internal exit codes CHEAT_NO_MAIN does not compile main() CHEAT_NO_WRAP disables wrapping certain procedures CHEAT_UNWRAP(name) returns an unwrapped procedure CHEAT_WRAP(name) returns a wrapped procedure CHEAT_COMMA expands to a comma CHEAT_COMMAS(...) separates its arguments with commas CHEAT_COMMAS_1(x1, x2) separates its arguments with commas   CHEAT_BEGIN and CHEAT_END turn a preprocessor directive into a statement type CHEAT_CAST(type, expression) casts pointer types when using C++ size_t CHEAT_INTEGER_LENGTH(type) returns the string length of an integer   size_t CHEAT_PASS determines the internal state of preprocessing   CHEAT_H guards the main header 7.2   Command Line -h or --help shows this help -v or --version prints version information -l or --list lists test cases   -s or --safe runs tests in isolated subprocesses -d or --dangerous pretends that crashing tests do nothing harmful -u or --unsafe lets crashing tests bring down the test suite   -t or --timed terminates isolated tests that take too long -e or --eternal allows isolated tests to take their time   -n or --noisy captures and displays standard streams -q or --quiet does not capture standard streams   -c or --colorful uses ISO/IEC 6429 escape codes to color text -m or --minimal reports things in a machine readable format -p or --plain presents everything in plain text 7.3   Extension Header cheat_assert_char(char actual, char expected) checks a specialized success condition cheat_assert_not_char(char actual, char unexpected) checks the opposite of a specialized success condition   cheat_assert_short_int(short int actual, short int expected) cheat_assert_not_short_int(short int actual, short int unexpected) cheat_assert_short_unsigned_int(short unsigned int actual, short unsigned int expected) cheat_assert_not_short_unsigned_int(short unsigned int actual, short unsigned int unexpected) cheat_assert_int(int actual, int expected) cheat_assert_not_int(int actual, int unexpected) cheat_assert_unsigned_int(unsigned int actual, unsigned int expected) cheat_assert_not_unsigned_int(unsigned int actual, unsigned int unexpected) cheat_assert_long_int(long int actual, long int expected) cheat_assert_not_long_int(long int actual, long int unexpected) cheat_assert_long_unsigned_int(long unsigned int actual, long unsigned int expected) cheat_assert_not_long_unsigned_int(long unsigned int actual, long unsigned int unexpected)   cheat_assert_double(double actual, double expected, double tolerance) cheat_assert_not_double(double actual, double unexpected, double tolerance)   cheat_assert_size(size_t actual, size_t expected) cheat_assert_not_size(size_t actual, size_t unexpected) cheat_assert_ptrdiff(ptrdiff_t actual, ptrdiff_t expected) cheat_assert_not_ptrdiff(ptrdiff_t actual, ptrdiff_t unexpected)   cheat_assert_long_long_int(long long int actual, long long int expected) cheat_assert_not_long_long_int(long long int actual, long long int unexpected) cheat_assert_long_long_unsigned_int(long long unsigned int actual, long long unsigned int expected) cheat_assert_not_long_long_unsigned_int(long long unsigned int actual, long long unsigned int unexpected)   cheat_assert_float(float actual, float expected, float tolerance) cheat_assert_not_float(float actual, float unexpected, float tolerance)   cheat_assert_long_double(long double actual, long double expected, long double tolerance) cheat_assert_not_long_double(long double actual, long double unexpected, long double tolerance)   cheat_assert_int8(int8_t actual, int8_t expected) cheat_assert_not_int8(int8_t actual, int8_t unexpected) cheat_assert_uint8(uint8_t actual, uint8_t expected) cheat_assert_not_uint8(uint8_t actual, uint8_t unexpected) cheat_assert_int16(int16_t actual, int16_t expected) cheat_assert_not_int16(int16_t actual, int16_t unexpected) cheat_assert_uint16(uint16_t actual, uint16_t expected) cheat_assert_not_uint16(uint16_t actual, uint16_t unexpected) cheat_assert_int32(int32_t actual, int32_t expected) cheat_assert_not_int32(int32_t actual, int32_t unexpected) cheat_assert_uint32(uint32_t actual, uint32_t expected) cheat_assert_not_uint32(uint32_t actual, uint32_t unexpected) cheat_assert_int64(int64_t actual, int64_t expected) cheat_assert_not_int64(int64_t actual, int64_t unexpected) cheat_assert_uint64(uint64_t actual, uint64_t expected) cheat_assert_not_uint64(uint64_t actual, uint64_t unexpected) cheat_assert_int_fast8(int_fast8_t actual, int_fast8_t expected) cheat_assert_not_int_fast8(int_fast8_t actual, int_fast8_t unexpected) cheat_assert_uint_fast8(uint_fast8_t actual, uint_fast8_t expected) cheat_assert_not_uint_fast8(uint_fast8_t actual, uint_fast8_t unexpected) cheat_assert_int_fast16(int_fast16_t actual, int_fast16_t expected) cheat_assert_not_int_fast16(int_fast16_t actual, int_fast16_t unexpected) cheat_assert_uint_fast16(uint_fast16_t actual, uint_fast16_t expected) cheat_assert_not_uint_fast16(uint_fast16_t actual, uint_fast16_t unexpected) cheat_assert_int_fast32(int_fast32_t actual, int_fast32_t expected) cheat_assert_not_int_fast32(int_fast32_t actual, int_fast32_t unexpected) cheat_assert_uint_fast32(uint_fast32_t actual, uint_fast32_t expected) cheat_assert_not_uint_fast32(uint_fast32_t actual, uint_fast32_t unexpected) cheat_assert_int_fast64(int_fast64_t actual, int_fast64_t expected) cheat_assert_not_int_fast64(int_fast64_t actual, int_fast64_t unexpected) cheat_assert_uint_fast64(uint_fast64_t actual, uint_fast64_t expected) cheat_assert_not_uint_fast64(uint_fast64_t actual, uint_fast64_t unexpected) cheat_assert_int_least8(int_least8_t actual, int_least8_t expected) cheat_assert_not_int_least8(int_least8_t actual, int_least8_t unexpected) cheat_assert_uint_least8(uint_least8_t actual, uint_least8_t expected) cheat_assert_not_uint_least8(uint_least8_t actual, uint_least8_t unexpected) cheat_assert_int_least16(int_least16_t actual, int_least16_t expected) cheat_assert_not_int_least16(int_least16_t actual, int_least16_t unexpected) cheat_assert_uint_least16(uint_least16_t actual, uint_least16_t expected) cheat_assert_not_uint_least16(uint_least16_t actual, uint_least16_t unexpected) cheat_assert_int_least32(int_least32_t actual, int_least32_t expected) cheat_assert_not_int_least32(int_least32_t actual, int_least32_t unexpected) cheat_assert_uint_least32(uint_least32_t actual, uint_least32_t expected) cheat_assert_not_uint_least32(uint_least32_t actual, uint_least32_t unexpected) cheat_assert_int_least64(int_least64_t actual, int_least64_t expected) cheat_assert_not_int_least64(int_least64_t actual, int_least64_t unexpected) cheat_assert_uint_least64(uint_least64_t actual, uint_least64_t expected) cheat_assert_not_uint_least64(uint_least64_t actual, uint_least64_t unexpected) cheat_assert_intmax(intmax_t actual, intmax_t expected) cheat_assert_not_intmax(intmax_t actual, intmax_t unexpected) cheat_assert_uintmax(uintmax_t actual, uintmax_t expected) cheat_assert_not_uintmax(uintmax_t actual, uintmax_t unexpected) cheat_assert_intptr(intptr_t actual, intptr_t expected) cheat_assert_not_intptr(intptr_t actual, intptr_t unexpected) cheat_assert_uintptr(uintptr_t actual, uintptr_t expected) cheat_assert_not_uintptr(uintptr_t actual, uintptr_t unexpected)   cheat_assert_float_complex(float complex actual, float complex expected, float tolerance) cheat_assert_not_float_complex(float complex actual, float complex unexpected, float tolerance) cheat_assert_double_complex(double complex actual, double complex expected, double tolerance) cheat_assert_not_double_complex(double complex actual, double complex unexpected, double tolerance) cheat_assert_long_double_complex(long double complex actual, long double complex expected, long double tolerance) cheat_assert_not_long_double_complex(long double complex actual, long double complex unexpected, long double tolerance)   cheat_assert_signed_char(signed char actual, signed char expected) cheat_assert_not_signed_char(signed char actual, signed char unexpected) cheat_assert_unsigned_char(unsigned char actual, unsigned char expected) cheat_assert_not_unsigned_char(unsigned char actual, unsigned char unexpected)   cheat_assert_pointer(void const* actual, void const* expected) cheat_assert_not_pointer(void const* actual, void const* unexpected)   cheat_assert_string(char const* actual, char const* expected) cheat_assert_not_string(char const* actual, char const* expected)   CHEAT_NO_MATH disables mathematical assertions   CHEATS_H guards the extension header Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/Tuplanolla/cheat"	"A very simple unit testing framework.."	"true"
"Testing"	"Check"	"http://check.sourceforge.net/"	"A unit testing framework for C. only."	"null"	"null"	"null"	"GNU LGPL2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"null"	"null"	"null"	"Check | Unit testing framework for C Check Unit Testing Framework for C Check has moved to Github Please see the Check project page at Github: http://libcheck.github.io/check Sourceforge | Cloudbees Template provided by: DesignsByDarren.com"	"null"	"null"	"A unit testing framework for C. only."	"true"
"Testing"	"CMock"	"https://github.com/ThrowTheSwitch/CMock"	"A mock/stub generator for C.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"98"	"40"	"64"	"GitHub - ThrowTheSwitch/CMock: CMock - Mock/stub generator for C Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 40 Star 98 Fork 64 ThrowTheSwitch/CMock Code Issues 18 Pull requests 2 Pulse Graphs CMock - Mock/stub generator for C http://throwtheswitch.org 404 commits 3 branches 0 releases 17 contributors C++ 50.3% C 22.8% Ruby 17.1% Tcl 8.6% Other 1.2% C++ C Ruby Tcl Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags add_make_support bugfix/const master Nothing to show Nothing to show New pull request Latest commit 3aa9f60 Jul 13, 2016 mvandervoord committed on GitHub Merge pull request #88 from dmurdin/TMS470 … Pragma fix for TMS470 compilers. (Thanks!) Permalink Failed to load latest commit information. config Normalize all the line endings Jan 7, 2016 docs add mock_suffix configuration option Mar 1, 2016 examples fixed white space Jan 4, 2016 iar Normalize all the line endings Jan 7, 2016 lib Pragma fix for TMS470 compilers. Jul 13, 2016 release Pulled in latest Unity and CException and bumped version Apr 14, 2016 scripts Two small fixes to shell integration points. May 4, 2016 src -fix whitespace Jan 4, 2016 targets -fix whitespace Jan 5, 2016 test Fixed unit tests for TMS470 pragma fix. Jul 13, 2016 vendor Pulled in latest Unity and CException and bumped version Apr 15, 2016 .gitattributes - Added a couple more tests to our details test Dec 30, 2015 .gitignore Fixed/cleaned up require paths in make support scripts. Apr 7, 2015 .gitmodules Updated to latest version of Unity. Jul 25, 2014 .travis.yml Removed regression testing in Travis CI against Ruby 1.8.7, since 1.9… Apr 6, 2015 Gemfile - fixed license to make it standard MIT license. Dec 16, 2014 README.md updated README to have the correct bundle command May 7, 2015 Rakefile -fix whitespace Jan 5, 2016 rakefile_helper.rb - Added a couple more tests to our details test Dec 30, 2015 README.md CMock - Mock/stub generator for C Getting Started > git clone --recursive https://github.com/throwtheswitch/cmock.git > cd cmock > bundle install # Ensures you have all RubyGems needed > bundle exec rake # Run all CMock library tests  API Documentation Not sure what you're doing? View docs/CMock_Summary.md Interested in our MIT-style license? View docs/license.txt Are there examples? They are all in /examples Any other resources to check out? Definitely! Check out our developer portal on ThrowTheSwitch.org Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/ThrowTheSwitch/CMock"	"A mock/stub generator for C.."	"true"
"Testing"	"cmocka"	"https://cmocka.org/"	"A unit testing framework with support for mock objects.."	"null"	"null"	"null"	"Apache2.0"	"http://directory.fsf.org/wiki/License:Apache2.0"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"A unit testing framework with support for mock objects.."	"false"
"Testing"	"Criterion"	"https://github.com/Snaipe/Criterion"	"A KISS, non-intrusive C test framework.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"303"	"26"	"38"	"GitHub - Snaipe/Criterion: A KISS, non-intrusive cross-platform C unit testing framework Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 26 Star 303 Fork 38 Snaipe/Criterion Code Issues 16 Pull requests 2 Pulse Graphs A KISS, non-intrusive cross-platform C unit testing framework 1,074 commits 24 branches 18 releases 8 contributors C 44.7% C++ 25.9% CMake 12.4% Perl 10.0% Objective-C 3.8% Shell 1.6% Other 1.6% C C++ CMake Perl Objective-C Shell Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: bleeding Switch branches/tags Branches Tags bleeding coverity_scan emergency/fix-windows features/assert-msg-literal-fix features/cram-tests features/fp-compare features/io-rewrite-nanopb features/json-reporting features/language-decouple features/multiple-languages features/new-logging features/new-reporting features/parallel features/parameterized-tests features/pkg-config features/refactor features/sphinx-doxygen features/valgrind-integration features/winfork features/xml-reporting gh-pages master patch wip/nanomsg-fork Nothing to show v2.2.2 v2.2.1 v2.2.0 v2.1.1 v2.1.0 v2.0.2 v2.0.1 v2.0.0 v1.3.1 v1.3.0 v1.2.2 v1.2.1 v1.2.0 v1.1.0 v1.0.0 v0.3 v0.2 v0.1 Nothing to show New pull request Latest commit 0c9c765 Jul 1, 2016 Snaipe committed on GitHub Merge pull request #130 from kevinoid/freebsd-support … Compilation and test fixes for FreeBSD Permalink Failed to load latest commit information. .cmake Link against libanl only for getaddrinfo_a Jun 28, 2016 dependencies nanomsg: Updated winnt version and set fork sources to be unix-only Apr 23, 2016 dev dev: Fix FindCriterion.cmake package name May 15, 2016 doc Merge branch 'patch' into bleeding Jun 20, 2016 include/criterion Behavior of cr_assert_str* assertions changed: Jun 7, 2016 po Behavior of cr_assert_str* assertions changed: Jun 7, 2016 samples Fixed cross-compiling of cmake subprojects Feb 19, 2016 src Merge branch 'patch' into bleeding Jun 20, 2016 test Allow nullptr or __null in asserts.t Jun 28, 2016 .bumpversion.cfg Merge branch 'patch' into bleeding Jun 20, 2016 .gitignore Merge branch 'features/io-rewrite-nanopb' into bleeding Jan 18, 2016 .gitmodules Revert ""Switched from nanomsg to zeromq temporarily until the fork pa… Jan 28, 2016 .travis.yml travis: Added whole source archive deployment on github releases (fixes May 22, 2016 CMakeLists.txt Link against libanl only for getaddrinfo_a Jun 28, 2016 CONTRIBUTING.md Updated contribution road map Sep 17, 2015 ChangeLog release: Prepare release 2.2.2 Jun 20, 2016 LICENSE We're in 2016. Jan 6, 2016 README.md readme: Fixed travis badge not displaying Jun 28, 2016 appveyor.yml Merge branch 'patch' into bleeding Jun 20, 2016 debian.copyright [license] Updated license year on missed files Jan 18, 2016 description.txt Added missing files for ppa builds Nov 28, 2015 README.md A dead-simple, yet extensible, C and C++ unit testing framework. Philosophy Most test frameworks for C require a lot of boilerplate code to set up tests and test suites -- you need to create a main, then register new test suites, then register the tests within these suits, and finally call the right functions. This gives the user great control, at the unfortunate cost of simplicity. Criterion follows the KISS principle, while keeping the control the user would have with other frameworks: C99 and C++11 compatible. Tests are automatically registered when declared. Implements a xUnit framework structure. A default entry point is provided, no need to declare a main unless you want to do special handling. Test are isolated in their own process, crashes and signals can be reported and tested. Unified interface between C and C++: include the criterion header and it just works. Supports parameterized tests and theories. Progress and statistics can be followed in real time with report hooks. TAP output format can be enabled with an option. Runs on Linux, FreeBSD, Mac OS X, and Windows (Compiling with MinGW GCC and Visual Studio 2015+). Downloads Packages Mac OS X: brew install snaipe/soft/criterion AUR: yaourt -S criterion Binary archives Binary releases are available on the release page If you have a different platform, you can still build the library from source Developer Resources Documentation An online documentation is available on ReadTheDocs (PDF | Zip | Epub) Samples Sample tests can be found in the sample directory. A simple test Using multiple suites Writing assertions Adding test fixtures Tests with signals Using report hooks Getting help Channel Description Snaipe/Criterion on gitter.im #criterion on irc.freenode.net Misc CMake find module for Criterion Credits Logo made by Paul Bouigue Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/Snaipe/Criterion"	"A KISS, non-intrusive C test framework.."	"true"
"Testing"	"CUnit"	"http://cunit.sourceforge.net/"	"Another unit testing framework for C. only."	"null"	"null"	"null"	"GNU LGPL2.0"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"null"	"null"	"null"	"CUnit Home   CUnit A Unit Testing Framework for C   Overview Documentation Screenshots Contacts Example Code   Project Home      CUnit is a lightweight system for writing, administering, and running unit tests in C.  It provides C programmers a basic testing functionality with a flexible variety of user interfaces.      CUnit is built as a static library which is linked with the user's testing code.  It uses a simple framework for building test structures, and provides a rich set of assertions for testing common data types.   In addition, several different interfaces are provided for running tests and reporting results. These interfaces currently include: Automated Output to xml file Non-interactive Basic Flexible programming interface Non-interactive Console Console interface (ansi C) Interactive Curses Graphical interface (Unix) Interactive"	"null"	"null"	"Another unit testing framework for C. only."	"true"
"Testing"	"Cutest"	"https://github.com/rafael-santiago/cutest"	"Library for unit testing with memory leak detection (Linux, freeBSD and Windows).."	"null"	"null"	"null"	"GPL2"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"14"	"1"	"0"	"GitHub - rafael-santiago/cutest: C-Library for unit testing Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 1 Star 14 Fork 0 rafael-santiago/cutest Code Issues 0 Pull requests 0 Pulse Graphs C-Library for unit testing 80 commits 1 branch 0 releases Fetching contributors C 100.0% C Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Fetching latest commit… Cannot retrieve the latest commit at this time. Permalink Failed to load latest commit information. doc src .gitignore README.md README.md Cutest Cutest is an acronym that can be undestood as C unit test. This library brings a bunch of macros in order to guide the implementation of unit tests for C projects. It brings a minimal memory leak detection system (fully working on Linux, Windows and FreeBSD). It is possible customize the logs generated by your tests if you want to. How to build it? To build cutest the hefesto usage is necessary. Being Hefesto installed in your system all you need to emit on a shell inside the cutest's src subdirectory is: hefesto After a file named libcutest.a which stands for the library will be generated under the path src/lib. Now just use this file and the header src/cutest.h to develop your further unit tests. Note that the build was written based on GCC. So, you need to have the gcc/mingw installed (and well exported) on your system before going ahead. Maybe you should read the documentation before starting. Note for Visual Studio users If you want to build cutest under MSVC you need to use Forgefile-msvc.hsl instead of the default Forgefile.hsl script. For this goal the build command changes a little. Being inside the cutest's src subdirectory: hefesto --forgefile=Forgefile-msvc.hsl --Forgefile-msvc-projects=cutest After run the command above a file named libcutest.lib will be generated inside src/lib path. Note that use cutest on MSVC is a little bit tricky. It envolves composite the cutest with your current msvcrt.lib (it explains why the cutest.lib is so huge). Another point is that this experimental build was written for Visual Studio 2012 only. If you want to generate a debug version try: hefesto --forgefile=Forgefile-msvc.hsl --Forgefile-msvc-projects=cutest --compile-model=debug Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/rafael-santiago/cutest"	"Library for unit testing with memory leak detection (Linux, freeBSD and Windows).."	"true"
"Testing"	"minunit"	"https://github.com/siu/minunit"	"Minimal unit testing framework for C.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"110"	"13"	"28"	"GitHub - siu/minunit: Minimal unit testing framework for C Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 13 Star 110 Fork 28 siu/minunit Code Issues 0 Pull requests 3 Pulse Graphs Minimal unit testing framework for C 37 commits 1 branch 0 releases Fetching contributors C 100.0% C Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Latest commit 374af43 Jan 13, 2015 siu Merge pull request #7 from cr1901/master … Convert minunit.h to be ANSI C89 compliant (range comments and variable ... Permalink Failed to load latest commit information. MIT-LICENSE.txt Add license Jun 25, 2012 README.md fixed typo in gcc flags Mar 12, 2013 minunit.h Merge pull request #7 from cr1901/master Jan 13, 2015 minunit_example.c Add helper macro MU_RUN_SUITE() Sep 19, 2012 README.md MinUnit Minunit is a minimal unit testing framework for C/C++ self-contained in a single header file. It provides a way to define and configure test suites and a few handy assertion types. It reports the summary of the number of tests run, number of assertions and time elapsed. Note that this project is based on: http://www.jera.com/techinfo/jtns/jtn002.html How to use it This is a minimal test suite written with minunit: #include ""minunit.h""  MU_TEST(test_check) {     mu_check(5 == 7); } MU_TEST_SUITE(test_suite) {     MU_RUN_TEST(test_check); }  int main(int argc, char *argv[]) {     MU_RUN_SUITE(test_suite);     MU_REPORT();     return 0; }  Which will produce the following output: F test_check failed:     readme_sample.c:4: 5 == 7   1 tests, 1 assertions, 1 failures  Finished in 0.00032524 seconds (real) 0.00017998 seconds (proc)  Check out minunit_example.c to see a complete example. Compile with something like: gcc minunit_example.c -lrt -lm -o minunit_example  Don't forget to add -lrt for the timer and -lm for linking the function fabs used in mu_assert_double_eq. Setup and teardown functions One can define setup and teardown functions and configure the test suite to run them by using the macro MU_SUITE_CONFIGURE with within a MU_TEST_SUITE declaration. Assertion types mu_check(condition): will pass if the condition is evaluated to true, otherwise it will show the condition as the error message mu_fail(message): will fail and show the message mu_assert(condition, message): will pass if the condition is true, otherwise it will show the failed condition and the message mu_assert_int_eq(expected, result, message): it will pass if the two numbers are equal or show their values and the message mu_assert_double_eq(expected, result, message): it will pass if the two values are almost equal or show their values and the message. The value of MINUNIT_EPSILON sets the threshold to determine if the values are close enough. Authors David Siñuela Pastor siu.4coders@gmail.com Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/siu/minunit"	"Minimal unit testing framework for C.."	"true"
"Testing"	"Unity"	"https://github.com/ThrowTheSwitch/Unity"	"A simple unit testing framework for C.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"392"	"88"	"171"	"GitHub - ThrowTheSwitch/Unity: Simple Unit Testing for C Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 88 Star 392 Fork 171 ThrowTheSwitch/Unity Code Issues 15 Pull requests 3 Pulse Graphs Simple Unit Testing for C http://ThrowTheSwitch.org 515 commits 3 branches 1 release 35 contributors C 76.7% Ruby 18.8% Python 3.1% Makefile 1.2% C++ 0.2% C Ruby Python Makefile C++ Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags feature/cmd_line_args master stack_traces Nothing to show v2.1.0 Nothing to show New pull request Latest commit ad0c07c Jul 13, 2016 mvandervoord committed on GitHub Merge pull request #204 from dmurdin/tms470 … Weak attribute fix for TMS470 Compilers. Permalink Failed to load latest commit information. auto Escape backslashes for windows paths, fixes #137. Jul 13, 2016 docs The class gives back to the community: better documentation produced … May 6, 2016 examples Change example_1 to compile with std=c89 May 15, 2016 extras Update Fixtures too. May 6, 2016 release Update Version Apr 14, 2016 src Weak attribute fix for TMS470 Compilers. Jul 13, 2016 test making new flush routines work under all defined conditions. Jun 21, 2016 .gitattributes - fix whitespace Jan 4, 2016 .gitignore ignore more stuff we don't care about Dec 3, 2015 .travis.yml Add an option to omit UNITY_OUTPUT_CHAR declaration from the header Apr 24, 2016 README.md Fix trailing whitespace CRLF, no code changes Jan 6, 2016 README.md Unity Test API Copyright (c) 2007 - 2014 Unity Project by Mike Karlesky, Mark VanderVoord, and Greg Williams Running Tests RUN_TEST(func, linenum)  Each Test is run within the macro RUN_TEST. This macro performs necessary setup before the test is called and handles cleanup and result tabulation afterwards. Ignoring Tests There are times when a test is incomplete or not valid for some reason. At these times, TEST_IGNORE can be called. Control will immediately be returned to the caller of the test, and no failures will be returned. TEST_IGNORE()  Ignore this test and return immediately TEST_IGNORE_MESSAGE (message)  Ignore this test and return immediately. Output a message stating why the test was ignored. Aborting Tests There are times when a test will contain an infinite loop on error conditions, or there may be reason to escape from the test early without executing the rest of the test. A pair of macros support this functionality in Unity. The first TEST_PROTECT sets up the feature, and handles emergency abort cases. TEST_ABORT can then be used at any time within the tests to return to the last TEST_PROTECT call. TEST_PROTECT()  Setup and Catch macro TEST_ABORT()  Abort Test macro Example: main() {     if (TEST_PROTECT() == 0)     {         MyTest();     } }  If MyTest calls TEST_ABORT, program control will immediately return to TEST_PROTECT with a non-zero return value. Unity Assertion Summary Basic Validity Tests TEST_ASSERT_TRUE(condition)  Evaluates whatever code is in condition and fails if it evaluates to false TEST_ASSERT_FALSE(condition)  Evaluates whatever code is in condition and fails if it evaluates to true TEST_ASSERT(condition)  Another way of calling TEST_ASSERT_TRUE TEST_ASSERT_UNLESS(condition)  Another way of calling TEST_ASSERT_FALSE TEST_FAIL() TEST_FAIL_MESSAGE(message)  This test is automatically marked as a failure. The message is output stating why. Numerical Assertions: Integers TEST_ASSERT_EQUAL_INT(expected, actual) TEST_ASSERT_EQUAL_INT8(expected, actual) TEST_ASSERT_EQUAL_INT16(expected, actual) TEST_ASSERT_EQUAL_INT32(expected, actual) TEST_ASSERT_EQUAL_INT64(expected, actual)  Compare two integers for equality and display errors as signed integers. A cast will be performed to your natural integer size so often this can just be used. When you need to specify the exact size, like when comparing arrays, you can use a specific version: TEST_ASSERT_EQUAL_UINT(expected, actual) TEST_ASSERT_EQUAL_UINT8(expected, actual) TEST_ASSERT_EQUAL_UINT16(expected, actual) TEST_ASSERT_EQUAL_UINT32(expected, actual) TEST_ASSERT_EQUAL_UINT64(expected, actual)  Compare two integers for equality and display errors as unsigned integers. Like INT, there are variants for different sizes also. TEST_ASSERT_EQUAL_HEX(expected, actual) TEST_ASSERT_EQUAL_HEX8(expected, actual) TEST_ASSERT_EQUAL_HEX16(expected, actual) TEST_ASSERT_EQUAL_HEX32(expected, actual) TEST_ASSERT_EQUAL_HEX64(expected, actual)  Compares two integers for equality and display errors as hexadecimal. Like the other integer comparisons, you can specify the size... here the size will also effect how many nibbles are shown (for example, HEX16 will show 4 nibbles). _ARRAY  You can append _ARRAY to any of these macros to make an array comparison of that type. Here you will need to care a bit more about the actual size of the value being checked. You will also specify an additional argument which is the number of elements to compare. For example: TEST_ASSERT_EQUAL_HEX8_ARRAY(expected, actual, elements)  TEST_ASSERT_EQUAL(expected, actual)  Another way of calling TEST_ASSERT_EQUAL_INT TEST_ASSERT_INT_WITHIN(delta, expected, actual)  Asserts that the actual value is within plus or minus delta of the expected value. This also comes in size specific variants. Numerical Assertions: Bitwise TEST_ASSERT_BITS(mask, expected, actual)  Use an integer mask to specify which bits should be compared between two other integers. High bits in the mask are compared, low bits ignored. TEST_ASSERT_BITS_HIGH(mask, actual)  Use an integer mask to specify which bits should be inspected to determine if they are all set high. High bits in the mask are compared, low bits ignored. TEST_ASSERT_BITS_LOW(mask, actual)  Use an integer mask to specify which bits should be inspected to determine if they are all set low. High bits in the mask are compared, low bits ignored. TEST_ASSERT_BIT_HIGH(bit, actual)  Test a single bit and verify that it is high. The bit is specified 0-31 for a 32-bit integer. TEST_ASSERT_BIT_LOW(bit, actual)  Test a single bit and verify that it is low. The bit is specified 0-31 for a 32-bit integer. Numerical Assertions: Floats TEST_ASSERT_FLOAT_WITHIN(delta, expected, actual)  Asserts that the actual value is within plus or minus delta of the expected value. TEST_ASSERT_EQUAL_FLOAT(expected, actual) TEST_ASSERT_EQUAL_DOUBLE(expected, actual)  Asserts that two floating point values are ""equal"" within a small % delta of the expected value. String Assertions TEST_ASSERT_EQUAL_STRING(expected, actual)  Compare two null-terminate strings. Fail if any character is different or if the lengths are different. TEST_ASSERT_EQUAL_STRING_LEN(expected, actual, len)  Compare two strings. Fail if any character is different, stop comparing after len characters. TEST_ASSERT_EQUAL_STRING_MESSAGE(expected, actual, message)  Compare two null-terminate strings. Fail if any character is different or if the lengths are different. Output a custom message on failure. TEST_ASSERT_EQUAL_STRING_LEN_MESSAGE(expected, actual, len, message)  Compare two strings. Fail if any character is different, stop comparing after len characters. Output a custom message on failure. Pointer Assertions Most pointer operations can be performed by simply using the integer comparisons above. However, a couple of special cases are added for clarity. TEST_ASSERT_NULL(pointer)  Fails if the pointer is not equal to NULL TEST_ASSERT_NOT_NULL(pointer)  Fails if the pointer is equal to NULL Memory Assertions TEST_ASSERT_EQUAL_MEMORY(expected, actual, len)  Compare two blocks of memory. This is a good generic assertion for types that can't be coerced into acting like standard types... but since it's a memory compare, you have to be careful that your data types are packed. _MESSAGE you can append _MESSAGE to any of the macros to make them take an additional argument. This argument is a string that will be printed at the end of the failure strings. This is useful for specifying more information about the problem. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/ThrowTheSwitch/Unity"	"A simple unit testing framework for C.."	"true"
"Emacs"	"CEDET"	"http://cedet.sourceforge.net/"	"Collection of Emacs Development Environment Tools; designed to provide IDE-like features to Emacs. Built-in. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"Collection of Emacs Development Environment Tools Homepage        CEDET   User Tools    Simple Setup    Project Management    Smart Completion    Find References    Code Generation    UML Graphs    Language Support    Project Support   Developer Primers    Add a Language    Add external tool   Parts of CEDET    EDE    Semantic    SRecode    Cogre    Speedbar    EIEIO    Misc Tools    Documentation   Releases    1.0.1    1.1   Source Forge    Project    Mailing Lists     cedet-devel     cedet-semantic     cedet-eieio    Screenshots    Git Repository   More Tools    JDEE    ECB    CompletionUI    << Files >> What is CEDET ? CEDET is a Collection of Emacs Development Environment Tools written with the end goal of creating an advanced development environment in Emacs. CEDET is hosted at Source Forge and is Free Software. You can view CEDET's CVS archive, project summary, and mailing lists at the CEDET Project page. Why is CEDET needed? Emacs already is a great environment for writing software, but there are additional areas that need improvement. Many new ideas for integrated environments have been developed in newer products, such as Microsoft's Visual environment, JBuilder, or Eclipse. CEDET is a project which implements several advanced features developers have come to expect from an Editor. CEDET: A User's View So what does an Emacs User get out of CEDET? CEDET includes the following major user features: Projects The CEDET Project management system provides a few simple keystrokes for organizing your files, building Makefiles or Automake files, and compiling your sources. If you don't want CEDET to manage your Makefiles, CEDET will still be able to identify some types of projects based on pre-existing build configurations, such as the Emacs sources, the Linux kernel, or any project built using Automake. The entire CEDET Makefile tree was built with CEDET's project management system, so when you download and build the distribution package, you will be using a CEDET project. The image to the right shows a part of the Project management menu. Smart Completion Write code with smart code completion, sometimes known as ""Intellisense"". The CEDET infrastructure for parsing and tagging files, and analyzing source code is one of the most accurate completion tools for C++ anywhere. It will correctly handle inheritance scoping rules, templates, smart-pointers, and automatically filters based on what the value will be assigned into. Code completion is not restricted to just C or C++. The completion engine is generic and works for any language that has a robust tagging parser written for CEDET, and a thin adaptation layer for the language. See the language support page to see if your language is supported. The image to the right shows smart completion configured to use a popup menu in a CEDET unit test source file going through a templated smart pointer. Smart Help/Jump Smart help shows the prototype of the variable or method under point. As with the smart completion, it will correctly identify the method under point, deriving it's correct prototype by dereferencing the datatypes through templates and smart pointers. The smart jump feature is similar to the classic Emacs TAGS feature, except it always goes to the correct location. Using TAGS on a method name makes you scan through all the possible methods with the same name to find the one you want. Using the CEDET smart jump feature takes you to the right definition the first time. Symbol References Analyze where symbols are referenced in your code base. The Symbol References tool in CEDET can use external tools such as GNU Global, ID Utils, CScope, or even find/grep to locate usages of your symbols. Every location is analyzed and displayed hierarchically showing you the file and function the reference occurs in, instead of a flat list of locations. The image to the right shows integration with GNU Global running in the GNU Global source code. Code Generation Generate code with a powerful language-independent template system. The template system in CEDET is a framework designed for code-generating application developers. Even so, the base system and templates can also be used to insert small repetitive code blocks. The template language is straight-forward, and flexible. Because it uses the same code analytics as the Smart completion, it often can correctly guess a wide range of values to be used in your templates, saving you typing. Some pre-existing tools that use CEDET's code generation system will write texinfo documentation for you, create doxygen style comments fully filled out from the local context, or insert get/set methods for variables in a class. The image to the right shows a simple class declaration inserted into an empty buffer. UML Diagrams Create UML diagrams either by hand, or automatically generate simple 3-tier class diagrams from your sources. The diagrams are linked to your source-code, so you can browse quickly through you code from the convenience of UML. The image to the right shows CEDET's UML tool's source code, called 'COGRE', diagramming and browsing itself. Optional unicode character support is enabled for the special characters. Advanced Code Browsing With the CEDET parsing backend, advanced code browsing tools like ECB can be used. ECB, or the Emacs Code Browser provides an advanced set of UI windows docked to your Emacs frame. The extra windows provide a wide range of features, including: A list of functions, classes, and methods in the current file A code analyzer/completions list A current definition display A directory tree, A list of source files in the current directory, A history of recently visited files, and many others The ECB image on the right shows a sample of ECB (in full size). ECB is NOT a part of CEDET, and must be downloaded and installed seperately. Install and Configure CEDET Setting up a tool as large and complex as CEDET can seem daunting. Fortunately, a minimal CEDET initialization can take up only a couple lines of code in your .emacs file. If you are brave and enjoy customizing your CEDET past this, then you are in luck as there are more options and small features to play with than anyone sane person might want. Alex Ott has written a great article called A Gentle Introduction to CEDET that shows both the simple CEDET configuration process, and a wide array of customizations that helps tune your Emacs for programming the smart way. The image to the right shows the CEDET internal package and revision testing output. Making sure all the package revisions needed are accurate is important, and fully automatic. Contribute to CEDET In many ways, CEDET is a big pile of infrastructure with a thin user interface sitting on it. Consider helping CEDET by using the infrastructure to build better or more user interface tools. You can also help by adding more support for different languages. Join the cedet-devel mailing list to learn more. Downloading CEDET All the CEDET tools are available from a single distribution file to ease installation. Latest Stable Release: CEDET 1.1 Try out cedet-1.1.tar.gz. CEDET 1.1 includes all the security fixes from 1.0.1, a long list of bug fixes, and additional new features to support Java, Android and Arduino programming! Our goal for CEDET 1.1 is that this will be the LAST release using the current install and file organization schemes. This will also be the last release to support Emacs 22! Future released versions will use a new file system scheme compatible with Emacs 24.< After building CEDET 1.1, consider joining the mailing list and help make CEDET better. Previous Stable Release: CEDET 1.0.1 The previous stable release is cedet-1.0.1.tar.gz. You will need CEDET 1.0.1 for older versions of Emacs, such as Emacs 21 or 22.1. About this Security Release: CEDET 1.0 has a security issue related to loading project files with EDE. If you are using CEDET 1.0, please upgrade to CEDET 1.0.1 to recover from this issue. If you use Emacs 23.3 with built-in CEDET, please upgrade to Emacs 23.4 or later, apply the patch, or upgraded to CEDET 1.0.1. CEDET Development Did you find a bug? If you encounter problems with a CEDET release, those issues may have already been fixed in Git! CEDET has an active community of users that help identify and fix these issues quickly. You can check the mailing list archives or just try the Git version directly. When using CEDET from Git, please note that we are transitioning to a new file and install scheme to be more compatible with Emacs 24. Changes will be required in your .emacs. Emacs Version Support: CEDET 1.0.1, and 1.1* has TWO automated build processes, one via Make, and the other via starting Emacs, and executing a build command. This table shows the automated testing done for the release of CEDET 1.1:   Emacs 22 Emacs 23 Emacs 24 UBuntu 11.10 ✓ Debian Stable ✓ ✓ ✓ OSX 10.6 ✓ ✓ Windows 7/cygwin ✓ Emacs 21 CEDET's test suite will fail, but most parts still work for CEDET 1.0.1. XEmacs Neither build process works with XEmacs 21.4. It is possible to build parts of it by hand it so it works however. SXEmacs We have integrated patches to support SXEmacs, but we haven't tested it ourselves. Parts of CEDET have been reported to install and work. Windows XP/7 If you do not have cygwin, you will need to use the cedet-build.el script to build CEDET.   Eric's homepage Return to CEDET. Send mail to cedet-devel to contact the developers. Visit Siege-engine.com to see what I do in analog land. Copyright(C) 1997,98,99,2000,01,02,03,04,05,06,07,08,09,10,11 Eric M. Ludlam Verbatim copying and distribution is permitted in any medium, provided this notice is preserved.    "	"null"	"null"	"Collection of Emacs Development Environment Tools; designed to provide IDE-like features to Emacs. Built-in. or later."	"true"
"Emacs"	"Flycheck"	"https://github.com/flycheck/flycheck"	"Modern syntax checking. For C, it can use either GCC or Clang as a back-end. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"1069"	"54"	"214"	"GitHub - flycheck/flycheck: On the fly syntax checking for GNU Emacs Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 54 Star 1,069 Fork 214 flycheck/flycheck Code Issues 48 Pull requests 10 Pulse Graphs On the fly syntax checking for GNU Emacs http://www.flycheck.org 3,980 commits 2 branches 32 releases 116 contributors Emacs Lisp 96.9% Python 1.2% Makefile 0.9% Go 0.1% Ruby 0.1% Rust 0.1% Other 0.7% Emacs Lisp Python Makefile Go Ruby Rust Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags 836-new-chaining master Nothing to show 28 27 26 0.25.1 0.25 0.24 0.23 0.22 0.21 0.20 0.19 0.18 0.17 0.16 0.15 0.14.1 0.14 0.13 0.12 0.11 0.10 0.9 0.8 0.7.1 0.7 0.6.1 0.6 0.5 0.4 0.3 0.2 0.1 Nothing to show New pull request Latest commit b97df1e Jul 15, 2016 lunaryorn Add process for adding new maintainers Permalink Failed to load latest commit information. .github License contributions under any later GPL version Jul 15, 2016 doc Add process for adding new maintainers Jul 15, 2016 maint Require release announcements on Twitter account Jun 2, 2016 test Fix indentation Jul 11, 2016 .gitignore Require bundle install prior to rake Jan 3, 2016 .lgtm Explicitly add the default lgtm pattern Jul 12, 2016 .mailmap Update mailmap Dec 8, 2015 .travis.yml Don’t allow Emacs snapshot tests to fail Jul 11, 2016 CHANGES.old Split old changelog into separate file Apr 5, 2016 CHANGES.rst Optionally install golang test dependencies Jul 12, 2016 COPYING Re-license as GPL 3 Dec 30, 2012 Cask Update scala mode package name May 17, 2016 MAINTAINERS Add hidden mail address to fix parsing error Jul 15, 2016 Makefile Fix Makefile help Jun 5, 2016 README.md Drop Waffle Jun 29, 2016 flycheck-buttercup.el Port help tests to buttercup and simplify them May 18, 2016 flycheck-ert.el Disable local variables hook May 14, 2016 flycheck.el Optionally install golang test dependencies Jul 12, 2016 flycheck.svg [Fix #331] Add logo for Flycheck Jun 6, 2014 README.md Flycheck is a modern on-the-fly syntax checking extension for GNU Emacs 24, intended as replacement for the older Flymake extension which is part of GNU Emacs. It uses various syntax checking and linting tools to automatically check the contents of buffers while you type, and reports warnings and errors directly in the buffer or in an optional error list (see Flycheck manual for more information): Out of the box Flycheck supports over 40 different programming languages with more than 80 different syntax checking tools, and comes with a simple interface to define new syntax checkers. Many 3rd party extensions provide new syntax checkers and other features like alternative error displays or mode line indicators. Try out Flycheck needs GNU Emacs 24.3 or newer, and works best on Unix systems. Windows users, please be aware that Flycheck does not support Windows officially, although it should mostly work fine on Windows. See Windows support and watch out for known Windows issues! Install some syntax checker tools and type the following in your *scratch* buffer and run M-x eval-buffer: (require 'package) (add-to-list 'package-archives              '(""melpa"" . ""http://stable.melpa.org/packages/"") t) (package-initialize) (package-refresh-contents)  (package-install 'flycheck)  (global-flycheck-mode) For a more gentle introduction read the Installation instructions and go through Quickstart guide. Support & Contribution Please ask questions about Flycheck on Stack Exchange or in our Gitter chat. We try to answer all questions as fast and as precise as possible. To report problems or bugs, please use our issue tracker. Our Contributor’s Guide helps you to create good bug reports; please take a look. We welcome patches and pull requests that fix bugs or provide new features. Please read our Contributor’s Guide for help and guidance before submitting pull requests. When making larger changes to Flycheck or implementing new features we recommend that you first open a separate issue or ask in our Gitter channel to discuss you intended changes. All contributors and all participants in our communication channels are expected to follow our Code of Conduct. License Flycheck is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. Flycheck is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this program. If not, see http://www.gnu.org/licenses/. See COPYING for details. You may copy, distribute and/or modify the Flycheck documentation under the terms of the Creative Commons Attribution-ShareAlike 4.0 International Public License. A copy of the license can be obtained at https://creativecommons.org/licenses/by-sa/4.0/legalcode. Permission is granted to copy, distribute and/or modify the Flycheck logo in /flycheck.svg under the terms of the Creative Commons Attribution-ShareAlike 4.0 International Public License. A copy of the license can be obtained at https://creativecommons.org/licenses/by-sa/4.0/legalcode. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/flycheck/flycheck"	"Modern syntax checking. For C, it can use either GCC or Clang as a back-end. or later."	"true"
"Emacs"	"Yasnippet"	"https://github.com/capitaomorte/yasnippet"	"A template system, with C templates for common code snippets. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"1278"	"96"	"238"	"GitHub - joaotavora/yasnippet: A template system for Emacs Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 96 Star 1,278 Fork 238 joaotavora/yasnippet Code Issues 32 Pull requests 9 Pulse Graphs A template system for Emacs http://joaotavora.github.com/yasnippet/ 1,081 commits 22 branches 6 releases 43 contributors Emacs Lisp 98.7% Ruby 1.3% Emacs Lisp Ruby Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags 0.8-fsf-changes TRY-better-inhibit-modification-hooks alternate-692-proposal another-strategy-for-712 auto-compilation gh-pages improve-on-515-solution integration issue-537-experiment issue-558-snippet-local-exit-hooks issue-574-idea issue-665-multiline-mirror-indentation jit-loading jt-issue-497 master prevent-some-fallback-loops revamp-doc snippet-engine tighter-tab travis trigger-key-fallback-cleanup unclutter Nothing to show 0.10.0 0.9.1 0.9.1-snapshot 0.9.0-beta 0.9.0-a 0.8.0 Nothing to show New pull request Latest commit 9500b00 Jul 13, 2016 npostavs Fix field navigation in the backwards direction … * yasnippet.el (yas--find-next-field): For negative N, actually give the Nth previous field, not the 1st field. * yasnippet-tests.el (field-navigation): Add a 3rd field, and test calling `yas-prev-field' while on it.  Fixes #722. Permalink Failed to load latest commit information. doc Fix outdated and misformatted docs May 10, 2016 snippets @ 9ce0b05 Release 0.10.0 Jun 11, 2016 yasmate @ 0543618 Sync git submodule for yasmate repo Dec 31, 2013 .gitignore rake doc:upload: check for wrong/incomplete rev Dec 6, 2013 .gitmodules Update snippets submodule Jan 22, 2016 .travis.yml .travis.yml: Don't notify on success Jun 11, 2016 CONTRIBUTING.md * CONTRIBUTING.md: Add note about changelog only messages. Nov 7, 2015 NEWS Release 0.10.0 Jun 11, 2016 README.mdown Fix broken links in README.mdown May 24, 2016 Rakefile Support htmlize.el in Rakefile doc target Apr 30, 2016 yasnippet-debug.el Apply changes from GNU ELPA Jan 28, 2016 yasnippet-tests.el Fix field navigation in the backwards direction Jul 13, 2016 yasnippet.el Fix field navigation in the backwards direction Jul 13, 2016 README.mdown Intro YASnippet is a template system for Emacs. It allows you to type an abbreviation and automatically expand it into function templates. Bundled language templates include: C, C++, C#, Perl, Python, Ruby, SQL, LaTeX, HTML, CSS and more. The snippet syntax is inspired from TextMate's syntax, you can even import most TextMate templates to YASnippet. Watch a demo on YouTube. Installation Install the most recent version Clone this repository somewhere $ cd ~/.emacs.d/plugins $ git clone --recursive https://github.com/capitaomorte/yasnippet  Add the following in your .emacs file: (add-to-list 'load-path               ""~/.emacs.d/plugins/yasnippet"") (require 'yasnippet) (yas-global-mode 1)  Add your own snippets to ~/.emacs.d/snippets by placing files there or invoking yas-new-snippet. Install with package-install In a recent emacs M-x list-packages is the recommended way to list and install packages. MELPA keeps a very recent snapshot of YASnippet, see http://melpa.org/#installing. Install with el-get El-get is a nice way to get the most recent version, too. See https://github.com/dimitri/el-get for instructions. Use yas-minor-mode on a per-buffer basis To use YASnippet as a non-global minor mode, don't call yas-global-mode; instead call yas-reload-all to load the snippet tables and then call yas-minor-mode from the hooks of major-modes where you want YASnippet enabled. (yas-reload-all) (add-hook 'prog-mode-hook #'yas-minor-mode)  Where are the snippets? Yasnippet no longer bundles snippets directly, but it's very easy to get some! If you git-cloned yasnippet with the --recursive option you'll also download ""git submodules"" and find two subdirs under the main tree. snippets/ Points to yasnippet-snippets the snippet collection of AndreaCrotti. The default configuraiton already points to this dir, so to use them, just make sure the submodule really was downloaded (i.e. there are some files under snippets/) yasmate/ Points to a github repo of the yasmate tool, which is dedicated to converting textmate bundles into yasnippet snippets. To use these snippets you have to run the tool first, so see its doc), and then point the yas-snippet-dirs variable to the .../yasmate/snippets subdir. If you have a working ruby environment, you can probably get lucky directly with rake convert-bundles. textmate-to-yas.el This is another textmate bundle converting tool using Elisp instead of Ruby. Naturally, you can point yas-snippet-dirs to good snippet collections out there. If you have created snippets for a mode, or multiple modes, consider creating a repository to host them, then tell users that it should be added like this to yas-snippet-dirs: (setq yas-snippet-dirs       '(""~/.emacs.d/snippets""                 ;; personal snippets         ""/path/to/some/collection/""           ;; foo-mode and bar-mode snippet collection         ""/path/to/yasnippet/yasmate/snippets"" ;; the yasmate collection         ""/path/to/yasnippet/snippets""         ;; the default collection         ))  (yas-global-mode 1) ;; or M-x yas-reload-all if you've started YASnippet already.  Manual, issues etc Please refer to the comprehensive documentation for full customisation and support. If you find a bug in the code or in the documentation, please report it on the GitHub issue tracker. Important note regarding bug reporting Your bug reports are very valuable. The most important thing when reporting bugs is making sure that we have a way to reproduce the problem exactly like it happened to you. To do this, we need to rule out interference from external factors like other Emacs extensions or your own customisations. Here's an example report that ""sandboxes"" an Emacs session just for reproducing a bug. $ emacs --version Emacs 24.3 $ cd /tmp/ $ git clone https://github.com/capitaomorte/yasnippet.git yasnippet-bug $ cd yasnippet-bug $ git log -1 --oneline 6053db0 Closes #527: Unbreak case where yas-fallback-behaviour is a list $ HOME=$PWD emacs -L . # This ""sandboxes"" your emacs, melpa configuration, etc  (require 'yasnippet) (yas-global-mode 1)  When I open a foo-mode file I don't see foo-mode under the ""YASnippet"" menu! OR When loading yasnippet I see ""Error: failed to frobnicate""!  Using emacs -Q or temporarily moving your .emacs init file to the side is another way to achieve good reproducibility. Here's a another example of a bug report. It has everything needed for a successful analysis and speedy resolution. Also, don't forget to state the Emacs version (use M-x emacs-version) and the yasnippet version you are using (if using the latest from github, do git log -1 in the dir). Any more info is welcome, but don't just paste a backtrace or an error message string you got, unless we ask for it. There is also a YASnippet google group. I will keep the group open for reference and for discussion among users. Unfortunately I can't guarantee a timely response, so maybe it's better to create a github issue clearly marking your intent (user support/bug/feature request). Finally, thank you very much for using YASnippet! Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/capitaomorte/yasnippet"	"A template system, with C templates for common code snippets. or later."	"true"
"Vim"	"Syntastic"	"https://github.com/scrooloose/syntastic"	"Syntax checking and linting.."	"null"	"null"	"null"	"Do What The Fuck You Want To license"	"https://github.com/scrooloose/syntastic/blob/master/LICENCE"	"null"	"null"	"6860"	"187"	"835"	"GitHub - scrooloose/syntastic: Syntax checking hacks for vim Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 187 Star 6,860 Fork 835 scrooloose/syntastic Code Issues 28 Pull requests 6 Wiki Pulse Graphs Syntax checking hacks for vim 2,398 commits 3 branches 28 releases 258 contributors VimL 99.0% Other 1.0% VimL Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags loclist_state master sphinx_checker Nothing to show v0.5.7 v0.5.6 v0.5.5 v0.5.4 v0.5.3 v0.5.2 v0.5.1 v0.5.0 v0.4.0 v0.3.0 v0.2.0 v0.1.0 v0.0.6 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 2.3.0 2.2.0 2.1.0 2.0.0 1.2.0 1.1.0 1.0.0 Nothing to show New pull request Latest commit ddfa6a8 Jul 13, 2016 lcd047 Manual: document the SyntasticCheckHook() callback. Permalink Failed to load latest commit information. _assets make a cosmetic update to readme/screenshot Dec 27, 2011 autoload/syntastic New checker for JavaScript: tern-lint. Jun 21, 2016 doc Manual: document the SyntasticCheckHook() callback. Jul 13, 2016 plugin Manual: document the SyntasticCheckHook() callback. Jul 13, 2016 syntax_checkers Update MATLAB mlint after arguements Jul 8, 2016 .gitignore removed .DS_Store and added it to .gitignore Jan 18, 2012 CONTRIBUTING.md Documentation: move checker docs from the wiki to the manual. Jun 12, 2016 LICENCE add licence file Sep 17, 2012 README.markdown README: update the recipe for config files. Jul 11, 2016 README.markdown                ,               / \,,_  .'|            ,{{| /}}}}/_.'            _____________________________________________           }}}}` '{{'  '.            /                                             \         {{{{{    _   ;, \          /            Ladies and Gentlemen,              \      ,}}}}}}    /o`\  ` ;)        |                                                |     {{{{{{   /           (        |                 this is ...                    |     }}}}}}   |            \       |                                                |    {{{{{{{{   \            \      |                                                |    }}}}}}}}}   '.__      _  |     |    _____             __             __  _      |    {{{{{{{{       /`._  (_\ /     |   / ___/__  ______  / /_____ ______/ /_(_)____ |     }}}}}}'      |    //___/   --=:   \__ \/ / / / __ \/ __/ __ `/ ___/ __/ / ___/ | jgs `{{{{`       |     '--'       |  ___/ / /_/ / / / / /_/ /_/ (__  ) /_/ / /__   |      }}}`                         | /____/\__, /_/ /_/\__/\__,_/____/\__/_/\___/   |                                   |      /____/                                    |                                   |                                               /                                    \_____________________________________________/  Introduction Installation 2.1. Requirements 2.2. Installing syntastic with Pathogen Recommended settings FAQ 4.1. I installed syntastic but it isn't reporting any errors... 4.2. How can I check scripts written for different versions of Python? 4.3. How can I check scripts written for different versions of Ruby? 4.4. Are there any local checkers for HTML5 that I can use with syntastic? 4.5. The perl checker has stopped working... 4.6. What happened to the rustc checker? 4.7. What happened to the xcrun checker? 4.8. I run a checker and the location list is not updated... 4.8. I run:lopen or :lwindow and the error window is empty... 4.9. How can I pass additional arguments to a checker? 4.10. Syntastic supports several checkers for my filetype - how do I tell which one(s) to use? 4.11. What is the difference between syntax checkers and style checkers? 4.12. I have enabled multiple checkers for the current filetype. How can I display all errors from all checkers together? 4.13. How can I jump between the different errors without using the location list at the bottom of the window? 4.14. My favourite checker needs to load a configuration file from the project's root rather than the current directory... 4.15. The error window is closed automatically when I :quit the current buffer but not when I :bdelete it? Resources 1. Introduction Syntastic is a syntax checking plugin for Vim that runs files through external syntax checkers and displays any resulting errors to the user. This can be done on demand, or automatically as files are saved. If syntax errors are detected, the user is notified and is happy because they didn't have to compile their code or execute their script to find them. At the time of this writing, syntastic has checking plugins for ActionScript, Ada, Ansible configurations, API Blueprint, AppleScript, AsciiDoc, Assembly languages, BEMHTML, Bro, Bourne shell, C, C++, C#, Cabal, Chef, CoffeeScript, Coco, Coq, CSS, Cucumber, CUDA, D, Dart, DocBook, Dockerfile, Dust, Elixir, Erlang, eRuby, Fortran, Gentoo metadata, GLSL, Go, Haml, Haskell, Haxe, Handlebars, HSS, HTML, Java, JavaScript, JSON, JSX, LESS, Lex, Limbo, LISP, LLVM intermediate language, Lua, Markdown, MATLAB, Mercury, NASM, Nix, Objective-C, Objective-C++, OCaml, Perl, Perl POD, PHP, gettext Portable Object, OS X and iOS property lists, Pug (formerly Jade), Puppet, Python, QML, R, Racket, RDF TriG, RDF Turtle, Relax NG, reStructuredText, RPM spec, Ruby, SASS/SCSS, Scala, Slim, SML, Sphinx, SQL, Stylus, Tcl, TeX, Texinfo, Twig, TypeScript, Vala, Verilog, VHDL, VimL, xHtml, XML, XSLT, XQuery, YACC, YAML, YANG data models, z80, Zope page templates, and Zsh. See the manual for details about the corresponding supported checkers (:help syntastic-checkers in Vim). A number of third-party Vim plugins also provide checkers for syntastic, for example: merlin, omnisharp-vim, rust.vim, syntastic-extras, syntastic-more, vim-crystal, vim-eastwood, and vim-swift. Below is a screenshot showing the methods that Syntastic uses to display syntax errors. Note that, in practise, you will only have a subset of these methods enabled. Errors are loaded into the location list for the corresponding window. When the cursor is on a line containing an error, the error message is echoed in the command window. Signs are placed beside lines with errors - note that warnings are displayed in a different color. There is a configurable statusline flag you can include in your statusline config. Hover the mouse over a line containing an error and the error message is displayed as a balloon. (not shown) Highlighting errors with syntax highlighting. Erroneous parts of lines can be highlighted. 2. Installation 2.1. Requirements Syntastic itself has rather relaxed requirements: it doesn't have any external dependencies, and it needs a version of Vim compiled with a few common features: autocmd, eval, file_in_path, modify_fname, quickfix, reltime, and user_commands. Not all possible combinations of features that include the ones above make equal sense on all operating systems, but Vim version 7 or later with the ""normal"", ""big"", or ""huge"" feature sets should be fine. Syntastic should work with any modern plugin managers for Vim, such as NeoBundle, Pathogen, Vim-Addon-Manager, Vim-Plug, or Vundle. Instructions for installing syntastic with Pathogen are included below for completeness. Starting with Vim version 7.4.1486 you can also load syntastic using the standard mechanism of packages, without the help of third-party plugin managers (see :help packages in Vim for details). Beware however that, while support for packages has been added in Vim 7.4.1384, the functionality needed by syntastic is present only in versions 7.4.1486 and later. Last but not least: syntastic doesn't know how to do any syntax checks by itself. In order to get meaningful results you need to install external checkers corresponding to the types of files you use. Please consult the manual (:help syntastic-checkers in Vim) for a list of supported checkers. 2.2. Installing syntastic with Pathogen If you already have Pathogen working then skip Step 1 and go to Step 2. 2.2.1. Step 1: Install pathogen.vim First I'll show you how to install Tim Pope's Pathogen so that it's easy to install syntastic. Do this in your terminal so that you get the pathogen.vim file and the directories it needs: mkdir -p ~/.vim/autoload ~/.vim/bundle && \ curl -LSso ~/.vim/autoload/pathogen.vim https://tpo.pe/pathogen.vim Next you need to add this to your ~/.vimrc: execute pathogen#infect() 2.2.2. Step 2: Install syntastic as a Pathogen bundle You now have pathogen installed and can put syntastic into ~/.vim/bundle like this: cd ~/.vim/bundle && \ git clone https://github.com/scrooloose/syntastic.git Quit vim and start it back up to reload it, then type: :Helptags If you get an error when you do this, then you probably didn't install Pathogen right. Go back to Step 1 and make sure you did the following: Created both the ~/.vim/autoload and ~/.vim/bundle directories. Added the execute pathogen#infect() line to your ~/.vimrc file Did the git clone of syntastic inside ~/.vim/bundle Have permissions to access all of these directories. 3. Recommended settings Syntastic has numerous options that can be configured, and the defaults are not particularly well suitable for new users. It is recommended that you start by adding the following lines to your vimrc file, and return to them after reading the manual (see :help syntastic in Vim): set statusline+=%#warningmsg# set statusline+=%{SyntasticStatuslineFlag()} set statusline+=%*  let g:syntastic_always_populate_loc_list = 1 let g:syntastic_auto_loc_list = 1 let g:syntastic_check_on_open = 1 let g:syntastic_check_on_wq = 0 4. FAQ 4.1. Q. I installed syntastic but it isn't reporting any errors... A. The most likely reason is that none of the syntax checkers that it requires are installed. For example: by default, python requires either flake8 or pylint to be installed and in your $PATH. Read the manual (:help syntastic-checkers in Vim) to find out what executables are supported. Note that aliases do not work; the actual executables must be available in your $PATH. Symbolic links are okay though. You can see syntastic's idea of available checkers by running :SyntasticInfo. A second probable reason is that none of the available checkers are enabled. Syntastic comes preconfigured with a default list of enabled checkers per filetype, but this list is kept short in order to prevent slowing down Vim or trying to run conflicting checks. The command :SyntasticInfo will show you which checkers are enabled. You can tell syntastic which checkers (among the available ones) you want to run by setting g:syntastic_<filetype>_checkers in your vimrc (see below). A third possible reason is that the $PATH seen by syntastic might not be same as the $PATH in your login shell. Syntastic runs checkers using the shell pointed to by Vim's shell (or by g:syntastic_shell, if set), and that's the shell you need to configure to set the proper $PATH and environment variables for your checkers. You can see syntastic's idea of $PATH by running :echo syntastic#util#system('echo ""$PATH""') on UNIX and Mac OS-X systems, or :echo syntastic#util#system('echo %PATH%') on Windows. Finally, another reason it could fail is that either the command line options or the error output for a syntax checker may have changed. In this case, make sure you have the latest version of the syntax checker installed. If it still fails then post an issue - or better yet, create a pull request. 4.2. Q. How can I check scripts written for different versions of Python? A. Install a Python version manager such as virtualenv or pyenv, activate the environment for the relevant version of Python, and install in it the checkers you want to use. Set g:syntastic_python_checkers accordingly in your vimrc, and run Vim from the virtual environment. If you're starting Vim from a desktop manager rather than from a terminal you might need to write wrapper scripts around your checkers, to activate the virtual environment before running the actual checks. Then you'll need to point the relevant g:syntastic_python_<checker>_exec variables to the wrapper scripts. 4.3. Q. How can I check scripts written for different versions of Ruby? A. Install a Ruby version manager such as rvm or rbenv, activate the environment for the relevant version of Ruby, and install in it the checkers you want to use. Set g:syntastic_ruby_checkers accordingly in your vimrc, and run Vim from the virtual environment. If you're starting Vim from a desktop manager rather than from a terminal you might need to write wrapper scripts around your checkers, to activate the virtual environment before running the actual checks. Then you'll need to point the relevant g:syntastic_ruby_<checker>_exec variables to the wrapper scripts. 4.4. Q. Are there any local checkers for HTML5 that I can use with syntastic? HTML Tidy has a fork named HTML Tidy for HTML5. It's a drop in replacement, and syntastic can use it without changes. Just install it somewhere and point g:syntastic_html_tidy_exec to its executable: let g:syntastic_html_tidy_exec = 'tidy5' Alternatively, you can install vnu.jar from the validator.nu project and run it as a HTTP server: $ java -Xss512k -cp /path/to/vnu.jar nu.validator.servlet.Main 8888 Then you can configure syntastic to use it: let g:syntastic_html_validator_api = 'http://localhost:8888/' 4.5. Q. The perl checker has stopped working... A. The perl checker runs perl -c against your file, which in turn executes any BEGIN, UNITCHECK, and CHECK blocks, and any use statements in your file (cf. perlrun). This is probably fine if you wrote the file yourself, but it's a security problem if you're checking third-party files. Since there is currently no way to disable this behaviour while still producing useful results, the checker is now disabled by default. To (re-)enable it, make sure the g:syntastic_perl_checkers list includes perl, and set g:syntastic_enable_perl_checker to 1 in your vimrc: let g:syntastic_enable_perl_checker = 1 4.6. Q. What happened to the rustc checker? A. It is now part of the rust.vim plugin. If you install this plugin the checker should be picked up automatically by syntastic. 4.7. Q. What happened to the xcrun checker? A. The xcrun checker used to have a security problem and it has been removed. A better checker for Swift is part of the vim-swift plugin. If you install this plugin the checker should be picked up automatically by syntastic. 4.8. Q. I run a checker and the location list is not updated... 4.8. Q. I run:lopen or :lwindow and the error window is empty... A. By default the location list is changed only when you run the :Errors command, in order to minimise conflicts with other plugins. If you want the location list to always be updated when you run the checkers, add this line to your vimrc: let g:syntastic_always_populate_loc_list = 1 4.9. Q. How can I pass additional arguments to a checker? A. Almost all syntax checkers use the makeprgBuild() function. Those checkers that do can be configured using global variables. The general form of the global args variables is syntastic_<filetype>_<checker>_args. So, If you wanted to pass --my --args --here to the ruby mri checker you would add this line to your vimrc: let g:syntastic_ruby_mri_args = ""--my --args --here"" See :help syntastic-checker-options for more information. 4.10. Q. Syntastic supports several checkers for my filetype - how do I tell it which one(s) to use? A. Stick a line like this in your vimrc: let g:syntastic_<filetype>_checkers = ['<checker-name>'] To see the list of supported checkers for your filetype read the manual (:help syntastic-checkers in Vim). e.g. Python has the following checkers, among others: flake8, pyflakes, pylint and a native python checker. To tell syntastic to use pylint, you would use this setting: let g:syntastic_python_checkers = ['pylint'] Checkers can be chained together like this: let g:syntastic_php_checkers = ['php', 'phpcs', 'phpmd'] This is telling syntastic to run the php checker first, and if no errors are found, run phpcs, and then phpmd. You can also run checkers explicitly by calling :SyntasticCheck <checker>. e.g. to run phpcs and phpmd: :SyntasticCheck phpcs phpmd This works for any checkers available for the current filetype, even if they aren't listed in g:syntastic_<filetype>_checkers. You can't run checkers for ""foreign"" filetypes though (e.g. you can't run, say, a Python checker if the filetype of the current file is php). 4.11. Q. What is the difference between syntax checkers and style checkers? A. The errors and warnings they produce are highlighted differently and can be filtered by different rules, but otherwise the distinction is pretty much arbitrary. There is an ongoing effort to keep things consistent, so you can generally expect messages produced by syntax checkers to be mostly related to syntax, and messages produced by style checkers to be mostly about style. But there can be no formal guarantee that, say, a style checker that runs into a syntax error wouldn't die with a fatal message, nor that a syntax checker wouldn't give you warnings against using some constructs as being bad practice. There is also no guarantee that messages marked as ""style"" are less severe than the ones marked as ""syntax"" (whatever that might mean). And there are even a few Frankenstein checkers (for example flake8 and pylama) that, by their nature, produce both kinds of messages. Syntastic is not smart enough to be able to sort out these things by itself. In fact it's more useful to look at this from the perspective of filtering unwanted messages, rather than as an indicator of severity levels. The distinction between syntax and style is orthogonal to the distinction between errors and warnings, and thus you can turn off messages based on level, on type, or both. e.g. To disable all style messages: let g:syntastic_quiet_messages = { ""type"": ""style"" } See :help syntastic_quiet_messages for details. 4.12. Q. I have enabled multiple checkers for the current filetype. How can I display all errors from all checkers together? A. Set g:syntastic_aggregate_errors to 1 in your vimrc: let g:syntastic_aggregate_errors = 1 See :help syntastic-aggregating-errors for more details. 4.13. Q. How can I jump between the different errors without using the location list at the bottom of the window? A. Vim provides several built-in commands for this. See :help :lnext and :help :lprevious. If you use these commands a lot then you may want to add shortcut mappings to your vimrc, or install something like unimpaired, which provides such mappings (among other things). 4.14. My favourite checker needs to load a configuration file from the project's root rather than the current directory... A. You can set up an autocmd to search for the configuration file in the current directory and upwards, and add it to the checker's options when found. For example for jscs: function! FindConfig(prefix, what, where)     let cfg = findfile(a:what, escape(a:where, ' ') . ';')     return cfg !=# '' ? ' ' . a:prefix . ' ' . cfg : '' endfunction  autocmd FileType javascript let b:syntastic_javascript_jscs_args =     \ get(g:, 'syntastic_javascript_jscs_args', '') .     \ FindConfig('-c', '.jscsrc', expand('<amatch>:p:h', 1)) 4.15. Q. The error window is closed automatically when I :quit the current buffer but not when I :bdelete it? A. There is no safe way to handle that situation automatically, but you can work around it: nnoremap <silent> <C-d> :lclose<CR>:bdelete<CR> cabbrev <silent> bd <C-r>=(getcmdtype()==#':' && getcmdpos()==1 ? 'lclose\|bdelete' : 'bd')<CR> 5. Resources The preferred place for posting suggestions, reporting bugs, and general discussions related to syntastic is the issue tracker at GitHub. A guide for writing syntax checkers can be found in the wiki. There are also a dedicated google group, and a syntastic tag at StackOverflow. Syntastic aims to provide a common interface to syntax checkers for as many languages as possible. For particular languages, there are, of course, other plugins that provide more functionality than syntastic. You might want to take a look at ghcmod-vim, jedi-vim, python-mode, vim-go, or YouCompleteMe. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/scrooloose/syntastic"	"Syntax checking and linting.."	"true"
"Vim"	"YouCompleteMe"	"http://valloric.github.io/YouCompleteMe/"	"A code completion engine for Vim. only."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"YouCompleteMe by Valloric YouCompleteMe A code-completion engine for Vim Project maintained by Valloric Hosted on GitHub Pages — Theme by mattgraham Intro Installation Mac OS X Ubuntu Linux x64 Fedora Linux x64 Windows FreeBSD/OpenBSD Full Installation Guide Quick Feature Summary User Guide General Usage Client-Server Architecture Completion String Ranking General Semantic Completion C-family Semantic Completion JavaScript Semantic Completion Rust Semantic Completion Python Semantic Completion Semantic Completion for Other Languages Writing New Semantic Completers Diagnostic Display Diagnostic Highlighting Groups Commands YcmCompleter subcommands GoTo Commands Semantic Information Commands Refactoring and FixIt Commands Miscellaneous Commands Functions Autocommands Options FAQ Contributor Code of Conduct Contact License Intro YouCompleteMe is a fast, as-you-type, fuzzy-search code completion engine for Vim. It has several completion engines: an identifier-based engine that works with every programming language, a Clang-based engine that provides native semantic code completion for C/C++/Objective-C/Objective-C++ (from now on referred to as ""the C-family languages""), a Jedi-based completion engine for Python 2 and 3 (using the JediHTTP wrapper), an OmniSharp-based completion engine for C#, a combination of Gocode and Godef semantic engines for Go, a TSServer-based completion engine for TypeScript, a Tern-based completion engine for JavaScript, a racer-based completion engine for Rust, and an omnifunc-based completer that uses data from Vim's omnicomplete system to provide semantic completions for many other languages (Ruby, PHP etc.). Here's an explanation of what happens in the short GIF demo above. First, realize that no keyboard shortcuts had to be pressed to get the list of completion candidates at any point in the demo. The user just types and the suggestions pop up by themselves. If the user doesn't find the completion suggestions relevant and/or just wants to type, they can do so; the completion engine will not interfere. When the user sees a useful completion string being offered, they press the TAB key to accept it. This inserts the completion string. Repeated presses of the TAB key cycle through the offered completions. If the offered completions are not relevant enough, the user can continue typing to further filter out unwanted completions. A critical thing to notice is that the completion filtering is NOT based on the input being a string prefix of the completion (but that works too). The input needs to be a subsequence match of a completion. This is a fancy way of saying that any input characters need to be present in a completion string in the order in which they appear in the input. So abc is a subsequence of xaybgc, but not of xbyxaxxc. After the filter, a complicated sorting system ranks the completion strings so that the most relevant ones rise to the top of the menu (so you usually need to press TAB just once). All of the above works with any programming language because of the identifier-based completion engine. It collects all of the identifiers in the current file and other files you visit (and your tags files) and searches them when you type (identifiers are put into per-filetype groups). The demo also shows the semantic engine in use. When the user presses ., -> or :: while typing in insert mode (for C++; different triggers are used for other languages), the semantic engine is triggered (it can also be triggered with a keyboard shortcut; see the rest of the docs). The last thing that you can see in the demo is YCM's diagnostic display features (the little red X that shows up in the left gutter; inspired by Syntastic) if you are editing a C-family file. As Clang compiles your file and detects warnings or errors, they will be presented in various ways. You don't need to save your file or press any keyboard shortcut to trigger this, it ""just happens"" in the background. In essence, YCM obsoletes the following Vim plugins because it has all of their features plus extra: clang_complete AutoComplPop Supertab neocomplcache And that's not all... YCM also provides semantic IDE-like features in a number of languages, including: finding declarations, definitions, usages, etc. of identifiers, displaying type information for classes, variables, functions etc., displaying documentation for methods, members, etc. in the preview window, fixing common coding errors, like missing semi-colons, typos, etc., semantic renaming of variables across files (JavaScript only). Features vary by file type, so make sure to check out the file type feature summary and the full list of completer subcommands to find out what's available for your favourite languages. You'll also find that YCM has filepath completers (try typing ./ in a file) and a completer that integrates with UltiSnips. Installation Mac OS X Please refer to the full Installation Guide below; the following commands are provided on a best-effort basis and may not work for you. Install the latest version of MacVim. Yes, MacVim. And yes, the latest. If you don't use the MacVim GUI, it is recommended to use the Vim binary that is inside the MacVim.app package (MacVim.app/Contents/MacOS/Vim). To ensure it works correctly copy the mvim script from the MacVim download to your local binary folder (for example /usr/local/bin/mvim) and then symlink it: ln -s /usr/local/bin/mvim vim  Install YouCompleteMe with Vundle. Remember: YCM is a plugin with a compiled component. If you update YCM using Vundle and the ycm_core library APIs have changed (happens rarely), YCM will notify you to recompile it. You should then rerun the install process. NOTE: If you want C-family completion, you MUST have the latest Xcode installed along with the latest Command Line Tools (they are installed automatically when you run clang for the first time, or manually by running xcode-select --install) Install CMake. Preferably with Homebrew, but here's the stand-alone CMake installer. If you have installed a Homebrew Python and/or Homebrew MacVim, see the FAQ for details. Compiling YCM with semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe ./install.py --clang-completer  Compiling YCM without semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe ./install.py  The following additional language support options are available: C# support: install Mono with Homebrew or by downloading the Mono Mac package and add --omnisharp-completer when calling ./install.py. Go support: install Go and add --gocode-completer when calling ./install.py. TypeScript support: install Node.js and npm then install the TypeScript SDK with npm install -g typescript. JavaScript support: install Node.js and npm and add --tern-completer when calling ./install.py. Rust support: install Rust and add --racer-completer when calling ./install.py. To simply compile with everything enabled, there's a --all flag. So, to install with all language features, ensure xbuild, go, tsserver, node, npm, rustc, and cargo tools are installed and in your PATH, then simply run: cd ~/.vim/bundle/YouCompleteMe ./install.py --all  That's it. You're done. Refer to the User Guide section on how to use YCM. Don't forget that if you want the C-family semantic completion engine to work, you will need to provide the compilation flags for your project to YCM. It's all in the User Guide. YCM comes with sane defaults for its options, but you still may want to take a look at what's available for configuration. There are a few interesting options that are conservatively turned off by default that you may want to turn on. Ubuntu Linux x64 Please refer to the full Installation Guide below; the following commands are provided on a best-effort basis and may not work for you. Make sure you have Vim 7.3.598 with python2 or python3 support. Ubuntu 14.04 and later have a Vim that's recent enough. You can see the version of Vim installed by running vim --version. If the version is too old, you may need to compile Vim from source (don't worry, it's easy). Install YouCompleteMe with Vundle. Remember: YCM is a plugin with a compiled component. If you update YCM using Vundle and the ycm_core library APIs have changed (happens rarely), YCM will notify you to recompile it. You should then rerun the install process. Install development tools and CMake: sudo apt-get install build-essential cmake Make sure you have Python headers installed: sudo apt-get install python-dev python3-dev. Compiling YCM with semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe ./install.py --clang-completer  Compiling YCM without semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe ./install.py  The following additional language support options are available: C# support: install Mono and add --omnisharp-completer when calling ./install.py. Go support: install Go and add --gocode-completer when calling ./install.py. TypeScript support: install Node.js and npm then install the TypeScript SDK with npm install -g typescript. JavaScript support: install Node.js and npm and add --tern-completer when calling ./install.py. Rust support: install Rust and add --racer-completer when calling ./install.py. To simply compile with everything enabled, there's a --all flag. So, to install with all language features, ensure xbuild, go, tsserver, node, npm, rustc, and cargo tools are installed and in your PATH, then simply run: cd ~/.vim/bundle/YouCompleteMe ./install.py --all  That's it. You're done. Refer to the User Guide section on how to use YCM. Don't forget that if you want the C-family semantic completion engine to work, you will need to provide the compilation flags for your project to YCM. It's all in the User Guide. YCM comes with sane defaults for its options, but you still may want to take a look at what's available for configuration. There are a few interesting options that are conservatively turned off by default that you may want to turn on. Fedora Linux x64 Please refer to the full Installation Guide below; the following commands are provided on a best-effort basis and may not work for you. Make sure you have Vim 7.3.598 with Python 2 or Python 3 support. Fedora 21 and later have a Vim that's recent enough. You can see the version of Vim installed by running vim --version. If the version is too old, you may need to compile Vim from source (don't worry, it's easy). Install YouCompleteMe with Vundle. Remember: YCM is a plugin with a compiled component. If you update YCM using Vundle and the ycm_core library APIs have changed (happens rarely), YCM will notify you to recompile it. You should then rerun the install process. Install development tools and CMake: sudo dnf install automake gcc gcc-c++ kernel-devel cmake Make sure you have Python headers installed: sudo dnf install python-devel python3-devel. Compiling YCM with semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe ./install.py --clang-completer  Compiling YCM without semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe ./install.py  The following additional language support options are available: C# support: install Mono and add --omnisharp-completer when calling ./install.py. Go support: install Go and add --gocode-completer when calling ./install.py. TypeScript support: install Node.js and npm then install the TypeScript SDK with npm install -g typescript. JavaScript support: install Node.js and npm and add --tern-completer when calling ./install.py. Rust support: install Rust and add --racer-completer when calling ./install.py. To simply compile with everything enabled, there's a --all flag. So, to install with all language features, ensure xbuild, go, tsserver, node, npm, rustc, and cargo tools are installed and in your PATH, then simply run: cd ~/.vim/bundle/YouCompleteMe ./install.py --all  That's it. You're done. Refer to the User Guide section on how to use YCM. Don't forget that if you want the C-family semantic completion engine to work, you will need to provide the compilation flags for your project to YCM. It's all in the User Guide. YCM comes with sane defaults for its options, but you still may want to take a look at what's available for configuration. There are a few interesting options that are conservatively turned off by default that you may want to turn on. Windows Please refer to the full Installation Guide below; the following commands are provided on a best-effort basis and may not work for you. Important: we assume that you are using the cmd.exe command prompt and that you know how to add an executable to the PATH environment variable. Make sure you have at least Vim 7.3.598 with Python 2 or Python 3 support. You can check the version and which Python is supported by typing :version inside Vim. Look at the features included: +python/dyn for Python 2 and +python3/dyn for Python 3. Take note of the Vim architecture, i.e. 32 or 64-bit. It will be important when choosing the Python installer. We recommend using a 64-bit client. Daily updated copies of 32-bit and 64-bit Vim with Python 2 and Python 3 support are available. Install YouCompleteMe with Vundle. Remember: YCM is a plugin with a compiled component. If you update YCM using Vundle and the ycm_core library APIs have changed (happens rarely), YCM will notify you to recompile it. You should then rerun the install process. Download and install the following software: Python 2 or Python 3. Be sure to pick the version corresponding to your Vim architecture. It is Windows x86 for a 32-bit Vim and Windows x86-64 for a 64-bit Vim. We recommend installing Python 3. CMake. Add CMake executable to the PATH environment variable. Visual Studio. Download the community edition. During setup, choose Custom as the installation type and select the Visual C++ component. 7-zip. Required to build YCM with semantic support for C-family languages. Compiling YCM with semantic support for C-family languages: cd %USERPROFILE%/vimfiles/bundle/YouCompleteMe install.py --clang-completer  Compiling YCM without semantic support for C-family languages: cd %USERPROFILE%/vimfiles/bundle/YouCompleteMe install.py  The following additional language support options are available: C# support: add --omnisharp-completer when calling install.py. Be sure that the build utility msbuild is in your PATH. Go support: install Go and add --gocode-completer when calling install.py. TypeScript support: install Node.js and npm then install the TypeScript SDK with npm install -g typescript. JavaScript support: install Node.js and npm and add --tern-completer when calling install.py. Rust support: install Rust and add --racer-completer when calling install.py. To simply compile with everything enabled, there's a --all flag. So, to install with all language features, ensure msbuild, go, tsserver, node, npm, and cargo tools are installed and in your PATH, then simply run: cd %USERPROFILE%/vimfiles/bundle/YouCompleteMe python install.py --all  You can specify the Microsoft Visual C++ (MSVC) version using the --msvc option. YCM officially supports MSVC 11 (Visual Studio 2012), 12 (2013), and 14 (2015). That's it. You're done. Refer to the User Guide section on how to use YCM. Don't forget that if you want the C-family semantic completion engine to work, you will need to provide the compilation flags for your project to YCM. It's all in the User Guide. YCM comes with sane defaults for its options, but you still may want to take a look at what's available for configuration. There are a few interesting options that are conservatively turned off by default that you may want to turn on. FreeBSD/OpenBSD Please refer to the full Installation Guide below; the following commands are provided on a best-effort basis and may not work for you. OpenBSD / FreeBSD are not officially supported platforms by YCM. Make sure you have Vim 7.3.598 with Python 2 or Python 3 support. OpenBSD 5.5 and later have a Vim that's recent enough. You can see the version of Vim installed by running vim --version. FreeBSD 10.x comes with clang compiler but not the libraries needed to install. pkg install llvm35 boost-all boost-python-libs clang35 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/llvm35/lib/  Install YouCompleteMe with Vundle. Remember: YCM is a plugin with a compiled component. If you update YCM using Vundle and the ycm_core library APIs have changed (happens rarely), YCM will notify you to recompile it. You should then rerun the install process. Install dependencies and CMake: sudo pkg_add llvm boost cmake Compiling YCM with semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe ./install.py --clang-completer --system-libclang --system-boost  Compiling YCM without semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe ./install.py --system-boost  The following additional language support options are available: C# support: install Mono and add --omnisharp-completer when calling ./install.py. Go support: install Go and add --gocode-completer when calling ./install.py. TypeScript support: install Node.js and npm then install the TypeScript SDK with npm install -g typescript. JavaScript support: install Node.js and npm and add --tern-completer when calling ./install.py. Rust support: install Rust and add --racer-completer when calling ./install.py. To simply compile with everything enabled, there's a --all flag. So, to install with all language features, ensure xbuild, go, tsserver, node, npm, and cargo tools are installed and in your PATH, then simply run: cd ~/.vim/bundle/YouCompleteMe ./install.py --all  That's it. You're done. Refer to the User Guide section on how to use YCM. Don't forget that if you want the C-family semantic completion engine to work, you will need to provide the compilation flags for your project to YCM. It's all in the User Guide. YCM comes with sane defaults for its options, but you still may want to take a look at what's available for configuration. There are a few interesting options that are conservatively turned off by default that you may want to turn on. Full Installation Guide These are the steps necessary to get YCM working on a Unix OS and on Windows. Note to Windows users: we assume that you are running the cmd.exe command prompt and that the needed executables are in the PATH environment variable. Do not just copy the shell commands. Replace ~ by %USERPROFILE% in them and use the right Vim home directory. It should be vimfiles by default instead of .vim. See the FAQ if you have any issues. Remember: YCM is a plugin with a compiled component. If you update YCM using Vundle and the ycm_core library APIs have changed (happens rarely), YCM will notify you to recompile it. You should then rerun the install process. Please follow the instructions carefully. Read EVERY WORD. Ensure that your version of Vim is at least 7.3.598 and that it has support for Python 2 or Python 3 scripting. Inside Vim, type :version. Look at the first two to three lines of output; it should say Vi IMproved X.Y, where X.Y is the major version of vim. If your version is greater than 7.3, then you're all set. If your version is 7.3 then look below that where it says, Included patches: 1-Z, where Z will be some number. That number needs to be 598 or higher. If your version of Vim is not recent enough, you may need to compile Vim from source (don't worry, it's easy). After you have made sure that you have Vim 7.3.598+, type the following in Vim: :echo has('python') || has('python3'). The output should be 1. If it's 0, then get a version of Vim with Python support. On Windows, check also if your Vim architecture is 32 or 64-bit. This is critical because it must match the Python and the YCM libraries architectures. We recommend using a 64-bit Vim. Install YCM with Vundle (or Pathogen, but Vundle is a better idea). With Vundle, this would mean adding a Plugin 'Valloric/YouCompleteMe' line to your vimrc. If you don't install YCM with Vundle, make sure you have run git submodule update --init --recursive after checking out the YCM repository (Vundle will do this for you) to fetch YCM's dependencies. [Complete this step ONLY if you care about semantic completion support for C-family languages. Otherwise it's not necessary.] Download the latest version of libclang. Clang is an open-source compiler that can compile C/C++/Objective-C/Objective-C++. The libclang library it provides is used to power the YCM semantic completion engine for those languages. YCM is designed to work with libclang version 3.8 or higher. You can use the system libclang only if you are sure it is version 3.8 or higher, otherwise don't. Even if it is, we recommend using the official binaries from llvm.org if at all possible. Make sure you download the correct archive file for your OS. We STRONGLY recommend AGAINST use of the system libclang instead of the upstream compiled binaries. Random things may break. Save yourself the hassle and use the upstream pre-built libclang. Compile the ycm_core library that YCM needs. This library is the C++ engine that YCM uses to get fast completions. You will need to have cmake installed in order to generate the required makefiles. Linux users can install cmake with their package manager (sudo apt-get install cmake for Ubuntu) whereas other users can download and install cmake from its project site. Mac users can also get it through Homebrew with brew install cmake. On a Unix OS, you need to make sure you have Python headers installed. On a Debian-like Linux distro, this would be sudo apt-get install python-dev python3-dev. On Mac they should already be present. On Windows, you need to download and install Python 2 or Python 3. Pick the version corresponding to your Vim architecture. You will also need Microsoft Visual C++ (MSVC) to build YCM. You can obtain it by installing Visual Studio. MSVC 11 (Visual Studio 2012), 12 (2013), and 14 (2015) are officially supported. Here we'll assume you installed YCM with Vundle. That means that the top-level YCM directory is in ~/.vim/bundle/YouCompleteMe. We'll create a new folder where build files will be placed. Run the following: cd ~ mkdir ycm_build cd ycm_build  Now we need to generate the makefiles. If you DON'T care about semantic support for C-family languages, run the following command in the ycm_build directory: cmake -G ""<generator>"" . ~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp  where <generator> is Unix Makefiles on Unix systems and one of the following Visual Studio generators on Windows: Visual Studio 11 Win64 Visual Studio 12 Win64 Visual Studio 14 Win64 Remove the Win64 part in these generators if your Vim architecture is 32-bit. For those who want to use the system version of boost, you would pass -DUSE_SYSTEM_BOOST=ON to cmake. This may be necessary on some systems where the bundled version of boost doesn't compile out of the box. NOTE: We STRONGLY recommend AGAINST use of the system boost instead of the bundled version of boost. Random things may break. Save yourself the hassle and use the bundled version of boost. If you DO care about semantic support for C-family languages, then your cmake call will be a bit more complicated. We'll assume you downloaded a binary distribution of LLVM+Clang from llvm.org in step 3 and that you extracted the archive file to folder ~/ycm_temp/llvm_root_dir (with bin, lib, include etc. folders right inside that folder). On Windows, you can extract the files from the LLVM+Clang installer using 7-zip. NOTE: This only works with a downloaded LLVM binary package, not a custom-built LLVM! See docs below for EXTERNAL_LIBCLANG_PATH when using a custom LLVM build. With that in mind, run the following command in the ycm_build directory: cmake -G ""<generator>"" -DPATH_TO_LLVM_ROOT=~/ycm_temp/llvm_root_dir . ~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp  where <generator> is replaced like above. Now that configuration files have been generated, compile the libraries using this command: cmake --build . --target ycm_core --config Release  The --config Release part is specific to Windows and will be ignored on a Unix OS. For those who want to use the system version of libclang, you would pass -DUSE_SYSTEM_LIBCLANG=ON to cmake instead of the -DPATH_TO_LLVM_ROOT=... flag. NOTE: We STRONGLY recommend AGAINST use of the system libclang instead of the upstream compiled binaries. Random things may break. Save yourself the hassle and use the upstream pre-built libclang. You could also force the use of a custom libclang library with -DEXTERNAL_LIBCLANG_PATH=/path/to/libclang.so flag (the library would end with .dylib on a Mac). Again, this flag would be used instead of the other flags. If you compiled LLVM from source, this is the flag you should be using. Running the cmake command will also place the libclang.[so|dylib|dll] in the YouCompleteMe/third_party/ycmd folder for you if you compiled with clang support (it needs to be there for YCM to work). Set up support for additional languages, as desired: C# support: install Mono on non-Windows platforms. Navigate to YouCompleteMe/third_party/ycmd/third_party/OmniSharpServer and run msbuild (Windows) or xbuild (other platforms, using Mono) depending on your platform. On Windows, be sure that the build utility msbuild is in your PATH. Go support: install Go and add it to your path. Navigate to YouCompleteMe/third_party/ycmd/third_party/gocode and run go build. TypeScript support: as with the quick installation, simply npm install -g typescript after successfully installing Node.js and npm. JavaScript support: install Node.js and npm. Then navigate to YouCompleteMe/third_party/ycmd/third_party/tern_runtime and run npm install --production Rust support: install Rust. Navigate to YouCompleteMe/third_party/ycmd/third_party/racerd and run cargo build --release. That's it. You're done. Refer to the User Guide section on how to use YCM. Don't forget that if you want the C-family semantic completion engine to work, you will need to provide the compilation flags for your project to YCM. It's all in the User Guide. YCM comes with sane defaults for its options, but you still may want to take a look at what's available for configuration. There are a few interesting options that are conservatively turned off by default that you may want to turn on. Quick Feature Summary General (all languages) Super-fast identifier completer including tags files and syntax elements Intelligent suggestion ranking and filtering File and path suggestions Suggestions from Vim's OmniFunc UltiSnips snippet suggestions C-family languages (C, C++, Objective C, Objective C++) Semantic auto-completion Real-time diagnostic display Go to include/declaration/definition (GoTo, etc.) Semantic type information for identifiers (GetType) Automatically fix certain errors (FixIt) View documentation comments for identifiers (GetDoc) C♯ Semantic auto-completion Real-time diagnostic display Go to declaration/definition (GoTo, etc.) Semantic type information for identifiers (GetType) Automatically fix certain errors (FixIt) Management of OmniSharp server instance View documentation comments for identifiers (GetDoc) Python Intelligent auto-completion Go to declaration/definition, find references (GoTo, GoToReferences) View documentation comments for identifiers (GetDoc) Restart JediHTTP server using a different Python interpreter Go Semantic auto-completion Go to definition (GoTo) Management of gocode server instance TypeScript Semantic auto-completion Renaming symbols (RefactorRename <new name>) Go to definition, find references (GoToDefinition, GoToReferences) Semantic type information for identifiers (GetType) View documentation comments for identifiers (GetDoc) JavaScript Intelligent auto-completion Renaming variables (RefactorRename <new name>) Go to definition, find references (GoToDefinition, GoToReferences) Type information for identifiers (GetType) View documentation comments for identifiers (GetDoc) Management of Tern server instance Rust Semantic auto-completion Go to definition (GoTo, GoToDefinition, and GoToDeclaration are identical) Management of racer server instance User Guide General Usage If the offered completions are too broad, keep typing characters; YCM will continue refining the offered completions based on your input. Filtering is ""smart-case"" sensitive; if you are typing only lowercase letters, then it's case-insensitive. If your input contains uppercase letters, then the uppercase letters in your query must match uppercase letters in the completion strings (the lowercase letters still match both). So, ""foo"" matches ""Foo"" and ""foo"", ""Foo"" matches ""Foo"" and ""FOO"" but not ""foo"". Use the TAB key to accept a completion and continue pressing TAB to cycle through the completions. Use Shift-TAB to cycle backwards. Note that if you're using console Vim (that is, not Gvim or MacVim) then it's likely that the Shift-TAB binding will not work because the console will not pass it to Vim. You can remap the keys; see the Options section below. Knowing a little bit about how YCM works internally will prevent confusion. YCM has several completion engines: an identifier-based completer that collects all of the identifiers in the current file and other files you visit (and your tags files) and searches them when you type (identifiers are put into per-filetype groups). There are also several semantic engines in YCM. There's a libclang-based completer that provides semantic completion for C-family languages. There's a Jedi-based completer for semantic completion for Python. There's also an omnifunc-based completer that uses data from Vim's omnicomplete system to provide semantic completions when no native completer exists for that language in YCM. There are also other completion engines, like the UltiSnips completer and the filepath completer. YCM automatically detects which completion engine would be the best in any situation. On occasion, it queries several of them at once, merges the outputs and presents the results to you. Client-Server Architecture YCM has a client-server architecture; the Vim part of YCM is only a thin client that talks to the ycmd HTTP+JSON server that has the vast majority of YCM logic and functionality. The server is started and stopped automatically as you start and stop Vim. Completion String Ranking The subsequence filter removes any completions that do not match the input, but then the sorting system kicks in. It's actually very complicated and uses lots of factors, but suffice it to say that ""word boundary"" (WB) subsequence character matches are ""worth"" more than non-WB matches. In effect, this means given an input of ""gua"", the completion ""getUserAccount"" would be ranked higher in the list than the ""Fooguxa"" completion (both of which are subsequence matches). A word-boundary character are all capital characters, characters preceded by an underscore and the first letter character in the completion string. General Semantic Completion You can use Ctrl+Space to trigger the completion suggestions anywhere, even without a string prefix. This is useful to see which top-level functions are available for use. C-family Semantic Completion YCM looks for a .ycm_extra_conf.py file in the directory of the opened file or in any directory above it in the hierarchy (recursively); when the file is found, it is loaded (only once!) as a Python module. YCM calls a FlagsForFile method in that module which should provide it with the information necessary to compile the current file. You can also provide a path to a global .ycm_extra_conf.py file, which will be used as a fallback. To prevent the execution of malicious code from a file you didn't write YCM will ask you once per .ycm_extra_conf.py if it is safe to load. This can be disabled and you can white-/blacklist files. See the Options section for more details. This system was designed this way so that the user can perform any arbitrary sequence of operations to produce a list of compilation flags YCM should hand to Clang. See YCM's own .ycm_extra_conf.py for details on how this works. You should be able to use it as a starting point. Don't just copy/paste that file somewhere and expect things to magically work; your project needs different flags. Hint: just replace the strings in the flags variable with compilation flags necessary for your project. That should be enough for 99% of projects. Yes, Clang's CompilationDatabase system is also supported. Again, see the above linked example file. You can get CMake to generate this file for you by adding set( CMAKE_EXPORT_COMPILE_COMMANDS 1 ) to your project's CMakeLists.txt file (if using CMake). If you're not using CMake, you could use something like Bear to generate the compile_commands.json file. Consider using YCM-Generator to generate the ycm_extra_conf.py file. If Clang encounters errors when compiling the header files that your file includes, then it's probably going to take a long time to get completions. When the completion menu finally appears, it's going to have a large number of unrelated completion strings (type/function names that are not actually members). This is because Clang fails to build a precompiled preamble for your file if there are any errors in the included headers and that preamble is key to getting fast completions. Call the :YcmDiags command to see if any errors or warnings were detected in your file. JavaScript Semantic Completion Quick start Ensure that you have enabled the Tern completer. See the installation guide for details. Create a .tern-project file in the root directory of your JavaScript project, by following the instructions in the Tern documentation. Make sure that Vim's working directory is a descendent of that directory (or that directory itself) when working with JavaScript files. Explanation JavaScript completion is based on Tern. This completion engine requires a file named .tern-project to exist in the current working directory or a directory which is an ancestor of the current working directory when the tern server is started. YCM starts the Tern server the first time a JavaScript file is edited, so Vim's working directory at that time needs to be a descendent of the directory containing the .tern-project file (or that directory itself). Alternatively, as described in the Tern documentation, a global .tern-config file may be used. Multiple Tern servers, are not supported. To switch to a different JavaScript project, you can do one of the following: start a new instance of Vim from the new project's directory change Vim's working directory (:cd /path/to/new/project) and restart the ycmd server (:YcmRestartServer) change Vim's working directory (:cd /path/to/new/project), open a JavaScript file (or set filetype to JavaScript) and restart the Tern server using YCM completer subcommands :YcmCompleter StopServer and :YcmCompleter StartServer. Tips and tricks This section contains some advice for configuring .tern-project and working with JavaScript files. The canonical reference for correctly configuring Tern is the Tern documentation. Any issues, improvements, advice, etc. should be sought from the Tern project. For example, see the list of tern plugins for the list of plugins which can be enabled in the plugins section of the .tern-project file. Configuring Tern for node support The following simple example .tern-project file enables nodejs support: {     ""plugins"": {         ""node"": {}     } }   Configuring Tern for requirejs support The Tern requirejs plugin requires that all included ""libraries"" are rooted under the same base directory. If that's not the case for your projects, then it is possible to make it work with appropriate symbolic links. For example, create a directory ext_lib within your project and populate it with symlinks to your libraries. Then set up the .tern-project something like this:  {   ""plugins"": {     ""requirejs"": {       ""baseURL"": ""./ext_lib"",     }   } }  Then, given the following structure: ./ext_lib/mylib (symlink) ./ext_lib/anotherlib (symlink)  Can be used as follows: define( [ 'mylib/file1', 'anotherlib/anotherfile' ], function( f1, f2 ) {     // etc. } );  Rust Semantic Completion Completions and GoTo commands within the current crate and its dependencies should work out of the box with no additional configuration (provided that you built YCM with the --racer-completer flag; see the Installation section for details). For semantic analysis inclusive of the standard library, you must have a local copy of the rust source code. You also need to set the following option so YouCompleteMe can locate it. "" In this example, the rust source code zip has been extracted to "" /usr/local/rust/rustc-1.5.0 let g:ycm_rust_src_path = '/usr/local/rust/rustc-1.5.0/src'  Python Semantic Completion Completion and GoTo commands work out of the box with no additional configuration. Those features are provided by the jedi library which supports a variety of Python versions (2.6, 2.7, 3.2+) as long as it runs in the corresponding Python interpreter. By default YCM runs jedi with the same Python interpreter used by the ycmd server, so if you would like to use a different interpreter, use the following option specifying the Python binary to use. For example, to provide Python 3 completion in your project, set: let g:ycm_python_binary_path = '/usr/bin/python3'  If the value of g:ycm_python_binary_path is an absolute path like above it will be used as-is, but if it's an executable name it will be searched through the PATH. So for example if you set: let g:ycm_python_binary_path = 'python'  YCM will use the first python executable it finds in the PATH to run jedi. This means that if you are in a virtual environment and you start vim in that directory, the first python that YCM will find will be the one in the virtual environment, so jedi will be able to provide completions for every package you have in the virtual environment. Semantic Completion for Other Languages Python, C#, Go, Rust, and TypeScript are supported natively by YouCompleteMe using the Jedi, Omnisharp, Gocode, racer, and TSServer engines, respectively. Check the installation section for instructions to enable these features if desired. YCM will use your omnifunc (see :h omnifunc in Vim) as a source for semantic completions if it does not have a native semantic completion engine for your file's filetype. Vim comes with okayish omnifuncs for various languages like Ruby, PHP etc. It depends on the language. You can get stellar omnifuncs for Java and Ruby with Eclim. Just make sure you have the latest Eclim installed and configured (this means Eclim >= 2.2.* and Eclipse >= 4.2.*). After installing Eclim remember to create a new Eclipse project within your application by typing :ProjectCreate <path-to-your-project> -n ruby (or -n java) inside vim and don't forget to have let g:EclimCompletionMethod = 'omnifunc' in your vimrc. This will make YCM and Eclim play nice; YCM will use Eclim's omnifuncs as the data source for semantic completions and provide the auto-triggering and subsequence-based matching (and other YCM features) on top of it. Writing New Semantic Completers You have two options here: writing an omnifunc for Vim's omnicomplete system that YCM will then use through its omni-completer, or a custom completer for YCM using the Completer API. Here are the differences between the two approaches: You have to use VimScript to write the omnifunc, but get to use Python to write for the Completer API; this by itself should make you want to use the API. The Completer API is a much more powerful way to integrate with YCM and it provides a wider set of features. For instance, you can make your Completer query your semantic back-end in an asynchronous fashion, thus not blocking Vim's GUI thread while your completion system is processing stuff. This is impossible with VimScript. All of YCM's completers use the Completer API. Performance with the Completer API is better since Python executes faster than VimScript. If you want to use the omnifunc system, see the relevant Vim docs with :h complete-functions. For the Completer API, see the API docs. If you want to upstream your completer into YCM's source, you should use the Completer API. Diagnostic Display YCM will display diagnostic notifications for C-family and C# languages if you compiled YCM with Clang and Omnisharp support, respectively. Since YCM continuously recompiles your file as you type, you'll get notified of errors and warnings in your file as fast as possible. Here are the various pieces of the diagnostic UI: Icons show up in the Vim gutter on lines that have a diagnostic. Regions of text related to diagnostics are highlighted (by default, a red wavy underline in gvim and a red background in vim). Moving the cursor to a line with a diagnostic echoes the diagnostic text. Vim's location list is automatically populated with diagnostic data (off by default, see options). The new diagnostics (if any) will be displayed the next time you press any key on the keyboard. So if you stop typing and just wait for the new diagnostics to come in, that will not work. You need to press some key for the GUI to update. Having to press a key to get the updates is unfortunate, but cannot be changed due to the way Vim internals operate; there is no way that a background task can update Vim's GUI after it has finished running. You have to press a key. This will make YCM check for any pending diagnostics updates. You can force a full, blocking compilation cycle with the :YcmForceCompileAndDiagnostics command (you may want to map that command to a key; try putting nnoremap <F5> :YcmForceCompileAndDiagnostics<CR> in your vimrc). Calling this command will force YCM to immediately recompile your file and display any new diagnostics it encounters. Do note that recompilation with this command may take a while and during this time the Vim GUI will be blocked. YCM will display a short diagnostic message when you move your cursor to the line with the error. You can get a detailed diagnostic message with the <leader>d key mapping (can be changed in the options) YCM provides when your cursor is on the line with the diagnostic. You can also see the full diagnostic message for all the diagnostics in the current file in Vim's locationlist, which can be opened with the :lopen and :lclose commands (make sure you have set let g:ycm_always_populate_location_list = 1 in your vimrc). A good way to toggle the display of the locationlist with a single key mapping is provided by another (very small) Vim plugin called ListToggle (which also makes it possible to change the height of the locationlist window), also written by yours truly. Diagnostic Highlighting Groups You can change the styling for the highlighting groups YCM uses. For the signs in the Vim gutter, the relevant groups are: YcmErrorSign, which falls back to group SyntasticErrorSign and then error if they exist YcmWarningSign, which falls back to group SyntasticWarningSign and then todo if they exist You can also style the line that has the warning/error with these groups: YcmErrorLine, which falls back to group SyntasticErrorLine if it exists YcmWarningLine, which falls back to group SyntasticWarningLine if it exists Note that the line highlighting groups only work when gutter signs are turned on. The syntax groups used to highlight regions of text with errors/warnings: - YcmErrorSection, which falls back to group SyntasticError if it exists and then SpellBad - YcmWarningSection, which falls back to group SyntasticWarning if it exists and then SpellCap Here's how you'd change the style for a group: highlight YcmErrorLine guibg=#3f0000  Commands The :YcmRestartServer command If the ycmd completion server suddenly stops for some reason, you can restart it with this command. The :YcmForceCompileAndDiagnostics command Calling this command will force YCM to immediately recompile your file and display any new diagnostics it encounters. Do note that recompilation with this command may take a while and during this time the Vim GUI will be blocked. You may want to map this command to a key; try putting nnoremap <F5> :YcmForceCompileAndDiagnostics<CR> in your vimrc. The :YcmDiags command Calling this command will fill Vim's locationlist with errors or warnings if any were detected in your file and then open it. If a given error or warning can be fixed by a call to :YcmCompleter FixIt, then (FixIt available) is appended to the error or warning text. See the FixIt completer subcommand for more information. NOTE: The absense of (FixIt available) does not strictly imply a fix-it is not available as not all completers are able to provide this indication. For example, the c-sharp completer provides many fix-its but does not add this additional indication. The g:ycm_open_loclist_on_ycm_diags option can be used to prevent the location list from opening, but still have it filled with new diagnostic data. See the Options section for details. The :YcmShowDetailedDiagnostic command This command shows the full diagnostic text when the user's cursor is on the line with the diagnostic. The :YcmDebugInfo command This will print out various debug information for the current file. Useful to see what compile commands will be used for the file if you're using the semantic completion engine. The :YcmToggleLogs command This command automatically opens in windows the stdout and stderr logfiles written by the ycmd server. If one or both logfiles are already opened, they are automatically closed. stderr or stdout can be specified as an argument of this command to only open the corresponding logfile instead of both. If this logfile is already opened, it will be closed. Only for debugging purpose. The :YcmCompleter command This command gives access to a number of additional IDE-like features in YCM, for things like semantic GoTo, type information, FixIt and refactoring. Technically the command invokes completer-specific commands. If the first argument is of the form ft=... the completer for that file type will be used (for example ft=cpp), else the native completer of the current buffer will be used. Call YcmCompleter without further arguments for a list of the commands you can call for the current completer. See the file type feature summary for an overview of the features available for each file type. See the YcmCompleter subcommands section for more information on the available subcommands and their usage. YcmCompleter Subcommands NOTE: See the docs for the YcmCompleter command before tackling this section. The invoked subcommand is automatically routed to the currently active semantic completer, so :YcmCompleter GoToDefinition will invoke the GoToDefinition subcommand on the Python semantic completer if the currently active file is a Python one and on the Clang completer if the currently active file is a C/C++/Objective-C one. You may also want to map the subcommands to something less verbose; for instance, nnoremap <leader>jd :YcmCompleter GoTo<CR> maps the <leader>jd sequence to the longer subcommand invocation. GoTo Commands These commands are useful for jumping around and exploring code. When moving the cursor, the subcommands add entries to Vim's jumplist so you can use CTRL-O to jump back to where you where before invoking the command (and CTRL-I to jump forward; see :h jumplist for details). If there is more than one destination, the quickfix list (see :h quickfix) is populated with the available locations and opened to full width at the bottom of the screen. You can change this behavior by using the YcmQuickFixOpened autocommand. The GoToInclude subcommand Looks up the current line for a header and jumps to it. Supported in filetypes: c, cpp, objc, objcpp The GoToDeclaration subcommand Looks up the symbol under the cursor and jumps to its declaration. Supported in filetypes: c, cpp, objc, objcpp, cs, go, python, rust The GoToDefinition subcommand Looks up the symbol under the cursor and jumps to its definition. NOTE: For C-family languages this only works in certain situations, namely when the definition of the symbol is in the current translation unit. A translation unit consists of the file you are editing and all the files you are including with #include directives (directly or indirectly) in that file. Supported in filetypes: c, cpp, objc, objcpp, cs, go, javascript, python, rust, typescript The GoTo subcommand This command tries to perform the ""most sensible"" GoTo operation it can. Currently, this means that it tries to look up the symbol under the cursor and jumps to its definition if possible; if the definition is not accessible from the current translation unit, jumps to the symbol's declaration. For C/C++/Objective-C, it first tries to look up the current line for a header and jump to it. For C#, implementations are also considered and preferred. Supported in filetypes: c, cpp, objc, objcpp, cs, go, javascript, python, rust The GoToImprecise subcommand WARNING: This command trades correctness for speed! Same as the GoTo command except that it doesn't recompile the file with libclang before looking up nodes in the AST. This can be very useful when you're editing files that take long to compile but you know that you haven't made any changes since the last parse that would lead to incorrect jumps. When you're just browsing around your codebase, this command can spare you quite a bit of latency. Supported in filetypes: c, cpp, objc, objcpp The GoToReferences subcommand This command attempts to find all of the references within the project to the identifier under the cursor and populates the quickfix list with those locations. Supported in filetypes: javascript, python, typescript The GoToImplementation subcommand Looks up the symbol under the cursor and jumps to its implementation (i.e. non-interface). If there are multiple implementations, instead provides a list of implementations to choose from. Supported in filetypes: cs The GoToImplementationElseDeclaration subcommand Looks up the symbol under the cursor and jumps to its implementation if one, else jump to its declaration. If there are multiple implementations, instead provides a list of implementations to choose from. Supported in filetypes: cs Semantic Information Commands These commands are useful for finding static information about the code, such as the types of variables, viewing declarations and documentation strings. The GetType subcommand Echos the type of the variable or method under the cursor, and where it differs, the derived type. For example:     std::string s;  Invoking this command on s returns std::string => std::basic_string<char> NOTE: Due to limitations of libclang, invoking this command on the word auto typically returns auto. However, invoking it on a usage of the variable with inferred type returns the correct type, but typically it is repeated due to libclang returning that the types differ. For example: const char *s = ""String""; auto x = &s; // invoking on x or auto returns ""auto"";              // invoking on s returns ""const char *"" std::cout << *x; // invoking on x returns ""const char ** => const char **""  NOTE: Causes re-parsing of the current translation unit. Supported in filetypes: c, cpp, objc, objcpp, javascript, typescript The GetParent subcommand Echos the semantic parent of the point under the cursor. The semantic parent is the item that semantically contains the given position. For example: class C {     void f(); };  void C::f() {  }  In the out-of-line definition of C::f, the semantic parent is the class C, of which this function is a member. In the example above, both declarations of C::f have C as their semantic context, while the lexical context of the first C::f is C and the lexical context of the second C::f is the translation unit. For global declarations, the semantic parent is the translation unit. NOTE: Causes re-parsing of the current translation unit. Supported in filetypes: c, cpp, objc, objcpp The GetDoc subcommand Displays the preview window populated with quick info about the identifier under the cursor. Depending on the file type, this includes things like: The type or declaration of identifier, Doxygen/javadoc comments, Python docstrings, etc. Supported in filetypes: c, cpp, objc, objcpp, cs, python, typescript, javascript Refactoring and FixIt Commands These commands make changes to your source code in order to perform refactoring or code correction. YouCompleteMe does not perform any action which cannot be undone, and never saves or writes files to the disk. The FixIt subcommand Where available, attempts to make changes to the buffer to correct the diagnostic closest to the cursor position. Completers which provide diagnostics may also provide trivial modifications to the source in order to correct the diagnostic. Examples include syntax errors such as missing trailing semi-colons, spurious characters, or other errors which the semantic engine can deterministically suggest corrections. If no fix-it is available for the current line, or there is no diagnostic on the current line, this command has no effect on the current buffer. If any modifications are made, the number of changes made to the buffer is echo'd and the user may use the editor's undo command to revert. When a diagnostic is available, and g:ycm_echo_current_diagnostic is set to 1, then the text (FixIt) is appended to the echo'd diagnostic when the completer is able to add this indication. The text (FixIt available) is also appended to the diagnostic text in the output of the :YcmDiags command for any diagnostics with available fix-its (where the completer can provide this indication). NOTE: Causes re-parsing of the current translation unit. NOTE: After applying a fix-it, the diagnostics UI is not immediately updated. This is due to a technical restriction in Vim. Moving the cursor, or issuing the :YcmForceCompileAndDiagnostics command will refresh the diagnostics. Repeated invocations of the FixIt command on a given line, however, do apply all diagnostics as expected without requiring refreshing of the diagnostics UI. This is particularly useful where there are multiple diagnostics on one line, or where after fixing one diagnostic, another fix-it is available. Supported in filetypes: c, cpp, objc, objcpp, cs The RefactorRename <new name> subcommand In supported file types, this command attempts to perform a semantic rename of the identifier under the cursor. This includes renaming declarations, definitions and usages of the identifier, or any other language-appropriate action. The specific behavior is defined by the semantic engine in use. Similar to FixIt, this command applies automatic modifications to your source files. Rename operations may involve changes to multiple files, which may or may not be open in Vim buffers at the time. YouCompleteMe handles all of this for you. The behavior is described in the following section. Supported in filetypes: javascript (variables only), typescript Multi-file Refactor When a Refactor or FixIt command touches multiple files, YouCompleteMe attempts to apply those modifications to any existing open, visible buffer in the current tab. If no such buffer can be found, YouCompleteMe opens the file in a new small horizontal split at the top of the current window, applies the change, and then hides the window. NOTE: The buffer remains open, and must be manually saved. A confirmation dialog is opened prior to doing this to remind you that this is about to happen. Once the modifications have been made, the quickfix list (see :help quickfix) is opened and populated with the locations of all modifications. This can be used to review all automatic changes made. Typically, use the CTRL-W <enter> combination to open the selected file in a new split. It is possible to customize how the quickfix window is opened by using the YcmQuickFixOpened autocommand. The buffers are not saved automatically. That is, you must save the modified buffers manually after reviewing the changes from the quickfix list. Changes can be undone using Vim's powerful undo features (see :help undo). Note that Vim's undo is per-buffer, so to undo all changes, the undo commands must be applied in each modified buffer separately. NOTE: While applying modifications, Vim may find files which are already open and have a swap file. The command is aborted if you select Abort or Quit in any such prompts. This leaves the Refactor operation partially complete and must be manually corrected using Vim's undo features. The quickfix list is not populated in this case. Inspect :buffers or equivalent (see :help buffers) to see the buffers that were opened by the command. Miscellaneous Commands These commands are for general administration, rather than IDE-like features. They cover things like the semantic engine server instance and compilation flags. The ClearCompilationFlagCache subcommand YCM caches the flags it gets from the FlagsForFile function in your ycm_extra_conf.py file if you return them with the do_cache parameter set to True. The cache is in memory and is never invalidated (unless you restart Vim of course). This command clears that cache entirely. YCM will then re-query your FlagsForFile function as needed in the future. Supported in filetypes: c, cpp, objc, objcpp The StartServer subcommand Starts the semantic-engine-as-localhost-server for those semantic engines that work as separate servers that YCM talks to. Supported in filetypes: cs, go, javascript, rust The StopServer subcommand Stops the semantic-engine-as-localhost-server for those semantic engines that work as separate servers that YCM talks to. Supported in filetypes: cs, go, javascript, rust The RestartServer subcommand Restarts the semantic-engine-as-localhost-server for those semantic engines that work as separate servers that YCM talks to. An additional optional argument may be supplied for Python, specifying the python binary to use to restart the Python semantic engine. :YcmCompleter RestartServer /usr/bin/python3.4  Supported in filetypes: cs, python, rust The ReloadSolution subcommand Instruct the Omnisharp server to clear its cache and reload all files from disk. This is useful when files are added, removed, or renamed in the solution, files are changed outside of Vim, or whenever Omnisharp cache is out-of-sync. Supported in filetypes: cs Functions The youcompleteme#GetErrorCount function Get the number of YCM Diagnostic errors. If no errors are present, this function returns 0. For example:   call youcompleteme#GetErrorCount()  Both this function and youcompleteme#GetWarningCount can be useful when integrating YCM with other Vim plugins. For example, a lightline user could add a diagnostics section to their statusline which would display the number of errors and warnings. The youcompleteme#GetWarningCount function Get the number of YCM Diagnostic warnings. If no warnings are present, this function returns 0. For example:   call youcompleteme#GetWarningCount()  Autocommands The YcmQuickFixOpened autocommand This User autocommand is fired when YCM opens the quickfix window in response to the GoTo* and RefactorRename subcommands. By default, the quickfix window is opened to full width at the bottom of the screen and its height is set to fit all entries. This behavior can be overridden by using the YcmQuickFixOpened autocommand. For instance: function s:CustomizeYcmQuickFixWindow()   "" Move the window at the top of the screen.   execute ""wincmd K""   "" Set the window height to 5.   execute ""5wincmd _"" endfunction  autocmd User YcmQuickFixOpened call s:CustomizeYcmQuickFixWindow()  Options All options have reasonable defaults so if the plug-in works after installation you don't need to change any options. These options can be configured in your vimrc script by including a line like this: let g:ycm_min_num_of_chars_for_completion = 1  Note that after changing an option in your vimrc script you have to restart Vim for the changes to take effect. The g:ycm_min_num_of_chars_for_completion option This option controls the number of characters the user needs to type before identifier-based completion suggestions are triggered. For example, if the option is set to 2, then when the user types a second alphanumeric character after a whitespace character, completion suggestions will be triggered. This option is NOT used for semantic completion. Setting this option to a high number like 99 effectively turns off the identifier completion engine and just leaves the semantic engine. Default: 2 let g:ycm_min_num_of_chars_for_completion = 2  The g:ycm_min_num_identifier_candidate_chars option This option controls the minimum number of characters that a completion candidate coming from the identifier completer must have to be shown in the popup menu. A special value of 0 means there is no limit. NOTE: This option only applies to the identifier completer; it has no effect on the various semantic completers. Default: 0 let g:ycm_min_num_identifier_candidate_chars = 0  The g:ycm_auto_trigger option When set to 0, this option turns off YCM's identifier completer (the as-you-type popup) and the semantic triggers (the popup you'd get after typing . or -> in say C++). You can still force semantic completion with the <C-Space> shortcut. If you want to just turn off the identifier completer but keep the semantic triggers, you should set g:ycm_min_num_of_chars_for_completion to a high number like 99. Default: 1 let g:ycm_auto_trigger = 1  The g:ycm_filetype_whitelist option This option controls for which Vim filetypes (see :h filetype) should YCM be turned on. The option value should be a Vim dictionary with keys being filetype strings (like python, cpp etc) and values being unimportant (the dictionary is used like a hash set, meaning that only the keys matter). The * key is special and matches all filetypes. By default, the whitelist contains only this * key. YCM also has a g:ycm_filetype_blacklist option that lists filetypes for which YCM shouldn't be turned on. YCM will work only in filetypes that both the whitelist and the blacklist allow (the blacklist ""allows"" a filetype by not having it as a key). For example, let's assume you want YCM to work in files with the cpp filetype. The filetype should then be present in the whitelist either directly (cpp key in the whitelist) or indirectly through the special * key. It should not be present in the blacklist. Filetypes that are blocked by the either of the lists will be completely ignored by YCM, meaning that neither the identifier-based completion engine nor the semantic engine will operate in them. You can get the filetype of the current file in Vim with :set ft?. Default: {'*' : 1} let g:ycm_filetype_whitelist = { '*': 1 }  The g:ycm_filetype_blacklist option This option controls for which Vim filetypes (see :h filetype) should YCM be turned off. The option value should be a Vim dictionary with keys being filetype strings (like python, cpp etc) and values being unimportant (the dictionary is used like a hash set, meaning that only the keys matter). See the g:ycm_filetype_whitelist option for more details on how this works. Default: [see next line] let g:ycm_filetype_blacklist = {       \ 'tagbar' : 1,       \ 'qf' : 1,       \ 'notes' : 1,       \ 'markdown' : 1,       \ 'unite' : 1,       \ 'text' : 1,       \ 'vimwiki' : 1,       \ 'pandoc' : 1,       \ 'infolog' : 1,       \ 'mail' : 1       \}  The g:ycm_filetype_specific_completion_to_disable option This option controls for which Vim filetypes (see :h filetype) should the YCM semantic completion engine be turned off. The option value should be a Vim dictionary with keys being filetype strings (like python, cpp etc) and values being unimportant (the dictionary is used like a hash set, meaning that only the keys matter). The listed filetypes will be ignored by the YCM semantic completion engine, but the identifier-based completion engine will still trigger in files of those filetypes. Note that even if semantic completion is not turned off for a specific filetype, you will not get semantic completion if the semantic engine does not support that filetype. You can get the filetype of the current file in Vim with :set ft?. Default: [see next line] let g:ycm_filetype_specific_completion_to_disable = {       \ 'gitcommit': 1       \}  The g:ycm_show_diagnostics_ui option When set, this option turns on YCM's diagnostic display features. See the Diagnostic display section in the User Manual for more details. Specific parts of the diagnostics UI (like the gutter signs, text highlighting, diagnostic echo and auto location list population) can be individually turned on or off. See the other options below for details. Note that YCM's diagnostics UI is only supported for C-family languages. When set, this option also makes YCM remove all Syntastic checkers set for the c, cpp, objc and objcpp filetypes since this would conflict with YCM's own diagnostics UI. If you're using YCM's identifier completer in C-family languages but cannot use the clang-based semantic completer for those languages and want to use the GCC Syntastic checkers, unset this option. Default: 1 let g:ycm_show_diagnostics_ui = 1  The g:ycm_error_symbol option YCM will use the value of this option as the symbol for errors in the Vim gutter. This option is part of the Syntastic compatibility layer; if the option is not set, YCM will fall back to the value of the g:syntastic_error_symbol option before using this option's default. Default: >> let g:ycm_error_symbol = '>>'  The g:ycm_warning_symbol option YCM will use the value of this option as the symbol for warnings in the Vim gutter. This option is part of the Syntastic compatibility layer; if the option is not set, YCM will fall back to the value of the g:syntastic_warning_symbol option before using this option's default. Default: >> let g:ycm_warning_symbol = '>>'  The g:ycm_enable_diagnostic_signs option When this option is set, YCM will put icons in Vim's gutter on lines that have a diagnostic set. Turning this off will also turn off the YcmErrorLine and YcmWarningLine highlighting. This option is part of the Syntastic compatibility layer; if the option is not set, YCM will fall back to the value of the g:syntastic_enable_signs option before using this option's default. Default: 1 let g:ycm_enable_diagnostic_signs = 1  The g:ycm_enable_diagnostic_highlighting option When this option is set, YCM will highlight regions of text that are related to the diagnostic that is present on a line, if any. This option is part of the Syntastic compatibility layer; if the option is not set, YCM will fall back to the value of the g:syntastic_enable_highlighting option before using this option's default. Default: 1 let g:ycm_enable_diagnostic_highlighting = 1  The g:ycm_echo_current_diagnostic option When this option is set, YCM will echo the text of the diagnostic present on the current line when you move your cursor to that line. If a FixIt is available for the current diagnostic, then (FixIt) is appended. This option is part of the Syntastic compatibility layer; if the option is not set, YCM will fall back to the value of the g:syntastic_echo_current_error option before using this option's default. Default: 1 let g:ycm_echo_current_diagnostic = 1  The g:ycm_always_populate_location_list option When this option is set, YCM will populate the location list automatically every time it gets new diagnostic data. This option is off by default so as not to interfere with other data you might have placed in the location list. See :help location-list in Vim to learn more about the location list. This option is part of the Syntastic compatibility layer; if the option is not set, YCM will fall back to the value of the g:syntastic_always_populate_loc_list option before using this option's default. Default: 0 let g:ycm_always_populate_location_list = 0  The g:ycm_open_loclist_on_ycm_diags option When this option is set, :YcmDiags will automatically open the location list after forcing a compilation and filling the list with diagnostic data. See :help location-list in Vim to learn more about the location list. Default: 1 let g:ycm_open_loclist_on_ycm_diags = 1  The g:ycm_allow_changing_updatetime option When this option is set to 1, YCM will change the updatetime Vim option to 2000 (see :h updatetime). This may conflict with some other plugins you have (but it's unlikely). The updatetime option is the number of milliseconds that have to pass before Vim's CursorHold (see :h CursorHold) event fires. YCM runs the completion engines' ""file comprehension"" systems in the background on every such event; the identifier-based engine collects the identifiers whereas the semantic engine compiles the file to build an AST. The Vim default of 4000 for updatetime is a bit long, so YCM reduces this. Set this option to 0 to force YCM to leave your updatetime setting alone. Default: 1 let g:ycm_allow_changing_updatetime = 1  The g:ycm_complete_in_comments option When this option is set to 1, YCM will show the completion menu even when typing inside comments. Default: 0 let g:ycm_complete_in_comments = 0  The g:ycm_complete_in_strings option When this option is set to 1, YCM will show the completion menu even when typing inside strings. Note that this is turned on by default so that you can use the filename completion inside strings. This is very useful for instance in C-family files where typing #include "" will trigger the start of filename completion. If you turn off this option, you will turn off filename completion in such situations as well. Default: 1 let g:ycm_complete_in_strings = 1  The g:ycm_collect_identifiers_from_comments_and_strings option When this option is set to 1, YCM's identifier completer will also collect identifiers from strings and comments. Otherwise, the text in comments and strings will be ignored. Default: 0 let g:ycm_collect_identifiers_from_comments_and_strings = 0  The g:ycm_collect_identifiers_from_tags_files option When this option is set to 1, YCM's identifier completer will also collect identifiers from tags files. The list of tags files to examine is retrieved from the tagfiles() Vim function which examines the tags Vim option. See :h 'tags' for details. YCM will re-index your tags files if it detects that they have been modified. The only supported tag format is the Exuberant Ctags format. The format from ""plain"" ctags is NOT supported. Ctags needs to be called with the --fields=+l option (that's a lowercase L, not a one) because YCM needs the language:<lang> field in the tags output. See the FAQ for pointers if YCM does not appear to read your tag files. This option is off by default because it makes Vim slower if your tags are on a network directory. Default: 0 let g:ycm_collect_identifiers_from_tags_files = 0  The g:ycm_seed_identifiers_with_syntax option When this option is set to 1, YCM's identifier completer will seed its identifier database with the keywords of the programming language you're writing. Since the keywords are extracted from the Vim syntax file for the filetype, all keywords may not be collected, depending on how the syntax file was written. Usually at least 95% of the keywords are successfully extracted. Default: 0 let g:ycm_seed_identifiers_with_syntax = 0  The g:ycm_extra_conf_vim_data option If you're using semantic completion for C-family files, this option might come handy; it's a way of sending data from Vim to your FlagsForFile function in your .ycm_extra_conf.py file. This option is supposed to be a list of VimScript expression strings that are evaluated for every request to the ycmd server and then passed to your FlagsForFile function as a client_data keyword argument. For instance, if you set this option to ['v:version'], your FlagsForFile function will be called like this: # The '704' value is of course contingent on Vim 7.4; in 7.3 it would be '703' FlagsForFile(filename, client_data = {'v:version': 704})  So the client_data parameter is a dictionary mapping Vim expression strings to their values at the time of the request. The correct way to define parameters for your FlagsForFile function: def FlagsForFile(filename, **kwargs):  You can then get to client_data with kwargs['client_data']. Default: [] let g:ycm_extra_conf_vim_data = []  The g:ycm_server_python_interpreter option YCM will by default search for an appropriate Python interpreter on your system. You can use this option to override that behavior and force the use of a specific interpreter of your choosing. NOTE: This interpreter is only used for the ycmd server. The YCM client running inside Vim always uses the Python interpreter that's embedded inside Vim. Default: '' let g:ycm_server_python_interpreter = ''  The g:ycm_server_keep_logfiles option When this option is set to 1, the ycmd completion server will keep the logfiles around after shutting down (they are deleted on shutdown by default). To see where the logfiles are, call :YcmDebugInfo. Default: 0 let g:ycm_server_keep_logfiles = 0  The g:ycm_server_log_level option The logging level that the ycmd completion server uses. Valid values are the following, from most verbose to least verbose: - debug - info - warning - error - critical Note that debug is very verbose. Default: info let g:ycm_server_log_level = 'info'  The g:ycm_auto_start_csharp_server option When set to 1, the OmniSharp server will be automatically started (once per Vim session) when you open a C# file. Default: 1 let g:ycm_auto_start_csharp_server = 1  The g:ycm_auto_stop_csharp_server option When set to 1, the OmniSharp server will be automatically stopped upon closing Vim. Default: 1 let g:ycm_auto_stop_csharp_server = 1  The g:ycm_csharp_server_port option When g:ycm_auto_start_csharp_server is set to 1, specifies the port for the OmniSharp server to listen on. When set to 0 uses an unused port provided by the OS. Default: 0 let g:ycm_csharp_server_port = 0  The g:ycm_csharp_insert_namespace_expr option By default, when YCM inserts a namespace, it will insert the using statement under the nearest using statement. You may prefer that the using statement is inserted somewhere, for example, to preserve sorting. If so, you can set this option to override this behavior. When this option is set, instead of inserting the using statement itself, YCM will set the global variable g:ycm_namespace_to_insert to the namespace to insert, and then evaluate this option's value as an expression. The option's expression is responsible for inserting the namespace - the default insertion will not occur. Default: '' let g:ycm_csharp_insert_namespace_expr = ''  The g:ycm_add_preview_to_completeopt option When this option is set to 1, YCM will add the preview string to Vim's completeopt option (see :h completeopt). If your completeopt option already has preview set, there will be no effect. You can see the current state of your completeopt setting with :set completeopt? (yes, the question mark is important). When preview is present in completeopt, YCM will use the preview window at the top of the file to store detailed information about the current completion candidate (but only if the candidate came from the semantic engine). For instance, it would show the full function prototype and all the function overloads in the window if the current completion is a function name. Default: 0 let g:ycm_add_preview_to_completeopt = 0  The g:ycm_autoclose_preview_window_after_completion option When this option is set to 1, YCM will auto-close the preview window after the user accepts the offered completion string. If there is no preview window triggered because there is no preview string in completeopt, this option is irrelevant. See the g:ycm_add_preview_to_completeopt option for more details. Default: 0 let g:ycm_autoclose_preview_window_after_completion = 0  The g:ycm_autoclose_preview_window_after_insertion option When this option is set to 1, YCM will auto-close the preview window after the user leaves insert mode. This option is irrelevant if g:ycm_autoclose_preview_window_after_completion is set or if no preview window is triggered. See the g:ycm_add_preview_to_completeopt option for more details. Default: 0 let g:ycm_autoclose_preview_window_after_insertion = 0  The g:ycm_max_diagnostics_to_display option This option controls the maximum number of diagnostics shown to the user when errors or warnings are detected in the file. This option is only relevant if you are using the C-family semantic completion engine. Default: 30 let g:ycm_max_diagnostics_to_display = 30  The g:ycm_key_list_select_completion option This option controls the key mappings used to select the first completion string. Invoking any of them repeatedly cycles forward through the completion list. Some users like adding <Enter> to this list. Default: ['<TAB>', '<Down>'] let g:ycm_key_list_select_completion = ['<TAB>', '<Down>']  The g:ycm_key_list_previous_completion option This option controls the key mappings used to select the previous completion string. Invoking any of them repeatedly cycles backwards through the completion list. Note that one of the defaults is <S-TAB> which means Shift-TAB. That mapping will probably only work in GUI Vim (Gvim or MacVim) and not in plain console Vim because the terminal usually does not forward modifier key combinations to Vim. Default: ['<S-TAB>', '<Up>'] let g:ycm_key_list_previous_completion = ['<S-TAB>', '<Up>']  The g:ycm_key_invoke_completion option This option controls the key mapping used to invoke the completion menu for semantic completion. By default, semantic completion is trigged automatically after typing ., -> and :: in insert mode (if semantic completion support has been compiled in). This key mapping can be used to trigger semantic completion anywhere. Useful for searching for top-level functions and classes. Console Vim (not Gvim or MacVim) passes <Nul> to Vim when the user types <C-Space> so YCM will make sure that <Nul> is used in the map command when you're editing in console Vim, and <C-Space> in GUI Vim. This means that you can just press <C-Space> in both console and GUI Vim and YCM will do the right thing. Setting this option to an empty string will make sure no mapping is created. Default: <C-Space> let g:ycm_key_invoke_completion = '<C-Space>'  The g:ycm_key_detailed_diagnostics option This option controls the key mapping used to show the full diagnostic text when the user's cursor is on the line with the diagnostic. It basically calls :YcmShowDetailedDiagnostic. Setting this option to an empty string will make sure no mapping is created. Default: <leader>d let g:ycm_key_detailed_diagnostics = '<leader>d'  The g:ycm_global_ycm_extra_conf option Normally, YCM searches for a .ycm_extra_conf.py file for compilation flags (see the User Guide for more details on how this works). This option specifies a fallback path to a config file which is used if no .ycm_extra_conf.py is found. You can place such a global file anywhere in your filesystem. Default: '' let g:ycm_global_ycm_extra_conf = ''  The g:ycm_confirm_extra_conf option When this option is set to 1 YCM will ask once per .ycm_extra_conf.py file if it is safe to be loaded. This is to prevent execution of malicious code from a .ycm_extra_conf.py file you didn't write. To selectively get YCM to ask/not ask about loading certain .ycm_extra_conf.py files, see the g:ycm_extra_conf_globlist option. Default: 1 let g:ycm_confirm_extra_conf = 1  The g:ycm_extra_conf_globlist option This option is a list that may contain several globbing patterns. If a pattern starts with a ! all .ycm_extra_conf.py files matching that pattern will be blacklisted, that is they won't be loaded and no confirmation dialog will be shown. If a pattern does not start with a ! all files matching that pattern will be whitelisted. Note that this option is not used when confirmation is disabled using g:ycm_confirm_extra_conf and that items earlier in the list will take precedence over the later ones. Rules: * matches everything ? matches any single character [seq] matches any character in seq [!seq] matches any char not in seq Example: let g:ycm_extra_conf_globlist = ['~/dev/*','!~/*']  The first rule will match everything contained in the ~/dev directory so .ycm_extra_conf.py files from there will be loaded. The second rule will match everything in the home directory so a .ycm_extra_conf.py file from there won't be loaded. As the first rule takes precedence everything in the home directory excluding the ~/dev directory will be blacklisted. NOTE: The glob pattern is first expanded with Python's os.path.expanduser() and then resolved with os.path.abspath() before being matched against the filename. Default: [] let g:ycm_extra_conf_globlist = []  The g:ycm_filepath_completion_use_working_dir option By default, YCM's filepath completion will interpret relative paths like ../ as being relative to the folder of the file of the currently active buffer. Setting this option will force YCM to always interpret relative paths as being relative to Vim's current working directory. Default: 0 let g:ycm_filepath_completion_use_working_dir = 0  The g:ycm_semantic_triggers option This option controls the character-based triggers for the various semantic completion engines. The option holds a dictionary of key-values, where the keys are Vim's filetype strings delimited by commas and values are lists of strings, where the strings are the triggers. Setting key-value pairs on the dictionary adds semantic triggers to the internal default set (listed below). You cannot remove the default triggers, only add new ones. A ""trigger"" is a sequence of one or more characters that trigger semantic completion when typed. For instance, C++ (cpp filetype) has . listed as a trigger. So when the user types foo., the semantic engine will trigger and serve foo's list of member functions and variables. Since C++ also has -> listed as a trigger, the same thing would happen when the user typed foo->. It's also possible to use a regular expression as a trigger. You have to prefix your trigger with re! to signify it's a regex trigger. For instance, re!\w+\. would only trigger after the \w+\. regex matches. NOTE: The regex syntax is NOT Vim's, it's Python's. Default: [see next line] let g:ycm_semantic_triggers =  {   \   'c' : ['->', '.'],   \   'objc' : ['->', '.', 're!\[[_a-zA-Z]+\w*\s', 're!^\s*[^\W\d]\w*\s',   \             're!\[.*\]\s'],   \   'ocaml' : ['.', '#'],   \   'cpp,objcpp' : ['->', '.', '::'],   \   'perl' : ['->'],   \   'php' : ['->', '::'],   \   'cs,java,javascript,typescript,d,python,perl6,scala,vb,elixir,go' : ['.'],   \   'ruby' : ['.', '::'],   \   'lua' : ['.', ':'],   \   'erlang' : [':'],   \ }  The g:ycm_cache_omnifunc option Some omnicompletion engines do not work well with the YCM cache—in particular, they might not produce all possible results for a given prefix. By unsetting this option you can ensure that the omnicompletion engine is re-queried on every keypress. That will ensure all completions will be presented, but might cause stuttering and lagginess if the omnifunc is slow. Default: 1 let g:ycm_cache_omnifunc = 1  The g:ycm_use_ultisnips_completer option By default, YCM will query the UltiSnips plugin for possible completions of snippet triggers. This option can turn that behavior off. Default: 1 let g:ycm_use_ultisnips_completer = 1  The g:ycm_goto_buffer_command option Defines where GoTo* commands result should be opened. Can take one of the following values: [ 'same-buffer', 'horizontal-split', 'vertical-split', 'new-tab', 'new-or-existing-tab' ] If this option is set to the 'same-buffer' but current buffer can not be switched (when buffer is modified and nohidden option is set), then result will be opened in horizontal split. Default: 'same-buffer' let g:ycm_goto_buffer_command = 'same-buffer'  The g:ycm_disable_for_files_larger_than_kb option Defines the max size (in Kb) for a file to be considered for completion. If this option is set to 0 then no check is made on the size of the file you're opening. Default: 1000 let g:ycm_disable_for_files_larger_than_kb = 1000  The g:ycm_python_binary_path option This option specifies the Python interpreter to use to run the jedi completion library. Specify the Python interpreter to use to get completions. By default the Python under which ycmd runs is used (ycmd runs on Python 2.6, 2.7 or 3.3+). Default: '' let g:ycm_python_binary_path = 'python'  NOTE: the settings above will make YCM use the first python executable found through the PATH. FAQ I used to be able to import vim in .ycm_extra_conf.py, but now can't YCM was rewritten to use a client-server architecture where most of the logic is in the ycmd server. So the magic vim module you could have previously imported in your .ycm_extra_conf.py files doesn't exist anymore. To be fair, importing the magic vim module in extra conf files was never supported in the first place; it only ever worked by accident and was never a part of the extra conf API. But fear not, you should be able to tweak your extra conf files to continue working by using the g:ycm_extra_conf_vim_data option. See the docs on that option for details. On very rare occasions Vim crashes when I tab through the completion menu That's a very rare Vim bug most users never encounter. It's fixed in Vim 7.4.72. Update to that version (or above) to resolve the issue. I get ImportError exceptions that mention PyInit_ycm_core or initycm_core These errors are caused by building the YCM native libraries for Python 2 and trying to load them into a Python 3 process (or the other way around). For instance, if building for Python 2 but loading in Python 3: ImportError: dynamic module does not define init function (PyInit_ycm_core)  If building for Python 3 but loading in Python 2: ImportError: dynamic module does not define init function (initycm_core)  Setting the g:ycm_server_python_interpreter option to force the use of a specific Python interpreter for ycmd is usually the easiest way to solve the problem. Common values for that option are /usr/bin/python and /usr/bin/python3. I get a linker warning regarding libpython on Mac when compiling YCM If the warning is ld: warning: path '/usr/lib/libpython2.7.dylib' following -L not a directory, then feel free to ignore it; it's caused by a limitation of CMake and is not an issue. Everything should still work fine. I get a weird window at the top of my file when I use the semantic engine This is Vim's preview window. Vim uses it to show you extra information about something if such information is available. YCM provides Vim with such extra information. For instance, when you select a function in the completion list, the preview window will hold that function's prototype and the prototypes of any overloads of the function. It will stay there after you select the completion so that you can use the information about the parameters and their types to write the function call. If you would like this window to auto-close after you select a completion string, set the g:ycm_autoclose_preview_window_after_completion option to 1 in your vimrc file. Similarly, the g:ycm_autoclose_preview_window_after_insertion option can be set to close the preview window after leaving insert mode. If you don't want this window to ever show up, add set completeopt-=preview to your vimrc. Also make sure that the g:ycm_add_preview_to_completeopt option is set to 0. It appears that YCM is not working In Vim, run :messages and carefully read the output. YCM will echo messages to the message log if it encounters problems. It's likely you misconfigured something and YCM is complaining about it. Also, you may want to run the :YcmDebugInfo command; it will make YCM spew out various debugging information, including the ycmd logfile paths and the compile flags for the current file if the file is a C-family language file and you have compiled in Clang support. Logfiles can be automatically opened in the editor using the :YcmToggleLogs command. Sometimes it takes much longer to get semantic completions than normal This means that libclang (which YCM uses for C-family semantic completion) failed to pre-compile your file's preamble. In other words, there was an error compiling some of the source code you pulled in through your header files. I suggest calling the :YcmDiags command to see what they were. Bottom line, if libclang can't pre-compile your file's preamble because there were errors in it, you're going to get slow completions because there's no AST cache. YCM auto-inserts completion strings I don't want! This means you probably have some mappings that interfere with YCM's internal ones. Make sure you don't have something mapped to <C-p>, <C-x> or <C-u> (in insert mode). YCM never selects something for you; it just shows you a menu and the user has to explicitly select something. If something is being selected automatically, this means there's a bug or a misconfiguration somewhere. I get a E227: mapping already exists for <blah> error when I start Vim This means that YCM tried to set up a key mapping but failed because you already had something mapped to that key combination. The <blah> part of the message will tell you what was the key combination that failed. Look in the Options section and see if any of the default mappings conflict with your own. Then change that option value to something else so that the conflict goes away. I get 'GLIBC_2.XX' not found (required by libclang.so) when starting Vim Your system is too old for the precompiled binaries from llvm.org. Compile Clang on your machine and then link against the libclang.so you just produced. See the full installation guide for help. I'm trying to use a Homebrew Vim with YCM and I'm getting segfaults Something (I don't know what) is wrong with the way that Homebrew configures and builds Vim. I recommend using MacVim. Even if you don't like the MacVim GUI, you can use the Vim binary that is inside the MacVim.app package (it's MacVim.app/Contents/MacOS/Vim) and get the Vim console experience. I have a Homebrew Python and/or MacVim; can't compile/SIGABRT when starting You should probably run brew rm python; brew install python to get the latest fixes that should make YCM work with such a configuration. Also rebuild Macvim then. If you still get problems with this, see issue #18 for suggestions. Vim segfaults when I use the semantic completer in Ruby files This was caused by a Vim bug. Update your version of Vim (Vim 7.3.874 is known to work, earlier versions may also fix this issue). I get LONG_BIT definition appears wrong for platform when compiling Look at the output of your CMake call. There should be a line in it like the following (with .dylib in place of .so on a Mac): -- Found PythonLibs: /usr/lib/libpython2.7.so (Required is at least version ""2.5"")  That would be the correct output. An example of incorrect output would be the following: -- Found PythonLibs: /usr/lib/libpython2.7.so (found suitable version ""2.5.1"", minimum required is ""2.5"")  Notice how there's an extra bit of output there, the found suitable version ""<version>"" part, where <version> is not the same as the version of the dynamic library. In the example shown, the library is version 2.7 but the second string is version 2.5.1. This means that CMake found one version of Python headers and a different version for the library. This is wrong. It can happen when you have multiple versions of Python installed on your machine. You should probably add the following flags to your cmake call (again, dylib instead of so on a Mac): -DPYTHON_INCLUDE_DIR=/usr/include/python2.7 -DPYTHON_LIBRARY=/usr/lib/libpython2.7.so  This will force the paths to the Python include directory and the Python library to use. You may need to set these flags to something else, but you need to make sure you use the same version of Python that your Vim binary is built against, which is highly likely to be the system's default Python. I get libpython2.7.a [...] relocation R_X86_64_32 when compiling The error is usually encountered when compiling YCM on Centos or RHEL. The full error looks something like the following: /usr/bin/ld: /usr/local/lib/libpython2.7.a(abstract.o): relocation R_X86_64_32 against `a local symbol' can not be used when making a shared object; recompile with -fPIC  It's possible to get a slightly different error that's similar to the one above. Here's the problem and how you solve it: Your libpython2.7.a was not compiled with -fPIC so it can't be linked into ycm_core.so. Use the -DPYTHON_LIBRARY= CMake flag to point it to a .so version of libpython on your machine (for instance, -DPYTHON_LIBRARY=/usr/lib/libpython2.7.so). Naturally, this means you'll have to go through the full installation guide by hand. I get Vim: Caught deadly signal SEGV on Vim startup This can happen on some Linux distros. If you encounter this situation, run Vim under gdb. You'll probably see something like this in the output when Vim crashes: undefined symbol: clang_CompileCommands_dispose  This means that Vim is trying to load a libclang.so that is too old. You need at least a 3.8 libclang. Just go through the installation guide and make sure you are using a correct libclang.so. We recommend downloading prebuilt binaries from llvm.org. I get Fatal Python error: PyThreadState_Get: no current thread on startup This is caused by linking a static version of libpython into ycmd's ycm_core.so. This leads to multiple copies of the python interpreter loaded when python loads ycmd_core.so and this messes up python's global state. The details aren't important. The solution is that the version of Python linked and run against must be built with either --enable-shared or --enable-framework (on OS X). This is achieved as follows (NOTE: for Mac, replace --enable-shared with --enable-framework): When building python from source: ./configure --enable-shared {options} When building python from pyenv: PYTHON_CONFIGURE_OPTS=""--enable-shared"" pyenv install {version} install.py says python must be compiled with --enable-framework. Wat? See the previous answer for how to ensure your python is built to support dynamic modules. YCM does not read identifiers from my tags files First, put let g:ycm_collect_identifiers_from_tags_files = 1 in your vimrc. Make sure you are using Exuberant Ctags to produce your tags files since the only supported tag format is the Exuberant Ctags format. The format from ""plain"" ctags is NOT supported. The output of ctags --version should list ""Exuberant Ctags"". Ctags needs to be called with the --fields=+l (that's a lowercase L, not a one) option because YCM needs the language:<lang> field in the tags output. NOTE: Exuberant Ctags by default sets language tag for *.h files as C++. If you have C (not C++) project, consider giving parameter --langmap=c:.c.h to ctags to see tags from *.h files. NOTE: Mac OS X comes with ""plain"" ctags installed by default. brew install ctags will get you the Exuberant Ctags version. Also make sure that your Vim tags option is set correctly. See :h 'tags' for details. If you want to see which tag files YCM will read for a given buffer, run :echo tagfiles() with the relevant buffer active. Note that that function will only list tag files that already exist. CTRL-U in insert mode does not work YCM keeps you in a completefunc completion mode when you're typing in insert mode and Vim disables <C-U> in completion mode as a ""feature."" Sadly there's nothing I can do about this. YCM conflicts with UltiSnips TAB key usage YCM comes with support for UltiSnips (snippet suggestions in the popup menu), but you'll have to change the UltiSnips mappings. See :h UltiSnips-triggers in Vim for details. You'll probably want to change some/all of the following options: g:UltiSnipsExpandTrigger g:UltiSnipsJumpForwardTrigger g:UltiSnipsJumpBackwardTrigger  Why isn't YCM just written in plain VimScript, FFS? Because of the identifier completion engine and subsequence-based filtering. Let's say you have many dozens of files open in a single Vim instance (I often do); the identifier-based engine then needs to store thousands (if not tens of thousands) of identifiers in its internal data-structures. When the user types, YCM needs to perform subsequence-based filtering on all of those identifiers (every single one!) in less than 10 milliseconds. I'm sorry, but that level of performance is just plain impossible to achieve with VimScript. I've tried, and the language is just too slow. No, you can't get acceptable performance even if you limit yourself to just the identifiers in the current file and simple prefix-based filtering. Why does YCM demand such a recent version of Vim? During YCM's development several show-stopper bugs were encountered in Vim. Those needed to be fixed upstream (and were). A few months after those bugs were fixed, Vim trunk landed the pyeval() function which improved YCM performance even more since less time was spent serializing and deserializing data between Vim and the embedded Python interpreter. A few critical bugfixes for pyeval() landed in Vim 7.3.584 (and a few commits before that). I get annoying messages in Vim's status area when I type If you're referring to the User defined completion <bla bla> back at original and similar, then just update to Vim 7.4.314 (or later) and they'll go away. Nasty bugs happen if I have the vim-autoclose plugin installed Use the delimitMate plugin instead. It does the same thing without conflicting with YCM. Is there some sort of YCM mailing list? I have questions If you have questions about the plugin or need help, please use the ycm-users mailing list, don't create issues on the tracker. The tracker is for bug reports and feature requests. I get an internal compiler error when installing This can be a problem on virtual servers with limited memory. A possible solution is to add more swap memory. A more practical solution would be to force the build script to run only one compile job at a time. You can do this by setting the YCM_CORES environment variable to 1. Example: YCM_CORES=1 ./install.py --clang-completer  I get weird errors when I press Ctrl-C in Vim Never use Ctrl-C in Vim. Using Ctrl-C to exit insert mode in Vim is a bad idea. The main issue here is that Ctrl-C in Vim doesn't just leave insert mode, it leaves it without triggering InsertLeave autocommands (as per Vim docs). This is a bad idea and is likely to break many other things and not just YCM. Bottom line, if you use Ctrl-C to exit insert mode in Vim, you're gonna have a bad time. If pressing <esc> is too annoying (agreed, it is), we suggest mapping it to something more convenient. On a QWERTY keyboard, a good pick for the <esc> map is inoremap jk <Esc>. This is right on the home row, it's an incredibly rare digraph in English and if you ever need to type those two chars in sequence in insert mode, you just type j, then wait 500ms, then type k. Why did YCM stop using Syntastic for diagnostics display? Previously, YCM would send any diagnostics it would receive from the libclang semantic engine to Syntastic for display as signs in the gutter, red squiggles etc. Today, YCM uses its own code to do that. Using Syntastic for this was always a kludge. Syntastic assumes its ""checker"" plugins behave in a certain way; those assumptions have never fit YCM. For instance, YCM continuously recompiles your code in the background for C-family languages and tries to push new diagnostics to the user as fast as possible, even while the user types. Syntastic assumes that a checker only runs on file save (""active"" mode) or even less frequently, when the user explicitly invokes it (""passive"" mode). This mismatch in assumptions causes performance problems since Syntastic code isn't optimized for this use case of constant diagnostic refreshing. Poor support for this use case also led to crash bugs in Vim caused by Syntastic-Vim interactions (issue #593) and other problems, like random Vim flickering. Attempts were made to resolve these issues in Syntastic, but ultimately some of them failed (for various reasons). Implementing diagnostic display code directly in YCM resolves all of these problems. Performance also improved substantially since the relevant code is now written in Python instead of VimScript (which is very slow) and is tailored only for YCM's use-cases. We were also able to introduce new features in this area since we're now not limited to the Syntastic checker API. We've tried to implement this in the most backwards-compatible way possible; YCM options that control diagnostic display fall back to Syntastic options that control the same concepts if the user has those set. Still, some Syntastic-specific configuration you might have had might not be supported by the new code. Please file issues on the tracker in such cases; if we find the request to be reasonable, we'll find a way to address it. Completion doesn't work with the C++ standard library headers This is caused by an issue with libclang that only affects some operating systems. Compiling with clang the binary will use the correct default header search paths but compiling with libclang.so (which YCM uses) does not. Mac OS X is normally affected, but there's a workaround in YCM for that specific OS. If you're not running that OS but still have the same problem, continue reading. The workaround is to call echo | clang -v -E -x c++ - and look at the paths under the #include <...> search starts here: heading. You should take those paths, prepend -isystem to each individual path and append them all to the list of flags you return from your FlagsForFile function in your .ycm_extra_conf.py file. See issue #303 for details. When I open a JavaScript file, I get an annoying warning about .tern-project file Take a look at the instructions for using the JavaScript completer. If this is still really annoying, and you have a good reason not to have a .tern-project file, create an empty .tern-config file in your home directory and YCM will stop complaining. When I start vim I get a runtime error saying R6034 An application has made an attempt to load the C runtime library incorrectly. CMake and other things seem to screw up the PATH with their own msvcrXX.dll versions. Add the following to the very top of your vimrc to remove these entries from the path. python << EOF import os import re path = os.environ['PATH'].split(';')  def contains_msvcr_lib(folder):     try:         for item in os.listdir(folder):             if re.match(r'msvcr\d+\.dll', item):                 return True     except:         pass     return False  path = [folder for folder in path if not contains_msvcr_lib(folder)] os.environ['PATH'] = ';'.join(path) EOF  I hear that YCM only supports Python 2, is that true? No. Both the Vim client and the ycmd server run on Python 2 or 3. If you work on a Python 3 project, you may need to set g:ycm_python_binary_path to the Python interpreter you use for your project to get completions for that version of Python. On Windows I get E887: Sorry, this command is disabled, the Python's site module could not be loaded If you are running vim on Windows with Python 2.7.11, this is likely caused by a bug. Follow this workaround or use a different version (Python 2.7.9 does not suffer from the bug). I can't complete python packages in a virtual environment. This means that the Python used to run JediHTTP is not the Python of the virtual environment you're in. To resolve this you either set g:ycm_python_binary_path to the absolute path of the Python binary in your virtual environment or since virtual environment will put that Python executable first in your PATH when the virtual environment is active then if you set g:ycm_python_binary_path to just 'python' it will be found as the first Python and used to run JediHTTP. Contributor Code of Conduct Please note that this project is released with a Contributor Code of Conduct. By participating in this project you agree to abide by its terms. Contact If you have questions about the plugin or need help, please use the ycm-users mailing list. If you have bug reports or feature suggestions, please use the issue tracker. The latest version of the plugin is available at http://valloric.github.io/YouCompleteMe/. The author's homepage is http://val.markovic.io. License This software is licensed under the GPL v3 license. © 2015-2016 YouCompleteMe contributors"	"null"	"null"	"A code completion engine for Vim. only."	"true"
"Tools"	"Artistic Style"	"http://astyle.sourceforge.net/"	"A fast and small automatic source code formatter that supports C. only."	"null"	"null"	"null"	"GNU LGPL3"	"http://www.gnu.org/licenses/lgpl.html"	"null"	"null"	"null"	"null"	"null"	"Artistic Style - Index Artistic Style 2.05 A Free, Fast, and Small Automatic Formatter for C, C++, C++/CLI, Objective‑C, C#, and Java Source Code Project Page: http://astyle.sourceforge.net/ SourceForge: http://sourceforge.net/projects/astyle/   Artistic Style is a source code indenter, formatter, and beautifier for the C, C++, C++/CLI, Objective‑C, C# and Java programming languages. When indenting source code, we as programmers have a tendency to use both spaces and tab characters to create the wanted indentation. Moreover, some editors by default insert spaces instead of tabs when pressing the tab key, and other editors (Emacs for example) have the ability to ""pretty up"" lines by automatically setting up the white space before the code on the line, possibly inserting spaces in a code that up to now used only tabs for indentation. Since the NUMBER of space characters showed on screen for each tab character in the source code changes between editors (unless the user sets up the number to his liking...), one of the standard problems programmers are facing when moving from one editor to another is that code containing both spaces and tabs that was up to now perfectly indented, suddenly becomes a mess to look at when changing to another editor. Even if you as a programmer take care to ONLY use spaces or tabs, looking at other people's source code can still be problematic. To address this problem, Artistic Style was created – a filter written in C++ that automatically re-indents and re-formats C / C++ / Objective‑C / C++/CLI / C# / Java source files. It can be used from a command line, or it can be incorporated as classes in another C++ program. Documentation There is complete documentation for using Artistic Style. The documentation needed to install and run Artistic Style is included in the distribution package. It does not need an Internet connection. News and Release Notes These contain information on the changes in the current release. The News contains information on major changes and how they might affect the use of Artistic Style. The Release Notes contains a list of all changes made to the program. Information on old releases is also listed. Download The latest release can be downloaded from the SourceForge file releases page. A link to the ""latest version"" near the top of the page will download the correct package for your platform. Or you can select the appropriate package from the ""astyle"" release folders. The Windows package contains a compiled binary. Other platforms will need to compile the source code. Makefiles are included for the most popular compilers. Follow the install instructions for the appropriate platform as described in the ""Install"" documentation. Subversion The latest development files can be checked out from the Artistic Style repository using Subversion. Install This containd information on compiling and installing Artistic Style. The Windows platform comes with a precompiled executable. Other platforms must compile the project. Follow the instructions for the appropriate platform (Linux, Mac, or Windows). License Artistic Style may be used and distributed under version 3 the GNU Lesser General Public License (LGPL). The LGPL is a set of additional permissions added to version 3 of the GNU General Public License. You can use Artistic Style in free or commercial software without charge. Projects that use Artistic Style do not have to make the source code available. If Artistic Style itself is modified, however, the modified Artistic Style source code must be made available. Scripts This page contains scripts to support the Artistic Style program. They are in various script languages and work on different platforms. It includes scripts to clean the directories of backup files created by Artistic Style. Links There are several applications that use Artistic Style as contributed software. It is either embedded in the application or called as a command line program. The applications include Graphical User Interfaces to view the effect of formatting on the source code, development environments for various platforms, and other software.  Developer Information Artistic Style has compile options for creating a shared library (DLL) or static library for use with a Graphical User Interface (GUI). With the Java Development Kit (JDK) installed it can be compiled as a Java Native Interface (JNI) and called from a Java program. The Developer Information documents the calling procedure and has example programs for C++, C++/CLI, Objective‑C, Java, C#, and Python. Bug Reports, Change Requests, Update Notifications Bug reports and change requests should be submitted to the bug tracker page. You must be logged in to SourceForge to submit a report. If possible include an example that shows the problem. It does not need to be functional code. Note that code copied and pasted into the bug report will not be indented after the data is submitted. You must indicate the indentation when you submit the request (e.g. replace leading spaces with periods). The best way to subscribe to update notifications is using the SourceForge Project Page ""Update Notifications"" button. The option to subscribe is also displayed during a file download. The subscription options for a project can be modified using the ""Me"", ""Account Settings"" option on the SourceForge bar at the top of the page. Select the ""Subscriptions"" tab and check the notifications you want. Usually only the ""files"" option is needed. You can also subscribe to change notifications using an RSS feed. There is an RSS symbol on the SourceForge Files page. Or you can use the ""subscriptions"" or ""add content"" option available in your RSS reader. To contact the project by email use the address jimp03@email.com. Maintainers Artistic Style is maintained and updated by Jim Pattee. The original author was Tal Davidson, Israel. Acknowledgments Thanks to Jim Watson, Fred Shwartz, W. Nathaniel Mills III, Danny Deschenes, Andre Houde, Richard Bullington, Paul-Michael Agapow, Daryn Adler, Dieter Bayer, Sam Cooler, Jim Duff, Emilio Guijarro, Jens Krinke, Eran Ifrah, Travis Robinson, Max Horn, Ettl Martin, Mario Gleichmann, J P Nurmi, Colin D Bennett, Christian Stimming, MrTact, Wim Rosseel, Matthew Woehlke, Chris Schwarz, Chang Jiang, Arseny Solokha, Milian Wolff, Johannes Martin, Arne F?rlie, Marvin Humphrey, J, Christopher Sean Morrison, Keith OHara, louis6g, Evmenov Georgiy, beta100100, Ruzzz, Peter A. Bigot, HyungKi Jeong, David Faure, Carl Moore, Mofi for their patches and contributions to Artistic Style. Thanks to SourceForge for giving Artistic Style its home. Thanks to all the dedicated beta-testers and bug notifiers!   ENJOY!!!  "	"null"	"null"	"A fast and small automatic source code formatter that supports C. only."	"true"
"Tools"	"address-sanitizer"	"https://github.com/google/sanitizers"	"A fast memory error detector.."	"null"	"null"	"null"	"Apache2.0"	"http://directory.fsf.org/wiki/License:Apache2.0"	"null"	"null"	"684"	"89"	"90"	"GitHub - google/sanitizers: AddressSanitizer, ThreadSanitizer, MemorySanitizer Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 89 Star 684 Fork 90 google/sanitizers Code Issues 162 Pull requests 1 Wiki Pulse Graphs AddressSanitizer, ThreadSanitizer, MemorySanitizer 2,096 commits 2 branches 0 releases 9 contributors Python 42.0% Shell 39.8% Go 6.9% C++ 5.8% C 5.5% Python Shell Go C++ C Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags gh-pages master Nothing to show Nothing to show New pull request Latest commit 0319ead Jun 24, 2016 mikea console fixes … - fixing missing x sign for broken builds - ignoring header row Permalink Failed to load latest commit information. address-sanitizer kasan_symbolize: don't print questionable frames by default Dec 3, 2015 benchmarks/apache move benchmarks from thread-sanitizer to root Dec 3, 2015 dashboard console fixes Jun 24, 2016 memory-sanitizer/bootstrap Remove deprecated parts of memory-sanitizer repo. Sep 1, 2015 README.md Update README.md Dec 2, 2015 README.md sanitizers This project is the home for Sanitizers: AddressSanitizer, MemorySanitizer, ThreadSanitizer, LeakSanitizer. The actual code resides in the LLVM repository. Here we keep extended documentation, bugs and some helper code. Wiki documentation for our tools: AddressSanitizer (detects addressability issues) and LeakSanitizer (detects memory leaks) ThreadSanitizer (detects data races and deadlocks) for C++ and Go MemorySanitizer (detects use of uninitialized memory) We have recently migrated from code.google.com to github, some links may be broken. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/google/sanitizers"	"A fast memory error detector.."	"true"
"Tools"	"biicode"	"https://biicode.github.io/biicode/"	"A modern dependency manager for C.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"null"	"null"	"null"	"Biicode's open source project. Open C and C++ dependency management. A multi-platform C and C++ dependency manager biicode manages your project’s dependencies so you can use the libs you need (Curl, Catch, Fann, OpenSSL, OpenCV, POCO, Boost, Libuv, GTest ...) as you wish within your project. biicode uses CMake to configure and build your projects and it is compatible with many IDEs, version control systems and compilers. Install biicode We have precompiled binaries for most platforms, and you can also run biicode from its sources. Just follow this steps: Clone biicode/biicode repo: $ git clone https://github.com/biicode/biicode.git Initialize its submodules: $ git submodule update --init --recursive Install biicode dependencies with pip: $ pip install -r client/requirements.txt $ pip install -r common/requirements.txt biicode entry point is biicode.client.shell.bii module. You can use bii python script, which calls bii.main function; just fill the absolute path of the cloned biicode repository folder: #!/usr/bin/env python  import sys, os  biicode_repo_path = """" # ABSOLUTE PATH TO BIICODE REPOSITORY FOLDER  sys.path.append(os.path.join(biicode_repo_path, ""../"")) from biicode.client.shell.bii import main main(sys.argv[1:]) Then add that bii file to your PATH and you are ready: $ bii --help SYNOPSIS:     $ bii COMMAND [options] For help about a command:     $ bii COMMAND --help To change verbosity, use options --quiet --verbose ... This is the site where the source code of the different parts of biicode will be released As stated here and here this is part of a full open source release of every single biicode element. The following repo acts as own main issue tracker, and includes the biicode modules that have been open sourced as git submodules. Currently sources of the biicode client are available only. Feel free to fork it, star it and clone it. We would like to receive as many PRs as possible, but please read the contribute information first. Join us! Create your own biicode account to distribute you open source C/C++ projects within the community! Registration for public open source projects is completely free, but we have premium accounts available for private projects too. Also you can contribute to our project! Help us make C and C++ programming environment more modern and agile. More info in biicode.com biicode is maintained by biicode."	"null"	"null"	"A modern dependency manager for C.."	"true"
"Tools"	"c"	"https://github.com/ryanmjacobs/c"	"Compile and execute C ""scripts"" in one go on the command line. Also has shebang support.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"1361"	"67"	"100"	"GitHub - ryanmjacobs/c: Compile and execute C ""scripts"" in one go! Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 67 Star 1,361 Fork 100 ryanmjacobs/c Code Issues 3 Pull requests 0 Pulse Graphs Compile and execute C ""scripts"" in one go! 134 commits 2 branches 10 releases Fetching contributors Shell 80.0% C 12.6% C++ 5.3% Ruby 2.1% Shell C C++ Ruby Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags gh-pages master Nothing to show v0.10 v0.09 v0.08 v0.07 v0.06 v0.05 v0.04 v0.03 v0.02 v0.01 Nothing to show New pull request Latest commit f4511eb Jun 27, 2016 Uladox committed with ryanmjacobs Removes bug with c library linking with shebang. (#32) … * Fixes bug where library comes before source file.  Before when compiling with a shebang like ""#!/usr/bin/c -lsomelib --"" it would run as ""cc -lsomelib source.c"" instead of the proper ""cc source.c -lsomelib"" with the only workaround being ""cc -- -lsomelib --"" which was a workaround.  * Removes comment of old code I forgot to last time.  Should have done it last commit. Permalink Failed to load latest commit information. examples s/NO_ADDRESS/NO_DATA/g Feb 8, 2016 tests tests: remove github_commits.c b/c of library dependencies Feb 8, 2016 .travis.yml add tests! Mar 2, 2015 LICENSE Move license out of README. Jan 3, 2016 README.md fix permissions, and move instead of copying May 28, 2016 c Removes bug with c library linking with shebang. (#32) Jun 28, 2016 c.rb Add brew formula Jun 11, 2015 package.json Fix bpkg. Mar 10, 2015 README.md c ""There isn't much that's special about C. That's one of the reasons why it's fast."" I love C for its raw speed (although it does have its drawbacks). We should all write more C. With this shell script, you can compile and execute C ""scripts"" in one go! (Oh yeah, and it works for C++ too.) Here's a simple example: #include <stdio.h>  int main(void) {     printf(""Hello World!\n"");     return 0; } Run it by typing: $ c hello.c Hello World! Or, call it from the shebang! #!/usr/bin/c #include <stdio.h>  int main(void) {     printf(""Hello World!\n"");     return 0; } $ chmod +x hello.c $ ./hello.c Hello World! Hooked? Here's how to install it: Use a package manager? Check here. For all users: $ wget https://raw.githubusercontent.com/ryanmjacobs/c/master/c $ sudo install -Dm 755 c /usr/bin/c Just for a local user: $ wget https://raw.githubusercontent.com/ryanmjacobs/c/master/c $ sudo install -Dm 755 c ~/.bin/c $ echo 'PATH=$PATH:$HOME/.bin' >> ~/.bashrc Note: if you install it somewhere other than /usr/bin/c, then your shebang will be different. For example it may be something more similar to #!/home/ryan/.bin/c. Okay, how do I use it? c will use whatever $CC is set to. You can change this with: $ export CC=clang $ export CC=tcc $ # etc... CLI Multiple Files - CLI Anything you want passed to the compiler, put in quotes as the first argument. Whether they're flags (-Wall, -O2, etc.) or file names (file.c, main.c, etc.). $ c ""main.c other.c"" arg1 arg2 $ c ""main.c other.c -O3 -Wall -lncurses"" arg1 arg2 Single File - CLI With only one file, omit the quotes: $ c hello.c $ c main.c arg1 arg2 Shebang! After adding a shebang, just set the file to executable and it's ready to run. $ chmod +x file.c $ ./file.c Single File - Shebang Add this to the top of your C file: #!/usr/bin/c Multiple Files - Shebang Just tack on any extra flags, options, or files you want passed to the compiler. Then be sure to add the terminating -- characters. #!/usr/bin/c file1.c file2.c -lncurses -lm -- Compiling from stdin $ cat hello.c | c # ...or... $ c < hello.c $ c """" arg1 arg2 < hello.c $ c ""other.c -lncurses"" arg1 arg2 < hello.c Caching The default cache size is set to 5 MB. You can change this with: $ export C_CACHE_SIZE=$((10*1024)) # 10 MB The default cache path is set to $TMPDIR/c.cache. You can change this with: $ export C_CACHE_PATH=""/tmp/the_cache"" Contributing Feel free to submit any ideas, questions, or problems by reporting an issue. Or, if you're feeling bit brave, submit a pull request. 😬 Just hack away and make sure that all the tests pass. $ cd tests $ ./test.sh Why? First of all, I want to clarify why this is not the same as tcc -run. TCC is a compiler. We all know that. TCC will perform its own set of optimizations, just as GCC will perform its own and Clang will perform its own. The purpose of this script is to give a simple front-end to your favorite compiler. Whether it's GCC, Clang, or something else entirely, you get to choose your compiler. Second reason: it's simply satisfying to type c hello.c and see it run instantly. Third reason: I'm a fan of speed, and C definitely offers it. Being able to write a small, fast, and portable C ""script"" is great. You can pass around a C ""script"" just like you would a BASH script. zsh If you're using zsh, then you can take advantage of zsh's suffix aliases: $ alias -s c='c' $ alias -s cc='c' $ alias -s cpp='c' Then you can run files with ./file.c without chmod +x. Packages Use a package manager? You've come to the right place. AUR: https://aur.archlinux.org/packages/c/ bpkg: bpkg install ryanmjacobs/c brew: brew install https://raw.githubusercontent.com/ryanmjacobs/c/master/c.rb (shebang will be #!/usr/local/bin/c) Todo Maybe later we can implement caching. Done! License MIT License. Basically, you can do whatever you want provided that you include the LICENSE notice in any copy of the source. Also, I am not liable if the script breaks anything. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/ryanmjacobs/c"	"Compile and execute C ""scripts"" in one go on the command line. Also has shebang support.."	"true"
"Tools"	"c99sh"	"https://github.com/RhysU/c99sh"	"Run C files using hash-bang.."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"29"	"2"	"5"	"GitHub - RhysU/c99sh: A shebang-friendly script for ""interpreting"" single C99 files. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 2 Star 29 Fork 5 RhysU/c99sh Code Issues 7 Pull requests 0 Pulse Graphs A shebang-friendly script for ""interpreting"" single C99 files. 59 commits 1 branch 5 releases Fetching contributors Shell 82.5% C 8.9% Matlab 8.6% Shell C Matlab Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show v1.0.1 v1.0.0 v0.0.3 v0.0.2 v0.0.1 Nothing to show New pull request Fetching latest commit… Cannot retrieve the latest commit at this time. Permalink Failed to load latest commit information. basic cxx gsl openmp README.md c11sh c99sh c99shrc.example cxxsh README.md c99sh A shebang-friendly script for ""interpreting"" single C99, C11, and C++ files, including rcfile support. For example, installing this ~/.c99shrc control file -Wall -g -O2 #include <stdio.h>  permits executing hello containing #!/usr/bin/env c99sh int main() {     puts(""Hello, world!""); }  to produce the output one expects provided c99sh is in the path. You may also run c99sh foo.c to execute some foo.c lacking the shebang line. Try c99sh -v foo.c if you encounter trouble and want to see the compilation command. Check out c99sh -h for all the command line options you might use. In particular, for simple tasks you might find that the command line options in conjunction with HERE documents can accomplish many things. For example, $ ./c99sh -sm <<HERE puts(""Hello, world!""); HERE  Control files can supply compilation and linking flags, preprocessor directives like #include, and pkg-config directives to simplify library usage. A c99shrc located in the same directory as the interpreted source will be used. Otherwise a ~/.c99shrc is processed if available. See c99shrc.example for an extended control file enabling GSL, GLib, and SQLite capabilities. This permits quickly getting access to higher-level data structures. A more entertaining example is an OpenMP-enabled Monte Carlo computation of π screaming like a banshee on all your cores (c99shrc, source): #!/usr/bin/env c99sh  int main(int argc, char *argv[]) {     long long niter = argc > 1 ? atof(argv[1]) : 100000;     long long count = 0;      #pragma omp parallel     {         unsigned int seed = omp_get_thread_num();          #pragma omp for reduction(+: count) schedule(static)         for (long long i = 0; i < niter; ++i) {             const double x = rand_r(&seed) / (double) RAND_MAX;             const double y = rand_r(&seed) / (double) RAND_MAX;             count += sqrt(x*x + y*y) < 1;         }      }      printf(""%lld: %g\n"", niter, M_PI - 4*(count / (double) niter)); }  Take that, GIL. Kidding aside, the speedup in the edit-compile-run loop can be handy during prototyping or analysis. It is nice when useful one-off scripts can be moved directly into C ABI code instead of requiring an additional {Python,Octave,R}-to-C translation and debugging phase. For example, compare the Octave version of some simple logic with the equivalent c99sh-based version requiring only a few one-time additions to your ~/.c99shrc. As nearly the entire C99-oriented implementation works for C++, by invoking c99sh through either a copy or symlink named cxxsh, you can write C++-based logic. The relevant control files are named like cxxshrc in this case and they support directives like using namespace std and namespace fb = foo::bar. See cxx/hello and cxx/cxxshrc for a hello world C++ example. One nice use case is hacking atop Eigen since it provides pkg-config support. That is, cxxsh -p eigen3 myprogram builds and runs a one-off, Eigen-based program. With the right cxxshrc, such a program can be turned into a script. Though, you will likely notice the compilation overhead much moreso with C++ than C99. That said, for repeated invocation an output binary can be saved with the -x option should repeated recompilation be prohibitively expensive. C11 can be used via a symlink named c11sh with control files like c11shrc. The idea for c99sh came from 21st Century C's section ""Compiling C Programs via Here Document"" (available online) by Ben Klemens. Additionally, I wrote it somewhat in reaction to browsing the C++-ish work by elsamuko/cppsh. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/RhysU/c99sh"	"Run C files using hash-bang.."	"true"
"Tools"	"CBMC"	"http://www.cprover.org/cbmc/"	"C Bounded Model Checker; a tool for verification of array bounds, pointer safety and user-specified assertions.."	"null"	"null"	"null"	"Original BSD"	"https://directory.fsf.org/wiki/License:BSD_4Clause"	"null"	"null"	"12"	"8"	"19"	"GitHub - diffblue/cbmc: C Bounded Model Checker Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 8 Star 12 Fork 19 diffblue/cbmc Code Issues 30 Pull requests 28 Pulse Graphs C Bounded Model Checker http://www.cprover.org/cbmc 6,957 commits 6 branches 17 releases Fetching contributors C++ 79.5% C 13.7% Scilab 2.8% Yacc 1.3% Lex 0.8% Makefile 0.6% Other 1.3% C++ C Scilab Yacc Lex Makefile Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags ESOP2014-heap cegis master peter-incremental-unwinding-4.9 peter-incremental-unwinding propositional-encodings Nothing to show cbmc-5.4 cbmc-5.3 cbmc-5.2 cbmc-5.1 cbmc-5.0 cbmc-4.9 cbmc-4.9-sv-comp-2015 cbmc-4.8-incremental cbmc-4.7 cbmc-4.6 cbmc-4.5 cbmc-4.5-sv-comp-2014 cbmc-4.4 cbmc-4.3 cbmc-4.2 cbmc-4.1 cbmc-4.0 Nothing to show New pull request Latest commit 260b11f Jul 13, 2016 kroening fix for length modifiers Permalink Failed to load latest commit information. doc added the option --trace Jul 5, 2016 regression fix for length modifiers Jul 13, 2016 scripts removed spurious output in glucose patch Jul 8, 2016 src fix for length modifiers Jul 13, 2016 unit Moved unit tests to separate directory Feb 16, 2016 .gitignore more binaries Jul 1, 2016 .travis.yml Initial README.md, including Travis-CI configuration Mar 19, 2016 CHANGELOG added floating-point overflow checks Jan 28, 2014 CODING_STANDARD initial commit May 8, 2011 COMPILING libzip build instructions Jun 23, 2016 LICENSE Daniel's affiliation Aug 28, 2014 README.md fixed travis links in README.md Mar 20, 2016 README.md CProver Wiki About CBMC is a Bounded Model Checker for C and C++ programs. It supports C89, C99, most of C11 and most compiler extensions provided by gcc and Visual Studio. It also supports SystemC using Scoot. It allows verifying array bounds (buffer overflows), pointer safety, exceptions and user-specified assertions. Furthermore, it can check C and C++ for consistency with other languages, such as Verilog. The verification is performed by unwinding the loops in the program and passing the resulting equation to a decision procedure. For full information see cprover.org. License 4-clause BSD license, see LICENSE file. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/diffblue/cbmc"	"C Bounded Model Checker; a tool for verification of array bounds, pointer safety and user-specified assertions.."	"true"
"Utilities"	"libmpv"	"https://github.com/mpv-player/mpv"	"A music-playing library. Compile with to not have the music player. or later."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"3672"	"264"	"499"	"GitHub - mpv-player/mpv: Video player based on MPlayer/mplayer2 Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 264 Star 3,672 Fork 499 mpv-player/mpv Code Issues 307 Pull requests 15 Wiki Pulse Graphs Video player based on MPlayer/mplayer2 https://mpv.io 43,564 commits 37 branches 57 releases 165 contributors C 89.9% Objective-C 3.9% Lua 2.3% Python 2.2% Perl 0.9% C++ 0.3% Other 0.5% C Objective-C Lua Python Perl C++ Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags build clang-format coverity_scan cplugins d3d_copy_texture deprecate_opengl_hq display_link fix-ffmpeg-build gl-query-timer hooks json_test libxmp lockfocus master matroska2 mruby native-fs no-graphics-switching openbsd-iconv qtexample_qwidget_osd_overlay_demo release/current release/0.1 release/0.2 release/0.3 release/0.4 release/0.5 release/0.6 release/0.7 release/0.8 release/0.9 sdl2-pixelformats something sub_render timing udp_sync wayland-next win32-alpha Nothing to show v0.18.1 v0.18.0 v0.17.0 v0.16.0 v0.15.0 v0.14.0 v0.13.0 v0.12.0 v0.11.0 v0.10.0 v0.9.2 v0.9.1 v0.9.0 v0.8.3 v0.8.2 v0.8.1 v0.8.0 v0.7.3 v0.7.2 v0.7.1 v0.7.0 v0.6.2 v0.6.1 v0.6.0 v0.5.4 v0.5.3 v0.5.2 v0.5.1 v0.5.0 v0.4.2 v0.4.1 v0.4.0 v0.3.11 v0.3.10 v0.3.9 v0.3.8 v0.3.7 v0.3.6 v0.3.5 v0.3.4 v0.3.3 v0.3.2 v0.3.1 v0.3.0 v0.2.4 v0.2.3 v0.2.2 v0.2.1 v0.2.0 v0.1.7 v0.1.6 v0.1.5 v0.1.4 v0.1.3 v0.1.2 v0.1.1 v0.1.0 Nothing to show New pull request Latest commit 79974e7 Jul 15, 2016 wm4 audio: fix crashes due to broken uninit check … Since mixer->ao is always NULL now (it was really just forgotten to be removed), the uninit call never actually cleared the af field, leaving a dangling pointer that could be accessed by volume control. Permalink Failed to load latest commit information. .github github: move ""reproduction steps"" before behavior sections Jun 20, 2016 DOCS vf_d3d11vpp: add video processor selection Jul 15, 2016 TOOLS Use - as command-name separator everywhere Jul 14, 2016 audio audio: fix crashes due to broken uninit check Jul 15, 2016 common player: fatal error if linked and compiled FFmpeg versions mismatch Jul 1, 2016 demux demux_timeline: restore mkv edition switching Jul 14, 2016 etc Use - as command-name separator everywhere Jul 14, 2016 input Use - as command-name separator everywhere Jul 14, 2016 libmpv Use - as command-name separator everywhere Jul 14, 2016 misc Fix misspellings Jun 26, 2016 options videotoolbox: add --hwdec=videotoolbox-copy for h/w accelerated decod… Jul 15, 2016 osdep Use - as command-name separator everywhere Jul 14, 2016 player player: do not cut off terminal status line if it contains newlines Jul 15, 2016 stream cache: minor simplification Jul 11, 2016 sub mp_image: split colorimetry metadata into its own struct Jul 3, 2016 ta ta: remove old and redundant macro May 17, 2016 test chmap_sel: prefer inexact equivalents over perfect upmix Jan 4, 2016 video vf_vavpp: get rid of mp_refqueue_is_interlaced() Jul 15, 2016 waftools waftools: remove trailing newline Jun 8, 2016 .gitignore vo_opengl: remove nnedi3 prescaler Jun 18, 2016 .travis.yml travis: move travis-deps script to TOOLS May 12, 2016 Copyright vo_opengl: remove nnedi3 prescaler Jun 18, 2016 LICENSE Copyright, LICENSE: switch to GPL version 2 or later Oct 13, 2013 README.md readme: fix typo Jul 1, 2016 appveyor.yml Add Appveyor CI integration for Windows builds May 12, 2016 bootstrap.py build: update waf to 1.8.12 Jul 18, 2015 mpv_talloc.h mpv_talloc.h: rename from talloc.h Jan 11, 2016 version.sh build: don't make version.sh create version.h by default Jul 14, 2015 wscript vd_lavc: expose mastering display side data reference peak Jul 3, 2016 wscript_build.py d3d: merge angle_common.h into d3d.h Jun 28, 2016 README.md mpv Overview Downloads Compilation FFmpeg vs. Libav Release cycle Bug reports Contributing Relation to MPlayer and mplayer2 Wiki Man pages Contact License Overview mpv is a media player based on MPlayer and mplayer2. It supports a wide variety of video file formats, audio and video codecs, and subtitle types. Releases can be found on the release list. System requirements A not too ancient Linux, or Windows Vista or later, or OSX 10.8 or later. A somewhat capable CPU. Hardware decoding might sometimes help if the CPU is too slow to decode video realtime, but must be explicitly enabled with the --hwdec option. On Windows, a CPU with SSE4 instruction set is required to get decent hardware decoding performance. A not too crappy GPU. mpv is not intended to be used with bad GPUs. There are many caveats with drivers or system compositors causing tearing, stutter, etc. On Windows, you might want to make sure the graphics drivers are current, especially OpenGL. In some cases, ancient fallback video output methods can help (such as --vo=xv on Linux), but this use is not recommended or supported. Downloads For semi-official builds and third-party packages please see mpv.io. Compilation Compiling with full features requires development files for several external libraries. Below is a list of some important requirements. The mpv build system uses waf but we don't store it in your source tree. The script './bootstrap.py' will download the latest version of waf that was tested with the build system. For a list of the available build options use ./waf configure --help. If you think you have support for some feature installed but configure fails to detect it, the file build/config.log may contain information about the reasons for the failure. NOTE: To avoid cluttering the output with unreadable spam, --help only shows one of the two switches for each option. If the option is autodetected by default, the --disable-*** switch is printed; if the option is disabled by default, the --enable-*** switch is printed. Either way, you can use --enable-*** or --disable-** regardless of what is printed by --help. To build the software you can use ./waf build: the result of the compilation will be located in build/mpv. You can use ./waf install to install mpv to the prefix after it is compiled. Essential dependencies (incomplete list): gcc or clang X development headers (xlib, X extensions, libvdpau, libGL, libXv, ...) Audio output development headers (libasound/ALSA, pulseaudio) FFmpeg libraries (libavutil libavcodec libavformat libswscale libavfilter and either libswresample or libavresample) At least FFmpeg 2.4.0 or Libav 11 is required. zlib iconv (normally provided by the system libc) libass (OSD, OSC, text subtitles) Lua (optional, required for the OSC pseudo-GUI and youtube-dl integration) libjpeg (optional, used for screenshots only) uchardet (optional, for subtitle charset detection) vdpau and vaapi libraries for hardware decoding on Linux (optional) Libass dependencies: gcc or clang, yasm on x86 and x86_64 fribidi, freetype, fontconfig development headers (for libass) harfbuzz (optional, required for correct rendering of combining characters, particularly for correct rendering of non-English text on OSX, and Arabic/Indic scripts on any platform) FFmpeg dependencies: gcc or clang, yasm on x86 and x86_64 OpenSSL (has to be explicitly enabled when compiling ffmpeg) libx264/libmp3lame/libfdk-aac if you want to use encoding (has to be explicitly enabled when compiling ffmpeg) Libav also works, but some features will not work. (See section below.) Most of the above libraries are available in suitable versions on normal Linux distributions. However FFmpeg is an exception (distro versions may be too old to work at all or work well). For that reason you may want to use the separately available build wrapper (mpv-build) that first compiles FFmpeg libraries and libass, and then compiles the player statically linked against those. If you want to build a Windows binary, you either have to use MSYS2 and MinGW, or cross-compile from Linux with MinGW. See Windows compilation. FFmpeg vs. Libav Generally, mpv should work with the latest release as well as the git version of both FFmpeg and Libav. But FFmpeg is preferred, and some mpv features work with FFmpeg only (subtitle formats in particular). Preferred FFmpeg version Using the latest FFmpeg release (or FFmpeg git master) is strongly recommended. Older versions are unsupported, even if the build system still happens to accept them. The main reason mpv still builds with older FFmpeg versions is to evade arguing with people (users, distros) who insist on using older FFmpeg versions for no rational reason. If you want to use a stable FFmpeg release, use the latest release, which has most likely the best maintenance out of all stable releases. Older releases are for distros, and at best receive basic changes like fixing critical security issues or build fixes, and at worst are completely abandoned. FFmpeg ABI compatibility mpv does not support linking against FFmpeg versions it was not built with, even if the linked version is supposedly ABI-compatible with the version it was compiled against. Expect malfunctions, crashes, and security issues if you do it anyway. The reason for not supporting this is because it creates far too much complexity with little to no benefit, coupled with absurd and unusable FFmpeg API artifacts. Newer mpv versions will refuse to start if runtime and compile time FFmpeg library versions mismatch. Release cycle Every other month, an arbitrary git snapshot is made, and is assigned a 0.X.0 version number. No further maintenance is done. The goal of releases is to make Linux distributions happy. Linux distributions are also expected to apply their own patches in case of bugs and security issues. Releases other than the latest release are unsupported and unmaintained. See the release policy document for more information. Bug reports Please use the issue tracker provided by GitHub to send us bug reports or feature requests. Contributing For small changes you can just send us pull requests through GitHub. For bigger changes come and talk to us on IRC before you start working on them. It will make code review easier for both parties later on. Relation to MPlayer and mplayer2 mpv is based on mplayer2, which in turn is based on the original MPlayer (also called mplayer, mplayer-svn, mplayer1). Many changes have been made, a large part of which is incompatible or completely changes how the player behaves. Although there are still many similarities to its ancestors, mpv should generally be treated as a completely different program. mpv was forked because we wanted to modernize MPlayer. This includes removing cruft (including features which stopped making sense 10 years ago), and of course adding modern features. Such huge and intrusive changes made it infeasible to work directly with MPlayer, which is mostly focused on preservation, so a fork had to be made. (Actually, mpv is based on mplayer2, which already started this process of removing cruft.) In general, mpv should be considered a completely new program, rather than a MPlayer drop-in replacement. If you are wondering what's different from mplayer2 and MPlayer, an incomplete list of changes is located here. Contact Most activity happens on the IRC channel and the github issue tracker. The mailing lists are mostly unused. GitHub issue tracker: issue tracker (report bugs here) User IRC Channel: #mpv on irc.freenode.net Developer IRC Channel: #mpv-devel on irc.freenode.net To contact the mpv team in private write to mpv-team@googlegroups.com. Use only if discretion is required. License Mostly GPLv2 or later. See details. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/mpv-player/mpv"	"A music-playing library. Compile with to not have the music player. or later."	"true"
"Tools"	"cinclude2dot"	"https://www.flourish.org/cinclude2dot/"	"Graphs include dependencies in a C project using Graphviz. Any GNU GPL version (due to underspecification in the file)."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"C/C++ Dependency Graphing C/C++ Depedency Graphing TortoiseCVS This picture was generated from the TortoiseCVS source code on 23 Feb 2002. The arrows represent a dependency by one module of the code on another module. TortoiseCVS.pdf You can inspect a graph and find where there are unnecessary dependencies. This might be because of a forgotten #include, or because there is a straightforward way to rewrite the code without the dependency. This will speed up compile times, and make code more useful to steal for later projects. cinclude2dot.pl This is the Perl script which analyses C/C++ code and produces a #include dependency graph. The output from the script is a dot file for input into graphviz. This is an improved version of the original script, which you can find here. Many thanks to Darxus for creating the original. The new version adds directory clustering, file include path searching and various other features. Both are licensed under the GPL. cinclude2dot (perl script) - Version 1.1 (8.1k) - Generates C/C++ dependency graphs cinclude2dot.1 (man page) - Documentation in Unix man file format (thanks to John Murdie, may be out of date) For usage instructions, run the script with --help. To Francis's page $Id: index.html 691 2005-12-13 02:15:11Z francis $"	"null"	"null"	"Graphs include dependencies in a C project using Graphviz. Any GNU GPL version (due to underspecification in the file)."	"true"
"Tools"	"Complexity"	"https://www.gnu.org/software/complexity/"	"A tool for measuring the complexity of C source code. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"Complexity - Compute a Complexity Measure for C Code Complexity You can find the manual at http://www.gnu.org/software/complexity/manual/. The project source can be found here: http://ftp.gnu.org/gnu/complexity/. Return to GNU's home page. Please send FSF & GNU inquiries & questions to gnu@gnu.org. There are also other ways to contact the FSF. Please send comments on these web pages or this project to bkorb@gnu.org. Copyright (C) 2011 Free Software Foundation, Inc. Verbatim copying and distribution of this entire article is permitted in any medium, provided this notice is preserved. Updated: 7 April 2011 Bruce"	"null"	"null"	"A tool for measuring the complexity of C source code. or later."	"true"
"Tools"	"CScout"	"http://www.spinellis.gr/cscout/"	"a source code analyzer and refactoring browser for collections of C programs. only."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"25"	"4"	"4"	"GitHub - dspinellis/cscout: C code refactoring browser Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 4 Star 25 Fork 4 dspinellis/cscout Code Issues 8 Pull requests 0 Pulse Graphs C code refactoring browser http://www.spinellis.gr/cscout 1,543 commits 2 branches 4 releases Fetching contributors C 71.8% C++ 21.5% Yacc 3.3% Perl 1.0% Shell 0.7% Makefile 0.5% Other 1.2% C C++ Yacc Perl Shell Makefile Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags coverity_scan master Nothing to show R3-0 R2-8 R2-7 R2-6 Nothing to show New pull request Latest commit a257dde Jul 14, 2016 dspinellis Check the return value of system(3) … This eliminates a number of warnings. Permalink Failed to load latest commit information. doc Cleanup directory structure for git-status Apr 7, 2016 example.obf Cleanup directory structure for git-status Apr 7, 2016 example Clarify instructions Jan 29, 2016 include Revert ""Add _Thread_local workaround"" Feb 19, 2016 man Support clang and user-specified compiler names Jul 4, 2016 src Check the return value of system(3) Jul 14, 2016 travis Add install-gcc Travis CI script Feb 20, 2016 web Cleanup directory structure for git-status Apr 7, 2016 .gitignore Cleanup directory structure for git-status Apr 7, 2016 .travis.yml Remove attempty to minimize Coverity runs Apr 7, 2016 LICENSE.txt Incorporate GPL Jun 7, 2015 Makefile Ensure HSQLDB can be installed when absent Jul 14, 2016 README.md Increase flexibiliy regarding use of HSQLDB Jul 14, 2016 README.md CScout is a source code analyzer and refactoring browser for collections of C programs. It can process workspaces of multiple projects (a project is defined as a collection of C source files that are linked together) mapping the complexity introduced by the C preprocessor back into the original C source code files. CScout takes advantage of modern hardware (fast processors and large memory capacities) to analyze C source code beyond the level of detail and accuracy provided by current compilers and linkers. The analysis CScout performs takes into account the identifier scopes introduced by the C preprocessor and the C language proper scopes and namespaces. CScout has already been applied on projects of tens of thousands of lines to millions of lines, like the Linux, OpenSolaris, and FreeBSD kernels, and the Apache web server. For more details, examples, and documentation visit the project's web site. Building, Testing, Installing, Using CScout has been compiled and tested on GNU/Linux (Debian jessie), Apple OS X (El Capitan), FreeBSD (11.0), and Cygwin. In order to build and use CScout you need a Unix (like) system with a modern C++ compiler, GNU make, and Perl. To test CScout you also need to be able to run Java from the command line, in order to use the HSQLDB database. To view CScout's diagrams you must have the GraphViz dot command in your executable file path. To build run make. You can also use the -j make option to increase the build's speed. To build and test, run make test. To install (typically after building and testing), run sudo make install. To see CScout in action run make example. Under FreeBSD use gmake rather than make. Testing requires an installed version of HSQLDB. If this is already installed in your system, specify to make the absolute path of the hsqldb directory, e.g. make HSQLDB_DIR=/usr/local/lib/hsqldb-2.3.3/hsqldb. Otherwise, make will automatically download and unpack a local copy of HSQLDB in the current directory. Contributing You can contribute to any of the open issues or you can open a new one describing what you want to di. For small-scale improvements and fixes simply submit a GitHub pull request. Each pull request should cover only a single feature or bug fix. The changed code should follow the code style of the rest of the program. If you're contributing a feature don't forget to update the documentation. If you're submitting a bug fix, open a corresponding GitHub issue, and refer to the issue in your commit. Avoid gratuitous code changes. Ensure that the tests continue to pass after your change. If you're fixing a bug or adding a feature related to the language, add a corresponding test case. Before embarking on a large-scale contribution, please open a GitHub issue. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/dspinellis/cscout"	"a source code analyzer and refactoring browser for collections of C programs. only."	"true"
"Tools"	"DDD"	"https://www.gnu.org/software/ddd/ddd.html"	"A graphical front-end for a range of command-line debuggers. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"DDD - Data Display Debugger - GNU Project - Free Software Foundation (FSF) GNU Project - Software About DDD DDD News Getting DDD Building DDD Documentation Alpha Releases Reporting Bugs Where can I learn more about the debuggers DDD uses? Help and Assistance References What is DDD? GNU DDD is a graphical front-end for command-line debuggers such as GDB, DBX, WDB, Ladebug, JDB, XDB, the Perl debugger, the bash debugger bashdb, the GNU Make debugger remake, or the Python debugger pydb. Besides ``usual'' front-end features such as viewing source texts, DDD has become famous through its interactive graphical data display, where data structures are displayed as graphs. For more information (and more screenshots), see the DDD Manual. DDD News (2013/01/18) Shaunak Saha is the new maintainer of DDD. (2009/02/11) DDD 3.3.12 is now available from ftp.gnu.org. DDD 3.3.12 features much improved support for debugging Python, Bash and Make, as well as various bug fixes. (2008/11/07) Release candidate 3.3.12-rc1 is available. DDD can now be used effectively to debug Python, Bash and Makefiles. You can grab the new release candidate from alpha.gnu.org. The source tarball is signed with the maintainer's GPG public key, which you can download from Savannah. (2008/10/22) DDD has a bug tracker on Savannah. The bug tracker is the best way to report bugs (use ""Bugs"" on the toolbar, and ""Submit""). You are encouraged to login, but you can post bug anonymously if you want. Posting directly to the bug-ddd mailing list is now deprecated, since the tracker is a much more powerful way to organise the information. Please follow the instructions for bug reporting. (2008/10/19) Jose Maria Gomez Vergara has handed maintainership of DDD to Peter Wainwright. Older News. Where do I get DDD source? DDD can be found at /gnu/ddd/ on ftp.gnu.org, on Savannah or at any GNU FTP mirror near you. The ddd/ directory contains the DDD source distribution: ddd-version.tar.gz -- this package is the one you want. It includes the complete DDD source code, building instructions, as well as the DDD manual in TeXinfo, Info, PostScript, and PDF formats. Here are further instructions on how to download and unpack GNU packages. You can support the principle of software freedom by buying stuff from the FSF shop. Where do I get DDD binaries? The FSF does not distribute DDD binaries. You can ask for help if you need technical support. DDD binaries for GNU/Linux are typically available via your GNU/Linux distributor: DDD packages for Debian GNU/Linux are found here. DDD RPMs can be found in http://rpmfind.net/linux/rpm2html/search.php?query=ddd. The written word provides binaries of freely available software for various platforms. Their FTP server contains DDD and XPM packages. What do I need to build DDD? To build DDD from sources, you need The DDD source distribution (see above). The GNU compiler collection (GCC), version 3.0 or higher (or another ISO C++ compiler). The LessTif user interface toolkit, version 0.89 or higher (or another Motif-compatible user interface toolkit). The simplest way to build and install DDD is: Unpack the DDD source distribution Change into the ddd-version subdirectory Type ./configure && make. If the above doesn't give an error, type make install to install the program. (Depending on your OS and permission level you might need to use sudo make install to install instead.) To run DDD, you need the GNU debugger (GDB), version 4.16 or later (or depending on the program to be debugged, possibly other command-line debuggers such as Ladebug, JDB, XDB, the Perl debugger, the bash debugger bashdb, the GNU Make debugger remake, or the Python debugger pydb.) How do I get started with DDD? The DDD Manual contains a detailed tutorial. Here are some free third-party tutorials on the Web: There's an article on DDD in Dr. Dobb's Journal. Linux Magazin has articles (in German) on debugging with GDB and DDD. LinuxFocus has a DDD tutorial in English, Spanish, German, French, Korean, and Turkish. Where do I get DDD alpha releases? The DDD Subversion repository (containing all versions of DDD, including the very latest changes) is available via http://savannah.gnu.org/projects/ddd. I have found a bug! How do I report it? You can report bugs on the bug tracker. Before you do this, please check the following: Please try to see whether your bug has already been reported. You can browse or search the bug tracker. Please read the section ``Bugs and How to Report Them'' toward the end of the DDD Manual. Be sure to include a copy of your ~/.ddd/log file which tells your DDD configuration as well as the interaction between DDD and the underlying command-line debugger. Remember, the more (relevant) information you put in your bug report, the more likely it is to be fixed rapidly. The purpose of reporting a bug is to enable the bug to be fixed for the sake of the whole community of users. You may or may not receive a response; the maintainers will send one if that helps them find or verify a fix. Most GNU maintainers are volunteers and all are overworked; they don't have time to help individuals and still fix the bugs and make the improvements that everyone wants. If you want help for yourself in particular, you may have to hire someone for technical support. If you are willing to help fixing DDD bugs, you can subscribe to the bug-ddd mailing list or access its archives. I have a question regarding DDD. Where do I get assistance? We have a general-purpose mailing list devoted to DDD. You can ask any questions to ddd at gnu.org. Patches and new releases are also announced here. Subscription info and mailing list archives are available. Owing to abuse by spammers, it is necessary to subscribe before posting to the list. If you need technical support on DDD, you can ask for technical support. Where can I learn more about the debuggers DDD uses? As mentioned above, DDD runs a number of debuggers under the scenes. One can issue commands directly to those debuggers. Below are links for these debuggers: GNU Debugger: gdb Perl Debugger: perl -d Bash Debugger: bashdb Python Debugger: pydb GNU Make Debugger: remake dbx: dbx Ladebug: ladebug (To do: expand the above for more references on each debugger, e.g, tutorials, books, video demos.) Where can I learn more about debugging and debuggers? Here are some other related resources: LessTif or Open Motif. A window library needed to compile DDD. HP Wildebeest (WDB). A port of GDB to PA-RISC/HP-UX, by HP. Insight. A very nice GUI for GDB from Redhat, the GDB maintainers. KDbg. A KDE-based GDB Interface with inspection of variable values in a tree structure. xxgdb. The oldest and simplest X interface for GDB and DBX. tgdb. A Tcl/Tk GDB interface (similar to Turbo Debugger or CodeView). deet. A simple and extensible graphical debugger. A list of available Perl debuggers. The ultimate Perl reference. A GUI for the Perl Debugger. Written in Perl. GNU Nana. Improved support for assertions and logging in C and C++. GNU Checker. A tool to find memory errors at runtime xwpe. A programming environment integrating a program editor with an external debugger. Valgrind. No-one developing C or C++ code under Linux/x86 or Linux/PPC should be without it. Have fun with DDD! Current Maintainer: Shaunak Saha <shaunak at gnu.org> Former Maintainers: Peter Wainwright <peter dot wainwright at ieee dot org> Andreas Zeller <zeller at gnu.org> Andrew Gaylard <apg at users dot sf dot net> Jose María Gómez Vergara <josemaria at jmgv dot org> Return to GNU's home page. Please send FSF & GNU inquiries & questions to gnu at gnu.org. There are also other ways to contact the FSF. Please send comments on these web pages to bug-ddd at gnu.org. Copyright © 2000-2011 Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA Verbatim copying and distribution of this entire article is permitted in any medium, provided this notice is preserved. Updated: $Date: 2013/08/23 08:56:53 $ $Author: shaunak $"	"null"	"null"	"A graphical front-end for a range of command-line debuggers. or later."	"true"
"Tools"	"GDB"	"http://www.gnu.org/software/gdb/"	"The GNU Project debugger; a debugger for C. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"GDB: The GNU Project Debugger GDB: The GNU Project Debugger [bugs] [GDB Maintainers] [contributing] [current git] [documentation] [download] [home] [irc] [links] [mailing lists] [news] [schedule] [song] [wiki] GDB: The GNU Project Debugger What is GDB? GDB, the GNU Project debugger, allows you to see what is going on `inside' another program while it executes -- or what another program was doing at the moment it crashed. GDB can do four main kinds of things (plus other things in support of these) to help you catch bugs in the act: Start your program, specifying anything that might affect its behavior. Make your program stop on specified conditions. Examine what has happened, when your program has stopped. Change things in your program, so you can experiment with correcting the effects of one bug and go on to learn about another. The program being debugged can be written in Ada, C, C++, Objective-C, Pascal (and many other languages). Those programs might be executing on the same machine as GDB (native) or on another machine (remote). GDB can run on most popular UNIX and Microsoft Windows variants. GDB version 7.11.1 Version 7.11.1 of GDB, the GNU Debugger, is now available for download. See the ANNOUNCEMENT for details including changes in this release. An errata list (PROBLEMS) and documentation are also available. News May 31st, 2016: GDB 7.11.1 Released! The latest version of GDB, version 7.11.1, is available for download. This is a minor corrective release over GDB 7.11, fixing the following issues: PR remote/19863 (7.10 regression: gdb remote.c due to ""setfs"" with gdbserver < 7.7) PR gdb/19829 (gdb crashes with PT and reverse next) PR gdb/19676 (gdb fails with assert error if /proc is not mounted) PR gdb/19828 (7.11 regression: non-stop gdb -p : internal error) PR remote/19840 (gdb crashes on reverse-stepi) PR gdb/19858 (GDB doesn't register the JIT libraries on attach) PR gdb/19958 (Breakpoints/watchpoints broken on MIPS Linux <= 4.5) PR build/20029 (symfile.c ambiguous else warning) PR python/20037 (GDB use-after-free error) PR gdb/20039 (Using MI/all-stop, can't interrupt multi-threaded program after continue) February 24th, 2016: GDB 7.11 Released! The latest version of GDB, version 7.11, is available for download. Changes in this release include: Per-inferior thread numbers. Breakpoint ""explicit locations"" (via CLI and GDB/MI). New convenience variables ($_gthread, $_inferior). Record btrace now supports non-stop mode. Various improvements on AArch64 GNU/Linux: Multi-architecture debugging support. displaced stepping. tracepoint support added in GDBserver. kernel-based threads support on FreeBSD. Support for reading/writing memory and extracting values on architectures whose memory is addressable in units of any integral multiple of 8 bits. In Ada, the overloads selection menu provides the parameter types and return types for the matching overloaded subprograms. Various remote protocol improvements, including several new packets which can be used to support features such as follow-exec-mode, exec catchpoints, syscall catchpoints, etc. Some minor improvements in the Python API for extending GDB. Support for various ROM monitors has been removed: target dbug dBUG ROM monitor for Motorola ColdFire target picobug Motorola picobug monitor target dink32 DINK32 ROM monitor for PowerPC target m32r Renesas M32R/D ROM monitor target mon2000 mon2000 ROM monitor target ppcbug PPCBUG ROM monitor for PowerPC See the NEWS file for a more complete and detailed list of what this release includes. Feb 10th, 2016: GDB 7.11 branch created The GDB 7.11 branch (gdb-7.11-branch) has been created. To check out a copy of the branch use:  git clone --branch gdb-7.11-branch ssh://sourceware.org/git/binutils-gdb.git  September 30, 2011: Release Mistakes in GDB Versions 6.0 - 7.3 A mistake has been detected in the release tar files for all GDB releases from version 6.0 to version 7.3 (included). The mistake has been corrected, and the FSF issued the following announcements: Making up for a release mistake in GDB versions 6.0 - 6.6 Making up for a release mistake in GDB versions 6.7 - 7.3 Nov 28, 2006: Reversible Debugging The GDB maintainers are looking for contributors interested in reversible debugging. Late breaking information, such as recently added features, can be found in the NEWS file in the gdb source tree. Old announcements are in the news archive. [bugs] [GDB Maintainers] [contributing] [current git] [documentation] [download] [home] [irc] [links] [mailing lists] [news] [schedule] [song] [wiki] Please send FSF & GNU inquiries & questions to gnu@gnu.org. There are also other ways to contact the FSF. This page is maintained by the GDB developers. Copyright Free Software Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA. Verbatim copying and distribution of this entire article is permitted in any medium, provided this notice is preserved. Last modified 2016-05-31."	"null"	"null"	"The GNU Project debugger; a debugger for C. or later."	"true"
"Tools"	"Glade"	"https://glade.gnome.org/"	"A RAD tool to enable quick development of GTK+ GUIs. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"null"	"null"	"null"	"Glade - A User Interface Designer Glade - A User Interface Designer Current Version: 3.20 Download Sources Browse Sources Windows Binaries Older MacOSX Binaries User Survey Preliminary results Documentation Tutorials API Reference Help Users mailing list File a bug Development Developers mailing list Bug list Roadmap Wiki IRC server: irc.gimp.net channel: #glade3 Related tools Anjuta IDE Nemiver Debugger Devhelp API browser Parasite What is Glade? Glade is a RAD tool to enable quick & easy development of user interfaces for the GTK+ toolkit and the GNOME desktop environment. The user interfaces designed in Glade are saved as XML, and by using the GtkBuilder GTK+ object these can be loaded by applications dynamically as needed. By using GtkBuilder, Glade XML files can be used in numerous programming languages including C, C++, C#, Vala, Java, Perl, Python,and others. Glade is Free Software released under the GNU GPL License Latest news Old stories Glade 3.20.0 released Tuesday 22 March 2016 by Juan Pablo Ugarte Glade 3.20.0 is now available for download. Glade 3.20.0 is the new stable release for GNOME 3.20. Glade User Survey results Monday 08 February 2016 by Juan Pablo Ugarte Preliminary results are available in my blog Glade 3.19.0 released Thursday 11 June 2015 by Juan Pablo Ugarte Glade 3.19.0 is now available for download. Glade 3.19.0 is the first development release in the series. 3.19.0 release notes for more details. Glade 3.18.3 released Monday 14 April 2014 by Juan Pablo Ugarte Glade 3.18.3 is now available for download. Glade 3.18.3 is the third bug fix release in the series. See 3.18.3 release notes for more details. Glade 3.8.5 released Monday 12 May 2014 by Juan Pablo Ugarte Glade 3.8.5 is now available for download. It is the fifth bug fix release in the series. See 3.8.5 release notes for more details. Copyright 2014, The Glade project"	"null"	"null"	"A RAD tool to enable quick development of GTK+ GUIs. only."	"true"
"Tools"	"GMSL"	"http://gmsl.sourceforge.net/"	"GNU Make Standard Library; a collection of additional functionality for GNU Make.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"null"	"null"	"null"	"GNU Make Standard Library GNU Make Standard Library The GNU Make Standard Library (GMSL) is a collection of functions implemented using native GNU Make functionality that provide list and string manipulation, integer arithmetic, associative arrays, stacks, and debugging facilities.  The GMSL is released under the BSD License. [Project Page] [Download] [Discussion Forum] Using GMSL The two files needed are gmsl and __gmsl.  To include the GMSL in your Makefile do include gmsl gmsl automatically includes __gmsl.  To check that you have the right version of gmsl use the gmsl_compatible function (see below). The current version is 1 1 7. The GMSL package also includes a test suite for GMSL.  Just run make -f gmsl-tests. Logical OperatorsGMSL has boolean $(true) (a non-empty string) and $(false) (an empty string).  The following operators can be used with those variables. not Arguments: A boolean value Returns:   Returns $(true) if the boolean is $(false) and vice versa and Arguments: Two boolean values Returns:   Returns $(true) if both of the booleans are true or Arguments: Two boolean values Returns:   Returns $(true) if either of the booleans is true xor Arguments: Two boolean values Returns:   Returns $(true) if exactly one of the booleans is true nand Arguments: Two boolean values Returns:   Returns value of 'not and' nor Arguments: Two boolean values Returns:   Returns value of 'not or' xnor Arguments: Two boolean values Returns:   Returns value of 'not xor' List Manipulation Functions  A list is a string of characters; the list separator is a space. first Arguments: 1: A list Returns:   Returns the first element of a list last Arguments: 1: A list Returns:   Returns the last element of a list rest Arguments: 1: A list Returns:   Returns the list with the first element removed chop Arguments: 1: A list Returns:   Returns the list with the last element removed map Arguments: 1: Name of function to $(call) for each element of list            2: List to iterate over calling the function in 1 Returns:   The list after calling the function on each element pairmap Arguments: 1: Name of function to $(call) for each pair of elements            2: List to iterate over calling the function in 1            3: Second list to iterate over calling the function in 1 Returns:   The list after calling the function on each pair of elements leq Arguments: 1: A list to compare against...            2: ...this list Returns:   Returns $(true) if the two lists are identical lne Arguments: 1: A list to compare against...            2: ...this list Returns:   Returns $(true) if the two lists are different reverse Arguments: 1: A list to reverse Returns:   The list with its elements in reverse order uniq Arguments: 1: A list to deduplicate Returns:   The list with elements in order without duplicates length Arguments: 1: A list Returns:   The number of elements in the list String Manipulation Functions A string is any sequence of characters. seq Arguments: 1: A string to compare against...            2: ...this string Returns:   Returns $(true) if the two strings are identical sne Arguments: 1: A string to compare against...            2: ...this string Returns:   Returns $(true) if the two strings are not the same strlen Arguments: 1: A string Returns:   Returns the length of the string substr Arguments: 1: A string            2: Start offset (first character is 1)            3: Ending offset (inclusive) Returns:   Returns a substring split Arguments: 1: The character to split on            2: A string to split Returns:   Splits a string into a list separated by spaces at the split            character in the first argument merge Arguments: 1: The character to put between fields            2: A list to merge into a string Returns:   Merges a list into a single string, list elements are separated            by the character in the first argument tr Arguments: 1: The list of characters to translate from            2: The list of characters to translate to            3: The text to translate Returns:   Returns the text after translating characters uc Arguments: 1: Text to upper case Returns:   Returns the text in upper case lc Arguments: 1: Text to lower case Returns:   Returns the text in lower case Set Manipulation Functions Sets are represented by sorted, deduplicated lists. To create a set from a list use set_create, or start with the empty_set and set_insert individual elements. The empty set is defined as empty_set. set_create Arguments: 1: A list of set elements Returns:   Returns the newly created set set_insert Arguments: 1: A single element to add to a set            2: A set Returns:   Returns the set with the element added set_remove Arguments: 1: A single element to remove from a set            2: A set Returns:   Returns the set with the element removed set_is_member Arguments: 1: A single element            2: A set Returns:   Returns $(true) if the element is in the set set_is_not_member Arguments: 1: A single element            2: A set Returns:   Returns $(false) if the element is in the set set_union Arguments: 1: A set            2: Another set Returns:   Returns the union of the two sets set_intersection Arguments: 1: A set            2: Another set Returns:   Returns the intersection of the two sets set_is_subset Arguments: 1: A set            2: Another set Returns:   Returns $(true) if the first set is a subset of the second set_equal Arguments: 1: A set            2: Another set Returns:   Returns $(true) if the two sets are identical Integer Arithmetic Functions Integers are represented by lists with the equivalent number of x's.  For example the number 4 is x x x x.  The maximum integer that the library can handle as input (i.e. as the argument to a call to int_encode) is 65536. There is no limit on integer size for internal computations or output. The arithmetic library functions come in two forms: one form of each function takes integers as arguments and the other form takes the encoded form (x's created by a call to int_encode).  For example, there are two plus functions: plus (called with integer arguments and returns an integer) and int_plus (called with encoded arguments and returns an encoded result). plus will be slower than int_plus because its arguments and result have to be translated between the x's format and integers.  If doing a complex calculation use the int_* forms with a single encoding of inputs and single decoding of the output.  For simple calculations the direct forms can be used. int_decode Arguments: 1: A number of x's representation Returns:   Returns the integer for human consumption that is represented            by the string of x's int_encode Arguments: 1: A number in human-readable integer form Returns:   Returns the integer encoded as a string of x's int_plus Arguments: 1: A number in x's representation            2: Another number in x's represntation Returns:   Returns the sum of the two numbers in x's representation plus (wrapped version of int_plus) Arguments: 1: An integer            2: Another integer Returns:   Returns the sum of the two integers int_subtract Arguments: 1: A number in x's representation            2: Another number in x's represntation Returns:   Returns the difference of the two numbers in x's representation,            or outputs an error on a numeric underflow subtract (wrapped version of int_subtract) Arguments: 1: An integer            2: Another integer Returns:   Returns the difference of the two integers,            or outputs an error on a numeric underflow int_multiply Arguments: 1: A number in x's representation            2: Another number in x's represntation Returns:   Returns the product of the two numbers in x's representation multiply (wrapped version of int_multiply) Arguments: 1: An integer            2: Another integer Returns:   Returns the product of the two integers int_divide Arguments: 1: A number in x's representation            2: Another number in x's represntation Returns:   Returns the result of integer division of argument 1 divided            by argument 2 in x's representation divide (wrapped version of int_divide) Arguments: 1: An integer            2: Another integer Returns:   Returns the integer division of the first argument by the second int_max, int_min Arguments: 1: A number in x's representation            2: Another number in x's represntation Returns:   Returns the maximum or minimum of its arguments in x's            representation max, min Arguments: 1: An integer            2: Another integer Returns:   Returns the maximum or minimum of its integer arguments int_gt, int_gte, int_lt, int_lte, int_eq, int_ne Arguments: Two x's representation numbers to be compared Returns:   $(true) or $(false) int_gt First argument greater than second argument int_gte First argument greater than or equal to second argument int_lt First argument less than second argument int_lte First argument less than or equal to second argument int_eq First argument is numerically equal to the second argument int_ne First argument is not numerically equal to the second argument gt, gte, lt, lte, eq, ne Arguments: Two integers to be compared Returns:   $(true) or $(false) gt First argument greater than second argument gte First argument greater than or equal to second argument lt First argument less than second argument lte First argument less than or equal to second argument eq First argument is numerically equal to the second argument ne First argument is not numerically equal to the second argument increment adds 1 to its argument, decrement subtracts 1. Note that decrement does not range check and hence will not underflow, but will incorrectly say that 0 - 1 = 0 int_inc Arguments: 1: A number in x's representation Returns:   The number incremented by 1 in x's representation inc Arguments: 1: An integer Returns:   The argument incremented by 1 int_dec Arguments: 1: A number in x's representation Returns:   The number decremented by 1 in x's representation dec Arguments: 1: An integer Returns:   The argument decremented by 1 int_double Arguments: 1: A number in x's representation Returns:   The number doubled (i.e. * 2) and returned in x's representation double Arguments: 1: An integer Returns:   The integer times 2 int_halve Arguments: 1: A number in x's representation Returns:   The number halved (i.e. / 2) and returned in x's representation halve Arguments: 1: An integer Returns:   The integer divided by 2 sequence Arguments: 1: An integer            2: An integer Returns:   The sequence [arg1 arg2] if arg1 >= arg2 or [arg2 arg1] if arg2 > arg1 dec2hex, dec2bin, dec2oct Arguments: 1: An integer Returns:   The decimal argument converted to hexadecimal, binary or octal Associative Arrays An associate array maps a key value (a string with no spaces in it) to a single value (any string).    set Arguments: 1: Name of associative array            2: The key value to associate            3: The value associated with the key Returns:   Nothing get Arguments: 1: Name of associative array            2: The key to retrieve Returns:   The value stored in the array for that key keys Arguments: 1: Name of associative array Returns:   Returns a list of all defined keys in the array defined Arguments: 1: Name of associative array            2: The key to test Returns:   Returns true if the key is defined (i.e. not empty) Named Stacks A stack is an ordered list of strings (with no spaces in them). push Arguments: 1: Name of stack            2: Value to push onto the top of the stack (must not contain            a space) Returns:   None pop Arguments: 1: Name of stack Returns:   Top element from the stack after removing it peek Arguments: 1: Name of stack Returns:   Top element from the stack without removing it depth Arguments: 1: Name of stack Returns:   Number of items on the stack Function memoization To reduce the number of calls to slow functions (such as $(shell) a single memoization function is provided. memoize Arguments: 1: Name of function to memoize            2: String argument for the function Returns:   Result of $1 applied to $2 but only calls $1 once for each unique $2 Miscellaneous and Debugging Facilities GMSL defines the following constants; all are accessed as normal GNU Make variables by wrapping them in $() or ${}. Constant Value Purpose true T Boolean for $(if) and return from  GMSL functions false Boolean for $(if) and return from GMSL functions gmsl_version 1 0 0 GMSL version number as list: major minor revision gmsl_compatible Arguments: List containing the desired library version number (maj min rev) Returns:   $(true) if this version of the library is compatible            with the requested version number, otherwise $(false) gmsl-print-% (target not a function) Arguments: The % should be replaced by the name of a variable that you            wish to print out. Action:    Echos the name of the variable that matches the % and its value.            For example, 'make gmsl-print-SHELL' will output the value of            the SHELL variable assert Arguments: 1: A boolean that must be true or the assertion will fail            2: The message to print with the assertion Returns:   None assert_exists Arguments: 1: Name of file that must exist, if it is missing an assertion            will be generated Returns:   None GMSL has a number of environment variables (or command-line overrides) that control various bits of functionality: Variable Purpose GMSL_NO_WARNINGS If set prevents GMSL from outputting warning messages: artithmetic functions generate underflow warnings. GMSL_NO_ERRORS If set prevents GMSL from generating fatal errors: division by zero or failed assertions are fatal. GMSL_TRACE Enables function tracing.  Calls to GMSL functions will result in name and arguments being traced. Copyright (c) 2005-2014 John Graham-Cumming. John Graham-Cumming's work on this project was sponsored by Electric Cloud, Inc."	"null"	"null"	"GNU Make Standard Library; a collection of additional functionality for GNU Make.."	"true"
"Tools"	"GNU Global"	"https://www.gnu.org/software/global/"	"A source code tagging tool which works with C. only."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"GNU GLOBAL source code tagging system GNU Project - GLOBAL / Savannah - GLOBAL Top page What's new Tutorial License Links Plans Known bugs Contribution Mailing lists Download Donation GNU GLOBAL source code tagging system Copyright (c) 2000-2015 Tama Communications Corporation GNU GLOBAL is a source code tagging system that works the same way across diverse environments, such as Emacs editor, Vi editor, Less viewer, Bash shell, various web browsers, etc. You can locate various objects, such as functions, macros, structs, classes, in your source files and move there easily. It is useful for hacking a large projects which contain many sub-directories, many #ifdef and many main() functions. It is similar to ctags or etags, but is different from them in the following two points: independence of any editor capability to treat definition and reference It runs in UNIX (POSIX) compatible operating system, like GNU and BSD. GNU GLOBAL is part of the GNU project, and is free software. You can freely copy, modify and redistribute this program under GNU GPL. GNU GLOBAL has the following features: supports 6 languages by built-in parser. (definition and reference) C, C++, Yacc, Java, PHP4 and assembly. supports 25 languages by Pygments + Exuberant Ctags plug-in parser. (definition and reference) Awk, Dos batch, COBOL, C, C++, C#, Erlang, Fortran, Java, JavaScript, Lisp, Lua, Pascal, Perl, PHP, Python, Ruby, Matlab, OCaml, Scheme, Tcl, TeX, Verilog, Vhdl and Vim. To use the parser, please see the file 'plugin-factory/PLUGIN_HOWTO.pygments' in the package. works the same way across diverse environments like follows: Shell command line Bash shell Vi editor (Nvi, Elvis, vim) Less viewer Emacs editor (Emacs, Mule, Xemacs) Web browser (See UNIX kernel source tour!.) Doxygen documentation system finds locations of specified symbol quickly. locate not only definitions but also references. allows duplicate tags. locate paths which matches to the specified pattern. hierarchical searches by default. searches not only in a source project but also in library projects. generates completion list for completing input method. supports various output formats. allows customizing of the set of candidate files to be tagged. understands POSIX 1003.2 regular expression. supports idutils as an external search engine. tag files are independent of machine architecture. supports incremental updating of tag files. plug-in parser is available to treat new language. supports customizing with gtags.conf. generates a hypertext of source code. compact format to save disk space. supports client/server environment (TRAMP ready). ignores binary files, dot files and specified files. includes cscope-compatible program (gtags-cscope). includes grep-like command (-g command). deals with loop of symbolic links well. Please also see 'Comparison with Similar Tools' in the OpenGrok project site for comparison with other tools. If you have a plan to make a yet another editor with tag facility, you can use GLOBAL for it. May the GLOBAL be under you like the globe! [Top of page] Copyright (c) 2000-2015 Tama Communications Corporation Permission is granted to copy, distribute and/or modify this document under the terms of the GNU Free Documentation License, Version 1.2"	"null"	"null"	"A source code tagging tool which works with C. only."	"true"
"Tools"	"gprof"	"http://www.gnu.org/software/binutils/"	"A performance analysis tool. Part of GNU binutils. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"GNU Binutils GNU Binutils The GNU Binutils are a collection of binary tools. The main ones are: ld - the GNU linker. as - the GNU assembler. But they also include: addr2line - Converts addresses into filenames and line numbers. ar - A utility for creating, modifying and extracting from archives. c++filt - Filter to demangle encoded C++ symbols. dlltool - Creates files for building and using DLLs. gold - A new, faster, ELF only linker, still in beta test. gprof - Displays profiling information. nlmconv - Converts object code into an NLM. nm - Lists symbols from object files. objcopy - Copies and translates object files. objdump - Displays information from object files. ranlib - Generates an index to the contents of an archive. readelf - Displays information from any ELF format object file. size - Lists the section sizes of an object or archive file. strings - Lists printable strings from files. strip - Discards symbols. windmc - A Windows compatible message compiler. windres - A compiler for Windows resource files. Most of these programs use BFD, the Binary File Descriptor library, to do low-level manipulation. Many of them also use the opcodes library to assemble and disassemble machine instructions. The binutils have been ported to most major Unix variants as well as Wintel systems, and their main reason for existence is to give the GNU system (and GNU/Linux) the facility to compile and link programs. Obtaining binutils The latest release of GNU binutils is 2.26. The various NEWS files (binutils, gas, and ld) have details of what has changed in this release. See the SOFTWARE page for information on obtaining releases of GNU binutils and other GNU software. The current release can be downloaded from http://ftp.gnu.org/gnu/binutils If you plan to do active work on GNU binutils, you can access the development source tree by anonymous git:    git clone git://sourceware.org/git/binutils-gdb.git   Alternatively, you can use the gitweb interface, or the source snapshots, available as bzipped tar files via anonymous FTP from ftp://sourceware.org/pub/binutils/snapshots. Bug reports There is a bug-tracking system at http://sourceware.org/bugzilla/. Mailing lists There are three binutils mailing lists: bug-binutils@gnu.org (archives) For reporting bugs. binutils@sourceware.org (archives) For discussing binutils issues. binutils-cvs (archives) A read-only mailing list containing the notes from checkins to the binutils git repository. (This list has an odd name for historical reasons.) You can use this form to subscribe to the binutils@sourceware.org or binutils-cvs@sourceware.org mailing lists: Mailing list: binutils binutils-cvs Your e-mail address: Digest version? subscribe unsubscribe To subscribe to the bug-binutils@gnu.org mailing list, see the bug-binutils info page. You may wish to browse the old mail archives of the gas2 and bfd mailing lists. These were the discussion lists for binutils until May 1999. Please do not send mail to them any longer. Documentation The documentation for binutils 2.26 is available. A guide to porting the binutils to a new target has been contributed. Return to GNU's home page. Please send FSF & GNU inquiries & questions to gnu@gnu.org. There are also other ways to contact the FSF. Please send comments on these web pages to binutils@sourceware.org, send other questions to gnu@gnu.org. Copyright (C) 1998, 2000-2014 Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA Verbatim copying and distribution of this entire article is permitted in any medium, provided this notice is preserved. Updated: Last modified: Mon Sep 23 08:45:03 BST 2014"	"null"	"null"	"A performance analysis tool. Part of GNU binutils. or later."	"true"
"Tools"	"Highlight"	"http://www.andre-simon.de/index.php"	"Converts source code to formatted text with nice highlighting. only."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"André Simon - Startseite text processing utilities Index Highlight Ansifilter MikroLock Downloads Hi! Welcome to my dark si[d|t]e. It offers some software for developers, administrators and the others. The highlight logo is based on the image Alcedo Atthis by Lukasz Lukasik. The original was published in Wikimedia Commons under the terms of the GNU FDL license. Bei der Erstellung dieser Inhalte entstandene Aggressionen wurden sozialverträglich abgebaut. Highlight 3.30 Highlight converts source code to formatted text with syntax highlighting. Coloured output in HTML, XHTML, RTF, ODT, TeX, LaTeX, SVG and BBCode format Supports 200 programming languages Includes 80 colour themes Syntax elements are defined as regular expressions or plain string lists Customizable keyword groups Recognition of nested languages Reformatting and indentation of C, C++, C# and Java source code Language definitions and themes are Lua scripts Plug-In interface to tweak the output CLI, GUI and Lib builds available Platform independent Manual ][ Wiki ][ Screenshots ][ ChangeLog ][ Download Deutsche Dokumentation Ansifilter 1.18 Ansifilter handles text files containing ANSI terminal escape codes. Command sequences may be stripped or interpreted Coloured output in HTML, LaTeX, TeX, RTF and BBCode format Enables ""tail -f"" functionality on Windows CLI and GUI builds available Platform independent Manual with screenshots ][ ChangeLog ][ Download Deutsche Dokumentation MikroLock 1.1 MikroLock reads and writes encrypted miniLock files. No cumbersome key exchange Easy handling - no nerd assistance required Compatible to original Chrome plugin (minilock.io) ...but can also handle big files Uses Scrypt or Argon2 for key derivation, XSalsa20 for encryption, Blake2 for verification CLI, GUI and Lib builds available Platform independent Manual ][ Screenshots ][ ChangeLog ][ Download Deutsche Dokumentation Stand: 01.07.2016 ][ Impressum & Kontakt ][ Webmaster"	"null"	"null"	"Converts source code to formatted text with nice highlighting. only."	"true"
"Tools"	"include-what-you-use"	"https://github.com/include-what-you-use/include-what-you-use"	"Helps find unecessary inclusions and make suggestions for fixing them. Based on LLVM/Clang (and only works with it).."	"null"	"null"	"null"	"NCSA"	"http://directory.fsf.org/wiki/License:IllinoisNCSA"	"null"	"null"	"487"	"25"	"40"	"GitHub - include-what-you-use/include-what-you-use: A tool for use with clang to analyze #includes in C and C++ source files Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 25 Star 487 Fork 40 include-what-you-use/include-what-you-use Code Issues 90 Pull requests 7 Pulse Graphs A tool for use with clang to analyze #includes in C and C++ source files http://include-what-you-use.org 612 commits 7 branches 8 releases Fetching contributors C++ 78.3% Python 17.8% C 3.4% Other 0.5% C++ Python C Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags clang_3.2 clang_3.4 clang_3.5 clang_3.6 clang_3.7 clang_3.8 master Nothing to show clang_3.8 clang_3.7 clang_3.6 clang_3.5 clang_3.4 clang_3.3 clang_3.2 clang_3.0 Nothing to show New pull request Latest commit 5b61a55 Jun 12, 2016 kimgr Fix #310: Replace Each with C++11 range for loops … The Each construct was nice, but it's outlived its usefulness, the range for loops are both easier to read and write.  For iteration over maps, we consistently use 'auto' to avoid repeating the map value type. Permalink Failed to load latest commit information. docs They're #include directives, not statements Feb 13, 2016 more_tests Fixed file heading comments not matching the filename (issue #83). Pa… Nov 25, 2012 tests Use absolute paths to build include names Jun 8, 2016 .clang-format Unix line endings for .clang-format Mar 1, 2016 CMakeLists.txt Update CMake minimum required version to 3.4.3 to sync with LLVM+Clang. Jul 3, 2016 LICENSE.TXT Clean up third-party license listing Nov 11, 2015 README.md Remove Makefile as it's not supported by LLVM+Clang. Feb 6, 2016 boost-all-private.imp Collect Boost and Qt mappings created by Scott Howard aka @maqifrnswa. Sep 9, 2015 boost-all.imp Collect Boost and Qt mappings created by Scott Howard aka @maqifrnswa. Sep 10, 2015 dist.sh Add shebang line and specify error handling options in dist.sh script. Oct 20, 2013 fix_includes.py Fix #280: unified diff output Mar 15, 2016 fix_includes_test.py Fix #280: unified diff output Mar 15, 2016 gcc.libc.imp Add more libc mapping(s). Feb 1, 2016 gcc.stl.headers.imp Fix issue #88: GCC header map lists some private headers as public Feb 18, 2013 gcc.symbols.imp Allow size_t from multiple headers. Jun 24, 2015 iwyu.cc Fix #310: Replace Each with C++11 range for loops Jul 11, 2016 iwyu.gcc.imp Specify public STL headers explicitly (issue #132). Sep 28, 2014 iwyu_ast_util.cc Fix #310: Replace Each with C++11 range for loops Jul 11, 2016 iwyu_ast_util.h Fix some Clang-tidy warnings Jun 7, 2016 iwyu_cache.cc Handle precomputed template arguments in libc++ like in libstdc++ (is… Sep 7, 2014 iwyu_cache.h Make header guards consistent May 25, 2016 iwyu_driver.cc Fix some Clang-tidy warnings Jun 7, 2016 iwyu_driver.h Make header guards consistent May 25, 2016 iwyu_getopt.cc Added getopt_long for Windows (resolves issue #52). Aug 11, 2012 iwyu_getopt.h Make header guards consistent May 25, 2016 iwyu_globals.cc Fix #310: Replace Each with C++11 range for loops Jul 11, 2016 iwyu_globals.h Make header guards consistent May 25, 2016 iwyu_include_picker.cc Fix #310: Replace Each with C++11 range for loops Jul 11, 2016 iwyu_include_picker.h Use absolute paths to build include names Jun 8, 2016 iwyu_lexer_utils.cc Fix some Clang-tidy warnings Jun 18, 2016 iwyu_lexer_utils.h Fix some Clang-tidy warnings Jun 18, 2016 iwyu_location_util.cc Fix some Clang-tidy warnings Jun 7, 2016 iwyu_location_util.h Fix some Clang-tidy warnings Jun 7, 2016 iwyu_output.cc Fix #310: Replace Each with C++11 range for loops Jul 11, 2016 iwyu_output.h Fix #310: Replace Each with C++11 range for loops Jul 11, 2016 iwyu_path_util.cc Fix #310: Replace Each with C++11 range for loops Jul 11, 2016 iwyu_path_util.h Use absolute paths to build include names Jun 8, 2016 iwyu_preprocessor.cc Fix #310: Replace Each with C++11 range for loops Jul 11, 2016 iwyu_preprocessor.h Fix Clang-tidy modernize warnings Jun 7, 2016 iwyu_stl_util.h Fix #310: Replace Each with C++11 range for loops Jul 11, 2016 iwyu_string_util.h Fix some Clang-tidy warnings Jun 7, 2016 iwyu_test_util.py Fix in tests ""fatal error: file not found"", make test suite detect su… Jun 8, 2016 iwyu_tool.py Use realpath instead of abspath Jul 10, 2016 iwyu_verrs.cc Fixed file heading comments not matching the filename (issue #83). Pa… Nov 25, 2012 iwyu_verrs.h Make header guards consistent May 25, 2016 iwyu_version.h Make header guards consistent May 25, 2016 make_readme.py Rewrite relative links so they can be followed on GitHub. Sep 2, 2015 port.h Explicitly use ASCII version of PathMatchSpec Jul 10, 2016 qt4.imp Collect Boost and Qt mappings created by Scott Howard aka @maqifrnswa. Sep 10, 2015 qt5_4.imp Mappings for qt5.4 Jan 2, 2016 run_iwyu_tests.py Fix in tests ""fatal error: file not found"", make test suite detect su… Jun 9, 2016 stl.c.headers.imp Specify public STL headers explicitly (issue #132). Sep 28, 2014 third_party.imp Read private to public mappings from external file. Patch by Kim Gräs… Oct 14, 2012 README.md Include What You Use This README was generated on 2016-02-01 00:55:37 UTC. For more in-depth documentation, see http://github.com/include-what-you-use/include-what-you-use/tree/master/docs. Instructions for Users ""Include what you use"" means this: for every symbol (type, function, variable, or macro) that you use in foo.cc (or foo.cpp), either foo.cc or foo.h should include a .h file that exports the declaration of that symbol. (Similarly, for foo_test.cc, either foo_test.cc or foo.h should do the including.) Obviously symbols defined in foo.cc itself are excluded from this requirement. This puts us in a state where every file includes the headers it needs to declare the symbols that it uses. When every file includes what it uses, then it is possible to edit any file and remove unused headers, without fear of accidentally breaking the upwards dependencies of that file. It also becomes easy to automatically track and update dependencies in the source code. CAVEAT This is alpha quality software -- at best (as of February 2011). It was written to work specifically in the Google source tree, and may make assumptions, or have gaps, that are immediately and embarrassingly evident in other types of code. For instance, we only run this on C++ code, not C or Objective C. Even for Google code, the tool still makes a lot of mistakes. While we work to get IWYU quality up, we will be stinting new features, and will prioritize reported bugs along with the many existing, known bugs. The best chance of getting a problem fixed is to submit a patch that fixes it (along with a unittest case that verifies the fix)! How to Build Include-what-you-use makes heavy use of Clang internals, and will occasionally break when Clang is updated. Usually such discrepancies are detected by build bot and fixed promptly. We support two build configurations: out-of-tree and in-tree. Building out-of-tree In an out-of-tree configuration, we assume you already have compiled LLVM and Clang headers and libs somewhere on your filesystem, such as via the libclang-dev package. Create a directory for IWYU development, e.g. iwyu-trunk Clone the IWYU Git repo: iwyu-trunk$ git clone https://github.com/include-what-you-use/include-what-you-use.git  Presumably, you'll be building IWYU with a released version of LLVM and Clang, so check out the corresponding branch. For example if you have Clang 3.2 installed, use the clang_3.2 branch. IWYU master tracks LLVM & Clang trunk: iwyu-trunk$ cd include-what-you-use iwyu-trunk/include-what-you-use$ git checkout clang_3.2 iwyu-trunk/include-what-you-use$ cd ..  Create a build root and use CMake to generate a build system linked with LLVM/Clang prebuilts, e.g. # This example uses the Makefile generator, but anything should work. iwyu-trunk$ mkdir build && cd build iwyu-trunk/build$ cmake -G ""Unix Makefiles"" -DIWYU_LLVM_ROOT_PATH=/usr/lib/llvm-3.4 ../include-what-you-use  Once CMake has generated a build system, you can invoke it directly from build, e.g. iwyu-trunk/build$ make  This configuration is more useful if you want to get IWYU up and running quickly without building Clang and LLVM from scratch. Building in-tree You will need the Clang and LLVM trees on your system, such as by checking out their SVN trees (but don't configure or build before you've done the following.) Clone the IWYU Git repo into the Clang source tree: llvm/tools/clang/tools$ git clone https://github.com/include-what-you-use/include-what-you-use.git  Edit tools/clang/tools/CMakeLists.txt and put in add_subdirectory(include-what-you-use) Once this is done, IWYU is recognized and picked up by CMake workflow as described in the Clang Getting Started guide This configuration is more useful if you're actively developing IWYU against Clang trunk. It's easier to set up correctly, but it requires that you build all of LLVM and Clang. How to Install If you're building IWYU out-of-tree or installing pre-built binaries, you need to make sure it can find Clang built-in headers (stdarg.h and friends.) Clang's default policy is to look in path/to/clang-executable/../lib/clang/<clang ver>/include. So if Clang 3.5.0 is installed in /usr/bin, it will search for built-ins in /usr/lib/clang/3.5.0/include. Clang tools have the same policy by default, so in order for IWYU to analyze any non-trivial code, it needs to find Clang's built-ins in path/to/iwyu/../lib/clang/3.5.0/include where 3.5.0 is a stand-in for the version of Clang your IWYU was built against. So for IWYU to function correctly, you need to copy in the Clang headers at a good location before running. This weirdness is tracked in issue 100, hopefully we can make this more transparent over time. How to Run The easiest way to run IWYU over your codebase is to run   make -k CXX=/path/to/llvm/Debug+Asserts/bin/include-what-you-use  or   make -k CXX=/path/to/llvm/Release/bin/include-what-you-use  (include-what-you-use always exits with an error code, so the build system knows it didn't build a .o file. Hence the need for -k.) Include-what-you-use only analyzes .cc (or .cpp) files built by make, along with their corresponding .h files. If your project has a .h file with no corresponding .cc file, IWYU will ignore it unless you use the --check_also switch to add it for analysis together with a .cc file. We also include, in this directory, a tool that automatically fixes up your source files based on the IWYU recommendations. This is also alpha-quality software! Here's how to use it (requires python):   make -k CXX=/path/to/llvm/Debug+Asserts/bin/include-what-you-use > /tmp/iwyu.out   python fix_includes.py < /tmp/iwyu.out  If you don't like the way fix_includes.py munges your #include lines, you can control its behavior via flags. fix_includes.py --help will give a full list, but these are some common ones: -b: Put blank lines between system and Google includes --nocomments: Don't add the 'why' comments next to includes How to Correct IWYU Mistakes If fix_includes.py has removed an #include you actually need, add it back in with the comment '// IWYU pragma: keep' at the end of the #include line. Note that the comment is case-sensitive. If fix_includes.py has added an #include you don't need, just take it out. We hope to come up with a more permanent way of fixing later. If fix_includes.py has wrongly added or removed a forward-declare, just fix it up manually. If fix_includes.py has suggested a private header file (such as <bits/stl_vector.h>) instead of the proper public header file (<vector>), you can fix this by inserting a specially crafted comment near top of the private file (assuming you can write to it): '// IWYU pragma: private, include ""the/public/file.h""'. Current IWYU pragmas are described in IWYUPragmas. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/include-what-you-use/include-what-you-use"	"Helps find unecessary inclusions and make suggestions for fixing them. Based on LLVM/Clang (and only works with it).."	"true"
"Tools"	"indent"	"https://www.gnu.org/software/indent/"	"Formats C source code automatically to make it easier to read. Also converts from one style of source to another. or later."	"null"	"null"	"null"	"GNU GPLv3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"Indent - GNU Project - Free Software Foundation Skip to main text Set language English [en] The  9th HACKERS MEETING  will be held in Rennes (France) from August 18 to 20. JOIN THE FSF Free Software Supporter GNU Operating System Sponsored by the Free Software Foundation About GNU Philosophy Licenses Education = Software = Documentation Help GNU Indent Introduction to Indent The indent program can be used to make code easier to read. It can also convert from one style of writing C to another. indent understands a substantial amount about the syntax of C, but it also attempts to cope with incomplete and misformed syntax. Downloading Indent indent can be found on in the subdirectory /gnu/indent/ on your favorite GNU mirror. For other ways to obtain Indent, please read How to get GNU Software Documentation indent documentation can be found at http://www.gnu.org/software/indent/manual/. You may also find more information about indent by running info indent, man indent, or looking at /usr/share/doc/indent/ or /usr/local/share/doc/indent/ on your system. Mailing Lists/Newsgroups Email the indent bug and help list at <bug-indent@gnu.org>. See http://lists.gnu.org/mailman/listinfo/bug-indent for subscription information. Announcements about indent and most other GNU software are made on <info-gnu@gnu.org>. GNU home page FSF home page GNU Art GNU's Who? Free Software Directory Hardware Site map “Our mission is to preserve, protect and promote the freedom to use, study, copy, modify, and redistribute computer software, and to defend the rights of Free Software users.” The Free Software Foundation is the principal organizational sponsor of the GNU Operating System. Support GNU and the FSF by buying manuals and gear, joining the FSF as an associate member, or making a donation, either directly to the FSF or via Flattr. back to top Please send general FSF & GNU inquiries to <gnu@gnu.org>. There are also other ways to contact the FSF. Broken links and other corrections or suggestions can be sent to <bug-indent@gnu.org>. Please see the Translations README for information on coordinating and submitting translations of this article. Copyright © 2007, 2008 Free Software Foundation, Inc. This page is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License. Copyright Infringement Notification Updated: $Date: 2016/05/28 12:20:21 $"	"null"	"null"	"Formats C source code automatically to make it easier to read. Also converts from one style of source to another. or later."	"true"
"Tools"	"Make"	"https://www.gnu.org/software/make/"	"A tool which controls the generation of executables and other non-source files of a program. or later (link to the GNU implementation)."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"Make - GNU Project - Free Software Foundation Skip to main text Set language English [en] The  9th HACKERS MEETING  will be held in Rennes (France) from August 18 to 20. JOIN THE FSF Free Software Supporter GNU Operating System Sponsored by the Free Software Foundation About GNU Philosophy Licenses Education = Software = Documentation Help GNU GNU Make GNU Make is a tool which controls the generation of executables and other non-source files of a program from the program's source files. Make gets its knowledge of how to build your program from a file called the makefile, which lists each of the non-source files and how to compute it from other files. When you write a program, you should write a makefile for it, so that it is possible to use Make to build and install the program. Capabilities of Make Make enables the end user to build and install your package without knowing the details of how that is done -- because these details are recorded in the makefile that you supply. Make figures out automatically which files it needs to update, based on which source files have changed. It also automatically determines the proper order for updating files, in case one non-source file depends on another non-source file. As a result, if you change a few source files and then run Make, it does not need to recompile all of your program. It updates only those non-source files that depend directly or indirectly on the source files that you changed. Make is not limited to any particular language. For each non-source file in the program, the makefile specifies the shell commands to compute it. These shell commands can run a compiler to produce an object file, the linker to produce an executable, ar to update a library, or TeX or Makeinfo to format documentation. Make is not limited to building a package. You can also use Make to control installing or deinstalling a package, generate tags tables for it, or anything else you want to do often enough to make it worth while writing down how to do it. Make Rules and Targets A rule in the makefile tells Make how to execute a series of commands in order to build a target file from source files. It also specifies a list of dependencies of the target file. This list should include all files (whether source files or other targets) which are used as inputs to the commands in the rule. Here is what a simple rule looks like:  target:   dependencies ...           commands           ...  When you run Make, you can specify particular targets to update; otherwise, Make updates the first target listed in the makefile. Of course, any other target files needed as input for generating these targets must be updated first. Make uses the makefile to figure out which target files ought to be brought up to date, and then determines which of them actually need to be updated. If a target file is newer than all of its dependencies, then it is already up to date, and it does not need to be regenerated. The other target files do need to be updated, but in the right order: each target file must be regenerated before it is used in regenerating other targets. Advantages of GNU Make GNU Make has many powerful features for use in makefiles, beyond what other Make versions have. It can also regenerate, use, and then delete intermediate files which need not be saved. GNU Make also has a few simple features that are very convenient. For example, the -o file option which says ``pretend that source file file has not changed, even though it has changed.'' This is extremely useful when you add a new macro to a header file. Most versions of Make will assume they must therefore recompile all the source files that use the header file; but GNU Make gives you a way to avoid the recompilation, in the case where you know your change to the header file does not require it. However, the most important difference between GNU Make and most versions of Make is that GNU Make is free software. Makefiles And Conventions We have developed conventions for how to write Makefiles, which all GNU packages ought to follow. It is a good idea to follow these conventions in your program even if you don't intend it to be GNU software, so that users will be able to build your package just like many other packages, and will not need to learn anything special before doing so. These conventions are found in the chapter ``Makefile conventions'' (147 k characters) of the GNU Coding Standards (147 k characters). Downloading Make Make can be found on the main GNU ftp server: http://ftp.gnu.org/gnu/make/ (via HTTP) and ftp://ftp.gnu.org/gnu/make/ (via FTP). It can also be found on the GNU mirrors; please use a mirror if possible. Documentation Documentation for Make is available online, as is documentation for most GNU software. You may also find more information about Make by running info make or man make, or by looking at /usr/share/doc/make/, /usr/local/doc/make/, or similar directories on your system. A brief summary is available by running make --help. Mailing lists Make has the following mailing lists: bug-make is used to discuss most aspects of Make, including development and enhancement requests, as well as bug reports. help-make is for general user help and discussion. Announcements about Make and most other GNU software are made on info-gnu (archive). Security reports that should not be made immediately public can be sent directly to the maintainer. If there is no response to an urgent issue, you can escalate to the general security mailing list for advice. Getting involved Development of Make, and GNU in general, is a volunteer effort, and you can contribute. For information, please read How to help GNU. If you'd like to get involved, it's a good idea to join the discussion mailing list (see above). Test releases Trying the latest test release (when available) is always appreciated. Test releases of Make can be found at http://alpha.gnu.org/gnu/make/ (via HTTP) and ftp://alpha.gnu.org/gnu/make/ (via FTP). Development For development sources, issue trackers, and other information, please see the Make project page at savannah.gnu.org. Translating Make To translate Make's messages into other languages, please see the Translation Project page for Make. If you have a new translation of the message strings, or updates to the existing strings, please have the changes made in this repository. Only translations from this site will be incorporated into Make. For more information, see the Translation Project. Maintainer Make is currently being maintained by Paul Smith. Please use the mailing lists for contact. Licensing Make is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 3 of the License, or (at your option) any later version. GNU home page FSF home page GNU Art GNU's Who? Free Software Directory Hardware Site map “Our mission is to preserve, protect and promote the freedom to use, study, copy, modify, and redistribute computer software, and to defend the rights of Free Software users.” The Free Software Foundation is the principal organizational sponsor of the GNU Operating System. Support GNU and the FSF by buying manuals and gear, joining the FSF as an associate member, or making a donation, either directly to the FSF or via Flattr. back to top Please send general FSF & GNU inquiries to <gnu@gnu.org>. There are also other ways to contact the FSF. Broken links and other corrections or suggestions can be sent to <bug-make@gnu.org>. Please see the Translations README for information on coordinating and submitting translations of this article. Copyright © 2016 Free Software Foundation, Inc. This page is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License. Copyright Infringement Notification Updated: $Date: 2016/05/22 13:44:17 $"	"null"	"null"	"A tool which controls the generation of executables and other non-source files of a program. or later (link to the GNU implementation)."	"true"
"Tools"	"qo"	"https://github.com/andlabs/qo"	"A build system that works without a separate config file.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"243"	"15"	"6"	"GitHub - andlabs/qo: Another build system for C/C++, I guess? Inspired by 'go build' Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 15 Star 243 Fork 6 andlabs/qo Code Issues 5 Pull requests 1 Pulse Graphs Another build system for C/C++, I guess? Inspired by 'go build' 125 commits 1 branch 0 releases Fetching contributors Go 100.0% Go Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Latest commit 052c578 Nov 25, 2015 andlabs Fine-tuned MSVC warnings. Permalink Failed to load latest commit information. LICENSE Added a license. Sep 25, 2014 README.md Added -nounix. Apr 14, 2015 TODO More TODOs. Apr 20, 2015 builder.go Fixed build; now to fix program. Mar 2, 2015 collector.go Added conditional compilation by filename. Sep 27, 2014 flagcompiler.go Fixed various broken bits of flag handling. Oct 9, 2014 gcc.go More notes in TODOs. Mar 5, 2015 main.go Split [FAIL] errors into a fail() function; other TODO/panic() pairs … Sep 28, 2014 msvc.go Fine-tuned MSVC warnings. Nov 25, 2015 scriptgen.go Fixed the past bunch of commits. Yay no more overloading! Mar 2, 2015 step.go Put together the new Stage/Step system and applied it to the toolchains. Mar 2, 2015 target.go Added -nounix. Apr 14, 2015 toolchain.go Put together the new Stage/Step system and applied it to the toolchains. Mar 2, 2015 README.md qo: a build system for C/C++ qo is a new build system for C and C++ (though I can add other languages later). In contrast to existing build systems, which require the use of not only a Makefile but also an assortment of complex configuration files (or multiple stages thereof), qo doesn't use any. Instead, custom build settings are embedded using simple directives directly into the source code of your program. qo conditionally compiles each source file based on its filename. qo also supports some resource files normally compiled into the program. Debug builds and cross-compiles are also intended to be done as easily as possible. Enjoy! Suggestions, fixes, etc. welcome. News 14 April 2015 Added a -nounix flag to inhibit the unix pseudo-OS. 6 April 2015 Added unix pseudo-OS. 2 March 2015 I rewrote the actual build script part of the program a bit: some of the internal names have changed, a script can have an arbitrary number of stages (groups of steps that must be completed before the next group can start), and most important, load balancing. A future change will provide an option to change the number of concurrent build steps (currently set to the number of CPU cores on your system). Please report any bugs should this have broken anything. Installing qo is written in Go. It has no outside dependencies and does not use cgo, so a compiled qo binary is statically linked and ready to run out of the box. Once the project matures more, I may offer prebuilt binaries for download. Getting Started Let's say you have a simple project in a directory: $ cd project $ ls file1.c  file2.c  file3.c  file4.c  project.h  To build this project as it stands, simply invoke qo with no arguments: $ qo [  0%] Beginning build [ 20%] Compiled file1.c [ 40%] Compiled file3.c [ 60%] Compiled file4.c [ 80%] Compiled file2.c [100%] Linked project  You should see the status of the build as it happens (as above), and upon completion, the compiled program will be left as the executable project (named after the project directory) in the project directory, ready for running: $ ./project  To build a debug version, pass -g: $ qo -g  To see the individual commands as they happen, pass -x. Note that qo automatically builds with as many reasonable compiler diagnostics as possible enabled. What is Built? qo scans the current directory and all subdirectories for files to build. Files matched have the given (case-insensitive) extensions: C files: .c C++ files: .cpp, .cxx, .c++, .cc note the case-insensitive part; .C is recognized as C, not C++ C header files: .h, .hpp, .hxx, .h++, .hh Objective-C files: .m Objective-C++ files: .mm Windows Resource files: .rc Files can be excluded from the build if they are meant for a different operating system and/or CPU architecture; this is also done by filename and is described below, under ""Cross-Compiling"". C files are assumed to be C99. C++ files are assumed to be C++11. Configuring the Build So how do you specify extra libraries or compiler options for a project? Simple: you include special directives in the source files! Directives take the form // #qo directive: arguments  where whitespace up to and including the first space after #qo is significant, and where the // must be the first thing on the line. The two most important (and most portable) directives are pkg-config and LIBS. pkg-config passes the package names listed in arguments to pkg-config, inserting the resultant compiler flags as needed. LIBS takes the library names in arguments and passes them to the linker, applying the correct argument format for the toolchain in use (see ""Cross-Compiling"" below). For example: // #qo pkg-config: gtk+-3.0 // #qo LIBS: pwquality sqlite3  For more control over the command lines for compiling each file, the CFLAGS, CXXFLAGS, and LDFLAGS directives pass their arguments as extra arguments to the C compiler, C++ compiler, and linker, respectively. #qo directives are assembled from all source files together. That is, do not copy the directives into each source file; bad things will happen. In addition, the $CFLAGS, $CXXFLAGS, and $LDFLAGS environment variables also change compiler/linker command-line arguments. Cross-Compiling qo tries to make cross-compiling easy. There are three concepts at play: the target OS the target architecture the toolchain, which defines which compilers and linkers to use By default, qo builds for the system you are presently running (actually the system the qo binary was built for; but this is a limitation of Go). This is called the host. You can change the target OS, target arch, or toolchain with the -os, -arch, and -tc options, respectively. Pass list to see a list of supported OSs, architectures, and toolchains. (qo by default tends toward gcc/clang-based toolchains.) In addition, qo will omit files and folders from the build if they are intended for a different OS and/or architecture than the target. To omit a file, have _OS, _arch, or _OS_arch before the extension. To omit a folder, its name must consist entirely of OS, arch, or OS_arch. For example: file.c                compiled always file_windows.c        only compiled if targetting Windows file_386.c            only compiled if targetting architecture 386 file_windows_386.c    only compiled if targetting 386-based Windows directory/            trasversed always windows/              only trasversed on Windows 386/                  only trasversed if targetting 386 windows_386/          only trasversed if targetting 386-based Windows  In addition, the OS name unix is valid on all Unix systems (Linux, FreeBSD, Mac OS X, etc.). You can choose to inhibit this with the -nounix flag. Cross-Compiler Executable Search Order Under the hood, however, cross-compiling is a very complex and problematic undertaking for historical and practical reasons. qo assumes you have a correctly configured cross-compiler setup for the target OS, architecture, and toolchain (even if it's just the toolchain). qo makes the following compromise. Given the following terms: unqualified binaries - binaries named gcc, g++, clang, and clang++, without any target triplet multilib flags - -m32 and -m64 If the -triplet option is passed to qo to explicitly specify a triplet to use, that triplet is used, no questions asked. No mulitlib flags will be appended to the command line. Otherwise, if the target is the same as the host, unqualified binaries are run, and multilib flags may or may not be appended. Otherwise, if the target OS is the same as the host OS and host OS is not Windows, if the host arch is either 386 or amd64 and the target arch is either 386 or amd64, a multilib flag is appended, and the unqualified binaries are run. Otherwise, if using clang, a generic target triplet is generated and used. Otherwise, if the target OS is windows, MinGW-w64 binaries are used. Otherwise, an error occurs. For more information, see this and its references. Notes A note on optional features and cyclic dependencies qo does not support the notion of optional features: everything in the recursive directory tree of the current directory is compiled. I personally don't like features being optional; if something really needs to be conditional, it should be a plugin, and there's no reason to ship a gimped or feature-incomplete version of a program. I don't like how graphviz packages in at least Ubuntu don't ship with pic support (even though I'm probably the only person int he world that still uses troff). In a related vein, cyclic dependencies (usually caused by optional features, as is the case with GLib ↔ GVFS) should also be avoided. Notes on MSVC The version of MSVC used defines how much C99 or C++11 can be used. The following seem to be undocumented as being MinGW extensions to the rc format: arithmetic expressions Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/andlabs/qo"	"A build system that works without a separate config file.."	"true"
"Tools"	"rr"	"http://rr-project.org/"	"A debugger that records non-deterministic executions to allow for deterministic debugging.."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"1859"	"92"	"158"	"GitHub - mozilla/rr: Record and Replay Framework Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 92 Star 1,859 Fork 158 mozilla/rr Code Issues 171 Pull requests 7 Wiki Pulse Graphs Record and Replay Framework http://rr-project.org/ 3,753 commits 2 branches 28 releases 50 contributors C++ 65.4% C 25.1% Python 6.4% CMake 1.4% Assembly 0.9% Shell 0.7% HTML 0.1% C++ C Python CMake Assembly Shell HTML Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags gh-pages master Nothing to show 4.3.0 4.2.0 4.1.0 4.0.3 4.0.2 4.0.1 4.0.0 3.2.0 3.1.0 3.0.0 2.0.0 1.5.0 1.4.0 1.3.0 1.2.1 1.2.0 1.1.0 1.0.0 0.5.1 0.5.0 0.4.1 0.4.0 0.3.0 0.2.0 0.1.0 0.1prerelease.0 0.0.0 0.0prerelease.0 Nothing to show New pull request Latest commit a5a4241 Jul 12, 2016 rocallahan More robust handling of cases where the tracee doesn't have permissio… … …n to read parts of the rr installation  Resolves #1751 Permalink Failed to load latest commit information. doc Replace references to Fedora's YUM with DNF. Nov 5, 2015 include/rr Enforce a floor on the desched_fd to prevent it from being too low fo… Jul 17, 2015 scripts Make signal-rr-recording.sh catch 'rr path/to/exe' recording syntax. Sep 27, 2014 src More robust handling of cases where the tracee doesn't have permissio… Jul 12, 2016 third-party/gdb Support gdb XML target descriptions and thereby AVX registers Jun 1, 2016 .clang-format Reformat C/C++ sources using clang-format. Sep 9, 2014 .gitignore Add .orig/.rej to .gitignore Apr 26, 2016 .travis.yml Skip installing pyexpect and gdb on Travis Jun 28, 2016 CMakeLists.txt Fix stupid regression in `rr ps` Jul 8, 2016 CONTRIBUTING.md Update contribution guidelines May 6, 2016 Dockerfile Add a Dockerfile Apr 30, 2015 LICENSE Do not truncate filename pointer in preload sys_creat. Dec 5, 2015 README.md Update README to remove Jenkins continuous build Mar 22, 2016 configure Basic CMake system May 8, 2013 rr.spec Update rpm spec file for exec_stub rename Jun 28, 2016 README.md rr is a lightweight tool for recording and replaying execution of applications (trees of processes and threads). More information about the project, including instructions on how to install, run, and build rr, is at http://rr-project.org. Or go directly to the installation and building instructions. Please contribute! Make sure to review the pull request checklist before submitting a pull request. If you find rr useful, please add a testimonial. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/mozilla/rr"	"A debugger that records non-deterministic executions to allow for deterministic debugging.."	"true"
"Tools"	"tup"	"http://gittup.org/tup/index.html"	"A very fast, file-based, cross-platform build system. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"null"	"null"	"null"	"tup | Home Site Map Home Getting Started Examples A First Tupfile Dependencies Generated Header Multiple Directories Manual Lua Parser Lua Examples Tips and Tricks Make vs Tup Tup vs Mordor License Support Additional Info Build System Rules and Algorithms (PDF) tup-users mailing list Home What is tup? Tup is a file-based build system for Linux, OSX, and Windows. It inputs a list of file changes and a directed acyclic graph (DAG), then processes the DAG to execute the appropriate commands required to update dependent files. Updates are performed with very little overhead since tup implements powerful build algorithms to avoid doing unnecessary work. This means you can stay focused on your project rather than on your build system. Get tup Git Repository  $ git clone git://github.com/gittup/tup.git $ cd tup tup$ ./bootstrap.sh tup$ man ./tup.1  Windows Download latest version List of previous versions Linux Ubuntu If you don't want to install tup from the git tree, you can use the unofficial tup PPA repository that works for Debian-based distributions (e.g. Ubuntu 10.04+).  sudo apt-add-repository 'deb http://ppa.launchpad.net/anatol/tup/ubuntu precise main' sudo apt-get update sudo apt-get install tup  MacOSX If you use the Homebrew package manager you can install tup as follows:  brew tap homebrew/fuse brew install homebrew/fuse/tup  If you use MacPorts install tup as: sudo port install tup Why tup? You can use tup anywhere you would use another build system (like make, or any of its derivatives). One reason you would want to use tup is if you like to update things very quickly. For example, if you typically execute a build in a subdirectory because it takes too long to figure out what to do when you execute the build from the top, you might want to look into tup. Unfortunately, tup is so fast that your chair mounted jousting might suffer. I apologize in advance if someone besmirches your honor and you are unable to properly defend yourself as a result. Wha tup? Nothing much, just writing some web pages. What's up with you? Why is it so awesome? It is very fast. It will automatically clean-up old files. It will detect if your build description isn't parallel-safe, and tell you. What this means is: Your edit/compile/test cycle is quick, even if your project is large. You just run: tup upd You don't have to outsmart your build system by starting it in a subdirectory to make it go faster. Anywhere in the tree: tup upd Your version control lets you rename a file. Does your build system? tup upd Fresh checkouts: gone. 'clean' builds: gone. Worries: gone. What remains: tup upd How is it so awesome? In a typical build system, the dependency arrows go down. Although this is the way they would naturally go due to gravity, it is unfortunately also where the enemy's gate is. This makes it very inefficient and unfriendly. In tup, the arrows go up. This is obviously true because it rhymes. See how the dependencies differ in make and tup: Make Tup See the difference? The arrows go up. This makes it very fast. In fact, in at least one case, tup is optimal. See the Build System Rules and Algorithms (PDF) paper for more detailed information. © 2008-2016 Mike Shal. All Rights Reserved."	"null"	"null"	"A very fast, file-based, cross-platform build system. only."	"true"
"Tools"	"unifdef"	"http://dotat.at/prog/unifdef/"	"Removes #ifdef and #if directives with their delimited text without touching any other part of the file."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"43"	"4"	"16"	"GitHub - fanf2/unifdef: selectively remove C preprocessor conditionals Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 4 Star 43 Fork 16 fanf2/unifdef Code Pull requests 1 Pulse Graphs selectively remove C preprocessor conditionals http://dotat.at/prog/unifdef 624 commits 3 branches 12 releases Fetching contributors C 74.3% Groff 10.7% Shell 9.5% HTML 2.4% Makefile 1.2% ApacheConf 1.1% Other 0.8% C Groff Shell HTML Makefile ApacheConf Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags FreeBSD master wip Nothing to show unifdef-2.11 unifdef-2.10 unifdef-2.9 unifdef-2.8 unifdef-2.7 unifdef-2.6 unifdef-2.5 unifdef-2.4 unifdef-2.3 unifdef-2.2 unifdef-2.1 unifdef-2.0 Nothing to show New pull request Latest commit 87dfd91 Feb 26, 2016 fanf2 portability: fix problems compiling with C++ compiler … Michael McConville suggested removing a ""redundant"" cast of the return value from malloc(), based on a change in the OpenBSD version of unifdef. This is a good suggestion for a purely C program, but the cast is required in C++.  Carsten Hey contributed some portability improvements in 2012 which included this cast, so that unifdef can be compiled with a C++ compiler. Unfortunately since then there have been several regressions in C++ support.  This commit fixes those regressions. Permalink Failed to load latest commit information. FreeBSD port: clean up err.c and getopt.c Feb 21, 2012 scripts test: try to work better on MinGW Feb 15, 2016 tests test: need newlines in MinGW printf workaround Feb 16, 2016 web Freecode is read-only Dec 3, 2015 win32 portability: fix problems compiling with C++ compiler Feb 26, 2016 .gitignore Tell git to ignore .exe target. Apr 4, 2013 .travis.yml travis: add OSX and Ubuntu Trusty builds Feb 15, 2016 COPYING Bump copyright dates Dec 3, 2015 INSTALL INSTALL: use GitHub for Windows to run Unix shell scripts Jun 12, 2013 Makefile Makefile: correct dependencies and portability to GNU make. Jun 6, 2013 README README: thanks to Ruediger Meier! Feb 15, 2016 ifdef-how.pl ifdef-how: what conditionals cause this line to be emitted? Dec 7, 2015 unifdef.1 man: use .Mt to mark up email addresses Dec 3, 2015 unifdef.c portability: fix problems compiling with C++ compiler Feb 26, 2016 unifdef.h unifdef: typo in comment Jan 8, 2014 unifdefall.sh unifdefall: use unifdef -f and delete lots of arcane shell hackery May 6, 2013 README unifdef - selectively remove C preprocessor conditionals  Written by Tony Finch <dot@dotat.at> - http://dotat.at/prog/unifdef/  The unifdef utility selectively processes conditional C preprocessor #if and #ifdef directives. It removes from a file both the directives and the additional text that they delimit, while otherwise leaving the file alone.  Please see the INSTALL file for installation instructions.  Pre-formatted documentation can be found in unifdef.txt  You can download the latest release tar and zip files from: 	http://dotat.at/prog/unifdef  You can clone the development repository using: 	git clone http://dotat.at/git/unifdef.git  I also maintain a copy at http://github.com/fanf2/unifdef (Warning: GitHub's zip download is incomplete and unusable.)  Please send bug reports and patches to me. Unless you state otherwise, I will assume that any contributions are under the two-clause BSD licence. See the COPYING file for details.  Thanks to the following people for their contributions:  Bob Proulx <bob@proulx.com>  - test suite  Jonathan Nieder <jrnieder@gmail.com>  - bug fixes, improved unifdefall  Anders H Kaseorg <andersk@mit.edu>  - bug fixes and other improvements  Ruediger Meier <ruediger.meier@ga-group.nl>  - build and portability cleanups  Ben Hutchings at Solarflare Communications  - lenient evaluation of && and ||  Steve Underwood <steveu@coppice.org>  - read #define and #undef directives from a file  Brian Ginsbach <ginsbach@netbsd.org>  - improved expression evaluator  Other contributions are listed in the Changelog.  - end -  Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/fanf2/unifdef"	"Removes #ifdef and #if directives with their delimited text without touching any other part of the file."	"true"
"Tools"	"Valgrind"	"http://www.valgrind.org/"	"A range of dynamic analysis tools, including a leak checker. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"null"	"null"	"null"	"Valgrind Home Information About News Tool Suite Supported Platforms The Developers Source Code Current Releases Release Archive Variants / Patches Code Repository Valkyrie / GUIs Documentation Table of Contents Quick Start FAQ User Manual Download Manual Research Papers Books Contact Mailing Lists and IRC Bug Reports Feature Requests Contact Summary Commercial Support How to Help Contributing Project Suggestions Gallery Projects / Users Press / Media Awards Surveys Artwork / Clothing Current release: valgrind-3.11.0   Valgrind is an instrumentation framework for building dynamic analysis tools. There are Valgrind tools that can automatically detect many memory management and threading bugs, and profile your programs in detail. You can also use Valgrind to build new tools. The Valgrind distribution currently includes six production-quality tools: a memory error detector, two thread error detectors, a cache and branch-prediction profiler, a call-graph generating cache and branch-prediction profiler, and a heap profiler. It also includes three experimental tools: a stack/global array overrun detector, a second heap profiler that examines how heap blocks are used, and a SimPoint basic block vector generator. It runs on the following platforms: X86/Linux, AMD64/Linux, ARM/Linux, ARM64/Linux, PPC32/Linux, PPC64/Linux, PPC64LE/Linux, S390X/Linux, MIPS32/Linux, MIPS64/Linux, TILEGX/Linux, X86/Solaris, AMD64/Solaris, ARM/Android (2.3.x and later), ARM64/Android, X86/Android (4.0 and later), MIPS32/Android, X86/Darwin and AMD64/Darwin (Mac OS X 10.10, with initial support for 10.11). Valgrind is Open Source / Free Software, and is freely available under the GNU General Public License, version 2. Recent News 22 September 2015: valgrind-3.11.0, is available. This release supports: X86/Linux, AMD64/Linux, ARM/Linux, ARM64/Linux, PPC32/Linux, PPC64/Linux, PPC64LE/Linux, S390X/Linux, MIPS32/Linux, MIPS64/Linux, TILEGX/Linux, X86/Solaris, AMD64/Solaris, ARM/Android (2.3.x and later), ARM64/Android, X86/Android (4.0 and later), MIPS32/Android, X86/Darwin and AMD64/Darwin (Mac OS X 10.10, with initial support for 10.11). (release notes). 21 October 2010: Valkyrie-2.0.0, a Qt4-based GUI for the Memcheck and Helgrind tools in Valgrind-3.6.0, is now available. May 5 2010: Valgrind t-shirts are available for purchase at FreeWear.org. For each t-shirt sold, € 3 will be donated to the Valgrind project. Copyright © 2000-2015 Valgrind™ Developers Hosting kindly donated by Mythic Beasts Best Viewed With A(ny) Browser"	"null"	"null"	"A range of dynamic analysis tools, including a leak checker. only."	"true"
"Utilities"	"ApeTagLibs"	"https://github.com/jeremyevans/ape_tag_libs/tree/master/c"	"A C library for working with APEv2 tags.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"8"	"3"	"3"	"ape_tag_libs/c at master · jeremyevans/ape_tag_libs · GitHub Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 3 Star 8 Fork 3 jeremyevans/ape_tag_libs Code Issues 0 Pull requests 0 Pulse Graphs Branch: master Switch branches/tags Branches Tags gh-pages master Nothing to show Nothing to show Create new file Find file History ape_tag_libs/c/ Fetching latest commit… Cannot retrieve the latest commit at this time. Permalink .. Failed to load latest commit information. m4 test .gitignore CHANGELOG MIT-LICENSE Makefile.am README apeinfo.1 apeinfo.c apetag.3 apetag.c apetag.h configure.ac libapetag.pc.in README libapetag                         http://www.sourceforge.net/projects/pylibape/ ===============================================================================  Table of Contents ================== 1 Introduction 2 License 3 Installation 4 API 5 apeinfo 6 Source Control  1 Introduction ===============  libapetag implements an APEv2 tag reader/writer.  It aims for standards compliance with the APEv2 tag specification [1].  APEv2 is the tagging format used by Musepack (.mpc), Monday's Audio (.ape), WavPack (.wv), and OptimFROG (.ofr) audio formats, and it can also be used with mp3s as an alternative to ID3v2.[234].    [1] http://wiki.hydrogenaudio.org/index.php?title=APEv2_specification  2 License =========  libapetag is released under the MIT License, which gives you freedom to do pretty much anything you want with it as long as you include a copy of the license.  A copy of the license is included in the MIT-LICENSE file.  3 Installation ==============  Hopefully, it's as simple as:    $ make # build library   $ make regress # Check that all tests complete successfully   $ sudo make install # install library and program  However, this may fail, and if it does, hopefully it can be fixed by a simple change in the Makefile.  If you have to patch the library to make it work on your system, please contribute patches back via SourceForge.  4 API =====  See the man page (man 3 apetag) for a description of the API.  5 apeinfo =========  apeinfo is a short C program that gives an example using the library.  It just analyzes the files given on the command line and outputs the contents of each item in the tag if the tag exists.  6 Source Control ================  Public access to the source repository can be found at  https://github.com/jeremyevans/ape_tag_libs/tree/master/c  Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/jeremyevans/ape_tag_libs/tree/master/c"	"A C library for working with APEv2 tags.."	"true"
"Utilities"	"bfd"	"http://sourceware.org/binutils/docs/bfd/"	"A library for manipulating binary object files. Part of GNU binutils. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"Untitled Table of Contents 1 Introduction 1.1 History 1.2 How To Use BFD 1.3 What BFD Version 2 Can Do 1.3.1 Information Loss 1.3.2 The BFD canonical object-file format 2 BFD Front End 2.1 typedef bfd 2.2 Error reporting 2.2.1 Type bfd_error_type 2.2.1.1 bfd_get_error 2.2.1.2 bfd_set_error 2.2.1.3 bfd_errmsg 2.2.1.4 bfd_perror 2.2.2 BFD error handler 2.2.2.1 bfd_set_error_handler 2.2.2.2 bfd_set_error_program_name 2.2.2.3 bfd_get_error_handler 2.2.3 BFD assert handler 2.2.3.1 bfd_set_assert_handler 2.2.3.2 bfd_get_assert_handler 2.3 Miscellaneous 2.3.1 Miscellaneous functions 2.3.1.1 bfd_get_reloc_upper_bound 2.3.1.2 bfd_canonicalize_reloc 2.3.1.3 bfd_set_reloc 2.3.1.4 bfd_set_file_flags 2.3.1.5 bfd_get_arch_size 2.3.1.6 bfd_get_sign_extend_vma 2.3.1.7 bfd_set_start_address 2.3.1.8 bfd_get_gp_size 2.3.1.9 bfd_set_gp_size 2.3.1.10 bfd_scan_vma 2.3.1.11 bfd_copy_private_header_data 2.3.1.12 bfd_copy_private_bfd_data 2.3.1.13 bfd_merge_private_bfd_data 2.3.1.14 bfd_set_private_flags 2.3.1.15 Other functions 2.3.1.16 bfd_alt_mach_code 2.3.1.17 bfd_emul_get_maxpagesize 2.3.1.18 bfd_emul_set_maxpagesize 2.3.1.19 bfd_emul_get_commonpagesize 2.3.1.20 bfd_emul_set_commonpagesize 2.3.1.21 bfd_demangle 2.3.1.22 bfd_update_compression_header 2.3.1.23 bfd_check_compression_header 2.3.1.24 bfd_get_compression_header_size 2.3.1.25 bfd_convert_section_size 2.3.1.26 bfd_convert_section_contents 2.3.1.27 struct bfd_iovec 2.3.1.28 bfd_get_mtime 2.3.1.29 bfd_get_size 2.3.1.30 bfd_mmap 2.4 Memory Usage 2.5 Initialization 2.5.1 Initialization functions 2.5.1.1 bfd_init 2.6 Sections 2.6.1 Section input 2.6.2 Section output 2.6.3 Link orders 2.6.4 typedef asection 2.6.5 Section prototypes 2.6.5.1 bfd_section_list_clear 2.6.5.2 bfd_get_section_by_name 2.6.5.3 bfd_get_next_section_by_name 2.6.5.4 bfd_get_linker_section 2.6.5.5 bfd_get_section_by_name_if 2.6.5.6 bfd_get_unique_section_name 2.6.5.7 bfd_make_section_old_way 2.6.5.8 bfd_make_section_anyway_with_flags 2.6.5.9 bfd_make_section_anyway 2.6.5.10 bfd_make_section_with_flags 2.6.5.11 bfd_make_section 2.6.5.12 bfd_get_next_section_id 2.6.5.13 bfd_set_section_flags 2.6.5.14 bfd_rename_section 2.6.5.15 bfd_map_over_sections 2.6.5.16 bfd_sections_find_if 2.6.5.17 bfd_set_section_size 2.6.5.18 bfd_set_section_contents 2.6.5.19 bfd_get_section_contents 2.6.5.20 bfd_malloc_and_get_section 2.6.5.21 bfd_copy_private_section_data 2.6.5.22 bfd_generic_is_group_section 2.6.5.23 bfd_generic_discard_group 2.7 Symbols 2.7.1 Reading symbols 2.7.2 Writing symbols 2.7.3 Mini Symbols 2.7.4 typedef asymbol 2.7.5 Symbol handling functions 2.7.5.1 bfd_get_symtab_upper_bound 2.7.5.2 bfd_is_local_label 2.7.5.3 bfd_is_local_label_name 2.7.5.4 bfd_is_target_special_symbol 2.7.5.5 bfd_canonicalize_symtab 2.7.5.6 bfd_set_symtab 2.7.5.7 bfd_print_symbol_vandf 2.7.5.8 bfd_make_empty_symbol 2.7.5.9 _bfd_generic_make_empty_symbol 2.7.5.10 bfd_make_debug_symbol 2.7.5.11 bfd_decode_symclass 2.7.5.12 bfd_is_undefined_symclass 2.7.5.13 bfd_symbol_info 2.7.5.14 bfd_copy_private_symbol_data 2.8 Archives 2.8.1 Archive functions 2.8.1.1 bfd_get_next_mapent 2.8.1.2 bfd_set_archive_head 2.8.1.3 bfd_openr_next_archived_file 2.9 File formats 2.9.1 File format functions 2.9.1.1 bfd_check_format 2.9.1.2 bfd_check_format_matches 2.9.1.3 bfd_set_format 2.9.1.4 bfd_format_string 2.10 Relocations 2.10.1 typedef arelent 2.10.1.1 enum complain_overflow 2.10.1.2 reloc_howto_type 2.10.1.3 The HOWTO Macro 2.10.1.4 bfd_get_reloc_size 2.10.1.5 arelent_chain 2.10.1.6 bfd_check_overflow 2.10.1.7 bfd_perform_relocation 2.10.1.8 bfd_install_relocation 2.10.2 The howto manager 2.10.2.1 bfd_reloc_code_type 2.10.2.2 bfd_reloc_type_lookup 2.10.2.3 bfd_default_reloc_type_lookup 2.10.2.4 bfd_get_reloc_code_name 2.10.2.5 bfd_generic_relax_section 2.10.2.6 bfd_generic_gc_sections 2.10.2.7 bfd_generic_lookup_section_flags 2.10.2.8 bfd_generic_merge_sections 2.10.2.9 bfd_generic_get_relocated_section_contents 2.11 Core files 2.11.1 Core file functions 2.11.1.1 bfd_core_file_failing_command 2.11.1.2 bfd_core_file_failing_signal 2.11.1.3 bfd_core_file_pid 2.11.1.4 core_file_matches_executable_p 2.11.1.5 generic_core_file_matches_executable_p 2.12 Targets 2.12.1 bfd_target 2.12.1.1 bfd_set_default_target 2.12.1.2 bfd_find_target 2.12.1.3 bfd_get_target_info 2.12.1.4 bfd_target_list 2.12.1.5 bfd_seach_for_target 2.12.1.6 bfd_flavour_name 2.13 Architectures 2.13.1 bfd_architecture 2.13.2 bfd_arch_info 2.13.2.1 bfd_printable_name 2.13.2.2 bfd_scan_arch 2.13.2.3 bfd_arch_list 2.13.2.4 bfd_arch_get_compatible 2.13.2.5 bfd_default_arch_struct 2.13.2.6 bfd_set_arch_info 2.13.2.7 bfd_default_set_arch_mach 2.13.2.8 bfd_get_arch 2.13.2.9 bfd_get_mach 2.13.2.10 bfd_arch_bits_per_byte 2.13.2.11 bfd_arch_bits_per_address 2.13.2.12 bfd_default_compatible 2.13.2.13 bfd_default_scan 2.13.2.14 bfd_get_arch_info 2.13.2.15 bfd_lookup_arch 2.13.2.16 bfd_printable_arch_mach 2.13.2.17 bfd_octets_per_byte 2.13.2.18 bfd_arch_mach_octets_per_byte 2.13.2.19 bfd_arch_default_fill 2.14 Opening and closing BFDs 2.14.1 Functions for opening and closing 2.14.1.1 bfd_fopen 2.14.1.2 bfd_openr 2.14.1.3 bfd_fdopenr 2.14.1.4 bfd_openstreamr 2.14.1.5 bfd_openr_iovec 2.14.1.6 bfd_openw 2.14.1.7 bfd_close 2.14.1.8 bfd_close_all_done 2.14.1.9 bfd_create 2.14.1.10 bfd_make_writable 2.14.1.11 bfd_make_readable 2.14.1.12 bfd_alloc 2.14.1.13 bfd_alloc2 2.14.1.14 bfd_zalloc 2.14.1.15 bfd_zalloc2 2.14.1.16 bfd_calc_gnu_debuglink_crc32 2.14.1.17 bfd_get_debug_link_info 2.14.1.18 bfd_get_alt_debug_link_info 2.14.1.19 separate_debug_file_exists 2.14.1.20 separate_alt_debug_file_exists 2.14.1.21 find_separate_debug_file 2.14.1.22 bfd_follow_gnu_debuglink 2.14.1.23 bfd_follow_gnu_debugaltlink 2.14.1.24 bfd_create_gnu_debuglink_section 2.14.1.25 bfd_fill_in_gnu_debuglink_section 2.15 Implementation details 2.15.1 Internal functions 2.15.1.1 bfd_write_bigendian_4byte_int 2.15.1.2 bfd_put_size 2.15.1.3 bfd_get_size 2.15.1.4 bfd_h_put_size 2.15.1.5 bfd_log2 2.16 File caching 2.16.1 Caching functions 2.16.1.1 bfd_cache_init 2.16.1.2 bfd_cache_close 2.16.1.3 bfd_cache_close_all 2.16.1.4 bfd_open_file 2.17 Linker Functions 2.17.1 Creating a linker hash table 2.17.2 Adding symbols to the hash table 2.17.2.1 Differing file formats 2.17.2.2 Adding symbols from an object file 2.17.2.3 Adding symbols from an archive 2.17.3 Performing the final link 2.17.3.1 Information provided by the linker 2.17.3.2 Relocating the section contents 2.17.3.3 Writing the symbol table 2.17.3.4 bfd_link_split_section 2.17.3.5 bfd_section_already_linked 2.17.3.6 bfd_generic_define_common_symbol 2.17.3.7 bfd_find_version_for_sym 2.17.3.8 bfd_hide_sym_by_version 2.18 Hash Tables 2.18.1 Creating and freeing a hash table 2.18.2 Looking up or entering a string 2.18.3 Traversing a hash table 2.18.4 Deriving a new hash table type 2.18.4.1 Define the derived structures 2.18.4.2 Write the derived creation routine 2.18.4.3 Write other derived routines 3 BFD back ends 3.1 What to Put Where 3.2 a.out backends 3.2.1 Relocations 3.2.2 Internal entry points 3.2.2.1 aout_size_swap_exec_header_in 3.2.2.2 aout_size_swap_exec_header_out 3.2.2.3 aout_size_some_aout_object_p 3.2.2.4 aout_size_mkobject 3.2.2.5 aout_size_machine_type 3.2.2.6 aout_size_set_arch_mach 3.2.2.7 aout_size_new_section_hook 3.3 coff backends 3.3.1 Porting to a new version of coff 3.3.2 How the coff backend works 3.3.2.1 File layout 3.3.2.2 Coff long section names 3.3.2.3 Bit twiddling 3.3.2.4 Symbol reading 3.3.2.5 Symbol writing 3.3.2.6 coff_symbol_type 3.3.2.7 bfd_coff_backend_data 3.3.2.8 Writing relocations 3.3.2.9 Reading linenumbers 3.3.2.10 Reading relocations 3.4 ELF backends 3.5 mmo backend 3.5.1 File layout 3.5.2 Symbol table format 3.5.3 mmo section mapping BFD Index Next: Overview, Previous: (dir), Up: (dir) Overview: Overview of BFD BFD front end: BFD front end BFD back ends: BFD back ends GNU Free Documentation License: GNU Free Documentation License BFD Index: BFD Index"	"null"	"null"	"A library for manipulating binary object files. Part of GNU binutils. or later."	"true"
"Utilities"	"ccv"	"https://github.com/liuliu/ccv"	"C-based/Cached/Core Computer Vision library; modern computer vision.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"5313"	"366"	"1292"	"GitHub - liuliu/ccv: C-based/Cached/Core Computer Vision Library, A Modern Computer Vision Library Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 366 Star 5,313 Fork 1,292 liuliu/ccv Code Issues 49 Pull requests 16 Wiki Pulse Graphs C-based/Cached/Core Computer Vision Library, A Modern Computer Vision Library http://libccv.org 903 commits 11 branches 0 releases 5 contributors C 71.0% Cuda 12.6% HTML 10.6% Ruby 1.5% C++ 1.1% Ragel in Ruby Host 1.1% Other 2.1% C Cuda HTML Ruby C++ Ragel in Ruby Host Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: stable Switch branches/tags Branches Tags gh-pages r0.1-rc1 r0.2-rc1 r0.3-rc1 r0.4-rc1 r0.5-rc1 r0.6-rc1 r0.7-rc1 r0.7-rc2 stable unstable Nothing to show Nothing to show New pull request Latest commit 07fc691 Apr 12, 2016 liuliu A better fix. Permalink Failed to load latest commit information. bin Added new post Dec 24, 2014 doc updated documents, added vgg-d model, about ready for the big release Dec 23, 2014 js changed ccv_unserialize/ccv_serialize to a more sensible name Mar 14, 2012 lib A better fix. Apr 12, 2016 samples Correct download logic Mar 6, 2016 serve updated documents, added vgg-d model, about ready for the big release Dec 23, 2014 site Added new post Dec 24, 2014 test Fix unittest on Mac OSX due to different libpng versions Dec 24, 2014 .doxygen.conf added a script to generate markdown doc from xml of Doxygen, haven't … Dec 21, 2014 .gitignore add libccv.org site source file to the tree Mar 1, 2014 .travis.yml try libatlas-base-dev Dec 12, 2014 COPYING fix typo. change license for files included in ./doc ./samples, ./sit… Mar 6, 2014 README.md portability => portable Dec 17, 2014 THANKS added THANKS Jan 12, 2014 README.md Build Status Travis CI VM: Raspberry Pi: FreeBSD x64: Linux x64: Mac OSX: Backstory I set to build ccv with a minimalism inspiration. That was back in 2010, out of the frustration with the computer vision library then I was using, ccv was meant to be a much easier to deploy, simpler organized code with a bit caution with dependency hygiene. The simplicity and minimalistic nature at then, made it much easier to integrate into any server-side deployment environments. Portable and Embeddable Fast forward to now, the world is quite different from then, but ccv adapts pretty well in this new, mobile-first environment. It now runs on Mac OSX, Linux, FreeBSD, Windows*, iPhone, iPad, Android, Raspberry Pi. In fact, anything that has a proper C compiler probably can run ccv. The majority (with notable exception of convolutional networks, which requires a BLAS library) of ccv will just work with no compilation flags or dependencies. Modern Computer Vision Algorithms One core concept of ccv development is application driven. Thus, ccv ends up implementing a handful state-of-art algorithms. It includes a close to state-of-the-art image classifier, a state-of-the-art frontal face detector, reasonable collection of object detectors for pedestrians and cars, a useful text detection algorithm, a long-term general object tracking algorithm, and the long-standing feature point extraction algorithm. Clean Interface with Cached Image Preprocessing Many computer vision tasks nowadays consist of quite a few preprocessing layers: image pyramid generation, color space conversion etc. These potentially redundant operations cannot be easily eliminated within a mature API. ccv provides a built-in cache mechanism that, while maintains a clean function interface, effectively does transparent cache for you. For computer vision community, there is no shortage of good algorithms, good implementation is what it lacks of. After years, we stuck in between either the high-performance, battle-tested but old algorithm implementations, or the new, shining but Matlab algorithms. ccv is my take on this problem, hope you enjoy it. License ccv source code is distributed under BSD 3-clause License. ccv's data models and documentations are distributed under Creative Commons Attribution 4.0 International License. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/liuliu/ccv"	"C-based/Cached/Core Computer Vision library; modern computer vision.."	"true"
"Utilities"	"cf4ocl"	"https://fakenmc.github.io/cf4ocl/"	"The C Framework for OpenCL; a cross-platform object-oriented framework for developing and benchmarking projects. only (library), (other code)."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"cf4ocl View on GitHub cf4ocl C Framework for OpenCL Download this project as a .zip file Download this project as a tar.gz file News 4 July 2016 Version 2.1.0 is available for download in the releases page. Summary The C Framework for OpenCL, cf4ocl, is a cross-platform pure C object-oriented framework for developing and benchmarking OpenCL projects. It aims to: Promote the rapid development of OpenCL host programs in C (with support for C++) and avoid the tedious and error-prone boilerplate code usually required. Assist in the benchmarking of OpenCL events, such as kernel execution and data transfers. Profiling comes for free with cf4ocl. Simplify the analysis of the OpenCL environment and of kernel requirements. Allow for all levels of integration with existing OpenCL code: use as much or as few of cf4ocl required for your project, with full access to the underlying OpenCL objects and functions at all times. Features Object-oriented interface to the OpenCL API New/destroy functions, no direct memory alloc/free Easy (and extensible) device selection Simple event dependency mechanism User-friendly error management OpenCL version and platform independent Integrated profiling Advanced device query utility Offline kernel compiler and linker Documentation User guide and API Tutorial Wiki Utilities Function list Library modules Examples Feedback and collaboration Download or clone cf4ocl, build and install it, and code a small example, such as the one below, which shows a clean and fast way to create an OpenCL context with a user-selected device: #include <cf4ocl2.h> int main() {      /* Variables. */     CCLContext * ctx = NULL;      /* Code. */     ctx = ccl_context_new_from_menu(NULL);     if (ctx == NULL) exit(-1);      /* Destroy context wrapper. */     ccl_context_destroy(ctx);      return 0; } If you like this project and want to contribute, take a look at the existing issues. We also need help with binary packaging for different OSes. Other improvements or suggestions are of course, welcome. We appreciate any feedback. Not yet integrated A few OpenCL API calls, most of which introduced with OpenCL 2.1, are not yet integrated with cf4ocl. However, this functionality is still available to client code, because cf4ocl can be used simultaneously with raw OpenCL objects and functions. License Library code is licensed under LGPLv3, while the remaining code (utilities, examples and tests) is licensed under GPLv3. Other useful C frameworks/utilities for OpenCL If cf4ocl does not meet your requirements, take a look at the following projects: Simple OpenCL The OpenCL utility library Computing Language Utility OCL-MLA oclkit ocl-ke cf4ocl maintained by fakenmc Published with GitHub Pages"	"null"	"null"	"The C Framework for OpenCL; a cross-platform object-oriented framework for developing and benchmarking projects. only (library), (other code)."	"true"
"Utilities"	"OpenCL"	"https://www.khronos.org/opencl/"	"The C Framework for OpenCL; a cross-platform object-oriented framework for developing and benchmarking projects. only (library), (other code)."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"75"	"46"	"28"	"GitHub - KhronosGroup/SPIR Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 46 Star 75 Fork 28 KhronosGroup/SPIR Code Issues 3 Pull requests 1 Wiki Pulse Graphs No description or website provided. 40,400 commits 4 branches 0 releases Fetching contributors C++ 76.5% C 10.7% Objective-C 9.3% Objective-C++ 1.1% Python 1.0% HTML 0.9% Other 0.5% C++ C Objective-C Objective-C++ Python HTML Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: spir_12 Switch branches/tags Branches Tags spir_12 spir_20_provisional spirv-1.0 spirv-1.1 Nothing to show Nothing to show New pull request Latest commit fd090c8 Apr 26, 2016 nizhegorodets committed with bader Add spir12 Ignore optimization level provided by user (#35) … Ignore optimization level provided by user Permalink Failed to load latest commit information. INPUTS Revert 'Fix a typo 'iff' => 'if''. iff is an abreviation of if and on… Sep 27, 2012 bindings [clang.py] Add Cursor.get_arguments() Nov 1, 2012 docs Added Documentation and ASan notes, clean-up of emtpy sections, coupl… Dec 20, 2012 examples analyzer-plugin/MainCallChecker.cpp: Fixup corresponding to r167275. Nov 2, 2012 include Add spir12 Ignore optimization level provided by user (#35) Apr 26, 2016 lib Add spir12 Ignore optimization level provided by user (#35) Apr 26, 2016 runtime Pass LLVM_ANDROID_TOOLCHAIN_DIR if set. Oct 24, 2012 test Add spir12 Ignore optimization level provided by user (#35) Apr 26, 2016 tools Merge SPIR generator changes Nov 28, 2013 unittests Fix binding of nodes in case of forEach..() matchers. Nov 11, 2012 utils Remove leftover code. Nov 9, 2012 www [analyzer] Check that the argument to CFMakeCollectable is non-NULL. Nov 7, 2012 .gitignore Add extra vim swap file pattern Oct 9, 2012 CMakeLists.txt CMake: Fix public header search for generating Xcode/MSVC projects. Oct 23, 2012 INSTALL.txt Add minimal INSTALL.txt Sep 13, 2009 LICENSE.TXT Happy new year 2012! Jan 1, 2012 Makefile The top-level clang Makefile is #included into other Makefiles. (sigh… Oct 3, 2012 ModuleInfo.txt Move the ModuleInfo.txt file. Jul 11, 2007 NOTES.txt Fix typo (test commit) Oct 18, 2012 README.md Add spir12 Ignore optimization level provided by user (#35) Apr 26, 2016 README.txt commit access verified, revert change Mar 6, 2012 README.md SPIR generator/Clang Installation Instructions These instructions describe how to build, install and operate SPIR generator Clang. Step 1: Organization SPIR generator/Clang is designed to be built as part of an LLVM build. SPIR generator/Clang is based on LLVM/Clang version 3.2. The LLVM source code could be downloaded from http://www.llvm.org/releases/3.2/llvm-3.2.src.tar.gz. It is also available directly from the LLVM svn server:   svn co http://llvm.org/svn/llvm-project/llvm/tags/RELEASE_32/final llvm Or could be cloned from LLVM git repository:   git clone http://llvm.org/git/llvm.git llvm   cd llvm   git checkout --track -b release_32 remotes/origin/release_32 Assuming that the LLVM source code is located at $LLVM_SRC_ROOT, then the clang source code should be installed as: $LLVM_SRC_ROOT/tools/clang. The directory is not required to be called clang, but doing so will allow the LLVM build system to automatically recognize it and build it along with LLVM.   cd $LLVM_SRC_ROOT/tools   git clone https://github.com/KhronosGroup/SPIR clang   cd clang   git checkout --track -b spir_12 remotes/origin/spir_12 Step 2: Configure and Build LLVM Configure and build your copy of LLVM (see $LLVM_SRC_ROOT/GettingStarted.html for more information). Assuming you installed clang at $LLVM_SRC_ROOT/tools/clang then Clang will automatically be built with LLVM. Otherwise, run make in the Clang source directory to build Clang. Note: currently there might be failures in check_clang project. Step 3: (Optional) Verify Your Build It is a good idea to run the Clang tests to make sure your build works correctly. From inside the Clang build directory, run make test to run the tests. Step 4: Install Clang If you wish to run Clang from the generated binary directory, you may skip this section. From inside the Clang build directory, run make install to install the Clang compiler and header files into the prefix directory selected when LLVM was configured. The Clang compiler is available as clang and clang++. It supports a gcc like command line interface. See the man page for clang (installed into $prefix/share/man/man1) for more information. Step 5: Creating SPIR binaries To create a SPIR binary from a valid OpenCL-C file (.cl), use the following command lines:   clang -cc1 -emit-llvm-bc -triple <triple> <OpenCL compile options> -cl-spir-compile-options ""<OpenCL compile options>"" -include <opencl_spir.h> -o <output> <input> <triple>: for 32 bit SPIR use spir-unknown-unknown, for 64 bit SPIR use spir64-unknown-unknown. Note: <OpenCL compile options> appears twice. The command line option -cl-spir-compile-options ""<OpenCL compile options>"" specifies the compile options that occur in the SPIR metadata. : download opencl_spir.h from https://github.com/KhronosGroup/SPIR-Tools/blob/master/headers/opencl_spir.h -O: -O0 (default) is the only tested option value at the moment. It's assumed by design that all optimizations are executed by SPIR consumer. Reporting issues Bugs/feature requests can be filed via github or Khronos Bugzilla bug tracker. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/KhronosGroup/SPIR"	"The C Framework for OpenCL; a cross-platform object-oriented framework for developing and benchmarking projects. only (library), (other code)."	"true"
"Utilities"	"CommonMark"	"https://github.com/jgm/CommonMark"	"A C implementation of the CommonMark spec.."	"null"	"null"	"null"	"Variety of licenses, all free"	"https://github.com/jgm/CommonMark/blob/master/LICENSE"	"null"	"null"	"3113"	"140"	"177"	"GitHub - jgm/CommonMark: CommonMark spec, with reference implementations in C and JavaScript Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 140 Star 3,113 Fork 177 jgm/CommonMark Code Issues 18 Pull requests 2 Wiki Pulse Graphs CommonMark spec, with reference implementations in C and JavaScript http://commonmark.org 1,618 commits 3 branches 21 releases 57 contributors Python 96.6% Makefile 3.4% Python Makefile Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master mom newformat Nothing to show 0.26 0.25 0.24 0.23 0.22 0.21.1 0.21 0.20 0.19 0.18 0.17 0.16 0.15 0.14 0.13 0.12 0.11 0.10 0.9 0.7 0.6 Nothing to show New pull request Latest commit 91e045c Jul 15, 2016 jgm Bump version to 0.26, update changelog. Permalink Failed to load latest commit information. test spec_tests.py: exit code is sum of failures and errors. Jun 2, 2016 tools make interact more button-like and clearer Jun 4, 2016 .editorconfig Removed JS specific stuff from .editorconfig. Jan 24, 2015 .gitignore Added spec.html to .gitignore. Jun 26, 2015 CommonMark.dtd CommonMark.dtd - allow item in custom_block. Dec 31, 2015 LICENSE Update license year range to 2016 Jan 26, 2016 Makefile New format for spec tests, new lua formatter for specs. Jan 10, 2016 README.md Add closing paranthesis to README.md Mar 16, 2016 alternative-html-blocks.txt Initial commit Aug 13, 2014 changelog.txt Bump version to 0.26, update changelog. Jul 15, 2016 spec.txt Bump version to 0.26, update changelog. Jul 15, 2016 README.md CommonMark CommonMark is a rationalized version of Markdown syntax, with a spec and BSD-licensed reference implementations in C and JavaScript. Try it now! For more details, see http://commonmark.org. This repository contains the spec itself, along with tools for running tests against the spec, and for creating HTML and PDF versions of the spec. The reference implementations live in separate repositories: https://github.com/jgm/cmark (C) https://github.com/jgm/commonmark.js (JavaScript) There is a list of third-party libraries in a dozen different languages here. Running tests against the spec The spec contains over 500 embedded examples which serve as conformance tests. To run the tests using an executable $PROG: python3 test/spec_tests.py --program $PROG  If you want to extract the raw test data from the spec without actually running the tests, you can do: python3 test/spec_tests.py --dump-tests  and you'll get all the tests in JSON format. The spec The source of the spec is spec.txt. This is basically a Markdown file, with code examples written in a shorthand form: ```````````````````````````````` example Markdown source . expected HTML output ````````````````````````````````  To build an HTML version of the spec, do make spec.html. To build a PDF version, do make spec.pdf. For both versions, you must have the lua rock lcmark installed: after installing lua and lua rocks, luarocks install lcmark. For the PDF you must also have xelatex installed. The spec is written from the point of view of the human writer, not the computer reader. It is not an algorithm---an English translation of a computer program---but a declarative description of what counts as a block quote, a code block, and each of the other structural elements that can make up a Markdown document. Because John Gruber's canonical syntax description leaves many aspects of the syntax undetermined, writing a precise spec requires making a large number of decisions, many of them somewhat arbitrary. In making them, we have appealed to existing conventions and considerations of simplicity, readability, expressive power, and consistency. We have tried to ensure that ""normal"" documents in the many incompatible existing implementations of Markdown will render, as far as possible, as their authors intended. And we have tried to make the rules for different elements work together harmoniously. In places where different decisions could have been made (for example, the rules governing list indentation), we have explained the rationale for our choices. In a few cases, we have departed slightly from the canonical syntax description, in ways that we think further the goals of Markdown as stated in that description. For the most part, we have limited ourselves to the basic elements described in Gruber's canonical syntax description, eschewing extensions like footnotes and definition lists. It is important to get the core right before considering such things. However, we have included a visible syntax for line breaks and fenced code blocks. Differences from original Markdown There are only a few places where this spec says things that contradict the canonical syntax description: It allows all punctuation symbols to be backslash-escaped, not just the symbols with special meanings in Markdown. We found that it was just too hard to remember which symbols could be escaped. It introduces an alternative syntax for hard line breaks, a backslash at the end of the line, supplementing the two-spaces-at-the-end-of-line rule. This is motivated by persistent complaints about the “invisible” nature of the two-space rule. Link syntax has been made a bit more predictable (in a backwards-compatible way). For example, Markdown.pl allows single quotes around a title in inline links, but not in reference links. This kind of difference is really hard for users to remember, so the spec allows single quotes in both contexts. The rule for HTML blocks differs, though in most real cases it shouldn't make a difference. (See the section on HTML Blocks for details.) The spec's proposal makes it easy to include Markdown inside HTML block-level tags, if you want to, but also allows you to exclude this. It is also makes parsing much easier, avoiding expensive backtracking. It does not collapse adjacent bird-track blocks into a single blockquote: > this is two  > blockquotes  > this is a single > > blockquote with two paragraphs  Rules for content in lists differ in a few respects, though (as with HTML blocks), most lists in existing documents should render as intended. There is some discussion of the choice points and differences in the subsection of List Items entitled Motivation. We think that the spec's proposal does better than any existing implementation in rendering lists the way a human writer or reader would intuitively understand them. (We could give numerous examples of perfectly natural looking lists that nearly every existing implementation flubs up.) The spec stipulates that two blank lines break out of all list contexts. This is an attempt to deal with issues that often come up when someone wants to have two adjacent lists, or a list followed by an indented code block. Changing bullet characters, or changing from bullets to numbers or vice versa, starts a new list. We think that is almost always going to be the writer's intent. The number that begins an ordered list item may be followed by either . or ). Changing the delimiter style starts a new list. The start number of an ordered list is significant. Fenced code blocks are supported, delimited by either backticks (```) or tildes (~~~). Contributing There is a forum for discussing CommonMark; you should use it instead of github issues for questions and possibly open-ended discussions. Use the github issue tracker only for simple, clear, actionable issues. Authors The spec was written by John MacFarlane, drawing on his experience writing and maintaining Markdown implementations in several languages, including the first Markdown parser not based on regular expression substitutions (pandoc) and the first markdown parsers based on PEG grammars (peg-markdown, lunamark) a detailed examination of the differences between existing Markdown implementations using BabelMark 2, and extensive discussions with David Greenspan, Jeff Atwood, Vicent Marti, Neil Williams, and Benjamin Dumke-von der Ehe. Since the first announcement, many people have contributed ideas. Kārlis Gaņģis was especially helpful in refining the rules for emphasis, strong emphasis, links, and images. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/jgm/CommonMark"	"A C implementation of the CommonMark spec.."	"true"
"Utilities"	"CException"	"https://github.com/ThrowTheSwitch/CException"	"A C implementation of exceptions.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"34"	"16"	"14"	"GitHub - ThrowTheSwitch/CException: Lightweight exception implementation for C Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 16 Star 34 Fork 14 ThrowTheSwitch/CException Code Issues 0 Pull requests 0 Pulse Graphs Lightweight exception implementation for C http://throwtheswitch.org 49 commits 1 branch 0 releases Fetching contributors C 63.2% C++ 27.4% Ruby 6.6% Makefile 2.8% C C++ Ruby Makefile Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Latest commit d426b12 Apr 19, 2016 mvandervoord Merge pull request #5 from austinglaser/master … avoid duplication of CEXCEPTION_GET_ID in Throw macro Permalink Failed to load latest commit information. docs More documentation updates Feb 25, 2016 lib avoid duplication of CEXCEPTION_GET_ID Apr 19, 2016 release Created README.md based on docs. Jul 26, 2014 test modify variable i, to make test slightly more useful Mar 31, 2016 vendor Added ExitTry option to abort a Try block without an error. Feb 25, 2016 .gitattributes Updated gitattributes to handle line endings for us. Feb 25, 2016 .gitignore Ignored .out files Mar 12, 2012 .gitmodules submodule cleanup Jul 26, 2014 .travis.yml Created README.md based on docs. Jul 26, 2014 Gemfile Created README.md based on docs. Jul 26, 2014 Gemfile.lock Created README.md based on docs. Jul 26, 2014 LICENSE.txt dos2unix on files that had CRLF Mar 25, 2016 README.md More documentation updates Feb 25, 2016 Rakefile Renamed rakefile.rb to standard name Rakefile Jul 28, 2014 makefile dos2unix on files that had CRLF Mar 25, 2016 README.md CException - Lightweight exception library for C This Documentation Is Released Under a Creative Commons 3.0 Attribution Share-Alike License CException is simple exception handling in C. It is significantly faster than full-blown C++ exception handling but loses some flexibility. It is portable to any platform supporting setjmp/longjmp. Getting Started > git clone --recursive https://github.com/throwtheswitch/cexception.git > cd cexception > bundle install # Ensures you have all RubyGems needed > bundle execute rake # Run CException tests  Usage So what's it good for? Mostly error handling. Passing errors down a long chain of function calls gets ugly. Sometimes really ugly. So what if you could just specify certain places where you want to handle errors, and all your errors were transferred there? Let's try a lame example: CException uses C standard library functions setjmp and longjmp to operate. As long as the target system has these two functions defined, this library should be useable with very little configuration. It even supports environments where multiple program flows are in use, such as real-time operating systems... we started this project for use in embedded systems... but it obviously can be used for larger systems too. Error Handling with CException: void functionC(void) {   //do some stuff   if (there_was_a_problem) Throw(ERR_BAD_BREATH); //this stuff never gets called because of error  There are about a gajillion exception frameworks using a similar setjmp/longjmp method out there... and there will probably be more in the future. Unfortunately, when we started our last embedded project, all those that existed either (a) did not support multiple tasks (therefore multiple stacks) or (b) were way more complex than we really wanted. CException was born. Why? It's ANSI C, and it beats passing error codes around. You want something simple... CException throws a single id. You can define those ID's to be whatever you like. You might even choose which type that number is for your project. But that's as far as it goes. We weren't interested in passing objects or structs or strings... just simple error codes. Fast. Easy to Use. Easy to Understand. Performance... CException can be configured for single tasking or multitasking. In single tasking, there is very little overhead past the setjmp/longjmp calls (which are already fast). In multitasking, your only additional overhead is the time it takes you to determine a unique task id (0 to num_tasks). How? Code that is to be protected are wrapped in Try { } blocks. The code inside the Try block is protected, meaning that if any Throws occur, program control is directly transferred to the start of the Catch block. The Catch block immediately follows the Try block. It's ignored if no errors have occurred. A numerical exception ID is included with Throw, and is passed into the Catch block. This allows you to handle errors differently or to report which error has occurred... or maybe it just makes debugging easier so you know where the problem was Thrown. Throws can occur from anywhere inside the Try block, directly in the function you're testing or even within function calls (nested as deeply as you like). There can be as many Throws as you like, just remember that execution of the guts of your Try block ends as soon as the first Throw is triggered. Once you throw, you're transferred to the Catch block. A silly example: void SillyExampleWhichPrintsZeroThroughFive(void) {   CEXCEPTION_T e;   int i;   while (i = 0; i < 6; i++) {     Try {       Throw(i);       //This spot is never reached } Catch(e) {       printf(“%i “, e);     } }  Limitations This library was made to be as fast as possible, and provide basic exception handling. It is not a full-blown exception library like C++. Because of this, there are a few limitations that should be observed in order to successfully utilize this library: Do not directly return from within a Try block, nor goto into or out of a Try block. The Try macro allocates some local memory and alters a global pointer. These are cleaned up at the top of the Catch macro. Gotos and returns would bypass some of these steps, resulting in memory leaks or unpredictable behavior. If (a) you change local (stack) variables within your Try block, and (b) wish to make use of the updated values after an exception is thrown, those variables should be made volatile. Note that this is ONLY for locals and ONLY when you need access to them after a Throw. Compilers optimize (and thank goodness they do). There is no way to guarantee that the actual memory location was updated and not just a register unless the variable is marked volatile. Memory which is malloc'd within a Try block is not automatically released when an error is thrown. This will sometimes be desirable, and othertimes may not. It will be the responsibility of the code you put in the Catch block to perform this kind of cleanup. There's just no easy way to track malloc'd memory, etc., without replacing or wrapping malloc calls or something like that. This is a lightweight framework, so these options were not desirable. CException API Try { ... } Try is a macro which starts a protected block. It MUST be followed by a pair of braces or a single protected line (similar to an 'if'), enclosing the data that is to be protected. It MUST be followed by a Catch block (don't worry, you'll get compiler errors to let you know if you mess any of that up). The Try block is your protected block. It contains your main program flow, where you can ignore errors (other than a quick Throw call). You may nest multiple Try blocks if you want to handle errors at multiple levels, and you can even rethrow an error from within a nested Catch. Catch(e) { } Catch is a macro which ends the Try block and starts the error handling block. The Catch block is executed if and only if an exception was thrown while within the Try block. This error was thrown by a Throw call somewhere within Try (or within a function called within Try, or a function called by a function called within Try... you get the idea.). Catch receives a single id of type CEXCEPTION_T which you can ignore or use to handle the error in some way. You may throw errors from within Catches, but they will be caught by a Try wrapping the Catch, not the one immediately preceeding. Throw(e) Throw is the method used to throw an error. Throws should only occur from within a protected (Try...Catch) block, though it may easily be nested many function calls deep without an impact on performance or functionality. Throw takes a single argument, which is an exception id which will be passed to Catch as the reason for the error. If you wish to re-throw an error, this can be done by calling Throw(e) with the error code you just caught. It IS valid to throw from a Catch block. ExitTry() ExitTry is a method used to immediately exit your current Try block but NOT treat this as an error. Don't run the Catch. Just start executing from after the Catch as if nothing had happened. Configuration CException is a mostly portable library. It has one universal dependency, plus some macros which are required if working in a multi-tasking environment. The standard C library setjmp must be available. Since this is part of the standard library, it's all good. If working in a multitasking environment, you need a stack frame for each task. Therefore, you must define methods for obtaining an index into an array of frames and to get the overall number of id's are required. If the OS supports a method to retrieve task ID's, and those tasks are number 0, 1, 2... you are in an ideal situation. Otherwise, a more creative mapping function may be required. Note that this function is likely to be called twice for each protected block and once during a throw. This is the only added overhead in the system. You have options for configuring the library, if the defaults aren't good enough for you. You can add defines at the command prompt directly. You can always include a configuration file before including CException.h. You can make sure CEXCEPTION_USE_CONFIG_FILE is defined, which will force make CException look for CExceptionConfig.h, where you can define whatever you like. However you do it, you can override any or all of the following: CEXCEPTION_T Set this to the type you want your exception id's to be. Defaults to an 'unsigned int'. CEXCEPTION_NONE Set this to a number which will never be an exception id in your system. Defaults to 0x5a5a5a5a. CEXCEPTION_GET_ID If in a multi-tasking environment, this should be set to be a call to the function described in #2 above. It defaults to just return 0 all the time (good for single tasking environments, not so good otherwise). CEXCEPTION_NUM_ID If in a multi-tasking environment, this should be set to the number of ID's required (usually the number of tasks in the system). Defaults to 1 (good for single tasking environments or systems where you will only use this from one task). CEXCEPTION_NO_CATCH_HANDLER (id) This macro can be optionally specified. It allows you to specify code to be called when a Throw is made outside of Try...Catch protection. Consider this the emergency fallback plan for when something has gone terribly wrong. You may also want to include any header files which will commonly be needed by the rest of your application where it uses exception handling here. For example, OS header files or exception codes would be useful. Finally, there are some hook macros which you can implement to inject your own target-specific code in particular places. It is a rare instance where you will need these, but they are here if you need them: CEXCEPTION_HOOK_START_TRY - called immediately before the Try block CEXCEPTION_HOOK_HAPPY_TRY - called immediately after the Try block if no exception was thrown CEXCEPTION_HOOK_AFTER_TRY - called immediately after the Try block OR before an exception is caught CEXCEPTION_HOOK_START_CATCH - called immediately before the catch Testing If you want to validate that CException works with your tools or that it works with your custom configuration, you may want to run the included test suite. This is the test suite (along with real projects we've used it on) that we use to make sure that things actually work the way we claim. The test suite included makes use of the Unity Test Framework. It will require a native C compiler. The example makefile and rakefile both use MinGW's gcc. Modify either to include the proper paths to tools, then run make to compile and run the test application. C_COMPILER - The C compiler to use to perform the tests. C_LIBS - The path to the C libraries (including setjmp). UNITY_DIR - The path to the Unity framework (required to run tests) License This software is licensed under the MIT License: Copyright (c) 2007-2016 Mark VanderVoord Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/ThrowTheSwitch/CException"	"A C implementation of exceptions.."	"true"
"Utilities"	"docopt.c"	"https://github.com/docopt/docopt.c"	"A C implementation of a command-line option parser.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"198"	"33"	"25"	"GitHub - docopt/docopt.c: C-code generator for docopt language. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 33 Star 198 Fork 25 docopt/docopt.c Code Issues 6 Pull requests 3 Wiki Pulse Graphs C-code generator for docopt language. 79 commits 1 branch 0 releases Fetching contributors C 51.2% Python 48.8% C Python Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Latest commit 33ad3bb Dec 12, 2014 keleshev Merge pull request #31 from fxkr/make-docopt_c.py-executable … Marks docopt_c.py as executable. Permalink Failed to load latest commit information. .gitignore Add python/vim files to gitignore. Jun 24, 2012 LICENSE-MIT organizes tree of files and copies license from docopt.py Feb 20, 2013 README.md fix README steps example to work on fresh checkout Mar 7, 2014 docopt.c fixes default option value Mar 7, 2014 docopt.py Update docopt.py to the current master May 25, 2013 docopt_c.py Makes docopt_c.py executable Dec 12, 2014 example.c Changes example to the Naval Fate example Jun 9, 2013 example.docopt Changes example to the Naval Fate example Jun 9, 2013 log.h Remove tests folder Mar 29, 2013 template.c Removes warnings when -Wall is used Jun 28, 2013 test_docopt.c Simplifies parse_* function's arguments Jun 28, 2013 README.md C-code generator for docopt language Note, at this point the code generator handles only options (positional arguments, commands and pattern matching will follow). Step 1. Describe your CLI in docopt language Naval Fate.  Usage:   naval_fate.py ship create <name>...   naval_fate.py ship <name> move <x> <y> [--speed=<kn>]   naval_fate.py ship shoot <x> <y>   naval_fate.py mine (set|remove) <x> <y> [--moored|--drifting]   naval_fate.py --help   naval_fate.py --version  Options:   -h --help     Show this screen.   --version     Show version.   --speed=<kn>  Speed in knots [default: 10].   --moored      Moored (anchored) mine.   --drifting    Drifting mine.  Step 2. Generate the C code $ python docopt_c.py -o docopt.c example.docopt or by using pipe $ cat example.docopt | python docopt_c.py > docopt.c Step 3. Include the generated docopt.c into your program #include ""docopt.c""  int main(int argc, char *argv[]) {     DocoptArgs args = docopt(argc, argv, /* help */ 1, /* version */ ""2.0rc2"");      printf(""Commands\n"");     printf(""    mine == %s\n"", args.mine ? ""true"" : ""false"");     printf(""    move == %s\n"", args.move ? ""true"" : ""false"");     printf(""    create == %s\n"", args.create ? ""true"" : ""false"");     printf(""    remove == %s\n"", args.remove ? ""true"" : ""false"");     printf(""    set == %s\n"", args.set ? ""true"" : ""false"");     printf(""    ship == %s\n"", args.ship ? ""true"" : ""false"");     printf(""    shoot == %s\n"", args.shoot ? ""true"" : ""false"");     printf(""Arguments\n"");     printf(""    x == %s\n"", args.x);     printf(""    y == %s\n"", args.y);     printf(""Flags\n"");     printf(""    --drifting == %s\n"", args.drifting ? ""true"" : ""false"");     printf(""    --help == %s\n"", args.help ? ""true"" : ""false"");     printf(""    --moored == %s\n"", args.moored ? ""true"" : ""false"");     printf(""    --version == %s\n"", args.version ? ""true"" : ""false"");     printf(""Options\n"");     printf(""    --speed == %s\n"", args.speed);     return 0; } Step 4. Profit! $ c99 example.c -o example.out $ ./example.out mine --drifting --speed=20 Commands     mine == true     move == false     create == false     remove == false     set == false     ship == false     shoot == false Arguments     x == (null)     y == (null) Flags     --drifting == true     --help == false     --moored == false     --version == false Options     --speed == 20 Development See the Python version's page for more info on developing. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/docopt/docopt.c"	"A C implementation of a command-line option parser.."	"true"
"Utilities"	"dyncall"	"http://www.dyncall.org/"	"Another foreign function interface library.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"null"	"null"	"null"	"dyncall.org - calling C functions dynamically dyncall library: home - news - download - source/repository - bindings - documentation - license - credits - showcase/users - contact Introduction NEW: Join our news letter and mailing list Receive announcements of dyncall releases, critical bug-fixes and porting news by subscribing to the dyncall-news mailing list. Subscribe with your e-mail address In addition you may want to join the dyncall-talk mailing list for general discussion. The dyncall library encapsulates architecture-, OS- and compiler-specific function call semantics in a virtual bind argument parameters from left to right and then call interface allowing programmers to call C functions in a completely dynamic manner. In other words, instead of calling a function directly, the dyncall library provides a mechanism to push the function parameters manually and to issue the call afterwards. This means, that a program can determine at runtime what function to call, and what parameters to pass to it. The library is written in C and assembly and provides a very simple C interface to program against. The library comes in very handy to power flexible message systems, dynamic function call dispatch mechanisms, closure implementations, to bridge different programming languages, or to simply wrap a ""vararg"" function. When it comes to language bindings, the dyncall library provides a clean and portable C interface to dynamically issue calls to foreign code using small call kernels written in assembly. Instead of providing code for every bridged function call, which unnecessarily results in code bloat, only a couple of instructions are used to invoke every possible call. Example Let's say, we want to make a call to the function: double sqrt(double x); Using the dyncall library, this function would be called as follows: double r; DCCallVM* vm = dcNewCallVM(4096); dcMode(vm, DC_CALL_C_DEFAULT); dcReset(vm); dcArgDouble(vm, 4.2373); r = dcCallDouble(vm, (DCpointer)&sqrt); dcFree(vm); If you already have a DCCallVM object (e.g. for followup calls), this simply boils down to: dcReset(vm); // Init/flush arguments. dcArgDouble(vm, 5.2); // Push/bind argument(s). r = dcCallDouble(vm, (DCpointer)&sqrt); // Call. Note that, by exposing this functionality to a dynamic scripting environment, the latter can gain system programming status to a certain degree. It is easy to see the power one can get by calling a C function directly from within a scripting language. Demonstrative bindings and examples for several different scripting languages are provided with the library. Rough overview of platforms and features The dyncall library runs on many different platforms and operating systems (including Windows, Linux, OpenBSD, FreeBSD, MacOS X, DragonFlyBSD, NetBSD, Plan9, iOS, Haiku, Nintendo DS, Playstation Portable, Solaris, Minix, Raspberry Pi, ReactOS, etc.) and processors (x86, x64, arm (arm & thumb mode), arm64, mips, mips64, ppc32, ppc64, sparc, sparc64, etc.). Most of the platforms' C-calling conventions are supported - including ""vararg"" functions, as well es C++-""thiscalls"" (on some platforms), syscalls (on some platforms), and the multitude of calling conventions on Windows (""fastcall"", ""stdcall"", etc.) or some embedded platforms (e.g. atpcs, eabi, apple, armhf on arm, ...). Most of C99's types are supported for setting up a call, however, structure and union support is still missing (we are working on it, though). Additionally, dyncall comes with dyncallback, a library for callback support (currently missing on some platforms, but working towards complete support for dyncall 1.0), and dynload, to facilitate portable dynamic library symbol loading and access (only for platforms with dynamic library support). The feature matrix below gives a brief overview of the currently supported platforms (as of r0.9). Different colors are used, where a green cell indicates a supported platform, yellow a platform that might work (but is untested) and red a platform that is currently unsupported. Gray cells are combinations that don't exist at the time of writing, or that are not taken into account. Light green cells mark complete feature support, as in dyncall and dyncallback. Dark green means basic support but lacking features (e.g. dyncall support, but not dyncallback). Please note that a green cell (even a light-green one) doesn't imply that all existing calling conventions/features/build tools are supported for that platform (but the most important). For details, refer to the dyncall manual/documentation. For information about how we test and build a majority of the supported platforms, check out dynOS."	"null"	"null"	"Another foreign function interface library.."	"true"
"Utilities"	"FANN"	"http://leenissen.dk/fann/wp/"	"Fast Artifical Neural Network library; an implementation of neural networks. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"592"	"104"	"165"	"GitHub - libfann/fann: Official github repository for Fast Artificial Neural Network Library (FANN) Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 104 Star 592 Fork 165 libfann/fann Code Issues 8 Pull requests 4 Pulse Graphs Official github repository for Fast Artificial Neural Network Library (FANN) 156 commits 4 branches 1 release 19 contributors C++ 77.6% C 12.0% Python 8.5% CMake 1.2% Other 0.7% C++ C Python CMake Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags gh-pages master pr/40 pr/45 Nothing to show 2.2.0 Nothing to show New pull request Latest commit d71d547 Nov 29, 2015 steffennissen ensure that cmake is not dependent on directory it's run in Permalink Failed to load latest commit information. .idea ensure that cmake is not dependent on directory it's run in Nov 29, 2015 VS2010 also get tests to compile with x64 Aug 17, 2014 bin delete some flaky tests Aug 17, 2014 cmake Also add win32 as a possible build target, update ignore lists Aug 3, 2015 datasets Added more examples Jan 21, 2012 docs refactoring of the C++ headers and associated documentation Nov 1, 2015 examples updated email + copyright year Nov 1, 2015 lib/googletest removed old version of google test and added cmake setup. I'm sure th… Oct 31, 2015 src Merge pull request #59 from joelself/Clean Nov 29, 2015 tests fix some tests on travis Nov 29, 2015 .gitignore Also add win32 as a possible build target, update ignore lists Aug 4, 2015 .travis.yml remove clang Nov 29, 2015 CMakeLists.txt ensure that cmake is not dependent on directory it's run in Nov 29, 2015 LICENSE.md move COPYING.txt to more correct name LICENSE.md Nov 15, 2014 README.md Renamed README to .md, and added markdown formatting as well as Insta… Nov 16, 2014 biicode.conf Biicode Dependency Manager support Jan 21, 2015 ignore.bii Biicode Dependency Manager support Jan 21, 2015 README.md Fast Artificial Neural Network Library FANN Fast Artificial Neural Network (FANN) Library is a free open source neural network library, which implements multilayer artificial neural networks in C with support for both fully connected and sparsely connected networks. Cross-platform execution in both fixed and floating point are supported. It includes a framework for easy handling of training data sets. It is easy to use, versatile, well documented, and fast. Bindings to more than 15 programming languages are available. An easy to read introduction article and a reference manual accompanies the library with examples and recommendations on how to use the library. Several graphical user interfaces are also available for the library. FANN Features Multilayer Artificial Neural Network Library in C Backpropagation training (RPROP, Quickprop, Batch, Incremental) Evolving topology training which dynamically builds and trains the ANN (Cascade2) Easy to use (create, train and run an ANN with just three function calls) Fast (up to 150 times faster execution than other libraries) Versatile (possible to adjust many parameters and features on-the-fly) Well documented (An easy to read introduction article, a thorough reference manual, and a 50+ page university report describing the implementation considerations etc.) Cross-platform (configure script for linux and unix, dll files for windows, project files for MSVC++ and Borland compilers are also reported to work) Several different activation functions implemented (including stepwise linear functions for that extra bit of speed) Easy to save and load entire ANNs Several easy to use examples Can use both floating point and fixed point numbers (actually both float, double and int are available) Cache optimized (for that extra bit of speed) Open source, but can still be used in commercial applications (licenced under LGPL) Framework for easy handling of training data sets Graphical Interfaces Language Bindings to a large number of different programming languages Widely used (approximately 100 downloads a day) To Install On Linux From Source First you'll want to clone the repository: git clone https://github.com/libfann/fann.git Once that's finished, navigate to the Root directory. In this case it would be ./fann: cd ./fann Then run CMake cmake . After that, you'll need to use elevated priviledges to install the library: sudo make install That's it! If everything went right, you should see a lot of text, and FANN should be installed! To Learn More To get started with FANN, go to the FANN help site, which will include links to all the available resources. For more information about FANN, please refer to the FANN website Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/libfann/fann"	"Fast Artifical Neural Network library; an implementation of neural networks. only."	"true"
"Utilities"	"Firm"	"http://pp.ipd.kit.edu/firm/Index"	"A C library that provides a graph-based intermediate representation, optimizations and assembly code generation suitable for use in compilers. Comes with an example C front-end under the same license. only."	"null"	"null"	"null"	"GNU LGPLv2.1"	"http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"	"null"	"null"	"null"	"null"	"null"	"libFirm - optimization and machine code generation About Features Download Documentation Projects Development Contact Publications Firm is a C-library that provides a graph-based intermediate representation, optimizations, and assembly code generation suitable for use in compilers. Features Completely graph-based, source- and target-independent intermediate representation in SSA form Accompanying GCC-compatible C frontend with full C99 support Extensive set of optimizations High-quality register allocation Mature code generation support for x86 (32-bit) and SPARC For a more complete list of features, see our Features page. Interested? If you're interested in trying out Firm, visit the Download page to get you started. You can also try out Firm in your browser! Mailing list: firm@ipd.info.uni-karlsruhe.de | IRC: #firm on Freenode | Bugtracker"	"null"	"null"	"A C library that provides a graph-based intermediate representation, optimizations and assembly code generation suitable for use in compilers. Comes with an example C front-end under the same license. only."	"true"
"Utilities"	"gjrand"	"https://sourceforge.net/projects/gjrand/"	"A library of random-number generation routines. or (user's choice)."	"null"	"null"	"null"	"GNU GPLv3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"gjrand random numbers download | SourceForge.net SourceForge Browse Enterprise Blog Deals Help Create Log In or Join Solution Centers Go Parallel Resources Newsletters Cloud Storage Providers Business VoIP Providers Call Center Providers Home Browse Development Algorithms gjrand random numbers gjrand random numbers alpha Brought to you by: geronimojones Summary Files Reviews Support Wiki News Discussion ★ Add a Review 1 Download (This Week) Last Update: 2014-11-28 Download gjrand.4.2.1.tar.bz2 Browse All Files Description Programmer's library for random numbers. Also random number generator testing code. Intended for simulation, games and ""Monte-Carlo"" algorithms. gjrand random numbers Web Site Categories Algorithms, Mathematics, Simulations License GNU General Public License version 2.0 (GPLv2) KEEP ME UPDATED By clicking on ""Follow"" below, you are agreeing to the Terms of Use and the Privacy Policy. Get notifications on updates for this project. Get newsletters with site news, white paper/events resources, and sponsored content from our partners. Invalid email address. Please try again. Sent to None. Follow You seem to have CSS turned off. Please don't fill out this field. You seem to have CSS turned off. Please don't fill out this field. Write a Review User Reviews Be the first to post a review of gjrand random numbers! Additional Project Details Intended Audience Developers User Interface Command-line Programming Language C Registered 2005-02-16 Recommended Projects Joker Random Number Generator LavaRnd random number generator Monte Carlo Machine Learning Library Deals Report inappropriate content Thanks for helping keep SourceForge clean. Screenshot instructions: Windows Mac Red Hat Linux   Ubuntu Click URL instructions: Right-click on ad, choose ""Copy Link"", then paste here → (This may not be possible with some types of ads) More information about our ad policies X You seem to have CSS turned off. Please don't fill out this field. You seem to have CSS turned off. Please don't fill out this field. Briefly describe the problem (required): Upload screenshot of ad (required): Select a file, or drag & drop file here. ✔ ✘ Please provide the ad click URL, if possible: SourceForge About Site Status @sfnet_ops Find and Develop Software Create a Project Software Directory Top Downloaded Projects Community Blog @sourceforge Resources Help Site Documentation Support Request © 2016 Slashdot Media. All Rights Reserved. Terms Privacy Opt Out Choices Advertise Get latest updates about Open Source Projects, Conferences and News. Sign up for the SourceForge newsletter: I agree to receive quotes, newsletters and other information from sourceforge.net and its partners regarding IT services and products. I understand that I can withdraw my consent at any time. Please refer to our Privacy Policy or Contact Us for more details You seem to have CSS turned off. Please don't fill out this field. You seem to have CSS turned off. Please don't fill out this field. No, thanks Screenshots can attract more users to your project. Features can attract more users to your project."	"null"	"null"	"A library of random-number generation routines. or (user's choice)."	"true"
"Utilities"	"GNU FreeIPMI"	"https://gnu.org/software/freeipmi/index.html"	"An in-band and out-of-band IPMI implementation. only."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"FreeIPMI - Home Home Project Download Documentation Mailing List Links Core Team NEWS Mon May 23 2016 Freeipmi 1.5.2 released. Tue Dec 01 2015 Freeipmi 1.5.1 released. Fri Nov 13 2015 Freeipmi 1.5.0.beta1 released. Thu Oct 29 2015 Freeipmi 1.4.11 released. Tue Oct 20 2015 Freeipmi 1.4.10 released. Mon Jun 01 2015 Freeipmi 1.4.9 released. Wed Jan 07 2015 Freeipmi 1.4.8 released. Wed Dec 10 2014 Freeipmi 1.4.7 released. Wed Oct 29 2014 Freeipmi 1.4.6 released. Mon Jul 28 2014 Freeipmi 1.4.5 released. Fri Jun 27 2014 Freeipmi 1.4.4 released. Wed May 7 2014 Freeipmi 1.4.3 released. Tue May 6 2014 Freeipmi 1.4.2 released. Mon Mar 3 2014 Freeipmi 1.4.1 released. Fri Jan 24 2014 Freeipmi 1.4.0.beta0 released. Tue Dec 12 2013 Freeipmi 1.3.4 released. Tue Oct 29 2013 Freeipmi 1.3.3 released. Thu Sep 10 2013 Freeipmi 1.3.2 released. Thu Aug 22 2013 Freeipmi 1.3.1 released. Wed Jul 17 2013 Freeipmi 1.2.9 released. Fri Jun 21 2013 Freeipmi 1.2.8 released. Wed May 29 2013 Freeipmi 1.3.0 Beta0 released. Thur May 16 2013 Freeipmi 1.2.7 released. Mon Apr 29 2013 Freeipmi 1.2.6 released. Tue Feb 26 2013 Freeipmi 1.2.5 released. Thu Jan 10 2013 Freeipmi 1.2.4 released. Wed Nov 14 2012 Freeipmi 1.2.3 released. Tue Oct 02 2012 Freeipmi 1.2.2 released. Wed Aug 22 2012 Freeipmi 1.2.1 released. FreeIPMI FreeIPMI provides in-band and out-of-band IPMI software based on the IPMI v1.5/2.0 specification. The IPMI specification defines a set of interfaces for platform management and is implemented by a number vendors for system management. The features of IPMI that most users will be interested in are sensor monitoring, system event monitoring, power control, and serial-over-LAN (SOL). The FreeIPMI tools and libraries listed below should provide users with the ability to access and utilize these and many other features. A number of useful features for large HPC or cluster environments have also been implemented into FreeIPMI. See the README or FAQ for more info. The FreeIPMI project currently includes the following tools and libraries: Project Tools Bmc-info A tool to read information about a BMC such as device version numbers, device support, and globally unique IDs (guids). (example output) Bmc-watchdog A tool/daemon to manage a BMC Watchdog. This tool is typically used for system timeout management and automatic system restarts in the event of a system crash. Ipmi-chassis A tool to manage/monitor a chassis, such as chassis power, identification (i.e. LED control), and status. Ipmi-fru A tool to read field replaceable unit (FRU) information from a motherboard/machine. (example output) Ipmi-sel A tool to read and manage IPMI System Event Log (SEL) records. SEL records store system event information and may be useful for debugging problems. (example output, example output w/ event state) Ipmi-sensors A tool to read IPMI sensor readings and sensor data repository (SDR) information. (example output, example output w/ sensor state) Ipmipower A tool for remote power control. Ipmiconsole A tool for Serial-over-Lan (SOL) console access. Ipmi-config A tool to configure BMC and IPMI information. In can be used to configured usernames, passwords, networking information, security, Serial-over-LAN (SOL), Platform Event Filtering (PEF), boot devices, power restoration policy, sensor thresholds, sensor events, and many more configuration options. (example core config, PEF config, Chassis config, Sensors config) Ipmi-raw A tool that provides hex input/output of IPMI commands. Ipmi-locate A tool that can probe for information about a BMC device, such as device addresses or IPMI version support. (example output) Ipmi-pet A tool to parse and interpret Platform Event Traps (PET). Ipmi-dcmi A tool to perform Data Center Manageability Interface (DCMI) IPMI extension commands. Supports extensions for asset management and power usage management. Bmc-device A tool to perform advanced BMC commands, such as resetting the BMC, configuring ACPI, configuring SDR/SEL time, manually generating events, re-arming sensors, and configuring manufacturer settings. Ipmiping An IPMI ping tool for debugging. (example output) Rmcpping A RMCP ping tool for debugging. (example output) Ipmi-oem An IPMI tool for OEM specific commands. Ipmidetect/Ipmidetectd A tool and daemon for IPMI node detection. Ipmiseld A daemon that regularly polls the SEL and stores the events to the local syslog. Project Libraries Libfreeipmi A C library that includes KCS, SSIF, and OpenIPMI Linux, and Solaris BMC drivers, IPMI 1.5 and IPMI 2.0 LAN communication interfaces, IPMI packet building utilities, IPMI command utilities, and utilities for reading/interpreting/managing IPMI. Libipmiconsole A library for Serial-over-Lan (SOL) console access. SOL console access is abstracted into a file descriptor interface, so users may read and write console data through a file descriptor. Libipmimonitoring A library for sensor monitoring and interpretation. Sensor monitoring and interpretation of those sensors is abstracted into an API with an iterator interface. Libipmidetect A library for IPMI node detection. Last Update: 12:02:39 PM Mon Mar 03, 2014 © 2004-2008 FreeIPMI Core Team"	"null"	"null"	"An in-band and out-of-band IPMI implementation. only."	"true"
"Utilities"	"GNU gperf"	"https://www.gnu.org/software/gperf/"	"A perfect hash function generator, given a list of strings. Outputs C code. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"gperf - GNU Project - Free Software Foundation (FSF) gperf Introduction | Get the Software Introduction to gperf GNU gperf is a perfect hash function generator. For a given list of strings, it produces a hash function and hash table, in form of C or C++ code, for looking up a value depending on the input string. The hash function is perfect, which means that the hash table has no collisions, and the hash table lookup needs a single string comparison only. GNU gperf is highly customizable. There are options for generating C or C++ code, for emitting switch statements or nested ifs instead of a hash table, and for tuning the algorithm employed by gperf. Online Manual is available at www.gnu.org/software/gperf/manual/gperf.html Downloading gperf gperf can be found on in the subdirectory /gnu/gperf/ on your favorite GNU mirror. For other ways to obtain gperf, please read How to get GNU Software. The latest release is http://ftp.gnu.org/pub/gnu/gperf/gperf-3.0.4.tar.gz The latest development sources can be obtained through the savannah project. Return to GNU's home page. Please send general FSF & GNU inquiries to <gnu@gnu.org>. There are also other ways to contact the FSF. Please send broken links and other corrections or suggestions to <bug-gnu-gperf-antispam@antispam.gnu.org>. Copyright (C) 1998, 2010 Free Software Foundation, Inc. Verbatim copying and distribution of this entire article is permitted in any medium, provided this notice is preserved. Updated: $Date: 2010/01/31 14:50:00 $ $Author: haible $"	"null"	"null"	"A perfect hash function generator, given a list of strings. Outputs C code. or later."	"true"
"Utilities"	"GNU Libffcall"	"https://gnu.org/software/libffcall/"	"A collection of libraries for building foreign function interfaces. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"Libffcall - GNU Project - Free Software Foundation Skip to main text Set language English [en] The  9th HACKERS MEETING  will be held in Rennes (France) from August 18 to 20. JOIN THE FSF Free Software Supporter GNU Operating System Sponsored by the Free Software Foundation About GNU Philosophy Licenses Education = Software = Documentation Help GNU GNU Libffcall GNU Libffcall is a collection of four libraries which can be used to build foreign function call interfaces in embedded interpreters: Avcall Calling C functions with variable arguments. Vacall C functions accepting variable argument prototypes. Trampoline Closures as first-class C functions. Callback Closures with variable arguments as first-class C functions (a reentrant combination of vacall and trampoline). Downloading Libffcall For now, get the libffcall sources from the CVS. Mailing lists and Updates GNU Libffcall has a development and general discussion mailing list: <libffcall@gnu.org>. You can subscribe through the web interface. This is the main discussion list, and is used to discuss most aspects of Libffcall, including development, enhancement requests and bug reports. Announcements about Libffcall and most other GNU software are made on libffcall (archive). Security reports that should not be made immediately public can be sent directly to the maintainer. If there is no response to an urgent issue, you can escalate to the general security mailing list for advice. Getting involved Development of Libffcall, and GNU in general, is a volunteer effort, and you can contribute. For information, please read How to help GNU. If you'd like to get involved, it's a good idea to join the discussion mailing list (see above). Development For development sources, issue trackers, and other information, please see the Libffcall project page at savannah.gnu.org. Maintainer GNU Libffcall is currently being maintained by Avneet Kaur. Please use the mailing list for contact. Licensing Libffcall is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 3 of the License, or (at your option) any later version. GNU home page FSF home page GNU Art GNU's Who? Free Software Directory Hardware Site map “Our mission is to preserve, protect and promote the freedom to use, study, copy, modify, and redistribute computer software, and to defend the rights of Free Software users.” The Free Software Foundation is the principal organizational sponsor of the GNU Operating System. Support GNU and the FSF by buying manuals and gear, joining the FSF as an associate member, or making a donation, either directly to the FSF or via Flattr. back to top Please send general FSF & GNU inquiries to <gnu@gnu.org>. There are also other ways to contact the FSF. Broken links and other corrections or suggestions can be sent to <libffcall@gnu.org>. Please see the Translations README for information on coordinating and submitting translations of this article. Copyright © 2014 Free Software Foundation, Inc. This page is licensed under a Creative Commons Attribution-NoDerivs 3.0 United States License. Copyright Infringement Notification Updated: $Date: 2014/02/14 14:30:57 $"	"null"	"null"	"A collection of libraries for building foreign function interfaces. or later."	"true"
"Utilities"	"gperftools"	"https://github.com/gperftools/gperftools"	"A collection of utilities for measuring and improving performance.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"874"	"121"	"238"	"GitHub - gperftools/gperftools: Main gperftools repository Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 121 Star 874 Fork 238 gperftools/gperftools Code Issues 81 Pull requests 8 Wiki Pulse Graphs Main gperftools repository 463 commits 7 branches 52 releases 32 contributors C++ 81.6% Perl 7.1% C 3.7% Makefile 2.9% M4 2.2% Shell 1.8% Other 0.7% C++ Perl C Makefile M4 Shell Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags at7_0-release at7_1-release at8_0-release master-issue_626 master rzinsly-master wip-from-alk-for-review Nothing to show perftools-1.6 perftools-1.5 perftools-1.3 perftools-1.2 perftools-1.1 perftools-1.0 perftools-1.0rc2 perftools-1.0rc1 perftools-0.99.2 perftools-0.99.1 perftools-0.99 perftools-0.98 perftools-0.97 perftools-0.96 perftools-0.95.1 perftools-0.95 perftools-0.94.1 perftools-0.94 perftools-0.93 perftools-0.92 perftools-0.91 perftools-0.90 perftools-0.8 perftools-0.7 perftools-0.6 perftools-0.5 perftools-0.4 perftools-0.3 perftools-0.2 perftools-0.1 gperftools-2.5 gperftools-2.4.91 gperftools-2.4.90 gperftools-2.4 gperftools-2.3.90 gperftools-2.3 gperftools-2.2.90 gperftools-2.2.1 gperftools-2.2 gperftools-2.1.90 gperftools-2.1 gperftools-2.0 google-perftools-1.10 google-perftools-1.9.1 google-perftools-1.9 google-perftools-1.8.3 google-perftools-1.8.2 google-perftools-1.8.1 google-perftools-1.8 google-perftools-1.7 google-perftools-1.5 HSD Nothing to show New pull request Latest commit eb474c9 Jul 3, 2016 alk Summary: support gcc atomic ops on clang too … Clang actually does support __atomic_XXX atomic ops builtins but does not advertise itselt as gcc 4.7 or later. So we now detect clang separetely.  We're enabling gcc atomic ops on clang >= 3.4 since this is the oldest version that I can test.  This should fix issue #797. Permalink Failed to load latest commit information. benchmark added binary_trees benchmark Nov 21, 2015 doc fixed default value of HEAP_PROFILER_TIME_INTERVAL in .html doc Jan 10, 2015 m4 Add support for 31-bit s390; merge linux_syscall_support.h changes fr… Jun 25, 2016 packages bump version to 2.1 Jul 30, 2013 src Summary: support gcc atomic ops on clang too Jul 3, 2016 vsprojects unbreak compilation with visual studio Mar 5, 2016 .gitignore added malloc_bench_shared_full Feb 6, 2016 .travis.yml added simple .travis.yml config Mar 13, 2016 AUTHORS Fri Feb 03 15:40:45 2012 Google Inc. <google-perftools@googlegroups.com> Feb 4, 2012 COPYING Wed Jun 14 15:11:14 2006 Google Inc. <opensource@google.com> Mar 22, 2007 ChangeLog Autogenerate ChangeLog from git on make dist Jun 25, 2016 ChangeLog.old renamed ChangeLog to ChangeLog.old Jun 25, 2016 INSTALL Clarify that only tcmalloc_minimal is supported on Windows. May 9, 2015 Makefile.am Autogenerate ChangeLog from git on make dist Jun 25, 2016 NEWS bumped version up to 2.5 Mar 12, 2016 README Update README Jun 25, 2016 README_windows.txt Clarify that only tcmalloc_minimal is supported on Windows. May 9, 2015 TODO Tue Mar 18 14:30:44 2008 Google Inc. <opensource@google.com> Mar 19, 2008 autogen.sh issue-503: removed checked in configure and other auto* products Mar 11, 2013 configure.ac Add support for 31-bit s390; merge linux_syscall_support.h changes fr… Jun 26, 2016 gperftools.sln Adds system-alloc_unittest Visual Studio project Sep 21, 2013 README gperftools ---------- (originally Google Performance Tools)  The fastest malloc we’ve seen; works particularly well with threads and STL. Also: thread-friendly heap-checker, heap-profiler, and cpu-profiler.   OVERVIEW ---------  gperftools is a collection of a high-performance multi-threaded malloc() implementation, plus some pretty nifty performance analysis tools.  gperftools is distributed under the terms of the BSD License. Join our mailing list at gperftools@googlegroups.com for updates: https://groups.google.com/forum/#!forum/gperftools  gperftools was original home for pprof program. But do note that original pprof (which is still included with gperftools) is now deprecated in favor of golang version at https://github.com/google/pprof   TCMALLOC -------- Just link in -ltcmalloc or -ltcmalloc_minimal to get the advantages of tcmalloc -- a replacement for malloc and new.  See below for some environment variables you can use with tcmalloc, as well.  tcmalloc functionality is available on all systems we've tested; see INSTALL for more details.  See README_windows.txt for instructions on using tcmalloc on Windows.  NOTE: When compiling with programs with gcc, that you plan to link with libtcmalloc, it's safest to pass in the flags   -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free  when compiling.  gcc makes some optimizations assuming it is using its own, built-in malloc; that assumption obviously isn't true with tcmalloc.  In practice, we haven't seen any problems with this, but the expected risk is highest for users who register their own malloc hooks with tcmalloc (using gperftools/malloc_hook.h).  The risk is lowest for folks who use tcmalloc_minimal (or, of course, who pass in the above flags :-) ).   HEAP PROFILER ------------- See doc/heap-profiler.html for information about how to use tcmalloc's heap profiler and analyze its output.  As a quick-start, do the following after installing this package:  1) Link your executable with -ltcmalloc 2) Run your executable with the HEAPPROFILE environment var set:      $ HEAPPROFILE=/tmp/heapprof <path/to/binary> [binary args] 3) Run pprof to analyze the heap usage      $ pprof <path/to/binary> /tmp/heapprof.0045.heap  # run 'ls' to see options      $ pprof --gv <path/to/binary> /tmp/heapprof.0045.heap  You can also use LD_PRELOAD to heap-profile an executable that you didn't compile.  There are other environment variables, besides HEAPPROFILE, you can set to adjust the heap-profiler behavior; c.f. ""ENVIRONMENT VARIABLES"" below.  The heap profiler is available on all unix-based systems we've tested; see INSTALL for more details.  It is not currently available on Windows.   HEAP CHECKER ------------ See doc/heap-checker.html for information about how to use tcmalloc's heap checker.  In order to catch all heap leaks, tcmalloc must be linked *last* into your executable.  The heap checker may mischaracterize some memory accesses in libraries listed after it on the link line.  For instance, it may report these libraries as leaking memory when they're not. (See the source code for more details.)  Here's a quick-start for how to use:  As a quick-start, do the following after installing this package:  1) Link your executable with -ltcmalloc 2) Run your executable with the HEAPCHECK environment var set:      $ HEAPCHECK=1 <path/to/binary> [binary args]  Other values for HEAPCHECK: normal (equivalent to ""1""), strict, draconian  You can also use LD_PRELOAD to heap-check an executable that you didn't compile.  The heap checker is only available on Linux at this time; see INSTALL for more details.   CPU PROFILER ------------ See doc/cpu-profiler.html for information about how to use the CPU profiler and analyze its output.  As a quick-start, do the following after installing this package:  1) Link your executable with -lprofiler 2) Run your executable with the CPUPROFILE environment var set:      $ CPUPROFILE=/tmp/prof.out <path/to/binary> [binary args] 3) Run pprof to analyze the CPU usage      $ pprof <path/to/binary> /tmp/prof.out      # -pg-like text output      $ pprof --gv <path/to/binary> /tmp/prof.out # really cool graphical output  There are other environment variables, besides CPUPROFILE, you can set to adjust the cpu-profiler behavior; cf ""ENVIRONMENT VARIABLES"" below.  The CPU profiler is available on all unix-based systems we've tested; see INSTALL for more details.  It is not currently available on Windows.  NOTE: CPU profiling doesn't work after fork (unless you immediately       do an exec()-like call afterwards).  Furthermore, if you do       fork, and the child calls exit(), it may corrupt the profile       data.  You can use _exit() to work around this.  We hope to have       a fix for both problems in the next release of perftools       (hopefully perftools 1.2).   EVERYTHING IN ONE ----------------- If you want the CPU profiler, heap profiler, and heap leak-checker to all be available for your application, you can do:    gcc -o myapp ... -lprofiler -ltcmalloc  However, if you have a reason to use the static versions of the library, this two-library linking won't work:    gcc -o myapp ... /usr/lib/libprofiler.a /usr/lib/libtcmalloc.a  # errors!  Instead, use the special libtcmalloc_and_profiler library, which we make for just this purpose:    gcc -o myapp ... /usr/lib/libtcmalloc_and_profiler.a   CONFIGURATION OPTIONS --------------------- For advanced users, there are several flags you can pass to './configure' that tweak tcmalloc performace.  (These are in addition to the environment variables you can set at runtime to affect tcmalloc, described below.)  See the INSTALL file for details.   ENVIRONMENT VARIABLES --------------------- The cpu profiler, heap checker, and heap profiler will lie dormant, using no memory or CPU, until you turn them on.  (Thus, there's no harm in linking -lprofiler into every application, and also -ltcmalloc assuming you're ok using the non-libc malloc library.)  The easiest way to turn them on is by setting the appropriate environment variables.  We have several variables that let you enable/disable features as well as tweak parameters.  Here are some of the most important variables:  HEAPPROFILE=<pre> -- turns on heap profiling and dumps data using this prefix HEAPCHECK=<type>  -- turns on heap checking with strictness 'type' CPUPROFILE=<file> -- turns on cpu profiling and dumps data to this file. PROFILESELECTED=1 -- if set, cpu-profiler will only profile regions of code                      surrounded with ProfilerEnable()/ProfilerDisable(). CPUPROFILE_FREQUENCY=x-- how many interrupts/second the cpu-profiler samples.  TCMALLOC_DEBUG=<level> -- the higher level, the more messages malloc emits MALLOCSTATS=<level>    -- prints memory-use stats at program-exit  For a full list of variables, see the documentation pages:    doc/cpuprofile.html    doc/heapprofile.html    doc/heap_checker.html   COMPILING ON NON-LINUX SYSTEMS ------------------------------  Perftools was developed and tested on x86 Linux systems, and it works in its full generality only on those systems.  However, we've successfully ported much of the tcmalloc library to FreeBSD, Solaris x86, and Darwin (Mac OS X) x86 and ppc; and we've ported the basic functionality in tcmalloc_minimal to Windows.  See INSTALL for details. See README_windows.txt for details on the Windows port.   PERFORMANCE -----------  If you're interested in some third-party comparisons of tcmalloc to other malloc libraries, here are a few web pages that have been brought to our attention.  The first discusses the effect of using various malloc libraries on OpenLDAP.  The second compares tcmalloc to win32's malloc.   http://www.highlandsun.com/hyc/malloc/   http://gaiacrtn.free.fr/articles/win32perftools.html  It's possible to build tcmalloc in a way that trades off faster performance (particularly for deletes) at the cost of more memory fragmentation (that is, more unusable memory on your system).  See the INSTALL file for details.   OLD SYSTEM ISSUES -----------------  When compiling perftools on some old systems, like RedHat 8, you may get an error like this:     ___tls_get_addr: symbol not found  This means that you have a system where some parts are updated enough to support Thread Local Storage, but others are not.  The perftools configure script can't always detect this kind of case, leading to that error.  To fix it, just comment out (or delete) the line    #define HAVE_TLS 1 in your config.h file before building.   64-BIT ISSUES -------------  There are two issues that can cause program hangs or crashes on x86_64 64-bit systems, which use the libunwind library to get stack-traces. Neither issue should affect the core tcmalloc library; they both affect the perftools tools such as cpu-profiler, heap-checker, and heap-profiler.  1) Some libc's -- at least glibc 2.4 on x86_64 -- have a bug where the libc function dl_iterate_phdr() acquires its locks in the wrong order.  This bug should not affect tcmalloc, but may cause occasional deadlock with the cpu-profiler, heap-profiler, and heap-checker. Its likeliness increases the more dlopen() commands an executable has. Most executables don't have any, though several library routines like getgrgid() call dlopen() behind the scenes.  2) On x86-64 64-bit systems, while tcmalloc itself works fine, the cpu-profiler tool is unreliable: it will sometimes work, but sometimes cause a segfault.  I'll explain the problem first, and then some workarounds.  Note that this only affects the cpu-profiler, which is a gperftools feature you must turn on manually by setting the CPUPROFILE environment variable.  If you do not turn on cpu-profiling, you shouldn't see any crashes due to perftools.  The gory details: The underlying problem is in the backtrace() function, which is a built-in function in libc. Backtracing is fairly straightforward in the normal case, but can run into problems when having to backtrace across a signal frame. Unfortunately, the cpu-profiler uses signals in order to register a profiling event, so every backtrace that the profiler does crosses a signal frame.  In our experience, the only time there is trouble is when the signal fires in the middle of pthread_mutex_lock.  pthread_mutex_lock is called quite a bit from system libraries, particularly at program startup and when creating a new thread.  The solution: The dwarf debugging format has support for 'cfi annotations', which make it easy to recognize a signal frame.  Some OS distributions, such as Fedora and gentoo 2007.0, already have added cfi annotations to their libc.  A future version of libunwind should recognize these annotations; these systems should not see any crashses.  Workarounds: If you see problems with crashes when running the cpu-profiler, consider inserting ProfilerStart()/ProfilerStop() into your code, rather than setting CPUPROFILE.  This will profile only those sections of the codebase.  Though we haven't done much testing, in theory this should reduce the chance of crashes by limiting the signal generation to only a small part of the codebase.  Ideally, you would not use ProfilerStart()/ProfilerStop() around code that spawns new threads, or is otherwise likely to cause a call to pthread_mutex_lock!  --- 17 May 2011  Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/gperftools/gperftools"	"A collection of utilities for measuring and improving performance.."	"true"
"Utilities"	"hammer"	"https://github.com/abiggerhammer/hammer"	"Parser combinators for binary formats. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"144"	"10"	"42"	"GitHub - abiggerhammer/hammer: Parser combinators for binary formats, in C. Yes, in C. What? Don't look at me like that. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 10 Star 144 Fork 42 abiggerhammer/hammer Code Issues 6 Pull requests 2 Pulse Graphs Parser combinators for binary formats, in C. Yes, in C. What? Don't look at me like that. 1,167 commits 11 branches 0 releases 12 contributors C 65.8% Ruby 7.0% Python 5.8% C# 4.7% PHP 4.6% C++ 4.2% Other 7.9% C Ruby Python C# PHP C++ Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags c++ cxx java-bindings luajit master php-bindings python-bindings refactor-build regex static-analysis windows-vs2013 Nothing to show Nothing to show New pull request Latest commit 9ee4fbd Feb 25, 2016 abiggerhammer backports swig is named swig3.0, so fix that across bindings Permalink Failed to load latest commit information. contrib Added NetBSD and OpenBSD ports Apr 22, 2014 docs replaced man page as asciidoc instead of groff, changed to section 3 … Apr 29, 2014 examples Changed generating functions printouts to be copy-paste-able into Sag… Apr 10, 2015 jni Switched sequence and choice in JNI to varargs May 16, 2013 lib Fixed character parsing Jan 11, 2014 src backports swig is named swig3.0, so fix that across bindings Feb 25, 2016 tools Update list of files to compile on windows Aug 16, 2015 .gitignore Allow in-place build via scons --in-place Nov 22, 2013 .travis.yml swig3.0, not swig Feb 25, 2016 Doxyfile Remove absolute paths from Doxyfile Dec 13, 2013 HACKING Test suite now builds Jan 4, 2014 LICENSE Licensing under GPL v2. Apr 23, 2012 Makefile Added new build system Jul 10, 2013 NOTES Added benchmark skeleton, and at least stubs for all of the necessary… Nov 2, 2012 README.md Mention user guide in README Nov 30, 2014 SConstruct now both clang and gcc have coverage without any dumb hacks Oct 4, 2015 TODO Added benchmark skeleton, and at least stubs for all of the necessary… Nov 2, 2012 appveyor.yml Remove now unneeded workaround Sep 22, 2015 common.mk Added new build system Jul 10, 2013 config.mk Refactored tests; make just builds library, make test builds/runs tests Nov 13, 2012 libhammer.pc.in Fix include path Dec 2, 2013 README.md Hammer is a parsing library. Like many modern parsing libraries, it provides a parser combinator interface for writing grammars as inline domain-specific languages, but Hammer also provides a variety of parsing backends. It's also bit-oriented rather than character-oriented, making it ideal for parsing binary data such as images, network packets, audio, and executables. Hammer is written in C, but will provide bindings for other languages. If you don't see a language you're interested in on the list, just ask. Hammer currently builds under Linux and OS X. (Windows is coming.) Features Bit-oriented -- grammars can include single-bit flags or multi-bit constructs that span character boundaries, with no hassle Thread-safe, reentrant Benchmarking for parsing backends -- determine empirically which backend will be most time-efficient for your grammar Parsing backends: Packrat parsing LL(k) GLR LALR Regular expressions Language bindings: C++ Java (not currently building; give us a few days) Python Ruby Perl Go PHP .NET Installing Prerequisites SCons Optional Dependencies pkg-config (for scons test) glib-2.0 (>= 2.29) (for scons test) glib-2.0-dev (for scons test) swig (for Python/Perl/PHP bindings; Perl requires >= 2.0.8) python2.7-dev (for Python bindings) a JDK (for Java bindings) a working phpenv configuration (for PHP bindings) Ruby >= 1.9.3 and bundler, for the Ruby bindings mono-devel and mono-mcs (>= 3.0.6) (for .NET bindings) nunit (for testing .NET bindings) To build, type scons. To run the built-in test suite, type scons test. For a debug build, add --variant=debug. To build bindings, pass a ""bindings"" argument to scons, e.g. scons bindings=python. scons bindings=python test will build Python bindings and run tests for both C and Python. --variant=debug is valid here too. You can build more than one set of bindings at a time; just separate them with commas, e.g. scons bindings=python,perl. For Java, if jni.h and jni_md.h aren't already somewhere on your include path, prepend C_INCLUDE_PATH=/path/to/jdk/include to that. To make Hammer available system-wide, use scons install. This places include files in /usr/local/include/hammer and library files in /usr/local/lib by default; to install elsewhere, add a prefix=<destination> argument, e.g. scons install prefix=$HOME. A suitable bindings= argument will install bindings in whatever place your system thinks is appropriate. Usage Just #include <hammer/hammer.h> (also #include <hammer/glue.h> if you plan to use any of the convenience macros) and link with -lhammer. If you've installed Hammer system-wide, you can use pkg-config in the usual way. For documentation, see the user guide. Examples The examples/ directory contains some simple examples, currently including: base64 DNS Known Issues The Python bindings only work with Python 2.7. SCons doesn't work with Python 3, and PyCapsule isn't available in 2.6 and below, so 2.7 is all you get. Sorry about that. The requirement for SWIG >= 2.0.8 for Perl bindings is due to a known bug in SWIG. ppa:dns/irc has backports of SWIG 2.0.8 for Ubuntu versions 10.04-12.10; you can also build SWIG from source. The .NET bindings are for Mono 3.0.6 and greater. If you're on a Debian-based distro that only provides Mono 2 (e.g., Ubuntu 12.04), there are backports for 3.0.x, and a 3.2.x PPA maintained by the Mono team. Community Please join us at #hammer on irc.upstandinghackers.com if you have any questions or just want to talk about parsing. Contact You can also email us at hammer@upstandinghackers.com. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/abiggerhammer/hammer"	"Parser combinators for binary formats. only."	"true"
"Utilities"	"Hans Boehm GC"	"http://www.hboehm.info/gc/"	"Garbage collection for C? Don't mind if I do! Various licenses, all free."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"A garbage collector for C and C++ Interface Overview Tutorial Slides FAQ Example Download License A garbage collector for C and C++ Where to get the collector Platforms Scalable multiprocessor versions Some collector details Further reading Current users Local links for this collector Local background Links Contacts and mailing list Translations of this page [ This is an updated version of the page formerly at http://www.hpl.hp.com/personal/Hans_Boehm/gc, and before that at http://reality.sgi.com/boehm/gc.html and before that at ftp://parcftp.xerox.com/pub/gc/gc.html.] The Boehm-Demers-Weiser conservative garbage collector can be used as a garbage collecting replacement for C malloc or C++ new. It allows you to allocate memory basically as you normally would, without explicitly deallocating memory that is no longer useful. The collector automatically recycles memory when it determines that it can no longer be otherwise accessed. A simple example of such a use is given here. The collector is also used by a number of programming language implementations that either use C as intermediate code, want to facilitate easier interoperation with C libraries, or just prefer the simple collector interface. For a more detailed description of the interface, see here. Alternatively, the garbage collector may be used as a leak detector for C or C++ programs, though that is not its primary goal. The arguments for and against conservative garbage collection in C and C++ are briefly discussed in issues.html. The beginnings of a frequently-asked-questions list are here. Empirically, this collector works with most unmodified C programs, simply by replacing malloc with GC_malloc calls, replacing realloc with GC_realloc calls, and removing free calls. Exceptions are discussed in issues.html. Where to get the collector Typically several versions will be available in the gc_source subdirectory. Currently a fairly recent stable version is gc-7.2g.tar.gz. A later version is available as gc-7.4.4.tar.gz. Note that this uses a slightly different version numbering scheme and requires a separate libatomic_ops download (see below). If that fails, try the latest explicitly numbered version in gc_source. Later versions may contain additional features, platform support, or bug fixes, but are likely to be less well tested. Note that 7.3 and later require that you download a corresponding (or possibly later) version of libatomic_ops, which should be available in https://github.com/ivmai/libatomic_ops/wiki/Download. The current version is also available as gc_source/libatomic_ops-7.4.4.tar.gz. You will need to place that in a libatomic_ops subdirectory. (We expect these to be replaced by C11 atomics in the future.) The development version of the GC source code now resides on github, along with the downloadable packages. The GC tree itself is at https://github.com/ivmai/bdwgc/. The libatomic_ops tree required by the GC is at https://github.com/ivmai/libatomic_ops/. To build a working version of the collector, you will need to do something like the following, where D is the absolute path to an installation directory:  cd D git clone git://github.com/ivmai/libatomic_ops.git git clone git://github.com/ivmai/bdwgc.git ln -s  D/libatomic_ops D/bdwgc/libatomic_ops cd bdwgc autoreconf -vif automake --add-missing ./configure make  This will require that you have C and C++ toolchains, git, automake, autoconf, and libtool already installed. Historical versions of the source can still be found on the SourceForge site (project ""bdwgc""). It can be browsed here. An even older version of the garbage collector is included as part of the GNU compiler distribution. The source code for that version is available for browsing here. The garbage collector code is copyrighted by Hans-J. Boehm, Alan J. Demers, Xerox Corporation, Silicon Graphics, and Hewlett-Packard Company. It may be used and copied without payment of a fee under minimal restrictions. See the README file in the distribution or the license for more details. IT IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED OR IMPLIED. ANY USE IS AT YOUR OWN RISK. Platforms The collector is not completely portable, but the distribution includes ports to most standard PC and UNIX/Linux platforms. The collector should work on Linux, *BSD, recent Windows versions, MacOS X, HP/UX, Solaris, Tru64, Irix and a few other operating systems. Some ports are more polished than others. There are instructions for porting the collector to a new platform. Irix pthreads, Linux threads, Win32 threads, Solaris threads (old style and pthreads), HP/UX 11 pthreads, Tru64 pthreads, and MacOS X threads are supported in recent versions. Separately distributed ports For MacOS 9/Classic use, Patrick Beard's latest port is available from http://homepage.mac.com/pcbeard/gc/. (Unfortunately, that's now quite dated. I'm not in a position to test under MacOS. Although I try to incorporate changes, it is impossible for me to update the project file.) Precompiled versions of the collector for NetBSD are available here or here. Debian Linux includes prepackaged versions of the collector. Scalable multiprocessor versions Kenjiro Taura, Toshio Endo, and Akinori Yonezawa have made available a parallel collector based on this one. Their collector takes advantage of multiple processors during a collection. Starting with collector version 6.0alpha1 we also do this, though with more modest processor scalability goals. Our approach is discussed briefly in scale.html. Some Collector Details The collector uses a mark-sweep algorithm. It provides incremental and generational collection under operating systems which provide the right kind of virtual memory support. (Currently this includes SunOS[45], IRIX, OSF/1, Linux, and Windows, with varying restrictions.) It allows finalization code to be invoked when an object is collected. It can take advantage of type information to locate pointers if such information is provided, but it is usually used without such information. ee the README and gc.h files in the distribution for more details. For an overview of the implementation, see here. The garbage collector distribution includes a C string (cord) package that provides for fast concatenation and substring operations on long strings. A simple curses- and win32-based editor that represents the entire file as a cord is included as a sample application. Performance of the nonincremental collector is typically competitive with malloc/free implementations. Both space and time overhead are likely to be only slightly higher for programs written for malloc/free (see Detlefs, Dosser and Zorn's Memory Allocation Costs in Large C and C++ Programs.) For programs allocating primarily very small objects, the collector may be faster; for programs allocating primarily large objects it will be slower. If the collector is used in a multithreaded environment and configured for thread-local allocation, it may in some cases significantly outperform malloc/free allocation in time. We also expect that in many cases any additional overhead will be more than compensated for by decreased copying etc. if programs are written and tuned for garbage collection. Further Reading: The beginnings of a frequently asked questions list for this collector are here. The following provide information on garbage collection in general: Paul Wilson's garbage collection ftp archive and GC survey. The Ravenbrook Memory Management Reference. David Chase's GC FAQ. Richard Jones' GC page and his book. The following papers describe the collector algorithms we use and the underlying design decisions at a higher level. (Some of the lower level details can be found here.) The first one is not available electronically due to copyright considerations. Most of the others are subject to ACM copyright. Boehm, H., ""Dynamic Memory Allocation and Garbage Collection"", Computers in Physics 9, 3, May/June 1995, pp. 297-303. This is directed at an otherwise sophisticated audience unfamiliar with memory allocation issues. The algorithmic details differ from those in the implementation. There is a related letter to the editor and a minor correction in the next issue. Boehm, H., and M. Weiser, ""Garbage Collection in an Uncooperative Environment"", Software Practice & Experience, September 1988, pp. 807-820. Boehm, H., A. Demers, and S. Shenker, ""Mostly Parallel Garbage Collection"", Proceedings of the ACM SIGPLAN '91 Conference on Programming Language Design and Implementation, SIGPLAN Notices 26, 6 (June 1991), pp. 157-164. Boehm, H., ""Space Efficient Conservative Garbage Collection"", Proceedings of the ACM SIGPLAN '93 Conference on Programming Language Design and Implementation, SIGPLAN Notices 28, 6 (June 1993), pp. 197-206. Boehm, H., ""Reducing Garbage Collector Cache Misses"", Proceedings of the 2000 International Symposium on Memory Management . Official version. Technical report version. Describes the prefetch strategy incorporated into the collector for some platforms. Explains why the sweep phase of a ""mark-sweep"" collector should not really be a distinct phase. M. Serrano, H. Boehm, ""Understanding Memory Allocation of Scheme Programs"", Proceedings of the Fifth ACM SIGPLAN International Conference on Functional Programming, 2000, Montreal, Canada, pp. 245-256. Official version. Earlier Technical Report version. Includes some discussion of the collector debugging facilities for identifying causes of memory retention. Boehm, H., ""Fast Multiprocessor Memory Allocation and Garbage Collection"", HP Labs Technical Report HPL 2000-165. Discusses the parallel collection algorithms, and presents some performance results. Boehm, H., ""Bounding Space Usage of Conservative Garbage Collectors"", Proceeedings of the 2002 ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, Jan. 2002, pp. 93-100. Official version. Technical report version. Includes a discussion of a collector facility to much more reliably test for the potential of unbounded heap growth. The following papers discuss language and compiler restrictions necessary to guaranteed safety of conservative garbage collection. We thank John Levine and JCLT for allowing us to make the second paper available electronically, and providing PostScript for the final version. Boehm, H., ``Simple Garbage-Collector-Safety'', Proceedings of the ACM SIGPLAN '96 Conference on Programming Language Design and Implementation. Boehm, H., and D. Chase, ``A Proposal for Garbage-Collector-Safe C Compilation'', Journal of C Language Translation 4, 2 (Decemeber 1992), pp. 126-141. Other related information: The Detlefs, Dosser and Zorn's Memory Allocation Costs in Large C and C++ Programs. This is a performance comparison of the Boehm-Demers-Weiser collector to malloc/free, using programs written for malloc/free. Joel Bartlett's mostly copying conservative garbage collector for C++. John Ellis and David Detlef's Safe Efficient Garbage Collection for C++ proposal. Henry Baker's paper collection. Slides for Hans Boehm's Allocation and GC Myths talk. Current users: Known current users of some variant of this collector include: The runtime system for GCJ, the static GNU java compiler. W3m, a text-based web browser. Some versions of the Xerox DocuPrint printer software. The Mozilla project, as leak detector. The Mono project, an open source implementation of the .NET development framework. The DotGNU Portable.NET project, another open source .NET implementation. The Irssi IRC client. The Berkeley Titanium project. The NAGWare f90 Fortran 90 compiler. Elwood Corporation's Eclipse Common Lisp system, C library, and translator. The Bigloo Scheme and Camloo ML compilers written by Manuel Serrano and others. Brent Benson's libscheme. The MzScheme scheme implementation. The University of Washington Cecil Implementation. The Berkeley Sather implementation. The Berkeley Harmonia Project. The Toba Java Virtual Machine to C translator. The Gwydion Dylan compiler. The GNU Objective C runtime. Macaulay 2, a system to support research in algebraic geometry and commutative algebra. The Vesta configuration management system. Visual Prolog 6. Asymptote LaTeX-compatible vector graphics language. More collector information at this site A simple illustration of how to build and use the collector.. Description of alternate interfaces to the garbage collector. Slides from an ISMM 2004 tutorial about the GC. A FAQ (frequently asked questions) list. How to use the garbage collector as a leak detector. Some hints on debugging garbage collected applications. An overview of the implementation of the garbage collector. Instructions for porting the collector to new platforms. The data structure used for fast pointer lookups. Scalability of the collector to multiprocessors. Directory containing garbage collector source. More background information at this site An attempt to establish a bound on space usage of conservative garbage collectors. Mark-sweep versus copying garbage collectors and their complexity. Pros and cons of conservative garbage collectors, in comparison to other collectors. Issues related to garbage collection vs. manual memory management in C/C++. An example of a case in which garbage collection results in a much faster implementation as a result of reduced synchronization. Slide set discussing performance of nonmoving garbage collectors. Slide set discussing Destructors, Finalizers, and Synchronization (POPL 2003). Paper corresponding to above slide set. ( Technical Report version.) A Java/Scheme/C/C++ garbage collection benchmark. Slides for talk on memory allocation myths. Slides for OOPSLA 98 garbage collection talk. Related papers. Contacts and Mailing List We have set up two mailing list for collector announcements and discussions: bdwgc-announce@lists.opendylan.org is (very rarely) used for announcements of new versions. Postings are restricted. We expect this to always remain a very low volume list. bdwgc@lists.opendylan.org is used for discussions, bug reports, and the like. Subscribers may post. On-topic posts by nonsubscribers will usually also be accepted, but it may take some time to review them. To subscribe to these lists, send a mail message containing the word ""subscribe"" to bdwgc-announce-request@lists.opendylan.org or to bdwgc-request@lists.opendylan.org. The archives for these lists appear here for the gc list and here for the gc-announce list. The gc list archive may also be read at gmane.org. Some prior discussion of the collector has taken place on the gcc java mailing list, whose archives appear here, and also on gclist@iecc.com. Comments and bug reports may also be sent to (boehm@acm.org), but the gc mailing list is strongly preferred."	"null"	"null"	"Garbage collection for C? Don't mind if I do! Various licenses, all free."	"true"
"Utilities"	"huffandpuff"	"https://github.com/adamierymenko/huffandpuff"	"A minimal Huffman encoder and decoder. Public domain."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"34"	"5"	"1"	"GitHub - adamierymenko/huffandpuff: Minimal Huffman coder/decoder Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 5 Star 34 Fork 1 adamierymenko/huffandpuff Code Issues 0 Pull requests 0 Pulse Graphs Minimal Huffman coder/decoder 5 commits 1 branch 0 releases Fetching contributors C 100.0% C Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Fetching latest commit… Cannot retrieve the latest commit at this time. Permalink Failed to load latest commit information. .gitignore Makefile README.md huffman.c huffman.h README.md huffandpuff This is an extremely minimal huffman encoder/decoder. It uses no calls at all, not even stdlib/stdio, making it suitable for embedded applications. The supplied Makefile will build a test program. This is in the public domain and is distributed with NO WARRANTY. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/adamierymenko/huffandpuff"	"A minimal Huffman encoder and decoder. Public domain."	"true"
"Utilities"	"iniparser"	"https://github.com/ndevilla/iniparser"	"A parser for.ini files.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"221"	"35"	"139"	"GitHub - ndevilla/iniparser: ini file parser Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 35 Star 221 Fork 139 ndevilla/iniparser Code Issues 6 Pull requests 7 Wiki Pulse Graphs ini file parser http://ndevilla.free.fr/iniparser 84 commits 4 branches 3 releases 16 contributors C 55.6% HTML 27.3% Objective-C 7.9% CSS 6.5% Makefile 1.8% Shell 0.7% Python 0.2% C HTML Objective-C CSS Makefile Shell Python Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags custom_errback issue-73 master quoting Nothing to show v4.0 v3.2 v3.1 Nothing to show New pull request Latest commit ed1fd91 Jun 12, 2016 touilleMan Update doc index.html Permalink Failed to load latest commit information. doc Merge version 4 May 16, 2015 example Fix Makefile configuration by env var support Apr 8, 2016 html Update doc index.html Jun 12, 2016 src Fix parsing with Jun 12, 2016 test Fix parsing with Jun 12, 2016 .gitignore Correct gitignore .so.* rule Aug 13, 2015 .travis.yml Add travis.yml May 19, 2015 AUTHORS Switched to version 3.0 Mar 3, 2011 INSTALL Switched to version 3.0 Mar 3, 2011 LICENSE Switched to version 3.0 Mar 3, 2011 Makefile Add SO_TARGET to Makefile (see #65) Aug 9, 2015 README.md Add FAQ to the README Jun 5, 2015 README.md Iniparser 4 I - Overview This modules offers parsing of ini files from the C level. See a complete documentation in HTML format, from this directory open the file html/index.html with any HTML-capable browser. Key features : Small : around 1500 sloc inside 4 files (2 .c and 2 .h) Portable : no dependancies, written in -ansi -pedantic C89 Fully reintrant : easy to make it thread-safe (just surround library calls by mutex) II - Building project A simple make at the root of the project should be enough to get the static (i.e. libiniparser.a) and shared (i.e. libiniparser.so.0) libraries compiled. You should consider trying the following rules too : make check : run the unitary tests make example : compile the example, run it with ./example/iniexample III - License This software is released under MIT License. See LICENSE for full informations IV - Versions Current version is 4.0 which introduces breaking changes in the api. Older versions 3.1 and 3.2 with the legacy api are available as tags. V - FAQ Is Iniparser thread safe ? Starting from version 4, iniparser is designed to be thread-safe, provided you surround it with your own mutex logic. The choice not to add thread safety inside the library has been done to provide more freedom for the developer, especially when dealing with it own custom reading logic (i.g. acquiring the mutex, reading plenty of entries in iniparser, then releasing the mutex). Your build system isn't portable, let me help you... I have received countless contributions from distrib people to modify the Makefile into what they think is the ""standard"", which I had to reject. The default, standard Makefile for Debian bears absolutely no relationship with the one from SuSE or RedHat and there is no possible way to merge them all. A build system is something so specific to each environment that it is completely pointless to try and push anything that claims to be standard. The provided Makefile in this project is purely here to have something to play with quickly. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/ndevilla/iniparser"	"A parser for.ini files.."	"true"
"Utilities"	"jemalloc"	"http://www.canonware.com/jemalloc/"	"A malloc implementation that emphasizes avoidance of fragmentation and scalable concurrency support.."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"1420"	"154"	"331"	"GitHub - jemalloc/jemalloc Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 154 Star 1,420 Fork 331 jemalloc/jemalloc Code Issues 41 Pull requests 10 Wiki Pulse Graphs http://www.canonware.com/jemalloc/ 1,397 commits 2 branches 36 releases Fetching contributors C 77.4% Perl 13.1% M4 4.4% C++ 2.0% Shell 1.8% Makefile 1.3% C Perl M4 C++ Shell Makefile Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: dev Switch branches/tags Branches Tags dev master Nothing to show 4.2.1 4.2.0 4.1.1 4.1.0 4.0.4 4.0.3 4.0.2 4.0.1 4.0.0 3.6.0 3.5.1 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.0 3.0.0 2.2.5 2.2.4 2.2.3 2.2.2 2.2.1 2.2.0 2.1.3 2.1.2 2.1.1 2.1.0 2.0.1 2.0.0 1.0.3 1.0.2 1.0.1 1.0.0 0.0.0 Nothing to show New pull request Latest commit 19c9a3e Jul 8, 2016 glandium Change how the default zone is found … On OSX 10.12, malloc_default_zone returns a special zone that is not present in the list of registered zones. That zone uses a ""lite zone"" if one is present (apparently enabled when malloc stack logging is enabled), or the first registered zone otherwise. In practice this means unless malloc stack logging is enabled, the first registered zone is the default.  So get the list of zones to get the first one, instead of relying on malloc_default_zone. Permalink Failed to load latest commit information. bin Pass retain and exclude parameters to /pprof/symbol. Jan 29, 2016 build-aux Use AC_CONFIG_AUX_DIR([build-aux]). Nov 12, 2015 doc Modify extent hook functions to take an (extent_t *) argument. Jun 5, 2016 include Check for __builtin_unreachable at configure time Jul 7, 2016 msvc Fix MSVC project Jul 7, 2016 src Change how the default zone is found Jul 8, 2016 test Work around a weird pgi bug in test/unit/math.c Jun 8, 2016 .appveyor.yml Add an AppVeyor config Jun 9, 2016 .autom4te.cfg Disable autom4te cache. Sep 2, 2014 .gitattributes fix git handling of newlines on windows May 7, 2014 .gitignore Add MS Visual Studio 2015 support Feb 20, 2016 .travis.yml Add Travis-CI configuration Jul 7, 2016 COPYING Update copyright dates for 2016. Feb 28, 2016 ChangeLog Update ChangeLog for 4.2.1. Jun 8, 2016 INSTALL Better document --enable-ivsalloc. Jun 5, 2016 Makefile.in Fix librt detection when using a Cray compiler wrapper Jul 7, 2016 README Remove Valgrind support. May 13, 2016 autogen.sh Move repo contents in jemalloc/ to top level. Mar 31, 2011 config.stamp.in Move repo contents in jemalloc/ to top level. Apr 1, 2011 configure.ac Disable irrelevant Cray compiler warnings if cc-silence is enabled Jul 7, 2016 coverage.sh Add test code coverage analysis. Dec 6, 2013 jemalloc.pc.in Take into account the install suffix that jemalloc was built with in … Feb 13, 2015 README jemalloc is a general purpose malloc(3) implementation that emphasizes fragmentation avoidance and scalable concurrency support.  jemalloc first came into use as the FreeBSD libc allocator in 2005, and since then it has found its way into numerous applications that rely on its predictable behavior.  In 2010 jemalloc development efforts broadened to include developer support features such as heap profiling and extensive monitoring/tuning hooks.  Modern jemalloc releases continue to be integrated back into FreeBSD, and therefore versatility remains critical.  Ongoing development efforts trend toward making jemalloc among the best allocators for a broad range of demanding applications, and eliminating/mitigating weaknesses that have practical repercussions for real world applications.  The COPYING file contains copyright and licensing information.  The INSTALL file contains information on how to configure, build, and install jemalloc.  The ChangeLog file contains a brief summary of changes for each release.  URL: http://www.canonware.com/jemalloc/  Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/jemalloc/jemalloc"	"A malloc implementation that emphasizes avoidance of fragmentation and scalable concurrency support.."	"true"
"Utilities"	"jwHash"	"https://github.com/watmough/jwHash"	"A fast hashtable implementation.."	"null"	"null"	"null"	"Apache2.0"	"http://directory.fsf.org/wiki/License:Apache2.0"	"null"	"null"	"187"	"9"	"22"	"GitHub - watmough/jwHash: Simple hash table implementation for C. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 9 Star 187 Fork 22 watmough/jwHash Code Issues 1 Pull requests 0 Pulse Graphs Simple hash table implementation for C. 27 commits 1 branch 0 releases Fetching contributors C 99.0% Makefile 1.0% C Makefile Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Latest commit 7030adb May 18, 2015 watmough Added a note Permalink Failed to load latest commit information. .gitignore LICENSE Makefile README.md Added a note May 18, 2015 jwHash.c jwHash.h added makefile and multi-threading to test May 16, 2015 test.c README.md Simple hash table implementation for C. I just wanted a simple and straightforward hash table implementation that I could drop into my own C-based projects on whatever platform. I haven't implemented one of these before, so it may be super naive, but it does appear to work pretty well. NOTE: After exposure on HN, and seeing other hash implementations, I'm planning to restructure the code to a macro-based style, which should cut down the duplication. Features You can create a hash table, and add strings, long ints, doubles and pointers to it, keyed by strings or long ints. You can retrieve strings, long ints, doubles and pointers via the get functions. All strings saved in a hash table are copied, and copies of strings are returned on retrieval. I added locking on hash buckets which only minorly affects performance, and allows safe retrieval and storing of key value pairs. Performance seems decent. Saving 1,000,000 int values by string key is done in about 0.28 secs, and multi-threaded performance scales pretty closely with number of processors. Building and Using Type make in the folder to build the code. Type ./test to run the demo. References The following were key to getting various aspects working: Hash function for integer keys. http://stackoverflow.com/a/12996028 Hash function for string keys. http://www.cse.yorku.ca/~oz/hash.html Efficient lock when low-contention is expected. http://stackoverflow.com/questions/1383363/is-my-spin-lock-implementation-correct-and-optimal Data Structures Hash Table typedef struct jwHashTable jwHashTable; struct jwHashTable {     jwHashEntry **bucket;           // pointer to array of buckets     size_t buckets;     size_t bucketsinitial;          // if we resize, may need to hash multiple times     HASHRESULT lastError; #ifdef HASHTHREADED     volatile int *locks;            // array of locks     volatile int lock;              // lock for entire table #endif };  Hash Entry typedef struct jwHashEntry jwHashEntry; struct jwHashEntry {     union     {         char  *strValue;         double dblValue;         int    intValue;     } key;     HASHVALTAG valtag;     union     {         char  *strValue;         double dblValue;         int    intValue;         void  *ptrValue;     } value;     jwHashEntry *next; };  API Creating a Hash Table jwHashTable *create_hash( size_t buckets ); void *delete_hash( jwHashTable *table );        // clean up all memory  Storing by String Key HASHRESULT add_str_by_str( jwHashTable*, char *key, char *value ); HASHRESULT add_int_by_str( jwHashTable*, char *key, long int value ); HASHRESULT add_dbl_by_str( jwHashTable*, char *key, double value ); HASHRESULT add_ptr_by_str( jwHashTable*, char *key, void *value );  Deleting by String HASHRESULT del_by_str( jwHashTable*, char *key );  Retrieving by String HASHRESULT get_str_by_str( jwHashTable *table, char *key, char **value ); HASHRESULT get_int_by_str( jwHashTable *table, char *key, int *i ); HASHRESULT get_dbl_by_str( jwHashTable *table, char *key, double *val ); HASHRESULT get_ptr_by_str( jwHashTable *table, char *key, void **val );  [Similar for long int keys] TODO Support multi-threading, -- this started, and implemented for the test Implement clean-up, Implement re-hashing to a larger hash table, Implement a callback to allow iterating through keys, values Examples Example 1 - Save and Retrieve Some Values // Test hashing by string char * strv1 = ""Jonathan""; char * strv2 = ""Zevi""; char * strv3 = ""Jude""; char * strv4 = ""Voldemort"";  add_str_by_str(table,""oldest"",strv1); add_str_by_str(table,""2ndoldest"",strv2); add_str_by_str(table,""3rdoldest"",strv3); add_str_by_str(table,""4tholdest"",strv4);  char * sstrv1; get_str_by_str(table,""oldest"",&sstrv1); char * sstrv2; get_str_by_str(table,""2ndoldest"",&sstrv2); char * sstrv3; get_str_by_str(table,""3rdoldest"",&sstrv3); char * sstrv4; get_str_by_str(table,""4tholdest"",&sstrv4); printf(""got strings:\noldest->%s \n2ndoldest->%s \n3rdoldest->%s \n4tholdest->%s\n"",     sstrv1,sstrv2,sstrv3,sstrv4);  Example 2 - Write and Read Key Value Pairs on Multiple Threads #define NUMTHREADS 8 #define HASHCOUNT 1000000  typedef struct threadinfo {jwHashTable *table; int start;} threadinfo; void * thread_func(void *arg) {     threadinfo *info = arg;     char buffer[512];     int i = info->start;     jwHashTable *table = info->table;     free(info);     for(;i<HASHCOUNT;i+=NUMTHREADS) {         sprintf(buffer,""%d"",i);         add_int_by_str(table,buffer,i);     } }   int thread_test() {     // create     jwHashTable * table = create_hash(HASHCOUNT>>2);      // hash a million strings into various sizes of table     struct timeval tval_before, tval_done1, tval_done2, tval_writehash, tval_readhash;     gettimeofday(&tval_before, NULL);     int t;     pthread_t * threads[NUMTHREADS];     for(t=0;t<NUMTHREADS;++t) {         pthread_t * pth = malloc(sizeof(pthread_t));         threads[t] = pth;         threadinfo *info = (threadinfo*)malloc(sizeof(threadinfo));         info->table = table; info->start = t;         pthread_create(pth,NULL,thread_func,info);     }     for(t=0;t<NUMTHREADS;++t) {         pthread_join(*threads[t], NULL);     }     gettimeofday(&tval_done1, NULL);     int i,j;     int error = 0;     char buffer[512];     for(i=0;i<HASHCOUNT;++i) {         sprintf(buffer,""%d"",i);         get_int_by_str(table,buffer,&j);         if(i!=j) {             printf(""Error: %d != %d\n"",i,j);             error = 1;         }     }     if(!error) {         printf(""No errors.\n"");      }     gettimeofday(&tval_done2, NULL);     timersub(&tval_done1, &tval_before, &tval_writehash);     timersub(&tval_done2, &tval_done1, &tval_readhash);     printf(""\n%d threads.\n"",NUMTHREADS);     printf(""Store %d ints by string: %ld.%06ld sec, read %d ints: %ld.%06ld sec\n"",HASHCOUNT,         (long int)tval_writehash.tv_sec, (long int)tval_writehash.tv_usec,HASHCOUNT,         (long int)tval_readhash.tv_sec, (long int)tval_readhash.tv_usec);      return 0; }  Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/watmough/jwHash"	"A fast hashtable implementation.."	"true"
"Utilities"	"kdtree"	"https://github.com/jtsiomb/kdtree"	"A simple library for working with KD-trees.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"68"	"9"	"25"	"GitHub - jtsiomb/kdtree: A simple C library for working with KD-Trees Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 9 Star 68 Fork 25 jtsiomb/kdtree Code Issues 3 Pull requests 1 Pulse Graphs A simple C library for working with KD-Trees http://nuclear.mutantstargoat.com/sw/kdtree/ 18 commits 1 branch 2 releases 3 contributors C 100.0% C Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show kdtree-0.5.6 kdtree-0.5.5 Nothing to show New pull request Latest commit 073be8d Nov 18, 2015 jtsiomb Merge pull request #16 from whackashoe/examples_makefile_fix … link the example programs with LDFLAGS instead of just kdlibs (which was obviously the original intention) Permalink Failed to load latest commit information. doc moving arround files Aug 27, 2009 examples link with LDFLAGS instead of just kdlibs (this keeps libmath) Nov 17, 2015 .hgignore added readme, license, and .hgignore while moving to github Mar 13, 2015 .hgtags Added tag kdtree-0.5.6 for changeset af356a6eac25 Mar 13, 2015 COPYING added readme, license, and .hgignore while moving to github Mar 13, 2015 Makefile.in improved the makefile: Oct 11, 2015 README.rst added the logo in the readme file Mar 13, 2015 configure improved the makefile: Oct 10, 2015 kdtree.c added a standard config_h define block May 17, 2015 kdtree.h updated the email address in copyright statements Nov 25, 2011 README.rst kdtree Overview kdtree is a simple, easy to use C library for working with kd-trees. Kd-trees are an extension of binary search trees to k-dimensional data. They facilitate very fast searching, and nearest-neighbor queries. This particular implementation is designed to be efficient and very easy to use. It is completely written in ANSI/ISO C, and thus completely cross-platform. See under the doc/ and examples/ directories to find out how to use the kdtree library. License Author: John Tsiombikas <nuclear@member.fsf.org> kdtree is free software. You may use, modify, and redistribute it under the terms of the 3-clause BSD license. Download Latest release (0.5.6): http://nuclear.mutantstargoat.com/sw/kdtree/files/kdtree-0.5.6.tar.gz You can find previous releases here: http://nuclear.mutantstargoat.com/sw/kdtree/files/ You can also grab a copy of the source from github: https://github.com/jtsiomb/kdtree Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/jtsiomb/kdtree"	"A simple library for working with KD-trees.."	"true"
"Utilities"	"Kitsune"	"http://kitsune-dsu.com/"	"An efficient, general-purpose framework for dynamic software updating. or later."	"null"	"null"	"null"	"GNU LGPL3"	"http://www.gnu.org/licenses/lgpl.html"	"null"	"null"	"134"	"9"	"21"	"GitHub - kitsune-dsu/kitsune-core: Kitsune runtime, driver, ktcc, xfgen, documentation, and test suite. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 9 Star 134 Fork 21 kitsune-dsu/kitsune-core Code Issues 0 Pull requests 1 Pulse Graphs Kitsune runtime, driver, ktcc, xfgen, documentation, and test suite. 10 commits 1 branch 0 releases Fetching contributors C 91.8% Makefile 7.1% Other 1.1% C Makefile Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Fetching latest commit… Cannot retrieve the latest commit at this time. Permalink Failed to load latest commit information. contrib doc src tests tools .gitignore COPYING LICENSE Makefile README README  Kitsune - Dynamic Updating System =================================  Update ------ Tested with ""The OCaml toplevel, version 4.00.1"". Newer versions of Ocaml (ex: 4.02) might cause infinite loops with the code generator due to the version of Cil that we use.   Getting Started ---------------  1. Build the Kitsune runtime and compiler/transformation generator:  (in Kitsune root directory) make  2. Build tests in the test/* directories.  Most of these tests manually initiate an update by calling kitsune_signal_update() rather than having the user manually initiating the update.  3. Manually initiating an update normally works as follows:  Starting the initial version:   (kitsune root)/bin/driver (version 0).so (args)  To update that process, run:   (kitsune root)/bin/doupd (vN PID) (version N+1).so  Currently, the runtime prints the pid of the running process to stdout, which can be used in the call to doupd.  (Note that multiple calls to doupd may be needed for programs that fork, like vsftpd.)  If Kitsune was built for benchmarking, then a benchmarking result filename is expected by driver between the shared library and its arguments. [We plan to streamline this later.]  4. Building and updating redis (as an example):  (build kitsune with threading)  cd examples/redis make   - builds versions of redis from 2.0.0 -> 2.0.4  ../../bin/driver redis-2.0.0/redis-server.so   - starts the redis server under kitsune  (in another terminal) ../../bin/doupd PID redis-2.0.1/redis-server.so   - you can get PID from the original terminal or just use `pidof     driver` in place of PID in this line (assuming you aren't running     other things under Kitsune simultaneously)  When a program is updated with Kitsune, it generates a log file that can be found in /tmp/ekiden/PROG.PID (where PROG is the program name and PID is its pid).  5. Learning Kitsune: currently the tests/ are the best way to see how the kitsune tools work.     Overview of the Kitsune Repository ----------------------------------  src/     - contains the Kitsune runtime source code  tools/     - contains the Kitsune compiler and transformation generator  tools/ocaml-src/     - Kitsune specific code  tools/ocaml-src/cil     - Kitsune code linked with cil for compilation  tools/ocaml-src/tools     - xfgen-related code  tools/ocaml-src/common     - code shared between the compiler and xfgen  bin/     - contains the externally used Kitsune header files and the      compiled library  tests/     - a variety of tests ensuring correct behavior in the runtime      library and compilation tools.  These tests provide a good way to      see how the parts of the system work together, and the compilation      process for updating.   Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/kitsune-dsu/kitsune-core"	"An efficient, general-purpose framework for dynamic software updating. or later."	"true"
"Utilities"	"libavl"	"http://adtinfo.org/libavl.html/index.html"	"A library containing a range of self-balancing binary trees. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"GNU libavl 2.0.2 GNU libavl 2.0.2         Short Contents GNU libavl 2.0.2 Preface 1 Introduction 2 The Table ADT 3 Search Algorithms 4 Binary Search Trees 5 AVL Trees 6 Red-Black Trees 7 Threaded Binary Search Trees 8 Threaded AVL Trees 9 Threaded Red-Black Trees 10 Right-Threaded Binary Search Trees 11 Right-Threaded AVL Trees 12 Right-Threaded Red-Black Trees 13 BSTs with Parent Pointers 14 AVL Trees with Parent Pointers 15 Red-Black Trees with Parent Pointers Appendix A References Appendix B Supplementary Code Appendix C Glossary Appendix D Answers to All the Exercises Appendix E Catalogue of Algorithms Appendix F Index Table of Contents GNU libavl 2.0.2 Preface Acknowledgements Contacting the Author 1 Introduction 1.1 Audience 1.2 Reading the Code 1.3 Code Conventions 1.4 License 2 The Table ADT 2.1 Informal Definition 2.2 Identifiers 2.3 Comparison Function 2.4 Item and Copy Functions 2.5 Memory Allocation 2.6 Creation and Destruction 2.7 Count 2.8 Insertion and Deletion 2.9 Assertions 2.10 Traversers 2.10.1 Constructors 2.10.2 Manipulators 2.11 Table Headers 2.12 Additional Exercises 3 Search Algorithms 3.1 Sequential Search 3.2 Sequential Search with Sentinel 3.3 Sequential Search of Ordered Array 3.4 Sequential Search of Ordered Array with Sentinel 3.5 Binary Search of Ordered Array 3.6 Binary Search Tree in Array 3.7 Dynamic Lists 4 Binary Search Trees 4.1 Vocabulary 4.1.1 Aside: Differing Definitions 4.2 Data Types 4.2.1 Node Structure 4.2.2 Tree Structure 4.2.3 Maximum Height 4.3 Rotations 4.4 Operations 4.5 Creation 4.6 Search 4.7 Insertion 4.7.1 Aside: Root Insertion 4.8 Deletion 4.8.1 Aside: Deletion by Merging 4.9 Traversal 4.9.1 Traversal by Recursion 4.9.2 Traversal by Iteration 4.9.2.1 Improving Convenience 4.9.3 Better Iterative Traversal 4.9.3.1 Starting at the Null Node 4.9.3.2 Starting at the First Node 4.9.3.3 Starting at the Last Node 4.9.3.4 Starting at a Found Node 4.9.3.5 Starting at an Inserted Node 4.9.3.6 Initialization by Copying 4.9.3.7 Advancing to the Next Node 4.9.3.8 Backing Up to the Previous Node 4.9.3.9 Getting the Current Item 4.9.3.10 Replacing the Current Item 4.10 Copying 4.10.1 Recursive Copying 4.10.2 Iterative Copying 4.10.3 Error Handling 4.11 Destruction 4.11.1 Destruction by Rotation 4.11.2 Aside: Recursive Destruction 4.11.3 Aside: Iterative Destruction 4.12 Balance 4.12.1 From Tree to Vine 4.12.2 From Vine to Balanced Tree 4.12.2.1 General Trees 4.12.2.2 Implementation 4.12.2.3 Implementing Compression 4.13 Aside: Joining BSTs 4.14 Testing 4.14.1 Testing BSTs 4.14.1.1 BST Verification 4.14.1.2 Displaying BST Structures 4.14.2 Test Set Generation 4.14.3 Testing Overflow 4.14.4 Memory Manager 4.14.5 User Interaction 4.14.6 Utility Functions 4.14.7 Main Program 4.15 Additional Exercises 5 AVL Trees 5.1 Balancing Rule 5.1.1 Analysis 5.2 Data Types 5.3 Operations 5.4 Insertion 5.4.1 Step 1: Search 5.4.2 Step 2: Insert 5.4.3 Step 3: Update Balance Factors 5.4.4 Step 4: Rebalance 5.4.5 Symmetric Case 5.4.6 Example 5.4.7 Aside: Recursive Insertion 5.5 Deletion 5.5.1 Step 1: Search 5.5.2 Step 2: Delete 5.5.3 Step 3: Update Balance Factors 5.5.4 Step 4: Rebalance 5.5.5 Step 5: Finish Up 5.5.6 Symmetric Case 5.6 Traversal 5.7 Copying 5.8 Testing 6 Red-Black Trees 6.1 Balancing Rule 6.1.1 Analysis 6.2 Data Types 6.3 Operations 6.4 Insertion 6.4.1 Step 1: Search 6.4.2 Step 2: Insert 6.4.3 Step 3: Rebalance 6.4.4 Symmetric Case 6.4.5 Aside: Initial Black Insertion 6.4.5.1 Symmetric Case 6.5 Deletion 6.5.1 Step 2: Delete 6.5.2 Step 3: Rebalance 6.5.3 Step 4: Finish Up 6.5.4 Symmetric Case 6.6 Testing 7 Threaded Binary Search Trees 7.1 Threads 7.2 Data Types 7.3 Operations 7.4 Creation 7.5 Search 7.6 Insertion 7.7 Deletion 7.8 Traversal 7.8.1 Starting at the Null Node 7.8.2 Starting at the First Node 7.8.3 Starting at the Last Node 7.8.4 Starting at a Found Node 7.8.5 Starting at an Inserted Node 7.8.6 Initialization by Copying 7.8.7 Advancing to the Next Node 7.8.8 Backing Up to the Previous Node 7.9 Copying 7.10 Destruction 7.11 Balance 7.11.1 From Tree to Vine 7.11.2 From Vine to Balanced Tree 7.12 Testing 8 Threaded AVL Trees 8.1 Data Types 8.2 Rotations 8.3 Operations 8.4 Insertion 8.4.1 Steps 1 and 2: Search and Insert 8.4.2 Step 4: Rebalance 8.4.3 Symmetric Case 8.5 Deletion 8.5.1 Step 1: Search 8.5.2 Step 2: Delete 8.5.3 Step 3: Update Balance Factors 8.5.4 Step 4: Rebalance 8.5.5 Symmetric Case 8.5.6 Finding the Parent of a Node 8.6 Copying 8.7 Testing 9 Threaded Red-Black Trees 9.1 Data Types 9.2 Operations 9.3 Insertion 9.3.1 Steps 1 and 2: Search and Insert 9.3.2 Step 3: Rebalance 9.3.3 Symmetric Case 9.4 Deletion 9.4.1 Step 1: Search 9.4.2 Step 2: Delete 9.4.3 Step 3: Rebalance 9.4.4 Step 4: Finish Up 9.4.5 Symmetric Case 9.5 Testing 10 Right-Threaded Binary Search Trees 10.1 Data Types 10.2 Operations 10.3 Search 10.4 Insertion 10.5 Deletion 10.5.1 Right-Looking Deletion 10.5.2 Left-Looking Deletion 10.5.3 Aside: Comparison of Deletion Algorithms 10.6 Traversal 10.6.1 Starting at the First Node 10.6.2 Starting at the Last Node 10.6.3 Starting at a Found Node 10.6.4 Advancing to the Next Node 10.6.5 Backing Up to the Previous Node 10.7 Copying 10.8 Destruction 10.9 Balance 10.10 Testing 11 Right-Threaded AVL Trees 11.1 Data Types 11.2 Operations 11.3 Rotations 11.4 Insertion 11.4.1 Steps 1–2: Search and Insert 11.4.2 Step 4: Rebalance 11.5 Deletion 11.5.1 Step 1: Search 11.5.2 Step 2: Delete 11.5.3 Step 3: Update Balance Factors 11.5.4 Step 4: Rebalance 11.6 Copying 11.7 Testing 12 Right-Threaded Red-Black Trees 12.1 Data Types 12.2 Operations 12.3 Insertion 12.3.1 Steps 1 and 2: Search and Insert 12.3.2 Step 3: Rebalance 12.4 Deletion 12.4.1 Step 2: Delete 12.4.2 Step 3: Rebalance 12.4.3 Step 4: Finish Up 12.5 Testing 13 BSTs with Parent Pointers 13.1 Data Types 13.2 Operations 13.3 Insertion 13.4 Deletion 13.5 Traversal 13.5.1 Starting at the First Node 13.5.2 Starting at the Last Node 13.5.3 Starting at a Found Node 13.5.4 Starting at an Inserted Node 13.5.5 Advancing to the Next Node 13.5.6 Backing Up to the Previous Node 13.6 Copying 13.7 Balance 13.8 Testing 14 AVL Trees with Parent Pointers 14.1 Data Types 14.2 Rotations 14.3 Operations 14.4 Insertion 14.4.1 Steps 1 and 2: Search and Insert 14.4.2 Step 3: Update Balance Factors 14.4.3 Step 4: Rebalance 14.4.4 Symmetric Case 14.5 Deletion 14.5.1 Step 2: Delete 14.5.2 Step 3: Update Balance Factors 14.5.3 Step 4: Rebalance 14.5.4 Symmetric Case 14.6 Traversal 14.7 Copying 14.8 Testing 15 Red-Black Trees with Parent Pointers 15.1 Data Types 15.2 Operations 15.3 Insertion 15.3.1 Step 2: Insert 15.3.2 Step 3: Rebalance 15.3.3 Symmetric Case 15.4 Deletion 15.4.1 Step 2: Delete 15.4.2 Step 3: Rebalance 15.4.3 Step 4: Finish Up 15.4.4 Symmetric Case 15.5 Testing Appendix A References Appendix B Supplementary Code B.1 Option Parser B.2 Command-Line Parser Appendix C Glossary Appendix D Answers to All the Exercises Chapter 2 Chapter 3 Chapter 4 Chapter 5 Chapter 6 Chapter 7 Chapter 8 Chapter 9 Chapter 10 Chapter 11 Chapter 13 Chapter 14 Appendix E Catalogue of Algorithms Binary Search Tree Algorithms AVL Tree Algorithms Red-Black Tree Algorithms Threaded Binary Search Tree Algorithms Threaded AVL Tree Algorithms Threaded Red-Black Tree Algorithms Right-Threaded Binary Search Tree Algorithms Right-Threaded AVL Tree Algorithms Right-Threaded Red-Black Tree Algorithms Binary Search Tree with Parent Pointers Algorithms AVL Tree with Parent Pointers Algorithms Red-Black Tree with Parent Pointers Algorithms Appendix F Index GNU libavl 2.0.2 Preface Introduction The Table ADT Search Algorithms Binary Search Trees AVL Trees Red-Black Trees Threaded Binary Search Trees Threaded AVL Trees Threaded Red-Black Trees Right-Threaded Binary Search Trees Right-Threaded AVL Trees Right-Threaded Red-Black Trees BSTs with Parent Pointers AVL Trees with Parent Pointers Red-Black Trees with Parent Pointers References Supplementary Code Glossary Answers to All the Exercises Catalogue of Algorithms Index Table of Contents Preface"	"null"	"null"	"A library containing a range of self-balancing binary trees. or later."	"true"
"Utilities"	"libbson"	"https://github.com/mongodb/libbson"	"A BSON utility library.."	"null"	"null"	"null"	"Apache2.0"	"http://directory.fsf.org/wiki/License:Apache2.0"	"null"	"null"	"204"	"37"	"129"	"GitHub - mongodb/libbson: A BSON utility library. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 37 Star 204 Fork 129 mongodb/libbson Code Pull requests 2 Pulse Graphs A BSON utility library. 1,432 commits 6 branches 42 releases Fetching contributors C 88.3% M4 7.6% C++ 1.4% CMake 1.2% Other 1.5% C M4 C++ CMake Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags 1.2.0-dev 1.3.0-dev debian master r1.2 r1.3 Nothing to show 1.3.5 1.3.4 1.3.3 1.3.2 1.3.1 1.3.0 1.3.0-rc0 1.3.0-beta0 1.2.4 1.2.3 1.2.2 1.2.1 1.2.0 1.2.0-rc0 1.2.0-beta 1.1.11 1.1.10 1.1.9 1.1.8 1.1.7 1.1.6 1.1.5 1.1.4 1.1.2 1.1.0 1.1.0-rc0 1.0.2 1.0.0 0.98.0 0.8.4 0.8.2 0.8.0 0.6.8 0.6.6 0.6.4 0.6.2 0.6.0 0.5.0 0.4.0 0.2.4 0.2.2 0.2.0 Nothing to show New pull request Latest commit c5aef2e Jul 15, 2016 puppyofkosh committed with bjori Added warning message in mallard2man script (#163) Permalink Failed to load latest commit information. .evergreen Move evergreen config into more apropriate location Jul 6, 2016 build CDRIVER-1337 export all symbols in libbson-experimental.def Jul 7, 2016 doc Added warning message in mallard2man script (#163) Jul 15, 2016 examples CDRIVER-1145: Fix build on VS 2010 (-Wdeclaration-after-statement) Mar 25, 2016 src CDRIVER-1374: Accept uppercase hex characters in bson_oid_is_valid() (#… Jul 12, 2016 tests CDRIVER-1374: Fix strcasecmp() usage in test case (#169) Jul 15, 2016 .gitattributes Rewrite the Windows evergreen config to emulate the *nix one Jun 15, 2016 .gitignore Add generated files to .gitignore (#168) Jul 15, 2016 CMakeLists.txt CDRIVER-1337 export all symbols in libbson-experimental.def Jul 7, 2016 COPYING Fix LICENSE issue with cmake Mar 11, 2014 Makefile.am CDRIVER-1217 remove spec files Apr 30, 2016 NEWS merge r1.3 branch May 7, 2016 README.md Added Windows 10 and updated the Windows instructions to use current … Jul 15, 2016 VERSION_CURRENT post-release bump Mar 11, 2016 VERSION_RELEASED merge r1.3 branch May 7, 2016 autogen.sh build: check for libtoolize in autogen.sh, and remove from tree. Mar 12, 2014 configure.ac CDRIVER-1077 prefix all man pages with ""bson_"" Mar 25, 2016 README.md Libbson libbson is a library providing useful routines related to building, parsing, and iterating BSON documents. Building Libbson tries to support a variety of operation systems and architectures. The following are known to work. If your platform is not listed here, it may still work, we simply haven't tested it. If you would like us to add your platform here, we would be happy to hear from you. Supported Operating Systems RHEL/CentOS 5, 6, 7beta SLES 11 SP3 Ubuntu 12.04 LTS Debian 7 SmartOS Solaris FreeBSD 10 Windows Vista, 7, 8, 10 OS X 10.8 Supported Architectures x86 x86_64/amd64 SPARC ARM PowerPC Supported Compilers GCC 4.1 and newer Clang 3.3 and newer Visual Studio (MSVC) 2010 and newer Oracle Solaris Studio (5.7 and newer, Solaris 10) Dependencies Fedora / RedHat Enterprise / CentOS yum install git automake autoconf libtool gcc Debian / Ubuntu apt-get install git-core automake autoconf libtool gcc FreeBSD pkg install git automake autoconf libtool gcc pkgconf OS X You'll need to have Xcode (at least the command-line package) and we recommend using Homebrew for other dependencies. brew install automake autoconf libtool pkgconfig SmartOS pkgin install git automake autoconf libtool gcc47 gmake pkg-config export PATH=/opt/local/gcc47/bin:$PATH Windows Vista and Higher from Git Builds on Windows Vista and Higher require cmake to build Visual Studio project files. Alternatively, you can use cygwin or mingw with the automake based build. git clone git://github.com/mongodb/libbson.git cd libbson cmake.exe -G ""Visual Studio 10 Win64"" ""-DCMAKE_INSTALL_PREFIX=C:\install\path"" msbuild.exe ALL_BUILD.vcxproj msbuild.exe INSTALL.vcxproj For the adventurous, you can cross-compile for Windows from Fedora easily using mingw. sudo yum install mingw64-gcc automake autoconf libtool ./configure --host=x86_64-w64-mingw32 From Git git clone git://github.com/mongodb/libbson.git cd libbson/ git checkout x.y.z  # To build a particular release ./autogen.sh make sudo make install You can run the unit tests with make test From Tarball tar xzf libbson-$ver.tar.gz ./configure make sudo make install Configuration Options You may be interested in the following options for ./configure. These are not availble when using the alternate CMake build system. --help                    Show all possible help options.                           There are many more than those displayed here.  --enable-optimizations    Enable various compile and link optimizations. --enable-debug            Enable debugging features. --enable-debug-symbols    Link with debug symbols in tact. --enable-hardening        Enable stack protector and other hardening features. --enable-silent-rules     Force silent rules like the Linux kernel. --enable-coverage         Compile with gcov support. --enable-static           Build static archives (.a).  Developing using libbson In your source code: #include <bson.h> To get the include path and libraries appropriate for your system. gcc my_program.c $(pkg-config --cflags --libs libbson-1.0) Examples See the examples/ directory for how to use the libbson library in your application. Documentation See the doc/ directory for documentation on individual types. Bug reports and Feature requests Please use the MongoDB C Driver JIRA project to report bugs or request features. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/mongodb/libbson"	"A BSON utility library.."	"true"
"Utilities"	"libCello"	"http://libcello.org/"	"A library introducing higher-level programming to C.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"2924"	"214"	"218"	"GitHub - orangeduck/Cello: Higher level programming in C Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 214 Star 2,924 Fork 218 orangeduck/Cello Code Issues 9 Pull requests 1 Pulse Graphs Higher level programming in C http://libcello.org/ 293 commits 1 branch 1 release 22 contributors C 77.8% Lua 6.1% C++ 3.3% Java 2.2% Python 1.8% JavaScript 1.7% Other 7.1% C Lua C++ Java Python JavaScript Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show v2.0.3 Nothing to show New pull request Latest commit a6a7354 Jan 21, 2016 orangeduck Merge pull request #98 from sbwhitecap/master … Add MSYS2 support Permalink Failed to load latest commit information. benchmarks Linux merge Jun 15, 2015 examples Updated examples Jun 16, 2015 include screwed with some defines Jun 16, 2015 src Cello should now work on environments without threads. Sep 10, 2015 tests Cello should now work on environments without threads. Sep 10, 2015 .gitattributes added gitattributes Dec 9, 2013 .gitignore Windows merge WIP Lists debugging Feb 5, 2015 LICENSE.md Started hacking out autotools Jul 22, 2013 Makefile Should use MinGW64 toolchain on MSYS2 Jan 21, 2016 README.md Fix var name Nov 7, 2015 TODO.md Moved exception mechanics to own location Jun 15, 2015 README.md Cello Cello is a library that brings higher level programming to C. By acting as a modern, powerful runtime system Cello makes many things easy that were previously impractical or awkward in C such as: Generic Data Structures Polymorphic Functions Interfaces / Type Classes Constructors / Destructors Optional Garbage Collection Exceptions Reflection And because Cello works seamlessly alongside standard C you get all the other benefits such as great performance, powerful tooling, and extensive libraries. Examples #include ""Cello.h""  int main(int argc, char** argv) {    /* Stack objects are created using ""$"" */   var i0 = $(Int, 5);   var i1 = $(Int, 3);   var i2 = $(Int, 4);    /* Heap objects are created using ""new"" */   var items = new(Array, Int, i0, i1, i2);    /* Collections can be looped over */   foreach (item in items) {     print(""Object %$ is of type %$\n"",       item, type_of(item));   }    /* Heap objects destructed via Garbage Collection */   return 0; } #include ""Cello.h""  int main(int argc, char** argv) {    /* Shorthand $ can be used for basic types */   var prices = new(Table, String, Int);   set(prices, $S(""Apple""),  $I(12));    set(prices, $S(""Banana""), $I( 6));    set(prices, $S(""Pear""),   $I(55));     /* Tables also support iteration */   foreach (key in prices) {     var val = get(prices, key);     print(""Price of %$ is %$\n"", key, val);   }    return 0; } Articles Learning Resources. Installation Cello World Quickstart Common Queries / Pitfalls Articles about its creation and internal workings. Best Improvements of Cello 2.0 A Fat Pointer Library Cello vs C++ vs ObjC Benchmarks Garbage Collection More Examples #include ""Cello.h""  int main(int argc, char** argv) {    var items = new(Array, Int,      $I( 8), $I( 5), $I(20),      $I(15), $I(16), $I(98));    /* Iterate over indices using ""range"" */   foreach (i in range($I(len(items)))) {     print(""Item Range %i is %i\n"", i, get(items, i));   }    /* Iterate over every other item with ""slice"" */    foreach (item in slice(items, _, _, $I(2))) {     print(""Item Slice %i\n"", item);   }    return 0; } #include ""Cello.h""  /* Define a normal C structure */ struct Point {   float x, y; };  /* Make it compatible with Cello */ var Point = Cello(Point);  int main(int argc, char** argv) {    /* Create on Stack or Heap */   var p0 = $(Point, 0.0, 1.0);   var p1 = new(Point, $(Point, 0.0, 2.0));    /* It can be shown, compared, hashed, etc...   **   ** p0: <'Point' At 0x000000000022FC58>   ** p1: <'Point' At 0x00000000004C7CC8>   ** cmp: 1   ** hash: 2849275892l   */    print(""p0: %$\np1: %$\ncmp: %i\nhash: %ul\n"",     p0, p1, $I(cmp(p0, p1)), $I(hash(p0)));    /* And collected by the GC when out of scope */   return 0; } F.A.Q Why does this exist? I made Cello as a fun experiment to see what C looks like hacked to its limits. As well as being a powerful library and toolkit, it should be interesting to those who want to explore what is possible in C. How does it work? I recommend reading A Fat Pointer Library to get an overview of how Cello works.You can also peek at the source code, which I'm told is fairly readable, or ask me any questions you like via e-mail. Can it be used in Production? It might be better to try Cello out on a hobby project first. Cello does aim to be production ready, but because it is a hack it has its fair share of oddities and pitfalls, and if you are working in a team, or to a deadline, there is much better tooling, support and community for languages such as C++. Is anyone using Cello? People have experimented with it, but there is no high profile project I know of that uses it. Cello is too big and scary a dependency for new C projects if they want to be portable and easy to maintain. Can I get involved? Yes! That would be great. If you do anything with Cello I'd love to know, you can e-mail me at contact@theorangeduck.com, or help with the development at the Cello github repo. Contributions are very welcome. Who are you? Hello! I'm Daniel Holden. You many know me from a book I wrote or my personal website. I also have a rarely updated twitter account. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/orangeduck/libCello"	"A library introducing higher-level programming to C.."	"true"
"Utilities"	"libcox"	"http://libcox.net/"	"A library which permits cross-platform system calls and standard utilities across different operating systems.."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"A library which permits cross-platform system calls and standard utilities across different operating systems.."	"false"
"Utilities"	"libffi"	"https://github.com/libffi/libffi"	"A portable foreign-function interface library.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"586"	"55"	"185"	"GitHub - libffi/libffi: A portable foreign-function interface library. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 55 Star 586 Fork 185 libffi/libffi Code Issues 63 Pull requests 9 Pulse Graphs A portable foreign-function interface library. http://sourceware.org/libffi 984 commits 1 branch 8 releases 62 contributors C 63.0% Assembly 19.0% Groff 11.6% M4 4.4% Makefile 0.6% Shell 0.5% Other 0.9% C Assembly Groff M4 Makefile Shell Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show v3.2.1 v3.2 v3.1 v3.0.13 v3.0.12 v3.0.11 v3.0.10 v3.0.9 Nothing to show New pull request Latest commit 40e4063 Jul 7, 2016 rth7680 committed on GitHub Merge pull request #261 from tromey/fix-260 … Don't dereference ""ecif"" before NULL check Permalink Failed to load latest commit information. doc Merge pull request #212 from tromey/struct-layout Mar 14, 2016 include minor comment cleanup May 4, 2016 libffi.xcodeproj Darwin: Merge build scripts, redo project, incl. arm64 Feb 5, 2014 m4 Fix issue with builddir when calling configure with absolute path Jun 25, 2014 man Remove autogenerated files from the repository Mar 16, 2014 src Don't dereference ""ecif"" before NULL check Jun 17, 2016 testsuite Merge pull request #237 from tschwinge/libffi_feature_test May 23, 2016 .gitignore remove and ignore texinfo.tex Feb 22, 2016 .travis.yml Delete empty env in .travis.yml May 19, 2016 ChangeLog.libffi Test GCC update Jan 2, 2013 ChangeLog.libffi-3.1 Generate ChangeLog from git in make dist Mar 16, 2014 ChangeLog.libgcj Initial commit Oct 4, 2009 ChangeLog.v1 ChangeLog.v1: Fix typo in explanatory header. Mar 16, 2014 LICENSE Update copyright date and clean up README notes. Mar 25, 2014 Makefile.am Use ELF symbol versioning May 4, 2016 README Update project URLs to use libffi/libffi May 18, 2016 acinclude.m4 Use ELF symbol versioning May 4, 2016 autogen.sh Remove autogenerated files from the repository Mar 16, 2014 configure.ac [Darwin, configure] Allow configure to work for <arch>-*-darwin. May 26, 2016 configure.host Support the WIN64/EFI64 calling convention on all X86_64 platforms Jul 26, 2015 generate-darwin-source-and-headers.py Simplify error handling in mkdir_p() Mar 5, 2016 libffi.map.in Add parent to symbol version LIBFFI_BASE_7.1 May 18, 2016 libffi.pc.in Update libffi.pc.in May 14, 2013 libtool-ldflags Re-add libtool-ldflags Mar 16, 2014 libtool-version Update symbol versioning for ffi_get_struct_offsets May 4, 2016 msvcc.sh Merge pull request #199 from Pan7/master Feb 20, 2016 stamp-h.in Initial commit Oct 4, 2009 README Status ======  libffi-4?? was released on TBD.  Check the libffi web page for updates: <URL:http://sourceware.org/libffi/>.   What is libffi? ===============  Compilers for high level languages generate code that follow certain conventions. These conventions are necessary, in part, for separate compilation to work. One such convention is the ""calling convention"". The ""calling convention"" is essentially a set of assumptions made by the compiler about where function arguments will be found on entry to a function. A ""calling convention"" also specifies where the return value for a function is found.  Some programs may not know at the time of compilation what arguments are to be passed to a function. For instance, an interpreter may be told at run-time about the number and types of arguments used to call a given function. Libffi can be used in such programs to provide a bridge from the interpreter program to compiled code.  The libffi library provides a portable, high level programming interface to various calling conventions. This allows a programmer to call any function specified by a call interface description at run time.    FFI stands for Foreign Function Interface.  A foreign function interface is the popular name for the interface that allows code written in one language to call code written in another language. The libffi library really only provides the lowest, machine dependent layer of a fully featured foreign function interface. A layer must exist above libffi that handles type conversions for values passed between the two languages.   Supported Platforms ===================  Libffi has been ported to many different platforms. For specific configuration details and testing status, please refer to the wiki page here:   http://www.moxielogic.org/wiki/index.php?title=Libffi_3.2  At the time of release, the following basic configurations have been tested:  |-----------------+------------------+-------------------------| | Architecture    | Operating System | Compiler                | |-----------------+------------------+-------------------------| | AArch64 (ARM64) | iOS              | Clang                   | | AArch64         | Linux            | GCC                     | | Alpha           | Linux            | GCC                     | | Alpha           | Tru64            | GCC                     | | ARC             | Linux            | GCC                     | | ARM             | Linux            | GCC                     | | ARM             | iOS              | GCC                     | | AVR32           | Linux            | GCC                     | | Blackfin        | uClinux          | GCC                     | | HPPA            | HPUX             | GCC                     | | IA-64           | Linux            | GCC                     | | M68K            | FreeMiNT         | GCC                     | | M68K            | Linux            | GCC                     | | M68K            | RTEMS            | GCC                     | | M88K            | OpenBSD/mvme88k  | GCC                     | | Meta            | Linux            | GCC                     | | MicroBlaze      | Linux            | GCC                     | | MIPS            | IRIX             | GCC                     | | MIPS            | Linux            | GCC                     | | MIPS            | RTEMS            | GCC                     | | MIPS64          | Linux            | GCC                     | | Moxie           | Bare metal       | GCC                     | | Nios II         | Linux            | GCC                     | | OpenRISC        | Linux            | GCC                     | | PowerPC 32-bit  | AIX              | IBM XL C                | | PowerPC 64-bit  | AIX              | IBM XL C                | | PowerPC         | AMIGA            | GCC                     | | PowerPC         | Linux            | GCC                     | | PowerPC         | Mac OSX          | GCC                     | | PowerPC         | FreeBSD          | GCC                     | | PowerPC 64-bit  | FreeBSD          | GCC                     | | PowerPC 64-bit  | Linux ELFv1      | GCC                     | | PowerPC 64-bit  | Linux ELFv2      | GCC                     | | S390            | Linux            | GCC                     | | S390X           | Linux            | GCC                     | | SPARC           | Linux            | GCC                     | | SPARC           | Solaris          | GCC                     | | SPARC           | Solaris          | Oracle Solaris Studio C | | SPARC64         | Linux            | GCC                     | | SPARC64         | FreeBSD          | GCC                     | | SPARC64         | Solaris          | Oracle Solaris Studio C | | TILE-Gx/TILEPro | Linux            | GCC                     | | VAX             | OpenBSD/vax      | GCC                     | | X86             | FreeBSD          | GCC                     | | X86             | GNU HURD         | GCC                     | | X86             | Interix          | GCC                     | | X86             | kFreeBSD         | GCC                     | | X86             | Linux            | GCC                     | | X86             | Mac OSX          | GCC                     | | X86             | OpenBSD          | GCC                     | | X86             | OS/2             | GCC                     | | X86             | Solaris          | GCC                     | | X86             | Solaris          | Oracle Solaris Studio C | | X86             | Windows/Cygwin   | GCC                     | | X86             | Windows/MingW    | GCC                     | | X86-64          | FreeBSD          | GCC                     | | X86-64          | Linux            | GCC                     | | X86-64          | Linux/x32        | GCC                     | | X86-64          | OpenBSD          | GCC                     | | X86-64          | Solaris          | Oracle Solaris Studio C | | X86-64          | Windows/Cygwin   | GCC                     | | X86-64          | Windows/MingW    | GCC                     | | Xtensa          | Linux            | GCC                     | |-----------------+------------------+-------------------------|  Please send additional platform test results to libffi-discuss@sourceware.org and feel free to update the wiki page above.  Installing libffi =================  First you must configure the distribution for your particular system. Go to the directory you wish to build libffi in and run the ""configure"" program found in the root directory of the libffi source distribution.  If you're building libffi directly from version control, configure won't exist yet; run ./autogen.sh first.  You may want to tell configure where to install the libffi library and header files. To do that, use the --prefix configure switch.  Libffi will install under /usr/local by default.   If you want to enable extra run-time debugging checks use the the --enable-debug configure switch. This is useful when your program dies mysteriously while using libffi.   Another useful configure switch is --enable-purify-safety. Using this will add some extra code which will suppress certain warnings when you are using Purify with libffi. Only use this switch when using  Purify, as it will slow down the library.  If you don't want to build documentation, use the --disable-docs configure switch.  It's also possible to build libffi on Windows platforms with Microsoft's Visual C++ compiler.  In this case, use the msvcc.sh wrapper script during configuration like so:  path/to/configure CC=path/to/msvcc.sh CXX=path/to/msvcc.sh LD=link CPP=""cl -nologo -EP""  For 64-bit Windows builds, use CC=""path/to/msvcc.sh -m64"" and CXX=""path/to/msvcc.sh -m64"".  You may also need to specify --build appropriately.  It is also possible to build libffi on Windows platforms with the LLVM project's clang-cl compiler, like below:  path/to/configure CC=""path/to/msvcc.sh -clang-cl"" CXX=""path/to/msvcc.sh -clang-cl"" LD=link CPP=""clang-cl -EP""  When building with MSVC under a MingW environment, you may need to remove the line in configure that sets 'fix_srcfile_path' to a 'cygpath' command.  ('cygpath' is not present in MingW, and is not required when using MingW-style paths.)  For iOS builds, the 'libffi.xcodeproj' Xcode project is available.  Configure has many other options. Use ""configure --help"" to see them all.  Once configure has finished, type ""make"". Note that you must be using GNU make.  You can ftp GNU make from ftp.gnu.org:/pub/gnu/make .  To ensure that libffi is working as advertised, type ""make check"". This will require that you have DejaGNU installed.  To install the library and header files, type ""make install"".   History =======  See the git log for details at http://github.com/libffi/libffi.  4.0 TBD         New API in support of GO closures.  3.2.1 Nov-12-14         Build fix for non-iOS AArch64 targets.  3.2 Nov-11-14         Add C99 Complex Type support (currently only supported on           s390). 	Add support for PASCAL and REGISTER calling conventions on x86 	  Windows/Linux. 	Add OpenRISC and Cygwin-64 support.         Bug fixes.  3.1 May-19-14         Add AArch64 (ARM64) iOS support.         Add Nios II support.         Add m88k and DEC VAX support. 	Add support for stdcall, thiscall, and fastcall on non-Windows 	  32-bit x86 targets such as Linux. 	Various Android, MIPS N32, x86, FreeBSD and UltraSPARC IIi 	  fixes. 	Make the testsuite more robust: eliminate several spurious 	  failures, and respect the $CC and $CXX environment variables. 	Archive off the manually maintained ChangeLog in favor of git 	  log.  3.0.13 Mar-17-13 	Add Meta support. 	Add missing Moxie bits. 	Fix stack alignment bug on 32-bit x86. 	Build fix for m68000 targets. 	Build fix for soft-float Power targets. 	Fix the install dir location for some platforms when building 	  with GCC (OS X, Solaris). 	Fix Cygwin regression.  3.0.12 Feb-11-13         Add Moxie support. 	Add AArch64 support. 	Add Blackfin support. 	Add TILE-Gx/TILEPro support. 	Add MicroBlaze support. 	Add Xtensa support. 	Add support for PaX enabled kernels with MPROTECT. 	Add support for native vendor compilers on 	  Solaris and AIX. 	Work around LLVM/GCC interoperability issue on x86_64.  3.0.11 Apr-11-12         Lots of build fixes. 	Add support for variadic functions (ffi_prep_cif_var). 	Add Linux/x32 support. 	Add thiscall, fastcall and MSVC cdecl support on Windows. 	Add Amiga and newer MacOS support. 	Add m68k FreeMiNT support. 	Integration with iOS' xcode build tools. 	Fix Octeon and MC68881 support. 	Fix code pessimizations.  3.0.10 Aug-23-11         Add support for Apple's iOS. 	Add support for ARM VFP ABI.         Add RTEMS support for MIPS and M68K. 	Fix instruction cache clearing problems on 	  ARM and SPARC. 	Fix the N64 build on mips-sgi-irix6.5. 	Enable builds with Microsoft's compiler. 	Enable x86 builds with Oracle's Solaris compiler. 	Fix support for calling code compiled with Oracle's Sparc 	  Solaris compiler. 	Testsuite fixes for Tru64 Unix. 	Additional platform support.  3.0.9 Dec-31-09         Add AVR32 and win64 ports.  Add ARM softfp support. 	Many fixes for AIX, Solaris, HP-UX, *BSD. 	Several PowerPC and x86-64 bug fixes. 	Build DLL for windows.  3.0.8 Dec-19-08         Add *BSD, BeOS, and PA-Linux support.  3.0.7 Nov-11-08         Fix for ppc FreeBSD. 	(thanks to Andreas Tobler)  3.0.6 Jul-17-08         Fix for closures on sh. 	Mark the sh/sh64 stack as non-executable. 	(both thanks to Kaz Kojima)  3.0.5 Apr-3-08         Fix libffi.pc file. 	Fix #define ARM for IcedTea users. 	Fix x86 closure bug.  3.0.4 Feb-24-08         Fix x86 OpenBSD configury.  3.0.3 Feb-22-08         Enable x86 OpenBSD thanks to Thomas Heller, and 	x86-64 FreeBSD thanks to Björn König and Andreas Tobler. 	Clean up test instruction in README.  3.0.2 Feb-21-08         Improved x86 FreeBSD support. 	Thanks to Björn König.  3.0.1 Feb-15-08         Fix instruction cache flushing bug on MIPS. 	Thanks to David Daney.  3.0.0 Feb-15-08         Many changes, mostly thanks to the GCC project. 	Cygnus Solutions is now Red Hat.    [10 years go by...]  1.20 Oct-5-98 	Raffaele Sena produces ARM port.  1.19 Oct-5-98 	Fixed x86 long double and long long return support. 	m68k bug fixes from Andreas Schwab. 	Patch for DU assembler compatibility for the Alpha from Richard 	Henderson.  1.18 Apr-17-98 	Bug fixes and MIPS configuration changes.  1.17 Feb-24-98 	Bug fixes and m68k port from Andreas Schwab. PowerPC port from 	Geoffrey Keating. Various bug x86, Sparc and MIPS bug fixes.  1.16 Feb-11-98 	Richard Henderson produces Alpha port.  1.15 Dec-4-97 	Fixed an n32 ABI bug. New libtool, auto* support.  1.14 May-13-97 	libtool is now used to generate shared and static libraries. 	Fixed a minor portability problem reported by Russ McManus 	<mcmanr@eq.gs.com>.  1.13 Dec-2-96 	Added --enable-purify-safety to keep Purify from complaining 	about certain low level code. 	Sparc fix for calling functions with < 6 args. 	Linux x86 a.out fix.  1.12 Nov-22-96 	Added missing ffi_type_void, needed for supporting void return  	types. Fixed test case for non MIPS machines. Cygnus Support  	is now Cygnus Solutions.   1.11 Oct-30-96 	Added notes about GNU make.  1.10 Oct-29-96 	Added configuration fix for non GNU compilers.  1.09 Oct-29-96 	Added --enable-debug configure switch. Clean-ups based on LCLint  	feedback. ffi_mips.h is always installed. Many configuration  	fixes. Fixed ffitest.c for sparc builds.  1.08 Oct-15-96 	Fixed n32 problem. Many clean-ups.  1.07 Oct-14-96 	Gordon Irlam rewrites v8.S again. Bug fixes.  1.06 Oct-14-96 	Gordon Irlam improved the sparc port.   1.05 Oct-14-96 	Interface changes based on feedback.  1.04 Oct-11-96 	Sparc port complete (modulo struct passing bug).  1.03 Oct-10-96 	Passing struct args, and returning struct values works for 	all architectures/calling conventions. Expanded tests.  1.02 Oct-9-96 	Added SGI n32 support. Fixed bugs in both o32 and Linux support. 	Added ""make test"".  1.01 Oct-8-96 	Fixed float passing bug in mips version. Restructured some 	of the code. Builds cleanly with SGI tools.  1.00 Oct-7-96 	First release. No public announcement.   Authors & Credits =================  libffi was originally written by Anthony Green <green@moxielogic.com>.  The developers of the GNU Compiler Collection project have made innumerable valuable contributions.  See the ChangeLog file for details.  Some of the ideas behind libffi were inspired by Gianni Mariani's free gencall library for Silicon Graphics machines.  The closure mechanism was designed and implemented by Kresten Krab Thorup.  Major processor architecture ports were contributed by the following developers:  aarch64		Marcus Shawcroft, James Greenhalgh alpha		Richard Henderson arm		Raffaele Sena blackfin        Alexandre Keunecke I. de Mendonca cris		Simon Posnjak, Hans-Peter Nilsson frv		Anthony Green ia64		Hans Boehm m32r		Kazuhiro Inaoka m68k		Andreas Schwab m88k		Miod Vallat microblaze	Nathan Rossi mips		Anthony Green, Casey Marshall mips64		David Daney moxie		Anthony Green nios ii		Sandra Loosemore openrisc        Sebastian Macke pa		Randolph Chung, Dave Anglin, Andreas Tobler powerpc		Geoffrey Keating, Andreas Tobler,  			 David Edelsohn, John Hornkvist powerpc64	Jakub Jelinek s390		Gerhard Tonn, Ulrich Weigand sh		Kaz Kojima sh64		Kaz Kojima sparc		Anthony Green, Gordon Irlam tile-gx/tilepro Walter Lee vax		Miod Vallat x86		Anthony Green, Jon Beniston x86-64		Bo Thorsen xtensa		Chris Zankel  Jesper Skov and Andrew Haley both did more than their fair share of stepping through the code and tracking down bugs.  Thanks also to Tom Tromey for bug fixes, documentation and configuration help.  Thanks to Jim Blandy, who provided some useful feedback on the libffi interface.  Andreas Tobler has done a tremendous amount of work on the testsuite.  Alex Oliva solved the executable page problem for SElinux.  The list above is almost certainly incomplete and inaccurate.  I'm happy to make corrections or additions upon request.  If you have a problem, or have found a bug, please send a note to the author at green@moxielogic.com, or the project mailing list at libffi-discuss@sourceware.org.  Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/libffi/libffi"	"A portable foreign-function interface library.."	"true"
"Utilities"	"libgit2"	"https://libgit2.github.com/"	"Pure C implementation of Git.."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"libgit2 Downloads Reference Learning Source libgit2 is a portable, pure C implementation of the Git core methods provided as a re-entrant linkable library with a solid API, allowing you to write native speed custom Git applications in any language which supports C bindings. 100% Cross-Platform Linux, FreeBSD, OpenBSD, Mac OS X, iOS, Amiga, MinGW and fully native Windows. Zero Dependencies Builds out of the box with no dependencies. Works in embedded devices and iOS. C89 Written with portability in mind. Builds in GCC, Clang and MSVC. Permissive Licensing GPLv2 with Linking Exception. Link with open and proprietary software, no strings attached. Trusted and used in production by Language Bindings Ruby Rugged .Net & Mono LibGit2Sharp Objective-C objective-git Python pygit2 Perl Git::Raw Node.js nodegit Go git2go Erlang Geef GObject libgit2-glib Lua luagit2 Parrot VM parrot-libgit2 C++ Qt libqgit2 PHP php-git Chicken Scheme chicken-git D dlibgit And many more This open sourced site is hosted on GitHub. Patches, suggestions, and comments are welcome."	"null"	"https://libgit2.github.com/"	"Pure C implementation of Git.."	"true"
"Utilities"	"GNU GPL2 only, with a linking exception"	"https://github.com/libgit2/libgit2/blob/master/COPYING"	"Pure C implementation of Git.."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"5704"	"418"	"1387"	"libgit2/COPYING at master · libgit2/libgit2 · GitHub Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 418 Star 5,704 Fork 1,387 libgit2/libgit2 Code Issues 107 Pull requests 51 Pulse Graphs Permalink Branch: master Switch branches/tags Branches Tags bindings/libgit2sharp/020_2 bug/status_case clay-test cmn/auth-retry cmn/cancellation cmn/commit-on cmn/commit-to-memory cmn/commit-with-signature cmn/config-repeated cmn/ctest-jobs cmn/delta-base-eviction cmn/diff-binary-patch cmn/example-pull cmn/extract-oneline-sig cmn/forbid-mutiurl cmn/header-field-2 cmn/index-nolock cmn/init-libssh2 cmn/init-ssh cmn/io-stream-backends cmn/leaks cmn/mwindow-try-harder cmn/parallel-clar cmn/pool-limit cmn/read-only-size cmn/read-shared cmn/refdb-para cmn/remote-options cmn/remove-single-entry cmn/repo-v1 cmn/rpath-policy cmn/server cmn/strict-object cmn/tmp cmn/tree-parser-sort-input cmn/tree-update-basename cmn/typo cmn/warnings development diff-fails-with-cpp-file empty-name error-handling ethomson/annotated_commit_refs ethomson/checkout_conflict_respect_index ethomson/checkout_head_docs ethomson/checkout_no_index ethomson/cmake_pc ethomson/leaks ethomson/racy-diff ethomson/read_index_conflicts ethomson/readme ethomson/rebase_detached ethomson/rebase_inmemory_no_base ethomson/refresh_objects ethomson/revwalk_hide_old ethomson/signature_from_buffer ethomson/submodule_status ethomson/unborn_head ethomson/warnings features/push_old features/push filename-containing-bracket fileops fix-submodule-config-loading getenv-win32 gh-pages gpgsign halloc hf/libgit2sharp_020_patch hf/master_patch hf/021_patch jamill/push_fetch_first jamill/rebase_opt_ver_check jamill/submodule_update jss/fix-ignore-pop longpath-printf maint/v0.21 maint/v0.22 maint/v0.23 maint/v0.24 master merge more-api-tweaks new-error-handling niik/disable-tree-entry-pool-on-win32 ntk/appveyor_install ntk/expose_git_buf_put ntk/reflog_branch_create ntk/topic/config_rename_better_error precompose-test rb/commit-modified-file rb/filter-options rb/object-parse-flexibility rb/test-builtin-drivers rb/warnings-for-commit-headers refresh-submodule-on-lookup status-with-subdir stopwatch threadsafe topic/CRLF_blob_filtered_content vmg/attr-null vmg/commit-leak vmg/crud vmg/empty vmg/expand-fixes vmg/index-fill-2 vmg/index-fill vmg/mkdir-ext vmg/odb-lookups vmg/panic vmg/pkg-config-sort vmg/pool-align vmg/pool vmg/prefix-len vmg/read-types vmg/redundant vmg/repo-format-1 vmg/reuc-insert vmg/winrc-filename Nothing to show v0.24.1 v0.24.0 v0.24.0-rc1 v0.23.4 v0.23.3 v0.23.2 v0.23.1 v0.23.0 v0.23.0-rc2 v0.23.0-rc1 v0.22.3 v0.22.2 v0.22.1 v0.22.0 v0.22.0-rc2 v0.22.0-rc1 v0.21.5 v0.21.4 v0.21.3 v0.21.2 v0.21.1 v0.21.0 v0.21.0-rc2 v0.21.0-rc1 v0.20.0 v0.19.0 v0.18.0 v0.17.0 v0.16.0 v0.15.0 v0.14.0 v0.13.0 v0.12.0 v0.11.0 v0.10.0 v0.8.0 v0.3.0 v0.2.0 v0.1.0 Nothing to show Find file Copy path libgit2/COPYING afe0ff1 Aug 25, 2015 ethomson COPYING: include winhttp definition copyright 8 contributors Users who have contributed to this file ethomson arrbee schu spearce martinwoodward kiryl vmg carlosmn Raw Blame History 961 lines (783 sloc) 48.5 KB libgit2 is Copyright (C) the libgit2 contributors, unless otherwise stated. See the AUTHORS file for details. Note that the only valid version of the GPL as far as this project is concerned is _this_ particular version of the license (ie v2, not v2.2 or v3.x or whatever), unless explicitly otherwise stated. ---------------------------------------------------------------------- LINKING EXCEPTION In addition to the permissions in the GNU General Public License, the authors give you unlimited permission to link the compiled version of this library into combinations with other programs, and to distribute those combinations without any restriction coming from the use of this file. (The General Public License restrictions do apply in other respects; for example, they cover modification of the file, and distribution when not linked into a combined executable.) ---------------------------------------------------------------------- GNU GENERAL PUBLIC LICENSE Version 2, June 1991 Copyright (C) 1989, 1991 Free Software Foundation, Inc. 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed. Preamble The licenses for most software are designed to take away your freedom to share and change it. By contrast, the GNU General Public License is intended to guarantee your freedom to share and change free software--to make sure the software is free for all its users. This General Public License applies to most of the Free Software Foundation's software and to any other program whose authors commit to using it. (Some other Free Software Foundation software is covered by the GNU Library General Public License instead.) You can apply it to your programs, too. When we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for this service if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs; and that you know you can do these things. To protect your rights, we need to make restrictions that forbid anyone to deny you these rights or to ask you to surrender the rights. These restrictions translate to certain responsibilities for you if you distribute copies of the software, or if you modify it. For example, if you distribute copies of such a program, whether gratis or for a fee, you must give the recipients all the rights that you have. You must make sure that they, too, receive or can get the source code. And you must show them these terms so they know their rights. We protect your rights with two steps: (1) copyright the software, and (2) offer you this license which gives you legal permission to copy, distribute and/or modify the software. Also, for each author's protection and ours, we want to make certain that everyone understands that there is no warranty for this free software. If the software is modified by someone else and passed on, we want its recipients to know that what they have is not the original, so that any problems introduced by others will not reflect on the original authors' reputations. Finally, any free program is threatened constantly by software patents. We wish to avoid the danger that redistributors of a free program will individually obtain patent licenses, in effect making the program proprietary. To prevent this, we have made it clear that any patent must be licensed for everyone's free use or not licensed at all. The precise terms and conditions for copying, distribution and modification follow. GNU GENERAL PUBLIC LICENSE TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION 0. This License applies to any program or other work which contains a notice placed by the copyright holder saying it may be distributed under the terms of this General Public License. The ""Program"", below, refers to any such program or work, and a ""work based on the Program"" means either the Program or any derivative work under copyright law: that is to say, a work containing the Program or a portion of it, either verbatim or with modifications and/or translated into another language. (Hereinafter, translation is included without limitation in the term ""modification"".) Each licensee is addressed as ""you"". Activities other than copying, distribution and modification are not covered by this License; they are outside its scope. The act of running the Program is not restricted, and the output from the Program is covered only if its contents constitute a work based on the Program (independent of having been made by running the Program). Whether that is true depends on what the Program does. 1. You may copy and distribute verbatim copies of the Program's source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice and disclaimer of warranty; keep intact all the notices that refer to this License and to the absence of any warranty; and give any other recipients of the Program a copy of this License along with the Program. You may charge a fee for the physical act of transferring a copy, and you may at your option offer warranty protection in exchange for a fee. 2. You may modify your copy or copies of the Program or any portion of it, thus forming a work based on the Program, and copy and distribute such modifications or work under the terms of Section 1 above, provided that you also meet all of these conditions: a) You must cause the modified files to carry prominent notices stating that you changed the files and the date of any change. b) You must cause any work that you distribute or publish, that in whole or in part contains or is derived from the Program or any part thereof, to be licensed as a whole at no charge to all third parties under the terms of this License. c) If the modified program normally reads commands interactively when run, you must cause it, when started running for such interactive use in the most ordinary way, to print or display an announcement including an appropriate copyright notice and a notice that there is no warranty (or else, saying that you provide a warranty) and that users may redistribute the program under these conditions, and telling the user how to view a copy of this License. (Exception: if the Program itself is interactive but does not normally print such an announcement, your work based on the Program is not required to print an announcement.) These requirements apply to the modified work as a whole. If identifiable sections of that work are not derived from the Program, and can be reasonably considered independent and separate works in themselves, then this License, and its terms, do not apply to those sections when you distribute them as separate works. But when you distribute the same sections as part of a whole which is a work based on the Program, the distribution of the whole must be on the terms of this License, whose permissions for other licensees extend to the entire whole, and thus to each and every part regardless of who wrote it. Thus, it is not the intent of this section to claim rights or contest your rights to work written entirely by you; rather, the intent is to exercise the right to control the distribution of derivative or collective works based on the Program. In addition, mere aggregation of another work not based on the Program with the Program (or with a work based on the Program) on a volume of a storage or distribution medium does not bring the other work under the scope of this License. 3. You may copy and distribute the Program (or a work based on it, under Section 2) in object code or executable form under the terms of Sections 1 and 2 above provided that you also do one of the following: a) Accompany it with the complete corresponding machine-readable source code, which must be distributed under the terms of Sections 1 and 2 above on a medium customarily used for software interchange; or, b) Accompany it with a written offer, valid for at least three years, to give any third party, for a charge no more than your cost of physically performing source distribution, a complete machine-readable copy of the corresponding source code, to be distributed under the terms of Sections 1 and 2 above on a medium customarily used for software interchange; or, c) Accompany it with the information you received as to the offer to distribute corresponding source code. (This alternative is allowed only for noncommercial distribution and only if you received the program in object code or executable form with such an offer, in accord with Subsection b above.) The source code for a work means the preferred form of the work for making modifications to it. For an executable work, complete source code means all the source code for all modules it contains, plus any associated interface definition files, plus the scripts used to control compilation and installation of the executable. However, as a special exception, the source code distributed need not include anything that is normally distributed (in either source or binary form) with the major components (compiler, kernel, and so on) of the operating system on which the executable runs, unless that component itself accompanies the executable. If distribution of executable or object code is made by offering access to copy from a designated place, then offering equivalent access to copy the source code from the same place counts as distribution of the source code, even though third parties are not compelled to copy the source along with the object code. 4. You may not copy, modify, sublicense, or distribute the Program except as expressly provided under this License. Any attempt otherwise to copy, modify, sublicense or distribute the Program is void, and will automatically terminate your rights under this License. However, parties who have received copies, or rights, from you under this License will not have their licenses terminated so long as such parties remain in full compliance. 5. You are not required to accept this License, since you have not signed it. However, nothing else grants you permission to modify or distribute the Program or its derivative works. These actions are prohibited by law if you do not accept this License. Therefore, by modifying or distributing the Program (or any work based on the Program), you indicate your acceptance of this License to do so, and all its terms and conditions for copying, distributing or modifying the Program or works based on it. 6. Each time you redistribute the Program (or any work based on the Program), the recipient automatically receives a license from the original licensor to copy, distribute or modify the Program subject to these terms and conditions. You may not impose any further restrictions on the recipients' exercise of the rights granted herein. You are not responsible for enforcing compliance by third parties to this License. 7. If, as a consequence of a court judgment or allegation of patent infringement or for any other reason (not limited to patent issues), conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License. If you cannot distribute so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not distribute the Program at all. For example, if a patent license would not permit royalty-free redistribution of the Program by all those who receive copies directly or indirectly through you, then the only way you could satisfy both it and this License would be to refrain entirely from distribution of the Program. If any portion of this section is held invalid or unenforceable under any particular circumstance, the balance of the section is intended to apply and the section as a whole is intended to apply in other circumstances. It is not the purpose of this section to induce you to infringe any patents or other property right claims or to contest validity of any such claims; this section has the sole purpose of protecting the integrity of the free software distribution system, which is implemented by public license practices. Many people have made generous contributions to the wide range of software distributed through that system in reliance on consistent application of that system; it is up to the author/donor to decide if he or she is willing to distribute software through any other system and a licensee cannot impose that choice. This section is intended to make thoroughly clear what is believed to be a consequence of the rest of this License. 8. If the distribution and/or use of the Program is restricted in certain countries either by patents or by copyrighted interfaces, the original copyright holder who places the Program under this License may add an explicit geographical distribution limitation excluding those countries, so that distribution is permitted only in or among countries not thus excluded. In such case, this License incorporates the limitation as if written in the body of this License. 9. The Free Software Foundation may publish revised and/or new versions of the General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns. Each version is given a distinguishing version number. If the Program specifies a version number of this License which applies to it and ""any later version"", you have the option of following the terms and conditions either of that version or of any later version published by the Free Software Foundation. If the Program does not specify a version number of this License, you may choose any version ever published by the Free Software Foundation. 10. If you wish to incorporate parts of the Program into other free programs whose distribution conditions are different, write to the author to ask for permission. For software which is copyrighted by the Free Software Foundation, write to the Free Software Foundation; we sometimes make exceptions for this. Our decision will be guided by the two goals of preserving the free status of all derivatives of our free software and of promoting the sharing and reuse of software generally. NO WARRANTY 11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM ""AS IS"" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION. 12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. END OF TERMS AND CONDITIONS How to Apply These Terms to Your New Programs If you develop a new program, and you want it to be of the greatest possible use to the public, the best way to achieve this is to make it free software which everyone can redistribute and change under these terms. To do so, attach the following notices to the program. It is safest to attach them to the start of each source file to most effectively convey the exclusion of warranty; and each file should have at least the ""copyright"" line and a pointer to where the full notice is found. <one line to give the program's name and a brief idea of what it does.> Copyright (C) <year> <name of author> This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this program; if not, write to the Free Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA Also add information on how to contact you by electronic and paper mail. If the program is interactive, make it output a short notice like this when it starts in an interactive mode: Gnomovision version 69, Copyright (C) year name of author Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'. This is free software, and you are welcome to redistribute it under certain conditions; type `show c' for details. The hypothetical commands `show w' and `show c' should show the appropriate parts of the General Public License. Of course, the commands you use may be called something other than `show w' and `show c'; they could even be mouse-clicks or menu items--whatever suits your program. You should also get your employer (if you work as a programmer) or your school, if any, to sign a ""copyright disclaimer"" for the program, if necessary. Here is a sample; alter the names: Yoyodyne, Inc., hereby disclaims all copyright interest in the program `Gnomovision' (which makes passes at compilers) written by James Hacker. <signature of Ty Coon>, 1 April 1989 Ty Coon, President of Vice This General Public License does not permit incorporating your program into proprietary programs. If your program is a subroutine library, you may consider it more useful to permit linking proprietary applications with the library. If this is what you want to do, use the GNU Library General Public License instead of this License. ---------------------------------------------------------------------- The bundled ZLib code is licensed under the ZLib license: Copyright (C) 1995-2010 Jean-loup Gailly and Mark Adler This software is provided 'as-is', without any express or implied warranty. In no event will the authors be held liable for any damages arising from the use of this software. Permission is granted to anyone to use this software for any purpose, including commercial applications, and to alter it and redistribute it freely, subject to the following restrictions: 1. The origin of this software must not be misrepresented; you must not claim that you wrote the original software. If you use this software in a product, an acknowledgment in the product documentation would be appreciated but is not required. 2. Altered source versions must be plainly marked as such, and must not be misrepresented as being the original software. 3. This notice may not be removed or altered from any source distribution. Jean-loup Gailly Mark Adler jloup@gzip.org madler@alumni.caltech.edu ---------------------------------------------------------------------- The Clar framework is licensed under the ISC license: Copyright (c) 2011-2015 Vicent Marti Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED ""AS IS"" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. ---------------------------------------------------------------------- The regex library (deps/regex/) is licensed under the GNU LGPL (available at the end of this file). Definitions for data structures and routines for the regular expression library. Copyright (C) 1985,1989-93,1995-98,2000,2001,2002,2003,2005,2006,2008 Free Software Foundation, Inc. This file is part of the GNU C Library. The GNU C Library is free software; you can redistribute it and/or modify it under the terms of the GNU Lesser General Public License as published by the Free Software Foundation; either version 2.1 of the License, or (at your option) any later version. The GNU C Library is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details. You should have received a copy of the GNU Lesser General Public License along with the GNU C Library; if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA. ---------------------------------------------------------------------- The bundled winhttp definition files (deps/winhttp/) are licensed under the GNU LGPL (available at the end of this file). Copyright (C) 2007 Francois Gouget This library is free software; you can redistribute it and/or modify it under the terms of the GNU Lesser General Public License as published by the Free Software Foundation; either version 2.1 of the License, or (at your option) any later version. This library is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details. You should have received a copy of the GNU Lesser General Public License along with this library; if not, write to the Free Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA ---------------------------------------------------------------------- GNU LESSER GENERAL PUBLIC LICENSE Version 2.1, February 1999 Copyright (C) 1991, 1999 Free Software Foundation, Inc. 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed. [This is the first released version of the Lesser GPL. It also counts as the successor of the GNU Library Public License, version 2, hence the version number 2.1.] Preamble The licenses for most software are designed to take away your freedom to share and change it. By contrast, the GNU General Public Licenses are intended to guarantee your freedom to share and change free software--to make sure the software is free for all its users. This license, the Lesser General Public License, applies to some specially designated software packages--typically libraries--of the Free Software Foundation and other authors who decide to use it. You can use it too, but we suggest you first think carefully about whether this license or the ordinary General Public License is the better strategy to use in any particular case, based on the explanations below. When we speak of free software, we are referring to freedom of use, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for this service if you wish); that you receive source code or can get it if you want it; that you can change the software and use pieces of it in new free programs; and that you are informed that you can do these things. To protect your rights, we need to make restrictions that forbid distributors to deny you these rights or to ask you to surrender these rights. These restrictions translate to certain responsibilities for you if you distribute copies of the library or if you modify it. For example, if you distribute copies of the library, whether gratis or for a fee, you must give the recipients all the rights that we gave you. You must make sure that they, too, receive or can get the source code. If you link other code with the library, you must provide complete object files to the recipients, so that they can relink them with the library after making changes to the library and recompiling it. And you must show them these terms so they know their rights. We protect your rights with a two-step method: (1) we copyright the library, and (2) we offer you this license, which gives you legal permission to copy, distribute and/or modify the library. To protect each distributor, we want to make it very clear that there is no warranty for the free library. Also, if the library is modified by someone else and passed on, the recipients should know that what they have is not the original version, so that the original author's reputation will not be affected by problems that might be introduced by others. Finally, software patents pose a constant threat to the existence of any free program. We wish to make sure that a company cannot effectively restrict the users of a free program by obtaining a restrictive license from a patent holder. Therefore, we insist that any patent license obtained for a version of the library must be consistent with the full freedom of use specified in this license. Most GNU software, including some libraries, is covered by the ordinary GNU General Public License. This license, the GNU Lesser General Public License, applies to certain designated libraries, and is quite different from the ordinary General Public License. We use this license for certain libraries in order to permit linking those libraries into non-free programs. When a program is linked with a library, whether statically or using a shared library, the combination of the two is legally speaking a combined work, a derivative of the original library. The ordinary General Public License therefore permits such linking only if the entire combination fits its criteria of freedom. The Lesser General Public License permits more lax criteria for linking other code with the library. We call this license the ""Lesser"" General Public License because it does Less to protect the user's freedom than the ordinary General Public License. It also provides other free software developers Less of an advantage over competing non-free programs. These disadvantages are the reason we use the ordinary General Public License for many libraries. However, the Lesser license provides advantages in certain special circumstances. For example, on rare occasions, there may be a special need to encourage the widest possible use of a certain library, so that it becomes a de-facto standard. To achieve this, non-free programs must be allowed to use the library. A more frequent case is that a free library does the same job as widely used non-free libraries. In this case, there is little to gain by limiting the free library to free software only, so we use the Lesser General Public License. In other cases, permission to use a particular library in non-free programs enables a greater number of people to use a large body of free software. For example, permission to use the GNU C Library in non-free programs enables many more people to use the whole GNU operating system, as well as its variant, the GNU/Linux operating system. Although the Lesser General Public License is Less protective of the users' freedom, it does ensure that the user of a program that is linked with the Library has the freedom and the wherewithal to run that program using a modified version of the Library. The precise terms and conditions for copying, distribution and modification follow. Pay close attention to the difference between a ""work based on the library"" and a ""work that uses the library"". The former contains code derived from the library, whereas the latter must be combined with the library in order to run. GNU LESSER GENERAL PUBLIC LICENSE TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION 0. This License Agreement applies to any software library or other program which contains a notice placed by the copyright holder or other authorized party saying it may be distributed under the terms of this Lesser General Public License (also called ""this License""). Each licensee is addressed as ""you"". A ""library"" means a collection of software functions and/or data prepared so as to be conveniently linked with application programs (which use some of those functions and data) to form executables. The ""Library"", below, refers to any such software library or work which has been distributed under these terms. A ""work based on the Library"" means either the Library or any derivative work under copyright law: that is to say, a work containing the Library or a portion of it, either verbatim or with modifications and/or translated straightforwardly into another language. (Hereinafter, translation is included without limitation in the term ""modification"".) ""Source code"" for a work means the preferred form of the work for making modifications to it. For a library, complete source code means all the source code for all modules it contains, plus any associated interface definition files, plus the scripts used to control compilation and installation of the library. Activities other than copying, distribution and modification are not covered by this License; they are outside its scope. The act of running a program using the Library is not restricted, and output from such a program is covered only if its contents constitute a work based on the Library (independent of the use of the Library in a tool for writing it). Whether that is true depends on what the Library does and what the program that uses the Library does. 1. You may copy and distribute verbatim copies of the Library's complete source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice and disclaimer of warranty; keep intact all the notices that refer to this License and to the absence of any warranty; and distribute a copy of this License along with the Library. You may charge a fee for the physical act of transferring a copy, and you may at your option offer warranty protection in exchange for a fee. 2. You may modify your copy or copies of the Library or any portion of it, thus forming a work based on the Library, and copy and distribute such modifications or work under the terms of Section 1 above, provided that you also meet all of these conditions: a) The modified work must itself be a software library. b) You must cause the files modified to carry prominent notices stating that you changed the files and the date of any change. c) You must cause the whole of the work to be licensed at no charge to all third parties under the terms of this License. d) If a facility in the modified Library refers to a function or a table of data to be supplied by an application program that uses the facility, other than as an argument passed when the facility is invoked, then you must make a good faith effort to ensure that, in the event an application does not supply such function or table, the facility still operates, and performs whatever part of its purpose remains meaningful. (For example, a function in a library to compute square roots has a purpose that is entirely well-defined independent of the application. Therefore, Subsection 2d requires that any application-supplied function or table used by this function must be optional: if the application does not supply it, the square root function must still compute square roots.) These requirements apply to the modified work as a whole. If identifiable sections of that work are not derived from the Library, and can be reasonably considered independent and separate works in themselves, then this License, and its terms, do not apply to those sections when you distribute them as separate works. But when you distribute the same sections as part of a whole which is a work based on the Library, the distribution of the whole must be on the terms of this License, whose permissions for other licensees extend to the entire whole, and thus to each and every part regardless of who wrote it. Thus, it is not the intent of this section to claim rights or contest your rights to work written entirely by you; rather, the intent is to exercise the right to control the distribution of derivative or collective works based on the Library. In addition, mere aggregation of another work not based on the Library with the Library (or with a work based on the Library) on a volume of a storage or distribution medium does not bring the other work under the scope of this License. 3. You may opt to apply the terms of the ordinary GNU General Public License instead of this License to a given copy of the Library. To do this, you must alter all the notices that refer to this License, so that they refer to the ordinary GNU General Public License, version 2, instead of to this License. (If a newer version than version 2 of the ordinary GNU General Public License has appeared, then you can specify that version instead if you wish.) Do not make any other change in these notices. Once this change is made in a given copy, it is irreversible for that copy, so the ordinary GNU General Public License applies to all subsequent copies and derivative works made from that copy. This option is useful when you wish to copy part of the code of the Library into a program that is not a library. 4. You may copy and distribute the Library (or a portion or derivative of it, under Section 2) in object code or executable form under the terms of Sections 1 and 2 above provided that you accompany it with the complete corresponding machine-readable source code, which must be distributed under the terms of Sections 1 and 2 above on a medium customarily used for software interchange. If distribution of object code is made by offering access to copy from a designated place, then offering equivalent access to copy the source code from the same place satisfies the requirement to distribute the source code, even though third parties are not compelled to copy the source along with the object code. 5. A program that contains no derivative of any portion of the Library, but is designed to work with the Library by being compiled or linked with it, is called a ""work that uses the Library"". Such a work, in isolation, is not a derivative work of the Library, and therefore falls outside the scope of this License. However, linking a ""work that uses the Library"" with the Library creates an executable that is a derivative of the Library (because it contains portions of the Library), rather than a ""work that uses the library"". The executable is therefore covered by this License. Section 6 states terms for distribution of such executables. When a ""work that uses the Library"" uses material from a header file that is part of the Library, the object code for the work may be a derivative work of the Library even though the source code is not. Whether this is true is especially significant if the work can be linked without the Library, or if the work is itself a library. The threshold for this to be true is not precisely defined by law. If such an object file uses only numerical parameters, data structure layouts and accessors, and small macros and small inline functions (ten lines or less in length), then the use of the object file is unrestricted, regardless of whether it is legally a derivative work. (Executables containing this object code plus portions of the Library will still fall under Section 6.) Otherwise, if the work is a derivative of the Library, you may distribute the object code for the work under the terms of Section 6. Any executables containing that work also fall under Section 6, whether or not they are linked directly with the Library itself. 6. As an exception to the Sections above, you may also combine or link a ""work that uses the Library"" with the Library to produce a work containing portions of the Library, and distribute that work under terms of your choice, provided that the terms permit modification of the work for the customer's own use and reverse engineering for debugging such modifications. You must give prominent notice with each copy of the work that the Library is used in it and that the Library and its use are covered by this License. You must supply a copy of this License. If the work during execution displays copyright notices, you must include the copyright notice for the Library among them, as well as a reference directing the user to the copy of this License. Also, you must do one of these things: a) Accompany the work with the complete corresponding machine-readable source code for the Library including whatever changes were used in the work (which must be distributed under Sections 1 and 2 above); and, if the work is an executable linked with the Library, with the complete machine-readable ""work that uses the Library"", as object code and/or source code, so that the user can modify the Library and then relink to produce a modified executable containing the modified Library. (It is understood that the user who changes the contents of definitions files in the Library will not necessarily be able to recompile the application to use the modified definitions.) b) Use a suitable shared library mechanism for linking with the Library. A suitable mechanism is one that (1) uses at run time a copy of the library already present on the user's computer system, rather than copying library functions into the executable, and (2) will operate properly with a modified version of the library, if the user installs one, as long as the modified version is interface-compatible with the version that the work was made with. c) Accompany the work with a written offer, valid for at least three years, to give the same user the materials specified in Subsection 6a, above, for a charge no more than the cost of performing this distribution. d) If distribution of the work is made by offering access to copy from a designated place, offer equivalent access to copy the above specified materials from the same place. e) Verify that the user has already received a copy of these materials or that you have already sent this user a copy. For an executable, the required form of the ""work that uses the Library"" must include any data and utility programs needed for reproducing the executable from it. However, as a special exception, the materials to be distributed need not include anything that is normally distributed (in either source or binary form) with the major components (compiler, kernel, and so on) of the operating system on which the executable runs, unless that component itself accompanies the executable. It may happen that this requirement contradicts the license restrictions of other proprietary libraries that do not normally accompany the operating system. Such a contradiction means you cannot use both them and the Library together in an executable that you distribute. 7. You may place library facilities that are a work based on the Library side-by-side in a single library together with other library facilities not covered by this License, and distribute such a combined library, provided that the separate distribution of the work based on the Library and of the other library facilities is otherwise permitted, and provided that you do these two things: a) Accompany the combined library with a copy of the same work based on the Library, uncombined with any other library facilities. This must be distributed under the terms of the Sections above. b) Give prominent notice with the combined library of the fact that part of it is a work based on the Library, and explaining where to find the accompanying uncombined form of the same work. 8. You may not copy, modify, sublicense, link with, or distribute the Library except as expressly provided under this License. Any attempt otherwise to copy, modify, sublicense, link with, or distribute the Library is void, and will automatically terminate your rights under this License. However, parties who have received copies, or rights, from you under this License will not have their licenses terminated so long as such parties remain in full compliance. 9. You are not required to accept this License, since you have not signed it. However, nothing else grants you permission to modify or distribute the Library or its derivative works. These actions are prohibited by law if you do not accept this License. Therefore, by modifying or distributing the Library (or any work based on the Library), you indicate your acceptance of this License to do so, and all its terms and conditions for copying, distributing or modifying the Library or works based on it. 10. Each time you redistribute the Library (or any work based on the Library), the recipient automatically receives a license from the original licensor to copy, distribute, link with or modify the Library subject to these terms and conditions. You may not impose any further restrictions on the recipients' exercise of the rights granted herein. You are not responsible for enforcing compliance by third parties with this License. 11. If, as a consequence of a court judgment or allegation of patent infringement or for any other reason (not limited to patent issues), conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License. If you cannot distribute so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not distribute the Library at all. For example, if a patent license would not permit royalty-free redistribution of the Library by all those who receive copies directly or indirectly through you, then the only way you could satisfy both it and this License would be to refrain entirely from distribution of the Library. If any portion of this section is held invalid or unenforceable under any particular circumstance, the balance of the section is intended to apply, and the section as a whole is intended to apply in other circumstances. It is not the purpose of this section to induce you to infringe any patents or other property right claims or to contest validity of any such claims; this section has the sole purpose of protecting the integrity of the free software distribution system which is implemented by public license practices. Many people have made generous contributions to the wide range of software distributed through that system in reliance on consistent application of that system; it is up to the author/donor to decide if he or she is willing to distribute software through any other system and a licensee cannot impose that choice. This section is intended to make thoroughly clear what is believed to be a consequence of the rest of this License. 12. If the distribution and/or use of the Library is restricted in certain countries either by patents or by copyrighted interfaces, the original copyright holder who places the Library under this License may add an explicit geographical distribution limitation excluding those countries, so that distribution is permitted only in or among countries not thus excluded. In such case, this License incorporates the limitation as if written in the body of this License. 13. The Free Software Foundation may publish revised and/or new versions of the Lesser General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns. Each version is given a distinguishing version number. If the Library specifies a version number of this License which applies to it and ""any later version"", you have the option of following the terms and conditions either of that version or of any later version published by the Free Software Foundation. If the Library does not specify a license version number, you may choose any version ever published by the Free Software Foundation. 14. If you wish to incorporate parts of the Library into other free programs whose distribution conditions are incompatible with these, write to the author to ask for permission. For software which is copyrighted by the Free Software Foundation, write to the Free Software Foundation; we sometimes make exceptions for this. Our decision will be guided by the two goals of preserving the free status of all derivatives of our free software and of promoting the sharing and reuse of software generally. NO WARRANTY 15. BECAUSE THE LIBRARY IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY FOR THE LIBRARY, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE LIBRARY ""AS IS"" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE LIBRARY IS WITH YOU. SHOULD THE LIBRARY PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION. 16. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR REDISTRIBUTE THE LIBRARY AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE LIBRARY (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE LIBRARY TO OPERATE WITH ANY OTHER SOFTWARE), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. END OF TERMS AND CONDITIONS How to Apply These Terms to Your New Libraries If you develop a new library, and you want it to be of the greatest possible use to the public, we recommend making it free software that everyone can redistribute and change. You can do so by permitting redistribution under these terms (or, alternatively, under the terms of the ordinary General Public License). To apply these terms, attach the following notices to the library. It is safest to attach them to the start of each source file to most effectively convey the exclusion of warranty; and each file should have at least the ""copyright"" line and a pointer to where the full notice is found. <one line to give the library's name and a brief idea of what it does.> Copyright (C) <year> <name of author> This library is free software; you can redistribute it and/or modify it under the terms of the GNU Lesser General Public License as published by the Free Software Foundation; either version 2.1 of the License, or (at your option) any later version. This library is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details. You should have received a copy of the GNU Lesser General Public License along with this library; if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA Also add information on how to contact you by electronic and paper mail. You should also get your employer (if you work as a programmer) or your school, if any, to sign a ""copyright disclaimer"" for the library, if necessary. Here is a sample; alter the names: Yoyodyne, Inc., hereby disclaims all copyright interest in the library `Frob' (a library for tweaking knobs) written by James Random Hacker. <signature of Ty Coon>, 1 April 1990 Ty Coon, President of Vice That's all there is to it! ---------------------------------------------------------------------- Jump to Line Go Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/libgit2/libgit2/blob/master/COPYING"	"Pure C implementation of Git.."	"true"
"Utilities"	"libimobiledevice"	"https://github.com/libimobiledevice/libimobiledevice"	"A cross-platform protocol library to communicate with iThings. or later (library), or later (tools)."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"996"	"110"	"326"	"GitHub - libimobiledevice/libimobiledevice: A cross-platform protocol library to communicate with iOS devices Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 110 Star 996 Fork 326 libimobiledevice/libimobiledevice Code Issues 121 Pull requests 18 Wiki Pulse Graphs A cross-platform protocol library to communicate with iOS devices http://www.libimobiledevice.org 1,354 commits 1 branch 25 releases 34 contributors C 79.7% Python 15.5% M4 3.2% Other 1.6% C Python M4 Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show 1.2.0 1.1.7 1.1.6 1.1.5 1.1.4 1.1.3 1.1.2 1.1.1 1.1.0 1.0.7 1.0.6 1.0.5 1.0.4 1.0.3 1.0.2 1.0.1 1.0.0 0.9.7 0.9.6 0.9.5 0.9.4 0.9.3 0.9.2 0.9.1 0.9.0 Nothing to show New pull request Latest commit 13bf235 Mar 21, 2016 dweinstein committed with nikias Fix SSL version negotiation for newer versions of OpenSSL … Depending on the OpenSSL version (and custom distribution patches), `SSLv3_method()` would return NULL on some systems and also `SSLv23_method()` fails with some older iOS versions... Permalink Failed to load latest commit information. common idevicebackup: fix some timestamps that are relative to the Mac epoch… Apr 1, 2016 cython lockdown: Add more error codes Jul 10, 2015 docs docs: Add link to project homepage Jan 27, 2015 include Add new function to get the underlying file descriptor of an idevice … Apr 1, 2016 m4 m4: Use python-config if available to fix Python 3 support on newer d… Jan 29, 2015 src Fix SSL version negotiation for newer versions of OpenSSL Jun 16, 2016 tools idevicedebug: Show error if container info not found Apr 29, 2016 .gitignore Updated .gitignore Apr 29, 2016 AUTHORS Update AUTHORS from git history Apr 7, 2012 COPYING Added documentation and licensing information. Jul 30, 2008 COPYING.LESSER Added documentation and licensing information. Jul 31, 2008 Makefile.am Move pkg-config file into src directory Jan 28, 2015 NEWS Update NEWS with latest changes Jan 28, 2015 README Update README with new git URL, IRC and twitter profile Jan 28, 2015 autogen.sh Try to use glibtoolize if possible in autogen.sh to fix OSX build Sep 25, 2010 configure.ac configure.ac: Only check for pthread support on non-win32 platforms Apr 29, 2016 doxygen.cfg.in Update doxygen configuration to 1.8.8 Jan 28, 2015 README About =====  A library to communicate with services of Apple iOS devices using native protocols.  Requirements ============  Development Packages of: 	libgnutls or openssl 	libplist 	libusbmuxd  Software: 	usbmuxd 	make 	autoheader 	automake 	autoconf 	libtool 	pkg-config 	gcc  Optional: 	cython (Python bindings) 	doxygen (Documentation)  Installation ============  To compile run: 	./autogen.sh 	make 	sudo make install  Who/What/Where? ===============  Home: 	http://www.libimobiledevice.org/  Code: 	git clone http://git.libimobiledevice.org/libimobiledevice.git  Code (Mirror): 	git clone https://github.com/libimobiledevice/libimobiledevice.git  Tickets: 	http://github.com/libimobiledevice/libimobiledevice/issues  Mailing List: 	http://lists.libimobiledevice.org/mailman/listinfo/libimobiledevice-devel  IRC: 	irc://irc.freenode.net#libimobiledevice  Twitter: 	https://twitter.com/libimobiledev  Credits =======  Apple, iPhone, iPod, and iPod Touch are trademarks of Apple Inc. libimobiledevice is an independent software library and has not been authorized, sponsored, or otherwise approved by Apple Inc.  README Updated on: 	2015-01-28  Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/libimobiledevice/libimobiledevice"	"A cross-platform protocol library to communicate with iThings. or later (library), or later (tools)."	"true"
"Utilities"	"libnfc"	"https://github.com/nfc-tools/libnfc"	"A platform-independent Near-Field Communication library. only."	"null"	"null"	"null"	"GNU LGPL3"	"http://www.gnu.org/licenses/lgpl.html"	"null"	"null"	"136"	"33"	"73"	"GitHub - nfc-tools/libnfc: Platform independent Near Field Communication (NFC) library Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 33 Star 136 Fork 73 nfc-tools/libnfc Code Issues 42 Pull requests 3 Pulse Graphs Platform independent Near Field Communication (NFC) library http://nfc-tools.org 1,939 commits 6 branches 23 releases 30 contributors C 90.5% CMake 3.4% M4 2.1% Groff 1.9% Makefile 1.2% Shell 0.6% C++ 0.3% C CMake M4 Groff Makefile Shell C++ Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags libusb10 master nfc_get_supported_baud_rate_proposal pending wiki win-cross Nothing to show libnfc-1.7.1 libnfc-1.7.0 libnfc-1.7.0-rc7 libnfc-1.7.0-rc6 libnfc-1.7.0-rc5 libnfc-1.7.0-rc4 libnfc-1.7.0-rc3 libnfc-1.7.0-rc2 libnfc-1.7.0-rc1 libnfc-1.6.0-rc1 libnfc-1.5.1 libnfc-1.5.0 libnfc-1.4.2 libnfc-1.4.1 libnfc-1.4.0 libnfc-1.3.9 libnfc-1.3.4 libnfc-1.3.3 libnfc-1.3.2 libnfc-1.3.1 libnfc-1.3.0 libnfc-1.2.1 libnfc-1.2.0 Nothing to show New pull request Latest commit 659f5f4 Jun 24, 2016 neomilium committed on GitHub Merge pull request #357 from yerzhanm/patch-1 … added support for ACR1222U-C1 Permalink Failed to load latest commit information. cmake Drop PCRE dependency. Jul 22, 2015 contrib Add SCM_SCL3712 support Nov 4, 2015 examples Fix nfc-poll card removing check (should be done only if a target has… Aug 2, 2015 include Do not include extra header in nfc.h Aug 19, 2015 libnfc added support for ACR1222U-C1 Jun 23, 2016 m4 I2C: remove unneeded I2C_DRIVERS_ENABLED Jun 15, 2013 test Fix cppcheck warning: The scope of the variable X can be reduced. Apr 5, 2013 utils nfc-mfultralight: also set failure state on uid write error May 13, 2016 .gitignore Git: ignore generated files May 18, 2015 .travis.yml Add travis config file Sep 1, 2015 AUTHORS Update ChangeLog & AUTHORS Feb 18, 2014 CMakeLists.txt Merge pull request #314 from xantares/patch-3 Sep 1, 2015 COPYING Add LICENSE and README files to releases produce by make_release.sh s… Jun 26, 2009 ChangeLog Fix out-of-bounds access in nfc-mfultralight unveiled by coverity scan: Apr 14, 2014 Doxyfile.in Remove last SVN cruft Nov 27, 2012 HACKING.md Added Markdown to HACKING file Apr 8, 2016 Makefile.am I2C: add i2c to cppcheck Jun 15, 2013 NEWS.md Changed a few README Markdown files to the .md extension so GitHub Apr 7, 2016 README-Windows.md Added Markdown to HACKING file Apr 8, 2016 README.md Added more Markdown formatting to README Apr 8, 2016 configure.ac tell Automake that we will not follow GNU Standards May 3, 2016 libnfc.conf.sample Fix typo in libnfc.conf.sample Apr 30, 2013 libnfc.pc.in Sync libnfc.pc includedir with the rest of the project source files. Dec 22, 2009 make_release.sh Fix version fetch using make_release.sh Jan 15, 2013 manual-test-results.txt add some manual test reports. May 5, 2011 mingw-cross-configure.sh Improves mingw-cross-configure.sh script using patch provided by Fran… Dec 5, 2012 README.md *- * Free/Libre Near Field Communication (NFC) library * * Libnfc historical contributors: * Copyright (C) 2009      Roel Verdult * Copyright (C) 2009-2015 Romuald Conty * Copyright (C) 2010-2012 Romain Tartière * Copyright (C) 2010-2013 Philippe Teuwen * Copyright (C) 2012-2013 Ludovic Rousseau * Additional contributors: * See AUTHORS file -*  General Information libnfc is a library which allows userspace application access to NFC devices. The official web site is: http://www.nfc-tools.org/ The official forum site is: http://www.libnfc.org/community/ The official development site is: https://github.com/nfc-tools/libnfc Important note: this file covers POSIX systems, for Windows please read README-Windows.txt Requirements Some NFC drivers depend on third party software: pn53x_usb & acr122_usb: libusb-0.1 http://libusb.sf.net acr122_pcsc: pcsc-lite http://pcsclite.alioth.debian.org/ The regression test suite depends on the cutter framework: http://cutter.sf.net Installation See the file INSTALL for configure, build and install details. Additionnally, you may need to grant permissions to your user to drive your device. Under GNU/Linux systems, if you use udev, you could use the provided udev rules. e.g. under Debian, Ubuntu, etc. sudo cp contrib/udev/42-pn53x.rules /lib/udev/rules.d/  Under FreeBSD, if you use devd, there is also a rules file: contrib/devd/pn53x.conf. Configuration In order to change the default behavior of the library, the libnfc uses a configuration file located in sysconfdir (as provided to ./configure). A sample commented file is available in sources: libnfc.conf.sample If you have compiled using: ./configure --prefix=/usr --sysconfdir=/etc  you can make configuration directory and copy the sample file: sudo mkdir /etc/nfc sudo cp libnfc.conf.sample /etc/nfc/libnfc.conf  To configure multiple devices, you can either modify libnfc.conf or create a file per device in a nfc/devices.d directory: sudo mkdir -p /etc/nfc/devices.d printf 'name = ""My first device""\nconnstring = ""pn532_uart:/dev/ttyACM0""\n' | sudo tee /etc/nfc/devices.d/first.conf printf 'name = ""My second device""\nconnstring = ""pn532_uart:/dev/ttyACM1""\n' | sudo tee /etc/nfc/devices.d/second.conf  How to report bugs To report a bug, visit https://github.com/nfc-tools/libnfc/issues and fill out a bug report form. If you have questions, remarks, we encourage you to post this in the developers community: http://www.libnfc.org/community Please make sure to include: The version of libnfc Information about your system. For instance: What operating system and version For Linux, what version of the C library And anything else you think is relevant. A trace with debug activated. Reproduce the bug with debug, e.g. if it was:   $ nfc-list -v  run it as:   $ LIBNFC_LOG_LEVEL=3 nfc-list -v  How to reproduce the bug. Please include a short test program that exhibits the behavior. As a last resort, you can also provide a pointer to a larger piece of software that can be downloaded. If the bug was a crash, the exact text that was printed out when the crash occured. Further information such as stack traces may be useful, but is not necessary. Patches Patches can be posted to https://github.com/nfc-tools/libnfc/issues If the patch fixes a bug, it is usually a good idea to include all the information described in ""How to Report Bugs"". Building It should be as simple as running these two commands: ./configure make  Troubleshooting Touchatag/ACR122: If your Touchatag or ACR122 device fails being detected by libnfc, make sure that PCSC-lite daemon (pcscd) is installed and is running. If your Touchatag or ACR122 device fails being detected by PCSC-lite daemon (pcsc_scan doesn't see anything) then try removing the bogus firmware detection of libccid: edit libccid_Info.plist configuration file (usually /etc/libccid_Info.plist) and locate <key>ifdDriverOptions</key>, turn <string>0x0000</string> value into 0x0004 to allow bogus devices and restart pcscd daemon. ACR122: Using an ACR122 device with libnfc and without tag (e.g. to use NFCIP modes or card emulation) needs yet another PCSC-lite tweak: You need to allow usage of CCID Exchange command. To do this, edit libccid_Info.plist configuration file (usually /etc/libccid_Info.plist) and locate <key>ifdDriverOptions</key>, turn <string>0x0000</string> value into 0x0001 to allow CCID exchange or 0x0005 to allow CCID exchange and bogus devices (cf previous remark) and restart pcscd daemon. Warning: if you use ACS CCID drivers (acsccid), configuration file is located in something like: /usr/lib/pcsc/drivers/ifd-acsccid.bundle/Contents/Info.plist SCL3711: Libnfc cannot be used concurrently with the PCSC proprietary driver of SCL3711. Two possible solutions: Either you don't install SCL3711 driver at all Or you stop the PCSC daemon when you want to use libnfc-based tools PN533 USB device on Linux >= 3.1: Since Linux kernel version 3.1, two kernel-modules must not be loaded in order to use libnfc : ""nfc"" and ""pn533"". To prevent kernel from loading automatically these modules, you can blacklist them in a modprobe conf file. This file is provided within libnfc archive: sudo cp contrib/linux/blacklist-libnfc.conf /etc/modprobe.d/blacklist-libnfc.conf  Proprietary Notes FeliCa is a registered trademark of the Sony Corporation. MIFARE is a trademark of NXP Semiconductors. Jewel Topaz is a trademark of Innovision Research & Technology. All other trademarks are the property of their respective owners. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/nfc-tools/libnfc"	"A platform-independent Near-Field Communication library. only."	"true"
"Utilities"	"libPhenom"	"http://facebook.github.io/libphenom/index.html"	"An eventing framework for building high-scalability and high-performance systems.."	"null"	"null"	"null"	"Apache2.0"	"http://directory.fsf.org/wiki/License:Apache2.0"	"null"	"null"	"null"	"null"	"null"	"README libPhenom Topics Headers"	"null"	"null"	"An eventing framework for building high-scalability and high-performance systems.."	"true"
"Utilities"	"libsoundio"	"https://github.com/andrewrk/libsoundio"	"A library for cross-platform, real-time audio input and output. Has a range of back-ends.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"426"	"37"	"39"	"GitHub - andrewrk/libsoundio: C library for cross-platform real-time audio input and output Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 37 Star 426 Fork 39 andrewrk/libsoundio Code Issues 12 Pull requests 0 Wiki Pulse Graphs C library for cross-platform real-time audio input and output http://libsound.io/ 334 commits 4 branches 5 releases 11 contributors C 87.7% C++ 9.9% CMake 2.4% C C++ CMake Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags duplex macos9 master symver Nothing to show 1.1.0 1.0.3 1.0.2 1.0.1 1.0.0 Nothing to show New pull request Latest commit 7469bee Jul 4, 2016 andrewrk committed on GitHub Merge pull request #86 from IceDragon200/master … Static lib and dynamic lib building options Permalink Failed to load latest commit information. cmake WASAPI: use `check_include_file` instead of 'find_path` in CMake May 24, 2016 doc build docs in little endian mode and add note Jun 13, 2016 example sio_sine example: check memory allocation Jun 29, 2016 soundio build docs in little endian mode and add note Jun 13, 2016 src Only define E_NOTFOUND if not already defined Jul 4, 2016 test convert source code to pure C Nov 10, 2015 .gitignore use hidden visibility by default and explicitly export Aug 20, 2015 CHANGELOG.md Release 1.1.0 Jan 31, 2016 CMakeLists.txt Added flag to building the dynamic libraries Jun 30, 2016 LICENSE add LICENSE Jun 30, 2015 README.md no longer ship config.h header Nov 23, 2015 README.md libsoundio C library providing cross-platform audio input and output. The API is suitable for real-time software such as digital audio workstations as well as consumer software such as music players. This library is an abstraction; however in the delicate balance between performance and power, and API convenience, the scale is tipped closer to the former. Features that only exist in some sound backends are exposed. Features and Limitations Supported operating systems: Windows 7+ MacOS 10.10+ Linux 3.7+ Supported backends: JACK PulseAudio ALSA CoreAudio WASAPI Dummy (silence) Exposes both raw devices and shared devices. Raw devices give you the best performance but prevent other applications from using them. Shared devices are default and usually provide sample rate conversion and format conversion. Exposes both device id and friendly name. id you could save in a config file because it persists between devices becoming plugged and unplugged, while friendly name is suitable for exposing to users. Supports optimal usage of each supported backend. The same API does the right thing whether the backend has a fixed buffer size, such as on JACK and CoreAudio, or whether it allows directly managing the buffer, such as on ALSA, PulseAudio, and WASAPI. C library. Depends only on the respective backend API libraries and libc. Does not depend on libstdc++, and does not have exceptions, run-time type information, or setjmp. Errors are communicated via return codes, not logging to stdio. Supports channel layouts (also known as channel maps), important for surround sound applications. Ability to monitor devices and get an event when available devices change. Ability to get an event when the backend is disconnected, for example when the JACK server or PulseAudio server shuts down. Detects which input device is default and which output device is default. Ability to connect to multiple backends at once. For example you could have an ALSA device open and a JACK device open at the same time. Meticulously checks all return codes and memory allocations and uses meaningful error codes. Exposes extra API that is only available on some backends. For example you can provide application name and stream names which is used by JACK and PulseAudio. Synopsis Complete program to emit a sine wave over the default device using the best backend: #include <soundio/soundio.h>  #include <stdio.h> #include <stdlib.h> #include <string.h> #include <math.h>  static const float PI = 3.1415926535f; static float seconds_offset = 0.0f; static void write_callback(struct SoundIoOutStream *outstream,         int frame_count_min, int frame_count_max) {     const struct SoundIoChannelLayout *layout = &outstream->layout;     float float_sample_rate = outstream->sample_rate;     float seconds_per_frame = 1.0f / float_sample_rate;     struct SoundIoChannelArea *areas;     int frames_left = frame_count_max;     int err;      while (frames_left > 0) {         int frame_count = frames_left;          if ((err = soundio_outstream_begin_write(outstream, &areas, &frame_count))) {             fprintf(stderr, ""%s\n"", soundio_strerror(err));             exit(1);         }          if (!frame_count)             break;          float pitch = 440.0f;         float radians_per_second = pitch * 2.0f * PI;         for (int frame = 0; frame < frame_count; frame += 1) {             float sample = sinf((seconds_offset + frame * seconds_per_frame) * radians_per_second);             for (int channel = 0; channel < layout->channel_count; channel += 1) {                 float *ptr = (float*)(areas[channel].ptr + areas[channel].step * frame);                 *ptr = sample;             }         }         seconds_offset += seconds_per_frame * frame_count;          if ((err = soundio_outstream_end_write(outstream))) {             fprintf(stderr, ""%s\n"", soundio_strerror(err));             exit(1);         }          frames_left -= frame_count;     } }  int main(int argc, char **argv) {     int err;     struct SoundIo *soundio = soundio_create();     if (!soundio) {         fprintf(stderr, ""out of memory\n"");         return 1;     }      if ((err = soundio_connect(soundio))) {         fprintf(stderr, ""error connecting: %s"", soundio_strerror(err));         return 1;     }      soundio_flush_events(soundio);      int default_out_device_index = soundio_default_output_device_index(soundio);     if (default_out_device_index < 0) {         fprintf(stderr, ""no output device found"");         return 1;     }      struct SoundIoDevice *device = soundio_get_output_device(soundio, default_out_device_index);     if (!device) {         fprintf(stderr, ""out of memory"");         return 1;     }      fprintf(stderr, ""Output device: %s\n"", device->name);      struct SoundIoOutStream *outstream = soundio_outstream_create(device);     outstream->format = SoundIoFormatFloat32NE;     outstream->write_callback = write_callback;      if ((err = soundio_outstream_open(outstream))) {         fprintf(stderr, ""unable to open device: %s"", soundio_strerror(err));         return 1;     }      if (outstream->layout_error)         fprintf(stderr, ""unable to set channel layout: %s\n"", soundio_strerror(outstream->layout_error));      if ((err = soundio_outstream_start(outstream))) {         fprintf(stderr, ""unable to start device: %s"", soundio_strerror(err));         return 1;     }      for (;;)         soundio_wait_events(soundio);      soundio_outstream_destroy(outstream);     soundio_device_unref(device);     soundio_destroy(soundio);     return 0; } Backend Priority When you use soundio_connect, libsoundio tries these backends in order. If unable to connect to that backend, due to the backend not being installed, or the server not running, or the platform is wrong, the next backend is tried. JACK PulseAudio ALSA (Linux) CoreAudio (OSX) WASAPI (Windows) Dummy If you don't like this order, you can use soundio_connect_backend to explicitly choose a backend to connect to. You can use soundio_backend_count and soundio_get_backend to get the list of available backends. API Documentation Building Install the dependencies: cmake ALSA library (optional) libjack2 (optional) libpulseaudio (optional) mkdir build cd build cmake .. make sudo make install  Building for Windows You can build libsoundio with mxe. Follow the requirements section to install the packages necessary on your system. Then somewhere on your file system: git clone https://github.com/mxe/mxe cd mxe make MXE_TARGETS='x86_64-w64-mingw32.static i686-w64-mingw32.static' gcc  Then in the libsoundio source directory (replace ""/path/to/mxe"" with the appropriate path): mkdir build-win32 cd build-win32 cmake .. -DCMAKE_TOOLCHAIN_FILE=/path/to/mxe/usr/i686-w64-mingw32.static/share/cmake/mxe-conf.cmake make  mkdir build-win64 cd build-win64 cmake .. -DCMAKE_TOOLCHAIN_FILE=/path/to/mxe/usr/x86_64-w64-mingw32.static/share/cmake/mxe-conf.cmake make  Testing For each backend, do the following: Run the unit tests: ./unit_tests. To see test coverage, install lcov, run make coverage, and then view coverage/index.html in a browser. Run the example ./sio_list_devices and make sure it does not crash, and the output looks good. If valgrind is available, use it. Run ./sio_list_devices --watch and make sure it detects when you plug and unplug a USB microphone. Run ./sio_sine and make sure you hear a sine wave. For backends with raw devices, run ./sio_sine --device id --raw (where 'id' is a device id you got from sio_list_devices and make sure you hear a sine wave. Use 'p' to test pausing, 'u' to test unpausing, 'q' to test cleanup. 'c' for clear buffer. Clear buffer should not pause the stream and it should also not cause an underflow. Use 'P' to test pausing from the callback, and then 'u' to unpause. Run ./underflow and read the testing instructions that it prints. Run ./sio_microphone and ensure that it is both recording and playing back correctly. If possible use the --in-device and --out-device parameters to test a USB microphone in raw mode. Run ./backend_disconnect_recover and read the testing instructions that it prints. Run ./latency and make sure the printed beeps line up with the beeps that you hear. Building the Documentation Ensure that doxygen is installed, then: make doc  Then look at html/index.html in a browser. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/andrewrk/libsoundio"	"A library for cross-platform, real-time audio input and output. Has a range of back-ends.."	"true"
"Utilities"	"libucl"	"https://github.com/vstakhov/libucl"	"A universal configuration library parser.."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"663"	"39"	"55"	"GitHub - vstakhov/libucl: Universal configuration library parser Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 39 Star 663 Fork 55 vstakhov/libucl Code Issues 35 Pull requests 3 Pulse Graphs Universal configuration library parser 815 commits 1 branch 14 releases 15 contributors C 87.9% M4 5.1% C++ 2.2% CMake 1.3% Python 1.0% Makefile 0.9% Other 1.6% C M4 C++ CMake Python Makefile Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show 0.8.0 0.7.3 0.7.2 0.7.1 0.6.1 0.5.2 0.5.1 0.4.0 0.3.1 0.2.6 0.2.3 0.2.2 0.2.1 0.2.0 Nothing to show New pull request Latest commit 3354f7f Jun 25, 2016 vstakhov committed on GitHub Merge pull request #142 from denisvm/python3 … python: add support to Python 3 Permalink Failed to load latest commit information. doc Fix Makefile whitespaces. Oct 22, 2015 examples Add a simple C++ example. Apr 16, 2015 haskell Haskell example Jul 7, 2015 include Merge pull request #132 from allanjude/add_file_full Jun 25, 2016 klib Fix kv_concat May 18, 2015 lua Add more consistent API methods Feb 16, 2016 m4 Add coverage support Feb 8, 2016 python python: add support for Python 2.6 tests Jun 25, 2016 src Merge pull request #132 from allanjude/add_file_full Jun 25, 2016 tests Add tests for comments Feb 26, 2016 uthash Move to mum_hash from xxhash May 31, 2016 utils Add more consistent API methods Feb 16, 2016 .gitignore python: add build artefacts to gitignore Apr 7, 2015 .travis.yml Disable trusty: OOM on tests Feb 11, 2016 CMakeLists.txt Switch to mum hash broke your builds! Jun 17, 2016 COPYING Add license. Aug 2, 2014 ChangeLog.md Release 0.8.0 Mar 1, 2016 Makefile.am Exclude unrelevant files from lcov scan Feb 9, 2016 Makefile.unix Fix build with plain makefile Jun 24, 2016 Makefile.w32 Switch to mum hash broke your builds! Jun 17, 2016 README.md Add coveralls badge Feb 8, 2016 autogen.sh Migrate to autotools. Mar 17, 2014 configure.ac Add coverage support Feb 8, 2016 libucl.pc.in Link lua API to build. Jul 21, 2014 stamp-h.in Rework autotools chain. Mar 18, 2014 README.md LIBUCL Table of Contents generated with DocToc Introduction Basic structure Improvements to the json notation General syntax sugar Automatic arrays creation Named keys hierarchy Convenient numbers and booleans General improvements Commments Macros support Variables support Multiline strings Emitter Validation Performance Conclusion Introduction This document describes the main features and principles of the configuration language called UCL - universal configuration language. If you are looking for the libucl API documentation you can find it at this page. Basic structure UCL is heavily infused by nginx configuration as the example of a convenient configuration system. However, UCL is fully compatible with JSON format and is able to parse json files. For example, you can write the same configuration in the following ways: in nginx like: param = value; section {     param = value;     param1 = value1;     flag = true;     number = 10k;     time = 0.2s;     string = ""something"";     subsection {         host = {             host = ""hostname"";              port = 900;         }         host = {             host = ""hostname"";             port = 901;         }     } } or in JSON: {     ""param"": ""value"",     ""param1"": ""value1"",     ""flag"": true,     ""subsection"": {         ""host"": [         {             ""host"": ""hostname"",             ""port"": 900         },         {             ""host"": ""hostname"",             ""port"": 901         }         ]     } } Improvements to the json notation. There are various things that make ucl configuration more convenient for editing than strict json: General syntax sugar Braces are not necessary to enclose a top object: it is automatically treated as an object: ""key"": ""value"" is equal to: {""key"": ""value""} There is no requirement of quotes for strings and keys, moreover, : may be replaced = or even be skipped for objects: key = value; section {     key = value; } is equal to: {     ""key"": ""value"",     ""section"": {         ""key"": ""value""     } } No commas mess: you can safely place a comma or semicolon for the last element in an array or an object: {     ""key1"": ""value"",     ""key2"": ""value"", } Automatic arrays creation Non-unique keys in an object are allowed and are automatically converted to the arrays internally: {     ""key"": ""value1"",     ""key"": ""value2"" } is converted to: {     ""key"": [""value1"", ""value2""] } Named keys hierarchy UCL accepts named keys and organize them into objects hierarchy internally. Here is an example of this process: section ""blah"" {     key = value; } section foo {     key = value; } is converted to the following object: section {     blah {         key = value;     }     foo {         key = value;     } } Plain definitions may be more complex and contain more than a single level of nested objects: section ""blah"" ""foo"" {     key = value; } is presented as: section {     blah {         foo {             key = value;         }     } } Convenient numbers and booleans Numbers can have suffixes to specify standard multipliers: [kKmMgG] - standard 10 base multipliers (so 1k is translated to 1000) [kKmMgG]b - 2 power multipliers (so 1kb is translated to 1024) [s|min|d|w|y] - time multipliers, all time values are translated to float number of seconds, for example 10min is translated to 600.0 and 10ms is translated to 0.01 Hexadecimal integers can be used by 0x prefix, for example key = 0xff. However, floating point values can use decimal base only. Booleans can be specified as true or yes or on and false or no or off. It is still possible to treat numbers and booleans as strings by enclosing them in double quotes. General improvements Commments UCL supports different style of comments: single line: # multiline: /* ... */ Multiline comments may be nested: # Sample single line comment /*   some comment  /* nested comment */  end of comment */ Macros support UCL supports external macros both multiline and single line ones: .macro ""sometext""; .macro {     Some long text     .... }; Moreover, each macro can accept an optional list of arguments in braces. These arguments themselves are the UCL object that is parsed and passed to a macro as options: .macro(param=value) ""something""; .macro(param={key=value}) ""something""; .macro(.include ""params.conf"") ""something""; .macro(#this is multiline macro param = [value1, value2]) ""something""; .macro(key=""()"") ""something""; UCL also provide a convenient include macro to load content from another files to the current UCL object. This macro accepts either path to file: .include ""/full/path.conf"" .include ""./relative/path.conf"" .include ""${CURDIR}/path.conf"" or URL (if ucl is built with url support provided by either libcurl or libfetch): .include ""http://example.com/file.conf""  .include macro supports a set of options: try (default: false) - if this option is true than UCL treats errors on loading of this file as non-fatal. For example, such a file can be absent but it won't stop the parsing of the top-level document. sign (default: false) - if this option is true UCL loads and checks the signature for a file from path named <FILEPATH>.sig. Trusted public keys should be provided for UCL API after parser is created but before any configurations are parsed. glob (default: false) - if this option is true UCL treats the filename as GLOB pattern and load all files that matches the specified pattern (normally the format of patterns is defined in glob manual page for your operating system). This option is meaningless for URL includes. url (default: true) - allow URL includes. path (default: empty) - A UCL_ARRAY of directories to search for the include file. Search ends after the first patch, unless glob is true, then all matches are included. prefix (default false) - Put included contents inside an object, instead of loading them into the root. If no key is provided, one is automatically generated based on each files basename() key (default: ) - Key to load contents of include into. If the key already exists, it must be the correct type target (default: object) - Specify if the prefix key should be an object or an array. priority (default: 0) - specify priority for the include (see below). duplicate (default: 'append') - specify policy of duplicates resolving: append - default strategy, if we have new object of higher priority then it replaces old one, if we have new object with less priority it is ignored completely, and if we have two duplicate objects with the same priority then we have a multi-value key (implicit array) merge - if we have object or array, then new keys are merged inside, if we have a plain object then an implicit array is formed (regardeless of priorities) error - create error on duplicate keys and stop parsing rewrite - always rewrite an old value with new one (ignoring priorities) Priorities are used by UCL parser to manage the policy of objects rewriting during including other files as following: If we have two objects with the same priority then we form an implicit array If a new object has bigger priority then we overwrite an old one If a new object has lower priority then we ignore it By default, the priority of top-level object is set to zero (lowest priority). Currently, you can define up to 16 priorities (from 0 to 15). Includes with bigger priorities will rewrite keys from the objects with lower priorities as specified by the policy. Variables support UCL supports variables in input. Variables are registered by a user of the UCL parser and can be presented in the following forms: ${VARIABLE} $VARIABLE UCL currently does not support nested variables. To escape variables one could use double dollar signs: $${VARIABLE} is converted to ${VARIABLE} $$VARIABLE is converted to $VARIABLE However, if no valid variables are found in a string, no expansion will be performed (and $$ thus remains unchanged). This may be a subject to change in future libucl releases. Multiline strings UCL can handle multiline strings as well as single line ones. It uses shell/perl like notation for such objects: key = <<EOD some text splitted to lines EOD  In this example key will be interpreted as the following string: some text\nsplitted to\nlines. Here are some rules for this syntax: Multiline terminator must start just after << symbols and it must consist of capital letters only (e.g. <<eof or << EOF won't work); Terminator must end with a single newline character (and no spaces are allowed between terminator and newline character); To finish multiline string you need to include a terminator string just after newline and followed by a newline (no spaces or other characters are allowed as well); The initial and the final newlines are not inserted to the resulting string, but you can still specify newlines at the begin and at the end of a value, for example: key <<EOD  some text  EOD  Emitter Each UCL object can be serialized to one of the three supported formats: JSON - canonic json notation (with spaces indented structure); Compacted JSON - compact json notation (without spaces or newlines); Configuration - nginx like notation; YAML - yaml inlined notation. Validation UCL allows validation of objects. It uses the same schema that is used for json: json schema v4. UCL supports the full set of json schema with the exception of remote references. This feature is unlikely useful for configuration objects. Of course, a schema definition can be in UCL format instead of JSON that simplifies schemas writing. Moreover, since UCL supports multiple values for keys in an object it is possible to specify generic integer constraints maxValues and minValues to define the limits of values count in a single key. UCL currently is not absolutely strict about validation schemas themselves, therefore UCL users should supply valid schemas (as it is defined in json-schema draft v4) to ensure that the input objects are validated properly. Performance Are UCL parser and emitter fast enough? Well, there are some numbers. I got a 19Mb file that consist of ~700 thousands lines of json (obtained via http://www.json-generator.com/). Then I checked jansson library that performs json parsing and emitting and compared it with UCL. Here are results: jansson: parsed json in 1.3899 seconds jansson: emitted object in 0.2609 seconds  ucl: parsed input in 0.6649 seconds ucl: emitted config in 0.2423 seconds ucl: emitted json in 0.2329 seconds ucl: emitted compact json in 0.1811 seconds ucl: emitted yaml in 0.2489 seconds  So far, UCL seems to be significantly faster than jansson on parsing and slightly faster on emitting. Moreover, UCL compiled with optimizations (-O3) performs significantly faster: ucl: parsed input in 0.3002 seconds ucl: emitted config in 0.1174 seconds ucl: emitted json in 0.1174 seconds ucl: emitted compact json in 0.0991 seconds ucl: emitted yaml in 0.1354 seconds  You can do your own benchmarks by running make check in libucl top directory. Conclusion UCL has clear design that should be very convenient for reading and writing. At the same time it is compatible with JSON language and therefore can be used as a simple JSON parser. Macroes logic provides an ability to extend configuration language (for example by including some lua code) and comments allows to disable or enable the parts of a configuration quickly. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/vstakhov/libucl"	"A universal configuration library parser.."	"true"
"Utilities"	"libuv"	"https://github.com/libuv/libuv"	"Cross-platform asynchronous I/O.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"4375"	"379"	"724"	"GitHub - libuv/libuv: Cross-platform asynchronous I/O Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 379 Star 4,375 Fork 724 libuv/libuv Code Issues 63 Pull requests 40 Wiki Pulse Graphs Cross-platform asynchronous I/O http://libuv.org/ 3,551 commits 6 branches 179 releases 231 contributors C 95.2% C++ 1.8% Python 0.8% M4 0.6% Makefile 0.6% Shell 0.4% Other 0.6% C C++ Python M4 Makefile Shell Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: v1.x Switch branches/tags Branches Tags master v0.6 v0.8 v0.10 v1.x wip/uv-object Nothing to show v1.9.1 v1.9.0 v1.8.0 v1.7.5 v1.7.4 v1.7.3 v1.7.2 v1.7.1 v1.7.0 v1.6.1 v1.6.0 v1.5.0 v1.4.2 v1.4.1 v1.4.0 v1.3.0 v1.2.1 v1.2.0 v1.1.0 v1.0.2 v1.0.1 v1.0.0 v1.0.0-rc2 v1.0.0-rc1 v0.11.29 v0.11.28 v0.11.27 v0.11.26 v0.11.25 v0.11.24 v0.11.23 v0.11.22 v0.11.21 v0.11.20 v0.11.19 v0.11.18 v0.11.17 v0.11.16 v0.11.15 v0.11.14 v0.11.13 v0.11.12 v0.11.11 v0.11.10 v0.11.9 v0.11.8 v0.11.7 v0.11.6 v0.11.5 v0.11.4 v0.11.3 v0.11.2 v0.11.1 v0.10.37 v0.10.36 v0.10.35 v0.10.34 v0.10.33 v0.10.32 v0.10.31 v0.10.30 v0.10.29 v0.10.28 v0.10.27 v0.10.26 v0.10.25 v0.10.24 v0.10.23 v0.10.22 v0.10.21 v0.10.20 v0.10.19 v0.10.18 v0.10.17 v0.10.16 v0.10.15 v0.10.14 v0.10.13 v0.10.12 v0.10.11 v0.10.10 v0.10.9 v0.10.8 v0.10.7 v0.10.6 v0.10.5 v0.10.4 v0.10.3 v0.10.2 pubkey-saghul pubkey-iwuzhere pubkey-indutny pubkey-cjihrig pubkey-bnoordhuis node-v0.11.0 node-v0.10.1 node-v0.10.0 node-v0.9.12 node-v0.9.11 node-v0.9.10 Nothing to show New pull request Latest commit 840a8c5 Jun 27, 2016 cjihrig unix,win: make uv_get_process_title() stricter … This commit causes uv_get_process_title() to:  - return EINVAL if the buffer is null or size is 0  - return ENOBUFS if the title is too big for the buffer  - null terminate the buffer on success  Fixes: #315 PR-URL: #928 Reviewed-By: Saúl Ibarra Corretgé <saghul@gmail.com> Permalink Failed to load latest commit information. docs unix,win: make uv_get_process_title() stricter Jul 14, 2016 img img: add logo files Jul 20, 2014 include Now working on version 1.9.2 May 16, 2016 m4 build: remove dtrace probes Nov 10, 2014 samples gyp: qualify `library` variable Feb 5, 2014 src unix,win: make uv_get_process_title() stricter Jul 14, 2016 test unix,win: make uv_get_process_title() stricter Jul 14, 2016 .gitignore gitignore: ignore VS temporary database files May 12, 2016 .mailmap 2016.05.17, Version 1.9.1 (Stable) May 16, 2016 AUTHORS 2016.05.17, Version 1.9.1 (Stable) May 16, 2016 CONTRIBUTING.md doc: update coding style link Jun 13, 2016 ChangeLog Add SHA to ChangeLog May 16, 2016 LICENSE license: add license text we've been using for a while May 28, 2016 MAINTAINERS.md doc: add iWuzHere GPG ID Jun 8, 2016 Makefile.am build: fix build on DragonFly Jun 9, 2016 Makefile.mingw Revert ""win,build: remove unused build defines"" Apr 12, 2016 README.md doc: add licensing information to README May 28, 2016 android-configure build: bump android ndk version Apr 26, 2016 appveyor.yml 2016.05.17, Version 1.9.1 (Stable) May 16, 2016 autogen.sh build: invoke libtoolize with --copy Jan 5, 2016 checksparse.sh unix,win: add uv_get_passwd() Mar 29, 2016 common.gypi build: always compile with -fvisibility=hidden Apr 29, 2016 configure.ac build: check for warnings for -fvisibility=hidden Jun 15, 2016 gyp_uv.py build: python 2.x/3.x consistent print usage Feb 15, 2016 libuv.nsi build: add experimental Windows installer Jul 28, 2015 libuv.pc.in build: add required libraries to libuv.pc.in Mar 2, 2014 uv.gyp test: silence build warnings Jun 3, 2016 vcbuild.bat build,win: rename platform to msbuild_platform May 12, 2016 README.md Overview libuv is a multi-platform support library with a focus on asynchronous I/O. It was primarily developed for use by Node.js, but it's also used by Luvit, Julia, pyuv, and others. Feature highlights Full-featured event loop backed by epoll, kqueue, IOCP, event ports. Asynchronous TCP and UDP sockets Asynchronous DNS resolution Asynchronous file and file system operations File system events ANSI escape code controlled TTY IPC with socket sharing, using Unix domain sockets or named pipes (Windows) Child processes Thread pool Signal handling High resolution clock Threading and synchronization primitives Versioning Starting with version 1.0.0 libuv follows the semantic versioning scheme. The API change and backwards compatibility rules are those indicated by SemVer. libuv will keep a stable ABI across major releases. Licensing libuv is licensed under the MIT license. Check the LICENSE file. Community Mailing list IRC chatroom (#libuv@irc.freenode.org) Documentation Official API documentation Located in the docs/ subdirectory. It uses the Sphinx framework, which makes it possible to build the documentation in multiple formats. Show different supported building options: $ make help  Build documentation as HTML: $ make html  Build documentation as HTML and live reload it when it changes (this requires sphinx-autobuild to be installed and is only supported on Unix): $ make livehtml  Build documentation as man pages: $ make man  Build documentation as ePub: $ make epub  NOTE: Windows users need to use make.bat instead of plain 'make'. Documentation can be browsed online here. The tests and benchmarks also serve as API specification and usage examples. Other resources An Introduction to libuv — An overview of libuv with tutorials. LXJS 2012 talk — High-level introductory talk about libuv. libuv-dox — Documenting types and methods of libuv, mostly by reading uv.h. learnuv — Learn uv for fun and profit, a self guided workshop to libuv. These resources are not handled by libuv maintainers and might be out of date. Please verify it before opening new issues. Downloading libuv can be downloaded either from the GitHub repository or from the downloads site. Starting with libuv 1.7.0, binaries for Windows are also provided. This is to be considered EXPERIMENTAL. Before verifying the git tags or signature files, importing the relevant keys is necessary. Key IDs are listed in the MAINTAINERS file, but are also available as git blob objects for easier use. Importing a key the usual way: $ gpg --keyserver pool.sks-keyservers.net \   --recv-keys AE9BC059  Importing a key from a git blob object: $ git show pubkey-saghul | gpg --import  Verifying releases Git tags are signed with the developer's key, they can be verified as follows: $ git verify-tag v1.6.1  Starting with libuv 1.7.0, the tarballs stored in the downloads site are signed and an accompanying signature file sit alongside each. Once both the release tarball and the signature file are downloaded, the file can be verified as follows: $ gpg --verify libuv-1.7.0.tar.gz.sign  Build Instructions For GCC there are two build methods: via autotools or via GYP. GYP is a meta-build system which can generate MSVS, Makefile, and XCode backends. It is best used for integration into other projects. To build with autotools: $ sh autogen.sh $ ./configure $ make $ make check $ make install  Windows First, Python 2.6 or 2.7 must be installed as it is required by GYP. If python is not in your path, set the environment variable PYTHON to its location. For example: set PYTHON=C:\Python27\python.exe To build with Visual Studio, launch a git shell (e.g. Cmd or PowerShell) and run vcbuild.bat which will checkout the GYP code into build/gyp and generate uv.sln as well as related project files. To have GYP generate build script for another system, checkout GYP into the project tree manually: $ git clone https://chromium.googlesource.com/external/gyp.git build/gyp  Unix For Debug builds (recommended) run: $ ./gyp_uv.py -f make $ make -C out  For Release builds run: $ ./gyp_uv.py -f make $ BUILDTYPE=Release make -C out  Run ./gyp_uv.py -f make -Dtarget_arch=x32 to build x32 binaries. OS X Run: $ ./gyp_uv.py -f xcode $ xcodebuild -ARCHS=""x86_64"" -project uv.xcodeproj \      -configuration Release -target All  Using Homebrew: $ brew install --HEAD libuv  Note to OS X users: Make sure that you specify the architecture you wish to build for in the ""ARCHS"" flag. You can specify more than one by delimiting with a space (e.g. ""x86_64 i386""). Android Run: $ source ./android-configure NDK_PATH gyp $ make -C out  Note for UNIX users: compile your project with -D_LARGEFILE_SOURCE and -D_FILE_OFFSET_BITS=64. GYP builds take care of that automatically. Using Ninja To use ninja for build on ninja supported platforms, run: $ ./gyp_uv.py -f ninja $ ninja -C out/Debug     #for debug build OR $ ninja -C out/Release  Running tests Run: $ ./gyp_uv.py -f make $ make -C out $ ./out/Debug/run-tests  Supported Platforms Microsoft Windows operating systems since Windows XP SP2. It can be built with either Visual Studio or MinGW. Consider using Visual Studio Express 2010 or later if you do not have a full Visual Studio license. Linux using the GCC toolchain. OS X using the GCC or XCode toolchain. Solaris 121 and later using GCC toolchain. AIX 6 and later using GCC toolchain (see notes). AIX Notes AIX support for filesystem events requires the non-default IBM bos.ahafs package to be installed. This package provides the AIX Event Infrastructure that is detected by autoconf. IBM documentation describes the package in more detail. AIX support for filesystem events is not compiled when building with gyp. Patches See the guidelines for contributing. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/libuv/libuv"	"Cross-platform asynchronous I/O.."	"true"
"Utilities"	"libYAML"	"http://www.pyyaml.org/wiki/LibYAML"	"A YAML 1.1 parser and emitter.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"null"	"null"	"null"	"LibYAML – PyYAML     Search: Login Help/Guide About Trac Preferences Wiki Timeline Roadmap Browse Source View Tickets Search wiki:LibYAML Context Navigation Start Page Index History Last modified 2 years ago LibYAML LibYAML is a YAML 1.1 parser and emitter written in C. LibYAML Download and Installation Development and bug reports Documentation Scope Events Event Types Essential Event Attributes Stylistic Event Attributes API Parser API Synopsis Emitter API Synopsis Examples Copyright Download and Installation The current release of LibYAML: 0.1.5 (2014-02-04). Download the source package: http://pyyaml.org/download/libyaml/yaml-0.1.5.tar.gz. To build and install LibYAML, run $ ./configure $ make # make install  You may check out the latest development code of LibYAML from the Mercurial repository  https://bitbucket.org/xi/libyaml: $ hg clone https://bitbucket.org/xi/libyaml  If you checked out the LibYAML source code from the Subversion repository, you may build LibYAML with the commands: $ ./bootstrap $ ./configure $ make # make install  Development and bug reports You may check out the LibYAML source code from  LibYAML HG repository. If you find a bug in LibYAML, please  file a bug report. You may review open bugs through  the list of open tickets. You may discuss LibYAML at  the YAML-core mailing list. Documentation Scope LibYAML covers presenting and parsing  processes. Thus LibYAML defines the following two processors: Parser, which takes an input stream of bytes and produces a sequence of parsing events. Emitter, which takes a sequence of events and produces a stream of bytes. The processes of parsing and presenting are inverse to each other. Any sequence of events produced by parsing a well-formed YAML document should be acceptable by the Emitter, which should produce an equivalent document. Similarly, any document produced by emitting a sequence of events should be acceptable for the Parser, which should produce an equivalent sequence of events. The job of resolving implicit tags, composing and serializing representation trees, as well as constructing and representing native objects is left to applications and bindings. Although some of these processes may be covered in the latter releases, they are not in the scope of the initial release of LibYAML. Events Event Types The Parser produces while the Emitter accepts the following types of events: STREAM-START STREAM-END DOCUMENT-START DOCUMENT-END ALIAS SCALAR SEQUENCE-START SEQUENCE-END MAPPING-START MAPPING-END A valid sequence of events should obey the grammar: stream ::= STREAM-START document* STREAM-END document ::= DOCUMENT-START node DOCUMENT-END node ::= ALIAS | SCALAR | sequence | mapping sequence ::= SEQUENCE-START node* SEQUENCE-END mapping ::= MAPPING-START (node node)* MAPPING-END  Essential Event Attributes The following attributes affect the intepretation of a YAML document. ALIAS anchor - the alias anchor; [0-9a-zA-Z_-]+; not NULL. SCALAR anchor - the node anchor; [0-9a-zA-Z_-]+; may be NULL. tag - the node tag; should either start with ! (local tag) or be a valid URL (global tag); may be NULL or ! in which case either plain_implicit or quoted_implicit should be True. plain_implicit - True if the node tag may be omitted whenever the scalar value is presented in the plain style. quoted_implicit - True if the node tag may be omitted whenever the scalar value is presented in any non-plain style. value - the scalar value; a valid utf-8 sequence and may contain NUL characters; not NULL. length - the length of the scalar value. SEQUENCE-START anchor - the node anchor; [0-9a-zA-Z_-]+; may be NULL. tag - the node tag; should either start with ! (local tag) or be a valid URL (global tag); may be NULL or ! in which case implicit should be True. implicit - True if the node tag may be omitted. MAPPING-START anchor - the node anchor; [0-9a-zA-Z_-]+; may be NULL. tag - the node tag; should either start with ! (local tag) or be a valid URL (global tag); may be NULL or ! in which case implicit should be True. implicit - True if the node tag may be omitted. Stylistic Event Attributes The following attributes don't affect the interpretation of a YAML document. While parsing a YAML document, an application should not consider these attributes for resolving implicit tags and constructing representation graphs or native objects. The Emitter may ignore these attributes if they cannot be satisfied. STREAM-START encoding - the document encoding; utf-8|utf-16-le|utf-16-be. DOCUMENT-START version_directive - the version specified with the %YAML directive; the only valid value is 1.1; may be NULL. tag_directives - a set of tag handles and the corresponding tag prefixes specified with the %TAG directive; tag handles should match !|!!|![0-9a-zA-Z_-]+! while tag prefixes should be prefixes of valid local or global tags; may be empty. implicit - True if the document start indicator --- is not present. DOCUMENT-END implicit - True if the document end indicator ... is not present. SCALAR style - the value style; plain|single-quoted|double-quoted|literal|folded. SEQUENCE-START style - the sequence style; block|flow. MAPPING-START style - the mapping style; block|flow. any event start_mark - the position of the event beginning; attributes: index (in characters), line and column (starting from 0). end_mark - the position of the event end; attributes: index (in characters), line and column (starting from 0). API Note: the API may change drastically. You may also check the header file:  https://bitbucket.org/xi/libyaml/src/tip/include/yaml.h Parser API Synopsis #include <yaml.h>  yaml_parser_t parser; yaml_event_t event;  int done = 0;  /* Create the Parser object. */ yaml_parser_initialize(&parser);  /* Set a string input. */ char *input = ""...""; size_t length = strlen(input);  yaml_parser_set_input_string(&parser, input, length);  /* Set a file input. */ FILE *input = fopen(""..."", ""rb"");  yaml_parser_set_input_file(&parser, input);  /* Set a generic reader. */ void *ext = ...; int read_handler(void *ext, char *buffer, int size, int *length) {     /* ... */     *buffer = ...;     *length = ...;     /* ... */     return error ? 0 : 1; }  yaml_parser_set_input(&parser, read_handler, ext);  /* Read the event sequence. */ while (!done) {      /* Get the next event. */     if (!yaml_parser_parse(&parser, &event))         goto error;      /*       ...       Process the event.       ...     */      /* Are we finished? */     done = (event.type == YAML_STREAM_END_EVENT);      /* The application is responsible for destroying the event object. */     yaml_event_delete(&event);  }  /* Destroy the Parser object. */ yaml_parser_delete(&parser);  return 1;  /* On error. */ error:  /* Destroy the Parser object. */ yaml_parser_delete(&parser);  return 0;  Emitter API Synopsis #include <yaml.h>  yaml_emitter_t emitter; yaml_event_t event;  /* Create the Emitter object. */ yaml_emitter_initialize(&emitter);  /* Set a file output. */ FILE *output = fopen(""..."", ""wb"");  yaml_emitter_set_output_file(&emitter, output);  /* Set a generic writer. */ void *ext = ...; int write_handler(void *ext, char *buffer, int size) {     /*        ...        Write `size` bytes.        ...     */     return error ? 0 : 1; }  yaml_emitter_set_output(&emitter, write_handler, ext);  /* Create and emit the STREAM-START event. */ yaml_stream_start_event_initialize(&event, YAML_UTF8_ENCODING); if (!yaml_emitter_emit(&emitter, &event))     goto error;  /*   ...   Emit more events.   ... */  /* Create and emit the STREAM-END event. */ yaml_stream_end_event_initialize(&event); if (!yaml_emitter_emit(&emitter, &event))     goto error;  /* Destroy the Emitter object. */ yaml_emitter_delete(&emitter);  return 1;  /* On error. */ error:  /* Destroy the Emitter object. */ yaml_emitter_delete(emitter);  return 0;  Examples You may check  tests and examples in the source distribution. Copyright The LibYAML library is written by Kirill Simonov. LibYAML is released under the MIT license. This project is developed for  Python Software Foundation as a part of  Google Summer of Code under the mentorship of  Clark Evans. Download in other formats: Plain Text Powered by Trac 0.12.2 By Edgewall Software. Visit the Trac open source project at http://trac.edgewall.org/"	"null"	"null"	"A YAML 1.1 parser and emitter.."	"true"
"Utilities"	"lzo"	"http://www.oberhumer.com/opensource/lzo/"	"A very fast data compression library.."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"null"	"null"	"null"	"oberhumer.com: LZO real-time data compression library Home Products OpenSource Company   LZO Version 2.09 04 Feb 2015 Copyright (C) 1996 - 2015 Markus F.X.J. Oberhumer [News] [Abstract] [Download] [miniLZO] [lzop] [Links] News LZO 2.09 has been released; a small but important update that works around gcc bug #64516. Key Facts LZO is a portable lossless data compression library written in ANSI C. Offers pretty fast compression and *extremely* fast decompression. One of the fastest compression and decompression algorithms around. See the ratings for lzop in the famous Archive Comparison Test . Includes slower compression levels achieving a quite competitive compression ratio while still decompressing at this very high speed. Distributed under the terms of the GNU General Public License (GPL v2+). Download Download LZO (source code, 581 kB, SHA1: e2a60aca818836181e7e6f8c4f2c323aca6ac057). miniLZO miniLZO is a very lightweight subset of the LZO library. Very easy to use - it only takes a few minutes to add data compression to your application! I've created miniLZO for projects where it is inconvenient to include or require the full LZO source code just because you want to add a little bit of data compression to your application. miniLZO consists of one C source file and three header files. It compiles to less than 6 kB (on x86), and the sources are just a few kB when packed - so there's no more excuse that your application doesn't support data compression :-) Download miniLZO (source code, 59 kB, SHA1: 32d43a04d16da65258427d978960ecf1bf751ec1). LZOP lzop is a file compressor which uses LZO for compression services. It is very similar to gzip - its main advantages over gzip are much higher compression and decompression speed. Related links LZO Professional is our stunning new commercial LZO product. If you need better compression you should take a look at the excellent zlib library. zlib is slower and needs more memory, though. For even better compression consider using libbzip2 which is distributed with the bzip2 file compressor.   Copyright © 2016 oberhumer.com GmbH. All Rights Reserved. Terms of Use | Sitemap"	"null"	"null"	"A very fast data compression library.."	"true"
"Utilities"	"mpc"	"https://github.com/orangeduck/mpc"	"A parser combinator library.."	"null"	"null"	"null"	"FreeBSD"	"http://directory.fsf.org/wiki?title=License:FreeBSD"	"null"	"null"	"946"	"67"	"106"	"GitHub - orangeduck/mpc: A Parser Combinator library for C Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 67 Star 946 Fork 106 orangeduck/mpc Code Issues 4 Pull requests 1 Pulse Graphs A Parser Combinator library for C 152 commits 2 branches 2 releases 12 contributors C 99.5% Makefile 0.5% C Makefile Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags flags master Nothing to show 0.8.7 0.8.6 Nothing to show New pull request Latest commit 724e9a3 Jul 4, 2016 orangeduck committed on GitHub Merge pull request #57 from Forty-Bot/master … Fixed uninitialized terminator Permalink Failed to load latest commit information. examples Made traversal free May 31, 2016 tests Fixed folding of single child asts with tags Jun 11, 2016 .gitattributes Introduce end-of-line normalization Apr 15, 2014 .gitignore .gitignore examples/tree_traversal May 4, 2016 LICENSE.md big update to readme Sep 26, 2013 Makefile Remove foobar and tree_traversal too while doing 'make clean' May 4, 2016 README.md Fixed folding of single child asts with tags Jun 11, 2016 mpc.c Fixed uninitialized terminator Jul 4, 2016 mpc.h Merge branch 'master' of https://github.com/orangeduck/mpc into nparse Jun 29, 2016 package.json Fixed folding of single child asts with tags Jun 11, 2016 README.md Micro Parser Combinators Version 0.8.8 About mpc is a lightweight and powerful Parser Combinator library for C. Using mpc might be of interest to you if you are... Building a new programming language Building a new data format Parsing an existing programming language Parsing an existing data format Embedding a Domain Specific Language Implementing Greenspun's Tenth Rule Features Type-Generic Predictive, Recursive Descent Easy to Integrate (One Source File in ANSI C) Automatic Error Message Generation Regular Expression Parser Generator Language/Grammar Parser Generator Alternatives The current main alternative for a C based parser combinator library is a branch of Cesium3. mpc provides a number of features that this project does not offer, and also overcomes a number of potential downsides: mpc Works for Generic Types mpc Doesn't rely on Boehm-Demers-Weiser Garbage Collection mpc Doesn't use setjmp and longjmp for errors mpc Doesn't pollute the namespace Quickstart Here is how one would use mpc to create a parser for a basic mathematical expression language. mpc_parser_t *Expr  = mpc_new(""expression""); mpc_parser_t *Prod  = mpc_new(""product""); mpc_parser_t *Value = mpc_new(""value""); mpc_parser_t *Maths = mpc_new(""maths"");  mpca_lang(MPCA_LANG_DEFAULT,   "" expression : <product> (('+' | '-') <product>)*; ""   "" product    : <value>   (('*' | '/')   <value>)*; ""   "" value      : /[0-9]+/ | '(' <expression> ')';    ""   "" maths      : /^/ <expression> /$/;               "",   Expr, Prod, Value, Maths, NULL);  mpc_result_t r;  if (mpc_parse(""input"", input, Maths, &r)) {   mpc_ast_print(r.output);   mpc_ast_delete(r.output); } else {   mpc_err_print(r.error);   mpc_err_delete(r.error); }  mpc_cleanup(4, Expr, Prod, Value, Maths); If you were to set input to the string (4 * 2 * 11 + 2) - 5, the printed output would look like this. >   regex   expression|>     value|>       char:1:1 '('       expression|>         product|>           value|regex:1:2 '4'           char:1:4 '*'           value|regex:1:6 '2'           char:1:8 '*'           value|regex:1:10 '11'         char:1:13 '+'         product|value|regex:1:15 '2'       char:1:16 ')'     char:1:18 '-'     product|value|regex:1:20 '5'   regex  Getting Started Introduction Parser Combinators are structures that encode how to parse particular languages. They can be combined using intuitive operators to create new parsers of increasing complexity. Using these operators detailed grammars and languages can be parsed and processed in a quick, efficient, and easy way. The trick behind Parser Combinators is the observation that by structuring the library in a particular way, one can make building parser combinators look like writing a grammar itself. Therefore instead of describing how to parse a language, a user must only specify the language itself, and the library will work out how to parse it ... as if by magic! mpc can be used in this mode, or, as shown in the above example, you can specify the grammar directly as a string or in a file. Basic Parsers String Parsers All the following functions construct new basic parsers of the type mpc_parser_t *. All of those parsers return a newly allocated char * with the character(s) they manage to match. If unsuccessful they will return an error. They have the following functionality. mpc_parser_t *mpc_any(void); Matches any individual character mpc_parser_t *mpc_char(char c); Matches a single given character c mpc_parser_t *mpc_range(char s, char e); Matches any single given character in the range s to e (inclusive) mpc_parser_t *mpc_oneof(const char *s); Matches any single given character in the string s mpc_parser_t *mpc_noneof(const char *s); Matches any single given character not in the string s mpc_parser_t *mpc_satisfy(int(*f)(char)); Matches any single given character satisfying function f mpc_parser_t *mpc_string(const char *s); Matches exactly the string s Other Parsers Several other functions exist that construct parsers with some other special functionality. mpc_parser_t *mpc_pass(void); Consumes no input, always successful, returns NULL mpc_parser_t *mpc_fail(const char *m); mpc_parser_t *mpc_failf(const char *fmt, ...); Consumes no input, always fails with message m or formatted string fmt. mpc_parser_t *mpc_lift(mpc_ctor_t f); Consumes no input, always successful, returns the result of function f mpc_parser_t *mpc_lift_val(mpc_val_t *x); Consumes no input, always successful, returns x mpc_parser_t *mpc_state(void); Consumes no input, always successful, returns a copy of the parser state as a mpc_state_t *. This state is newly allocated and so needs to be released with free when finished with. mpc_parser_t *mpc_anchor(int(*f)(char,char)); Consumes no input. Successful when function f returns true. Always returns NULL. Function f is a anchor function. It takes as input the last character parsed, and the next character in the input, and returns success or failure. This function can be set by the user to ensure some condition is met. For example to test that the input is at a boundary between words and non-words. At the start of the input the first argument is set to '\0'. At the end of the input the second argument is set to '\0'. Parsing Once you've build a parser, you can run it on some input using one of the following functions. These functions return 1 on success and 0 on failure. They output either the result, or an error to a mpc_result_t variable. This type is defined as follows. typedef union {   mpc_err_t *error;   mpc_val_t *output; } mpc_result_t; where mpc_val_t * is synonymous with void * and simply represents some pointer to data - the exact type of which is dependant on the parser. int mpc_parse(const char *filename, const char *string, mpc_parser_t *p, mpc_result_t *r); Run a parser on some string. int mpc_parse_file(const char *filename, FILE *file, mpc_parser_t *p, mpc_result_t *r); Run a parser on some file. int mpc_parse_pipe(const char *filename, FILE *pipe, mpc_parser_t *p, mpc_result_t *r); Run a parser on some pipe (such as stdin). int mpc_parse_contents(const char *filename, mpc_parser_t *p, mpc_result_t *r); Run a parser on the contents of some file. Combinators Combinators are functions that take one or more parsers and return a new parser of some given functionality. These combinators work independently of exactly what data type the parser(s) supplied as input return. In languages such as Haskell ensuring you don't input one type of data into a parser requiring a different type is done by the compiler. But in C we don't have that luxury. So it is at the discretion of the programmer to ensure that he or she deals correctly with the outputs of different parser types. A second annoyance in C is that of manual memory management. Some parsers might get half-way and then fail. This means they need to clean up any partial result that has been collected in the parse. In Haskell this is handled by the Garbage Collector, but in C these combinators will need to take destructor functions as input, which say how clean up any partial data that has been collected. Here are the main combinators and how to use then. mpc_parser_t *mpc_expect(mpc_parser_t *a, const char *e); mpc_parser_t *mpc_expectf(mpc_parser_t *a, const char *fmt, ...); Returns a parser that runs a, and on success returns the result of a, while on failure reports that e was expected. mpc_parser_t *mpc_apply(mpc_parser_t *a, mpc_apply_t f); mpc_parser_t *mpc_apply_to(mpc_parser_t *a, mpc_apply_to_t f, void *x); Returns a parser that applies function f (optionality taking extra input x) to the result of parser a. mpc_parser_t *mpc_not(mpc_parser_t *a, mpc_dtor_t da); mpc_parser_t *mpc_not_lift(mpc_parser_t *a, mpc_dtor_t da, mpc_ctor_t lf); Returns a parser with the following behaviour. If parser a succeeds, then it fails and consumes no input. If parser a fails, then it succeeds, consumes no input and returns NULL (or the result of lift function lf). Destructor da is used to destroy the result of a on success. mpc_parser_t *mpc_maybe(mpc_parser_t *a); mpc_parser_t *mpc_maybe_lift(mpc_parser_t *a, mpc_ctor_t lf); Returns a parser that runs a. If a is successful then it returns the result of a. If a is unsuccessful then it succeeds, but returns NULL (or the result of lf). mpc_parser_t *mpc_many(mpc_fold_t f, mpc_parser_t *a); Runs a zero or more times until it fails. Results are combined using fold function f. See the Function Types section for more details. mpc_parser_t *mpc_many1(mpc_fold_t f, mpc_parser_t *a); Runs a one or more times until it fails. Results are combined with fold function f. mpc_parser_t *mpc_count(int n, mpc_fold_t f, mpc_parser_t *a, mpc_dtor_t da); Runs a exactly n times. If this fails, any partial results are destructed with da. If successful results of a are combined using fold function f. mpc_parser_t *mpc_or(int n, ...); Attempts to run n parsers in sequence, returning the first one that succeeds. If all fail, returns an error. mpc_parser_t *mpc_and(int n, mpc_fold_t f, ...); Attempts to run n parsers in sequence, returning the fold of the results using fold function f. First parsers must be specified, followed by destructors for each parser, excluding the final parser. These are used in case of partial success. For example: mpc_and(3, mpcf_strfold, mpc_char('a'), mpc_char('b'), mpc_char('c'), free, free); would attempt to match 'a' followed by 'b' followed by 'c', and if successful would concatenate them using mpcf_strfold. Otherwise would use free on the partial results. mpc_parser_t *mpc_predictive(mpc_parser_t *a); Returns a parser that runs a with backtracking disabled. This means if a consumes more than one character, it will not be reverted, even on failure. Turning backtracking off has good performance benefits for grammars which are LL(1). These are grammars where the first character completely determines the parse result - such as the decision of parsing either a C identifier, number, or string literal. This option should not be used for non LL(1) grammars or it will produce incorrect results or crash the parser. Another way to think of mpc_predictive is that it can be applied to a parser (for a performance improvement) if either successfully parsing the first character will result in a completely successful parse, or all of the referenced sub-parsers are also LL(1). Function Types The combinator functions take a number of special function types as function pointers. Here is a short explanation of those types are how they are expected to behave. It is important that these behave correctly otherwise it is easy to introduce memory leaks or crashes into the system. typedef void(*mpc_dtor_t)(mpc_val_t*); Given some pointer to a data value it will ensure the memory it points to is freed correctly. typedef mpc_val_t*(*mpc_ctor_t)(void); Returns some data value when called. It can be used to create empty versions of data types when certain combinators have no known default value to return. For example it may be used to return a newly allocated empty string. typedef mpc_val_t*(*mpc_apply_t)(mpc_val_t*); typedef mpc_val_t*(*mpc_apply_to_t)(mpc_val_t*,void*); This takes in some pointer to data and outputs some new or modified pointer to data, ensuring to free the input data if it is no longer used. The apply_to variation takes in an extra pointer to some data such as global state. typedef mpc_val_t*(*mpc_fold_t)(int,mpc_val_t**); This takes a list of pointers to data values and must return some combined or folded version of these data values. It must ensure to free any input data that is no longer used once the combination has taken place. Case Study - Identifier Combinator Method Using the above combinators we can create a parser that matches a C identifier. When using the combinators we need to supply a function that says how to combine two char *. For this we build a fold function that will concatenate zero or more strings together. For this sake of this tutorial we will write it by hand, but this (as well as many other useful fold functions), are actually included in mpc under the mpcf_* namespace, such as mpcf_strfold. mpc_val_t *strfold(int n, mpc_val_t **xs) {   char *x = calloc(1, 1);   int i;   for (i = 0; i < n; i++) {     x = realloc(x, strlen(x) + strlen(xs[i]) + 1);     strcat(x, xs[i]);     free(xs[i]);   }   return x; } We can use this to specify a C identifier, making use of some combinators to say how the basic parsers are combined. mpc_parser_t *alpha = mpc_or(2, mpc_range('a', 'z'), mpc_range('A', 'Z')); mpc_parser_t *digit = mpc_range('0', '9'); mpc_parser_t *underscore = mpc_char('_');  mpc_parser_t *ident = mpc_and(2, strfold,   mpc_or(2, alpha, underscore),   mpc_many(strfold, mpc_or(3, alpha, digit, underscore)),   free);  /* Do Some Parsing... */  mpc_delete(ident); Notice that previous parsers are used as input to new parsers we construct from the combinators. Note that only the final parser ident must be deleted. When we input a parser into a combinator we should consider it to be part of the output of that combinator. Because of this we shouldn't create a parser and input it into multiple places, or it will be doubly feed. Regex Method There is an easier way to do this than the above method. mpc comes with a handy regex function for constructing parsers using regex syntax. We can specify an identifier using a regex pattern as shown below. mpc_parser_t *ident = mpc_re(""[a-zA-Z_][a-zA-Z_0-9]*"");  /* Do Some Parsing... */  mpc_delete(ident); Library Method Although if we really wanted to create a parser for C identifiers, a function for creating this parser comes included in mpc along with many other common parsers. mpc_parser_t *ident = mpc_ident();  /* Do Some Parsing... */  mpc_delete(ident); Parser References Building parsers in the above way can have issues with self-reference or cyclic-reference. To overcome this we can separate the construction of parsers into two different steps. Construction and Definition. mpc_parser_t *mpc_new(const char *name); This will construct a parser called name which can then be used as input to others, including itself, without fear of being deleted. Any parser created using mpc_new is said to be retained. This means it will behave differently to a normal parser when referenced. When deleting a parser that includes a retained parser, the retained parser will not be deleted along with it. To delete a retained parser mpc_delete must be used on it directly. A retained parser can then be defined using... mpc_parser_t *mpc_define(mpc_parser_t *p, mpc_parser_t *a); This assigns the contents of parser a to p, and deletes a. With this technique parsers can now reference each other, as well as themselves, without trouble. mpc_parser_t *mpc_undefine(mpc_parser_t *p); A final step is required. Parsers that reference each other must all be undefined before they are deleted. It is important to do any undefining before deletion. The reason for this is that to delete a parser it must look at each sub-parser that is used by it. If any of these have already been deleted a segfault is unavoidable - even if they were retained beforehand. void mpc_cleanup(int n, ...); To ease the task of undefining and then deleting parsers mpc_cleanup can be used. It takes n parsers as input, and undefines them all, before deleting them all. mpc_parser_t *mpc_copy(mpc_parser_t *a); This function makes a copy of a parser a. This can be useful when you want to use a parser as input for some other parsers multiple times without retaining it. Library Reference Common Parsers mpc_soi Matches only the start of input, returns NULL mpc_eoi Matches only the end of input, returns NULL mpc_boundary Matches only the boundary between words, returns NULL mpc_whitespace Matches any whitespace character "" \f\n\r\t\v"" mpc_whitespaces Matches zero or more whitespace characters mpc_blank Matches whitespaces and frees the result, returns NULL mpc_newline Matches '\n' mpc_tab Matches '\t' mpc_escape Matches a backslash followed by any character mpc_digit Matches any character in the range '0' - '9' mpc_hexdigit Matches any character in the range '0 - '9' as well as 'A' - 'F' and 'a' - 'f' mpc_octdigit Matches any character in the range '0' - '7' mpc_digits Matches one or more digit mpc_hexdigits Matches one or more hexdigit mpc_octdigits Matches one or more octdigit mpc_lower Matches any lower case character mpc_upper Matches any upper case character mpc_alpha Matches any alphabet character mpc_underscore Matches '_' mpc_alphanum Matches any alphabet character, underscore or digit mpc_int Matches digits and returns an int* mpc_hex Matches hexdigits and returns an int* mpc_oct Matches octdigits and returns an int* mpc_number Matches mpc_int, mpc_hex or mpc_oct mpc_real Matches some floating point number as a string mpc_float Matches some floating point number and returns a float* mpc_char_lit Matches some character literal surrounded by ' mpc_string_lit Matches some string literal surrounded by "" mpc_regex_lit Matches some regex literal surrounded by / mpc_ident Matches a C style identifier Useful Parsers mpc_startswith(mpc_parser_t *a); Matches the start of input followed by a mpc_endswith(mpc_parser_t *a, mpc_dtor_t da); Matches a followed by the end of input mpc_whole(mpc_parser_t *a, mpc_dtor_t da); Matches the start of input, a, and the end of input mpc_stripl(mpc_parser_t *a); Matches a first consuming any whitespace to the left mpc_stripr(mpc_parser_t *a); Matches a then consumes any whitespace to the right mpc_strip(mpc_parser_t *a); Matches a consuming any surrounding whitespace mpc_tok(mpc_parser_t *a); Matches a and consumes any trailing whitespace mpc_sym(const char *s); Matches string s and consumes any trailing whitespace mpc_total(mpc_parser_t *a, mpc_dtor_t da); Matches the whitespace consumed a, enclosed in the start and end of input mpc_between(mpc_parser_t *a, mpc_dtor_t ad, const char *o, const char *c); Matches a between strings o and c mpc_parens(mpc_parser_t *a, mpc_dtor_t ad); Matches a between ""("" and "")"" mpc_braces(mpc_parser_t *a, mpc_dtor_t ad); Matches a between ""<"" and "">"" mpc_brackets(mpc_parser_t *a, mpc_dtor_t ad); Matches a between ""{"" and ""}"" mpc_squares(mpc_parser_t *a, mpc_dtor_t ad); Matches a between ""["" and ""]"" mpc_tok_between(mpc_parser_t *a, mpc_dtor_t ad, const char *o, const char *c); Matches a between o and c, where o and c have their trailing whitespace striped. mpc_tok_parens(mpc_parser_t *a, mpc_dtor_t ad); Matches a between trailing whitespace consumed ""("" and "")"" mpc_tok_braces(mpc_parser_t *a, mpc_dtor_t ad); Matches a between trailing whitespace consumed ""<"" and "">"" mpc_tok_brackets(mpc_parser_t *a, mpc_dtor_t ad); Matches a between trailing whitespace consumed ""{"" and ""}"" mpc_tok_squares(mpc_parser_t *a, mpc_dtor_t ad); Matches a between trailing whitespace consumed ""["" and ""]"" Apply Functions void mpcf_dtor_null(mpc_val_t *x); Empty destructor. Does nothing mpc_val_t *mpcf_ctor_null(void); Returns NULL mpc_val_t *mpcf_ctor_str(void); Returns """" mpc_val_t *mpcf_free(mpc_val_t *x); Frees x and returns NULL mpc_val_t *mpcf_int(mpc_val_t *x); Converts a decimal string x to an int* mpc_val_t *mpcf_hex(mpc_val_t *x); Converts a hex string x to an int* mpc_val_t *mpcf_oct(mpc_val_t *x); Converts a oct string x to an int* mpc_val_t *mpcf_float(mpc_val_t *x); Converts a string x to a float* mpc_val_t *mpcf_escape(mpc_val_t *x); Converts a string x to an escaped version mpc_val_t *mpcf_escape_regex(mpc_val_t *x); Converts a regex x to an escaped version mpc_val_t *mpcf_escape_string_raw(mpc_val_t *x); Converts a raw string x to an escaped version mpc_val_t *mpcf_escape_char_raw(mpc_val_t *x); Converts a raw character x to an escaped version mpc_val_t *mpcf_unescape(mpc_val_t *x); Converts a string x to an unescaped version mpc_val_t *mpcf_unescape_regex(mpc_val_t *x); Converts a regex x to an unescaped version mpc_val_t *mpcf_unescape_string_raw(mpc_val_t *x); Converts a raw string x to an unescaped version mpc_val_t *mpcf_unescape_char_raw(mpc_val_t *x); Converts a raw character x to an unescaped version mpc_val_t *mpcf_strtriml(mpc_val_t *x); Trims whitespace from the left of string x mpc_val_t *mpcf_strtrimr(mpc_val_t *x); Trims whitespace from the right of string x mpc_val_t *mpcf_strtrim(mpc_val_t *x); Trims whitespace from either side of string x Fold Functions mpc_val_t *mpcf_null(int n, mpc_val_t** xs); Returns NULL mpc_val_t *mpcf_fst(int n, mpc_val_t** xs); Returns first element of xs mpc_val_t *mpcf_snd(int n, mpc_val_t** xs); Returns second element of xs mpc_val_t *mpcf_trd(int n, mpc_val_t** xs); Returns third element of xs mpc_val_t *mpcf_fst_free(int n, mpc_val_t** xs); Returns first element of xs and calls free on others mpc_val_t *mpcf_snd_free(int n, mpc_val_t** xs); Returns second element of xs and calls free on others mpc_val_t *mpcf_trd_free(int n, mpc_val_t** xs); Returns third element of xs and calls free on others mpc_val_t *mpcf_strfold(int n, mpc_val_t** xs); Concatenates all xs together as strings and returns result Case Study - Maths Language Combinator Approach Passing around all these function pointers might seem clumsy, but having parsers be type-generic is important as it lets users define their own ouput types for parsers. For example we could design our own syntax tree type to use. We can also use this method to do some specific house-keeping or data processing in the parsing phase. As an example of this power, we can specify a simple maths grammar, that ouputs int *, and computes the result of the expression as it goes along. We start with a fold function that will fold two int * into a new int * based on some char * operator. mpc_val_t *fold_maths(int n, mpc_val_t **xs) {    int **vs = (int**)xs;    if (strcmp(xs[1], ""*"") == 0) { *vs[0] *= *vs[2]; }   if (strcmp(xs[1], ""/"") == 0) { *vs[0] /= *vs[2]; }   if (strcmp(xs[1], ""%"") == 0) { *vs[0] %= *vs[2]; }   if (strcmp(xs[1], ""+"") == 0) { *vs[0] += *vs[2]; }   if (strcmp(xs[1], ""-"") == 0) { *vs[0] -= *vs[2]; }    free(xs[1]); free(xs[2]);    return xs[0]; } And then we use this to specify a basic grammar, which folds together any results. mpc_parser_t *Expr   = mpc_new(""expr""); mpc_parser_t *Factor = mpc_new(""factor""); mpc_parser_t *Term   = mpc_new(""term""); mpc_parser_t *Maths  = mpc_new(""maths"");  mpc_define(Expr, mpc_or(2,    mpc_and(3, fold_maths,     Factor, mpc_oneof(""+-""), Factor,     free, free),   Factor ));  mpc_define(Factor, mpc_or(2,    mpc_and(3, fold_maths,     Term, mpc_oneof(""*/""), Term,     free, free),   Term ));  mpc_define(Term, mpc_or(2, mpc_int(), mpc_parens(Expr, free))); mpc_define(Maths, mpc_whole(Expr, free));  /* Do Some Parsing... */  mpc_delete(Maths); If we supply this function with something like (4*2)+5, we can expect it to output 13. Language Approach It is possible to avoid passing in and around all those function pointers, if you don't care what type is output by mpc. For this, a generic Abstract Syntax Tree type mpc_ast_t is included in mpc. The combinator functions which act on this don't need information on how to destruct or fold instances of the result as they know it will be a mpc_ast_t. So there are a number of combinator functions which work specifically (and only) on parsers that return this type. They reside under mpca_*. Doing things via this method means that all the data processing must take place after the parsing. In many instances this is not an issue, or even preferable. It also allows for one more trick. As all the fold and destructor functions are implicit, the user can simply specify the grammar of the language in some nice way and the system can try to build a parser for the AST type from this alone. For this there are a few functions supplied which take in a string, and output a parser. The format for these grammars is simple and familiar to those who have used parser generators before. It looks something like this. number ""number"" : /[0-9]+/ ; expression      : <product> (('+' | '-') <product>)* ; product         : <value>   (('*' | '/')   <value>)* ; value           : <number> | '(' <expression> ')' ; maths           : /^/ <expression> /$/ ;  The syntax for this is defined as follows. ""ab"" The string ab is required. 'a' The character a is required. 'a' 'b' First 'a' is required, then 'b' is required.. 'a' | 'b' Either 'a' is required, or 'b' is required. 'a'* Zero or more 'a' are required. 'a'+ One or more 'a' are required. <abba> The rule called abba is required. Rules are specified by rule name, optionally followed by an expected string, followed by a colon :, followed by the definition, and ending in a semicolon ;. Multiple rules can be specified. The rule names must match the names given to any parsers created by mpc_new, otherwise the function will crash. The flags variable is a set of flags MPCA_LANG_DEFAULT, MPCA_LANG_PREDICTIVE, or MPCA_LANG_WHITESPACE_SENSITIVE. For specifying if the language is predictive or whitespace sensitive. Like with the regular expressions, this user input is parsed by existing parts of the mpc library. It provides one of the more powerful features of the library. mpc_parser_t *mpca_grammar(int flags, const char *grammar, ...); This takes in some single right hand side of a rule, as well as a list of any of the parsers referenced, and outputs a parser that does what is specified by the rule. The list of parsers referenced can be terminated with NULL to get an error instead of a crash when a parser required is not supplied. mpc_err_t *mpca_lang(int flags, const char *lang, ...); This takes in a full language (zero or more rules) as well as any parsers referred to by either the right or left hand sides. Any parsers specified on the left hand side of any rule will be assigned a parser equivalent to what is specified on the right. On valid user input this returns NULL, while if there are any errors in the user input it will return an instance of mpc_err_t describing the issues. The list of parsers referenced can be terminated with NULL to get an error instead of a crash when a parser required is not supplied. mpc_err_t *mpca_lang_file(int flags, FILE* f, ...); This reads in the contents of file f and inputs it into mpca_lang. mpc_err_t *mpca_lang_contents(int flags, const char *filename, ...); This opens and reads in the contents of the file given by filename and passes it to mpca_lang. Error Reporting mpc provides some automatic generation of error messages. These can be enhanced by the user, with use of mpc_expect, but many of the defaults should provide both useful and readable. An example of an error message might look something like this: <test>:0:3: error: expected one or more of 'a' or 'd' at 'k'  Misc Here are some other misc functions that mpc provides. These functions are susceptible to change between versions so use them with some care. void mpc_print(mpc_parser_t *p); Prints out a parser in some weird format. This is generally used for debugging so don't expect to be able to understand the output right away without looking at the source code a little bit. void mpc_stats(mpc_parser_t *p); Prints out some basic stats about a parser. Again used for debugging and optimisation. void mpc_optimise(mpc_parser_t *p); Performs some basic optimisations on a parser to reduce it's size and increase its running speed. Limitations & FAQ Does mpc support Unicode? mpc Only supports ASCII. Sorry! Writing a parser library that supports Unicode is pretty difficult. I welcome contributions! Is mpc binary safe? No. Sorry! Including NULL characters in a string or a file will probably break it. Avoid this if possible. The Parser is going into an infinite loop! While it is certainly possible there is an issue with mpc, it is probably the case that your grammar contains left recursion. This is something mpc cannot deal with. Left recursion is when a rule directly or indirectly references itself on the left hand side of a derivation. For example consider this left recursive grammar intended to parse an expression. expr : <expr> '+' (<expr> | <int> | <string>);  When the rule expr is called, it looks the first rule on the left. This happens to be the rule expr again. So again it looks for the first rule on the left. Which is expr again. And so on. To avoid left recursion this can be rewritten (for example) as the following. Note that rewriting as follows also changes the operator associativity. value : <int> | <string> ; expr  : <value> ('+' <expr>)* ;  Avoiding left recursion can be tricky, but is easy once you get a feel for it. For more information you can look on wikipedia which covers some common techniques and more examples. Possibly in the future mpc will support functionality to warn the user or re-write grammars which contain left recursion, but it wont for now. Backtracking isn't working! mpc supports backtracking, but it may not work as you expect. It isn't a silver bullet, and you still must structure your grammar to be unambiguous. To demonstrate this behaviour examine the following erroneous grammar, intended to parse either a C style identifier, or a C style function call. factor : <ident>        | <ident> '('  <expr>? (',' <expr>)* ')' ;  This grammar will never correctly parse a function call because it will always first succeed parsing the initial identifier and return a factor. At this point it will encounter the parenthesis of the function call, give up, and throw an error. Even if it were to try and parse a factor again on this failure it would never reach the correct function call option because it always tries the other options first, and always succeeds with the identifier. The solution to this is to always structure grammars with the most specific clause first, and more general clauses afterwards. This is the natural technique used for avoiding left-recursive grammars and unambiguity, so is a good habit to get into anyway. Now the parser will try to match a function first, and if this fails backtrack and try to match just an identifier. factor : <ident> '('  <expr>? (',' <expr>)* ')'        | <ident> ;  An alternative, and better option is to remove the ambiguity completely by factoring out the first identifier. This is better because it removes any need for backtracking at all! Now the grammar is predictive! factor : <ident> ('('  <expr>? (',' <expr>)* ')')? ;  How can I avoid the maximum string literal length? Some compilers limit the maximum length of string literals. If you have a huge language string in the source file to be passed into mpca_lang you might encounter this. The ANSI standard says that 509 is the maximum length allowed for a string literal. Most compilers support greater than this. Visual Studio supports up to 2048 characters, while gcc allocates memory dynamically and so has no real limit. There are a couple of ways to overcome this issue if it arises. You could instead use mpca_lang_contents and load the language from file or you could use a string literal for each line and let the preprocessor automatically concatenate them together, avoiding the limit. The final option is to upgrade your compiler. In C99 this limit has been increased to 4095. The automatic tags in the AST are annoying! When parsing from a grammar, the abstract syntax tree is tagged with different tags for each primitive type it encounters. For example a regular expression will be automatically tagged as regex. Character literals as char and strings as string. This is to help people wondering exactly how they might need to convert the node contents. If you have a rule in your grammar called string, char or regex, you may encounter some confusion. This is because nodes will be tagged with (for example) string either if they are a string primitive, or if they were parsed via your string rule. If you are detecting node type using something like strstr, in this situation it might break. One solution to this is to always check that string is the innermost tag to test for string primitives, or to rename your rule called string to something that doesn't conflict. Yes it is annoying but its probably not going to change! Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/orangeduck/mpc"	"A parser combinator library.."	"true"
"Utilities"	"ncurses"	"https://gnu.org/software/ncurses/"	"Coloured terminal UI library. or later."	"null"	"null"	"null"	"GNU GPL3"	"http://www.gnu.org/licenses/gpl.html"	"null"	"null"	"null"	"null"	"null"	"Announcing ncurses 6.0 - GNU Project - Free Software   Foundation (FSF) Announcing ncurses 6.0 Overview The ncurses (new curses) library is a free software emulation of curses in System V Release 4.0 (SVr4), and more. It uses terminfo format, supports pads and color and multiple highlights and forms characters and function-key mapping, and has all the other SVr4-curses enhancements over BSD curses. SVr4 curses is better known today as X/Open Curses. In mid-June 1995, the maintainer of 4.4BSD curses declared that he considered 4.4BSD curses obsolete, and encouraged the keepers of unix releases such as BSD/OS, FreeBSD and NetBSD to switch over to ncurses. Since 1995, ncurses has been ported to many systems: It is used in almost every system based on the Linux kernel (aside from some embedded applications). It is used as the system curses library on OpenBSD, FreeBSD and OSX. It is used in environments such as Cygwin and MinGW. The first of these was EMX on OS/2 Warp. It is used (though usually not as the system curses) on all of the vendor unix systems, e.g., AIX, HP-UX, IRIX64, SCO, Solaris, Tru64. It should work readily on any ANSI/POSIX-conforming unix. The distribution includes the library and support utilities, including captoinfo, a termcap conversion tool clear, utility for clearing the screen infocmp, the terminfo decompiler tabs, set tabs on a terminal tic, the terminfo compiler toe, list (table of) terminfo entries tput, utility for retrieving terminal capabilities in shell scripts tset, to initialize the terminal Full manual pages are provided for the library and tools. The ncurses distribution is available via anonymous FTP at the GNU distribution site ftp://ftp.gnu.org/gnu/ncurses/ http://ftp.gnu.org/gnu/ncurses/ It is also available at ftp://invisible-island.net/ncurses/ http://invisible-mirror.net/archives/ncurses/ Release Notes These notes are for ncurses 6.0, released August 8, 2015. This release is designed to be source-compatible with ncurses 5.0 through 5.9; providing a new application binary interface (ABI). Although the source can still be configured to support the ncurses 5 ABI, the intent of the release is to provide extensions which are generally useful, but binary-incompatible with ncurses 5: Extend the cchar_t structure to allow more than 16 colors to be encoded. Modify the encoding of mouse state to make room for a 5th mouse button. That allows one to use ncurses with a wheel mouse with xterm or similar X terminal emulators. There are, of course, numerous other improvements, including fixes made based on the Clang and Coverity static analyzers. memory leak fixes using Valgrind The release notes mention some bug-fixes, but are focused on new features and improvements to existing features log since ncurses 5.9 release. While the intent of the release is to provide a new stable ABI, there are other development activities which are summarized below. The original release plan, e.g., for ""5.10"" was to improve the MinGW port. Ultimately that was completed (wide-character support, mouse, etc), but was deferred to focus on termcap support and performance issues. Also, pinpointing the problems with Console2 took a while. A review of termcap compatibility in 2011 led to several minor fixes in the library and improvements to utilities. To do this properly, a review of the various extent termcap implementations was needed. The termcap library checker (tctest) (not part of ncurses) was one result. A followup review of performance using ncurses-examples in 2014 led to additional improvements. Output buffering provided a further, but worthwhile distraction. A bug report in 2012 regarding the use of signal handlers in ncurses) pointed out a problem with the use of unsafe functions for handling SIGTSTP. Other signals could be addressed with workarounds; repairing SIGTSTP required a different approach. The solution required changing internal behavior of the library: how it handles output buffering. Now ncurses buffers its own output, independently of the standard output. A few applications relied upon the library's direct reuse of the standard output buffering; however that is unspecified behavior and has never been a recommended practice. Identifying these applications as well as refining the change to permit low-level applications to work consistently took time. Since the introduction of the experimental support for 256 colors early in 2005 (released in ncurses 5.5), there has been increased user interest. Almost all packagers continue providing the ncurses ABI 5 which cannot support 256 colors. Symbol versioning, or the lack of it in ncurses, is the main reason why packagers would be reluctant to add a new ncurses ABI. This release provides the new ABI along with script-generated lists of versioned symbols which can be used for both ABI 5 and 6 (with distinct names to keep the two separate). This took time to development, as reported in Symbol versioning in ncurses. Library improvements Output buffering X/Open curses provides more than one initialization function: initscr (the simplest) accepts no parameters. newterm accepts parameters for the stream input and output setupterm (the low-level function) accepts a parameter for the file descriptor of the output. They are documented in X/Open as if initscr calls newterm using stdout for output stream, and in turn newterm calls setupterm using fileno(stdout) for the file descriptor. As long as an implementation acts as if it does this, it conforms. In practice, implementations do what is implied. This creates a problem: the low-level setupterm function's file descriptor is unbuffered, while newterm implies buffered output. X/Open Curses says that all output is done through the file descriptor, and does not say how the output stream is actually used. Initially, ncurses used the file descriptor (obtained from the output stream passed to newterm) for changing the terminal modes, and relied upon the output parameter of newterm for buffered output. Later (to avoid using unsafe buffered I/O in signal handlers), ncurses was modified to use the file descriptor (unbuffered output) when cleaning up on receipt of a signal. Otherwise (when not handling a signal), it continued to use the buffered output. That approach worked reasonably well and as a side effect, using the same buffered output as an application might use for printf meant that no flushing was needed when switching between normal- and screen-modes. There were a couple of problems: to get good performance, curses (not only ncurses, but SVr4 curses in general) set an output buffer using setbuf or similar function. There is no standard (or portable) way to turn that output buffer off, and revert to line-buffering. The NCURSES_NO_SETBUF environment variable did make it optional. to handle SIGTSTP (the “stop” signal), ncurses relied upon unsafe functions. That is, due to the complexity of the feature, it relied upon reusing existing functions which should not have been called via the signal handler. Conveniently, solving the second problem (by making ncurses do its own output buffering) also fixed the first one. But there were special cases to resolve: low-level functions such as mvcur, putp, vidattr explicitly use the standard output. Those functions were reused internally, and required modification to distinguish whether they were used by the high-level or low-level interfaces. Finally, there may still be a few programs which should be modified to improve their portability, e.g., adding an  fflush(stdout);  when switching from “shell” mode to “program” (curses) mode. Those are fairly rare because most programmers have learned not to mix printf and printw. Symbol versioning This release introduces symbol-versioning to ncurses because without it, the change of ABI would be less successful. A lengthy discussion will be presented in Symbol versioning in ncurses. These notes summarize what has changed, and what can be done with the new release. Symbol-versioning allows the developers of a library to mark each public symbol (both data and functions) with an identifier denoting the library name and the version for which it was built. By doing this, users of the library have a way to help ensure that applications do not accidentally load an incompatible library. In addition, private symbols can be hidden entirely. This release provides sample files for the four principal configurations of ncurses libraries: ncurses, ncursesw, ncursest and ncursestw. Each sample is given in two forms: “.map” These list all public symbols, together with version names. “.sym” These list all public symbols, without version names. The sample files are generated by scripts which take into account a few special cases such as tack to omit many of the ncurses private symbols (beginning with “_nc_”). Here are counts of globals versus locals: Config Symbols Globals Locals ""_nc_"" ncurses 976 796 180 332 ncursesw 1089 905 184 343 ncursest 979 804 175 358 ncursestw 1098 914 184 372 Although only four sample configurations are presented, each is formed by merging symbols from several combinations of configure-script options, taking into account advice from downstream packagers. Because they are formed by merging, the sample files may list a symbol which is not in a given package. That is expected. The samples have been tested and are working with systems (such as Fedora, FreeBSD and Debian) which fully support this feature. There are other systems which do not support the feature, and a few (such as Solaris) which provide incomplete support. The version-naming convention used allows these sample files to build distinct libraries for ABI 5 and 6. Version names consist of configuration name, e.g., “NCURSESW” for the wide-character libraries ABI version (if not 5) library name for two special cases which have the same interface across configurations: “TINFO” and “TIC” release version patch date (for the release version) For example, running nm -D on the libraries in the ncurses6 test package shows these symbol-versions:  0000000000000000 A NCURSES6_TIC_5.0.19991023 0000000000000000 A NCURSES6_TIC_5.1.20000708 0000000000000000 A NCURSES6_TIC_5.5.20051010 0000000000000000 A NCURSES6_TIC_5.7.20081102 0000000000000000 A NCURSES6_TIC_5.9.20150530 0000000000000000 A NCURSES6_TINFO_5.0.19991023 0000000000000000 A NCURSES6_TINFO_5.1.20000708 0000000000000000 A NCURSES6_TINFO_5.2.20001021 0000000000000000 A NCURSES6_TINFO_5.3.20021019 0000000000000000 A NCURSES6_TINFO_5.4.20040208 0000000000000000 A NCURSES6_TINFO_5.5.20051010 0000000000000000 A NCURSES6_TINFO_5.6.20061217 0000000000000000 A NCURSES6_TINFO_5.7.20081102 0000000000000000 A NCURSES6_TINFO_5.8.20110226 0000000000000000 A NCURSES6_TINFO_5.9.20150530 0000000000000000 A NCURSESW6_5.1.20000708 0000000000000000 A NCURSESW6_5.3.20021019 0000000000000000 A NCURSESW6_5.4.20040208 0000000000000000 A NCURSESW6_5.5.20051010 0000000000000000 A NCURSESW6_5.6.20061217 0000000000000000 A NCURSESW6_5.7.20081102 0000000000000000 A NCURSESW6_5.8.20110226 0000000000000000 A NCURSESW6_5.9.20150530  As a special case, this release (which makes the final change for ABI 5) is marked with release version 5.9 and patch date 20150530. Miscellaneous The new release has several improvements for performance and building. For instance: several files in ncurses- and progs-directories were modified to allow const data used in internal tables to be put by the linker into the readonly text segment. various improvements were made to building the Ada95 binding, both in simplifying the generated files as well as improving the way it uses gnatmake There are also new features in the libraries: added use_tioctl function added wgetdelay to retrieve _delay member of WINDOW if it happens to be opaque, e.g., in the pthread configuration. added A_ITALIC extension. added form library extension O_DYNAMIC_JUSTIFY option which can be used to override the different treatment of justification for static versus dynamic fields . rewrote putwin and getwin, making an extended version which is capable of reading screen-dumps between the wide/normal ncurses configurations. These are text files, except for a magic code at the beginning:  0       string          \210\210        Screen-dump (ncurses)  several changes to mouse support include: added decoder for xterm SGR 1006 mouse mode. added experimental support for “%u” format to terminfo. improved behavior of wheel-mice for xterm protocol: noting that there are only button-presses for buttons “4” and “5”, so there is no need to wait to combine events into double-clicks . There are a few new configure options dealing with library customization: add “--enable-ext-putwin” configure option to turn on the extended putwin/getwin. By default, this is enabled for ABI 6 and disabled with ABI 5. add “--enable-string-hacks” option to control whether strlcat and strlcpy may be used. Because ncurses already does the requisite buffer-limit checks, this feature is mainly of interest to quiet compiler-warnings on a few systems. add configure option “--with-tparm-arg” to allow tparm's parameters to be something more likely to be the same size as a pointer, e.g., intptr_t (again, the default is set for ABI 6). Program improvements Utilities Most of the termcap-related changes based on development of tctest (termcap library checker) are implemented in the tic and infocmp programs rather than affecting the library. As noted in the discussion of tctest, ncurses's ability to translate between terminfo and termcap formats has been improved at different times, but subject to feedback from ""real"" termcap users. There are very few of those. Nowadays, virtually all termcap users are using ncurses (or NetBSD, with its own terminfo library) and their programs are actually using terminfo rather than termcap data. Still, there are a few. A comment about the translation of the ASCII NUL character prompted a review: Both terminfo and termcap store string capabilities as NUL-terminated strings. In terminfo, a \0 in a terminal description is stored as \200. There are no (known) terminals which would behave differently when sent \0 or \200. When translating to terminfo format (or displaying a printable version of an entry using infocmp), ncurses shows \200 as \0. It has done this since 1998 (quoting from the NEWS file):  980103 ...         + modify _nc_tic_expand() to generate \0 rather than \200. ...         + correct translation of terminfo ""^@"", to \200, like \0.  However, the _nc_tic_expand function (which optionally produces terminfo or termcap format) did not address this special case for termcap. Even the later 4.4BSD cgetstr interprets a \0 literally, ending that string (rather than using the terminfo improvement). As a result of the review, several improvements were made to ncurses translation to/from termcap format — and improving the checks made in tic for consistency of entries. Most of these are not of general interest, except for two new command-line options for tic and infocmp: the “-0” option generates termcap/terminfo source on a single line. the “-K” option provides stricter BSD-compatibility for termcap output. Other user-visible improvements and new features include: added “-D” option to tic and infocmp, to show the database locations that it could use. added “-s” option to toe, to sort its output. extended “-c” and “-n” options of infocmp to allow comparing more than two entries. modified toe's report when “-a” and “-s” options are combined, to add a column showing which entries belong to a given database. modified the clear program to take into account the “E3” extended capability to clear the terminal's scrollback buffer. Examples Along with the library and utilities, many improvements were made to the ncurses-examples. Some were made to allow building (and comparison-testing) against NetBSD curses and PDCurses. Both lack some of the X/Open Curses features, necessitating customization. But this activity was useful because it showed some remaining performance issues (which have been resolved in this release). These changes were made to verify compatibility or compare performance of ncurses: made workarounds for compiling test-programs with NetBSD curses, though it lacks some common functions such as use_env. added dots_termcap test-program added dots_curses test-program, for comparison with the low-level examples. added test_setupterm test-proram to demonstrate normal/error returns from the setupterm and restartterm functions. added “-d”, “-e” and “-q” options to the demo_terminfo and demo_termcap test-programs. added “-y” option to demo_termcap and test/demo_terminfo test-programs to demonstrate behavior with/without extended capabilities. modified demo_termcap and demo_terminfo test-programs to make their options more directly comparable, and add “-i” option to specify a terminal description filename to parse for names to lookup. rewrote the tests for mvderwin and test for recursive mvwin in the movewindow test-program. These changes were made to help with the MinGW port: added test-screens to the ncurses test-program to show 256-characters at a time, to help with MinGW port. modified the view test-program to load UTF-8 when built with MinGW by using regular win32 API because the MinGW functions mblen and mbtowc do not work. added “-s” option to the view test-program to allow it to start in single-step mode, reducing size of trace files when it is used for debugging MinGW changes. These changes were made to verify new extensions in ncurses: added form_driver_w entrypoint to wide-character forms library, as well as form_driver_w test-program. modified ncurses test-program's b/B tests to display lines only for the attributes which a given terminal supports, to make room for an italics test. modified ncurses test-program, adding “-E” and “-T” options to demonstrate use_env versus use_tioctl. modified ncurses test-program's c/C tests to cycle through subsets of the total number of colors, to better illustrate 8/16/88/256-colors by providing directly comparable screens. modified the ncurses test-program to also show position reports in 'a' test. These changes were made to make the examples more useful: added scripts for building dpkg and rpm test-packages modified the hanoi test-program to show the minimum number of moves possible for the given number of tiles. modified the knight test-program to show the number of choices possible for each position in automove option, e.g., to allow user to follow Warnsdorff's rule to solve the puzzle. Terminal database This release provides improvements to tic's “-c” checking option, which was used for example to make sgr in several entries agree with other caps. correct padding in some entries where earlier versions had miscounted the number of octal digits. There are several new terminal descriptions: mlterm is now aliased to mlterm3 nsterm is now derived from nsterm-256color putty-sco teken is FreeBSD's ""xterm"" console. terminator terminology tmux is derived from screen. several screen.XXX entries support the respective variations for 256 colors. simpleterm is now 0.5 vte is aliased to vte-2012 vt520ansi A few entries use extensions (user-defined terminal capabilities): E3, used in linux, putty and xterm-basic is tested in the clear program to erase a terminal's scrollback. TS is used in the xterm+sl building block to help deprecate the misuse of tsl for xterm's title-string. XT is used in some terminfo entries to improve usefulness for other applications than screen, which would like to pretend that xterm's title is a status-line. xm is used in examples xterm-1005 and xterm-1006 to illustrate a way to make mouse handling more general A few terminals support italics and/or dim capabilities. In particular, screen does not. Documented that, and accommodated the terminals where this feature works with the A_ITALIC extension. konsole, mlterm3 (italics) nsterm (dim) screen (dim) vte (dim, italics) xterm (dim, italics) Documentation As usual, this release improves documentation by describing new features, attempts to improve the description of features which users have found confusing fills in overlooked descriptions of features which were described in the NEWS file but treated sketchily in manual pages. In addition, the mechanism for producing HTML versions of the documentation has been improved: use an improved version of man2html to generate html manpages. regenerated NCURSES-Programming-HOWTO.html to fix some of the broken html emitted by docbook. Interesting bug-fixes Ada95 binding: modify makefile rules to ensure that the PIC option is not used when building a static library make Ada95 build-fix for big-endian architectures such as sparc. This undoes one of the fixes from 20110319, which added an “Unused” member to representation clauses, replacing that with pragmas to suppress warnings about unused bits. Color and attributes: parenthesize parameter of COLOR_PAIR and PAIR_NUMBER in curses.h in case it happens to be a comma-expression. improve 20021221 workaround for broken acs, handling a case where that ACS_xxx character is not in the acsc string but there is a known wide-character which can be used. modify init_pair to accept -1's for color value after assume_default_colors has been called. add a check in start_color to limit color-pairs to 256 when extended colors are not supported. Resizing the screen: propagate error-returns from wresize, i.e., the internal increase_size and decrease_size functions through resize_term. add check for zero/negative dimensions for resizeterm and resize_term. modify resizeterm to always push a KEY_RESIZE onto the fifo, even if screensize is unchanged. Modify library to push a KEY_RESIZE if there was a SIGWINCH, even if it does not call resizeterm). These changes eliminate the case where a SIGWINCH is received, but ERR is returned from wgetch or wgetnstr because the screen dimensions did not change. Low-level interfaces fix an old bug in the termcap emulation; “%i” was ignored in tparm because the parameters to be incremented were already on the internal stack. change “%l” behavior in tparm to push the string length onto the stack rather than saving the formatted length into the output buffer. modify name-comparison for tgetstr, etc., to accommodate legacy applications as well as to improve compatbility with BSD 4.2 termcap implementations (see note for 980725). High-level interfaces modify internal recursion in wgetch which handles cooked mode to check if the call to wgetnstr returned an error. This can happen when both nocbreak and nodelay are set, for instance (see note for 960418). add a check in internal function waddch_nosync to ensure that tab characters are treated as control characters; some broken locales claim they are printable. modify menu library to ensure that a menu's top-row is adjusted as needed to ensure that the current item is on the screen fix special case where double-width character overwrites a single- width character in the first column. Configuration changes Major changes The ncurses 6.0 configure script makes changes to the default value of several configure options, depending on the --with-abi-version option (i.e., whether its value is “5” or “6”): --enable-const Feature introduced in 970405 supports the use of const where X/Open Curses should have, but did not. NetBSD curses does something similar with const. --enable-ext-colors Extends the cchar_t structure to allow more than 16 colors to be encoded. This applies only to the wide-character (--enable-widec) configuration. --enable-ext-mouse Modifies the encoding of mouse state to make room for a 5th mouse button. That allows one to use ncurses with a wheel mouse with xterm or similar X terminal emulators. --enable-ext-putwin Modifies the file-format written by putwin to use printable text rather than binary files, allowing getwin to read screen dumps written by differently-configured ncurses libraries. The extended getwin can still read binary screen dumps from the same configuration of ncurses. This does not change the ABI (the binary interface seen by calling applications). --enable-interop Modifies the FIELDTYPE structure used for the form library to make it more generic. --enable-lp64 Allows an application to define _LP64 to declare chtype and mmask_t as simply “unsigned” rather than the configured types using the --with-chtype and --with-mmask_t options. --enable-sp-funcs Compile-in support for extended functions which accept a SCREEN pointer, reducing the need for juggling the global SP value with set_term and delscreen. --with-chtype=uint32_t Makes chtype explicitly a 32-bit unsigned value. --with-mmask_t=uint32_t Makes mmask_t explicitly a 32-bit unsigned value. --with-tparm-arg=intptr_t X/Open Curses declares tparm using long for each of the parameters aside from the formatting string, presuming that long and char* are the same size. This configure option uses intptr_t which provides a better guarantee of the sizes. The configure script no longer checks for antique compilers; c89 is assumed as a minimum. There are a few features from later revisions which are used when available. The configure script makes checks to turn on useful warnings from clang, gcc and icc. You should be able to build ncurses 6.0 with any of the current (or not so current) C compilers available in 2015. The configure script, by the way, makes changes which do not work with systems whose /bin/sh is non-POSIX. This mainly affects Solaris (the other vendor unix systems have followed the POSIX guidelines for the past twenty years). If you must build on Solaris, its xpg4 binaries suffice, e.g., #!/bin/sh WHAT=`hostname|sed -e 's/\..*//'` OUT=configure.out cat >>$OUT <<EOF/ ** `date` ** node: $WHAT ** user: `id` ** conf: $* EOF/   SHELL=/bin/sh if test -f /usr/xpg4/bin/sh then         CONFIG_SHELL=/usr/xpg4/bin/sh         export CONFIG_SHELL         SHELL=$CONFIG_SHELL fi   rm -f config.status config.cache TOP=$HOME/$WHAT $SHELL ./configure --verbose \         --disable-echo \         --disable-overwrite \         --enable-warnings \         --with-warnings \         --prefix=$TOP $* 2>&1 | tee -a $OUT Other major changes to the configure script include: ABI 6 is now the default, intending that the existing ABI 5 should build as before using the “--with-abi-version=5” option. added --with-extra-suffix option to help with installing nonconflicting ncurses6 packages, e.g., avoiding header- and library-conflicts. NOTE: as a side-effect, this renames adacurses-config to adacurses5-config and adacursesw-config to adacursesw5-config the configure script looks for gnatgcc if the Ada95 binding is built, in preference to the default gcc/cc. The script also ensures that the Ada95 binding is built with the level of optimization as the C libraries. the configure script captures define's related to -D_XOPEN_SOURCE from the configure check and adds those to the *-config and *.pc files, to simplify use for the wide-character libraries. Configuration options There are several new (or extended) configure options: --disable-db-install Do not install the terminal database. This is used to omit features for packages, as done with --without-progs. The option simplifies building cross-compile support packages. --disable-gnat-projects This option is used for regression testing --disable-lib-suffixes Suppress the “w”, “t” or “tw” suffixes which normally would be added to the library names for the --enable-widec and --with-pthread options. --with-cxx-shared When --with-shared is set, build libncurses++ as a shared library. This implicitly relies upon building with gcc/g++, since other compiler suites may have differences in the way shared libraries are built. libtool by the way has similar limitations. --with-hashed-db Extended this configure option to simplify building with different versions of Berkeley database using FreeBSD ports. --with-pc-suffix If "".pc"" files are installed, optionally add a suffix to the files and corresponding package names to separate unusual configurations. If no option value is given (or if it is ""none""), no suffix is added. This option is used in the test package for ncurses6. --with-xterm-kbs Configure xterm's terminfo entries to use either BS (^H, i.e., ASCII backspace) or DEL (^?, or 127). Portability MinGW Most of the portability-related work since ncurses 5.9 extended and improved the MinGW port introduced in ncurses 5.8. The MinGW port can be readily cross-compiled: modified configure script to allow creating dll's for MinGW when cross-compiling. enforced Windows-style path-separator if cross-compiling, added scripts for test-builds of cross-compiled packages for ncurses6 to MinGW. added pc-files to the MinGW cross-compiling test-packages. added script for building test-packages of binaries cross-compiled to MinGW using NSIS. added nc_mingw.h to installed headers for MinGW port; this is needed for cross-compiling ncurses-examples. added test-packages for cross-compiling ncurses-examples using the MinGW test-packages. The MinGW-specific Windows driver accounts for several changes: wide-character display is made usable by replacing MinGW's non-working wcrtomb and wctomb functions. implemented some display features: beep, flash, curs_set. the driver handles repainting on endwin/refresh combination. modified treatment of TERM variable for MinGW port to allow explicit use of the Windows console driver by checking if $TERM is set to “#win32console” or an abbreviation of that. the Windows driver also matches the special TERM value “unknown” the driver now returns characters for special keys, (like ansi.sys does), when keypad mode is off, rather than returning nothing at all. the driver checks a new environment variable NCURSES_CONSOLE2 to optionally work around a deficiency in Console2 (and its descendent ConsoleZ) which hang when an application creates a console buffer. Finally, there are other improvements: MinGW is one of the configurations where ncurses installs by default into /usr configuration for cross-compiling uses AC_CHECK_TOOLS in preference to AC_PATH_PROGS when searching for ncurses*-config, e.g., in Ada95/configure and test/configure. extend Windows support to work with MSYS2; this works with a scenario where there is an ANSI-escape handler such as ansicon running in the console window. wrap isatty calls with a macro, provide a corresponding set of support routines to address differences between MinGW and MSYS2. ensure WINVER is defined in makefiles rather than using headers. add check for the gnatprep “-T” option. work around a bug introduced by gcc 4.8.1 in MinGW which breaks ""trace"" feature. add a driver-name method to each of the drivers. Other ports These changes affect certain platforms (ports): the configure script knows how to build shared libraries with DragonFlyBSD and Interix. support for AIX shared libraries is improved, tested with AIX 5.3, 6.1 and 7.1 with both gcc 4.2.4 and cc: the shared-library suffix for AIX 5 and 6 is now "".so"" the -brtl option is used with AIX 5-7; it is needed to link with the shared libraries. the configure --enable-pc-files option takes into account the PKG_CONFIG_PATH variable. the configure option --with-pkg-config-libdir provides control over the actual directory into which pc-files are installed. the build scripts add explicit -ltinfo, etc., to the generated "".pc"" file when ld option “--as-needed” is used, or when ncurses and tinfo are installed without using rpath. the configure script disallows conflicting options “--with-termlib” and “--enable-term-driver”. the check for missing c++ compiler to work when no error is reported, and no variables set is improved (see note for 20021206). the misc/gen_edit.sh script selects a ""linux"" entry which works with the current kernel rather than assuming it is always ""linux3.0"" the test/configure script makes it simpler to override names of curses-related libraries, to help with linking with pdcurses in MinGW environment. the configure-script/ifdef's allow the BSD OLD_TTY feature to be suppressed if the type of ospeed is configured using the option --with-ospeed to not be a short. By default, it is a short for termcap-compatibility. the MKlib_gen.sh script works around a recent change in gcc 5 (released mid-2015) which essentially emits multiple #line statements for the same position in a file. the configure script works with Minix3.2 (see note on portability) OS/2 redux: the configure script supports OS/2 kLIBC. the --with-lib-prefix option allows configuring for old/new flavors of OS/2 EMX. improved configure-script checks for _XOPEN_SOURCE: the definition works starting with Solaris 10. the definition is suppressed for IRIX64, since its header files have a conflict versus _SGI_SOURCE. Features of ncurses The ncurses package is fully upward-compatible with SVr4 (System V Release 4) curses: All of the SVr4 calls have been implemented (and are documented). ncurses supports all of the for SVr4 curses features including keyboard mapping, color, forms-drawing with ACS characters, and automatic recognition of keypad and function keys. ncurses provides these SVr4 add-on libraries (not part of X/Open Curses): the panels library, supporting a stack of windows with backing store. the menus library, supporting a uniform but flexible interface for menu programming. the form library, supporting data collection through on-screen forms. ncurses's terminal database is fully compatible with that used by SVr4 curses. ncurses supports user-defined capabilities which it can see, but which are hidden from SVr4 curses applications using the same terminal database. It can be optionally configured to match the format used in related systems such as AIX and Tru64. Alternatively, ncurses can be configured to use hashed databases rather than the directory of files used by SVr4 curses. The ncurses utilities have options to allow you to filter terminfo entries for use with less capable curses/terminfo versions such as the HP/UX and AIX ports. The ncurses package also has many useful extensions over SVr4: The API is 8-bit clean and base-level conformant with the X/OPEN curses specification, XSI curses (that is, it implements all BASE level features, and most EXTENDED features). It includes many function calls not supported under SVr4 curses (but portability of all calls is documented so you can use the SVr4 subset only). Unlike SVr3 curses, ncurses can write to the rightmost-bottommost corner of the screen if your terminal has an insert-character capability. Ada95 and C++ bindings. Support for mouse event reporting with X Window xterm and FreeBSD and OS/2 console windows. Extended mouse support via Alessandro Rubini's gpm package. The function wresize allows you to resize windows, preserving their data. The function use_default_colors allows you to use the terminal's default colors for the default color pair, achieving the effect of transparent colors. The functions keyok and define_key allow you to better control the use of function keys, e.g., disabling the ncurses KEY_MOUSE, or by defining more than one control sequence to map to a given key code. Support for 256-color terminals, such as modern xterm. Support for 16-color terminals, such as aixterm and modern xterm. Better cursor-movement optimization. The package now features a cursor-local-movement computation more efficient than either BSD's or System V's. Super hardware scrolling support. The screen-update code incorporates a novel, simple, and cheap algorithm that enables it to make optimal use of hardware scrolling, line-insertion, and line-deletion for screen-line movements. This algorithm is more powerful than the 4.4BSD curses quickch routine. Real support for terminals with the magic-cookie glitch. The screen-update code will refrain from drawing a highlight if the magic- cookie unattributed spaces required just before the beginning and after the end would step on a non-space character. It will automatically shift highlight boundaries when doing so would make it possible to draw the highlight without changing the visual appearance of the screen. It is possible to generate the library with a list of pre-loaded fallback entries linked to it so that it can serve those terminal types even when no terminfo tree or termcap file is accessible (this may be useful for support of screen-oriented programs that must run in single-user mode). The tic/captoinfo utility provided with ncurses has the ability to translate many termcaps from the XENIX, IBM and AT&T extension sets. A BSD-like tset utility is provided. The ncurses library and utilities will automatically read terminfo entries from $HOME/.terminfo if it exists, and compile to that directory if it exists and the user has no write access to the system directory. This feature makes it easier for users to have personal terminfo entries without giving up access to the system terminfo directory. You may specify a path of directories to search for compiled descriptions with the environment variable TERMINFO_DIRS (this generalizes the feature provided by TERMINFO under stock System V.) In terminfo source files, use capabilities may refer not just to other entries in the same source file (as in System V) but also to compiled entries in either the system terminfo directory or the user's $HOME/.terminfo directory. The table-of-entries utility toe makes it easy for users to see exactly what terminal types are available on the system. The library meets the XSI requirement that every macro entry point have a corresponding function which may be linked (and will be prototype-checked) if the macro definition is disabled with #undef. Extensive documentation is provided (see the Additional Reading section of the ncurses FAQ for online documentation). Applications using ncurses The ncurses distribution includes a selection of test programs (including a few games). These are available separately as ncurses-examples The ncurses library has been tested with a wide variety of applications including: cdk Curses Development Kit http://invisible-island.net/cdk/ ded directory-editor http://invisible-island.net/ded/ dialog the underlying application used in Slackware's setup, and the basis for similar install/configure applications on many systems. http://invisible-island.net/dialog/ lynx the text WWW browser http://lynx.isc.org/ Midnight Commander file manager http://www.midnight-commander.org/ mutt mail utility http://www.mutt.org/ ncftp file-transfer utility http://www.ncftp.com/ nvi New vi uses ncurses. https://sites.google.com/a/bostic.com/keithbostic/nvi tin newsreader, supporting color, MIME http://www.tin.org/ as well as some that use ncurses for the terminfo support alone: minicom terminal emulator for serial modem connections http://alioth.debian.org/projects/minicom/ mosh a replacement for ssh. https://mosh.mit.edu/ tack terminfo action checker http://invisible-island.net/ncurses/tack.html tmux terminal multiplexor http://tmux.github.io/ vile vi-like-emacs may be built to use the terminfo, termcap or curses interfaces. http://invisible-island.net/vile/ and finally, those which use only the termcap interface: emacs text editor http://www.gnu.org/software/emacs/ screen terminal multiplexor http://www.gnu.org/software/screen/ vim text editor http://www.vim.org/ Development activities Zeyd Ben-Halim started ncurses from a previous package pcurses, written by Pavel Curtis. Eric S. Raymond continued development. Jürgen Pfeifer wrote most of the form and menu libraries. Ongoing development work is done by Thomas Dickey. Thomas Dickey also acts as the maintainer for the Free Software Foundation, which holds the copyright on ncurses. Contact the current maintainers at bug-ncurses@gnu.org To join the ncurses mailing list, please write email to bug-ncurses-request@gnu.org containing the line: subscribe <name>@<host.domain> This list is open to anyone interested in helping with the development and testing of this package. Beta versions of ncurses and patches to the current release are made available at ftp://invisible-island.net/ncurses/ . There is an archive of the mailing list here: http://lists.gnu.org/archive/html/bug-ncurses (also https) Related resources The release notes make scattered references to these pages, which may be interesting by themselves: man2html ncurses licensing Symbol versioning in ncurses The MinGW port of ncurses tack – terminfo action checker tar versus portability tctest – termcap library checker Terminal Database Other resources The distribution provides a newer version of the terminfo-format terminal description file once maintained by Eric Raymond . Unlike the older version, the termcap and terminfo data are provided in the same file, and provides several user-definable extensions beyond the X/Open specification. You can find lots of information on terminal-related topics not covered in the terminfo file at Richard Shuford's archive . Overview Release Notes Library improvements Output buffering Symbol versioning Miscellaneous Program improvements Utilities Examples Terminal database Documentation Interesting bug-fixes Configuration changes Major changes Configuration options Portability MinGW Other ports Features of ncurses Applications using ncurses Development activities Related resources Other resources Return to GNU's home page. Please send FSF & GNU inquiries & questions to gnu@gnu.org. There are also other ways to contact the FSF. Please send comments on these web pages to webmasters@www.gnu.org, send other questions to gnu@gnu.org. Copyright © 1998,2000,2004,2005,2006,2008,2011,2015 Free Software Foundation, Inc., 51 Franklin Street, Boston, MA 02110-1301, USA Verbatim copying and distribution of this entire article is permitted in any medium, provided this notice is preserved. Updated: $Date: 2015/08/10 10:56:30 $ $Author: dickey $"	"null"	"null"	"Coloured terminal UI library. or later."	"true"
"Utilities"	"nope.c"	"https://github.com/riolet/WAFer"	"A C-language-based, ultra-light software platform for scalable server-side and networking applications (think node.js for C programmers). only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"614"	"55"	"59"	"GitHub - riolet/WAFer: WAFer is a C language-based software platform for scalable server-side and networking applications. Think node.js for C programmers. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 55 Star 614 Fork 59 riolet/WAFer Code Issues 20 Pull requests 1 Pulse Graphs WAFer is a C language-based software platform for scalable server-side and networking applications. Think node.js for C programmers. 140 commits 1 branch 1 release Fetching contributors C 92.3% C++ 5.5% Makefile 2.1% Shell 0.1% C C++ Makefile Shell Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show v0.0.4-alpha Nothing to show New pull request Latest commit 45a4b19 Jun 26, 2016 rrezel Fix segfault bug Permalink Failed to load latest commit information. .gitignore First Draft Jul 8, 2014 .travis.yml Enabling travis Aug 12, 2014 LICENSE Initial commit Jul 8, 2014 Makefile Updating Readme Jan 9, 2016 README.md Pointing travis to the right place Jan 9, 2016 example.c Updating Readme Jan 10, 2016 run.sh Fixes after Valgrind Jul 24, 2014 server.c Updating Readme Jan 10, 2016 wafer.c Fix segfault bug Jun 26, 2016 wafer.h Fix segfault bug Jun 27, 2016 waferapi.c Fix segfault bug Jun 27, 2016 waferapi.h Updating Readme Jan 10, 2016 README.md WAFer WAFer is a C language-based ultra-light scalable server-side web applications framework. Think node.js for C programmers. Because it's written in C for the C eco system, WAFer is wafer-thins with a memory footprint that is only a fraction of that of node.js and other bulky frameworks. Just copy server.c (say, as myserver.c), put your code inside the function void server(Request request) in myserver.c and, make with make SERVER=myserver, and you are good to go. WAFer can operate in many different configurations, all selected at compile time. They include: Single-threaded (Default) or multi-threaded (make with THREADS=n where n>0) Select(Default) or epoll (make with LOOP=epoll) based event loop C10K mode (make with LOOP=epoll MAX_CON_CONS=n where n>10,000) Default port is 4242. Set environment variable 'PORT' to change it. That's really it. The source comes with a simple example example.c to get you started. Note to Contributors Thank you for making this a wonderful project! Here's our preferred formatting style: find . \( -name '*.c' -o -name '*.h' \) -exec indent --no-tabs --linux-style --line-length 90 --indent-level 4 -bli0 \{\} \; Acknowledgements J. David Blackstone and Feng Shen, whose web servers have been repurposed to build this platform. Mark Karpeles for the incredible number of bug fixes! Fine folks at /r/programming for the honest and constructive feedback. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/riolet/WAFer"	"A C-language-based, ultra-light software platform for scalable server-side and networking applications (think node.js for C programmers). only."	"true"
"Utilities"	"pbc"	"https://github.com/cloudwu/pbc"	"A protocol buffers library.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"730"	"114"	"309"	"GitHub - cloudwu/pbc: A protocol buffers library for C Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 114 Star 730 Fork 309 cloudwu/pbc Code Issues 18 Pull requests 2 Pulse Graphs A protocol buffers library for C 197 commits 1 branch 0 releases Fetching contributors C 75.7% Lua 14.4% Protocol Buffer 8.9% Makefile 1.0% C Lua Protocol Buffer Makefile Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Latest commit b8969a8 May 31, 2016 cloudwu Merge pull request #78 from CheyiLin/master … assemble LuaJIT's executable name automatically Permalink Failed to load latest commit information. binding change global to table field Jan 27, 2016 pbc.xcodeproj remove userdata and update gitignore Mar 23, 2016 pbc ios编译不过 Jul 23, 2013 src bugfix, see #73 Mar 22, 2016 test lua 5.3 binding Jan 22, 2015 tool i -> idx Jun 11, 2015 .gitignore remove userdata and update gitignore Mar 23, 2016 .travis.yml assemble LuaJIT's executable name automatically May 31, 2016 Android.mk commit pbc andorid.mk Jul 30, 2013 Makefile lua 5.3 binding Jan 22, 2015 README.md [ci skip] update Travis CI status badge for upstream repo May 22, 2015 license.txt change src directory and add license Dec 1, 2011 pbc.h 修复VC下pbc默认编译成c++符号表而导致的链接问题 Jun 24, 2015 pbc.sln Create VS2012 project Jul 18, 2013 pbc.vcxproj LNK4006 Jul 19, 2013 pbc.vcxproj.filters replace typename to type_name, conflict with C++ keyword Jul 18, 2013 README.md PBC PBC is a google protocol buffers library for C without code generation. Quick Example package tutorial;  message Person {   required string name = 1;   required int32 id = 2;        // Unique ID number for this person.   optional string email = 3;    enum PhoneType {     MOBILE = 0;     HOME = 1;     WORK = 2;   }    message PhoneNumber {     required string number = 1;     optional PhoneType type = 2 [default = HOME];   }    repeated PhoneNumber phone = 4; }  struct pbc_rmessage * m = pbc_rmessage_new(env, ""tutorial.Person"", slice); printf(""name = %s\n"", pbc_rmessage_string(m , ""name"" , 0 , NULL)); printf(""id = %d\n"", pbc_rmessage_integer(m , ""id"" , 0 , NULL)); printf(""email = %s\n"", pbc_rmessage_string(m , ""email"" , 0 , NULL));  int phone_n = pbc_rmessage_size(m, ""phone""); int i;  for (i=0;i<phone_n;i++) {     struct pbc_rmessage * p = pbc_rmessage_message(m , ""phone"", i);     printf(""\tnumber[%d] = %s\n"",i,pbc_rmessage_string(p , ""number"", i ,NULL));     printf(""\ttype[%d] = %s\n"",i,pbc_rmessage_string(p, ""type"", i, NULL)); }  pbc_rmessage_delete(m); Message API You can use wmessage for encoding , and rmessage for decoding. See test/addressbook.c for details. Pattern API If you need better performance , you can use pbc_pattern_xxx api . See test/pattern.c for details. Pattern api is faster and less memory used because it can access data in native C struct. Extension PBC support extension in a very simple way . PBC add a specific prefix to every extension field name. Service Not supported Enum With message API , you can use both string and integer as enum type . They must be integer in Pattern API. Lua bindings cd bindings/lua && make See https://github.com/cloudwu/pbc/tree/master/binding/lua/README.md Question ? Send me email : http://www.codingnow.com/2000/gmail.gif My Blog : http://blog.codingnow.com Design : http://blog.codingnow.com/2011/12/protocol_buffers_for_c.html (in Chinese) Build for Visual Studio 2012 : https://github.com/miaodadao/pbc Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/cloudwu/pbc"	"A protocol buffers library.."	"true"
"Utilities"	"rabbitmq-c"	"https://github.com/alanxz/rabbitmq-c"	"A client library for.."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"514"	"98"	"300"	"GitHub - alanxz/rabbitmq-c: RabbitMQ C client Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 98 Star 514 Fork 300 alanxz/rabbitmq-c forked from rabbitmq/rabbitmq-c Code Issues 24 Pull requests 5 Pulse Graphs RabbitMQ C client 800 commits 12 branches 17 releases 46 contributors C 82.6% CMake 6.5% Python 5.5% M4 3.4% Makefile 1.8% Shell 0.2% C CMake Python M4 Makefile Shell Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags ci consumer_cancel_example coverity_scan double_ack_example gh-pages ios2 master release_080 rmq2 scan-build ver_bump win32_warn Nothing to show v0.8.0 v0.7.1 v0.7.0 v0.6.0 v0.5.2 v0.5.1 v0.5.0 v0.4.1 v0.4.0 v0.4.0-test v0.3.0 v0.2 v0.1 rabbitmq-c-v0.3.0 librabbitmq-0.1-amqp_0_9_1 librabbitmq-0.1-amqp_0_8 0.2 Nothing to show New pull request Pull request Compare This branch is 515 commits ahead, 2 commits behind rabbitmq:master. Latest commit edaccdd Apr 21, 2016 jstefanski committed with alanxz Add NORETURN macro for MSVC Permalink Failed to load latest commit information. cmake CMake: Remove install_pdb macro. Apr 9, 2016 codegen @ 0a95a69 Initial connection.blocked/unblocked support Dec 15, 2013 coverity Coverity: update model to include more abort funcs Dec 25, 2015 docs Document public API Aug 13, 2013 examples Fix: small warning fixes. Apr 9, 2016 librabbitmq Add NORETURN macro for MSVC Apr 21, 2016 m4 Lib: remove unmaintained SSL backends Oct 13, 2015 tests Fix: small warning fixes. Apr 10, 2016 tools Squash warnings about static initializers in tools. May 3, 2015 .clang-format Add clang-format configuration file. Jul 20, 2014 .gitattributes Adding .gitattributes Oct 24, 2012 .gitignore Adding build/ in .gitignore Dec 12, 2015 .gitmodules Use https for codegen submodule URI protocol Jan 15, 2013 .travis.yml CI: add clang-analyzer build on travis. Jan 13, 2016 .ycm_extra_conf.py ycm: add -std=gnu90 -DHAVE_POLL flags to ycm config. Jun 1, 2015 AUTHORS Fix remaining mentions of the defunct tonyg@rabbitmq.com address Mar 2, 2011 CMakeLists.txt Bumping revision for development. Apr 10, 2016 CONTRIBUTING.md Adding a CONTRIBUTING.md document Nov 7, 2012 ChangeLog.md Preparation for v0.8.0 release. Apr 9, 2016 LICENSE-MIT Updating license year Apr 8, 2013 Makefile.am Lib: Add robust OpenSSL hostname validation. Nov 8, 2015 README.md Preparation for v0.8.0 release. Apr 10, 2016 THANKS Credit recent contributors Feb 7, 2011 TODO Remove note about amqp_pool_alloc. Apr 16, 2010 appveyor.yml CI: bump OpenSSL version to 1.0.2g. Mar 7, 2016 configure.ac Bumping revision for development. Apr 11, 2016 librabbitmq.pc.in CMake: correct generation of librabbitmq.pc Aug 20, 2013 travis.sh CI: add clang-analyzer build on travis. Jan 13, 2016 README.md RabbitMQ C AMQP client library Introduction This is a C-language AMQP client library for use with v2.0+ of the RabbitMQ broker. http://github.com/alanxz/rabbitmq-c Announcements regarding the library are periodically made on the rabbitmq-users mailing list: https://groups.google.com/forum/#!forum/rabbitmq-users Latest Stable Version The latest stable release of rabbitmq-c can be found at: https://github.com/alanxz/rabbitmq-c/releases/latest Documentation API documentation for v0.8.0+ can viewed from: http://alanxz.github.io/rabbitmq-c/docs/0.8.0/ Getting started Building and installing Prereqs: CMake v2.6 or better A C compiler (GCC 4.4+, clang, and MSVC are test. Other compilers may also work) Optionally OpenSSL v0.9.8+ to enable support for connecting to RabbitMQ over SSL/TLS Optionally POpt to build some handy command-line tools. Optionally XmlTo to build man pages for the handy command-line tools Optionally Doxygen to build developer API documentation. After downloading and extracting the source from a tarball to a directory. ([see above][Latest Stable Version]), the commands to build rabbitmq-c on most systems are: mkdir build && cd build cmake .. cmake --build [--config Release] .  The --config Release flag should be used in multi-configuration generators e.g., Visual Studio or XCode. It is also possible to point the CMake GUI tool at the CMakeLists.txt in the root of the source tree and generate build projects or IDE workspace Installing the library and optionally specifying a prefix can be done with: cmake -DCMAKE_INSTALL_PREFIX=/usr/local .. cmake --build . [--config Release] --target install  More information on CMake can be found on its FAQ (http://www.cmake.org/Wiki/CMake_FAQ) Other interesting flags that can be passed to CMake: BUILD_EXAMPLES=ON/OFF toggles building the examples. ON by default. BUILD_SHARED_LIBS=ON/OFF toggles building rabbitmq-c as a shared library. ON by default. BUILD_STATIC_LIBS=ON/OFF toggles building rabbitmq-c as a static library. OFF by default. BUILD_TESTS=ON/OFF toggles building test code. ON by default. BUILD_TOOLS=ON/OFF toggles building the command line tools. By default this is ON if the build system can find the POpt header and library. BUILD_TOOLS_DOCS=ON/OFF toggles building the man pages for the command line tools. By default this is ON if BUILD_TOOLS is ON and the build system can find the XmlTo utility. ENABLE_SSL_SUPPORT=ON/OFF toggles building rabbitmq-c with SSL support. By default this is ON if the OpenSSL headers and library can be found. ENABLE_THREAD_SAFETY=ON/OFF toggles OpenSSL thread-safety. By default this is ON BUILD_API_DOCS=ON/OFF - toggles building the Doxygen API documentation, by default this is OFF autotools For legacy purposes, a GNU autotools based build system is also maintained. The required utilities you need are autoconf v2.59+, automake v1.9+, libtool v2.2+, and pkg-config. Then the standard autotools build procedure will build rabbitmq-c: autoreconf -i ./configure make make install  Running the examples Arrange for a RabbitMQ or other AMQP server to be running on localhost at TCP port number 5672. In one terminal, run ./examples/amqp_listen localhost 5672 amq.direct test  In another terminal, ./examples/amqp_sendstring localhost 5672 amq.direct test ""hello world""  You should see output similar to the following in the listener's terminal window: Delivery 1, exchange amq.direct routingkey test Content-type: text/plain ---- 00000000: 68 65 6C 6C 6F 20 77 6F : 72 6C 64                 hello world 0000000B:  Writing applications using librabbitmq Please see the examples directory for short examples of the use of the librabbitmq library. Threading You cannot share a socket, an amqp_connection_state_t, or a channel between threads using librabbitmq. The librabbitmq library is built with event-driven, single-threaded applications in mind, and does not yet cater to any of the requirements of pthreaded applications. Your applications instead should open an AMQP connection (and an associated socket, of course) per thread. If your program needs to access an AMQP connection or any of its channels from more than one thread, it is entirely responsible for designing and implementing an appropriate locking scheme. It will generally be much simpler to have a connection exclusive to each thread that needs AMQP service. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/alanxz/rabbitmq-c"	"A client library for.."	"true"
"Utilities"	"RabbitMQ"	"http://www.rabbitmq.com/"	"A client library for.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"47"	"24"	"57"	"GitHub - rabbitmq/rabbitmq-website: Source files for www.rabbitmq.com Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 24 Star 47 Fork 57 rabbitmq/rabbitmq-website Code Issues 11 Pull requests 1 Pulse Graphs Source files for www.rabbitmq.com 962 commits 72 branches 31 releases Fetching contributors JavaScript 83.1% PHP 5.4% HTML 4.6% XSLT 3.6% CSS 2.2% Python 0.7% Other 0.4% JavaScript PHP HTML XSLT CSS Python Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags 3.6.3-release elixir-tutorial-fixups-1 fix-objc-tutorial-4-source-link fix-teaser-reveals live-objc-tutorials live master network-configuration-guide objc-tutorial1-async objc-tutorial2 objc-tutorial3 objc-tutorial4 objc-tutorial5 rabbitmq-auth-backend-ldap-3 rabbitmq-auth-backend-ldap-12 rabbitmq-management-41 rabbitmq-management-63 rabbitmq-management-138 rabbitmq-management-157 rabbitmq-management-221 rabbitmq-mqtt-21 rabbitmq-mqtt-49 rabbitmq-server-20 rabbitmq-server-58 rabbitmq-server-75 rabbitmq-server-121 rabbitmq-server-207 rabbitmq-server-210 rabbitmq-server-250 rabbitmq-server-336 rabbitmq-server-351 rabbitmq-server-369 rabbitmq-server-453 rabbitmq-server-460 rabbitmq-server-461 rabbitmq-server-528 rabbitmq-server-546 rabbitmq-server-550 rabbitmq-server-591 rabbitmq-shovel-2 rabbitmq-stomp-43 rabbitmq-web-stomp-4 rabbitmq-web-stomp-17 rabbitmq-web-stomp-19 rabbitmq-web-stomp-22 rabbitmq-web-stomp-43 rabbitmq-website-15 rabbitmq-website-26 rabbitmq-website-37 rabbitmq-website-39 rabbitmq-website-43 rabbitmq-website-47 rabbitmq-website-49 rabbitmq-website-50 rabbitmq-website-54 rabbitmq-website-57 rabbitmq-website-58 rabbitmq-website-65 rabbitmq-website-68 rabbitmq-website-79 rabbitmq-website-84 rabbitmq-website-128 rabbitmq-website-131 rabbitmq-website-158 rabbitmq-website-173 rabbitmq-website-185 rabbitmq-website-192 rabbitmq-website-206 rabbitmq-website-221 rabbitmq-website-224 stable stage Nothing to show rabbitmq_v3_7_0_milestone5 rabbitmq_v3_7_0_milestone4 rabbitmq_v3_7_0_milestone3 rabbitmq_v3_7_0_milestone2 rabbitmq_v3_7_0_milestone1 rabbitmq_v3_6_3 rabbitmq_v3_6_3_rc3 rabbitmq_v3_6_3_rc2 rabbitmq_v3_6_3_rc1 rabbitmq_v3_6_3_milestone2 rabbitmq_v3_6_3_milestone1 rabbitmq_v3_6_2 rabbitmq_v3_6_2_rc4 rabbitmq_v3_6_2_rc3 rabbitmq_v3_6_2_rc2 rabbitmq_v3_6_2_rc1 rabbitmq_v3_6_2_milestone5 rabbitmq_v3_6_2_milestone4 rabbitmq_v3_6_2_milestone3 rabbitmq_v3_6_2_milestone2 rabbitmq_v3_6_2_milestone1 rabbitmq_v3_6_1 rabbitmq_v3_6_1_rc2 rabbitmq_v3_6_1_rc1 rabbitmq_v3_6_0 rabbitmq_v3_6_0_rc3 rabbitmq_v3_6_0_rc2 rabbitmq_v3_6_0_rc1 rabbitmq_v3_6_0_milestone3 rabbitmq_v3_6_0_milestone2 rabbitmq_v3_5_7 Nothing to show New pull request Latest commit b2a9909 Jul 9, 2016 michaelklishin Merge branch 'stable' Permalink Failed to load latest commit information. code Initial commit for the `live` branch May 22, 2015 conf conf/www.rabbitmq.com-common: Update rabbit-web-stage domain name Jul 6, 2016 graphics-src Initial commit for the `live` branch May 22, 2015 site Merge branch 'stable' Jul 9, 2016 wordpress-theme Initial commit for the `live` branch May 22, 2015 .gitignore Ignore the generated news.atom feed Dec 9, 2015 CODE_OF_CONDUCT.md Update CONTRIBUTING.md, add CODE_OF_CONDUCT.md May 28, 2016 CONTRIBUTING.md Update CONTRIBUTING.md, add CODE_OF_CONDUCT.md May 28, 2016 LICENSE Initial commit for the `live` branch May 22, 2015 NOTICE Update (c) info Jan 1, 2016 README.md List the stable branch Dec 21, 2015 deploy Initial commit for the `live` branch May 22, 2015 driver.py Initial commit for the `live` branch May 22, 2015 link-local-manpages Initial commit for the `live` branch May 22, 2015 README.md rabbitmq.com This repository contains source code for rabbitmq.com content. Branches There are a few noteworthy and long-lived named branches in this repository: Branch Description live The current version of the website. This must represent whatever's deployed to www.rabbitmq.com. stable Changes to the website that will correspond to the next point (maintenance) release of RabbitMQ. This gets merged into live when the release occurs. master Changes to the website that will correspond to the next release of RabbitMQ. This gets merged into live when the release occurs. Normally this should represent whatever's deployed to next.rabbitmq.com. stage The staging version of the website. Only relevant while a release is being prepared, it acts to snapshot master in case changes are made to that during the release process. Development environment Running a Local Copy The site requires Python and Python XSLT support for development, and assumes Apache is used for deployment. For simple development on Debian-based systems, it is enough to run sudo apt-get install python-lxml python-markdown python-pygments to install required dependencies and then ./driver.py [www|next|previous] from the base of the repository to run a local version of the site, with page regeneration on reload. The site will be available at http://localhost:8191. Note that using driver.py the site will not feature: Any release artefacts (this includes the web versions of the man pages) The blog The script diagrams.py generates PNGs from graph descriptions embedded in files. Generally you don't need to run this, since we check the PNGs in, but if you do want to use it, you'll also need dot: sudo apt-get install graphviz If you want the site/news.atom feed generated, you can run the following command: xsltproc --novalid site/feed-atom.xsl site/news.xml > site/news.atom On OS X Using Homebrew, you can install the necessary parts with: brew install python pip install lxml markdown Using the system Python, you can install the necessary parts with: sudo easy_install pip sudo pip install lxml markdown Modes The website also has the concept of being deployed in modes. The three modes are: Mode Description www This is the ""normal"" mode. You would normally deploy from the live branch with this mode. next This is the mode for next.rabbitmq.com. This mode has the home page and download page chopped down, no blog or search, and a watermark. You would normally deploy from the master branch with this mode. previous For previous.rabbitmq.com. The website is reduced in the same way as ""next"", but this mode is meant for previous releases rather than future releases. You determine which mode you are using with an argument to the driver or deploy scripts. Modes are implemented with the <x:modal/> tag and the $page-mode variable in XSLT. Copyright and License See NOTICE and LICENSE. Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/rabbitmq/rabbitmq-website"	"A client library for.."	"true"
"Utilities"	"Ragel"	"http://www.colm.net/open-source/ragel/"	"A DSL for state machines that compiles to C. only."	"null"	"null"	"null"	"GNU GPL2.1"	"http://www.gnu.org/licenses/old-licenses/gpl-2.0.html"	"null"	"null"	"null"	"null"	"null"	"Ragel State Machine Compiler Colm Networks Computer Language Machinery About News Ragel Colm Ragel State Machine Compiler Ragel compiles executable finite state machines from regular languages. Ragel targets C, C++, Obj-C, C#, D, Java, Go and Ruby. Ragel state machines can not only recognize byte sequences as regular expression machines do, but can also execute code at arbitrary points in the recognition of a regular language. Code embedding is done using inline operators that do not disrupt the regular language syntax. The core language consists of standard regular expression operators (such as union, concatenation and Kleene star) and action embedding operators. The user’s regular expressions are compiled to a deterministic state machine and the embedded actions are associated with the transitions of the machine. Understanding the formal relationship between regular expressions and deterministic finite automata is key to using Ragel effectively. Ragel also provides operators that let you control any non-determinism that you create, construct scanners, and build state machines using a statechart model. It is also possible to influence the execution of a state machine from inside an embedded action by jumping or calling to other parts of the machine, or reprocessing input. Ragel provides a very flexible interface to the host language that attempts to place minimal restrictions on how the generated code is integrated into the application. The generated code has no dependencies. Ragel code looks like: action dgt      { printf(""DGT: %c\n"", fc); } action dec      { printf(""DEC: .\n""); } action exp      { printf(""EXP: %c\n"", fc); } action exp_sign { printf(""SGN: %c\n"", fc); } action number   { /*NUMBER*/ }  number = (     [0-9]+ $dgt ( '.' @dec [0-9]+ $dgt )?     ( [eE] ( [+\-] $exp_sign )? [0-9]+ $exp )? ) %number;  main := ( number '\n' )*;  .. and it compiles to: st0:     if ( ++p == pe )         goto out0;     if ( 48 <= (*p) && (*p) <= 57 )         goto tr0;     goto st_err; tr0:     { printf(""DGT: %c\n"", (*p)); } st1:     if ( ++p == pe )         goto out1;     switch ( (*p) ) {         case 10: goto tr5;         case 46: goto tr7;         case 69: goto st4;         case 101: goto st4;     }     if ( 48 <= (*p) && (*p) <= 57 )         goto tr0;     goto st_err;  … and it visualizes as: What kind of task is Ragel good for? Writing robust protocol implementations. Parsing data formats. Lexical analysis of programming languages. Validating user input. Features Construct finite state machines using: regular language operators state chart operators a scanner operator some mix of the above Embed actions into machines in arbitrary places. Control non-determinism using guarded operators. Minimize state machines using Hopcroft’s algorithm. Visualize output with Graphviz. Use byte, double byte or word-sized alphabets. Generate C, C++, Obj-C, C#, D, Java, Go or Ruby code with no dependencies. Choose from table or control flow driven state machines. Download Stable October 14, 2014 ragel-6.9.tar.gz (sig) (key) ragel-guide-6.9.pdf Development July 11, 2016 ragel-7.0.0.7.tar.gz (news item) License Ragel is released under the GNU General Public License, Version 2. A copy of the license is included in the distribution. It is also available from GNU. Note: Parts of Ragel output are copied from Ragel source covered by the GNU GPL. As a special exception to the GPL, you may use the parts of Ragel output copied from Ragel source without restriction. The remainder of Ragel output is derived from the input and inherits the copyright status of the input file. Use of Ragel makes no requirements about the license of generated code. Colm Networks Colm Networks info@colm.net ehdtee"	"null"	"null"	"A DSL for state machines that compiles to C. only."	"true"
"Utilities"	"uthash"	"http://troydhanson.github.io/uthash/"	"A hash table implementation, allowing existing structures to be stored in a hash table easily."	"null"	"null"	"null"	"1-clause BSD"	"http://troydhanson.github.io/uthash/license.html"	"null"	"null"	"781"	"77"	"222"	"GitHub - troydhanson/uthash: C macros for hash tables and more Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 77 Star 781 Fork 222 troydhanson/uthash Code Issues 1 Pull requests 5 Pulse Graphs C macros for hash tables and more 247 commits 2 branches 5 releases 19 contributors C 94.5% C++ 1.7% Makefile 1.5% Perl 1.0% Objective-C 0.7% Shell 0.4% Batchfile 0.2% C C++ Makefile Perl Objective-C Shell Batchfile Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags gh-pages master Nothing to show v2.0.1 v2.0.0 v1.9.9.1 v1.9.9 v1.9.8 Nothing to show New pull request Latest commit 1485401 Jul 14, 2016 Quuxplusone Fix some pedantic warnings in tests/threads/. … No functional change. Permalink Failed to load latest commit information. doc Remove trailing spaces from the docs. Jul 14, 2016 libut Patch Makefiles to honor CPPFLAGS May 7, 2016 src Hooks to replace memcmp and strlen on freestanding implementations. Jul 14, 2016 tests Fix some pedantic warnings in tests/threads/. Jul 14, 2016 .gitignore Squashed commit of the following: Jun 28, 2016 LICENSE consolidate changelog for 1.9.9 and 2014 bump Feb 25, 2014 README.md tweak Jan 7, 2013 include reorg Aug 26, 2015 package.json Bump version to 2.0.1 to justify a release tag. Jul 5, 2016 README.md Documentation for uthash is available at: http://troydhanson.github.com/uthash/ Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/troydhanson/uthash"	"A hash table implementation, allowing existing structures to be stored in a hash table easily."	"true"
"Utilities"	"Viola"	"https://github.com/eatonphil/Viola"	"A simplification of libCello.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"33"	"3"	"2"	"GitHub - eatonphil/Viola: Taking the load off libCello. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 3 Star 33 Fork 2 eatonphil/Viola Code Issues 0 Pull requests 0 Pulse Graphs Taking the load off libCello. 30 commits 1 branch 0 releases Fetching contributors Verilog 34.4% Shell 28.2% C 26.5% Coq 10.9% Verilog Shell C Coq Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags master Nothing to show Nothing to show New pull request Latest commit cec1453 Jan 15, 2015 Phil Added Symbol constructor for Array(Char) Permalink Failed to load latest commit information. examples Added Symbol constructor for Array(Char) Jan 15, 2015 include Added Symbol constructor for Array(Char) Jan 15, 2015 LICENSE.md Added license Dec 29, 2014 README.md Added Symbol constructor for Array(Char) Jan 15, 2015 viola Added support for auto freeing variables Jan 14, 2015 README.md Viola Taking the load off libCello - a work in progress. Introduction I saw https://github.com/orangeduck/libCello after it hit the top of Hackernews. It seemed like there were a number of ways to make this even more beginner friendly. I think there is a lot of potential for this library to be a standalone tool used for teaching beginning programmers and slowly weaning them towards manual memory management via a lite syntax. Viola depends on libCello to provide the backbone. The more interesting parts of Viola revolve around very simple (completely context-free) string replacements and a somewhat simpler/more-friendly API that sits on top of libCello. Furthermore, Viola is intended more as a ""standalone"" language for teaching. Viola also extends libCello by adding support for smart pointers, thanks to snaipe's work and blog post on smart pointers in C. I haven't really had time to make documentation, but I wrote a number of examples in examples/ to demonstrate some of the cooler features in Viola. This is obviously a work in progress. Please feel free to make any suggestions or give any guidance! Setup Make and install (make install) libCello or add references (-I, -L) to the GCC_BUILD variable in ./viola. Add this directory to your path to access viola. Example example.v var a = Int(1), b = Int(2), c = Int(3) let myList = Ints(Int(1), Int(2), Int(3)); // Now automatically freed.  foreach (element in myList) {     print(""%$\n"", element) }  Compile (and Run) viola example.v  Note The built .c and binary files are stored in build/. More Check out examples/ for more. Features Semi-optional semi-colons Any expression ending in a right parenthesis can optionally omit an ending semi-colon: var i = $(Int, 3); // needs semi-colon because line ends with comment not ) show(i) int f = 3; // must have semi-colon // doesn't need semi-colon int g = (4)  Abbreviated access to creating objects // $(Int, 2) var i = Int(2) // $(String, ""foo"") and so on var s = String(""foo"") // Also works for lists of objects, heap memory is allocated here though var l = List(Int(2), Int(4)) delete(l); // so don't forget to deallocate the memory.  Smart pointers declaring pointers using ""let"" instead of ""var"" allows auto-cleanup once the variable leaves scope: // Without auto cleanup var list = List(Int(2), Int(3)) delete(list); // Must free manually  // With auto cleanup let list = List(Int(2), Int(4))  Idea came from http://snaipe.me/c/c-smart-pointers/ Symbols Another type that treats strings as character arrays. These arrays are stored with libCello arrays so you can iterate over them with foreach: var s = Symbol(""this is my char array"") foreach(c in s) {     print(""%s\n"", c) }  Functions ""function"" is just a mask for ""var"", but it is also used to simplify passing functions: function add(var a, var b) {return sum(a, b)} function addRenamed(var, var) = add; // same as ""function (*addRenamed)(var, var) = add;"" var res = addRenamed(Int(2), Int(3)) show(res)  functions can be nested Namespacing Namespaces can be declared and all members must be declared at the time too. namespace std ( function (*_print)(var) )  function _print(var object) { show(object); } // needs semi-colon because the line does not end with ) std._print = _print;  std._print(Int(9))  Import Viola files can be imported import ""local_file.v"" // contains the above std namespace  std._print(String(""I can import and use namespaces!""))  Keywords, Restricted Functions The following keywords cannot be used as identifiers (in addition to any C keywords): var, is, isnt, not, and, or, elif, in local, global, class, data, instance foreach, with, try, throw, catch $, lit Due to the macro implementation of global functions in libCello, the following functions CANNOT be reused in any form in Viola (or libCello) files - this includes using these names as members in a namespace, struct, etc: (these are just a sample of the more obvious ones to remember) print new construct Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/eatonphil/Viola"	"A simplification of libCello.."	"true"
"Utilities"	"zlib"	"https://github.com/madler/zlib"	"A massively-spiffy yet delicately-unobtrusive compression library.."	"null"	"null"	"null"	"3-clause BSD"	"http://directory.fsf.org/wiki/License:BSD_3Clause"	"null"	"null"	"606"	"89"	"410"	"GitHub - madler/zlib: A massively spiffy yet delicately unobtrusive compression library. Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository Watch 89 Star 606 Fork 410 madler/zlib Code Issues 17 Pull requests 63 Wiki Pulse Graphs A massively spiffy yet delicately unobtrusive compression library. http://zlib.net/ 312 commits 2 branches 69 releases 17 contributors C 67.3% Assembly 9.4% C++ 8.2% Ada 5.9% C# 3.7% Component Pascal 2.8% Other 2.7% C Assembly C++ Ada C# Component Pascal Other Clone or download Use SSH Clone with HTTPS Use Git or checkout with SVN using the web URL. Use HTTPS Clone with SSH Use an SSH key and passphrase from account. Open in Desktop Download ZIP Find file Branch: master Switch branches/tags Branches Tags develop master Nothing to show v1.2.8 v1.2.7.3 v1.2.7.2 v1.2.7.1 v1.2.7 v1.2.6.1 v1.2.6 v1.2.5.3 v1.2.5.2 v1.2.5.1 v1.2.5 v1.2.4.5 v1.2.4.4 v1.2.4.3 v1.2.4.2 v1.2.4.1 v1.2.4 v1.2.4-pre2 v1.2.4-pre1 v1.2.3.9 v1.2.3.8 v1.2.3.7 v1.2.3.6 v1.2.3.5 v1.2.3.4 v1.2.3.3 v1.2.3.2 v1.2.3.1 v1.2.3 v1.2.2.4 v1.2.2.3 v1.2.2.2 v1.2.2.1 v1.2.2 v1.2.1.2 v1.2.1.1 v1.2.1 v1.2.0.8 v1.2.0.7 v1.2.0.6 v1.2.0.5 v1.2.0.4 v1.2.0.3 v1.2.0.2 v1.2.0.1 v1.2.0 v1.1.4 v1.1.3 v1.1.2 v1.1.1 v1.1.0 v1.0.9 v1.0.8 v1.0.7 v1.0.5 v1.0.4 v1.0.2 v1.0.1 v1.0-pre v0.99 v0.95 v0.94 v0.93 v0.92 v0.91 v0.79 v0.71 v0.9 v0.8 Nothing to show New pull request Latest commit 5089329 Apr 28, 2013 madler zlib 1.2.8 Permalink Failed to load latest commit information. amiga zlib 1.2.3.9 Sep 9, 2011 as400 Change version number to 1.2.8. Apr 28, 2013 contrib Fix mixed line endings in contrib/vstudio. Apr 28, 2013 doc zlib 1.2.5.1 Sep 11, 2011 examples Check for input buffer malloc failure in examples/gzappend.c. Oct 11, 2012 msdos Move example.c and minigzip.c to test/. Nov 27, 2011 nintendods zlib 1.2.3.5 Sep 9, 2011 old Move obsolete emx makefile to old [Truta]. Mar 12, 2012 qnx Change version number to 1.2.8. Apr 28, 2013 test Clean up the usage of z_const and respect const usage within zlib. Aug 13, 2012 watcom zlib 1.2.3.9 Sep 10, 2011 win32 Update some copyright years. Apr 28, 2013 .gitignore zlib 1.2.7.1 Mar 24, 2013 CMakeLists.txt Change version number to 1.2.8. Apr 28, 2013 ChangeLog zlib 1.2.8 Apr 28, 2013 FAQ Move example.c and minigzip.c to test/. Nov 27, 2011 INDEX Generate and install the pkg-config file with cmake. Mar 11, 2012 Makefile zlib 1.2.4-pre2 Sep 9, 2011 Makefile.in Update some copyright years. Apr 28, 2013 README Change version number to 1.2.8. Apr 28, 2013 adler32.c zlib 1.2.5.1 Sep 11, 2011 compress.c Clean up the usage of z_const and respect const usage within zlib. Aug 13, 2012 configure Remove runtime check in configure for four-byte integer type. Mar 23, 2013 crc32.c Fix type mismatch between get_crc_table() and crc_table. Apr 29, 2012 crc32.h Fix type mismatch between get_crc_table() and crc_table. Apr 29, 2012 deflate.c Change version number to 1.2.8. Apr 28, 2013 deflate.h Correct comment in deflate.h. Jun 2, 2012 gzclose.c zlib 1.2.3.9 Sep 10, 2011 gzguts.h Add casts in gzwrite.c for pointer differences. Apr 13, 2013 gzlib.c zlib 1.2.7.1 Mar 25, 2013 gzread.c zlib 1.2.7.1 Mar 25, 2013 gzwrite.c Add casts in gzwrite.c for pointer differences. Apr 14, 2013 infback.c Clean up the usage of z_const and respect const usage within zlib. Aug 13, 2012 inffast.c zlib 1.2.7.1 Mar 25, 2013 inffast.h zlib 1.2.5 Sep 9, 2011 inffixed.h Get inffixed.h and MAKEFIXED result to match. Oct 5, 2011 inflate.c Clean up the usage of z_const and respect const usage within zlib. Aug 13, 2012 inflate.h zlib 1.2.3.5 Sep 10, 2011 inftrees.c Change version number to 1.2.8. Apr 28, 2013 inftrees.h zlib 1.2.5 Sep 10, 2011 make_vms.com Add ability to choose the builder in make_vms.com [Schweda]. Mar 9, 2012 treebuild.xml Change version number to 1.2.8. Apr 28, 2013 trees.c Clean up the usage of z_const and respect const usage within zlib. Aug 13, 2012 trees.h zlib 1.2.4.5 Sep 9, 2011 uncompr.c Clean up the usage of z_const and respect const usage within zlib. Aug 13, 2012 zconf.h Do not force Z_CONST for C++. Apr 28, 2013 zconf.h.cmakein Do not force Z_CONST for C++. Apr 28, 2013 zconf.h.in Do not force Z_CONST for C++. Apr 28, 2013 zlib.3 zlib 1.2.8 Apr 29, 2013 zlib.3.pdf zlib 1.2.8 Apr 29, 2013 zlib.h zlib 1.2.8 Apr 29, 2013 zlib.map Clean up the addition of gzvprintf. Mar 23, 2013 zlib.pc.cmakein Generate and install the pkg-config file with cmake. Mar 11, 2012 zlib.pc.in zlib 1.2.4.4 Sep 9, 2011 zlib2ansi zlib 1.2.3.8 Sep 9, 2011 zutil.c Clean up the usage of z_const and respect const usage within zlib. Aug 13, 2012 zutil.h zlib 1.2.7.1 Mar 25, 2013 README ZLIB DATA COMPRESSION LIBRARY  zlib 1.2.8 is a general purpose data compression library.  All the code is thread safe.  The data format used by the zlib library is described by RFCs (Request for Comments) 1950 to 1952 in the files http://tools.ietf.org/html/rfc1950 (zlib format), rfc1951 (deflate format) and rfc1952 (gzip format).  All functions of the compression library are documented in the file zlib.h (volunteer to write man pages welcome, contact zlib@gzip.org).  A usage example of the library is given in the file test/example.c which also tests that the library is working correctly.  Another example is given in the file test/minigzip.c.  The compression library itself is composed of all source files in the root directory.  To compile all files and run the test program, follow the instructions given at the top of Makefile.in.  In short ""./configure; make test"", and if that goes well, ""make install"" should work for most flavors of Unix.  For Windows, use one of the special makefiles in win32/ or contrib/vstudio/ .  For VMS, use make_vms.com.  Questions about zlib should be sent to <zlib@gzip.org>, or to Gilles Vollant <info@winimage.com> for the Windows DLL version.  The zlib home page is http://zlib.net/ .  Before reporting a problem, please check this site to verify that you have the latest version of zlib; otherwise get the latest version and check whether the problem still exists or not.  PLEASE read the zlib FAQ http://zlib.net/zlib_faq.html before asking for help.  Mark Nelson <markn@ieee.org> wrote an article about zlib for the Jan.  1997 issue of Dr.  Dobb's Journal; a copy of the article is available at http://marknelson.us/1997/01/01/zlib-engine/ .  The changes made in version 1.2.8 are documented in the file ChangeLog.  Unsupported third party contributions are provided in directory contrib/ .  zlib is available in Java using the java.util.zip package, documented at http://java.sun.com/developer/technicalArticles/Programming/compression/ .  A Perl interface to zlib written by Paul Marquess <pmqs@cpan.org> is available at CPAN (Comprehensive Perl Archive Network) sites, including http://search.cpan.org/~pmqs/IO-Compress-Zlib/ .  A Python interface to zlib written by A.M. Kuchling <amk@amk.ca> is available in Python 1.5 and later versions, see http://docs.python.org/library/zlib.html .  zlib is built into tcl: http://wiki.tcl.tk/4610 .  An experimental package to read and write files in .zip format, written on top of zlib by Gilles Vollant <info@winimage.com>, is available in the contrib/minizip directory of zlib.   Notes for some targets:  - For Windows DLL versions, please see win32/DLL_FAQ.txt  - For 64-bit Irix, deflate.c must be compiled without any optimization. With   -O, one libpng test fails. The test works in 32 bit mode (with the -n32   compiler flag). The compiler bug has been reported to SGI.  - zlib doesn't work with gcc 2.6.3 on a DEC 3000/300LX under OSF/1 2.1 it works   when compiled with cc.  - On Digital Unix 4.0D (formely OSF/1) on AlphaServer, the cc option -std1 is   necessary to get gzprintf working correctly. This is done by configure.  - zlib doesn't work on HP-UX 9.05 with some versions of /bin/cc. It works with   other compilers. Use ""make test"" to check your compiler.  - gzdopen is not supported on RISCOS or BEOS.  - For PalmOs, see http://palmzlib.sourceforge.net/   Acknowledgments:    The deflate format used by zlib was defined by Phil Katz.  The deflate and   zlib specifications were written by L.  Peter Deutsch.  Thanks to all the   people who reported problems and suggested various improvements in zlib; they   are too numerous to cite here.  Copyright notice:   (C) 1995-2013 Jean-loup Gailly and Mark Adler    This software is provided 'as-is', without any express or implied   warranty.  In no event will the authors be held liable for any damages   arising from the use of this software.    Permission is granted to anyone to use this software for any purpose,   including commercial applications, and to alter it and redistribute it   freely, subject to the following restrictions:    1. The origin of this software must not be misrepresented; you must not      claim that you wrote the original software. If you use this software      in a product, an acknowledgment in the product documentation would be      appreciated but is not required.   2. Altered source versions must be plainly marked as such, and must not be      misrepresented as being the original software.   3. This notice may not be removed or altered from any source distribution.    Jean-loup Gailly        Mark Adler   jloup@gzip.org          madler@alumni.caltech.edu  If you use the zlib library in a product, we would appreciate *not* receiving lengthy legal documents to sign.  The sources are provided for free but without warranty of any kind.  The library has been entirely written by Jean-loup Gailly and Mark Adler; it does not include third-party code.  If you redistribute modified sources, we would appreciate that you include in the file ChangeLog history information documenting your changes.  Please read the FAQ for more information on the distribution of modified source versions.  Contact GitHub API Training Shop Blog About © 2016 GitHub, Inc. Terms Privacy Security Status Help Something went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session."	"null"	"https://github.com/madler/zlib"	"A massively-spiffy yet delicately-unobtrusive compression library.."	"true"
"XML"	"Expat"	"http://www.libexpat.org/"	"A stream-oriented XML parser.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"null"	"null"	"null"	"The Expat XML Parser The Expat XML Parser Expat is an XML parser library written in C. It is a stream-oriented parser in which an application registers handlers for things the parser might find in the XML document (like start tags). An introductory article on using Expat is available on xml.com. Expat project page (includes downloads) Mailing lists 3rd-party wrappers (SAX, DOM, other language bindings) CVS repository (browse online) Bug reports Notes for Expat maintainers This project aims to maintain Expat for both current and future users while improving the API to allow more reliable and robust access from ""scripting"" languages such as Python and Perl. We invite the community to participate on the mailing lists to help shape the future of Expat. News 24 March 2012, Expat 2.1.0 released. Release 2.1.0 includes security & other bug fixes, new features, and updated build support. Security fixes Memory leak in poolGrow (CVE-2012-1148) Resource leak in readfilemap.c (CVE-2012-1147) Hash DOS attack (CVE-2012-0876) Buffer over-read and crash in big2_toUtf8 (CVE-2009-3560) Parser crash with special UTF-8 sequences (CVE-2009-3270) New features Added function XML_SetHashSalt that allows setting an initial value (salt) for hash calculations (part of the fix for bug 3496608). When compiled with XML_ATTR_INFO defined, adds new API member XML_GetAttributeInfo() that allows retrieving the byte offsets for attribute names and values (patch 3446384). Added CMake build system (bug 2990652, patch 3312568). Added run-benchmark target to Makefile.in - relies on testdata module present in the same relative location as in the repository. Bug fixes Harmful XML_ParserCreateNS suggestion (1742315) CVE-2012-1147 - Resource leak in readfilemap.c (2895533) Expat build fails on linux-amd64 with gcc version>=4.1 -O3 (1785430) Build modifications using autoreconf instead of buildconf.sh (1983953, 2517952, 2517962, 2649838) OBJEXT and EXEEXT support while building (2815947, 2884086) CVE-2009-3720 - Parser crash with special UTF-8 sequences (1990430) xmlwf should return non-zero exit status if not well-formed (2517938) Wrong statement about XMLDecl in xmlwf.1 and xmlwf.sgml (2517946) Dangling positionPtr after error (2855609) CVE-2009-3560 - Buffer over-read and crash in big2_toUtf8() (2894085) CVE-2012-1148 - Memory leak in poolGrow (2958794) UNEXPECTED_STATE with a trailing ""%"" in entity value (3010819) Unitialized memory returned from XML_Parse (3206497) make check fails on mingw-w64 (87849) 5 June 2007, Expat 2.0.1 released. Release 2.0.1 of the Expat XML parser is a bugfix release resolving both code and build related issues. Changes include: Fixed: The character data handler's calling of XML_StopParser() was not handled properly; if the parser was stopped and the handler set to NULL, the parser would segfault. Fixed: Expat failed on EBCDIC systems as it assumed some character constants to be ASCII encoded. Minor cleanups of the test harness. Minor fixes for xmlwf and example programs. Fixes and improvements for the Windows platform. New Windows directory structure. Build fixes for various platforms: HP-UX, Tru64, Solaris 9. Build fixes for Unix: - Refreshed config.sub/config.guess. - Support both, DESTDIR and INSTALL_ROOT, without relying on GNU-Make specific features. - Patched configure.in to work better with Intel compiler. - Fixes to Makefile.in to have make check work correctly. Added Open Watcom support. 11 January 2006, Expat 2.0.0 released. Release 2.0.0 of the Expat XML parser is the end point of the 1.95.X series of releases. The goal was to solidify and stabilize the implementation of the given API, to add desirable features as long as they fit with the API, and to keep the API backwards compatible if extensions were required. Changes include: Fixed headers for use from C++. XML_GetCurrentLineNumber() and XML_GetCurrentColumnNumber() now return unsigned integers. Added XML_LARGE_SIZE switch to enable 64-bit integers for byte indexes and line/column numbers. Added support for AmigaOS. Some mostly minor bug fixes. SF issues include: 1006708, 1021776, 1023646, 1114960, 1156398, 1221160, 1271642. Old news archive References & 3rd-party Wrappers If you know of any additional articles or resources which should be linked to from this page, please send email to Fred Drake (fdrake@acm.org). We're especially interested in links to tutorial information and open source interfaces to Expat from languages other than C. James Clark's original Expat page, for Expat 1.2 and earlier Introductory article on using Expat on xml.com LuaExpat is a wrapper around Expat for the Lua programming language. The LuaSOAP library is a SOAP implementation built on top of LuaExpat. Perl's XML::Parser module is a wrapper built around a binding to Expat in the XML::Parser::Expat module. Documentation for the Python interface to Expat, part of the standard documentation for Python. SAXExpat.NET, a .NET wrapper for Expat, conforming to the SAX for .NET specifications. The Simple C Expat Wrapper is a wrapper around Expat that provides a light-weight object model somewhat like a DOM. C++ Wrappers for the Expat XML Parser, an article by Tim Smith providing object-oriented wrappers for Expat. The wrappers use some MFC-biased naming, but look interesting. Arabica -- an XML Parser toolkit for C++ programmers, with SAX2 implementations based on several parsers, including Expat. ExpatMM -- C++ interface to Expat SAX2 Wrapper for using Expat in Delphi, based on ""SAX for Pascal"" interface specs The TclXML project includes a Tcl binding for Expat tDOM is an alternate package providing XML support for Tcl, based in part on Expat. Article on using Expat from PHP on <?PHPBuilder?> (broken into lots of tiny pieces) Objective-C interface to Expat OCaml Expat is a wrapper around Expat for the Objective Caml language. Ruby interface to Expat XML Tools 2 is an AppleScript scripting addition that allows AppleScript applications to work with XML data; it is based on Expat. Simkin is an open source scripting language available under the GNU LGPL. It can be embedded in XML and supports a DOM-like API backed by Expat. EasySoap is a C++ SOAP implementation which uses Expat. A discussion of another way to manage stateful callbacks, using Expat as a sample library. The GOBO project is working on an Eiffel binding for Expat. Development is active and the package is fully supported in GOBO 3.0 and 3.1, though there isn't much status information about the Expat bindings on the website. (Most activity is reportedly on the relevant mailing lists.) Expat4D is a plug-in for the 4th Dimension application framework."	"null"	"null"	"A stream-oriented XML parser.."	"true"
"XML"	"libxml2"	"http://xmlsoft.org/"	"A standards-compliant, portable XML parser.."	"null"	"null"	"null"	"Expat"	"http://directory.fsf.org/wiki/License:Expat"	"null"	"null"	"null"	"null"	"null"	"The XML C parser and toolkit of Gnome The XML C parser and toolkit of Gnome libxml Main Menu Home Reference Manual Introduction FAQ Developer Menu Reporting bugs and getting help How to help Downloads Releases XML XSLT Validation & DTDs Encodings support Catalog support Namespaces Contributions Code Examples API Menu XML Guidelines Recent Changes Related links Mail archive XSLT libxslt DOM gdome2 XML-DSig xmlsec FTP Windows binaries Solaris binaries MacOsX binaries lxml Python bindings Perl bindings C++ bindings PHP bindings Pascal bindings Ruby bindings Tcl bindings Bug Tracker ""Programming with libxml2 is like the thrilling embrace of an exotic stranger."" Mark Pilgrim Libxml2 is the XML C parser and toolkit developed for the Gnome project (but usable outside of the Gnome platform), it is free software available under the MIT License. XML itself is a metalanguage to design markup languages, i.e. text language where semantic and structure are added to the content using extra ""markup"" information enclosed between angle brackets. HTML is the most well-known markup language. Though the library is written in C a variety of language bindings make it available in other environments. Libxml2 is known to be very portable, the library should build and work without serious troubles on a variety of systems (Linux, Unix, Windows, CygWin, MacOS, MacOS X, RISC Os, OS/2, VMS, QNX, MVS, VxWorks, ...) Libxml2 implements a number of existing standards related to markup languages: the XML standard: http://www.w3.org/TR/REC-xml Namespaces in XML: http://www.w3.org/TR/REC-xml-names/ XML Base: http://www.w3.org/TR/xmlbase/ RFC 2396 : Uniform Resource Identifiers http://www.ietf.org/rfc/rfc2396.txt XML Path Language (XPath) 1.0: http://www.w3.org/TR/xpath HTML4 parser: http://www.w3.org/TR/html401/ XML Pointer Language (XPointer) Version 1.0: http://www.w3.org/TR/xptr XML Inclusions (XInclude) Version 1.0: http://www.w3.org/TR/xinclude/ ISO-8859-x encodings, as well as rfc2044 [UTF-8] and rfc2781 [UTF-16] Unicode encodings, and more if using iconv support part of SGML Open Technical Resolution TR9401:1997 XML Catalogs Working Draft 06 August 2001: http://www.oasis-open.org/committees/entity/spec-2001-08-06.html Canonical XML Version 1.0: http://www.w3.org/TR/xml-c14n and the Exclusive XML Canonicalization CR draft http://www.w3.org/TR/xml-exc-c14n Relax NG, ISO/IEC 19757-2:2003, http://www.oasis-open.org/committees/relax-ng/spec-20011203.html W3C XML Schemas Part 2: Datatypes REC 02 May 2001 W3C xml:id Working Draft 7 April 2004 In most cases libxml2 tries to implement the specifications in a relatively strictly compliant way. As of release 2.4.16, libxml2 passed all 1800+ tests from the OASIS XML Tests Suite. To some extent libxml2 provides support for the following additional specifications but doesn't claim to implement them completely: Document Object Model (DOM) http://www.w3.org/TR/DOM-Level-2-Core/ the document model, but it doesn't implement the API itself, gdome2 does this on top of libxml2 RFC 959 : libxml2 implements a basic FTP client code RFC 1945 : HTTP/1.0, again a basic HTTP client code SAX: a SAX2 like interface and a minimal SAX1 implementation compatible with early expat versions A partial implementation of XML Schemas Part 1: Structure is being worked on but it would be far too early to make any conformance statement about it at the moment. Separate documents: the libxslt page providing an implementation of XSLT 1.0 and common extensions like EXSLT for libxml2 the gdome2 page : a standard DOM2 implementation for libxml2 the XMLSec page: an implementation of W3C XML Digital Signature for libxml2 also check the related links section for more related and active projects. Hosting sponsored by Open Source CMS services from AOE media. Logo designed by Marc Liyanage. Daniel Veillard"	"null"	"null"	"A standards-compliant, portable XML parser.."	"true"
"XML"	"mini-xml"	"http://www.msweet.org/projects.php?Z3"	"A small XML reading and writing library. No dependencies aside from C standard library.."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Mini-XML - msweet.org Toggle Navigation msweet.org Login Blog Photos Projects ABNF to REGEX EPM HTMLDOC KeyboardFun Mini-XML RasterView Mini-XML Tiny XML Library Home Blog New Article Bugs New Bug Roadmap Documentation PDF Downloads Source (.tar.gz) Mailing List About Mini-XML Mini-XML is a small XML library that you can use to read and write XML and XML-like data files in your application without requiring large non-standard libraries. Mini-XML only requires an ANSI C compatible compiler (GCC works, as do most vendors' ANSI C compilers) and a 'make' program. Mini-XML supports reading of UTF-8 and UTF-16 and writing of UTF-8 encoded XML files and strings. Data is stored in a linked-list tree structure, preserving the XML data hierarchy, and arbitrary element names, attributes, and attribute values are supported with no preset limits, just available memory. License: LGPL2 w/Static Linking Stable: v2.10 SVN: http://svn.msweet.org/mxml List: mxml @ msweet.org   Mini-XML 2.10 Jun 13, 2016 Mini-XML 2.10 is now available for download from:    http://www.msweet.org/downloads.php/Mini-XML Mini-XML 2.10 fixes some stack overflow, XML, and API issues. Changes include: The version number in mxml.h was wrong (Bug #532) The mxml.spec file was out of date (Bug #521) Mini-XML no longer allows malformed element names (Bug #509) mxmlLoad* and mxmlSAXLoad* did not properly create text nodes when MXML_TEXT_CALLBACK was specified (Bug #531) mxmlDelete used a recursive algorithm which could require large amounts of stack space depending on the file (Bug #549, CVE-2016-4570) mxmlWrite* used a recursive algorithm which could require large amounts of stack space depending on the file (Bug #549, CVE-2016-4571) Enjoy! Post comment Mini-XML 2.9 Now Available Oct 19, 2014 Mini-XML 2.9 is now available for download from:   http://www.msweet.org/downloads.php/Mini-XML Mini-XML 2.9 fixes a bug in the mxmlLoad* functions when using the default (MXML_NO_CALLBACK or MXML_TEXT_CALLBACK) callback. 2 comments View All Articles Copyright © 1991-2016 by Michael R Sweet. All rights reserved."	"null"	"null"	"A small XML reading and writing library. No dependencies aside from C standard library.."	"true"
"XML"	"GNU LGPL2.1 with static linking exception"	"http://svn.msweet.org/mxml/trunk/COPYING"	"A small XML reading and writing library. No dependencies aside from C standard library.."	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"null"	"Mini-XML License September 18, 2010 The Mini-XML library and included programs are provided under the terms of the GNU Library General Public License version 2 (LGPL2) with the following exceptions: 1. Static linking of applications to the Mini-XML library does not constitute a derivative work and does not require the author to provide source code for the application, use the shared Mini-XML libraries, or link their applications against a user-supplied version of Mini-XML. If you link the application to a modified version of Mini-XML, then the changes to Mini-XML must be provided under the terms of the LGPL2 in sections 1, 2, and 4. 2. You do not have to provide a copy of the Mini-XML license with programs that are linked to the Mini-XML library, nor do you have to identify the Mini-XML license in your program or documentation as required by section 6 of the LGPL2. GNU LIBRARY GENERAL PUBLIC LICENSE Version 2, June 1991 Copyright (C) 1991 Free Software Foundation, Inc. 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed. [This is the first released version of the library GPL. It is numbered 2 because it goes with version 2 of the ordinary GPL.] Preamble The licenses for most software are designed to take away your freedom to share and change it. By contrast, the GNU General Public Licenses are intended to guarantee your freedom to share and change free software--to make sure the software is free for all its users. This license, the Library General Public License, applies to some specially designated Free Software Foundation software, and to any other libraries whose authors decide to use it. You can use it for your libraries, too. When we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for this service if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs; and that you know you can do these things. To protect your rights, we need to make restrictions that forbid anyone to deny you these rights or to ask you to surrender the rights. These restrictions translate to certain responsibilities for you if you distribute copies of the library, or if you modify it. For example, if you distribute copies of the library, whether gratis or for a fee, you must give the recipients all the rights that we gave you. You must make sure that they, too, receive or can get the source code. If you link a program with the library, you must provide complete object files to the recipients so that they can relink them with the library, after making changes to the library and recompiling it. And you must show them these terms so they know their rights. Our method of protecting your rights has two steps: (1) copyright the library, and (2) offer you this license which gives you legal permission to copy, distribute and/or modify the library. Also, for each distributor's protection, we want to make certain that everyone understands that there is no warranty for this free library. If the library is modified by someone else and passed on, we want its recipients to know that what they have is not the original version, so that any problems introduced by others will not reflect on the original authors' reputations. Finally, any free program is threatened constantly by software patents. We wish to avoid the danger that companies distributing free software will individually obtain patent licenses, thus in effect transforming the program into proprietary software. To prevent this, we have made it clear that any patent must be licensed for everyone's free use or not licensed at all. Most GNU software, including some libraries, is covered by the ordinary GNU General Public License, which was designed for utility programs. This license, the GNU Library General Public License, applies to certain designated libraries. This license is quite different from the ordinary one; be sure to read it in full, and don't assume that anything in it is the same as in the ordinary license. The reason we have a separate public license for some libraries is that they blur the distinction we usually make between modifying or adding to a program and simply using it. Linking a program with a library, without changing the library, is in some sense simply using the library, and is analogous to running a utility program or application program. However, in a textual and legal sense, the linked executable is a combined work, a derivative of the original library, and the ordinary General Public License treats it as such. Because of this blurred distinction, using the ordinary General Public License for libraries did not effectively promote software sharing, because most developers did not use the libraries. We concluded that weaker conditions might promote sharing better. However, unrestricted linking of non-free programs would deprive the users of those programs of all benefit from the free status of the libraries themselves. This Library General Public License is intended to permit developers of non-free programs to use free libraries, while preserving your freedom as a user of such programs to change the free libraries that are incorporated in them. (We have not seen how to achieve this as regards changes in header files, but we have achieved it as regards changes in the actual functions of the Library.) The hope is that this will lead to faster development of free libraries. The precise terms and conditions for copying, distribution and modification follow. Pay close attention to the difference between a ""work based on the library"" and a ""work that uses the library"". The former contains code derived from the library, while the latter only works together with the library. Note that it is possible for a library to be covered by the ordinary General Public License rather than by this special one. GNU LIBRARY GENERAL PUBLIC LICENSE TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION 0. This License Agreement applies to any software library which contains a notice placed by the copyright holder or other authorized party saying it may be distributed under the terms of this Library General Public License (also called ""this License""). Each licensee is addressed as ""you"". A ""library"" means a collection of software functions and/or data prepared so as to be conveniently linked with application programs (which use some of those functions and data) to form executables. The ""Library"", below, refers to any such software library or work which has been distributed under these terms. A ""work based on the Library"" means either the Library or any derivative work under copyright law: that is to say, a work containing the Library or a portion of it, either verbatim or with modifications and/or translated straightforwardly into another language. (Hereinafter, translation is included without limitation in the term ""modification"".) ""Source code"" for a work means the preferred form of the work for making modifications to it. For a library, complete source code means all the source code for all modules it contains, plus any associated interface definition files, plus the scripts used to control compilation and installation of the library. Activities other than copying, distribution and modification are not covered by this License; they are outside its scope. The act of running a program using the Library is not restricted, and output from such a program is covered only if its contents constitute a work based on the Library (independent of the use of the Library in a tool for writing it). Whether that is true depends on what the Library does and what the program that uses the Library does. 1. You may copy and distribute verbatim copies of the Library's complete source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice and disclaimer of warranty; keep intact all the notices that refer to this License and to the absence of any warranty; and distribute a copy of this License along with the Library. You may charge a fee for the physical act of transferring a copy, and you may at your option offer warranty protection in exchange for a fee. 2. You may modify your copy or copies of the Library or any portion of it, thus forming a work based on the Library, and copy and distribute such modifications or work under the terms of Section 1 above, provided that you also meet all of these conditions: a) The modified work must itself be a software library. b) You must cause the files modified to carry prominent notices stating that you changed the files and the date of any change. c) You must cause the whole of the work to be licensed at no charge to all third parties under the terms of this License. d) If a facility in the modified Library refers to a function or a table of data to be supplied by an application program that uses the facility, other than as an argument passed when the facility is invoked, then you must make a good faith effort to ensure that, in the event an application does not supply such function or table, the facility still operates, and performs whatever part of its purpose remains meaningful. (For example, a function in a library to compute square roots has a purpose that is entirely well-defined independent of the application. Therefore, Subsection 2d requires that any application-supplied function or table used by this function must be optional: if the application does not supply it, the square root function must still compute square roots.) These requirements apply to the modified work as a whole. If identifiable sections of that work are not derived from the Library, and can be reasonably considered independent and separate works in themselves, then this License, and its terms, do not apply to those sections when you distribute them as separate works. But when you distribute the same sections as part of a whole which is a work based on the Library, the distribution of the whole must be on the terms of this License, whose permissions for other licensees extend to the entire whole, and thus to each and every part regardless of who wrote it. Thus, it is not the intent of this section to claim rights or contest your rights to work written entirely by you; rather, the intent is to exercise the right to control the distribution of derivative or collective works based on the Library. In addition, mere aggregation of another work not based on the Library with the Library (or with a work based on the Library) on a volume of a storage or distribution medium does not bring the other work under the scope of this License. 3. You may opt to apply the terms of the ordinary GNU General Public License instead of this License to a given copy of the Library. To do this, you must alter all the notices that refer to this License, so that they refer to the ordinary GNU General Public License, version 2, instead of to this License. (If a newer version than version 2 of the ordinary GNU General Public License has appeared, then you can specify that version instead if you wish.) Do not make any other change in these notices. Once this change is made in a given copy, it is irreversible for that copy, so the ordinary GNU General Public License applies to all subsequent copies and derivative works made from that copy. This option is useful when you wish to copy part of the code of the Library into a program that is not a library. 4. You may copy and distribute the Library (or a portion or derivative of it, under Section 2) in object code or executable form under the terms of Sections 1 and 2 above provided that you accompany it with the complete corresponding machine-readable source code, which must be distributed under the terms of Sections 1 and 2 above on a medium customarily used for software interchange. If distribution of object code is made by offering access to copy from a designated place, then offering equivalent access to copy the source code from the same place satisfies the requirement to distribute the source code, even though third parties are not compelled to copy the source along with the object code. 5. A program that contains no derivative of any portion of the Library, but is designed to work with the Library by being compiled or linked with it, is called a ""work that uses the Library"". Such a work, in isolation, is not a derivative work of the Library, and therefore falls outside the scope of this License. However, linking a ""work that uses the Library"" with the Library creates an executable that is a derivative of the Library (because it contains portions of the Library), rather than a ""work that uses the library"". The executable is therefore covered by this License. Section 6 states terms for distribution of such executables. When a ""work that uses the Library"" uses material from a header file that is part of the Library, the object code for the work may be a derivative work of the Library even though the source code is not. Whether this is true is especially significant if the work can be linked without the Library, or if the work is itself a library. The threshold for this to be true is not precisely defined by law. If such an object file uses only numerical parameters, data structure layouts and accessors, and small macros and small inline functions (ten lines or less in length), then the use of the object file is unrestricted, regardless of whether it is legally a derivative work. (Executables containing this object code plus portions of the Library will still fall under Section 6.) Otherwise, if the work is a derivative of the Library, you may distribute the object code for the work under the terms of Section 6. Any executables containing that work also fall under Section 6, whether or not they are linked directly with the Library itself. 6. As an exception to the Sections above, you may also compile or link a ""work that uses the Library"" with the Library to produce a work containing portions of the Library, and distribute that work under terms of your choice, provided that the terms permit modification of the work for the customer's own use and reverse engineering for debugging such modifications. You must give prominent notice with each copy of the work that the Library is used in it and that the Library and its use are covered by this License. You must supply a copy of this License. If the work during execution displays copyright notices, you must include the copyright notice for the Library among them, as well as a reference directing the user to the copy of this License. Also, you must do one of these things: a) Accompany the work with the complete corresponding machine-readable source code for the Library including whatever changes were used in the work (which must be distributed under Sections 1 and 2 above); and, if the work is an executable linked with the Library, with the complete machine-readable ""work that uses the Library"", as object code and/or source code, so that the user can modify the Library and then relink to produce a modified executable containing the modified Library. (It is understood that the user who changes the contents of definitions files in the Library will not necessarily be able to recompile the application to use the modified definitions.) b) Accompany the work with a written offer, valid for at least three years, to give the same user the materials specified in Subsection 6a, above, for a charge no more than the cost of performing this distribution. c) If distribution of the work is made by offering access to copy from a designated place, offer equivalent access to copy the above specified materials from the same place. d) Verify that the user has already received a copy of these materials or that you have already sent this user a copy. For an executable, the required form of the ""work that uses the Library"" must include any data and utility programs needed for reproducing the executable from it. However, as a special exception, the source code distributed need not include anything that is normally distributed (in either source or binary form) with the major components (compiler, kernel, and so on) of the operating system on which the executable runs, unless that component itself accompanies the executable. It may happen that this requirement contradicts the license restrictions of other proprietary libraries that do not normally accompany the operating system. Such a contradiction means you cannot use both them and the Library together in an executable that you distribute. 7. You may place library facilities that are a work based on the Library side-by-side in a single library together with other library facilities not covered by this License, and distribute such a combined library, provided that the separate distribution of the work based on the Library and of the other library facilities is otherwise permitted, and provided that you do these two things: a) Accompany the combined library with a copy of the same work based on the Library, uncombined with any other library facilities. This must be distributed under the terms of the Sections above. b) Give prominent notice with the combined library of the fact that part of it is a work based on the Library, and explaining where to find the accompanying uncombined form of the same work. 8. You may not copy, modify, sublicense, link with, or distribute the Library except as expressly provided under this License. Any attempt otherwise to copy, modify, sublicense, link with, or distribute the Library is void, and will automatically terminate your rights under this License. However, parties who have received copies, or rights, from you under this License will not have their licenses terminated so long as such parties remain in full compliance. 9. You are not required to accept this License, since you have not signed it. However, nothing else grants you permission to modify or distribute the Library or its derivative works. These actions are prohibited by law if you do not accept this License. Therefore, by modifying or distributing the Library (or any work based on the Library), you indicate your acceptance of this License to do so, and all its terms and conditions for copying, distributing or modifying the Library or works based on it. 10. Each time you redistribute the Library (or any work based on the Library), the recipient automatically receives a license from the original licensor to copy, distribute, link with or modify the Library subject to these terms and conditions. You may not impose any further restrictions on the recipients' exercise of the rights granted herein. You are not responsible for enforcing compliance by third parties to this License. 11. If, as a consequence of a court judgment or allegation of patent infringement or for any other reason (not limited to patent issues), conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License. If you cannot distribute so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not distribute the Library at all. For example, if a patent license would not permit royalty-free redistribution of the Library by all those who receive copies directly or indirectly through you, then the only way you could satisfy both it and this License would be to refrain entirely from distribution of the Library. If any portion of this section is held invalid or unenforceable under any particular circumstance, the balance of the section is intended to apply, and the section as a whole is intended to apply in other circumstances. It is not the purpose of this section to induce you to infringe any patents or other property right claims or to contest validity of any such claims; this section has the sole purpose of protecting the integrity of the free software distribution system which is implemented by public license practices. Many people have made generous contributions to the wide range of software distributed through that system in reliance on consistent application of that system; it is up to the author/donor to decide if he or she is willing to distribute software through any other system and a licensee cannot impose that choice. This section is intended to make thoroughly clear what is believed to be a consequence of the rest of this License. 12. If the distribution and/or use of the Library is restricted in certain countries either by patents or by copyrighted interfaces, the original copyright holder who places the Library under this License may add an explicit geographical distribution limitation excluding those countries, so that distribution is permitted only in or among countries not thus excluded. In such case, this License incorporates the limitation as if written in the body of this License. 13. The Free Software Foundation may publish revised and/or new versions of the Library General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns. Each version is given a distinguishing version number. If the Library specifies a version number of this License which applies to it and ""any later version"", you have the option of following the terms and conditions either of that version or of any later version published by the Free Software Foundation. If the Library does not specify a license version number, you may choose any version ever published by the Free Software Foundation. 14. If you wish to incorporate parts of the Library into other free programs whose distribution conditions are incompatible with these, write to the author to ask for permission. For software which is copyrighted by the Free Software Foundation, write to the Free Software Foundation; we sometimes make exceptions for this. Our decision will be guided by the two goals of preserving the free status of all derivatives of our free software and of promoting the sharing and reuse of software generally. NO WARRANTY 15. BECAUSE THE LIBRARY IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY FOR THE LIBRARY, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE LIBRARY ""AS IS"" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE LIBRARY IS WITH YOU. SHOULD THE LIBRARY PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION. 16. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR REDISTRIBUTE THE LIBRARY AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE LIBRARY (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE LIBRARY TO OPERATE WITH ANY OTHER SOFTWARE), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. END OF TERMS AND CONDITIONS Appendix: How to Apply These Terms to Your New Libraries If you develop a new library, and you want it to be of the greatest possible use to the public, we recommend making it free software that everyone can redistribute and change. You can do so by permitting redistribution under these terms (or, alternatively, under the terms of the ordinary General Public License). To apply these terms, attach the following notices to the library. It is safest to attach them to the start of each source file to most effectively convey the exclusion of warranty; and each file should have at least the ""copyright"" line and a pointer to where the full notice is found. Copyright (C) This library is free software; you can redistribute it and/or modify it under the terms of the GNU Library General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version. This library is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Library General Public License for more details. You should have received a copy of the GNU Library General Public License along with this library; if not, write to the Free Software Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA. Also add information on how to contact you by electronic and paper mail. You should also get your employer (if you work as a programmer) or your school, if any, to sign a ""copyright disclaimer"" for the library, if necessary. Here is a sample; alter the names: Yoyodyne, Inc., hereby disclaims all copyright interest in the library `Frob' (a library for tweaking knobs) written by James Random Hacker. , 1 April 1990 Ty Coon, President of Vice That's all there is to it!"	"null"	"null"	"A small XML reading and writing library. No dependencies aside from C standard library.."	"true"
